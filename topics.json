{"topics": [["human", "bias"], ["data", "training"], ["attention", "performance"], ["llms", "large"], ["user", "system", "recommendation", "dialog"], ["dialogue", "explanation", "interpretability", "explainability"], ["response", "code", "generation", "conversation"], ["generation", "text"], ["question", "answering", "answer", "retrieval"], ["chatgpt", "llms", "ai"], ["transformer", "bert", "modeling"], ["learning", "agent", "reinforcement", "instruction"], ["research", "benchmark"], ["efficiency", "parameter", "training", "optimization"], ["translation", "machine", "multilingual", "neural"], ["generation", "text", "generative"], ["knowledge", "graph"], ["prompt", "prompting", "learning", "tuning"], ["multimodal", "visual", "image", "models"], ["pretrained", "pretraining", "lms", "lm"]], "paper_data": [{"key": "abbasiantaeb2023let", "year": "2023", "title": "Let The Llms Talk: Simulating Human-to-human Conversational QA Via Zero-shot Llm-to-llm Interactions", "topic_distr": {"0": 0.20155127346515656, "1": 0.000722497352398932, "2": 0.0006106146611273289, "3": 0.252216100692749, "4": 0.10032887756824493, "5": 0.00041719316504895687, "6": 0.0760912299156189, "7": 0.038697585463523865, "8": 0.14481021463871002, "9": 0.11829978972673416, "10": 0.00027305641560815275, "11": 0.00025540817296132445, "12": 0.00023990268527995795, "13": 0.06434811651706696, "14": 0.0002139281277777627, "15": 0.00020294175192248076, "16": 0.0001930286962306127, "17": 0.0001840389595599845, "18": 0.00017584931629244238, "19": 0.0001683574664639309}}, {"key": "abdelghani2022gpt", "year": "2022", "title": "Gpt-3-driven Pedagogical Agents For Training Children's Curious Question-asking Skills", "topic_distr": {"0": 0.09044615924358368, "1": 0.10123594850301743, "2": 0.0006194154266268015, "3": 0.08801217377185822, "4": 0.00047316146083176136, "5": 0.0004232076753396541, "6": 0.000382794882170856, "7": 0.05568306893110275, "8": 0.07735831290483475, "9": 0.10672155767679214, "10": 0.0002769929124042392, "11": 0.05842796340584755, "12": 0.2086396962404251, "13": 0.11449641734361649, "14": 0.0002170122170355171, "15": 0.09585446119308472, "16": 0.00019581148808356375, "17": 0.00018669215205591172, "18": 0.00017838444910012186, "19": 0.00017078459495678544}}, {"key": "aberdam2023looking", "year": "2023", "title": "CLIPTER: Looking At The Bigger Picture In Scene Text Recognition", "topic_distr": {"0": 0.0017567765899002552, "1": 0.0821460485458374, "2": 0.20273461937904358, "3": 0.0010502950754016638, "4": 0.0009263165411539376, "5": 0.0008285216172225773, "6": 0.0007494048331864178, "7": 0.1522810459136963, "8": 0.0006292320904321969, "9": 0.0005825259140692651, "10": 0.0005422743270173669, "11": 0.0005072259809821844, "12": 0.06877351552248001, "13": 0.0004491647705435753, "14": 0.0004248489858582616, "15": 0.0004030306590721011, "16": 0.0003833438968285918, "17": 0.12445643544197083, "18": 0.3600409924983978, "19": 0.00033434826764278114}}, {"key": "abukhalaf2023codex", "year": "2023", "title": "On Codex Prompt Engineering For OCL Generation: An Empirical Study", "topic_distr": {"0": 0.10980358719825745, "1": 0.0011069808388128877, "2": 0.0009358651586808264, "3": 0.37422633171081543, "4": 0.0007148936274461448, "5": 0.0006394194788299501, "6": 0.18535642325878143, "7": 0.13954900205135345, "8": 0.00048561589210294187, "9": 0.0004495699249673635, "10": 0.0004185053985565901, "11": 0.0003914564731530845, "12": 0.0003676916821859777, "13": 0.0003466471971478313, "14": 0.0003278812509961426, "15": 0.00031104276422411203, "16": 0.0002958493132609874, "17": 0.11290574073791504, "18": 0.07110946625471115, "19": 0.00025803648168221116}}, {"key": "adiwardana2020towards", "year": "2020", "title": "Towards A Human-like Open-domain Chatbot", "topic_distr": {"0": 0.2697882354259491, "1": 0.001543210120871663, "2": 0.44773975014686584, "3": 0.001129804295487702, "4": 0.0009964409982785583, "5": 0.0008912418270483613, "6": 0.10222779959440231, "7": 0.06280941516160965, "8": 0.0006768657476641238, "9": 0.055116113275289536, "10": 0.0005833252216689289, "11": 0.0005456235958263278, "12": 0.0005124995368532836, "13": 0.03205203264951706, "14": 0.00045701058115810156, "15": 0.000433540582889691, "16": 0.00041236350079998374, "17": 0.02134944312274456, "18": 0.0003756635414902121, "19": 0.00035965885035693645}}, {"key": "adlakha2023evaluating", "year": "2023", "title": "Evaluating Correctness And Faithfulness Of Instruction-following Models For Question Answering", "topic_distr": {"0": 0.12920629978179932, "1": 0.0009701922535896301, "2": 0.11065986752510071, "3": 0.3849026560783386, "4": 0.0687098503112793, "5": 0.012887335382401943, "6": 0.11209307610988617, "7": 0.02464388497173786, "8": 0.12564069032669067, "9": 0.0003939030284527689, "10": 0.0003666849806904793, "11": 0.00034298532409593463, "12": 0.0003221631341148168, "13": 0.0003037244314327836, "14": 0.000287282164208591, "15": 0.00027252864674665034, "16": 0.02728750929236412, "17": 0.00024714425671845675, "18": 0.00023614645760972053, "19": 0.000226085729082115}}, {"key": "aflalo2022vl", "year": "2022", "title": "Vl-interpret: An Interactive Visualization Tool For Interpreting Vision-language Transformers", "topic_distr": {"0": 0.07858669757843018, "1": 0.013137958943843842, "2": 0.13863496482372284, "3": 0.0007688914192840457, "4": 0.0006781282718293369, "5": 0.0523725226521492, "6": 0.000548616168089211, "7": 0.0005007945001125336, "8": 0.030548209324479103, "9": 0.12264204770326614, "10": 0.29498422145843506, "11": 0.0003713244805112481, "12": 0.00034878187580034137, "13": 0.00032881967490538955, "14": 0.0003110188408754766, "15": 0.0002950463385786861, "16": 0.0002806342381518334, "17": 0.00026756455190479755, "18": 0.24599634110927582, "19": 0.018397433683276176}}, {"key": "agarwal2018knowledge", "year": "2018", "title": "A Knowledge-grounded Multimodal Search-based Conversational Agent", "topic_distr": {"0": 0.0021512333769351244, "1": 0.0017559125553816557, "2": 0.0014843638055026531, "3": 0.001285629696212709, "4": 0.0011338760377839208, "5": 0.09493248909711838, "6": 0.21491739153862, "7": 0.0008373626042157412, "8": 0.039202332496643066, "9": 0.0007130522863008082, "10": 0.0006637815968133509, "11": 0.07014438509941101, "12": 0.0005831870948895812, "13": 0.0005498089594766498, "14": 0.047899942845106125, "15": 0.0004933376330882311, "16": 0.14194940030574799, "17": 0.00044738620636053383, "18": 0.37844589352607727, "19": 0.0004092655726708472}}, {"key": "agarwal2020history", "year": "2020", "title": "History For Visual Dialog: Do We Really Need It?", "topic_distr": {"0": 0.0021493323147296906, "1": 0.001756366342306137, "2": 0.3573743999004364, "3": 0.0012856730027124286, "4": 0.2571316361427307, "5": 0.001014198875054717, "6": 0.13381539285182953, "7": 0.0008373877499252558, "8": 0.09090571850538254, "9": 0.0007130737067200243, "10": 0.0006638015620410442, "11": 0.0006208985578268766, "12": 0.0005832046153955162, "13": 0.0005498254904523492, "14": 0.0005200603627599776, "15": 0.0004933524178341031, "16": 0.00046925374772399664, "17": 0.00044739965233020484, "18": 0.1482597440481186, "19": 0.0004092778835911304}}, {"key": "aghajanyan2020better", "year": "2020", "title": "Better Fine-tuning By Reducing Representational Collapse", "topic_distr": {"0": 0.1453135907649994, "1": 0.05119005963206291, "2": 0.5071653127670288, "3": 0.0009560061735101044, "4": 0.0008431577007286251, "5": 0.0007541424711234868, "6": 0.0006821283022873104, "7": 0.029432114213705063, "8": 0.0005727438256144524, "9": 0.0005302306381054223, "10": 0.0004935925826430321, "11": 0.00046169059351086617, "12": 0.00043366197496652603, "13": 0.08024734258651733, "14": 0.0003867088817059994, "15": 0.00036684927181340754, "16": 0.0003489298396743834, "17": 0.0003326794831082225, "18": 0.17918474972248077, "19": 0.00030433270148932934}}, {"key": "aghajanyan2021hyper", "year": "2021", "title": "HTLM: Hyper-text Pre-training And Prompting Of Language Models", "topic_distr": {"0": 0.0015028900234028697, "1": 0.0012271301820874214, "2": 0.16477154195308685, "3": 0.0008983740117400885, "4": 0.000792328966781497, "5": 0.0007086799014359713, "6": 0.0006410068599507213, "7": 0.0892198234796524, "8": 0.0005382165545597672, "9": 0.0004982661921530962, "10": 0.00046383682638406754, "11": 0.0004338580183684826, "12": 0.05948008596897125, "13": 0.00038419512566179037, "14": 0.0003633965097833425, "15": 0.00034473411506041884, "16": 0.0003278949297964573, "17": 0.24113228917121887, "18": 0.0002987126063089818, "19": 0.43597275018692017}}, {"key": "aghajanyan2021massive", "year": "2021", "title": "Muppet: Massive Multi-task Representations With Pre-finetuning", "topic_distr": {"0": 0.0022667679004371166, "1": 0.0018520705634728074, "2": 0.4827495515346527, "3": 0.08158939331769943, "4": 0.001195708871819079, "5": 0.0010694736847653985, "6": 0.0009673480526544154, "7": 0.0008830263977870345, "8": 0.000812226440757513, "9": 0.0007519370992667973, "10": 0.12708231806755066, "11": 0.0006547382799908519, "12": 0.0006149900145828724, "13": 0.11119609326124191, "14": 0.000548404292203486, "15": 0.043070923537015915, "16": 0.0004948286223225296, "17": 0.14131778478622437, "18": 0.0004507893172558397, "19": 0.0004315839905757457}}, {"key": "agrawal2017just", "year": "2017", "title": "Don't Just Assume; Look And Answer: Overcoming Priors For Visual Question Answering", "topic_distr": {"0": 0.09271624684333801, "1": 0.0007275409298017621, "2": 0.3932173550128937, "3": 0.0005326372338458896, "4": 0.0004697646654676646, "5": 0.0004201699048280716, "6": 0.00038004718953743577, "7": 0.0003469192888587713, "8": 0.15244007110595703, "9": 0.00029541755793616176, "10": 0.0002750046842265874, "11": 0.0002572305384092033, "12": 0.00024161439796444029, "13": 0.0002277858293382451, "14": 0.0002154545218218118, "15": 0.00020438975479919463, "16": 0.00019440596224740148, "17": 0.00018535209528636187, "18": 0.3564831018447876, "19": 0.00016955871251411736}}, {"key": "agrawal2022examples", "year": "2022", "title": "In-context Examples Selection For Machine Translation", "topic_distr": {"0": 0.001300762640312314, "1": 0.171820268034935, "2": 0.18508188426494598, "3": 0.0007767983479425311, "4": 0.0006851021316833794, "5": 0.0006127731176093221, "6": 0.000554258469492197, "7": 0.06405019760131836, "8": 0.0004653789510484785, "9": 0.0004308351199142635, "10": 0.0004010651318822056, "11": 0.09121158719062805, "12": 0.05718608200550079, "13": 0.00033220145269297063, "14": 0.2558225691318512, "15": 0.0002980807621497661, "16": 0.015675151720643044, "17": 0.1527893990278244, "18": 0.0002582874149084091, "19": 0.00024728337302803993}}, {"key": "aharoni2019massively", "year": "2019", "title": "Massively Multilingual Neural Machine Translation", "topic_distr": {"0": 0.0015209427801892161, "1": 0.0012420817511156201, "2": 0.25968319177627563, "3": 0.0009093961562030017, "4": 0.0008020494715310633, "5": 0.0007173744961619377, "6": 0.0006488708895631135, "7": 0.0005923102144151926, "8": 0.0005448195151984692, "9": 0.0005043790442869067, "10": 0.0004695272946264595, "11": 0.0004391807015053928, "12": 0.07978832721710205, "13": 0.00038890852010808885, "14": 0.6501594185829163, "15": 0.0003489633963909, "16": 0.000331917661242187, "17": 0.00031645959825254977, "18": 0.0003023772733286023, "19": 0.00028949487023055553}}, {"key": "aher2022using", "year": "2022", "title": "Using Large Language Models To Simulate Multiple Humans And Replicate Human Subject Studies", "topic_distr": {"0": 0.5580657124519348, "1": 0.00128950085490942, "2": 0.15096504986286163, "3": 0.0009439041605219245, "4": 0.000832482532132417, "5": 0.000744593795388937, "6": 0.0006734913331456482, "7": 0.0006147845415398479, "8": 0.0005654919077642262, "9": 0.13291703164577484, "10": 0.00048734285519458354, "11": 0.04073406010866165, "12": 0.0004281710716895759, "13": 0.00040366509347222745, "14": 0.00038181248237378895, "15": 0.0003622043295763433, "16": 0.00034451179089955986, "17": 0.10863185673952103, "18": 0.0003138505562674254, "19": 0.00030047932523302734}}, {"key": "ahmad2019evaluation", "year": "2019", "title": "Reqa: An Evaluation For End-to-end Answer Retrieval Models", "topic_distr": {"0": 0.0018361828988417983, "1": 0.0014977717073634267, "2": 0.22136671841144562, "3": 0.0010967006674036384, "4": 0.0009672414744272828, "5": 0.000865125737618655, "6": 0.028347982093691826, "7": 0.0007143033435568213, "8": 0.4244234561920166, "9": 0.0364573635160923, "10": 0.0005662319017574191, "11": 0.0005296350573189557, "12": 0.2785021960735321, "13": 0.00046900875167921185, "14": 0.00044361871550790966, "15": 0.00042083646985702217, "16": 0.0004002799396403134, "17": 0.00038163812132552266, "18": 0.0003646553959697485, "19": 0.0003491196839604527}}, {"key": "ahmad2020transformer", "year": "2020", "title": "A Transformer-based Approach For Source Code Summarization", "topic_distr": {"0": 0.001664719544351101, "1": 0.0013578286161646247, "2": 0.2175763100385666, "3": 0.04251614585518837, "4": 0.0008768611587584019, "5": 0.0007842873455956578, "6": 0.1959727704524994, "7": 0.08394346386194229, "8": 0.0005956377717666328, "9": 0.000551425211597234, "10": 0.3830180764198303, "11": 0.0004801454779226333, "12": 0.06809747219085693, "13": 0.00042518414556980133, "14": 0.0004021665663458407, "15": 0.000381513120373711, "16": 0.0003628774138633162, "17": 0.0003459774889051914, "18": 0.00033058164990507066, "19": 0.00031649760785512626}}, {"key": "ahmad2021unified", "year": "2021", "title": "Unified Pre-training For Program Understanding And Generation", "topic_distr": {"0": 0.0016856550937518477, "1": 0.053727708756923676, "2": 0.0011635037371888757, "3": 0.29250842332839966, "4": 0.0008888012380339205, "5": 0.0007949663558974862, "6": 0.29871711134910583, "7": 0.08148206025362015, "8": 0.0006037480779923499, "9": 0.000558933534193784, "10": 0.12630675733089447, "11": 0.00048668321687728167, "12": 0.05914907157421112, "13": 0.00043097350862808526, "14": 0.05078154057264328, "15": 0.0003867078630719334, "16": 0.0003678184002637863, "17": 0.02930361032485962, "18": 0.00033508290653117, "19": 0.0003208070993423462}}, {"key": "ahmad2023creating", "year": "2023", "title": "Creating Trustworthy Llms: Dealing With Hallucinations In Healthcare AI", "topic_distr": {"0": 0.31650084257125854, "1": 0.0014760277699679136, "2": 0.0012478295248001814, "3": 0.0010807702783495188, "4": 0.0009531930554658175, "5": 0.0008525598677806556, "6": 0.0007711476064287126, "7": 0.11559966206550598, "8": 0.0006474882829934359, "9": 0.3816525638103485, "10": 0.0005580075667239726, "11": 0.0005219422746449709, "12": 0.17534996569156647, "13": 0.0004621965636033565, "14": 0.00043717530206777155, "15": 0.0004147239669691771, "16": 0.000394466012949124, "17": 0.00037609494756907225, "18": 0.00035935890628024936, "19": 0.0003440488362684846}}, {"key": "ahmed2017weighted", "year": "2017", "title": "Weighted Transformer Network For Machine Translation", "topic_distr": {"0": 0.0019786914344877005, "1": 0.0016165381530299783, "2": 0.4846000075340271, "3": 0.0011835865443572402, "4": 0.0010438758181408048, "5": 0.000933670555241406, "6": 0.0008445128914900124, "7": 0.0007708985940553248, "8": 0.0007090889266692102, "9": 0.0006564551731571555, "10": 0.17760328948497772, "11": 0.0005715987645089626, "12": 0.0005368978017941117, "13": 0.06515788286924362, "14": 0.2597246468067169, "15": 0.0004541798844002187, "16": 0.0004319946456234902, "17": 0.00041187580791302025, "18": 0.0003935475251637399, "19": 0.00037678092485293746}}, {"key": "ahmed2022few", "year": "2022", "title": "Few-shot Training Llms For Project-specific Code-summarization", "topic_distr": {"0": 0.09158819913864136, "1": 0.25507885217666626, "2": 0.001345284515991807, "3": 0.29762160778045654, "4": 0.0010276337852701545, "5": 0.0009191411081701517, "6": 0.0008313709986396134, "7": 0.000758902111556381, "8": 0.0006980542675592005, "9": 0.2799002528190613, "10": 0.06613366305828094, "11": 0.0005627037025988102, "12": 0.0005285427323542535, "13": 0.0004982920945622027, "14": 0.0004713167727459222, "15": 0.0004471121064852923, "16": 0.0004252720973454416, "17": 0.0004054663295391947, "18": 0.00038742326432839036, "19": 0.0003709175798576325}}, {"key": "ahmed2023automatic", "year": "2023", "title": "Automatic Semantic Augmentation Of Language Model Prompts (for Code Summarization)", "topic_distr": {"0": 0.049496352672576904, "1": 0.04484277591109276, "2": 0.206473246216774, "3": 0.3809616267681122, "4": 0.0004216283850837499, "5": 0.00037711553159169853, "6": 0.0003411040815990418, "7": 0.07156956940889359, "8": 0.019306493923068047, "9": 0.00026514637283980846, "10": 0.0002468251914251596, "11": 0.0002308723342139274, "12": 0.00021685638057533652, "13": 0.00020444481924641877, "14": 0.03407270088791847, "15": 0.00018344611453358084, "16": 0.09818011522293091, "17": 0.09229852259159088, "18": 0.00015895631804596633, "19": 0.00015218417684081942}}, {"key": "ahmed2023better", "year": "2023", "title": "Better Patching Using LLM Prompting, Via Self-consistency", "topic_distr": {"0": 0.0013875379227101803, "1": 0.0011316919699311256, "2": 0.0009566370281390846, "3": 0.7377866506576538, "4": 0.000730755040422082, "5": 0.17107488214969635, "6": 0.0005911926855333149, "7": 0.08204346150159836, "8": 0.0004963904502801597, "9": 0.0004595447680912912, "10": 0.00042779097566381097, "11": 0.0004001419001724571, "12": 0.00037584983510896564, "13": 0.0003543384082149714, "14": 0.0003351561026647687, "15": 0.000317944010021165, "16": 0.00030241344938986003, "17": 0.00028832946554757655, "18": 0.0002754989545792341, "19": 0.00026376164169050753}}, {"key": "ahn2022do", "year": "2022", "title": "Do As I Can, Not As I Say: Grounding Language In Robotic Affordances", "topic_distr": {"0": 0.12392780929803848, "1": 0.0009700296213850379, "2": 0.0008199907606467605, "3": 0.0007102148956619203, "4": 0.0006263777031563222, "5": 0.015683067962527275, "6": 0.0005067497841082513, "7": 0.00046257750364020467, "8": 0.0004254886298440397, "9": 0.0003939057351090014, "10": 0.000366687512723729, "11": 0.6603780388832092, "12": 0.00032216537510976195, "13": 0.00030372655601240695, "14": 0.00028728414326906204, "15": 0.00027253053849563, "16": 0.16274964809417725, "17": 0.0002471459738444537, "18": 0.01634429767727852, "19": 0.014202219434082508}}, {"key": "ahuja2019natural", "year": "2019", "title": "Language2pose: Natural Language Grounded Pose Forecasting", "topic_distr": {"0": 0.08509223908185959, "1": 0.0011708803940564394, "2": 0.0009896875126287341, "3": 0.0008571881917305291, "4": 0.12194608896970749, "5": 0.0006761859403923154, "6": 0.0006116158328950405, "7": 0.0005583026213571429, "8": 0.00051353860180825, "9": 0.0004754200344905257, "10": 0.12553322315216064, "11": 0.11184269189834595, "12": 0.0003888338105753064, "13": 0.0003665792755782604, "14": 0.10950285196304321, "15": 0.20575964450836182, "16": 0.0003128605312667787, "17": 0.00029828998958691955, "18": 0.2328309863805771, "19": 0.0002728734689299017}}, {"key": "ahuja2023multilingual", "year": "2023", "title": "MEGA: Multilingual Evaluation Of Generative AI", "topic_distr": {"0": 0.04046391323208809, "1": 0.0010834679706022143, "2": 0.0009159265318885446, "3": 0.22068816423416138, "4": 0.000699658936355263, "5": 0.0006257937056943774, "6": 0.0005660355091094971, "7": 0.0005166954360902309, "8": 0.012440239079296589, "9": 0.16900239884853363, "10": 0.0004095870826859027, "11": 0.00038311455864459276, "12": 0.28939998149871826, "13": 0.00033926015021279454, "14": 0.07112640887498856, "15": 0.19025744497776031, "16": 0.00028954478329978883, "17": 0.0002760601055342704, "18": 0.00026377555332146585, "19": 0.0002525377203710377}}, {"key": "ai2024open", "year": "2024", "title": "Yi: Open Foundation Models By 01.AI", "topic_distr": {"0": 0.001067297300323844, "1": 0.08399209380149841, "2": 0.17293310165405273, "3": 0.0006373856449499726, "4": 0.024803554639220238, "5": 0.0005027989973314106, "6": 0.0004547859134618193, "7": 0.0004151432076469064, "8": 0.00038185756420716643, "9": 0.028394242748618126, "10": 0.08725957572460175, "11": 0.0003078165464103222, "12": 0.10136468708515167, "13": 0.0945235937833786, "14": 0.035430099815130234, "15": 0.0002445843128953129, "16": 0.032473448663949966, "17": 0.0002218027802882716, "18": 0.1561724841594696, "19": 0.17841964960098267}}, {"key": "ainslie2020encoding", "year": "2020", "title": "ETC: Encoding Long And Structured Inputs In Transformers", "topic_distr": {"0": 0.0016841263277456164, "1": 0.0013762976741418242, "2": 0.255557119846344, "3": 0.0010077649494633079, "4": 0.0008888028678484261, "5": 0.0007949691498652101, "6": 0.0007190562901087105, "7": 0.0006563776987604797, "8": 0.0006037501734681427, "9": 0.018175391480326653, "10": 0.5540623664855957, "11": 0.0004866848757956177, "12": 0.08377107977867126, "13": 0.021066831424832344, "14": 0.000407643907237798, "15": 0.00038670917274430394, "16": 0.05734841898083687, "17": 0.00035068957367911935, "18": 0.0003350840415805578, "19": 0.00032080820528790355}}, {"key": "ainslie2023training", "year": "2023", "title": "GQA: Training Generalized Multi-query Transformer Models From Multi-head Checkpoints", "topic_distr": {"0": 0.002545214956626296, "1": 0.0020783711224794388, "2": 0.45294561982154846, "3": 0.001521820086054504, "4": 0.0013421861222013831, "5": 0.0012004867894575, "6": 0.0010858504101634026, "7": 0.0009911992819979787, "8": 0.02595779113471508, "9": 0.0008440511883236468, "10": 0.2148434966802597, "11": 0.0007349452935159206, "12": 0.000690327724441886, "13": 0.26539215445518494, "14": 0.0006155851297080517, "15": 0.0005839715013280511, "16": 0.02510690875351429, "17": 0.0005295780720189214, "18": 0.000506012118421495, "19": 0.0004844540962949395}}, {"key": "aiyappa2023can", "year": "2023", "title": "Can We Trust The Evaluation On Chatgpt?", "topic_distr": {"0": 0.22910262644290924, "1": 0.08618342876434326, "2": 0.001655553700402379, "3": 0.30882135033607483, "4": 0.0012646971736103296, "5": 0.0011311768321320415, "6": 0.001023158896714449, "7": 0.0009339723037555814, "8": 0.0008590876241214573, "9": 0.2071944922208786, "10": 0.0007403646013699472, "11": 0.15674039721488953, "12": 0.0006504716584458947, "13": 0.0006132425041869283, "14": 0.0005800442886538804, "15": 0.0005502558778971434, "16": 0.0005233776173554361, "17": 0.000499002868309617, "18": 0.00047679748968221247, "19": 0.00045648409286513925}}, {"key": "akakzia2020grounding", "year": "2020", "title": "Grounding Language To Autonomously-acquired Skills Via Goal Generation", "topic_distr": {"0": 0.0010763435857370496, "1": 0.0008780668140389025, "2": 0.15566501021385193, "3": 0.0006429082714021206, "4": 0.0005670163664035499, "5": 0.14991404116153717, "6": 0.0004587240400724113, "7": 0.14512605965137482, "8": 0.0003851641668006778, "9": 0.0003565744555089623, "10": 0.0003319357638247311, "11": 0.44563916325569153, "12": 0.00029163307044655085, "13": 0.0002749417326413095, "14": 0.0002600576262921095, "15": 0.0002467022277414799, "16": 0.097243532538414, "17": 0.00022372342937160283, "18": 0.00021376783843152225, "19": 0.00020466052228584886}}, {"key": "aky\u00fcrek2020learning", "year": "2020", "title": "Learning To Recombine And Resample Data For Compositional Generalization", "topic_distr": {"0": 0.0015599238686263561, "1": 0.1878436952829361, "2": 0.19920596480369568, "3": 0.15543033182621002, "4": 0.0008221406606025994, "5": 0.0007353444234468043, "6": 0.0006651253206655383, "7": 0.0006071477546356618, "8": 0.000558467407245189, "9": 0.0005170138902030885, "10": 0.00048128911294043064, "11": 0.30857279896736145, "12": 0.0004228523466736078, "13": 0.0003986507945228368, "14": 0.10066329687833786, "15": 0.04024466872215271, "16": 0.00034023227635771036, "17": 0.00032438698690384626, "18": 0.0003099519235547632, "19": 0.0002967467880807817}}, {"key": "alabdulmohsin2022revisiting", "year": "2022", "title": "Revisiting Neural Scaling Laws In Language And Vision", "topic_distr": {"0": 0.07330204546451569, "1": 0.0014977322425693274, "2": 0.001266125706024468, "3": 0.001096606021746993, "4": 0.000967161962762475, "5": 0.0008650550153106451, "6": 0.0007824495551176369, "7": 0.000714245077688247, "8": 0.0006569778197444975, "9": 0.0006082121399231255, "10": 0.12228495627641678, "11": 0.0005295918672345579, "12": 0.31920477747917175, "13": 0.18447361886501312, "14": 0.13617359101772308, "15": 0.0004208021273370832, "16": 0.00040024728514254093, "17": 0.00038160698022693396, "18": 0.04487888142466545, "19": 0.10949526727199554}}, {"key": "alabi2022adapting", "year": "2022", "title": "Adapting Pre-trained Language Models To African Languages Via Multilingual Adaptive Fine-tuning", "topic_distr": {"0": 0.0013009707909077406, "1": 0.001061118789948523, "2": 0.0008969412883743644, "3": 0.116216741502285, "4": 0.0006851478829048574, "5": 0.0006128139211796224, "6": 0.000554295489564538, "7": 0.05542037636041641, "8": 0.0004654099466279149, "9": 0.0004308638162910938, "10": 0.20155662298202515, "11": 0.00037516839802265167, "12": 0.00035239243879914284, "13": 0.105968177318573, "14": 0.18459215760231018, "15": 0.02607051469385624, "16": 0.0002835393534041941, "17": 0.30265116691589355, "18": 0.00025830461527220905, "19": 0.00024729984579607844}}, {"key": "alamin2024history", "year": "2024", "title": "History Of Generative Artificial Intelligence (AI) Chatbots: Past, Present, And Future Development", "topic_distr": {"0": 0.0011053879279643297, "1": 0.10869529098272324, "2": 0.0007619516691192985, "3": 0.0006599470507353544, "4": 0.0005820468650199473, "5": 0.0005205972120165825, "6": 0.00047088455175980926, "7": 0.00042983851744793355, "8": 0.0003953746345359832, "9": 0.5903069376945496, "10": 0.013568887487053871, "11": 0.06684926152229309, "12": 0.21395108103752136, "13": 0.00028223026311025023, "14": 0.00026695156702771783, "15": 0.0002532421494834125, "16": 0.00024087209021672606, "17": 0.0002296541933901608, "18": 0.00021943468891549855, "19": 0.00021008594194427133}}, {"key": "alamri2019audio", "year": "2019", "title": "Audio-visual Scene-aware Dialog", "topic_distr": {"0": 0.0016221298137679696, "1": 0.0013226926093921065, "2": 0.0011181279551237822, "3": 0.0009684428223408759, "4": 0.21710510551929474, "5": 0.0007639532559551299, "6": 0.09483511000871658, "7": 0.017705900594592094, "8": 0.19897203147411346, "9": 0.00053712836233899, "10": 0.0005000137025490403, "11": 0.10105595737695694, "12": 0.0004393034614622593, "13": 0.000414160342188552, "14": 0.00039173956611193717, "15": 0.0003716216015163809, "16": 0.00035346904769539833, "17": 0.00033700731000863016, "18": 0.3608778715133667, "19": 0.00030829175375401974}}, {"key": "alaofi2025can", "year": "2025", "title": "Can Generative Llms Create Query Variants For Test Collections? An Exploratory Study", "topic_distr": {"0": 0.0019507227698341012, "1": 0.0015914625255391002, "2": 0.08842086791992188, "3": 0.3220551908016205, "4": 0.0010276032844558358, "5": 0.0009191145654767752, "6": 0.13313087821006775, "7": 0.0007588802254758775, "8": 0.23524512350559235, "9": 0.21020162105560303, "10": 0.0006015682010911405, "11": 0.0005626875208690763, "12": 0.0005285275401547551, "13": 0.000498277775477618, "14": 0.00047130321036092937, "15": 0.0004470992134884, "16": 0.0004252598446328193, "17": 0.00040545465890318155, "18": 0.00038741211756132543, "19": 0.0003709068987518549}}, {"key": "alayrac2022visual", "year": "2022", "title": "Flamingo: A Visual Language Model For Few-shot Learning", "topic_distr": {"0": 0.0013701897114515305, "1": 0.0011195152765139937, "2": 0.0009461194276809692, "3": 0.2384062111377716, "4": 0.0007227322785183787, "5": 0.0006464308244176209, "6": 0.0005847020074725151, "7": 0.0005337347975000739, "8": 0.02508804202079773, "9": 0.0004544994153548032, "10": 0.00042309428681619465, "11": 0.08583257347345352, "12": 0.06571581959724426, "13": 0.00035044815740548074, "14": 0.015900064259767532, "15": 0.00031445332570001483, "16": 0.00029909328441135585, "17": 0.00028516390011645854, "18": 0.5172861218452454, "19": 0.0437210276722908}}, {"key": "alberti2019bert", "year": "2019", "title": "A BERT Baseline For The Natural Questions", "topic_distr": {"0": 0.003465091809630394, "1": 0.002831854857504368, "2": 0.0023915667552500963, "3": 0.002071381313726306, "4": 0.0018268717685714364, "5": 0.001634002081118524, "6": 0.14176267385482788, "7": 0.0013491371646523476, "8": 0.15025439858436584, "9": 0.0011488515883684158, "10": 0.5588979125022888, "11": 0.0010003458010032773, "12": 0.0009396161185577512, "13": 0.1259685605764389, "14": 0.0008378827478736639, "15": 0.0007948529091663659, "16": 0.0007560268859378994, "17": 0.0007208171882666647, "18": 0.0006887411582283676, "19": 0.0006593982107006013}}, {"key": "alberti2019fusion", "year": "2019", "title": "Fusion Of Detected Objects In Text For Visual Question Answering", "topic_distr": {"0": 0.001711999997496605, "1": 0.001395347760990262, "2": 0.5549951791763306, "3": 0.0010215064976364374, "4": 0.0009009262430481613, "5": 0.0008058117236942053, "6": 0.0007288635242730379, "7": 0.0006653300952166319, "8": 0.05900754779577255, "9": 0.0005665587959811091, "10": 0.0005274105351418257, "11": 0.0004933227901346982, "12": 0.0004633738426491618, "13": 0.00043685309356078506, "14": 0.00041320378659293056, "15": 0.0003919835144188255, "16": 0.0003728363662958145, "17": 0.00035547264269553125, "18": 0.3744213283061981, "19": 0.0003251837333664298}}, {"key": "alberti2019synthetic", "year": "2019", "title": "Synthetic QA Corpora Generation With Roundtrip Consistency", "topic_distr": {"0": 0.002150628948584199, "1": 0.15509964525699615, "2": 0.257066011428833, "3": 0.0012856945395469666, "4": 0.0011339335469529033, "5": 0.0010142190149053931, "6": 0.0009173697326332331, "7": 0.0008374045719392598, "8": 0.17754854261875153, "9": 0.0007130880258046091, "10": 0.05332585796713829, "11": 0.0006209110142663121, "12": 0.0005832163733430207, "13": 0.0005498364917002618, "14": 0.000520070840138942, "15": 0.25309351086616516, "16": 0.00046926314826123416, "17": 0.000447408645413816, "18": 0.0004274991515558213, "19": 0.09219590574502945}}, {"key": "alex2021real", "year": "2021", "title": "RAFT: A Real-world Few-shot Text Classification Benchmark", "topic_distr": {"0": 0.13834644854068756, "1": 0.001434802426956594, "2": 0.20662787556648254, "3": 0.2233990728855133, "4": 0.000926329055801034, "5": 0.0008285332005470991, "6": 0.0007494152523577213, "7": 0.0006840903079137206, "8": 0.04173487052321434, "9": 0.0005825340049341321, "10": 0.0005422818940132856, "11": 0.000507232965901494, "12": 0.13598455488681793, "13": 0.00044917099876329303, "14": 0.00042485486483201385, "15": 0.10190963000059128, "16": 0.0003833492228295654, "17": 0.14380136132240295, "18": 0.00034923150087706745, "19": 0.00033435289515182376}}, {"key": "aliannejadi2019harnessing", "year": "2019", "title": "Harnessing Evolution Of Multi-turn Conversations For Effective Answer Retrieval", "topic_distr": {"0": 0.0009671573061496019, "1": 0.0369693748652935, "2": 0.15878120064735413, "3": 0.0005780885112471879, "4": 0.07845316082239151, "5": 0.028920141980051994, "6": 0.47386518120765686, "7": 0.0003765203000511974, "8": 0.06719119101762772, "9": 0.09720053523778915, "10": 0.054664745926856995, "11": 0.0002791788137983531, "12": 0.00026223022723570466, "13": 0.00024722173111513257, "14": 0.0002338382473681122, "15": 0.00022182938118930906, "16": 0.0002109937195200473, "17": 0.00020116732048336416, "18": 0.00019221547699999064, "19": 0.00018402637215331197}}, {"key": "alizadeh2023llm", "year": "2023", "title": "LLM In A Flash: Efficient Large Language Model Inference With Limited Memory", "topic_distr": {"0": 0.0012354252394288778, "1": 0.08429605513811111, "2": 0.07721516489982605, "3": 0.16634011268615723, "4": 0.037079449743032455, "5": 0.000582490989472717, "6": 0.0005268680397421122, "7": 0.000480942107969895, "8": 0.0004423807840794325, "9": 0.09679445624351501, "10": 0.0003812452487181872, "11": 0.0003566045197658241, "12": 0.00033495554816909134, "13": 0.4895552098751068, "14": 0.00029868949786759913, "15": 0.00028335017850622535, "16": 0.0002695094153750688, "17": 0.043046534061431885, "18": 0.00024552331888116896, "19": 0.00023506309662479907}}, {"key": "alkaswan2023open", "year": "2023", "title": "The (ab)use Of Open Source Code To Train Large Language Models", "topic_distr": {"0": 0.11480100452899933, "1": 0.10640737414360046, "2": 0.0014591374201700091, "3": 0.0012638119515031576, "4": 0.041384655982255936, "5": 0.0009969507809728384, "6": 0.22349143028259277, "7": 0.000823146547190845, "8": 0.0007571477326564491, "9": 0.5035189390182495, "10": 0.0006525124772451818, "11": 0.0006103391060605645, "12": 0.000573286262806505, "13": 0.0005404747789725661, "14": 0.000511215883307159, "15": 0.00048496213275939226, "16": 0.00046127327368594706, "17": 0.0004397908633109182, "18": 0.00042022037087008357, "19": 0.00040231741149909794}}, {"key": "almazrouei2023falcon", "year": "2023", "title": "The Falcon Series Of Open Language Models", "topic_distr": {"0": 0.0018339324742555618, "1": 0.0014982209540903568, "2": 0.18027816712856293, "3": 0.0828058123588562, "4": 0.0009673046879470348, "5": 0.0008651825482957065, "6": 0.0007825650391168892, "7": 0.0007143504917621613, "8": 0.0006570747937075794, "9": 0.0006083018961362541, "10": 0.0005662692710757256, "11": 0.061530422419309616, "12": 0.23784826695919037, "13": 0.29771688580513, "14": 0.00044364799396134913, "15": 0.0004208642349112779, "16": 0.0004003063659183681, "17": 0.00038166329613886774, "18": 0.0003646794648375362, "19": 0.12931610643863678}}, {"key": "almeida2023exploring", "year": "2023", "title": "Exploring The Psychology Of Llms' Moral And Legal Reasoning", "topic_distr": {"0": 0.42979615926742554, "1": 0.0011981755960732698, "2": 0.0010128900175914168, "3": 0.17901816964149475, "4": 0.0007737250416539609, "5": 0.0006920393207110465, "6": 0.0006259551737457514, "7": 0.0005713919526897371, "8": 0.0005255785072222352, "9": 0.26841020584106445, "10": 0.00045294532901607454, "11": 0.0004236704553477466, "12": 0.11423599720001221, "13": 0.0003751736949197948, "14": 0.00035486347042024136, "15": 0.00033663929207250476, "16": 0.00032019554055295885, "17": 0.000305283407215029, "18": 0.00029169843764975667, "19": 0.0002792709565255791}}, {"key": "alon2018generating", "year": "2018", "title": "Code2seq: Generating Sequences From Structured Representations Of Code", "topic_distr": {"0": 0.0015204568626359105, "1": 0.0012421691790223122, "2": 0.0010499611962586641, "3": 0.0009093759581446648, "4": 0.0008020289242267609, "5": 0.0007173557532951236, "6": 0.615608274936676, "7": 0.0005922950222156942, "8": 0.0005448055453598499, "9": 0.0005043661221861839, "10": 0.1532301902770996, "11": 0.08461394906044006, "12": 0.0004125080304220319, "13": 0.0003888985374942422, "14": 0.13627417385578156, "15": 0.00034895443241111934, "16": 0.0003319091338198632, "17": 0.0003164514491800219, "18": 0.0003023695317097008, "19": 0.0002894874196499586}}, {"key": "alrfou2016conversational", "year": "2016", "title": "Conversational Contextual Cues: The Case Of Personalization And History For Response Ranking", "topic_distr": {"0": 0.1367860585451126, "1": 0.0016426893416792154, "2": 0.27671492099761963, "3": 0.001202719984576106, "4": 0.0010607504518702626, "5": 0.0009487614734098315, "6": 0.47369468212127686, "7": 0.0007833584677428007, "8": 0.0007205497822724283, "9": 0.0006670653237961233, "10": 0.07643955200910568, "11": 0.0005808374262414873, "12": 0.0005455755745060742, "13": 0.025624170899391174, "14": 0.0004865054215770215, "15": 0.0004615207144524902, "16": 0.00043897691648453474, "17": 0.00041853287257254124, "18": 0.00039990837103687227, "19": 0.0003828707558568567}}, {"key": "alrfou2018character", "year": "2018", "title": "Character-level Language Modeling With Deeper Self-attention", "topic_distr": {"0": 0.0025455746799707413, "1": 0.002078130142763257, "2": 0.46167251467704773, "3": 0.06805349141359329, "4": 0.0013420861214399338, "5": 0.001200397964566946, "6": 0.001085770083591342, "7": 0.0009911258239299059, "8": 0.0009116586879827082, "9": 0.0008439887315034866, "10": 0.4539245069026947, "11": 0.0007348908693529665, "12": 0.0006902766181156039, "13": 0.0006507693324238062, "14": 0.0006155395531095564, "15": 0.0005839282530359924, "16": 0.0005554052186198533, "17": 0.0005295388982631266, "18": 0.0005059746326878667, "19": 0.00048441821127198637}}, {"key": "alvarezmelis2017causal", "year": "2017", "title": "A Causal Framework For Explaining The Predictions Of Black-box Sequence-to-sequence Models", "topic_distr": {"0": 0.04925183579325676, "1": 0.0347517728805542, "2": 0.27866142988204956, "3": 0.14578254520893097, "4": 0.001370331970974803, "5": 0.13642336428165436, "6": 0.0446794219315052, "7": 0.16620616614818573, "8": 0.0009308452135883272, "9": 0.0008617510902695358, "10": 0.07306179404258728, "11": 0.000750357226934284, "12": 0.0007048040279187262, "13": 0.0006644652457907796, "14": 0.0006284940172918141, "15": 0.00059621746186167, "16": 0.06312242895364761, "17": 0.00054068339522928, "18": 0.0005166232585906982, "19": 0.0004946131375618279}}, {"key": "amani2023generative", "year": "2023", "title": "Generative AI Perceptions: A Survey To Measure The Perceptions Of Faculty, Staff, And Students On Generative AI Tools In Academia", "topic_distr": {"0": 0.13056175410747528, "1": 0.0012734427582472563, "2": 0.001076254528015852, "3": 0.000932171184103936, "4": 0.0008221344905905426, "5": 0.0007353383698500693, "6": 0.0823880210518837, "7": 0.10489887744188309, "8": 0.0005584627506323159, "9": 0.40319159626960754, "10": 0.00048128506750799716, "11": 0.0004501785442698747, "12": 0.18118445575237274, "13": 0.0003986474475823343, "14": 0.0003770664625335485, "15": 0.0003577020252123475, "16": 0.0003402294241823256, "17": 0.08936572074890137, "18": 0.00030994933331385255, "19": 0.0002967443142551929}}, {"key": "an2022contrastive", "year": "2022", "title": "Cont: Contrastive Neural Text Generation", "topic_distr": {"0": 0.01508348435163498, "1": 0.000893458491191268, "2": 0.21704192459583282, "3": 0.0006541165057569742, "4": 0.0005769028794020414, "5": 0.0005159965949133039, "6": 0.00046672328608110547, "7": 0.3941364586353302, "8": 0.00039188069058582187, "9": 0.0003627924306783825, "10": 0.0003377240791451186, "11": 0.0003158962354063988, "12": 0.0002967185864690691, "13": 0.00027973618125543, "14": 0.13016481697559357, "15": 0.0002510042395442724, "16": 0.00023874349426478148, "17": 0.23756587505340576, "18": 0.00021749552979599684, "19": 0.00020822940859943628}}, {"key": "anderson2017vision", "year": "2017", "title": "Vision-and-language Navigation: Interpreting Visually-grounded Navigation Instructions In Real Environments", "topic_distr": {"0": 0.0016624529380351305, "1": 0.001357800210826099, "2": 0.0011479115346446633, "3": 0.0009942450560629368, "4": 0.0008768864208832383, "5": 0.0007843098719604313, "6": 0.0007094149477779865, "7": 0.0006475767586380243, "8": 0.037940967828035355, "9": 0.0005514410440810025, "10": 0.0005133373779244721, "11": 0.4362804889678955, "12": 0.3754369020462036, "13": 0.0004251963400747627, "14": 0.017394082620739937, "15": 0.0003815240634139627, "16": 0.00036288780393078923, "17": 0.00034598741331137717, "18": 0.12187004834413528, "19": 0.00031650668825022876}}, {"key": "anderson2024homogenization", "year": "2024", "title": "Homogenization Effects Of Large Language Models On Human Creative Ideation", "topic_distr": {"0": 0.36290761828422546, "1": 0.0013399932067841291, "2": 0.0011328049004077911, "3": 0.0009811517084017396, "4": 0.0008653356344439089, "5": 0.0007739774882793427, "6": 0.0007000690675340593, "7": 0.000639045552816242, "8": 0.0005878076772205532, "9": 0.626115620136261, "10": 0.0005065746372565627, "11": 0.0004738336137961596, "12": 0.0004450677952263504, "13": 0.0004195947840344161, "14": 0.0003968797973357141, "15": 0.0003764978318940848, "16": 0.0003581071214284748, "17": 0.0003414293460082263, "18": 0.0003262359241489321, "19": 0.00031233704066835344}}, {"key": "andreas2016reasoning", "year": "2016", "title": "Reasoning About Pragmatics With Neural Listeners And Speakers", "topic_distr": {"0": 0.11768397688865662, "1": 0.0018187511013820767, "2": 0.24835465848445892, "3": 0.0013315608957782388, "4": 0.001174381235614419, "5": 0.026103829964995384, "6": 0.16978290677070618, "7": 0.0008672748226672411, "8": 0.00079773785546422, "9": 0.0007385239005088806, "10": 0.0006874931859783828, "11": 0.28687530755996704, "12": 0.0006040196749381721, "13": 0.0005694492137990892, "14": 0.0005386217380873859, "15": 0.0005109605845063925, "16": 0.00048600180889479816, "17": 0.0004633677308447659, "18": 0.14018727838993073, "19": 0.0004238853289280087}}, {"key": "andreas2019good", "year": "2019", "title": "Good-enough Compositional Data Augmentation", "topic_distr": {"0": 0.0735308900475502, "1": 0.32377389073371887, "2": 0.3799433410167694, "3": 0.0015867394395172596, "4": 0.001399436965584755, "5": 0.0012516939314082265, "6": 0.0011321674101054668, "7": 0.02794067934155464, "8": 0.0009506158530712128, "9": 0.000880054198205471, "10": 0.0008192438981495798, "11": 0.18197810649871826, "12": 0.0007197736413218081, "13": 0.0006785781006328762, "14": 0.0006418428965844214, "15": 0.0006088807713240385, "16": 0.0005791388684883714, "17": 0.0005521672428585589, "18": 0.0005275960429571569, "19": 0.0005051184562034905}}, {"key": "andreas2022language", "year": "2022", "title": "Language Models As Agent Models", "topic_distr": {"0": 0.1954512894153595, "1": 0.1499478816986084, "2": 0.000827901647426188, "3": 0.0007170493481680751, "4": 0.0006324086571112275, "5": 0.06301083415746689, "6": 0.0005116285174153745, "7": 0.03269236907362938, "8": 0.02840448170900345, "9": 0.0003976980806328356, "10": 0.03132156655192375, "11": 0.212295800447464, "12": 0.0718078464269638, "13": 0.0003066506760660559, "14": 0.0002900499675888568, "15": 0.0002751543070189655, "16": 0.00026171389617957175, "17": 0.00024952535750344396, "18": 0.00023842160589993, "19": 0.21035970747470856}}, {"key": "anil2022exploring", "year": "2022", "title": "Exploring Length Generalization In Large Language Models", "topic_distr": {"0": 0.0015035204123705626, "1": 0.0012270687147974968, "2": 0.0010373573750257492, "3": 0.48973584175109863, "4": 0.0007924219244159758, "5": 0.0007087630219757557, "6": 0.0006410821806639433, "7": 0.0005852003814652562, "8": 0.0005382797680795193, "9": 0.0004983247490599751, "10": 0.16755618155002594, "11": 0.29363885521888733, "12": 0.00040756695671007037, "13": 0.00038424026570282876, "14": 0.0003634392051026225, "15": 0.0003447746275924146, "16": 0.000327933463267982, "17": 0.0003126609663013369, "18": 0.01655404269695282, "19": 0.02284242771565914}}, {"key": "anil2023palm", "year": "2023", "title": "Palm 2 Technical Report", "topic_distr": {"0": 0.07980576157569885, "1": 0.0009093934204429388, "2": 0.0007687042816542089, "3": 0.2542943060398102, "4": 0.031712938100099564, "5": 0.0005252090631984174, "6": 0.00047505597467534244, "7": 0.0004336463753134012, "8": 0.0003988771641161293, "9": 0.01702086254954338, "10": 0.0003437536652199924, "11": 0.0003215361211914569, "12": 0.00030201609479263425, "13": 0.5239773392677307, "14": 0.08754713088274002, "15": 0.0002554855600465089, "16": 0.00024300591030623764, "17": 0.00023168865300249308, "18": 0.00022137860651127994, "19": 0.00021194704459048808}}, {"key": "antonello2023scaling", "year": "2023", "title": "Scaling Laws For Language Encoding Models In Fmri", "topic_distr": {"0": 0.24703200161457062, "1": 0.056785792112350464, "2": 0.13152465224266052, "3": 0.0008877345244400203, "4": 0.0007829434471204877, "5": 0.0007002852507866919, "6": 0.0006334140198305249, "7": 0.01884405128657818, "8": 0.0005318412440828979, "9": 0.03799184784293175, "10": 0.16035497188568115, "11": 0.00042871886398643255, "12": 0.0004026919195894152, "13": 0.34118860960006714, "14": 0.00035909199505113065, "15": 0.0003406506439205259, "16": 0.00032401096541434526, "17": 0.0003089211240876466, "18": 0.0002951742790173739, "19": 0.00028259874670766294}}, {"key": "antoun2020pre", "year": "2020", "title": "Aragpt2: Pre-trained Transformer For Arabic Language Generation", "topic_distr": {"0": 0.0013133712345734239, "1": 0.0010720323771238327, "2": 0.0009061964810825884, "3": 0.0007848847308196127, "4": 0.000692237401381135, "5": 0.0006191551219671965, "6": 0.0005600310978479683, "7": 0.0005112143699079752, "8": 0.03014078177511692, "9": 0.0004353222611825913, "10": 0.11436454951763153, "11": 0.0003790505288634449, "12": 0.10220412164926529, "13": 0.05317418649792671, "14": 0.00031749013578519225, "15": 0.6914548873901367, "16": 0.0002864733396563679, "17": 0.0002731317072175443, "18": 0.00026097745285369456, "19": 0.0002498588291928172}}, {"key": "araabi2020optimizing", "year": "2020", "title": "Optimizing Transformer For Low-resource Neural Machine Translation", "topic_distr": {"0": 0.0021516415290534496, "1": 0.0017561936983838677, "2": 0.3914596140384674, "3": 0.0012857761466875672, "4": 0.0011339401826262474, "5": 0.0010142259998247027, "6": 0.0009173760772682726, "7": 0.0008374103344976902, "8": 0.0007702678558416665, "9": 0.0007130929734557867, "10": 0.08868326246738434, "11": 0.0006209153216332197, "12": 0.0005832203896716237, "13": 0.0005498403334058821, "14": 0.5052763819694519, "15": 0.0004933657473884523, "16": 0.0004692664078902453, "17": 0.0004474117304198444, "18": 0.0004275021201465279, "19": 0.0004092889139428735}}, {"key": "arakawa2023domain", "year": "2023", "title": "Catalyst: Domain-extensible Intervention For Preventing Task Procrastination Using Large Generative Models", "topic_distr": {"0": 0.20501093566417694, "1": 0.001786725246347487, "2": 0.0015105264028534293, "3": 0.4452897012233734, "4": 0.0011538765393197536, "5": 0.001032056286931038, "6": 0.000933503673877567, "7": 0.0008521321578882635, "8": 0.0007838092860765755, "9": 0.000725629273802042, "10": 0.0006754894857294858, "11": 0.0006318311206996441, "12": 0.0461883470416069, "13": 0.0005595065886154771, "14": 0.0005292174173519015, "15": 0.22761525213718414, "16": 0.00047751617967151105, "17": 0.06339242309331894, "18": 0.0004350176895968616, "19": 0.0004164842830505222}}, {"key": "arawjo2023visual", "year": "2023", "title": "Chainforge: A Visual Toolkit For Prompt Engineering And LLM Hypothesis Testing", "topic_distr": {"0": 0.0013719184789806604, "1": 0.0011192081728950143, "2": 0.0009461214649491012, "3": 0.3922596871852875, "4": 0.0007227323949337006, "5": 0.0006464303005486727, "6": 0.042159195989370346, "7": 0.0005337343900464475, "8": 0.0004909402341581881, "9": 0.26915043592453003, "10": 0.00042309396667405963, "11": 0.0003957484441343695, "12": 0.00037172308657318354, "13": 0.0003504478663671762, "14": 0.00033147618523798883, "15": 0.0003144530928693712, "16": 0.008280704729259014, "17": 0.24413494765758514, "18": 0.03573615849018097, "19": 0.00026086560683324933}}, {"key": "arefeen2023cost", "year": "2023", "title": "Leancontext: Cost-efficient Domain-specific Question Answering Using Llms", "topic_distr": {"0": 0.001066533732227981, "1": 0.04347394406795502, "2": 0.2178179919719696, "3": 0.000637363875284791, "4": 0.0005621261079795659, "5": 0.0005027801380492747, "6": 0.00045476885861717165, "7": 0.0665297657251358, "8": 0.16364014148712158, "9": 0.34484928846359253, "10": 0.00032907375134527683, "11": 0.00030780499218963087, "12": 0.00028911855770274997, "13": 0.09774590283632278, "14": 0.0002578153507784009, "15": 0.014320761896669865, "16": 0.00023262840113602579, "17": 0.00022179444204084575, "18": 0.0002119246928486973, "19": 0.04654845967888832}}, {"key": "aribandi2021towards", "year": "2021", "title": "Ext5: Towards Extreme Multi-task Scaling For Transfer Learning", "topic_distr": {"0": 0.0018346288707107306, "1": 0.0014977892860770226, "2": 0.001266050268895924, "3": 0.0010965453693643212, "4": 0.0009671086445450783, "5": 0.000865007343236357, "6": 0.0007824060157872736, "7": 0.0007142054382711649, "8": 0.01826365478336811, "9": 0.0006081783794797957, "10": 0.0005661542527377605, "11": 0.03335409611463547, "12": 0.174508199095726, "13": 0.21022234857082367, "14": 0.0004435578885022551, "15": 0.00042077875696122646, "16": 0.000400225049816072, "17": 0.5514753460884094, "18": 0.00036460539558902383, "19": 0.00034907180815935135}}, {"key": "arora2020natural", "year": "2020", "title": "Inltk: Natural Language Toolkit For Indic Languages", "topic_distr": {"0": 0.0023519531823694706, "1": 0.2216140329837799, "2": 0.0016244176076725125, "3": 0.0014069387689232826, "4": 0.0012408593902364373, "5": 0.0011098576942458749, "6": 0.0010038757463917136, "7": 0.0009163700160570443, "8": 0.0008428966393694282, "9": 0.0007803306798450649, "10": 0.5739858746528625, "11": 0.0006794615765102208, "12": 0.03566450998187065, "13": 0.000601684907451272, "14": 0.000569112366065383, "15": 0.15368899703025818, "16": 0.0005135136307217181, "17": 0.000489598314743489, "18": 0.00046781142009422183, "19": 0.00044788088416680694}}, {"key": "arora2022ask", "year": "2022", "title": "Ask Me Anything: A Simple Strategy For Prompting Language Models", "topic_distr": {"0": 0.0009387716418132186, "1": 0.07658390700817108, "2": 0.25513511896133423, "3": 0.3382023572921753, "4": 0.0004945141263306141, "5": 0.00044230654020793736, "6": 0.0004000699846073985, "7": 0.04990600049495697, "8": 0.022179188206791878, "9": 0.00031098161707632244, "10": 0.00028949329862371087, "11": 0.0002707827079575509, "12": 0.0002543438458815217, "13": 0.00023978673561941832, "14": 0.00022680574329569936, "15": 0.00021515802654903382, "16": 0.00020464824046939611, "17": 0.2533408999443054, "18": 0.00018643474322743714, "19": 0.00017849191499408334}}, {"key": "arora2023have", "year": "2023", "title": "Have Llms Advanced Enough? A Challenging Problem Solving Benchmark For Large Language Models", "topic_distr": {"0": 0.10936994850635529, "1": 0.0011072034249082208, "2": 0.0009359079995192587, "3": 0.47779232263565063, "4": 0.000714923779014498, "5": 0.0006394464871846139, "6": 0.03611764311790466, "7": 0.0005279682227410376, "8": 0.03638233616948128, "9": 0.0004495889297686517, "10": 0.0004185230936855078, "11": 0.09426603466272354, "12": 0.23918698728084564, "13": 0.00034666183637455106, "14": 0.00032789510441944003, "15": 0.000311055890051648, "16": 0.00029586179880425334, "17": 0.00028208293952047825, "18": 0.00026953037013299763, "19": 0.000258047366514802}}, {"key": "artetxe2021efficient", "year": "2021", "title": "Efficient Large Scale Language Modeling With Mixtures Of Experts", "topic_distr": {"0": 0.001920300186611712, "1": 0.00156672194134444, "2": 0.0013245039153844118, "3": 0.001147186616435647, "4": 0.0010117683559656143, "5": 0.0009049524087458849, "6": 0.0008185371407307684, "7": 0.0007471870048902929, "8": 0.000687278516124934, "9": 0.0006362636922858655, "10": 0.28699639439582825, "11": 0.0005540173733606935, "12": 0.14531174302101135, "13": 0.43370211124420166, "14": 0.0004640411352738738, "15": 0.000440210074884817, "16": 0.00041870723362080753, "17": 0.00039920720155350864, "18": 0.00038144266000017524, "19": 0.12056740373373032}}, {"key": "asai2018multilingual", "year": "2018", "title": "Multilingual Extractive Reading Comprehension By Runtime Machine Translation", "topic_distr": {"0": 0.0015980163589119911, "1": 0.001305784797295928, "2": 0.31459957361221313, "3": 0.0009559110621921718, "4": 0.0008430756279267371, "5": 0.0007540688966400921, "6": 0.0006820615963079035, "7": 0.0006226077675819397, "8": 0.08606317639350891, "9": 0.0005301788332872093, "10": 0.0004935443284921348, "11": 0.00046164548257365823, "12": 0.00043361959978938103, "13": 0.0004088018031325191, "14": 0.5408322215080261, "15": 0.04811202734708786, "16": 0.00034889575908891857, "17": 0.0003326469741296023, "18": 0.0003178443294018507, "19": 0.00030430295737460256}}, {"key": "asai2019learning", "year": "2019", "title": "Learning To Retrieve Reasoning Paths Over Wikipedia Graph For Question Answering", "topic_distr": {"0": 0.001539926859550178, "1": 0.016256069764494896, "2": 0.32801416516304016, "3": 0.024431636556982994, "4": 0.0008119749836623669, "5": 0.0007262519211508334, "6": 0.0006569011020474136, "7": 0.0005996404215693474, "8": 0.37066516280174255, "9": 0.0005106210592202842, "10": 0.00047533801989629865, "11": 0.08222794532775879, "12": 0.00041762381442822516, "13": 0.0003937215078622103, "14": 0.0003724072012118995, "15": 0.0003532820555847138, "16": 0.17062778770923615, "17": 0.0003203759843017906, "18": 0.0003061193856410682, "19": 0.00029307755175977945}}, {"key": "asai2020logic", "year": "2020", "title": "Logic-guided Data Augmentation And Regularization For Consistent Question Answering", "topic_distr": {"0": 0.0014850393636152148, "1": 0.16999360918998718, "2": 0.3749646544456482, "3": 0.13141468167304993, "4": 0.0007829334354028106, "5": 0.0007002760539762676, "6": 0.015910377725958824, "7": 0.0005781928775832057, "8": 0.14742152392864227, "9": 0.0004923574742861092, "10": 0.022016549482941628, "11": 0.0004287131014280021, "12": 0.00040268650627695024, "13": 0.0003796391247306019, "14": 0.00035908716381527483, "15": 0.0003406460746191442, "16": 0.13144239783287048, "17": 0.0003089169622398913, "18": 0.0002951703208964318, "19": 0.0002825949341058731}}, {"key": "asai2021one", "year": "2021", "title": "One Question Answering Model For Many Languages With Cross-lingual Dense Passage Retrieval", "topic_distr": {"0": 0.001467104651965201, "1": 0.001198439160361886, "2": 0.001012889202684164, "3": 0.0008772735018283129, "4": 0.0007737179985269904, "5": 0.0006920336745679379, "6": 0.0006259501678869128, "7": 0.0005713874124921858, "8": 0.32491716742515564, "9": 0.00048656234866939485, "10": 0.056379534304142, "11": 0.00042366707930341363, "12": 0.00039794680196791887, "13": 0.00037517069722525775, "14": 0.3387388288974762, "15": 0.14895537495613098, "16": 0.00032019297941587865, "17": 0.00030528096249327064, "18": 0.00029169610934332013, "19": 0.12118981778621674}}, {"key": "asai2022parameter", "year": "2022", "title": "ATTEMPT: Parameter-efficient Multi-task Tuning Via Attentional Mixtures Of Soft Prompts", "topic_distr": {"0": 0.0011131445644423366, "1": 0.0009092963300645351, "2": 0.20289355516433716, "3": 0.000665798899717629, "4": 0.0005872095352970064, "5": 0.0005252153496257961, "6": 0.00047506176633760333, "7": 0.0004336516431067139, "8": 0.00039888202445581555, "9": 0.00036927408655174077, "10": 0.05079543590545654, "11": 0.0003215400211047381, "12": 0.0003020197618752718, "13": 0.112026646733284, "14": 0.0002693197166081518, "15": 0.0002554886741563678, "16": 0.05451503023505211, "17": 0.5481264591217041, "18": 0.00022138131316751242, "19": 0.024795573204755783}}, {"key": "asai2023self", "year": "2023", "title": "Self-rag: Learning To Retrieve, Generate, And Critique Through Self-reflection", "topic_distr": {"0": 0.0012239800998941064, "1": 0.0009984116768464446, "2": 0.0008440595702268183, "3": 0.22509168088436127, "4": 0.000644757179543376, "5": 0.000576687220018357, "6": 0.03603743016719818, "7": 0.22938013076782227, "8": 0.15864448249340057, "9": 0.00040546341915614903, "10": 0.0003774465876631439, "11": 0.00035305137862451375, "12": 0.00033161809551529586, "13": 0.08754700422286987, "14": 0.0002957134274765849, "15": 0.000280526903225109, "16": 0.17559278011322021, "17": 0.0002543975424487144, "18": 0.00024307696730829775, "19": 0.08087728917598724}}, {"key": "asghar2016deep", "year": "2016", "title": "Deep Active Learning For Dialogue Generation", "topic_distr": {"0": 0.041049398481845856, "1": 0.0018519558943808079, "2": 0.0015654198359698057, "3": 0.001355830579996109, "4": 0.2644101679325104, "5": 0.0010695487726479769, "6": 0.40034252405166626, "7": 0.0008830880979076028, "8": 0.0008122831932269037, "9": 0.0007519896025769413, "10": 0.0007000283803790808, "11": 0.28109508752822876, "12": 0.0006150329718366265, "13": 0.0005798321217298508, "14": 0.000548442592844367, "15": 0.0005202770698815584, "16": 0.0004948631976731122, "17": 0.0004718164273072034, "18": 0.0004508208076003939, "19": 0.0004316141421440989}}, {"key": "ashok2023prompting", "year": "2023", "title": "Promptner: Prompting For Named Entity Recognition", "topic_distr": {"0": 0.0011888205772265792, "1": 0.0009700889931991696, "2": 0.43674635887145996, "3": 0.16970999538898468, "4": 0.0006263666437007487, "5": 0.07526678591966629, "6": 0.0005067408783361316, "7": 0.00046256938367150724, "8": 0.00042548117926344275, "9": 0.00039389883750118315, "10": 0.00036668110988102853, "11": 0.00034298168611712754, "12": 0.00032215972896665335, "13": 0.00030372123001143336, "14": 0.00028727910830639303, "15": 0.0002725257654674351, "16": 0.022952526807785034, "17": 0.2883927822113037, "18": 0.00023614395468030125, "19": 0.00022608332801610231}}, {"key": "askell2021general", "year": "2021", "title": "A General Language Assistant As A Laboratory For Alignment", "topic_distr": {"0": 0.3445521891117096, "1": 0.0011984119191765785, "2": 0.0010129290167242289, "3": 0.0008773145382292569, "4": 0.08065500110387802, "5": 0.0006920641171745956, "6": 0.0006259777583181858, "7": 0.0005714126164093614, "8": 0.000525597482919693, "9": 0.00048658379819244146, "10": 0.00045296165626496077, "11": 0.1921241730451584, "12": 0.0003979643515776843, "13": 0.17191678285598755, "14": 0.0003548762761056423, "15": 0.0003366514574736357, "16": 0.00032020709477365017, "17": 0.052124518901109695, "18": 0.00029170894413255155, "19": 0.15048269927501678}}, {"key": "asri2017corpus", "year": "2017", "title": "Frames: A Corpus For Adding Memory To Goal-oriented Dialogue Systems", "topic_distr": {"0": 0.002599343890324235, "1": 0.0021218338515609503, "2": 0.10819030553102493, "3": 0.001553507405333221, "4": 0.0013701312709599733, "5": 0.4229778051376343, "6": 0.15098199248313904, "7": 0.0010118354111909866, "8": 0.0009307077270932496, "9": 0.000861623790115118, "10": 0.0008020870736800134, "11": 0.0007502463995479047, "12": 0.0007046999526210129, "13": 0.0006643671076744795, "14": 0.000628401234280318, "15": 0.1384803056716919, "16": 0.16381913423538208, "17": 0.0005406035925261676, "18": 0.0005165469483472407, "19": 0.0004945400869473815}}, {"key": "athiwaratkun2022multi", "year": "2022", "title": "Multi-lingual Evaluation Of Code Generation Models", "topic_distr": {"0": 0.0015993542037904263, "1": 0.08878686279058456, "2": 0.0011038267984986305, "3": 0.3570730984210968, "4": 0.0008432010072283447, "5": 0.000754181295633316, "6": 0.22912763059139252, "7": 0.06934279948472977, "8": 0.0005727732786908746, "9": 0.0005302578792907298, "10": 0.0004936179029755294, "11": 0.0004617143131326884, "12": 0.11554824560880661, "13": 0.0004088627465534955, "14": 0.0538068450987339, "15": 0.00036686810199171305, "16": 0.00034894776763394475, "17": 0.07820865511894226, "18": 0.0003178917395416647, "19": 0.0003043483302462846}}, {"key": "atri2021leveraging", "year": "2021", "title": "See, Hear, Read: Leveraging Multimodality With Guided Attention For Abstractive Text Summarization", "topic_distr": {"0": 0.001015304820612073, "1": 0.0008281274931505322, "2": 0.20247063040733337, "3": 0.0006063570617698133, "4": 0.0005347801488824189, "5": 0.0004783202020917088, "6": 0.0004326446505729109, "7": 0.21149520576000214, "8": 0.0003632667940109968, "9": 0.00033630250254645944, "10": 0.09164892137050629, "11": 0.00029283048934303224, "12": 0.07751647382974625, "13": 0.00025931073469109833, "14": 0.00024527282221242785, "15": 0.00023267671349458396, "16": 0.10852140933275223, "17": 0.00021100429876241833, "18": 0.30231812596321106, "19": 0.0001930251601152122}}, {"key": "augenstein2023factuality", "year": "2023", "title": "Factuality Challenges In The Era Of Large Language Models", "topic_distr": {"0": 0.07952376455068588, "1": 0.1295812577009201, "2": 0.0011958950199186802, "3": 0.03559855371713638, "4": 0.0009135292493738234, "5": 0.000817084510345012, "6": 0.0007390598766505718, "7": 0.024273088201880455, "8": 0.0006205460522323847, "9": 0.614716649055481, "10": 0.0005347887054085732, "11": 0.0005002241232432425, "12": 0.00046985616791062057, "13": 0.00044296440319158137, "14": 0.0004189842729829252, "15": 0.10824113339185715, "16": 0.00037805215106345713, "17": 0.0003604454977903515, "18": 0.00034440585295669734, "19": 0.0003297328366898}}, {"key": "austin2021program", "year": "2021", "title": "Program Synthesis With Large Language Models", "topic_distr": {"0": 0.0009678219212219119, "1": 0.2366020381450653, "2": 0.0006673948373645544, "3": 0.6254555583000183, "4": 0.012024803087115288, "5": 0.00045599081204272807, "6": 0.07527830451726913, "7": 0.0003764952707570046, "8": 0.000346308370353654, "9": 0.0003206028195563704, "10": 0.0002984497114084661, "11": 0.02177075669169426, "12": 0.0002622127940412611, "13": 0.023929281160235405, "14": 0.0002338227059226483, "15": 0.0002218146255472675, "16": 0.00021097969147376716, "17": 0.0002011539472732693, "18": 0.0001922026858665049, "19": 0.0001840141339926049}}, {"key": "awadalla2023open", "year": "2023", "title": "Openflamingo: An Open-source Framework For Training Large Autoregressive Vision-language Models", "topic_distr": {"0": 0.0038958340883255005, "1": 0.003183929016813636, "2": 0.002690607216209173, "3": 0.4665495753288269, "4": 0.0020553565118461847, "5": 0.0018383654532954097, "6": 0.0016628167359158397, "7": 0.12203259021043777, "8": 0.0013961713993921876, "9": 0.0012925374321639538, "10": 0.001203225227072835, "11": 0.001125458162277937, "12": 0.0010571330785751343, "13": 0.31776756048202515, "14": 0.0009426759788766503, "15": 0.0008942644344642758, "16": 0.0008505824953317642, "17": 0.0008109691552817822, "18": 0.06800849735736847, "19": 0.0007418685127049685}}, {"key": "azaria2023chatgpt", "year": "2023", "title": "Chatgpt Is A Remarkable Tool -- For Experts", "topic_distr": {"0": 0.1079840213060379, "1": 0.03269491344690323, "2": 0.00087855284800753, "3": 0.25763994455337524, "4": 0.04716291278600693, "5": 0.0006002824520692229, "6": 0.0005429606535471976, "7": 0.03289861977100372, "8": 0.00045589276123791933, "9": 0.5160732269287109, "10": 0.00039288992411457, "11": 0.00036749657010659575, "12": 0.00034518635948188603, "13": 0.0003254299226682633, "14": 0.00030781261739321053, "15": 0.0002920047554653138, "16": 0.00027774125919677317, "17": 0.00026480629458092153, "18": 0.000253022531978786, "19": 0.00024224280787166208}}, {"key": "b2020language", "year": "2020", "title": "Language Models Are Few-shot Learners", "topic_distr": {"0": 0.0010233379434794188, "1": 0.0008349302224814892, "2": 0.18731914460659027, "3": 0.38409340381622314, "4": 0.03318127244710922, "5": 0.00048217130824923515, "6": 0.00043612802983261645, "7": 0.026984455063939095, "8": 0.00036619158345274627, "9": 0.00033901017741300166, "10": 0.00031558514456264675, "11": 0.0002951881615445018, "12": 0.062496401369571686, "13": 0.057920102030038834, "14": 0.026220377534627914, "15": 0.13169996440410614, "16": 0.0002230930549558252, "17": 0.043775297701358795, "18": 0.0002032379707088694, "19": 0.0417906790971756}}, {"key": "bach2022integrated", "year": "2022", "title": "Promptsource: An Integrated Development Environment And Repository For Natural Language Prompts", "topic_distr": {"0": 0.0019792888779193163, "1": 0.0016168055590242147, "2": 0.0013666788581758738, "3": 0.30152273178100586, "4": 0.06856974214315414, "5": 0.0855252593755722, "6": 0.0008446195279248059, "7": 0.0007709958590567112, "8": 0.018983442336320877, "9": 0.0006565380026586354, "10": 0.0006111722905188799, "11": 0.04322602599859238, "12": 0.11127573996782303, "13": 0.0005062327836640179, "14": 0.0004788275982718915, "15": 0.00045423718984238803, "16": 0.0004320491570979357, "17": 0.3604091703891754, "18": 0.0003935971762984991, "19": 0.0003768284514080733}}, {"key": "bae2019summary", "year": "2019", "title": "Summary Level Training Of Sentence Rewriting For Abstractive Summarization", "topic_distr": {"0": 0.0016639184905216098, "1": 0.0013581367675215006, "2": 0.366169810295105, "3": 0.0009942777687683702, "4": 0.04144514352083206, "5": 0.0007843308849260211, "6": 0.0007094339234754443, "7": 0.15861280262470245, "8": 0.0005956708337180316, "9": 0.0005514557706192136, "10": 0.22322654724121094, "11": 0.11971084773540497, "12": 0.0004510215076152235, "13": 0.0004252077196724713, "14": 0.00040218885987997055, "15": 0.0003815342497546226, "16": 0.0003628975246101618, "17": 0.08150766044855118, "18": 0.0003305999853182584, "19": 0.00031651515746489167}}, {"key": "baevski2019cloze", "year": "2019", "title": "Cloze-driven Pretraining Of Self-attention Networks", "topic_distr": {"0": 0.002188784070312977, "1": 0.0017869151197373867, "2": 0.46067214012145996, "3": 0.0013081798097118735, "4": 0.00115375651512295, "5": 0.0010319506982341409, "6": 0.0009334079804830253, "7": 0.0008520448463968933, "8": 0.0007837290177121758, "9": 0.0007255548844113946, "10": 0.23256422579288483, "11": 0.0006317663937807083, "12": 0.09053777903318405, "13": 0.03739451244473457, "14": 0.0005291631678119302, "15": 0.0005019877571612597, "16": 0.0004774672561325133, "17": 0.00045523064909502864, "18": 0.0004349731025286019, "19": 0.1650364100933075}}, {"key": "bahdanau2016actor", "year": "2016", "title": "An Actor-critic Algorithm For Sequence Prediction", "topic_distr": {"0": 0.03619546815752983, "1": 0.024977881461381912, "2": 0.4559592306613922, "3": 0.0008194781839847565, "4": 0.0007227465976029634, "5": 0.014546218328177929, "6": 0.0005847133579663932, "7": 0.19003066420555115, "8": 0.0004909501294605434, "9": 0.0004545082338154316, "10": 0.000423102464992553, "11": 0.14713266491889954, "12": 0.0003717305662576109, "13": 0.00035045493859797716, "14": 0.10940968245267868, "15": 0.0003144594084005803, "16": 0.00029909907607361674, "17": 0.0002851694298442453, "18": 0.016370875760912895, "19": 0.000260870874626562}}, {"key": "bahng2022exploring", "year": "2022", "title": "Exploring Visual Prompts For Adapting Large-scale Models", "topic_distr": {"0": 0.0019222229020670056, "1": 0.0640779361128807, "2": 0.001324614742770791, "3": 0.09206224977970123, "4": 0.0010118487989529967, "5": 0.0009050244116224349, "6": 0.0008186021586880088, "7": 0.0007472464349120855, "8": 0.0006873331731185317, "9": 0.0006363142747431993, "10": 0.0005923460121266544, "11": 0.000554061378352344, "12": 0.0005204250337556005, "13": 0.0004906390095129609, "14": 0.0004640780098270625, "15": 0.00044024508679285645, "16": 0.0004187404992990196, "17": 0.5330454111099243, "18": 0.29891544580459595, "19": 0.00036522079608403146}}, {"key": "bahrini2023threats", "year": "2023", "title": "Chatgpt: Applications, Opportunities, And Threats", "topic_distr": {"0": 0.0013721577124670148, "1": 0.0011194165563210845, "2": 0.000946155923884362, "3": 0.0008194821421056986, "4": 0.08635678887367249, "5": 0.000646443571895361, "6": 0.1974991261959076, "7": 0.0005337454495020211, "8": 0.000490950420498848, "9": 0.39609113335609436, "10": 0.10526641458272934, "11": 0.10370756685733795, "12": 0.03548375144600868, "13": 0.00035045514232479036, "14": 0.06788433343172073, "15": 0.00031445958302356303, "16": 0.0002990992506965995, "17": 0.00028516960446722806, "18": 0.0002724796941038221, "19": 0.0002608710201457143}}, {"key": "bai2021semantic", "year": "2021", "title": "Semantic Representation For Dialogue Modeling", "topic_distr": {"0": 0.001979596447199583, "1": 0.0016166680725291371, "2": 0.0013665080768987536, "3": 0.0011835593031719327, "4": 0.0010438516037538648, "5": 0.14235085248947144, "6": 0.14443878829479218, "7": 0.0007708796765655279, "8": 0.0007090715225785971, "9": 0.0006564390496350825, "10": 0.0006110802059993148, "11": 0.0005715847364626825, "12": 0.0005368845886550844, "13": 0.0005061565316282213, "14": 0.1452997624874115, "15": 0.00045416876673698425, "16": 0.5547219514846802, "17": 0.00041186570888385177, "18": 0.0003935378626920283, "19": 0.0003767716698348522}}, {"key": "bai2023prompt", "year": "2023", "title": "Prompt-based Distribution Alignment For Unsupervised Domain Adaptation", "topic_distr": {"0": 0.0011136336252093315, "1": 0.0009092402760870755, "2": 0.000768653117120266, "3": 0.0006657607736997306, "4": 0.0005871743196621537, "5": 0.0005251839756965637, "6": 0.000475033390102908, "7": 0.0004336257406976074, "8": 0.0003988581884186715, "9": 0.00036925202584825456, "10": 0.00034373733797110617, "11": 0.00032152081257663667, "12": 0.0003020017175003886, "13": 0.0002847169525921345, "14": 0.0002693036221899092, "15": 0.00025547342374920845, "16": 0.31343701481819153, "17": 0.49655458331108093, "18": 0.18177329003810883, "19": 0.00021193696011323482}}, {"key": "bai2023qwen", "year": "2023", "title": "Qwen Technical Report", "topic_distr": {"0": 0.001486090593971312, "1": 0.0611005574464798, "2": 0.0010249258484691381, "3": 0.33240988850593567, "4": 0.0007829424575902522, "5": 0.0007002836791798472, "6": 0.0006334125646390021, "7": 0.000578199396841228, "8": 0.0005318400799296796, "9": 0.13235434889793396, "10": 0.00045834158663637936, "11": 0.1484314352273941, "12": 0.19083286821842194, "13": 0.026225345209240913, "14": 0.0003590912092477083, "15": 0.0003406499163247645, "16": 0.042728912085294724, "17": 0.0003089204546995461, "18": 0.00029517363873310387, "19": 0.058416787534952164}}, {"key": "balaguer2024rag", "year": "2024", "title": "RAG Vs Fine-tuning: Pipelines, Tradeoffs, And A Case Study On Agriculture", "topic_distr": {"0": 0.0010143819963559508, "1": 0.0008281628834083676, "2": 0.0006999589968472719, "3": 0.3974840044975281, "4": 0.0005346868420019746, "5": 0.00047823769273236394, "6": 0.08150966465473175, "7": 0.00039486383320763707, "8": 0.15209384262561798, "9": 0.08325416594743729, "10": 0.00031301056151278317, "11": 0.0002927799941971898, "12": 0.1673498898744583, "13": 0.0002592660312075168, "14": 0.00024523050524294376, "15": 0.00023263659386429936, "16": 0.11240970343351364, "17": 0.00021096790442243218, "18": 0.0002015799400396645, "19": 0.0001929918653331697}}, {"key": "bang2023multimodal", "year": "2023", "title": "A Multitask, Multilingual, Multimodal Evaluation Of Chatgpt On Reasoning, Hallucination, And Interactivity", "topic_distr": {"0": 0.09643936157226562, "1": 0.04712991416454315, "2": 0.0006887389463372529, "3": 0.3702968657016754, "4": 0.0005261235637590289, "5": 0.0004705782048404217, "6": 0.00042564194882288575, "7": 0.0003885396581608802, "8": 0.0003573870344553143, "9": 0.14274859428405762, "10": 0.0003079973685089499, "11": 0.00028809081413783133, "12": 0.00027060118736699224, "13": 0.0002551135839894414, "14": 0.08184516429901123, "15": 0.056321024894714355, "16": 0.0768839493393898, "17": 0.0454249233007431, "18": 0.07874148339033127, "19": 0.0001899008930195123}}, {"key": "bansal2019learning", "year": "2019", "title": "Learning To Few-shot Learn Across Diverse Natural Language Classification Tasks", "topic_distr": {"0": 0.015108253806829453, "1": 0.13460855185985565, "2": 0.29948246479034424, "3": 0.0006968982634134591, "4": 0.0006146341329440475, "5": 0.0005497449892573059, "6": 0.0004972490132786334, "7": 0.00045390488230623305, "8": 0.00041751135722734034, "9": 0.00038652060902677476, "10": 0.09788338094949722, "11": 0.0003365571901667863, "12": 0.05668850243091583, "13": 0.0002980321296490729, "14": 0.00028189801378175616, "15": 0.00026742101181298494, "16": 0.00025435833958908916, "17": 0.39072054624557495, "18": 0.00023172068176791072, "19": 0.00022184850240591913}}, {"key": "bao2018deriving", "year": "2018", "title": "Deriving Machine Attention From Human Rationales", "topic_distr": {"0": 0.06512875854969025, "1": 0.0017562032444402575, "2": 0.6469211578369141, "3": 0.0012856979155912995, "4": 0.0011339279590174556, "5": 0.0010142148239538074, "6": 0.000917365774512291, "7": 0.0008374009630642831, "8": 0.0007702592411078513, "9": 0.0007130849990062416, "10": 0.0006638120394200087, "11": 0.08922938257455826, "12": 0.0005832138704136014, "13": 0.0005498341633938253, "14": 0.0005200685700401664, "15": 0.0004933602176606655, "16": 0.00046926114009693265, "17": 0.18617619574069977, "18": 0.000427497347118333, "19": 0.00040928434464149177}}, {"key": "bao2019non", "year": "2019", "title": "Non-autoregressive Transformer By Position Learning", "topic_distr": {"0": 0.0027099058497697115, "1": 0.002213709754869342, "2": 0.0018715370679274201, "3": 0.0016209675231948495, "4": 0.0014296307926997542, "5": 0.0012786996085196733, "6": 0.13482779264450073, "7": 0.11310186982154846, "8": 0.0009711259626783431, "9": 0.0008990418864414096, "10": 0.32722359895706177, "11": 0.0007828276138752699, "12": 0.0007353032124228776, "13": 0.000693218840751797, "14": 0.10402722656726837, "15": 0.3034028112888336, "16": 0.0005916341324336827, "17": 0.0005640806048177183, "18": 0.0005389792495407164, "19": 0.000516016676556319}}, {"key": "bao2019pre", "year": "2019", "title": "PLATO: Pre-trained Dialogue Generation Model With Discrete Latent Variable", "topic_distr": {"0": 0.0016848199302330613, "1": 0.0013761636801064014, "2": 0.001163443666882813, "3": 0.0010076615726575255, "4": 0.000888716836925596, "5": 0.0007948910351842642, "6": 0.6618053913116455, "7": 0.0006563130300492048, "8": 0.04094879701733589, "9": 0.00055888039059937, "10": 0.19484134018421173, "11": 0.00048663694178685546, "12": 0.028373902663588524, "13": 0.0004309325304348022, "14": 0.00040760377305559814, "15": 0.00038667110493406653, "16": 0.06318134814500809, "17": 0.0003506550274323672, "18": 0.0003350510378368199, "19": 0.00032077659852802753}}, {"key": "bao2020plato", "year": "2020", "title": "PLATO-2: Towards Building An Open-domain Chatbot Via Curriculum Learning", "topic_distr": {"0": 0.0022261289414018393, "1": 0.0018190612317994237, "2": 0.18462640047073364, "3": 0.0013315108371898532, "4": 0.0011743400245904922, "5": 0.0010503599187359214, "6": 0.3823741376399994, "7": 0.000867244612891227, "8": 0.0007977100904099643, "9": 0.0007384982309304178, "10": 0.0006874692044220865, "11": 0.0006430365610867739, "12": 0.0006039986619725823, "13": 0.0005694293649867177, "14": 0.0005386029952205718, "15": 0.4181361496448517, "16": 0.00048598487046547234, "17": 0.00046335160732269287, "18": 0.00044273267849348485, "19": 0.0004238705732859671}}, {"key": "bao2020pseudo", "year": "2020", "title": "Unilmv2: Pseudo-masked Language Models For Unified Language Model Pre-training", "topic_distr": {"0": 0.001641124370507896, "1": 0.0013403304619714618, "2": 0.0011327844113111496, "3": 0.0009811115451157093, "4": 0.0008652954711578786, "5": 0.0007739430293440819, "6": 0.0007000379264354706, "7": 0.0463469997048378, "8": 0.000587781541980803, "9": 0.0005441521061584353, "10": 0.9416366219520569, "11": 0.00047381254262290895, "12": 0.00044504800462163985, "13": 0.00041957609937526286, "14": 0.00039686213131062686, "15": 0.0003764810971915722, "16": 0.00035809120163321495, "17": 0.0003414141829125583, "18": 0.0003262214013375342, "19": 0.0003123231290373951}}, {"key": "bao2021g", "year": "2021", "title": "G-transformer For Document-level Machine Translation", "topic_distr": {"0": 0.10915784537792206, "1": 0.0015430200146511197, "2": 0.5133525133132935, "3": 0.0011298430617898703, "4": 0.000996474176645279, "5": 0.0008912728517316282, "6": 0.0008061638218350708, "7": 0.0007358922739513218, "8": 0.0006768893799744546, "9": 0.0006266457494348288, "10": 0.16937382519245148, "11": 0.0005456426297314465, "12": 0.0005125174066051841, "13": 0.00048318394692614675, "14": 0.19719380140304565, "15": 0.0004335557168815285, "16": 0.0004123779071960598, "17": 0.00039317263872362673, "18": 0.0003756766382139176, "19": 0.0003596713941078633}}, {"key": "bao2021unified", "year": "2021", "title": "Vlmo: Unified Vision-language Pre-training With Mixture-of-modality-experts", "topic_distr": {"0": 0.0021489127539098263, "1": 0.001756092649884522, "2": 0.0014843271346762776, "3": 0.0012856459943577647, "4": 0.001133883954025805, "5": 0.0010141755919903517, "6": 0.0009173304424621165, "7": 0.0008373687160201371, "8": 0.04659538343548775, "9": 0.0007130575249902904, "10": 0.5631144046783447, "11": 0.0006208844133652747, "12": 0.0005831913440488279, "13": 0.0005498129758052528, "14": 0.0005200485466048121, "15": 0.0004933411837555468, "16": 0.000469243066618219, "17": 0.00044738949509337544, "18": 0.32494720816612244, "19": 0.0503682941198349}}, {"key": "bao2022vl", "year": "2022", "title": "Vl-beit: Generative Vision-language Pretraining", "topic_distr": {"0": 0.0016839015297591686, "1": 0.0013762733433395624, "2": 0.0011633626418188214, "3": 0.0010076086036860943, "4": 0.0008886699215508997, "5": 0.0007948498241603374, "6": 0.000718948373105377, "7": 0.0006562792113982141, "8": 0.02149898372590542, "9": 0.0005588515778072178, "10": 0.3883245587348938, "11": 0.00048661185428500175, "12": 0.0004570703022181988, "13": 0.0004309103242121637, "14": 0.0004075827600900084, "15": 0.04836622253060341, "16": 0.03391559422016144, "17": 0.0003506369539536536, "18": 0.40982940793037415, "19": 0.08708364516496658}}, {"key": "bao2023effective", "year": "2023", "title": "Tallrec: An Effective And Efficient Tuning Framework To Align Large Language Model With Recommendation", "topic_distr": {"0": 0.0011759174522012472, "1": 0.0752527043223381, "2": 0.0008121685241349041, "3": 0.45246535539627075, "4": 0.22863443195819855, "5": 0.0005549141205847263, "6": 0.0005019245436415076, "7": 0.0004581728426273912, "8": 0.00042143711470998824, "9": 0.00039015497895888984, "10": 0.00036319592618383467, "11": 0.0003397217660676688, "12": 0.0003190977149643004, "13": 0.0003008344501722604, "14": 0.00028454861603677273, "15": 0.00026993549545295537, "16": 0.02629033848643303, "17": 0.21070733666419983, "18": 0.0002338994963793084, "19": 0.00022393449035007507}}, {"key": "bapna2018training", "year": "2018", "title": "Training Deeper Neural Machine Translation Models With Transparent Attention", "topic_distr": {"0": 0.0025439015589654446, "1": 0.0020786982495337725, "2": 0.1252584606409073, "3": 0.0015217253239825368, "4": 0.0013420995092019439, "5": 0.001200409489683807, "6": 0.0010857804445549846, "7": 0.0009911352535709739, "8": 0.0009116673027165234, "9": 0.0008439967059530318, "10": 0.1412619650363922, "11": 0.0007348978542722762, "12": 0.0006902831955812871, "13": 0.1918322741985321, "14": 0.47791510820388794, "15": 0.0005839337827637792, "16": 0.0005554104573093355, "17": 0.0005295439041219652, "18": 0.047634273767471313, "19": 0.00048442280967719853}}, {"key": "bapna2019scalable", "year": "2019", "title": "Simple, Scalable Adaptation For Neural Machine Translation", "topic_distr": {"0": 0.0015791530022397637, "1": 0.0012890610378235579, "2": 0.25193697214126587, "3": 0.0009439241257496178, "4": 0.0008325020899064839, "5": 0.0007446117815561593, "6": 0.0006735075730830431, "7": 0.0006147993262857199, "8": 0.00056550552835688, "9": 0.0005235295975580812, "10": 0.00048735455493442714, "11": 0.0004558557702694088, "12": 0.0004281813744455576, "13": 0.11030284315347672, "14": 0.3783630430698395, "15": 0.00036221303162164986, "16": 0.00034452008549124, "17": 0.24893805384635925, "18": 0.0003138580941595137, "19": 0.00030048657208681107}}, {"key": "bapna2022building", "year": "2022", "title": "Building Machine Translation Systems For The Next Thousand Languages", "topic_distr": {"0": 0.0015594582073390484, "1": 0.0012732536997646093, "2": 0.0010762974852696061, "3": 0.33433017134666443, "4": 0.18923498690128326, "5": 0.0007353603141382337, "6": 0.000665139639750123, "7": 0.0006071608513593674, "8": 0.000558479456230998, "9": 0.08842771500349045, "10": 0.00048129947390407324, "11": 0.00045019201934337616, "12": 0.20383618772029877, "13": 0.000398659409256652, "14": 0.1747366040945053, "15": 0.0003577127354219556, "16": 0.00034023961052298546, "17": 0.0003243939718231559, "18": 0.00030995861743576825, "19": 0.0002967531909234822}}, {"key": "bapna2022massively", "year": "2022", "title": "Mslam: Massively Multilingual Joint Pre-training For Speech And Text", "topic_distr": {"0": 0.0013006188673898578, "1": 0.3855149447917938, "2": 0.0008968286565504968, "3": 0.0007767645292915404, "4": 0.0006850730278529227, "5": 0.0006127475644461811, "6": 0.0005542354192584753, "7": 0.0005059238756075501, "8": 0.0004653595678973943, "9": 0.00043081719195470214, "10": 0.09020549803972244, "11": 0.00037512779817916453, "12": 0.08164245635271072, "13": 0.0003321876283735037, "14": 0.169804185628891, "15": 0.00029806833481416106, "16": 0.00028350864886306226, "17": 0.0002703050849959254, "18": 0.26479804515838623, "19": 0.00024727307027205825}}, {"key": "barei\u00df2022code", "year": "2022", "title": "Code Generation Tools (almost) For Free? A Study Of Few-shot, Pre-trained Language Models On Code", "topic_distr": {"0": 0.0008436577045358717, "1": 0.0006881383014842868, "2": 0.0005817090859636664, "3": 0.7271084785461426, "4": 0.0004443615034688264, "5": 0.00039744857349433005, "6": 0.2484017312526703, "7": 0.0003281591343693435, "8": 0.018895098939538002, "9": 0.0002794424071907997, "10": 0.0002601334126666188, "11": 0.0002433204062981531, "12": 0.0002285487571498379, "13": 0.00021546798234339803, "14": 0.00020380350179038942, "15": 0.00019333708041813225, "16": 0.00018389317847322673, "17": 0.00017532891070004553, "18": 0.00016752685769461095, "19": 0.00016038957983255386}}, {"key": "barikeri2021real", "year": "2021", "title": "Redditbias: A Real-world Resource For Bias Evaluation And Debiasing Of Conversational Language Models", "topic_distr": {"0": 0.3438993990421295, "1": 0.07835476100444794, "2": 0.0007757582352496684, "3": 0.15556123852729797, "4": 0.1001066267490387, "5": 0.0005300239427015185, "6": 0.09746848791837692, "7": 0.0004376218712422997, "8": 0.0004025339148938656, "9": 0.0003726549039129168, "10": 0.00034690508618950844, "11": 0.0003244838444516063, "12": 0.00030478485859930515, "13": 0.12840494513511658, "14": 0.00027178542222827673, "15": 0.0002578277781140059, "16": 0.000245233706664294, "17": 0.00023381267965305597, "18": 0.0002234081330243498, "19": 0.09147768467664719}}, {"key": "barkan2019scalable", "year": "2019", "title": "Scalable Attentive Sentence-pair Modeling Via Distilled Sentence Embedding", "topic_distr": {"0": 0.0010576556669548154, "1": 0.0008631887030787766, "2": 0.4554527699947357, "3": 0.0006320046377368271, "4": 0.0005574016831815243, "5": 0.0004985547857359052, "6": 0.00045094703091308475, "7": 0.00041163896094076335, "8": 0.013566838577389717, "9": 0.00035052926978096366, "10": 0.3014068603515625, "11": 0.0003052182437386364, "12": 0.0002866888535209, "13": 0.19421721994876862, "14": 0.00025564871612004936, "15": 0.00024251975992228836, "16": 0.00023067343863658607, "17": 0.02880229614675045, "18": 0.00021014371304772794, "19": 0.00020119079272262752}}, {"key": "barraco2022mean", "year": "2022", "title": "Camel: Mean Teacher Learning For Image Captioning", "topic_distr": {"0": 0.06070873513817787, "1": 0.0012893031816929579, "2": 0.24589796364307404, "3": 0.0009439089335501194, "4": 0.0008324914961121976, "5": 0.0007446015370078385, "6": 0.12749287486076355, "7": 0.0006147906533442438, "8": 0.0005654975539073348, "9": 0.0005235222051851451, "10": 0.00048734768643043935, "11": 0.0004558493383228779, "12": 0.0004281753208488226, "13": 0.16018594801425934, "14": 0.00038181626587174833, "15": 0.0003622079093474895, "16": 0.06805384159088135, "17": 0.0003284704580437392, "18": 0.3294021487236023, "19": 0.0003004823229275644}}, {"key": "bartolo2020beat", "year": "2020", "title": "Beat The AI: Investigating Adversarial Human Annotation For Reading Comprehension", "topic_distr": {"0": 0.19385935366153717, "1": 0.39991649985313416, "2": 0.22445327043533325, "3": 0.0008473593043163419, "4": 0.0007473371224477887, "5": 0.000668438442517072, "6": 0.0006046081543900073, "7": 0.0005519057740457356, "8": 0.10093538463115692, "9": 0.016724146902561188, "10": 0.05771215260028839, "11": 0.0004092220333404839, "12": 0.00038437871262431145, "13": 0.0003623791562858969, "14": 0.0003427615447435528, "15": 0.00032515887869521976, "16": 0.0003092758997809142, "17": 0.00029487229767255485, "18": 0.00028175063198432326, "19": 0.0002697469899430871}}, {"key": "bartolo2021improving", "year": "2021", "title": "Improving Question Answering Model Robustness With Synthetic Adversarial Data Generation", "topic_distr": {"0": 0.0013418321032077074, "1": 0.6143510937690735, "2": 0.0009257062920369208, "3": 0.0008017710642889142, "4": 0.000707129598595202, "5": 0.0006324743153527379, "6": 0.0005720783374272287, "7": 0.117336206138134, "8": 0.18196721374988556, "9": 0.0004446868260856718, "10": 0.00041395972948521376, "11": 0.00038720457814633846, "12": 0.0003636979090515524, "13": 0.07802948355674744, "14": 0.0003243199025746435, "15": 0.000307664304273203, "16": 0.00029263587202876806, "17": 0.00027900724671781063, "18": 0.00026659155264496803, "19": 0.00025523375370539725}}, {"key": "bassner2024ai", "year": "2024", "title": "Iris: An Ai-driven Virtual Tutor For Computer Science Education", "topic_distr": {"0": 0.09053505957126617, "1": 0.0009520842577330768, "2": 0.0008046910515986383, "3": 0.12080399692058563, "4": 0.14399322867393494, "5": 0.0005498055252246559, "6": 0.03962690010666847, "7": 0.0004539548244792968, "8": 0.07741792500019073, "9": 0.45129743218421936, "10": 0.00035985230351798236, "11": 0.00033659423934295774, "12": 0.012559834867715836, "13": 0.0002980649296659976, "14": 0.00028192903846502304, "15": 0.0002674504357855767, "16": 0.00025438633747398853, "17": 0.05875321477651596, "18": 0.00023174617672339082, "19": 0.0002218729059677571}}, {"key": "bastings2020elephant", "year": "2020", "title": "The Elephant In The Interpretability Room: Why Use Attention As Explanation When We Have Saliency Methods?", "topic_distr": {"0": 0.0017570385243743658, "1": 0.0014343346701934934, "2": 0.0012125226203352213, "3": 0.0010501809883862734, "4": 0.0009262204403057694, "5": 0.9867398142814636, "6": 0.0007493274752050638, "7": 0.0006840102723799646, "8": 0.0006291671888902783, "9": 0.0005824658437632024, "10": 0.000542218389455229, "11": 0.0005071736522950232, "12": 0.00047638380783610046, "13": 0.00044911843724548817, "14": 0.00042480515548959374, "15": 0.0004029890988022089, "16": 0.0003833043447230011, "17": 0.0003654531028587371, "18": 0.00034919060999527574, "19": 0.0003343137796036899}}, {"key": "bauer2018commonsense", "year": "2018", "title": "Commonsense For Generative Multi-hop Question Answering Tasks", "topic_distr": {"0": 0.0010851090773940086, "1": 0.0008856967906467617, "2": 0.4003605544567108, "3": 0.13842564821243286, "4": 0.0005719667533412576, "5": 0.0005115813692100346, "6": 0.03324390947818756, "7": 0.00042239451431669295, "8": 0.21040737628936768, "9": 0.00035968809970654547, "10": 0.00033483427250757813, "11": 0.0003131931880488992, "12": 0.00029417965561151505, "13": 0.0002773425658233464, "14": 0.00026232845266349614, "15": 0.08152423053979874, "16": 0.1300721913576126, "17": 0.00022567699488718063, "18": 0.00021563447080552578, "19": 0.00020644762844312936}}, {"key": "bavarian2022efficient", "year": "2022", "title": "Efficient Training Of Language Models To Fill In The Middle", "topic_distr": {"0": 0.08521813899278641, "1": 0.10283301770687103, "2": 0.26878389716148376, "3": 0.07637064903974533, "4": 0.0007738054846413434, "5": 0.0006921118474565446, "6": 0.0006260208319872618, "7": 0.13197198510169983, "8": 0.01618846505880356, "9": 0.00048661729670129716, "10": 0.0004529928555712104, "11": 0.0004237149260006845, "12": 0.16735440492630005, "13": 0.1459360271692276, "14": 0.000354900723323226, "15": 0.00033667462412267923, "16": 0.0003202291554771364, "17": 0.0003053154214285314, "18": 0.00029172905487939715, "19": 0.0002793002931866795}}, {"key": "beck2024extended", "year": "2024", "title": "Xlstm: Extended Long Short-term Memory", "topic_distr": {"0": 0.1483258605003357, "1": 0.0011444350238889456, "2": 0.24178674817085266, "3": 0.12402190268039703, "4": 0.0007390529499389231, "5": 0.000661027617752552, "6": 0.0005979050183668733, "7": 0.0005457869847305119, "8": 0.0005020264652557671, "9": 0.030372966080904007, "10": 0.17435365915298462, "11": 0.00040468506631441414, "12": 0.0003801171842496842, "13": 0.18140465021133423, "14": 0.00033896142849698663, "15": 0.000321553903631866, "16": 0.0932617112994194, "17": 0.00029160312260501087, "18": 0.00027862691786140203, "19": 0.0002667563676368445}}, {"key": "beltagy2020long", "year": "2020", "title": "Longformer: The Long-document Transformer", "topic_distr": {"0": 0.0016851176042109728, "1": 0.0013761689187958837, "2": 0.4633216857910156, "3": 0.001007630256935954, "4": 0.0008886888972483575, "5": 0.000794866937212646, "6": 0.000718963798135519, "7": 0.0006562932976521552, "8": 0.0006036725244484842, "9": 0.000558863568585366, "10": 0.4371374249458313, "11": 0.0004866223025601357, "12": 0.0004570801102090627, "13": 0.00043091957923024893, "14": 0.0004075914912391454, "15": 0.02057180367410183, "16": 0.00036777235800400376, "17": 0.00035064449184574187, "18": 0.00033504096791148186, "19": 0.06784311681985855}}, {"key": "benharrak2023writer", "year": "2023", "title": "Writer-defined AI Personas For On-demand Feedback Generation", "topic_distr": {"0": 0.29288172721862793, "1": 0.13464035093784332, "2": 0.0012661463115364313, "3": 0.0010966327972710133, "4": 0.12753939628601074, "5": 0.0008650753297843039, "6": 0.0007824679487384856, "7": 0.08290966600179672, "8": 0.019502628594636917, "9": 0.3060028553009033, "10": 0.0005661990726366639, "11": 0.0005296043236739933, "12": 0.0004974527982994914, "13": 0.0004689815395977348, "14": 0.00044359295861795545, "15": 0.00042081205174326897, "16": 0.0004002567147836089, "17": 0.0003816159733105451, "18": 0.028455432504415512, "19": 0.0003490994276944548}}, {"key": "berglund2023reversal", "year": "2023", "title": "The Reversal Curse: Llms Trained On \"A Is B\" Fail To Learn \"B Is A\"", "topic_distr": {"0": 0.0909300446510315, "1": 0.0753791481256485, "2": 0.08652552962303162, "3": 0.3083481788635254, "4": 0.0008221430471166968, "5": 0.0007353464607149363, "6": 0.0006651270668953657, "7": 0.0006071493844501674, "8": 0.1278550624847412, "9": 0.0005170152871869504, "10": 0.00048129039350897074, "11": 0.2716538906097412, "12": 0.00042285348172299564, "13": 0.0003986518713645637, "14": 0.0003770706243813038, "15": 0.0003577059833332896, "16": 0.000340233207680285, "17": 0.00032438786001875997, "18": 0.000309952738462016, "19": 0.03294922783970833}}, {"key": "betz2021thinking", "year": "2021", "title": "Thinking Aloud: Dynamic Context Generation Improves Zero-shot Reasoning Performance Of GPT-2", "topic_distr": {"0": 0.0015036360127851367, "1": 0.02654551900923252, "2": 0.32592064142227173, "3": 0.44428592920303345, "4": 0.0007923943339847028, "5": 0.000708738574758172, "6": 0.0006410600617527962, "7": 0.061983734369277954, "8": 0.0005382611998356879, "9": 0.0004983075195923448, "10": 0.0004638753307517618, "11": 0.051277779042720795, "12": 0.00040755289955995977, "13": 0.00038422702345997095, "14": 0.00036342666135169566, "15": 0.08245962858200073, "16": 0.0003279221709817648, "17": 0.00031265016878023744, "18": 0.0002987374027725309, "19": 0.00028601003577932715}}, {"key": "beurerkellner2022prompting", "year": "2022", "title": "Prompting Is Programming: A Query Language For Large Language Models", "topic_distr": {"0": 0.0010056584142148495, "1": 0.0008213392575271428, "2": 0.0006943250191397965, "3": 0.5612755417823792, "4": 0.086552195250988, "5": 0.0004743928147945553, "6": 0.0004290922952350229, "7": 0.1012822687625885, "8": 0.05466517060995102, "9": 0.00033354118932038546, "10": 0.0003104940406046808, "11": 0.0002904261345975101, "12": 0.00027279474306851625, "13": 0.11286181956529617, "14": 0.00024325892445631325, "15": 0.0002307662507519126, "16": 0.0002194940607296303, "17": 0.07764603197574615, "18": 0.0001999592932406813, "19": 0.00019144026737194508}}, {"key": "bewersdorff2024taking", "year": "2024", "title": "Taking The Next Step With Generative Artificial Intelligence: The Transformative Role Of Multimodal Large Language Models In Science Education", "topic_distr": {"0": 0.04761314392089844, "1": 0.0006884042522870004, "2": 0.000581743661314249, "3": 0.0005038687377236784, "4": 0.0004443899088073522, "5": 0.00039747258415445685, "6": 0.0003595172893255949, "7": 0.00032817895407788455, "8": 0.0003018659772351384, "9": 0.7024226188659668, "10": 0.00026014912873506546, "11": 0.00024333510373253375, "12": 0.00022856256691738963, "13": 0.00021548100630752742, "14": 0.00020381582726258785, "15": 0.00019334876560606062, "16": 0.0001839042961364612, "17": 0.00017533950449433178, "18": 0.24449442327022552, "19": 0.00016039927140809596}}, {"key": "bezirhan2023automated", "year": "2023", "title": "Automated Reading Passage Generation With Openai's Large Language Model", "topic_distr": {"0": 0.15323662757873535, "1": 0.0009343588608317077, "2": 0.0007899064221419394, "3": 0.0006841541617177427, "4": 0.08868391811847687, "5": 0.0005396901397034526, "6": 0.00048815435729920864, "7": 0.18890860676765442, "8": 0.18439066410064697, "9": 0.12113098800182343, "10": 0.0003532317641656846, "11": 0.00033040158450603485, "12": 0.00031034337007440627, "13": 0.16544610261917114, "14": 0.0002767421246971935, "15": 0.033449094742536545, "16": 0.0002497061504982412, "17": 0.05935203656554222, "18": 0.00022748252376914024, "19": 0.00021779090457130224}}, {"key": "bhagavatula2019abductive", "year": "2019", "title": "Abductive Commonsense Reasoning", "topic_distr": {"0": 0.0013144066324457526, "1": 0.0010720791760832071, "2": 0.21473369002342224, "3": 0.2518782615661621, "4": 0.0006922934553585947, "5": 0.12638218700885773, "6": 0.0005600767326541245, "7": 0.09560766071081161, "8": 0.053128596395254135, "9": 0.00043535776785574853, "10": 0.0004052752919960767, "11": 0.08005054295063019, "12": 0.17171457409858704, "13": 0.0003356887027621269, "14": 0.0003175160090904683, "15": 0.00030120983137749135, "16": 0.0002864966809283942, "17": 0.0002731539716478437, "18": 0.0002609987568575889, "19": 0.0002498792018741369}}, {"key": "bhandari2023are", "year": "2023", "title": "Are Large Language Models Geospatially Knowledgeable?", "topic_distr": {"0": 0.001810077577829361, "1": 0.0014764891238883138, "2": 0.0012478810967877507, "3": 0.54716557264328, "4": 0.0009532289695926011, "5": 0.0008525930461473763, "6": 0.000771177583374083, "7": 0.0007039557676762342, "8": 0.0006475134869106114, "9": 0.000599450315348804, "10": 0.02075241506099701, "11": 0.0005219626473262906, "12": 0.11131659895181656, "13": 0.00046221454977057874, "14": 0.0004371922987047583, "15": 0.00041474009049125016, "16": 0.20660370588302612, "17": 0.000376109586795792, "18": 0.0003593728761188686, "19": 0.10252775251865387}}, {"key": "bhattacharjee2023fighting", "year": "2023", "title": "Fighting Fire With Fire: Can Chatgpt Detect Ai-generated Text?", "topic_distr": {"0": 0.06613864004611969, "1": 0.15294554829597473, "2": 0.001163352164439857, "3": 0.23736260831356049, "4": 0.0008886871510185301, "5": 0.0007948654820211232, "6": 0.0007189625757746398, "7": 0.0006562921334989369, "8": 0.0006036714767105877, "9": 0.20991657674312592, "10": 0.0005202461034059525, "11": 0.0004866214585490525, "12": 0.0004570792953018099, "13": 0.00043091882253065705, "14": 0.00040759079274721444, "15": 0.32513412833213806, "16": 0.0003677717177197337, "17": 0.0003506438515614718, "18": 0.0003350403858348727, "19": 0.0003207663830835372}}, {"key": "bhavya2022analogy", "year": "2022", "title": "Analogy Generation By Prompting Large Language Models: A Case Study Of Instructgpt", "topic_distr": {"0": 0.05958584323525429, "1": 0.0011315952287986875, "2": 0.0009565904620103538, "3": 0.2696034610271454, "4": 0.0007307466585189104, "5": 0.07807980477809906, "6": 0.0005911857588216662, "7": 0.11031369864940643, "8": 0.01755109615623951, "9": 0.0004595393256749958, "10": 0.00042778594070114195, "11": 0.0004001371853519231, "12": 0.00037584538222290576, "13": 0.0003543342463672161, "14": 0.04691167548298836, "15": 0.10930132120847702, "16": 0.0003024098987225443, "17": 0.3023837208747864, "18": 0.00027549569495022297, "19": 0.00026375852758064866}}, {"key": "bhojanapalli2020low", "year": "2020", "title": "Low-rank Bottleneck In Multi-head Attention Models", "topic_distr": {"0": 0.0014335856540128589, "1": 0.0011705253273248672, "2": 0.4519840180873871, "3": 0.0008571080979891121, "4": 0.0007559327059425414, "5": 0.00067612633574754, "6": 0.0006115619326010346, "7": 0.000558253435883671, "8": 0.0005134933744557202, "9": 0.06451957672834396, "10": 0.19375543296337128, "11": 0.0004139286174904555, "12": 0.00038879955536685884, "13": 0.2805171012878418, "14": 0.0003467037749942392, "15": 0.00032889863359741867, "16": 0.0003128329699393362, "17": 0.00029826373793184757, "18": 0.00028499113977886736, "19": 0.00027284942916594446}}, {"key": "bhoopchand2016learning", "year": "2016", "title": "Learning Python Code Suggestion With A Sparse Pointer Network", "topic_distr": {"0": 0.07905000448226929, "1": 0.0008350000134669244, "2": 0.34796762466430664, "3": 0.0006113277631811798, "4": 0.043332818895578384, "5": 0.00048224188503809273, "6": 0.26315030455589294, "7": 0.0003981699119322002, "8": 0.00036624513450078666, "9": 0.17281939089298248, "10": 0.0349309965968132, "11": 0.019146492704749107, "12": 0.0002773082524072379, "13": 0.00026143676950596273, "14": 0.00024728375137783587, "15": 0.03528960794210434, "16": 0.0002231256803497672, "17": 0.00021273427410051227, "18": 0.00020326770027168095, "19": 0.00019460772455204278}}, {"key": "bi2019incorporating", "year": "2019", "title": "Incorporating External Knowledge Into Machine Reading For Generative Question Answering", "topic_distr": {"0": 0.0014343305956572294, "1": 0.001170517411082983, "2": 0.0009895431576296687, "3": 0.0008570642094127834, "4": 0.0007558903307653964, "5": 0.0006760882679373026, "6": 0.13171270489692688, "7": 0.12925326824188232, "8": 0.4544079899787903, "9": 0.00047535134945064783, "10": 0.00044250537757761776, "11": 0.0004139052762184292, "12": 0.0003887776401825249, "13": 0.00036652630660682917, "14": 0.0003466842172201723, "15": 0.0003288800944574177, "16": 0.2751238942146301, "17": 0.0002982469159178436, "18": 0.00028497507446445525, "19": 0.00027283403323963284}}, {"key": "bi2020pre", "year": "2020", "title": "PALM: Pre-training An Autoencoding&autoregressive Language Model For Context-conditioned Generation", "topic_distr": {"0": 0.0012747501023113728, "1": 0.0010393477277830243, "2": 0.000878649007063359, "3": 0.0007610147004015744, "4": 0.04336382448673248, "5": 0.024786727502942085, "6": 0.1266094446182251, "7": 0.22625139355659485, "8": 0.076187364757061, "9": 0.00042208065860904753, "10": 0.19305624067783356, "11": 0.00036752058076672256, "12": 0.00034520888584665954, "13": 0.08443186432123184, "14": 0.00030783272814005613, "15": 0.19186130166053772, "16": 0.0002777593908831477, "17": 0.00026482358225621283, "18": 0.027270592749118805, "19": 0.00024225864035543054}}, {"key": "bi2023code", "year": "2023", "title": "Codekgc: Code Language Model For Generative Knowledge Graph Construction", "topic_distr": {"0": 0.0012104229535907507, "1": 0.0009889269713312387, "2": 0.0008358777849934995, "3": 0.1392095685005188, "4": 0.0006385212182067335, "5": 0.0005711103440262377, "6": 0.31379109621047974, "7": 0.0004715454706456512, "8": 0.00043373755761422217, "9": 0.0004015423764940351, "10": 0.0003737964725587517, "11": 0.00034963717916980386, "12": 0.024022957310080528, "13": 0.00030961487209424376, "14": 0.0002928537141997367, "15": 0.08296751976013184, "16": 0.36598044633865356, "17": 0.06667961180210114, "18": 0.00024072628002613783, "19": 0.00023047043941915035}}, {"key": "bian2023chatgpt", "year": "2023", "title": "Chatgpt Is A Knowledgeable But Inexperienced Solver: An Investigation Of Commonsense Problem In Large Language Models", "topic_distr": {"0": 0.000983369187451899, "1": 0.000801915826741606, "2": 0.0006779271061532199, "3": 0.27351146936416626, "4": 0.0005178583669476211, "5": 0.00046318615204654634, "6": 0.0004189557512290776, "7": 0.0003824362647719681, "8": 0.2592410445213318, "9": 0.1938646286725998, "10": 0.0003031591768376529, "11": 0.0002835653140209615, "12": 0.00026635045651346445, "13": 0.00025110613205470145, "14": 0.00023751237313263118, "15": 0.0002253148122690618, "16": 0.1374925673007965, "17": 0.12969544529914856, "18": 0.00019523561059031636, "19": 0.00018691783770918846}}, {"key": "biderman2023emergent", "year": "2023", "title": "Emergent And Predictable Memorization In Large Language Models", "topic_distr": {"0": 0.41206640005111694, "1": 0.04035479947924614, "2": 0.0752655416727066, "3": 0.17549683153629303, "4": 0.020815039053559303, "5": 0.0008285690564662218, "6": 0.0007494475576095283, "7": 0.0006841198191978037, "8": 0.0006292679463513196, "9": 0.0005825590924359858, "10": 0.031174642965197563, "11": 0.0005072548519819975, "12": 0.00047646008897572756, "13": 0.20827607810497284, "14": 0.0004248732002452016, "15": 0.03023562952876091, "16": 0.00038336575380526483, "17": 0.0003655116306617856, "18": 0.0003492465475574136, "19": 0.00033436730154789984}}, {"key": "biderman2023suite", "year": "2023", "title": "Pythia: A Suite For Analyzing Large Language Models Across Training And Scaling", "topic_distr": {"0": 0.251991331577301, "1": 0.15068762004375458, "2": 0.0010762019082903862, "3": 0.3299309313297272, "4": 0.0008220825111493468, "5": 0.0007352913962677121, "6": 0.0006650773575529456, "7": 0.0006071039824746549, "8": 0.02267398126423359, "9": 0.0005169766373001039, "10": 0.00048125439207069576, "11": 0.00045014984789304435, "12": 0.07254941761493683, "13": 0.16480664908885956, "14": 0.0003770424227695912, "15": 0.0003576792369130999, "16": 0.00034020774182863533, "17": 0.00032436358742415905, "18": 0.0003099295718129724, "19": 0.000296725396765396}}, {"key": "binz2023turning", "year": "2023", "title": "Turning Large Language Models Into Cognitive Models", "topic_distr": {"0": 0.45460501313209534, "1": 0.0012894944520667195, "2": 0.0010898273903876543, "3": 0.15707942843437195, "4": 0.0008325054659508169, "5": 0.0007446138770319521, "6": 0.0006735094357281923, "7": 0.0006148010725155473, "8": 0.0005655070999637246, "9": 0.000523531052749604, "10": 0.0004873559228144586, "11": 0.00045585702173411846, "12": 0.12870976328849792, "13": 0.0004036759492009878, "14": 0.046211183071136475, "15": 0.00036221405025571585, "16": 0.13066333532333374, "17": 0.00032847601687535644, "18": 0.0003138589672744274, "19": 0.0740460455417633}}, {"key": "bird2020chatbot", "year": "2020", "title": "Chatbot Interaction With Artificial Intelligence: Human Data Augmentation With T5 And Language Transformer Ensemble For Text Classification", "topic_distr": {"0": 0.05746433883905411, "1": 0.21828968822956085, "2": 0.2515330910682678, "3": 0.0006266385316848755, "4": 0.0005526698660105467, "5": 0.06995134800672531, "6": 0.03813774883747101, "7": 0.0004081437364220619, "8": 0.02316933497786522, "9": 0.14090263843536377, "10": 0.13555006682872772, "11": 0.03058764711022377, "12": 0.0002842546091414988, "13": 0.00026798556791618466, "14": 0.0002534780069254339, "15": 0.03116627410054207, "16": 0.00022871479450259358, "17": 0.00021806309814564884, "18": 0.00020835938630625606, "19": 0.00019948248518630862}}, {"key": "biten2021layout", "year": "2021", "title": "Latr: Layout-aware Transformer For Scene-text VQA", "topic_distr": {"0": 0.0757269412279129, "1": 0.040291592478752136, "2": 0.40838900208473206, "3": 0.000768737867474556, "4": 0.0006779946852475405, "5": 0.0006064161425456405, "6": 0.0005485084839165211, "7": 0.032467346638441086, "8": 0.07215314358472824, "9": 0.0004263655573595315, "10": 0.0003969044191762805, "11": 0.00037125160451978445, "12": 0.00034871342359110713, "13": 0.0003287551226094365, "14": 0.00031095781014300883, "15": 0.0002949884219560772, "16": 0.0002805791737046093, "17": 0.0002675120485946536, "18": 0.36509954929351807, "19": 0.00024471801589243114}}, {"key": "black2022gpt", "year": "2022", "title": "Gpt-neox-20b: An Open-source Autoregressive Language Model", "topic_distr": {"0": 0.0028378558345139027, "1": 0.2127620279788971, "2": 0.0019567019771784544, "3": 0.0016947252443060279, "4": 0.0014946741284802556, "5": 0.0013368759537115693, "6": 0.0012092157267034054, "7": 0.001103810966014862, "8": 0.0010153088951483369, "9": 0.0009399452246725559, "10": 0.24838130176067352, "11": 0.0008184436010196805, "12": 0.0007687570177949965, "13": 0.32651785016059875, "14": 0.0006855227402411401, "15": 0.1941656619310379, "16": 0.0006185515085235238, "17": 0.0005897443043068051, "18": 0.000563500972930342, "19": 0.0005394936888478696}}, {"key": "blocklove2023chip", "year": "2023", "title": "Chip-chat: Challenges And Opportunities In Conversational Hardware Design", "topic_distr": {"0": 0.16729365289211273, "1": 0.0011573061347007751, "2": 0.0009783474961295724, "3": 0.42224642634391785, "4": 0.0007473587174899876, "5": 0.0006684573600068688, "6": 0.1466393619775772, "7": 0.0005519213736988604, "8": 0.0005076690576970577, "9": 0.22327746450901031, "10": 0.00043751089833676815, "11": 0.00040923358756117523, "12": 0.0003843895683530718, "13": 0.00036238940083421767, "14": 0.032857686281204224, "15": 0.0003251680755056441, "16": 0.00030928466003388166, "17": 0.00029488065047189593, "18": 0.0002817586064338684, "19": 0.00026975461514666677}}, {"key": "blukis2021persistent", "year": "2021", "title": "A Persistent Spatial Semantic Representation For High-level Natural Language Instruction Execution", "topic_distr": {"0": 0.0022688887547701597, "1": 0.0018516763811931014, "2": 0.0015654447488486767, "3": 0.2207738608121872, "4": 0.0011958256363868713, "5": 0.001069578225724399, "6": 0.0009674424072727561, "7": 0.0008831125451251864, "8": 0.0008123056613840163, "9": 0.0007520104409195483, "10": 0.11379513889551163, "11": 0.6499518752098083, "12": 0.0006150499684736133, "13": 0.0005798481870442629, "14": 0.0005484577850438654, "15": 0.000520291447173804, "16": 0.0004948768764734268, "17": 0.0004718294949270785, "18": 0.00045083329314365983, "19": 0.0004316261038184166}}, {"key": "bohnet2022attributed", "year": "2022", "title": "Attributed Question Answering: Evaluation And Modeling For Attributed Large Language Models", "topic_distr": {"0": 0.001710161566734314, "1": 0.0013958967756479979, "2": 0.10109096020460129, "3": 0.41040727496147156, "4": 0.0009009204222820699, "5": 0.0008058063103817403, "6": 0.0007288585766218603, "7": 0.13423898816108704, "8": 0.11458395421504974, "9": 0.0005665549542754889, "10": 0.000527406926266849, "11": 0.0004933194722980261, "12": 0.22991468012332916, "13": 0.00043685012497007847, "14": 0.0004132009926252067, "15": 0.00039198086597025394, "16": 0.0003728338342625648, "17": 0.00035547022707760334, "18": 0.00033965197508223355, "19": 0.0003251815214753151}}, {"key": "bommarito2022gpt", "year": "2022", "title": "GPT Takes The Bar Exam", "topic_distr": {"0": 0.14925792813301086, "1": 0.0008707463275641203, "2": 0.10319450497627258, "3": 0.29454299807548523, "4": 0.013516198843717575, "5": 0.0005027967854402959, "6": 0.00045478384708985686, "7": 0.0004151413158979267, "8": 0.011218608357012272, "9": 0.07071004807949066, "10": 0.0003290846070740372, "11": 0.00030781514942646027, "12": 0.20883117616176605, "13": 0.11225378513336182, "14": 0.00025782384909689426, "15": 0.00024458320694975555, "16": 0.00023263608454726636, "17": 0.032444532960653305, "18": 0.00021193169231992215, "19": 0.00020290259271860123}}, {"key": "bondarenko2021understanding", "year": "2021", "title": "Understanding And Overcoming The Challenges Of Efficient Transformer Quantization", "topic_distr": {"0": 0.0013293275842443109, "1": 0.0010835016146302223, "2": 0.21926239132881165, "3": 0.0007934026070870459, "4": 0.0006997419986873865, "5": 0.000625867978669703, "6": 0.0005661026807501912, "7": 0.0005167567287571728, "8": 0.0004753238463308662, "9": 0.0004400418547447771, "10": 0.22691194713115692, "11": 0.0003831600188277662, "12": 0.0003598988987505436, "13": 0.4573613107204437, "14": 0.08780474960803986, "15": 0.00030445060110650957, "16": 0.00028957915492355824, "17": 0.0002760928764473647, "18": 0.0002638068690430373, "19": 0.00025256769731640816}}, {"key": "bonifacio2022data", "year": "2022", "title": "Inpars: Data Augmentation For Information Retrieval Using Large Language Models", "topic_distr": {"0": 0.001558195217512548, "1": 0.2027461975812912, "2": 0.001076113898307085, "3": 0.05076530575752258, "4": 0.0008220304735004902, "5": 0.0007352451211772859, "6": 0.0006650354480370879, "7": 0.0006070656818337739, "8": 0.10560952126979828, "9": 0.0005169440410099924, "10": 0.05429482460021973, "11": 0.00045012147165834904, "12": 0.07858417928218842, "13": 0.0003985969233326614, "14": 0.15676730871200562, "15": 0.15163882076740265, "16": 0.0003401862923055887, "17": 0.0003243431565351784, "18": 0.00030991004314273596, "19": 0.19179002940654755}}, {"key": "bordes2016learning", "year": "2016", "title": "Learning End-to-end Goal-oriented Dialog", "topic_distr": {"0": 0.0014672765973955393, "1": 0.0011983606964349747, "2": 0.3693635165691376, "3": 0.0008772587170824409, "4": 0.6004641056060791, "5": 0.0006920232553966343, "6": 0.0006259405054152012, "7": 0.000571378564927727, "8": 0.0005255661671981215, "9": 0.000486554839881137, "10": 0.00045293470611795783, "11": 0.00042366053094156086, "12": 0.0003979406610596925, "13": 0.02056562528014183, "14": 0.00035485514672473073, "15": 0.000336631404934451, "16": 0.000320188031764701, "17": 0.00030527624767273664, "18": 0.00029169159824959934, "19": 0.0002792644372675568}}, {"key": "borgeaud2021improving", "year": "2021", "title": "Improving Language Models By Retrieving From Trillions Of Tokens", "topic_distr": {"0": 0.0019188356818631291, "1": 0.001567270141094923, "2": 0.2822505533695221, "3": 0.07580426335334778, "4": 0.001011896994896233, "5": 0.0009050677181221545, "6": 0.0008186413906514645, "7": 0.0007472822326235473, "8": 0.11132622510194778, "9": 0.000636344775557518, "10": 0.18489734828472137, "11": 0.0005540879210457206, "12": 0.0005204500048421323, "13": 0.12779271602630615, "14": 0.00046410024515353143, "15": 0.00044026615796610713, "16": 0.116642527282238, "17": 0.00039925804594531655, "18": 0.000381491263397038, "19": 0.09092143177986145}}, {"key": "borisov2022language", "year": "2022", "title": "Language Models Are Realistic Tabular Data Generators", "topic_distr": {"0": 0.001313157263211906, "1": 0.4589497745037079, "2": 0.2635402977466583, "3": 0.06614327430725098, "4": 0.0006923148757778108, "5": 0.000619224738329649, "6": 0.0005600940203294158, "7": 0.0005112718208692968, "8": 0.0004702787264250219, "9": 0.0004353711847215891, "10": 0.00040528777753934264, "11": 0.0003790931368712336, "12": 0.00035607890458777547, "13": 0.0003356990637257695, "14": 0.0003175258170813322, "15": 0.11816516518592834, "16": 0.03368454426527023, "17": 0.0002731623826548457, "18": 0.052598509937524796, "19": 0.00024988691438920796}}, {"key": "borji2023categorical", "year": "2023", "title": "A Categorical Archive Of Chatgpt Failures", "topic_distr": {"0": 0.26994380354881287, "1": 0.07136347144842148, "2": 0.0011793747544288635, "3": 0.11085828393697739, "4": 0.0009009229834191501, "5": 0.0008058095118030906, "6": 0.03637654334306717, "7": 0.0006653281161561608, "8": 0.031113658100366592, "9": 0.3722599148750305, "10": 0.000527408963534981, "11": 0.0004933213349431753, "12": 0.10087691992521286, "13": 0.00043685181299224496, "14": 0.00041320259333588183, "15": 0.0003919823793694377, "16": 0.0003728352894540876, "17": 0.00035547162406146526, "18": 0.0003396532847546041, "19": 0.00032518277294002473}}, {"key": "borsos2022language", "year": "2022", "title": "Audiolm: A Language Modeling Approach To Audio Generation", "topic_distr": {"0": 0.0013710823841392994, "1": 0.1135934367775917, "2": 0.0009461958543397486, "3": 0.020675091072916985, "4": 0.0007227885071188211, "5": 0.000646481232251972, "6": 0.047248564660549164, "7": 0.2756500840187073, "8": 0.0004909790004603565, "9": 0.0004545349511317909, "10": 0.12502385675907135, "11": 0.00039577967254444957, "12": 0.0003717524232342839, "13": 0.01573219895362854, "14": 0.00033150234958156943, "15": 0.0003144778893329203, "16": 0.0002991166547872126, "17": 0.062486179172992706, "18": 0.28678789734840393, "19": 0.04645799472928047}}, {"key": "borsos2023efficient", "year": "2023", "title": "Soundstorm: Efficient Parallel Audio Generation", "topic_distr": {"0": 0.0022280775010585785, "1": 0.0018189018592238426, "2": 0.14191995561122894, "3": 0.001331655657850206, "4": 0.0011744665680453181, "5": 0.025665348395705223, "6": 0.0009501619497314095, "7": 0.4099189043045044, "8": 0.0007977962377481163, "9": 0.0007385779754258692, "10": 0.05864541605114937, "11": 0.0006431060028262436, "12": 0.0006040639127604663, "13": 0.0663800984621048, "14": 0.0005386612028814852, "15": 0.0005109980120323598, "16": 0.0004860373737756163, "17": 0.048206355422735214, "18": 0.23701751232147217, "19": 0.00042391635361127555}}, {"key": "bostrom2020byte", "year": "2020", "title": "Byte Pair Encoding Is Suboptimal For Language Model Pretraining", "topic_distr": {"0": 0.001578291179612279, "1": 0.001289128907956183, "2": 0.0010897741885855794, "3": 0.0009438800043426454, "4": 0.0008324605878442526, "5": 0.0007445741211995482, "6": 0.0006734734633937478, "7": 0.0006147682433947921, "8": 0.0005654768901877105, "9": 0.0005235030548647046, "10": 0.1746191531419754, "11": 0.00045583269093185663, "12": 0.00042815969209186733, "13": 0.0004036543832626194, "14": 0.03325760364532471, "15": 0.0003621946962084621, "16": 0.04208482429385185, "17": 0.000328458467265591, "18": 0.00031384220346808434, "19": 0.7388909459114075}}, {"key": "bowman2021what", "year": "2021", "title": "What Will It Take To Fix Benchmarking In Natural Language Understanding?", "topic_distr": {"0": 0.16783231496810913, "1": 0.1044476106762886, "2": 0.23745889961719513, "3": 0.0010652596829459071, "4": 0.0693175420165062, "5": 0.0008403249084949493, "6": 0.0007600808166898787, "7": 0.0006938262959010899, "8": 0.0006381961866281927, "9": 0.0005908245802856982, "10": 0.0005499995895661414, "11": 0.0005144519382156432, "12": 0.41254258155822754, "13": 0.0004555635678116232, "14": 0.00043090138933621347, "15": 0.00040877226274460554, "16": 0.0003888050268869847, "17": 0.0003706976131070405, "18": 0.0003542017366271466, "19": 0.0003391114005353302}}, {"key": "bowman2022measuring", "year": "2022", "title": "Measuring Progress On Scalable Oversight For Large Language Models", "topic_distr": {"0": 0.20463770627975464, "1": 0.001198187586851418, "2": 0.0010128923458978534, "3": 0.39790546894073486, "4": 0.09064008295536041, "5": 0.0006920403684489429, "6": 0.0006259562214836478, "7": 0.0005713929422199726, "8": 0.09956888109445572, "9": 0.19960972666740417, "10": 0.0004529460857156664, "11": 0.00042367118294350803, "12": 0.0003979506727773696, "13": 0.00037517433520406485, "14": 0.00035486408160068095, "15": 0.0003366398741491139, "16": 0.0003201960935257375, "17": 0.00030528390198014677, "18": 0.00029169893241487443, "19": 0.00027927145129069686}}, {"key": "bozkir2024embedding", "year": "2024", "title": "Embedding Large Language Models Into Extended Reality: Opportunities And Challenges For Inclusion, Engagement, And Privacy", "topic_distr": {"0": 0.0016420213505625725, "1": 0.001340375398285687, "2": 0.0011328801047056913, "3": 0.0009812024654820561, "4": 0.04857545718550682, "5": 0.0007740170694887638, "6": 0.000700104923453182, "7": 0.0006390782655216753, "8": 0.0005878378287889063, "9": 0.8953335881233215, "10": 0.0005066005978733301, "11": 0.00047385788639076054, "12": 0.00044509058352559805, "13": 0.00041961626266129315, "14": 0.0003969001118093729, "15": 0.0003765171277336776, "16": 0.0003581254568416625, "17": 0.04467807337641716, "18": 0.00032625262974761426, "19": 0.0003123530186712742}}, {"key": "brade2023text", "year": "2023", "title": "Promptify: Text-to-image Generation Through Interactive Prompt Exploration With Large Language Models", "topic_distr": {"0": 0.0014022077666595578, "1": 0.0011443806579336524, "2": 0.0009673729655332863, "3": 0.23918500542640686, "4": 0.11910218745470047, "5": 0.03773394972085953, "6": 0.02511528693139553, "7": 0.0005457316292449832, "8": 0.0005019755335524678, "9": 0.22670653462409973, "10": 0.0004326042253524065, "11": 0.0004046440590173006, "12": 0.0003800786507781595, "13": 0.00035832522553391755, "14": 0.0003389270859770477, "15": 0.08113889396190643, "16": 0.0003058160364162177, "17": 0.1682383418083191, "18": 0.0957309827208519, "19": 0.0002667293301783502}}, {"key": "bragg2021unifying", "year": "2021", "title": "FLEX: Unifying Evaluation For Few-shot NLP", "topic_distr": {"0": 0.0013714211527258158, "1": 0.0011194100370630622, "2": 0.0009461896261200309, "3": 0.20481766760349274, "4": 0.1328507661819458, "5": 0.0006464695325121284, "6": 0.0005847371648997068, "7": 0.0005337668117135763, "8": 0.0004909700364805758, "9": 0.00045452668564394116, "10": 0.00042311963625252247, "11": 0.00039577248389832675, "12": 0.21432872116565704, "13": 0.06918510049581528, "14": 0.0003314963250886649, "15": 0.061453141272068024, "16": 0.0002991112123709172, "17": 0.2397651970386505, "18": 0.00027249057893641293, "19": 0.06972990185022354}}, {"key": "bran2023augmenting", "year": "2023", "title": "Chemcrow: Augmenting Large-language Models With Chemistry Tools", "topic_distr": {"0": 0.0014180302387103438, "1": 0.0011573139345273376, "2": 0.0009783683344721794, "3": 0.4357212483882904, "4": 0.0007473714649677277, "5": 0.000668467371724546, "6": 0.0006046344060450792, "7": 0.000551929697394371, "8": 0.0005076766829006374, "9": 0.25148871541023254, "10": 0.00043751750490628183, "11": 0.05307058244943619, "12": 0.0003843953600153327, "13": 0.05719028785824776, "14": 0.0003427764168009162, "15": 0.0003251729649491608, "16": 0.19355909526348114, "17": 0.0002948851033579558, "18": 0.0002817628555931151, "19": 0.0002697586896829307}}, {"key": "brocki2023deep", "year": "2023", "title": "Deep Learning Mental Health Dialogue System", "topic_distr": {"0": 0.045265521854162216, "1": 0.21968619525432587, "2": 0.0010500488569959998, "3": 0.0009094616980291903, "4": 0.2529095411300659, "5": 0.07299165427684784, "6": 0.0006489161169156432, "7": 0.0005923514836467803, "8": 0.014991791918873787, "9": 0.253385066986084, "10": 0.06057172268629074, "11": 0.0004392113187350333, "12": 0.00041254740790463984, "13": 0.07418874651193619, "14": 0.00036788039142265916, "15": 0.00034898772719316185, "16": 0.0003319407987874001, "17": 0.00031648165895603597, "18": 0.00030239837360568345, "19": 0.00028951503918506205}}, {"key": "brohan2023rt", "year": "2023", "title": "RT-2: Vision-language-action Models Transfer Web Knowledge To Robotic Control", "topic_distr": {"0": 0.0010487943654879928, "1": 0.10178614407777786, "2": 0.0007234880467876792, "3": 0.24701955914497375, "4": 0.0005526541499421, "5": 0.04473608732223511, "6": 0.03235182166099548, "7": 0.00040813215309754014, "8": 0.01892499253153801, "9": 0.0003475430712569505, "10": 0.0003235284530092031, "11": 0.3268297612667084, "12": 0.0002842465473804623, "13": 0.00026797797181643546, "14": 0.00025347081827931106, "15": 0.0002404537081019953, "16": 0.03304397314786911, "17": 0.00021805691358167678, "18": 0.10494968295097351, "19": 0.08568960428237915}}, {"key": "bsharat2023principled", "year": "2023", "title": "Principled Instructions Are All You Need For Questioning Llama-1/2, GPT-3.5/4", "topic_distr": {"0": 0.002354186261072755, "1": 0.0019218260422348976, "2": 0.0016244521830230951, "3": 0.2667335569858551, "4": 0.08425512909889221, "5": 0.0011098886607214808, "6": 0.0010039033368229866, "7": 0.0009163953363895416, "8": 0.027421457692980766, "9": 0.19047749042510986, "10": 0.0007264312589541078, "11": 0.0006794803775846958, "12": 0.05631098523736, "13": 0.0006017015548422933, "14": 0.0005691280821338296, "15": 0.0005399002693593502, "16": 0.03026091866195202, "17": 0.3315774202346802, "18": 0.0004678243421949446, "19": 0.00044789325329475105}}, {"key": "bubeck2023sparks", "year": "2023", "title": "Sparks Of Artificial General Intelligence: Early Experiments With GPT-4", "topic_distr": {"0": 0.0010572661412879825, "1": 0.0008632389362901449, "2": 0.06195366382598877, "3": 0.24406372010707855, "4": 0.0005573602393269539, "5": 0.0004985174164175987, "6": 0.0004509132413659245, "7": 0.0004116081108804792, "8": 0.00037860588054172695, "9": 0.4136495590209961, "10": 0.0003262838290538639, "11": 0.0003051953681278974, "12": 0.1470853090286255, "13": 0.12703874707221985, "14": 0.0002556295657996088, "15": 0.00024250158458016813, "16": 0.00023065615096129477, "17": 0.0002199140435550362, "18": 0.00021012796787545085, "19": 0.00020117571693845093}}, {"key": "buch2022revisiting", "year": "2022", "title": "Revisiting The \"video\" In Video-language Understanding", "topic_distr": {"0": 0.0014687592629343271, "1": 0.001198591198772192, "2": 0.24245207011699677, "3": 0.0008773420704528689, "4": 0.000773776788264513, "5": 0.0006920863525010645, "6": 0.0006259979563765228, "7": 0.0005714310682378709, "8": 0.07131744176149368, "9": 0.0004865995142608881, "10": 0.0004529762954916805, "11": 0.0004236994427628815, "12": 0.10119006037712097, "13": 0.11809613555669785, "14": 0.03403370827436447, "15": 0.00033666231320239604, "16": 0.0003202174266334623, "17": 0.0003053042746614665, "18": 0.42409786581993103, "19": 0.00027929007774218917}}, {"key": "buck2017ask", "year": "2017", "title": "Ask The Right Questions: Active Question Reformulation With Reinforcement Learning", "topic_distr": {"0": 0.0014523748541250825, "1": 0.0011845408007502556, "2": 0.21850769221782684, "3": 0.0008672048570588231, "4": 0.07890575379133224, "5": 0.000684090075083077, "6": 0.0006187652470543981, "7": 0.0005648288060911, "8": 0.3270244300365448, "9": 0.000480977410916239, "10": 0.0004477426700759679, "11": 0.3479246497154236, "12": 0.0003933790430892259, "13": 0.00037086434895172715, "14": 0.0003507874207571149, "15": 0.0003327725571580231, "16": 0.0003165176894981414, "17": 0.00030177683220244944, "18": 0.018994782119989395, "19": 0.0002760631905402988}}, {"key": "bucker2022reshaping", "year": "2022", "title": "Reshaping Robot Trajectories Using Natural Language Commands: A Study Of Multi-modal Data Alignment Using Transformers", "topic_distr": {"0": 0.020005283877253532, "1": 0.0008418744546361268, "2": 0.16455484926700592, "3": 0.000616327568423003, "4": 0.049772512167692184, "5": 0.10260332375764847, "6": 0.06685584038496017, "7": 0.00040142712532542646, "8": 0.0003692412283271551, "9": 0.13944600522518158, "10": 0.08774363994598389, "11": 0.3087381422519684, "12": 0.00027957677957601845, "13": 0.0002635754644870758, "14": 0.00024930667132139206, "15": 0.00023650340153835714, "16": 0.00022495097073260695, "17": 0.00021447455219458789, "18": 0.056386977434158325, "19": 0.00019619971862994134}}, {"key": "budzianowski2019gpt", "year": "2019", "title": "Hello, It's GPT-2 -- How Can I Help You? Towards The Use Of Pretrained Language Models For Task-oriented Dialogue Systems", "topic_distr": {"0": 0.0014175514224916697, "1": 0.19009952247142792, "2": 0.17493435740470886, "3": 0.0008473751950077713, "4": 0.0007473467849195004, "5": 0.1055549904704094, "6": 0.21487388014793396, "7": 0.0005519120604731143, "8": 0.0005076604429632425, "9": 0.00046997820027172565, "10": 0.00043750350596383214, "11": 0.17098665237426758, "12": 0.00038438307819887996, "13": 0.0003623832599259913, "14": 0.000342765444656834, "15": 0.09841987490653992, "16": 0.00030927942134439945, "17": 0.00029487567371688783, "18": 0.0002817538334056735, "19": 0.03817594796419144}}, {"key": "bugliarello2020multimodal", "year": "2020", "title": "Multimodal Pretraining Unmasked: A Meta-analysis And A Unified Framework Of Vision-and-language Berts", "topic_distr": {"0": 0.23692326247692108, "1": 0.0016697804676368833, "2": 0.0014113979414105415, "3": 0.001222431194037199, "4": 0.0010781341698020697, "5": 0.0009643113007768989, "6": 0.000872227770742029, "7": 0.0007961975643411279, "8": 0.0007323594763875008, "9": 0.028167439624667168, "10": 0.19342954456806183, "11": 0.0005903572309762239, "12": 0.11974743008613586, "13": 0.0005227801739238203, "14": 0.0004944791435264051, "15": 0.0004690849455073476, "16": 0.0004461716453079134, "17": 0.000425392558099702, "18": 0.31363409757614136, "19": 0.09640312194824219}}, {"key": "bugliarello2022benchmark", "year": "2022", "title": "IGLUE: A Benchmark For Transfer Learning Across Modalities, Tasks, And Languages", "topic_distr": {"0": 0.020876793190836906, "1": 0.0011446562130004168, "2": 0.0009676262270659208, "3": 0.0008380793733522296, "4": 0.000739145209081471, "5": 0.0006611109129153192, "6": 0.0005979803972877562, "7": 0.0005458557279780507, "8": 0.029559390619397163, "9": 0.000464820972410962, "10": 0.0004327026254031807, "11": 0.0004047360853292048, "12": 0.31812670826911926, "13": 0.0003584067162591964, "14": 0.2524773180484772, "15": 0.07781549543142319, "16": 0.0003058855945710093, "17": 0.0002916398807428777, "18": 0.25844982266426086, "19": 0.03494177758693695}}, {"key": "bulat2022text", "year": "2022", "title": "LASP: Text-to-text Optimization For Language-aware Soft Prompting Of Vision & Language Models", "topic_distr": {"0": 0.04351578280329704, "1": 0.0008490069303661585, "2": 0.1450691819190979, "3": 0.0006214728346094489, "4": 0.0674816444516182, "5": 0.0004902464570477605, "6": 0.00044343213085085154, "7": 0.00040477910079061985, "8": 0.00037232442991808057, "9": 0.0003446878108661622, "10": 0.0003208704583812505, "11": 0.00030013188370503485, "12": 0.00028191128512844443, "13": 0.14327095448970795, "14": 0.0002513884101063013, "15": 0.0002384782419539988, "16": 0.00022682933195028454, "17": 0.48535865545272827, "18": 0.1099603921175003, "19": 0.00019783801690209657}}, {"key": "bulathwela2023scalable", "year": "2023", "title": "Scalable Educational Question Generation With Pre-trained Language Models", "topic_distr": {"0": 0.003120953217148781, "1": 0.002547931857407093, "2": 0.002152354223653674, "3": 0.0018642136128619313, "4": 0.0016441622283309698, "5": 0.0014705791836604476, "6": 0.0013301513390615582, "7": 0.2618793845176697, "8": 0.24221286177635193, "9": 0.3078077435493469, "10": 0.0009625063976272941, "11": 0.000900297483894974, "12": 0.0008456415962427855, "13": 0.16724932193756104, "14": 0.0007540829828940332, "15": 0.0007153567275963724, "16": 0.0006804137956351042, "17": 0.0006487256032414734, "18": 0.0006198576302267611, "19": 0.0005934493383392692}}, {"key": "bulatov2022recurrent", "year": "2022", "title": "Recurrent Memory Transformer", "topic_distr": {"0": 0.0011650626547634602, "1": 0.0009517988655716181, "2": 0.4600784480571747, "3": 0.0006969143869355321, "4": 0.0006146486266516149, "5": 0.0005497578531503677, "6": 0.000497260713018477, "7": 0.028945928439497948, "8": 0.0004175211943220347, "9": 0.0003865297185257077, "10": 0.2623472809791565, "11": 0.00033656510640867054, "12": 0.00031613270402885973, "13": 0.12383304536342621, "14": 0.0002819046494551003, "15": 0.0002674272982403636, "16": 0.11761771142482758, "17": 0.00024251807190012187, "18": 0.00023172612418420613, "19": 0.0002218537119915709}}, {"key": "bulatov2023scaling", "year": "2023", "title": "Scaling Transformer To 1M Tokens And Beyond With RMT", "topic_distr": {"0": 0.0018069806974381208, "1": 0.024180682376027107, "2": 0.36809587478637695, "3": 0.0010806928621605039, "4": 0.0009531244286336005, "5": 0.0008524999138899148, "6": 0.0007710934150964022, "7": 0.02606264315545559, "8": 0.017695406451821327, "9": 0.12870144844055176, "10": 0.2103174924850464, "11": 0.0005219056038185954, "12": 0.0004902214277535677, "13": 0.21614424884319305, "14": 0.0004371445393189788, "15": 0.000414694775827229, "16": 0.0003944382769986987, "17": 0.0003760684921871871, "18": 0.00035933361505158246, "19": 0.00034402465098537505}}, {"key": "bunel2018leveraging", "year": "2018", "title": "Leveraging Grammar And Reinforcement Learning For Neural Program Synthesis", "topic_distr": {"0": 0.001125218695960939, "1": 0.046255048364400864, "2": 0.0007756709819659591, "3": 0.6129711270332336, "4": 0.0005925215664319694, "5": 0.0005299666081555188, "6": 0.0004793592670466751, "7": 0.10401071608066559, "8": 0.0004024903755635023, "9": 0.0003726145951077342, "10": 0.0003468675713520497, "11": 0.0652993693947792, "12": 0.0003047518839593977, "13": 0.00028730969643220305, "14": 0.16507290303707123, "15": 0.00025779989664442837, "16": 0.0002452071930747479, "17": 0.0002337874029763043, "18": 0.0002233839622931555, "19": 0.00021386696607805789}}, {"key": "bunk2020lightweight", "year": "2020", "title": "DIET: Lightweight Language Understanding For Dialogue Systems", "topic_distr": {"0": 0.0017085883300751448, "1": 0.0013951858272776008, "2": 0.46330901980400085, "3": 0.0896277129650116, "4": 0.0009009037166833878, "5": 0.08086776733398438, "6": 0.04118327796459198, "7": 0.0006653135060332716, "8": 0.0006119695026427507, "9": 0.0005665447097271681, "10": 0.24906380474567413, "11": 0.0004933105083182454, "12": 0.00046336231753230095, "13": 0.00043684220872819424, "14": 0.00041319351294077933, "15": 0.0003919737646356225, "16": 0.0668809711933136, "17": 0.0003554637951310724, "18": 0.0003396458341740072, "19": 0.00032517564250156283}}, {"key": "burns2022dataset", "year": "2022", "title": "A Dataset For Interactive Vision-language Navigation With Unknown Command Feasibility", "topic_distr": {"0": 0.0009673373424448073, "1": 0.0007894201553426683, "2": 0.0006673691095784307, "3": 0.0005780222127214074, "4": 0.0005097910179756582, "5": 0.5182801485061646, "6": 0.00041242907173000276, "7": 0.00037647850695066154, "8": 0.021217262372374535, "9": 0.0003205885586794466, "10": 0.00029843644006177783, "11": 0.37341365218162537, "12": 0.0002622011234052479, "13": 0.00024719431530684233, "14": 0.00023381230130326003, "15": 0.00022180475934874266, "16": 0.00021097030548844486, "17": 0.00020114499784540385, "18": 0.08060788363218307, "19": 0.00018400594126433134}}, {"key": "burns2022discovering", "year": "2022", "title": "Discovering Latent Knowledge In Language Models Without Supervision", "topic_distr": {"0": 0.3511420786380768, "1": 0.0010288386838510633, "2": 0.19379504024982452, "3": 0.000753226166125387, "4": 0.024326929822564125, "5": 0.0005941778654232621, "6": 0.0005374389002099633, "7": 0.07467813789844513, "8": 0.05274978652596474, "9": 0.00041776098078116775, "10": 0.0003888943756464869, "11": 0.07526028901338577, "12": 0.0003416759427636862, "13": 0.10718736797571182, "14": 0.00030468226759694517, "15": 0.0002890351752284914, "16": 0.06989405304193497, "17": 0.04582034423947334, "18": 0.00025044940412044525, "19": 0.00023977929959073663}}, {"key": "burns2023weak", "year": "2023", "title": "Weak-to-strong Generalization: Eliciting Strong Capabilities With Weak Supervision", "topic_distr": {"0": 0.21192725002765656, "1": 0.0008934758952818811, "2": 0.0007552324677817523, "3": 0.2825300693511963, "4": 0.0005769134731963277, "5": 0.0005160064320079982, "6": 0.0004667321627493948, "7": 0.00042604812188073993, "8": 0.0003918881411664188, "9": 0.00036279932828620076, "10": 0.00033773051109164953, "11": 0.3503578305244446, "12": 0.00029672423261217773, "13": 0.00027974150725640357, "14": 0.0002645975328050554, "15": 0.00025100901257246733, "16": 0.0002387480199104175, "17": 0.0002276290615554899, "18": 0.00021749967709183693, "19": 0.14868208765983582}}, {"key": "busch2023just", "year": "2023", "title": "Just Tell Me: Prompt Engineering In Business Process Management", "topic_distr": {"0": 0.001732416800223291, "1": 0.001414877362549305, "2": 0.0898909866809845, "3": 0.0010357191786170006, "4": 0.0009134612046182156, "5": 0.0008170231594704092, "6": 0.0007390043465420604, "7": 0.051628679037094116, "8": 0.000620499427895993, "9": 0.37690359354019165, "10": 0.0005347484839148819, "11": 0.0005001865210942924, "12": 0.10807636380195618, "13": 0.00044293110840953887, "14": 0.037149425595998764, "15": 0.0534861721098423, "16": 0.0003780237166211009, "17": 0.18012532591819763, "18": 0.00034437995054759085, "19": 0.09326619654893875}}, {"key": "buschek2021impact", "year": "2021", "title": "The Impact Of Multiple Parallel Phrase Suggestions On Email Input And Composition Behaviour Of Native And Non-native English Writers", "topic_distr": {"0": 0.20655681192874908, "1": 0.0013403567718341947, "2": 0.10895437747240067, "3": 0.0009811854688450694, "4": 0.0008653675904497504, "5": 0.000774006824940443, "6": 0.0007000956684350967, "7": 0.05002767592668533, "8": 0.0005878300871700048, "9": 0.3545064628124237, "10": 0.000506593962199986, "11": 0.00047385162906721234, "12": 0.00044508473365567625, "13": 0.09718438982963562, "14": 0.13115806877613068, "15": 0.0003765121800825, "16": 0.00035812074202112854, "17": 0.00034144235542044044, "18": 0.04354944825172424, "19": 0.0003123489150311798}}, {"key": "byrne2019taskmaster", "year": "2019", "title": "Taskmaster-1: Toward A Realistic And Diverse Dialog Dataset", "topic_distr": {"0": 0.0010761944577097893, "1": 0.10840249806642532, "2": 0.25670328736305237, "3": 0.0006429045461118221, "4": 0.18103618919849396, "5": 0.09135995805263519, "6": 0.0663880780339241, "7": 0.0004187361628282815, "8": 0.00038516244967468083, "9": 0.0678166076540947, "10": 0.0003319342795293778, "11": 0.03481195494532585, "12": 0.13860398530960083, "13": 0.017073916271328926, "14": 0.0002600564621388912, "15": 0.0002467011217959225, "16": 0.033799704164266586, "17": 0.00022372242528945208, "18": 0.00021376687800511718, "19": 0.00020465960551518947}}, {"key": "caccia2018language", "year": "2018", "title": "Language Gans Falling Short", "topic_distr": {"0": 0.2503412961959839, "1": 0.05387452617287636, "2": 0.18858151137828827, "3": 0.16284269094467163, "4": 0.0005925188888795674, "5": 0.0005299641634337604, "6": 0.0004793570551555604, "7": 0.20827999711036682, "8": 0.0004024885129183531, "9": 0.00037261287798173726, "10": 0.0003468659706413746, "11": 0.00032444726093672216, "12": 0.00030475048697553575, "13": 0.13128121197223663, "14": 0.00027175480499863625, "15": 0.00025779870338737965, "16": 0.0002452060580253601, "17": 0.0002337863261345774, "18": 0.0002233829436590895, "19": 0.00021386597654782236}}, {"key": "caciularu2021cross", "year": "2021", "title": "CDLM: Cross-document Language Modeling", "topic_distr": {"0": 0.0018890636274591088, "1": 0.0015429655322805047, "2": 0.499047189950943, "3": 0.001129773911088705, "4": 0.0009964152704924345, "5": 0.0008912198827601969, "6": 0.0008061159751378, "7": 0.0007358485599979758, "8": 0.0006768491584807634, "9": 0.0006266084965318441, "10": 0.3657933175563812, "11": 0.0005456102080643177, "12": 0.0005124869639985263, "13": 0.0004831552505493164, "14": 0.0004569993761833757, "15": 0.0004335299599915743, "16": 0.06080928444862366, "17": 0.00039314929745160043, "18": 0.0003756543155759573, "19": 0.061854731291532516}}, {"key": "cadene2019multimodal", "year": "2019", "title": "MUREL: Multimodal Relational Reasoning For Visual Question Answering", "topic_distr": {"0": 0.0013717289548367262, "1": 0.0011192397214472294, "2": 0.14885595440864563, "3": 0.0008194864494726062, "4": 0.0007227524183690548, "5": 0.0006464478792622685, "6": 0.035226158797740936, "7": 0.0005337490001693368, "8": 0.16911612451076508, "9": 0.00045451155165210366, "10": 0.0004231055499985814, "11": 0.00039575929986312985, "12": 0.00037173330201767385, "13": 0.00035045749973505735, "14": 0.0003314852947369218, "15": 0.08316598832607269, "16": 0.07410924881696701, "17": 0.00028517149621620774, "18": 0.4814400374889374, "19": 0.0002608727663755417}}, {"key": "caffagni2024revolution", "year": "2024", "title": "The Revolution Of Multimodal Large Language Models: A Survey", "topic_distr": {"0": 0.10065369307994843, "1": 0.001119482796639204, "2": 0.0009462151792831719, "3": 0.019434990361332893, "4": 0.000722811440937221, "5": 0.035220783203840256, "6": 0.0005847654538229108, "7": 0.01931557059288025, "8": 0.0004909939016215503, "9": 0.00045454874634742737, "10": 0.0004231401835568249, "11": 0.0003957916924264282, "12": 0.4450155794620514, "13": 0.00035048616700805724, "14": 0.00033151241950690746, "15": 0.027612656354904175, "16": 0.0002991257351823151, "17": 0.0002851948665920645, "18": 0.34608179330825806, "19": 0.00026089412858709693}}, {"key": "caglayan2016multimodal", "year": "2016", "title": "Multimodal Attention For Neural Machine Translation", "topic_distr": {"0": 0.0018925536423921585, "1": 0.0015428740298375487, "2": 0.384115993976593, "3": 0.0011298001045361161, "4": 0.000996437156572938, "5": 0.08168531954288483, "6": 0.0008061342523433268, "7": 0.000735865265596658, "8": 0.0006768645253032446, "9": 0.000626622699201107, "10": 0.0005833241157233715, "11": 0.0005456226062960923, "12": 0.0005124985473230481, "13": 0.00048316619358956814, "14": 0.23057399690151215, "15": 0.00043353979708626866, "16": 0.00041236274410039186, "17": 0.0003931582032237202, "18": 0.2914941608905792, "19": 0.00035965818096883595}}, {"key": "caglayan2017lium", "year": "2017", "title": "LIUM-CVC Submissions For WMT17 Multimodal Translation Task", "topic_distr": {"0": 0.003117774846032262, "1": 0.0025456224102526903, "2": 0.002152340952306986, "3": 0.0018641626229509711, "4": 0.16589482128620148, "5": 0.0014705468202009797, "6": 0.10263053327798843, "7": 0.0012141780462116003, "8": 0.0011168267810717225, "9": 0.0010339277796447277, "10": 0.0009624850936233997, "11": 0.0009002775768749416, "12": 0.0008456229115836322, "13": 0.0007972244638949633, "14": 0.24126219749450684, "15": 0.0007153408951126039, "16": 0.0006803987780585885, "17": 0.0006487112259492278, "18": 0.4695535898208618, "19": 0.0005934361834079027}}, {"key": "caglayan2019probing", "year": "2019", "title": "Probing The Need For Visual Context In Multimodal Machine Translation", "topic_distr": {"0": 0.10126090049743652, "1": 0.07053342461585999, "2": 0.0011330111883580685, "3": 0.0009813286596909165, "4": 0.0008654856937937438, "5": 0.0007741122390143573, "6": 0.09927933663129807, "7": 0.0006391569622792304, "8": 0.0005879101809114218, "9": 0.0005442711990326643, "10": 0.0005066629964858294, "11": 0.00047391621046699584, "12": 0.0004451453860383481, "13": 0.00041966792196035385, "14": 0.20655769109725952, "15": 0.00037656346103176475, "16": 0.0003581695491448045, "17": 0.00034148889244534075, "18": 0.4924086332321167, "19": 0.021513165906071663}}, {"key": "cahyawijaya2021benchmark", "year": "2021", "title": "Indonlg: Benchmark And Resources For Evaluating Indonesian Natural Language Generation", "topic_distr": {"0": 0.10476233065128326, "1": 0.001072289189323783, "2": 0.07927434146404266, "3": 0.0007850276306271553, "4": 0.0006923595210537314, "5": 0.000619264435954392, "6": 0.048819150775671005, "7": 0.0005113045917823911, "8": 0.05151897296309471, "9": 0.00043539906619116664, "10": 0.00040531373815611005, "11": 0.0003791174094658345, "12": 0.23602890968322754, "13": 0.08362894505262375, "14": 0.2197866588830948, "15": 0.09344311058521271, "16": 0.0002865238639060408, "17": 0.0002731798740569502, "18": 0.0002610234951134771, "19": 0.07701674848794937}}, {"key": "cai2018skeleton", "year": "2018", "title": "Skeleton-to-response: Dialogue Generation Guided By Retrieval Memory", "topic_distr": {"0": 0.0012861742870882154, "1": 0.0010501033393666148, "2": 0.211478590965271, "3": 0.0007687549223192036, "4": 0.0006780093535780907, "5": 0.0006064289482310414, "6": 0.31938159465789795, "7": 0.14814938604831696, "8": 0.11099521815776825, "9": 0.0004263744631316513, "10": 0.0003969126846641302, "11": 0.00037125934613868594, "12": 0.0003487206995487213, "13": 0.0003287619911134243, "14": 0.0003109642711933702, "15": 0.13067913055419922, "16": 0.07197573035955429, "17": 0.00026751760742627084, "18": 0.00025561320944689214, "19": 0.00024472310906276107}}, {"key": "cai2019graph", "year": "2019", "title": "Graph Transformer For Graph-to-sequence Learning", "topic_distr": {"0": 0.001685321913100779, "1": 0.0013760457513853908, "2": 0.12169620394706726, "3": 0.001007638406008482, "4": 0.0008887004223652184, "5": 0.0007948771235533059, "6": 0.0007189731695689261, "7": 0.0713876336812973, "8": 0.0006036803824827075, "9": 0.06068938970565796, "10": 0.15637058019638062, "11": 0.00048662861809134483, "12": 0.00045708604739047587, "13": 0.0004309251671656966, "14": 0.2382499724626541, "15": 0.0003866644692607224, "16": 0.3417631685733795, "17": 0.0003506490320432931, "18": 0.0003350453043822199, "19": 0.00032077112700790167}}, {"key": "cai2020data", "year": "2020", "title": "Data Manipulation: Towards Effective Instance Learning For Neural Dialogue Generation Via Learning To Augment And Reweight", "topic_distr": {"0": 0.17035605013370514, "1": 0.2679773271083832, "2": 0.08719019591808319, "3": 0.000582613458391279, "4": 0.0650816559791565, "5": 0.058246031403541565, "6": 0.20190604031085968, "7": 0.00037946878001093864, "8": 0.0003490434610284865, "9": 0.0003231349110137671, "10": 0.00030080683063715696, "11": 0.06096545234322548, "12": 0.0002642837353050709, "13": 0.0569232702255249, "14": 0.00023566940217278898, "15": 0.00022356650151778013, "16": 0.028113435953855515, "17": 0.00020274263806641102, "18": 0.00019372068345546722, "19": 0.00018546744831837714}}, {"key": "cai2020database", "year": "2020", "title": "IGSQL: Database Schema Interaction Graph Based Neural Model For Context-dependent Text-to-sql Generation", "topic_distr": {"0": 0.001918560592457652, "1": 0.0015668015694245696, "2": 0.27942612767219543, "3": 0.0011471471516415477, "4": 0.15063901245594025, "5": 0.0009049195214174688, "6": 0.0008185073966160417, "7": 0.07000880688428879, "8": 0.0006872535450384021, "9": 0.000636240525636822, "10": 0.09197846800088882, "11": 0.0005539971753023565, "12": 0.000520364788826555, "13": 0.0004905821988359094, "14": 0.0004640242550522089, "15": 0.0004401940677780658, "16": 0.3966531455516815, "17": 0.00039919267874211073, "18": 0.0003814287774730474, "19": 0.00036517847911454737}}, {"key": "cai2021neural", "year": "2021", "title": "Neural Machine Translation With Monolingual Translation Memory", "topic_distr": {"0": 0.0015390155604109168, "1": 0.0012572581181302667, "2": 0.1856524497270584, "3": 0.0009205900714732707, "4": 0.0008119228295981884, "5": 0.000726204423699528, "6": 0.0006568579701706767, "7": 0.0005996010731905699, "8": 0.07981812953948975, "9": 0.0005105875316075981, "10": 0.00047530679148621857, "11": 0.0004445866507012397, "12": 0.0004175963986199349, "13": 0.0003936956636607647, "14": 0.4487268328666687, "15": 0.0003532588598318398, "16": 0.27577653527259827, "17": 0.0003203549422323704, "18": 0.0003060993039980531, "19": 0.00029305831412784755}}, {"key": "cai2023do", "year": "2023", "title": "Do Large Language Models Resemble Humans In Language Use?", "topic_distr": {"0": 0.2651219367980957, "1": 0.0598720945417881, "2": 0.33209356665611267, "3": 0.0007036193273961544, "4": 0.0006205607787705958, "5": 0.012256135232746601, "6": 0.000502042646985501, "7": 0.00045828064321540296, "8": 0.0004215363005641848, "9": 0.24533893167972565, "10": 0.0003632814041338861, "11": 0.00033980171428993344, "12": 0.00031917280284687877, "13": 0.00030090525979176164, "14": 0.00028461558395065367, "15": 0.0002699990291148424, "16": 0.08003075420856476, "17": 0.00024485026369802654, "18": 0.00023395453172270209, "19": 0.00022398718283511698}}, {"key": "caines2023application", "year": "2023", "title": "On The Application Of Large Language Models For Language Teaching And Assessment Technology", "topic_distr": {"0": 0.24458806216716766, "1": 0.0007544822874478996, "2": 0.07247179001569748, "3": 0.13461937010288239, "4": 0.000487183133373037, "5": 0.00043574912706390023, "6": 0.0003941387985832989, "7": 0.09990023821592331, "8": 0.00033093566889874637, "9": 0.39753130078315735, "10": 0.0002852014731615782, "11": 0.0002667682711035013, "12": 0.0002505731245037168, "13": 0.046495385468006134, "14": 0.00022344326134771109, "15": 0.00021196823217906058, "16": 0.000201614253455773, "17": 0.0001922246883623302, "18": 0.00018367076700087637, "19": 0.00017584570741746575}}, {"key": "calixto2017incorporating", "year": "2017", "title": "Incorporating Global Visual Features Into Attention-based Neural Machine Translation", "topic_distr": {"0": 0.04936744272708893, "1": 0.06993884593248367, "2": 0.4541518986225128, "3": 0.0007767239003442228, "4": 0.0006850413628853858, "5": 0.0006127179367467761, "6": 0.0005542085273191333, "7": 0.0005058993701823056, "8": 0.0004653369833249599, "9": 0.0004307962954044342, "10": 0.00040102898492477834, "11": 0.00037510960828512907, "12": 0.00035233719972893596, "13": 0.00033217150485143065, "14": 0.2518022358417511, "15": 0.0002980538993142545, "16": 0.03851088136434555, "17": 0.0002702919882722199, "18": 0.12992170453071594, "19": 0.0002472610794939101}}, {"key": "cao2020behind", "year": "2020", "title": "Behind The Scene: Revealing The Secrets Of Pre-trained Vision-and-language Models", "topic_distr": {"0": 0.08400462567806244, "1": 0.000856087077409029, "2": 0.2775183916091919, "3": 0.0006267221760936081, "4": 0.0005527447792701423, "5": 0.0004943886888213456, "6": 0.00044717866694554687, "7": 0.00040819906280376017, "8": 0.00037547017564065754, "9": 0.0003476000565569848, "10": 0.00032358148018829525, "11": 0.0003026676713488996, "12": 0.05925409868359566, "13": 0.00026802188949659467, "14": 0.0002535123785492033, "15": 0.00024049312924034894, "16": 0.06425885111093521, "17": 0.00021809266763739288, "18": 0.31149277091026306, "19": 0.19775651395320892}}, {"key": "cao2020decomposing", "year": "2020", "title": "Deformer: Decomposing Pre-trained Transformers For Faster Question Answering", "topic_distr": {"0": 0.0018889508210122585, "1": 0.00154295249376446, "2": 0.001304388395510614, "3": 0.0011297560995444655, "4": 0.0009964004857465625, "5": 0.0008912073099054396, "6": 0.0008061045082286, "7": 0.0007358380826190114, "8": 0.18994849920272827, "9": 0.0006265995907597244, "10": 0.5957035422325134, "11": 0.0005456024664454162, "12": 0.0005124796880409122, "13": 0.20093630254268646, "14": 0.00045699288602918386, "15": 0.00043352378997951746, "16": 0.00041234755190089345, "17": 0.00039314370951615274, "18": 0.0003756489895749837, "19": 0.0003596449096221477}}, {"key": "cao2022model", "year": "2022", "title": "A Model-agnostic Data Manipulation Method For Persona-based Dialogue Generation", "topic_distr": {"0": 0.16270047426223755, "1": 0.1640951782464981, "2": 0.31559160351753235, "3": 0.0007688268087804317, "4": 0.0006780721014365554, "5": 0.12051224708557129, "6": 0.0005485708825290203, "7": 0.000500753172673285, "8": 0.0004606034199241549, "9": 0.0004264140734449029, "10": 0.0003969495592173189, "11": 0.04971059411764145, "12": 0.00034875309211201966, "13": 0.00032879255013540387, "14": 0.00031099317129701376, "15": 0.13340607285499573, "16": 0.048447154462337494, "17": 0.0002675424620974809, "18": 0.00025563695817254484, "19": 0.00024474586825817823}}, {"key": "cao2023assessing", "year": "2023", "title": "Assessing Cross-cultural Alignment Between Chatgpt And Human Societies: An Empirical Study", "topic_distr": {"0": 0.3929130733013153, "1": 0.0012731107417494059, "2": 0.0010761292651295662, "3": 0.0009320859098806977, "4": 0.0008220607996918261, "5": 0.0007352729444392025, "6": 0.1827024519443512, "7": 0.0006070884992368519, "8": 0.000558412924874574, "9": 0.2238512933254242, "10": 0.0004812421393580735, "11": 0.0004501383809838444, "12": 0.07507426291704178, "13": 0.0003986119118053466, "14": 0.03364662453532219, "15": 0.00035767012741416693, "16": 0.0003401990979909897, "17": 0.08317366987466812, "18": 0.00030992168467491865, "19": 0.00029671782976947725}}, {"key": "cao2023comprehensive", "year": "2023", "title": "A Comprehensive Survey Of Ai-generated Content (AIGC): A History Of Generative AI From GAN To Chatgpt", "topic_distr": {"0": 0.09199405461549759, "1": 0.0008083630818873644, "2": 0.0006832940271124244, "3": 0.0005918163806200027, "4": 0.000521958339959383, "5": 0.0004668530309572816, "6": 0.10942381620407104, "7": 0.0003854638780467212, "8": 0.00035455788020044565, "9": 0.24001054465770721, "10": 0.00030555916600860655, "11": 0.0002858102088794112, "12": 0.2982369065284729, "13": 0.05305681377649307, "14": 0.00023939266975503415, "15": 0.08629413694143295, "16": 0.00021600550098810345, "17": 0.00020594570378307253, "18": 0.11573030054569244, "19": 0.00018839759286493063}}, {"key": "cao2023pro", "year": "2023", "title": "Pro-cap: Leveraging A Frozen Vision-language Model For Hateful Meme Detection", "topic_distr": {"0": 0.0016428702510893345, "1": 0.001340067945420742, "2": 0.16406205296516418, "3": 0.0009811873314902186, "4": 0.0008653644472360611, "5": 0.0007740042055957019, "6": 0.0007000933983363211, "7": 0.0006390677881427109, "8": 0.08064014464616776, "9": 0.0528557151556015, "10": 0.0005065922741778195, "11": 0.00047385008656419814, "12": 0.0004450832784641534, "13": 0.0004196093650534749, "14": 0.00039689356344752014, "15": 0.00037651092861779034, "16": 0.0003581195487640798, "17": 0.1747141033411026, "18": 0.5174963474273682, "19": 0.00031234786729328334}}, {"key": "cao2023prompting", "year": "2023", "title": "Prompting For Multimodal Hateful Meme Classification", "topic_distr": {"0": 0.0015028154011815786, "1": 0.0012269754661247134, "2": 0.0010371898533776402, "3": 0.0008983445004560053, "4": 0.0007923007942736149, "5": 0.0007086551049724221, "6": 0.0006409845082089305, "7": 0.0005851112655363977, "8": 0.0005381978116929531, "9": 0.000498248846270144, "10": 0.13329097628593445, "11": 0.00043384291348047554, "12": 0.00040750487823970616, "13": 0.0003841817378997803, "14": 0.0003633838496170938, "15": 0.0003447220951784402, "16": 0.3212624490261078, "17": 0.46157971024513245, "18": 0.0732184574007988, "19": 0.00028597633354365826}}, {"key": "cao2024survey", "year": "2024", "title": "Survey On Large Language Model-enhanced Reinforcement Learning: Concept, Taxonomy, And Methods", "topic_distr": {"0": 0.01977706328034401, "1": 0.02357138693332672, "2": 0.0008279141620732844, "3": 0.0642121210694313, "4": 0.050877317786216736, "5": 0.000565679743885994, "6": 0.0005116621614433825, "7": 0.00046706164721399546, "8": 0.00042961325380019844, "9": 0.2782553732395172, "10": 0.00037024213816039264, "11": 0.22351579368114471, "12": 0.2657886743545532, "13": 0.01630435511469841, "14": 0.000290069030597806, "15": 0.00027517240960150957, "16": 0.0532442182302475, "17": 0.00024954177206382155, "18": 0.00023843727831263095, "19": 0.00022827895008958876}}, {"key": "caramancion2023news", "year": "2023", "title": "News Verifiers Showdown: A Comparative Performance Evaluation Of Chatgpt 3.5, Chatgpt 4.0, Bing AI, And Bard In News Fact-checking", "topic_distr": {"0": 0.21917681396007538, "1": 0.10500563681125641, "2": 0.0009160996996797621, "3": 0.28720077872276306, "4": 0.029902217909693718, "5": 0.0006259260699152946, "6": 0.0005661554750986397, "7": 0.0005168049247004092, "8": 0.0004753681714646518, "9": 0.2307261973619461, "10": 0.0004096738703083247, "11": 0.00038319575833156705, "12": 0.0003599324554670602, "13": 0.00033933206577785313, "14": 0.0003209621354471892, "15": 0.12199274450540543, "16": 0.00028960613417439163, "17": 0.00027611860423348844, "18": 0.00026383146177977324, "19": 0.00025259124231524765}}, {"key": "carlini2022quantifying", "year": "2022", "title": "Quantifying Memorization Across Neural Language Models", "topic_distr": {"0": 0.2497386932373047, "1": 0.36612141132354736, "2": 0.07904062420129776, "3": 0.0010966543341055512, "4": 0.0009672046289779246, "5": 0.0008650905219838023, "6": 0.0007824815693311393, "7": 0.0007142743561416864, "8": 0.0006570047698915005, "9": 0.06292855739593506, "10": 0.0005662089097313583, "11": 0.0005296135786920786, "12": 0.0004974614130333066, "13": 0.06493901461362839, "14": 0.0004436006711330265, "15": 0.0004208193568047136, "16": 0.00040026367059908807, "17": 0.04761974513530731, "18": 0.000364640582120046, "19": 0.12130661308765411}}, {"key": "carlini2023are", "year": "2023", "title": "Are Aligned Neural Networks Adversarially Aligned?", "topic_distr": {"0": 0.15146568417549133, "1": 0.6399469971656799, "2": 0.000827845127787441, "3": 0.0007170162862166762, "4": 0.06237221136689186, "5": 0.0005656182183884084, "6": 0.0005116062238812447, "7": 0.00046701059909537435, "8": 0.018556570634245872, "9": 0.0003976807347498834, "10": 0.0003702016547322273, "11": 0.0003462746972218156, "12": 0.0003252528258599341, "13": 0.011201627552509308, "14": 0.0002900373365264386, "15": 0.0002751423162408173, "16": 0.0002617024874780327, "17": 0.0002495145017746836, "18": 0.11062372475862503, "19": 0.0002282539935549721}}, {"key": "carrino2019automatic", "year": "2019", "title": "Automatic Spanish Translation Of The Squad Dataset For Multilingual Question Answering", "topic_distr": {"0": 0.0014507375890389085, "1": 0.0011842233361676335, "2": 0.2740750312805176, "3": 0.0008670735987834632, "4": 0.0007647249149158597, "5": 0.0006839892012067139, "6": 0.0006186739774420857, "7": 0.0005647454527206719, "8": 0.29770466685295105, "9": 0.00048090642667375505, "10": 0.0478624626994133, "11": 0.00041874227463267744, "12": 0.07817884534597397, "13": 0.0003708096337504685, "14": 0.23725295066833496, "15": 0.0563388355076313, "16": 0.00031647097785025835, "17": 0.00030173230334185064, "18": 0.0002883053384721279, "19": 0.0002760224451776594}}, {"key": "carta2023grounding", "year": "2023", "title": "Grounding Large Language Models In Interactive Environments With Online Reinforcement Learning", "topic_distr": {"0": 0.0013131260639056563, "1": 0.001072143786586821, "2": 0.000906250614207238, "3": 0.18028941750526428, "4": 0.0006922628963366151, "5": 0.00061917764833197, "6": 0.0005600514123216271, "7": 0.0005112329381518066, "8": 0.021517282351851463, "9": 0.14698269963264465, "10": 0.00040525695658288896, "11": 0.3938318192958832, "12": 0.00035605180892162025, "13": 0.09805216640233994, "14": 0.0003175016609020531, "15": 0.0003011962107848376, "16": 0.05821404978632927, "17": 0.0002731416025198996, "18": 0.09353534877300262, "19": 0.0002498679095879197}}, {"key": "casanueva2020efficient", "year": "2020", "title": "Efficient Intent Detection With Dual Sentence Encoders", "topic_distr": {"0": 0.001466702320612967, "1": 0.4704121947288513, "2": 0.2199293076992035, "3": 0.000877313083037734, "4": 0.0007737564737908542, "5": 0.047621529549360275, "6": 0.09327484667301178, "7": 0.0005714154103770852, "8": 0.0005256000440567732, "9": 0.0004865861847065389, "10": 0.1609758883714676, "11": 0.0004236878303345293, "12": 0.00039796633063815534, "13": 0.0003751890908461064, "14": 0.0003548780223354697, "15": 0.0003366531163919717, "16": 0.00032020866638049483, "17": 0.0003052959218621254, "18": 0.0002917103993240744, "19": 0.00027928242343477905}}, {"key": "cascantebonilla2023going", "year": "2023", "title": "Going Beyond Nouns With Vision & Language Models Using Synthetic Data", "topic_distr": {"0": 0.04840489849448204, "1": 0.23917590081691742, "2": 0.14932754635810852, "3": 0.12142466008663177, "4": 0.000620484643150121, "5": 0.0005549778579734266, "6": 0.000501982111018151, "7": 0.06324716657400131, "8": 0.00042148548527620733, "9": 0.00039019976975396276, "10": 0.0003632376028690487, "11": 0.051770228892564774, "12": 0.08337794989347458, "13": 0.00030086899641901255, "14": 0.0002845812705345452, "15": 0.00026996646192856133, "16": 0.00025677948724478483, "17": 0.06147299334406853, "18": 0.1330776959657669, "19": 0.044756412506103516}}, {"key": "castellon2021codified", "year": "2021", "title": "Codified Audio Language Modeling Learns Useful Representations For Music Information Retrieval", "topic_distr": {"0": 0.0016438537277281284, "1": 0.0013402991462498903, "2": 0.38091060519218445, "3": 0.0009812416974455118, "4": 0.0008654179982841015, "5": 0.000774052576161921, "6": 0.0007001365884207189, "7": 0.0006391071947291493, "8": 0.07259541004896164, "9": 0.024941815063357353, "10": 0.2551564574241638, "11": 0.00047387927770614624, "12": 0.0004451107233762741, "13": 0.0004196352092549205, "14": 0.00039691803976893425, "15": 0.00037653412437066436, "16": 0.00035814163857139647, "17": 0.00034146226244047284, "18": 0.2563275396823883, "19": 0.0003123671340290457}}, {"key": "cer2018universal", "year": "2018", "title": "Universal Sentence Encoder", "topic_distr": {"0": 0.06962790340185165, "1": 0.0011191890807822347, "2": 0.3388619124889374, "3": 0.0008194167749024928, "4": 0.0007226918241940439, "5": 0.0006463942700065672, "6": 0.0005846689455211163, "7": 0.0005337046459317207, "8": 0.0004909129347652197, "9": 0.0004544737748801708, "10": 0.2729422152042389, "11": 0.00039572641253471375, "12": 0.0003717023937497288, "13": 0.00035042836680077016, "14": 0.3106466829776764, "15": 0.0003144355723634362, "16": 0.00029907640418969095, "17": 0.00028514780569821596, "18": 0.0002724588557612151, "19": 0.0002608510840218514}}, {"key": "cha2023locality", "year": "2023", "title": "Honeybee: Locality-enhanced Projector For Multimodal LLM", "topic_distr": {"0": 0.2418431043624878, "1": 0.001072022132575512, "2": 0.0009062999160960317, "3": 0.17173334956169128, "4": 0.0006922997999936342, "5": 0.0006192110595293343, "6": 0.0005600816803053021, "7": 0.0005112605285830796, "8": 0.00047026833635754883, "9": 0.00043536158045753837, "10": 0.00040527881355956197, "11": 0.00037908475496806204, "12": 0.0003560710174497217, "13": 0.11000733077526093, "14": 0.00031751880305819213, "15": 0.0003012124798260629, "16": 0.0002864991838578135, "17": 0.00027315635816194117, "18": 0.4685807228088379, "19": 0.0002498813846614212}}, {"key": "chaaben2022towards", "year": "2022", "title": "Towards Using Few-shot Prompt Learning For Automating Model Completion", "topic_distr": {"0": 0.002835744060575962, "1": 0.002315466059371829, "2": 0.2802272140979767, "3": 0.001694808597676456, "4": 0.1361962854862213, "5": 0.0013369404477998614, "6": 0.0012092739343643188, "7": 0.001103864167816937, "8": 0.0010153576731681824, "9": 0.0009399904520250857, "10": 0.0008750386768952012, "11": 0.0008184830076061189, "12": 0.043228499591350555, "13": 0.0007247928297147155, "14": 0.0006855557439848781, "15": 0.0006503487238660455, "16": 0.26440900564193726, "17": 0.25863033533096313, "18": 0.0005635280977003276, "19": 0.000539519649464637}}, {"key": "chada2021simple", "year": "2021", "title": "Fewshotqa: A Simple Framework For Few-shot Learning Of Question Answering Tasks Using Pre-trained Text-to-text Models", "topic_distr": {"0": 0.0012229966232553124, "1": 0.11702071875333786, "2": 0.4753912389278412, "3": 0.0007310892106033862, "4": 0.000644790765363723, "5": 0.0005767173715867102, "6": 0.0005216458230279386, "7": 0.00047617501695640385, "8": 0.10098893940448761, "9": 0.00040548466495238245, "10": 0.0391724556684494, "11": 0.00035306985955685377, "12": 0.00033163547050207853, "13": 0.033604323863983154, "14": 0.0899648666381836, "15": 0.00028054160065948963, "16": 0.0002668380329851061, "17": 0.13757069408893585, "18": 0.00024308970023412257, "19": 0.0002327331603737548}}, {"key": "chakrabarty2022help", "year": "2022", "title": "Help Me Write A Poem: Instruction Tuning As A Vehicle For Collaborative Poetry Writing", "topic_distr": {"0": 0.0014843626413494349, "1": 0.0012125049252063036, "2": 0.0010249068727716804, "3": 0.3803500533103943, "4": 0.158635675907135, "5": 0.0007002649363130331, "6": 0.0006333954515866935, "7": 0.1687171459197998, "8": 0.000531825702637434, "9": 0.14777930080890656, "10": 0.00045832915930077434, "11": 0.1357795000076294, "12": 0.0004026801325380802, "13": 0.0003796331293415278, "14": 0.00035908148856833577, "15": 0.0003406406904105097, "16": 0.00032400147756561637, "17": 0.00030891207279637456, "18": 0.00029516563517972827, "19": 0.00028259048121981323}}, {"key": "chakrabarty2023art", "year": "2023", "title": "Art Or Artifice? Large Language Models And The False Promise Of Creativity", "topic_distr": {"0": 0.28347283601760864, "1": 0.028109537437558174, "2": 0.0012127426452934742, "3": 0.3458426594734192, "4": 0.0009263887768611312, "5": 0.0008285854710265994, "6": 0.000749462575186044, "7": 0.15523098409175873, "8": 0.0006292806356213987, "9": 0.1787617951631546, "10": 0.0005423161201179028, "11": 0.0005072650383226573, "12": 0.0004764696641359478, "13": 0.00044919937499798834, "14": 0.0004248817276675254, "15": 0.0004030617419630289, "16": 0.0003833734372165054, "17": 0.00036551899393089116, "18": 0.00034925356158055365, "19": 0.00033437402453273535}}, {"key": "chakraborty2023possibilities", "year": "2023", "title": "On The Possibilities Of Ai-generated Text Detection", "topic_distr": {"0": 0.18047550320625305, "1": 0.10456721484661102, "2": 0.05500412359833717, "3": 0.1965169608592987, "4": 0.0007924336823634803, "5": 0.0007087726844474673, "6": 0.0006410907371900976, "7": 0.08624116331338882, "8": 0.0005382869858294725, "9": 0.0004983314429409802, "10": 0.03106137178838253, "11": 0.00043391482904553413, "12": 0.1697133630514145, "13": 0.0003842454170808196, "14": 0.00036344409454613924, "15": 0.17083442211151123, "16": 0.00032793788705021143, "17": 0.00031266515725292265, "18": 0.00029875169275328517, "19": 0.0002860237436834723}}, {"key": "chalmers2023could", "year": "2023", "title": "Could A Large Language Model Be Conscious?", "topic_distr": {"0": 0.0975584089756012, "1": 0.0027533182874321938, "2": 0.2600775957107544, "3": 0.2727750241756439, "4": 0.0017776770982891321, "5": 0.0015899994177743793, "6": 0.0014381678774952888, "7": 0.0013128059217706323, "8": 0.0012075467966496944, "9": 0.35138142108917236, "10": 0.0010406678775325418, "11": 0.0009734071791172028, "12": 0.0009143129573203623, "13": 0.0008619831060059369, "14": 0.0008153191884048283, "15": 0.0007734480896033347, "16": 0.0007356675923801959, "17": 0.0007014060975052416, "18": 0.0006701938691549003, "19": 0.0006416410906240344}}, {"key": "chalvatzaki2023learning", "year": "2023", "title": "Learning To Reason Over Scene Graphs: A Case Study Of Finetuning GPT-2 Into A Robot Language Model For Grounded Task Planning", "topic_distr": {"0": 0.14975506067276, "1": 0.0013951071305200458, "2": 0.0011794136371463537, "3": 0.36298123002052307, "4": 0.0009009592467918992, "5": 0.0008058416424319148, "6": 0.0007288905326277018, "7": 0.0006653547170571983, "8": 0.0006120073958300054, "9": 0.13199450075626373, "10": 0.0005274300347082317, "11": 0.20208534598350525, "12": 0.00046339098480530083, "13": 0.00043686924618668854, "14": 0.0004132190952077508, "15": 0.0003919980372302234, "16": 0.1436430960893631, "17": 0.0003554857976268977, "18": 0.00033966684713959694, "19": 0.00032519575324840844}}, {"key": "chan2020self", "year": "2020", "title": "Cocon: A Self-supervised Approach For Controlled Text Generation", "topic_distr": {"0": 0.0019183445256203413, "1": 0.0015667857369408011, "2": 0.05310177057981491, "3": 0.13803483545780182, "4": 0.0010118242353200912, "5": 0.0009050028747878969, "6": 0.0008185827173292637, "7": 0.6061696410179138, "8": 0.0006873167585581541, "9": 0.0006362990825437009, "10": 0.07665698975324631, "11": 0.0005540481652133167, "12": 0.0005204126355238259, "13": 0.0004906273097731173, "14": 0.00046406695037148893, "15": 0.0004402345803100616, "16": 0.0004187305166851729, "17": 0.00039922940777614713, "18": 0.00038146390579640865, "19": 0.11482375860214233}}, {"key": "chan2022data", "year": "2022", "title": "Data Distributional Properties Drive Emergent In-context Learning In Transformers", "topic_distr": {"0": 0.3073030710220337, "1": 0.2555164098739624, "2": 0.2430063784122467, "3": 0.0006112041301093996, "4": 0.04145902395248413, "5": 0.0004821464535780251, "6": 0.0004361054743640125, "7": 0.0003980911278631538, "8": 0.00036617269506677985, "9": 0.00033899268601089716, "10": 0.042488664388656616, "11": 0.10573974996805191, "12": 0.00027725339168682694, "13": 0.0002613850519992411, "14": 0.0002472348278388381, "15": 0.00023453797621186823, "16": 0.00022308154439087957, "17": 0.00021269218996167183, "18": 0.00020322749332990497, "19": 0.00019456923473626375}}, {"key": "chan2023chatgpt", "year": "2023", "title": "Chatgpt Evaluation On Sentence Level Relations: A Focus On Temporal, Causal, And Discourse Relations", "topic_distr": {"0": 0.05733349919319153, "1": 0.0008856421336531639, "2": 0.06266177445650101, "3": 0.14948707818984985, "4": 0.000571924785617739, "5": 0.029700901359319687, "6": 0.00046269610174931586, "7": 0.000422363867983222, "8": 0.00038849926204420626, "9": 0.281350314617157, "10": 0.00033480997080914676, "11": 0.00031317045795731246, "12": 0.0002941582933999598, "13": 0.0002773224259726703, "14": 0.0002623094478622079, "15": 0.00024883841979317367, "16": 0.03330717235803604, "17": 0.3812755048274994, "18": 0.00021561884204857051, "19": 0.00020643265452235937}}, {"key": "chan2023towards", "year": "2023", "title": "Chateval: Towards Better Llm-based Evaluators Through Multi-agent Debate", "topic_distr": {"0": 0.24916015565395355, "1": 0.0010835553985089064, "2": 0.0009158782777376473, "3": 0.5246503353118896, "4": 0.0006996408919803798, "5": 0.0006257765926420689, "6": 0.0005660203169099987, "7": 0.06808589398860931, "8": 0.0004752546374220401, "9": 0.00043997776811011136, "10": 0.0004095760523341596, "11": 0.014737908728420734, "12": 0.1014748066663742, "13": 0.03496802970767021, "14": 0.0003208854759577662, "15": 0.0003044062468688935, "16": 0.00028953698347322643, "17": 0.0002760526549536735, "18": 0.0002637684519868344, "19": 0.00025253091007471085}}, {"key": "chandel2022training", "year": "2022", "title": "Training And Evaluating A Jupyter Notebook Data Science Assistant", "topic_distr": {"0": 0.0017584976740181446, "1": 0.17844432592391968, "2": 0.0012126126093789935, "3": 0.38055670261383057, "4": 0.0009262984967790544, "5": 0.0008285053772851825, "6": 0.14475058019161224, "7": 0.0006840673158876598, "8": 0.0006292196922004223, "9": 0.09846992790699005, "10": 0.05376711115241051, "11": 0.0005072159110568464, "12": 0.13475556671619415, "13": 0.000449155893875286, "14": 0.0004248405748512596, "15": 0.00040302268462255597, "16": 0.00038333632983267307, "17": 0.0003654835745692253, "18": 0.0003492197429295629, "19": 0.00033434166107326746}}, {"key": "chang2021multihop", "year": "2021", "title": "Webqa: Multihop And Multimodal QA", "topic_distr": {"0": 0.13248836994171143, "1": 0.0011707418598234653, "2": 0.0009896329138427973, "3": 0.000857154605910182, "4": 0.0007559747318737209, "5": 0.0006761636468581855, "6": 0.027654653415083885, "7": 0.03278873488306999, "8": 0.16477812826633453, "9": 0.0004754044348374009, "10": 0.0004425547958817333, "11": 0.0004139514931011945, "12": 0.0003888210339937359, "13": 0.05075893923640251, "14": 0.00034672292531467974, "15": 0.00032891679438762367, "16": 0.17926658689975739, "17": 0.0002982802106998861, "18": 0.4048473834991455, "19": 0.00027286450495012105}}, {"key": "chang2022exploration", "year": "2022", "title": "Speechprompt: An Exploration Of Prompt Tuning On Generative Spoken Language Model For Speech Processing Tasks", "topic_distr": {"0": 0.0010664052097126842, "1": 0.0008706089574843645, "2": 0.0007358407019637525, "3": 0.0006373291835188866, "4": 0.0005620967131108046, "5": 0.0005027540028095245, "6": 0.049855101853609085, "7": 0.0004151060711592436, "8": 0.00038182339631021023, "9": 0.00035348167875781655, "10": 0.03423560410737991, "11": 0.0003077890432905406, "12": 0.09749945998191833, "13": 0.16724197566509247, "14": 0.00025780199212022126, "15": 0.037984978407621384, "16": 0.07553590089082718, "17": 0.5056890845298767, "18": 0.0002119137061526999, "19": 0.025654995813965797}}, {"key": "chang2023archaeology", "year": "2023", "title": "Speak, Memory: An Archaeology Of Books Known To Chatgpt/gpt-4", "topic_distr": {"0": 0.40391772985458374, "1": 0.23620885610580444, "2": 0.0019566179253160954, "3": 0.0016946851974353194, "4": 0.0014946450246497989, "5": 0.001336849294602871, "6": 0.0012091913959011436, "7": 0.001103788847103715, "8": 0.05961516126990318, "9": 0.05414292961359024, "10": 0.0008749790722504258, "11": 0.0008184272446669638, "12": 0.0007687415927648544, "13": 0.044289425015449524, "14": 0.0006855090032331645, "15": 0.0006503043696284294, "16": 0.0006185391102917492, "17": 0.0005897324881516397, "18": 0.0005634896806441247, "19": 0.18746039271354675}}, {"key": "chang2023how", "year": "2023", "title": "Chipgpt: How Far Are We From Natural Language Hardware Design", "topic_distr": {"0": 0.0011764676310122013, "1": 0.0009607507381588221, "2": 0.0008122115395963192, "3": 0.7753487825393677, "4": 0.0006204474484547973, "5": 0.0005549437482841313, "6": 0.0005019513191655278, "7": 0.00045819731894880533, "8": 0.00042145964107476175, "9": 0.14655038714408875, "10": 0.0003632153384387493, "11": 0.016259782016277313, "12": 0.00031911476980894804, "13": 0.054138343781232834, "14": 0.0002845638373401016, "15": 0.0002699499309528619, "16": 0.0002567637129686773, "17": 0.00024480573483742774, "18": 0.00023391198192257434, "19": 0.00022394645202439278}}, {"key": "chang2023language", "year": "2023", "title": "Language Model Behavior: A Comprehensive Survey", "topic_distr": {"0": 0.257539302110672, "1": 0.0013059652410447598, "2": 0.0011038673110306263, "3": 0.22628934681415558, "4": 0.0008432075846940279, "5": 0.0007541869417764246, "6": 0.03036460466682911, "7": 0.08432936668395996, "8": 0.0005727775278501213, "9": 0.000530261779204011, "10": 0.09271232783794403, "11": 0.0004617177473846823, "12": 0.24141818284988403, "13": 0.05971735343337059, "14": 0.0003867316117975861, "15": 0.000366870837751776, "16": 0.0003489503578748554, "17": 0.0003326990408822894, "18": 0.0003178940969519317, "19": 0.00030435060034506023}}, {"key": "chang2023speechprompt", "year": "2023", "title": "Speechprompt V2: Prompt Tuning For Speech Classification Tasks", "topic_distr": {"0": 0.0014334609732031822, "1": 0.05423932895064354, "2": 0.0009895716793835163, "3": 0.16512106359004974, "4": 0.0007559285731986165, "5": 0.0006761210970580578, "6": 0.0006115572759881616, "7": 0.0005582491285167634, "8": 0.0005134894163347781, "9": 0.031289078295230865, "10": 0.00044252691441215575, "11": 0.00041392541606910527, "12": 0.0003887965576723218, "13": 0.135384663939476, "14": 0.0003467010974418372, "15": 0.00032889610156416893, "16": 0.00031283055432140827, "17": 0.5648319125175476, "18": 0.00028498892788775265, "19": 0.04107694700360298}}, {"key": "chang2023text", "year": "2023", "title": "Muse: Text-to-image Generation Via Masked Generative Transformers", "topic_distr": {"0": 0.0013124628458172083, "1": 0.0010719355195760727, "2": 0.0009062481694854796, "3": 0.05928482487797737, "4": 0.0006922694738022983, "5": 0.0006191841675899923, "6": 0.0005600572912953794, "7": 0.22422264516353607, "8": 0.00047024787636473775, "9": 0.0004353426629677415, "10": 0.22778642177581787, "11": 0.00037906828220002353, "12": 0.00035605556331574917, "13": 0.21464824676513672, "14": 0.00031750500784255564, "15": 0.0003011993831023574, "16": 0.00028648675652220845, "17": 0.0002731444837991148, "18": 0.2658267617225647, "19": 0.0002498705289326608}}, {"key": "chang2024data", "year": "2024", "title": "Data Is All You Need: Finetuning Llms For Chip Design Via An Automated Design-data Augmentation Framework", "topic_distr": {"0": 0.0010840228060260415, "1": 0.198123037815094, "2": 0.0007486483082175255, "3": 0.5344319939613342, "4": 0.0005718930624425411, "5": 0.0005115156527608633, "6": 0.14035582542419434, "7": 0.0004223402647767216, "8": 0.00038847755058668554, "9": 0.00035964191192761064, "10": 0.00033479128614999354, "11": 0.00031315296655520797, "12": 0.0002941418788395822, "13": 0.00027730694273486733, "14": 0.0002622947795316577, "15": 0.12063653022050858, "16": 0.00023667022469453514, "17": 0.00022564802202396095, "18": 0.00021560679306276143, "19": 0.0002064211294054985}}, {"key": "chaplot2017gated", "year": "2017", "title": "Gated-attention Architectures For Task-oriented Language Grounding", "topic_distr": {"0": 0.001618646550923586, "1": 0.0013225037837401032, "2": 0.17539352178573608, "3": 0.0009683454991318285, "4": 0.0008540438138879836, "5": 0.0007638792740181088, "6": 0.0006909352377988398, "7": 0.0006307078874669969, "8": 0.0005801385268568993, "9": 0.0005370764411054552, "10": 0.0004999653319828212, "11": 0.6509851813316345, "12": 0.00043926096986979246, "13": 0.00041412029531784356, "14": 0.0003917016729246825, "15": 0.00037158565828576684, "16": 0.03196144849061966, "17": 0.0003369747137185186, "18": 0.13093169033527374, "19": 0.00030826195143163204}}, {"key": "chefer2021generic", "year": "2021", "title": "Generic Attention-model Explainability For Interpreting Bi-modal And Encoder-decoder Transformers", "topic_distr": {"0": 0.039713356643915176, "1": 0.001305662444792688, "2": 0.3596360683441162, "3": 0.0009560558828525245, "4": 0.0008432004833593965, "5": 0.1035912036895752, "6": 0.0006821626448072493, "7": 0.0006227000267244875, "8": 0.04874291643500328, "9": 0.0005302573554217815, "10": 0.15690329670906067, "11": 0.0004617138474714011, "12": 0.00043368383194319904, "13": 0.00040886233909986913, "14": 0.00038672835216857493, "15": 0.00036686775274574757, "16": 0.00034894741838797927, "17": 0.00033269624691456556, "18": 0.2834292948246002, "19": 0.00030434803920798004}}, {"key": "chen2016latent", "year": "2016", "title": "Latent Attention For If-then Program Synthesis", "topic_distr": {"0": 0.0015596401644870639, "1": 0.0012733363546431065, "2": 0.49055302143096924, "3": 0.2919180691242218, "4": 0.0008220869931392372, "5": 0.0007352961110882461, "6": 0.1595228612422943, "7": 0.0006071075913496315, "8": 0.0005584305035881698, "9": 0.0005169797223061323, "10": 0.00048125730245374143, "11": 0.00045015255454927683, "12": 0.00042282440699636936, "13": 0.00039862445555627346, "14": 0.04855138063430786, "15": 0.0003576813905965537, "16": 0.00034020980820059776, "17": 0.00032436553738079965, "18": 0.00030993143445812166, "19": 0.00029672717209905386}}, {"key": "chen2017survey", "year": "2017", "title": "A Survey On Dialogue Systems: Recent Advances And New Frontiers", "topic_distr": {"0": 0.0014842735836282372, "1": 0.0012127390364184976, "2": 0.0010249337647110224, "3": 0.0008877167711034417, "4": 0.07152947038412094, "5": 0.20959021151065826, "6": 0.000633403891697526, "7": 0.000578191364184022, "8": 0.0005318327457644045, "9": 0.1965414136648178, "10": 0.0004583352420013398, "11": 0.0004287120245862752, "12": 0.3559506833553314, "13": 0.00037963816430419683, "14": 0.0003590862615965307, "15": 0.09397014230489731, "16": 0.00032400578493252397, "17": 0.00030891617643646896, "18": 0.06352376192808151, "19": 0.0002825942065101117}}, {"key": "chen2017syntax", "year": "2017", "title": "Syntax-directed Attention For Neural Machine Translation", "topic_distr": {"0": 0.0013132055755704641, "1": 0.014116382226347923, "2": 0.6879696249961853, "3": 0.014670542441308498, "4": 0.0006923888577148318, "5": 0.0006192909204401076, "6": 0.0005601538578048348, "7": 0.0005113264196552336, "8": 0.00047032893053255975, "9": 0.00043541769264265895, "10": 0.0004053310549352318, "11": 0.00037913359119556844, "12": 0.00035611691419035196, "13": 0.00033573489054106176, "14": 0.27579307556152344, "15": 0.00030125127523206174, "16": 0.00028653611661866307, "17": 0.00027319154469296336, "18": 0.0002610346709843725, "19": 0.0002499136026017368}}, {"key": "chen2018best", "year": "2018", "title": "The Best Of Both Worlds: Combining Recent Advances In Neural Machine Translation", "topic_distr": {"0": 0.0016014480497688055, "1": 0.00130576326046139, "2": 0.701721727848053, "3": 0.0009560516919009387, "4": 0.0008431976893916726, "5": 0.0007541767554357648, "6": 0.0006821593269705772, "7": 0.0006226969417184591, "8": 0.0005727699026465416, "9": 0.0005302547360770404, "10": 0.0004936150508001447, "11": 0.0004617116064764559, "12": 0.0004336817073635757, "13": 0.0004088603309355676, "14": 0.28694114089012146, "15": 0.00036686594830825925, "16": 0.0003489457303658128, "17": 0.00033269461710006, "18": 0.0003178898768965155, "19": 0.00030434655491262674}}, {"key": "chen2018fast", "year": "2018", "title": "Fast Abstractive Summarization With Reinforce-selected Sentence Rewriting", "topic_distr": {"0": 0.0016860823379829526, "1": 0.0013764428440481424, "2": 0.3165205121040344, "3": 0.0010077101178467274, "4": 0.08733711391687393, "5": 0.0007949292776174843, "6": 0.0007190201431512833, "7": 0.2512466013431549, "8": 0.0006037198472768068, "9": 0.0005589073407463729, "10": 0.11409196257591248, "11": 0.09303947538137436, "12": 0.00045711593702435493, "13": 0.08454541862010956, "14": 0.0004076234472449869, "15": 0.0442330576479435, "16": 0.0003678011998999864, "17": 0.000350671965861693, "18": 0.00033506721956655383, "19": 0.0003207920817658305}}, {"key": "chen2019bert", "year": "2019", "title": "BERT For Joint Intent Classification And Slot Filling", "topic_distr": {"0": 0.0015394381480291486, "1": 0.03487540781497955, "2": 0.001063009724020958, "3": 0.0009206889662891626, "4": 0.0008120030979625881, "5": 0.0007262771832756698, "6": 0.29680341482162476, "7": 0.0005996612017042935, "8": 0.0005515811499208212, "9": 0.0005106387543492019, "10": 0.5393894910812378, "11": 0.0004446312668733299, "12": 0.0004176383081357926, "13": 0.00039373518666252494, "14": 0.00037242009420879185, "15": 0.032862886786460876, "16": 0.02681880258023739, "17": 0.06029907241463661, "18": 0.00030613000853918493, "19": 0.00029308770899660885}}, {"key": "chen2019distilling", "year": "2019", "title": "Distilling Knowledge Learned In BERT For Text Generation", "topic_distr": {"0": 0.0014327579410746694, "1": 0.001170506002381444, "2": 0.1498405486345291, "3": 0.0008570767240598798, "4": 0.0007559068617410958, "5": 0.0006761031690984964, "6": 0.0006115409778431058, "7": 0.21514490246772766, "8": 0.015758605673909187, "9": 0.0004753618559334427, "10": 0.3882913887500763, "11": 0.0004139144148211926, "12": 0.00038878622581250966, "13": 0.07595495134592056, "14": 0.05329171568155289, "15": 0.00032888734131120145, "16": 0.05083167180418968, "17": 0.0002982534933835268, "18": 0.0002849813608918339, "19": 0.043192122131586075}}, {"key": "chen2019dual", "year": "2019", "title": "DMRM: A Dual-channel Multi-hop Reasoning Model For Visual Dialog", "topic_distr": {"0": 0.0013408729573711753, "1": 0.001094903564080596, "2": 0.0009257049532607198, "3": 0.0008017704240046442, "4": 0.23656252026557922, "5": 0.0006324708228930831, "6": 0.08525964617729187, "7": 0.0005222086329013109, "8": 0.054425813257694244, "9": 0.01626361533999443, "10": 0.0004139574302826077, "11": 0.11392278969287872, "12": 0.0003636959008872509, "13": 0.00034288011374883354, "14": 0.00032431812724098563, "15": 0.0003076626162510365, "16": 0.00029263427131809294, "17": 0.0002790057042147964, "18": 0.4856683015823364, "19": 0.0002552323567215353}}, {"key": "chen2019enabling", "year": "2019", "title": "Enabling Robots To Understand Incomplete Natural Language Instructions Using Commonsense Reasoning", "topic_distr": {"0": 0.0010937905171886086, "1": 0.0008934764773584902, "2": 0.13121849298477173, "3": 0.10757025331258774, "4": 0.0005769339622929692, "5": 0.0005160248256288469, "6": 0.12957845628261566, "7": 0.00042606322676874697, "8": 0.00039190202369354665, "9": 0.00036281219217926264, "10": 0.0003377425018697977, "11": 0.5217965245246887, "12": 0.00029673476819880307, "13": 0.0002797514316625893, "14": 0.0002646069333422929, "15": 0.0002510179183445871, "16": 0.10349199920892715, "17": 0.00022763713786844164, "18": 0.00021750738960690796, "19": 0.00020824074454139918}}, {"key": "chen2019few", "year": "2019", "title": "Few-shot NLG With Pre-trained Language Model", "topic_distr": {"0": 0.03227275237441063, "1": 0.08573386073112488, "2": 0.32306143641471863, "3": 0.0009942329488694668, "4": 0.0008768714033067226, "5": 0.0007842965424060822, "6": 0.0007094028405845165, "7": 0.12997309863567352, "8": 0.0005956446984782815, "9": 0.0005514316144399345, "10": 0.0005133285885676742, "11": 0.0004801510367542505, "12": 0.08497650176286697, "13": 0.0004251890641171485, "14": 0.04264887049794197, "15": 0.0003815175441559404, "16": 0.04231458157300949, "17": 0.2520596981048584, "18": 0.00033058549161069095, "19": 0.00031650130404159427}}, {"key": "chen2019gmail", "year": "2019", "title": "Gmail Smart Compose: Real-time Assisted Writing", "topic_distr": {"0": 0.002398155862465501, "1": 0.0019587278366088867, "2": 0.146322563290596, "3": 0.0014340648194774985, "4": 0.3438255190849304, "5": 0.0011312528513371944, "6": 0.13543832302093506, "7": 0.000934035109821707, "8": 0.0008591453661210835, "9": 0.2646716833114624, "10": 0.0007404143689200282, "11": 0.0006925597554072738, "12": 0.0006505153723992407, "13": 0.09585687518119812, "14": 0.0005800832877866924, "15": 0.0005502928397618234, "16": 0.0005234127747826278, "17": 0.0004990363959223032, "18": 0.00047682953299954534, "19": 0.0004565147974062711}}, {"key": "chen2019multi", "year": "2019", "title": "Multi-hop Question Answering Via Reasoning Chains", "topic_distr": {"0": 0.0010762996971607208, "1": 0.03259265795350075, "2": 0.3797305226325989, "3": 0.23551233112812042, "4": 0.0005669701495207846, "5": 0.0005071131163276732, "6": 0.00045868780580349267, "7": 0.07727223634719849, "8": 0.16904225945472717, "9": 0.0003565463121049106, "10": 0.02429605834186077, "11": 0.0003104575152974576, "12": 0.00029161004931665957, "13": 0.0002749200211837888, "14": 0.00026003707898780704, "15": 0.03896673396229744, "16": 0.00023463308752980083, "17": 0.03783155232667923, "18": 0.00021375095820985734, "19": 0.00020464435510803014}}, {"key": "chen2019reinforcement", "year": "2019", "title": "Reinforcement Learning Based Graph-to-sequence Model For Natural Question Generation", "topic_distr": {"0": 0.018183011561632156, "1": 0.001072122366167605, "2": 0.3095604479312897, "3": 0.0007849624380469322, "4": 0.052656132727861404, "5": 0.0006192157161422074, "6": 0.0005600858712568879, "7": 0.11374238133430481, "8": 0.13217365741729736, "9": 0.00043536486919038, "10": 0.1180524230003357, "11": 0.132746160030365, "12": 0.00035607372410595417, "13": 0.0003356941742822528, "14": 0.0003175211895722896, "15": 0.00030121474992483854, "16": 0.11731952428817749, "17": 0.0002731584245339036, "18": 0.00026100300601683557, "19": 0.00024988327641040087}}, {"key": "chen2019semantically", "year": "2019", "title": "Semantically Conditioned Dialog Response Generation Via Hierarchical Disentangled Self-attention", "topic_distr": {"0": 0.06404929608106613, "1": 0.0013055144809186459, "2": 0.18142499029636383, "3": 0.0009559834725223482, "4": 0.1364179253578186, "5": 0.0007541267550550401, "6": 0.3647412955760956, "7": 0.06686586886644363, "8": 0.0005727318930439651, "9": 0.0005302195786498487, "10": 0.04279854893684387, "11": 0.000461680960142985, "12": 0.00043365295277908444, "13": 0.0004088332352694124, "14": 0.00038670081994496286, "15": 0.0003668416175059974, "16": 0.13657090067863464, "17": 0.0003326725563965738, "18": 0.00031786877661943436, "19": 0.00030432635685428977}}, {"key": "chen2019universal", "year": "2019", "title": "UNITER: Universal Image-text Representation Learning", "topic_distr": {"0": 0.0011340358760207891, "1": 0.0009257658384740353, "2": 0.17885559797286987, "3": 0.0006778977112844586, "4": 0.0005978777189739048, "5": 0.0005347575643099844, "6": 0.00048369274009019136, "7": 0.00044153028284199536, "8": 0.04094646871089935, "9": 0.000375983101548627, "10": 0.3566926419734955, "11": 0.0003273818001616746, "12": 0.00030750688165426254, "13": 0.0002899070386774838, "14": 0.0002742127689998597, "15": 0.00026013044407591224, "16": 0.00024742388632148504, "17": 0.00023590086493641138, "18": 0.4161754846572876, "19": 0.00021580034808721393}}, {"key": "chen2020efficient", "year": "2020", "title": "Earlybert: Efficient BERT Training Via Early-bird Lottery Tickets", "topic_distr": {"0": 0.0013128266436979175, "1": 0.0010720357531681657, "2": 0.17092949151992798, "3": 0.0007849893881939352, "4": 0.0006923263426870108, "5": 0.0006192350410856307, "6": 0.000560103275347501, "7": 0.0005112803191877902, "8": 0.00047028649714775383, "9": 0.00043537840247154236, "10": 0.27159473299980164, "11": 0.0003790993941947818, "12": 0.00035608478356152773, "13": 0.5485928058624268, "14": 0.0003175310557708144, "15": 0.00030122409225441515, "16": 0.0002865102724172175, "17": 0.00027316692285239697, "18": 0.000261011125985533, "19": 0.0002498910471331328}}, {"key": "chen2020facebook", "year": "2020", "title": "Facebook Ai's WMT20 News Translation Task Submission", "topic_distr": {"0": 0.0013412813423201442, "1": 0.09861844778060913, "2": 0.13920389115810394, "3": 0.0008018519729375839, "4": 0.0007071997970342636, "5": 0.15904749929904938, "6": 0.0005721356719732285, "7": 0.0005222638137638569, "8": 0.0004803893971256912, "9": 0.04732052981853485, "10": 0.0004140012024436146, "11": 0.0003872433735523373, "12": 0.00036373434704728425, "13": 0.06982116401195526, "14": 0.3996025025844574, "15": 0.06502100825309753, "16": 0.00029266520868986845, "17": 0.00027903521549887955, "18": 0.0002666182699613273, "19": 0.01493655052036047}}, {"key": "chen2020high", "year": "2020", "title": "Logic2text: High-fidelity Natural Language Generation From Logical Forms", "topic_distr": {"0": 0.0011449531884863973, "1": 0.07179414480924606, "2": 0.0007898650947026908, "3": 0.0006841274444013834, "4": 0.0006033712415955961, "5": 0.0005396708147600293, "6": 0.1827833652496338, "7": 0.12466221302747726, "8": 0.000409860338550061, "9": 0.0003794375224970281, "10": 0.00035321901668794453, "11": 0.2719873785972595, "12": 0.19132177531719208, "13": 0.0002925705921370536, "14": 0.00027673214208334684, "15": 0.06397537887096405, "16": 0.054690539836883545, "17": 0.0002380682562943548, "18": 0.00022747433104086667, "19": 0.0328458696603775}}, {"key": "chen2020knowledge", "year": "2020", "title": "KGPT: Knowledge-grounded Pre-training For Data-to-text Generation", "topic_distr": {"0": 0.001385495881550014, "1": 0.10542817413806915, "2": 0.13664038479328156, "3": 0.0008285250514745712, "4": 0.0007307219202630222, "5": 0.0006535763968713582, "6": 0.0005911653861403465, "7": 0.0005396347842179239, "8": 0.0004963675164617598, "9": 0.0004595235222950578, "10": 0.00042777121416293085, "11": 0.0004001234192401171, "12": 0.00037583246012218297, "13": 0.00035432205186225474, "14": 0.0003351406194269657, "15": 0.47223618626594543, "16": 0.0003023994795512408, "17": 0.2772754728794098, "18": 0.0002754862071014941, "19": 0.00026374944718554616}}, {"key": "chen2020learning", "year": "2020", "title": "Learning Modality Interaction For Temporal Sentence Localization And Event Captioning In Videos", "topic_distr": {"0": 0.07689899951219559, "1": 0.0011315535521134734, "2": 0.2328597605228424, "3": 0.0008285181829705834, "4": 0.0007307197665795684, "5": 0.06782196462154388, "6": 0.0005911634070798755, "7": 0.0005396329797804356, "8": 0.0004963658866472542, "9": 0.000459522008895874, "10": 0.0004277698171790689, "11": 0.00040012208046391606, "12": 0.0003758312086574733, "13": 0.000354320858605206, "14": 0.00033513951348140836, "15": 0.0003179282648488879, "16": 0.00030239849002100527, "17": 0.00028831520467065275, "18": 0.6145762205123901, "19": 0.00026374857407063246}}, {"key": "chen2020logical", "year": "2020", "title": "Logical Natural Language Generation From Open-domain Tables", "topic_distr": {"0": 0.05105144903063774, "1": 0.05894000455737114, "2": 0.08274176716804504, "3": 0.000642832019366324, "4": 0.0005669494858011603, "5": 0.013965281657874584, "6": 0.11263518035411835, "7": 0.136140376329422, "8": 0.0003851196088362485, "9": 0.0003565332153812051, "10": 0.07920743525028229, "11": 0.19869618117809296, "12": 0.16431616246700287, "13": 0.00027490995125845075, "14": 0.0002600275329314172, "15": 0.05760471150279045, "16": 0.00023462447279598564, "17": 0.0002236975560663268, "18": 0.00021374311472754925, "19": 0.04154301807284355}}, {"key": "chen2020recall", "year": "2020", "title": "Recall And Learn: Fine-tuning Deep Pretrained Language Models With Less Forgetting", "topic_distr": {"0": 0.0016848720842972398, "1": 0.00137610686942935, "2": 0.3006874620914459, "3": 0.0010076070902869105, "4": 0.0008886706782504916, "5": 0.0007948495913296938, "6": 0.0007189481984823942, "7": 0.0006562790367752314, "8": 0.0006036593695171177, "9": 0.0005588514031842351, "10": 0.13428467512130737, "11": 0.00048661170876584947, "12": 0.0004570701566990465, "13": 0.0004309101786930114, "14": 0.00040758264367468655, "15": 0.0003866510232910514, "16": 0.20437464118003845, "17": 0.07537728548049927, "18": 0.0003350336628500372, "19": 0.27448225021362305}}, {"key": "chen2021data", "year": "2021", "title": "Visualgpt: Data-efficient Adaptation Of Pretrained Language Models For Image Captioning", "topic_distr": {"0": 0.001272322959266603, "1": 0.09040281176567078, "2": 0.21750392019748688, "3": 0.0007609297172166407, "4": 0.0006711088353767991, "5": 0.0006002574227750301, "6": 0.0005429380107671022, "7": 0.0004956112243235111, "8": 0.0004558737273328006, "9": 0.0004220354603603482, "10": 0.040589023381471634, "11": 0.00036748123238794506, "12": 0.04001247137784958, "13": 0.1673644334077835, "14": 0.00030779975350014865, "15": 0.0002919925609603524, "16": 0.060417719185352325, "17": 0.00026479523512534797, "18": 0.23584651947021484, "19": 0.1414099484682083}}, {"key": "chen2021evaluating", "year": "2021", "title": "Evaluating Large Language Models Trained On Code", "topic_distr": {"0": 0.1628715991973877, "1": 0.060071252286434174, "2": 0.10185115784406662, "3": 0.48165473341941833, "4": 0.0008654340053908527, "5": 0.0007740667788311839, "6": 0.11296004801988602, "7": 0.0006391193601302803, "8": 0.0005878756055608392, "9": 0.07376765459775925, "10": 0.0005066331359557807, "11": 0.0004738883289974183, "12": 0.000445119192590937, "13": 0.00041964324191212654, "14": 0.000396925606764853, "15": 0.00037654131301678717, "16": 0.0003581484779715538, "17": 0.00034146878169849515, "18": 0.0003262735845055431, "19": 0.00031237310031428933}}, {"key": "chen2021fine", "year": "2021", "title": "Fine-grained Style Control In Transformer-based Text-to-speech Synthesis", "topic_distr": {"0": 0.1273738145828247, "1": 0.11135445535182953, "2": 0.14245004951953888, "3": 0.0010808559600263834, "4": 0.0009532719268463552, "5": 0.0008526302408427, "6": 0.0007712111691944301, "7": 0.3024071156978607, "8": 0.0006475416012108326, "9": 0.0005994763341732323, "10": 0.2545432448387146, "11": 0.000521985290106386, "12": 0.0004902962828055024, "13": 0.0004622346314135939, "14": 0.00043721130350604653, "15": 0.00041475813486613333, "16": 0.00039449852192774415, "17": 0.053541868925094604, "18": 0.00035938850487582386, "19": 0.00034407718339934945}}, {"key": "chen2021generate", "year": "2021", "title": "Generate Natural Language Explanations For Recommendation", "topic_distr": {"0": 0.050839174538850784, "1": 0.0008856607018969953, "2": 0.2137325257062912, "3": 0.0006484442856162786, "4": 0.32677650451660156, "5": 0.16001209616661072, "6": 0.0004626746231224388, "7": 0.11835338175296783, "8": 0.00038848124677315354, "9": 0.00035964534617960453, "10": 0.0003347944584675133, "11": 0.03543734550476074, "12": 0.09009650349617004, "13": 0.00027730956207960844, "14": 0.0002622972533572465, "15": 0.00024882686557248235, "16": 0.0002366724656894803, "17": 0.00022565016115549952, "18": 0.0002156088303308934, "19": 0.0002064230793621391}}, {"key": "chen2021history", "year": "2021", "title": "History Aware Multimodal Transformer For Vision-and-language Navigation", "topic_distr": {"0": 0.00113403657451272, "1": 0.0009257441270165145, "2": 0.10144830495119095, "3": 0.000677864532917738, "4": 0.016439536586403847, "5": 0.0005347331753000617, "6": 0.0004836705920752138, "7": 0.0004415100847836584, "8": 0.00040611036820337176, "9": 0.00037596587208099663, "10": 0.06156358867883682, "11": 0.6145891547203064, "12": 0.00030749282450415194, "13": 0.0002898937673307955, "14": 0.0002742001961451024, "15": 0.000260118511505425, "16": 0.0002474125649314374, "17": 0.00023589006741531193, "18": 0.1991489827632904, "19": 0.00021579046733677387}}, {"key": "chen2021knowledge", "year": "2021", "title": "Knowprompt: Knowledge-aware Prompt-tuning With Synergistic Optimization For Relation Extraction", "topic_distr": {"0": 0.0013855912256985903, "1": 0.0011315691517665982, "2": 0.0009566320804879069, "3": 0.0008285560179501772, "4": 0.0007307542837224901, "5": 0.0006536055007018149, "6": 0.037524569779634476, "7": 0.0005396588239818811, "8": 0.01325422152876854, "9": 0.0004595440113916993, "10": 0.14983704686164856, "11": 0.00040014125988818705, "12": 0.00037584922392852604, "13": 0.00035433785524219275, "14": 0.0003351555787958205, "15": 0.00031794351525604725, "16": 0.2577967643737793, "17": 0.5325787663459778, "18": 0.0002754984889179468, "19": 0.0002637612051330507}}, {"key": "chen2021lightweight", "year": "2021", "title": "Lightner: A Lightweight Tuning Paradigm For Low-resource NER Via Pluggable Prompting", "topic_distr": {"0": 0.0011873571202158928, "1": 0.0009701919043436646, "2": 0.13045884668827057, "3": 0.0007101938244886696, "4": 0.0006263612303882837, "5": 0.0005602336605079472, "6": 0.0005067361053079367, "7": 0.00046256498899310827, "8": 0.0004254771047271788, "9": 0.0003938951122108847, "10": 0.03584343194961548, "11": 0.0003429784264881164, "12": 0.03685487434267998, "13": 0.09728150814771652, "14": 0.022943127900362015, "15": 0.00027252317522652447, "16": 0.10169275104999542, "17": 0.5680046677589417, "18": 0.00023614171368535608, "19": 0.00022608117433264852}}, {"key": "chen2021meta", "year": "2021", "title": "Meta-learning Via Language Model In-context Tuning", "topic_distr": {"0": 0.016493285074830055, "1": 0.0012423048028722405, "2": 0.36795923113822937, "3": 0.00090936163906008, "4": 0.0008020192617550492, "5": 0.0007173465564846992, "6": 0.0006488458602689207, "7": 0.0005922873970121145, "8": 0.0005447985604405403, "9": 0.0005043596029281616, "10": 0.00046950922114774585, "11": 0.05996539443731308, "12": 0.00041250273352488875, "13": 0.0003888935607392341, "14": 0.00036784057738259435, "15": 0.000348949950421229, "16": 0.00033190485555678606, "17": 0.5014165043830872, "18": 0.0003023656317964196, "19": 0.04558227211236954}}, {"key": "chen2021revisiting", "year": "2021", "title": "Revisiting Self-training For Few-shot Learning Of Language Model", "topic_distr": {"0": 0.0018094131955876946, "1": 0.2139890044927597, "2": 0.12810108065605164, "3": 0.0010807669023051858, "4": 0.0009531925315968692, "5": 0.0008525597513653338, "6": 0.0007711475482210517, "7": 0.0007039282936602831, "8": 0.020699379965662956, "9": 0.0005994269158691168, "10": 0.0005580075085163116, "11": 0.00052194221643731, "12": 0.1240922287106514, "13": 0.056917447596788406, "14": 0.00043717524386011064, "15": 0.12610888481140137, "16": 0.05364352464675903, "17": 0.267457515001297, "18": 0.00035935884807258844, "19": 0.00034404880716465414}}, {"key": "chen2021self", "year": "2021", "title": "Self-supervised Dialogue Learning For Spoken Conversational Question Answering", "topic_distr": {"0": 0.001212246366776526, "1": 0.0009887636406347156, "2": 0.23462329804897308, "3": 0.0007239611586555839, "4": 0.03967401757836342, "5": 0.08139359951019287, "6": 0.4109654128551483, "7": 0.00047153158811852336, "8": 0.19262471795082092, "9": 0.0004015305603388697, "10": 0.00037378547131083906, "11": 0.00034962690551765263, "12": 0.0003284015110693872, "13": 0.0003096057625953108, "14": 0.0002928450994659215, "15": 0.0002778058988042176, "16": 0.0002642359759192914, "17": 0.034253448247909546, "18": 0.00024071920779533684, "19": 0.00023046365822665393}}, {"key": "chen2021simple", "year": "2021", "title": "Hiddencut: Simple Data Augmentation For Natural Language Understanding With Better Generalization", "topic_distr": {"0": 0.0018899771384894848, "1": 0.18291203677654266, "2": 0.3424502909183502, "3": 0.0011297970777377486, "4": 0.0009964298224076629, "5": 0.0008912329212762415, "6": 0.0008061277912929654, "7": 0.0007358593866229057, "8": 0.0006768591119907796, "9": 0.0006266176933422685, "10": 0.2787419259548187, "11": 0.0005456182407215238, "12": 0.0005124944727867842, "13": 0.00048316235188394785, "14": 0.0004570060991682112, "15": 0.0004335363337304443, "16": 0.09332750737667084, "17": 0.09164818376302719, "18": 0.0003756598453037441, "19": 0.00035965529968962073}}, {"key": "chen2022adaptive", "year": "2022", "title": "Adaprompt: Adaptive Model Training For Prompt-based NLP", "topic_distr": {"0": 0.001485704444348812, "1": 0.0012125854846090078, "2": 0.22751973569393158, "3": 0.0008877249783836305, "4": 0.0007829315145500004, "5": 0.000700274424161762, "6": 0.0006334041827358305, "7": 0.0005781917134299874, "8": 0.0005318330368027091, "9": 0.0004923564847558737, "10": 0.0004583355039358139, "11": 0.0004287122574169189, "12": 0.0004026857204735279, "13": 0.00037963836803101003, "14": 0.0003590864362195134, "15": 0.0003406454052310437, "16": 0.07457628846168518, "17": 0.44933924078941345, "18": 0.0002951697097159922, "19": 0.23859542608261108}}, {"key": "chen2022altering", "year": "2022", "title": "Altclip: Altering The Language Encoder In CLIP For Extended Language Capabilities", "topic_distr": {"0": 0.039722565561532974, "1": 0.0016696910606697202, "2": 0.10786206275224686, "3": 0.0012224584352225065, "4": 0.001078154076822102, "5": 0.0009643286466598511, "6": 0.0008722434868104756, "7": 0.0007962118834257126, "8": 0.0007323726313188672, "9": 0.0006780105759389699, "10": 0.16885225474834442, "11": 0.0005903678829781711, "12": 0.0005545273888856173, "13": 0.03214675560593605, "14": 0.0808294489979744, "15": 0.0004690934147220105, "16": 0.0004461796779651195, "17": 0.0004254002124071121, "18": 0.5596987009048462, "19": 0.0003891529340762645}}, {"key": "chen2022code", "year": "2022", "title": "Codet: Code Generation With Generated Tests", "topic_distr": {"0": 0.001048991340212524, "1": 0.051289189606904984, "2": 0.19759078323841095, "3": 0.495571106672287, "4": 0.0005526501918211579, "5": 0.0004943044623360038, "6": 0.15321506559848785, "7": 0.09698805212974548, "8": 0.00037540632183663547, "9": 0.0003475409175734967, "10": 0.0003235264157410711, "11": 0.00030261618667282164, "12": 0.00028424477204680443, "13": 0.00026797628379426897, "14": 0.0002534692466724664, "15": 0.000240452223806642, "16": 0.00022870689281262457, "17": 0.00021805556025356054, "18": 0.00020835218310821801, "19": 0.0001994756021304056}}, {"key": "chen2022decoupling", "year": "2022", "title": "Decoupling Knowledge From Memorization: Retrieval-augmented Prompt Learning", "topic_distr": {"0": 0.19790509343147278, "1": 0.0010502730729058385, "2": 0.1928250789642334, "3": 0.0007687693578191102, "4": 0.0006780221010558307, "5": 0.0006064408808015287, "6": 0.05991322174668312, "7": 0.0005007166182622313, "8": 0.03219803422689438, "9": 0.00042638296145014465, "10": 0.0003969206300098449, "11": 0.02572467550635338, "12": 0.00034872765536420047, "13": 0.0003287685685791075, "14": 0.00031097049941308796, "15": 0.0002950004709418863, "16": 0.05271152779459953, "17": 0.4325110614299774, "18": 0.00025561833172105253, "19": 0.0002447279985062778}}, {"key": "chen2022exploring", "year": "2022", "title": "Convfinqa: Exploring The Chain Of Numerical Reasoning In Conversational Finance Question Answering", "topic_distr": {"0": 0.0014342071954160929, "1": 0.0011707248631864786, "2": 0.09137096256017685, "3": 0.30050376057624817, "4": 0.0007559538935311139, "5": 0.0006761446129530668, "6": 0.0802651047706604, "7": 0.0005582685116678476, "8": 0.08622942864894867, "9": 0.0004753909888677299, "10": 0.0004425422812346369, "11": 0.09873049706220627, "12": 0.33517587184906006, "13": 0.0003665568947326392, "14": 0.0003467131173238158, "15": 0.00032890751026570797, "16": 0.0003128414391539991, "17": 0.0002982717996928841, "18": 0.00028499882319010794, "19": 0.00027285679243505}}, {"key": "chen2022generating", "year": "2022", "title": "Emphi: Generating Empathetic Responses With Human-like Intents", "topic_distr": {"0": 0.18284417688846588, "1": 0.001616393681615591, "2": 0.0013665135484188795, "3": 0.0011835646582767367, "4": 0.0010438528843224049, "5": 0.08818960189819336, "6": 0.6091482043266296, "7": 0.0007708811899647117, "8": 0.000709072919562459, "9": 0.0006564403884112835, "10": 0.000611081428360194, "11": 0.0005715859006159008, "12": 0.0005368856946006417, "13": 0.0005061575211584568, "14": 0.00047875643940642476, "15": 0.0004541696689557284, "16": 0.10813048481941223, "17": 0.00041186652379110456, "18": 0.0003935386484954506, "19": 0.0003767724265344441}}, {"key": "chen2022hybrid", "year": "2022", "title": "Hybrid Transformer With Multi-level Fusion For Multimodal Knowledge Graph Completion", "topic_distr": {"0": 0.001285212580114603, "1": 0.0010498020565137267, "2": 0.0008875802159309387, "3": 0.0007687336765229702, "4": 0.05430218204855919, "5": 0.0006064119515940547, "6": 0.0005485047004185617, "7": 0.0005006927531212568, "8": 0.03087417595088482, "9": 0.0004263626178726554, "10": 0.10946333408355713, "11": 0.00037124904338270426, "12": 0.0003487110079731792, "13": 0.0003287528525106609, "14": 0.00031095565645955503, "15": 0.07906774431467056, "16": 0.3491488993167877, "17": 0.0002675101859495044, "18": 0.3691985011100769, "19": 0.00024471632787026465}}, {"key": "chen2022jointly", "year": "2022", "title": "Pali: A Jointly-scaled Multilingual Language-image Model", "topic_distr": {"0": 0.0014336652820929885, "1": 0.0011706582736223936, "2": 0.09987117350101471, "3": 0.0008570805657655001, "4": 0.0007559094810858369, "5": 0.0398864708840847, "6": 0.0006115424912422895, "7": 0.0005582356825470924, "8": 0.0005134770181030035, "9": 0.000475363020086661, "10": 0.1064831018447876, "11": 0.0004139154334552586, "12": 0.00038878718623891473, "13": 0.20093975961208344, "14": 0.06340090930461884, "15": 0.00032888815621845424, "16": 0.00031282301642932, "17": 0.0002982542209792882, "18": 0.4565742611885071, "19": 0.02472570165991783}}, {"key": "chen2022large", "year": "2022", "title": "Large Language Models Are Few(1)-shot Table Reasoners", "topic_distr": {"0": 0.0013275406090542674, "1": 0.0010834799613803625, "2": 0.0009158770553767681, "3": 0.7361786365509033, "4": 0.0006996379233896732, "5": 0.0006257743807509542, "6": 0.0005660182214342058, "7": 0.047004930675029755, "8": 0.019951753318309784, "9": 0.0004399761965032667, "10": 0.0004095745680388063, "11": 0.00038310285890474916, "12": 0.0875740721821785, "13": 0.00033924978924915195, "14": 0.00032088434090837836, "15": 0.0003044051700271666, "16": 0.00028953593573533, "17": 0.0002760516945272684, "18": 0.0002637675206642598, "19": 0.10104572027921677}}, {"key": "chen2022multimodal", "year": "2022", "title": "Murag: Multimodal Retrieval-augmented Generator For Open Question Answering Over Images And Text", "topic_distr": {"0": 0.0012851773062720895, "1": 0.0010500012431293726, "2": 0.133709117770195, "3": 0.0007687568431720138, "4": 0.0006780095864087343, "5": 0.0006064297631382942, "6": 0.0005485208239406347, "7": 0.03475680947303772, "8": 0.11766663938760757, "9": 0.00042637516162358224, "10": 0.0003969133540522307, "11": 0.00037125995731912553, "12": 0.0003487212525215, "13": 0.15903642773628235, "14": 0.00031096479506231844, "15": 0.10715443640947342, "16": 0.2308306097984314, "17": 0.00026751807308755815, "18": 0.20954255759716034, "19": 0.00024472351651638746}}, {"key": "chen2022program", "year": "2022", "title": "Program Of Thoughts Prompting: Disentangling Computation From Reasoning For Numerical Reasoning Tasks", "topic_distr": {"0": 0.001519806799478829, "1": 0.0012420897837728262, "2": 0.001049906830303371, "3": 0.9641985297203064, "4": 0.0008020006935112178, "5": 0.000717330607585609, "6": 0.0006488316575996578, "7": 0.025105390697717667, "8": 0.0005447865696623921, "9": 0.0005043485434725881, "10": 0.00046949891839176416, "11": 0.00043915415881201625, "12": 0.0004124936822336167, "13": 0.0003888850042130798, "14": 0.00036783251562155783, "15": 0.0003489422961138189, "16": 0.0003318975795991719, "17": 0.00031644044793210924, "18": 0.0003023589961230755, "19": 0.0002894773497246206}}, {"key": "chen2022prototypical", "year": "2022", "title": "Protoclip: Prototypical Contrastive Language Image Pretraining", "topic_distr": {"0": 0.04008727893233299, "1": 0.06787683069705963, "2": 0.11441744118928909, "3": 0.0006599171902053058, "4": 0.0005820214282721281, "5": 0.0005205743364058435, "6": 0.0004708639462478459, "7": 0.00042981974547728896, "8": 0.0003953573468606919, "9": 0.00036601105239242315, "10": 0.00034072028938680887, "11": 0.00031869878876022995, "12": 0.00029935099883005023, "13": 0.1432565301656723, "14": 0.06898827850818634, "15": 0.00025323109002783895, "16": 0.056491535156965256, "17": 0.00022964416712056845, "18": 0.4228634536266327, "19": 0.08115245401859283}}, {"key": "chen2022revisiting", "year": "2022", "title": "Revisiting Parameter-efficient Tuning: Are We Really There Yet?", "topic_distr": {"0": 0.0017105331644415855, "1": 0.0013955415925011039, "2": 0.0011794606689363718, "3": 0.36982759833335876, "4": 0.0009009610512293875, "5": 0.0008058433304540813, "6": 0.0007288918131962419, "7": 0.0006653559394180775, "8": 0.0006120085599832237, "9": 0.0005665807984769344, "10": 0.0005274310242384672, "11": 0.0004933419986627996, "12": 0.00046339185792021453, "13": 0.3117468059062958, "14": 0.00041321988101117313, "15": 0.00039199876482598484, "16": 0.0003728508891072124, "17": 0.19007301330566406, "18": 0.000339667487423867, "19": 0.11678551137447357}}, {"key": "chen2022think", "year": "2022", "title": "Think Global, Act Local: Dual-scale Graph Transformer For Vision-and-language Navigation", "topic_distr": {"0": 0.0015782959526404738, "1": 0.0012889940990135074, "2": 0.15367391705513, "3": 0.038207218050956726, "4": 0.0008324749069288373, "5": 0.0007445876835845411, "6": 0.0006734858616255224, "7": 0.0006147795938886702, "8": 0.000565487309359014, "9": 0.0005235127173364162, "10": 0.14215172827243805, "11": 0.45335784554481506, "12": 0.0004281675792299211, "13": 0.0004036618338432163, "14": 0.0003818093682639301, "15": 0.00036220139008946717, "16": 0.074613057076931, "17": 0.000328464520862326, "18": 0.12896986305713654, "19": 0.000300476880511269}}, {"key": "chen2022transferability", "year": "2022", "title": "On The Transferability Of Pre-trained Language Models For Low-resource Programming Languages", "topic_distr": {"0": 0.05271199345588684, "1": 0.0009093224653042853, "2": 0.11748041957616806, "3": 0.0006657983176410198, "4": 0.0005872047040611506, "5": 0.0005252115079201758, "6": 0.340724915266037, "7": 0.00043364849989302456, "8": 0.0003988791140727699, "9": 0.0003692713798955083, "10": 0.0003437553532421589, "11": 0.0003215376927983016, "12": 0.00030201757908798754, "13": 0.0002847318828571588, "14": 0.23530900478363037, "15": 0.00025548681151121855, "16": 0.00024300710356328636, "17": 0.24770043790340424, "18": 0.00022137969790492207, "19": 0.0002119480777764693}}, {"key": "chen2023autoregressive", "year": "2023", "title": "Autotamp: Autoregressive Task And Motion Planning With Llms As Translators And Checkers", "topic_distr": {"0": 0.0012598410248756409, "1": 0.0010287013137713075, "2": 0.0008696973090991378, "3": 0.44978782534599304, "4": 0.0006643342785537243, "5": 0.0005941975978203118, "6": 0.0005374568281695247, "7": 0.04846164211630821, "8": 0.0004512715386226773, "9": 0.00041777489241212606, "10": 0.0003889073268510401, "11": 0.4016404151916504, "12": 0.00034168732236139476, "13": 0.0003221311781089753, "14": 0.05228841304779053, "15": 0.0002890448085963726, "16": 0.0002749258710537106, "17": 0.000262122048297897, "18": 0.03987986966967583, "19": 0.000239787288592197}}, {"key": "chen2023benchmarking", "year": "2023", "title": "Benchmarking Large Language Models In Retrieval-augmented Generation", "topic_distr": {"0": 0.16551752388477325, "1": 0.11062933504581451, "2": 0.0008121885475702584, "3": 0.3176541328430176, "4": 0.000620426784735173, "5": 0.0005549259367398918, "6": 0.0005019351956434548, "7": 0.0004581825924105942, "8": 0.00042144610779359937, "9": 0.08608390390872955, "10": 0.00036320366780273616, "11": 0.0003397290129214525, "12": 0.046810589730739594, "13": 0.00030084088211879134, "14": 0.0002845546987373382, "15": 0.26768767833709717, "16": 0.000256755476584658, "17": 0.0002447978768032044, "18": 0.0002339044731343165, "19": 0.00022393926337826997}}, {"key": "chen2023chatgpt", "year": "2023", "title": "Gptutor: A Chatgpt-powered Programming Tool For Code Explanation", "topic_distr": {"0": 0.0012114584678784013, "1": 0.0009887233609333634, "2": 0.0008358556078746915, "3": 0.0007239830447360873, "4": 0.0006385226151905954, "5": 0.24658282101154327, "6": 0.2578370273113251, "7": 0.0004715452960226685, "8": 0.00043373738299123943, "9": 0.2685326933860779, "10": 0.0003737963270395994, "11": 0.00034963706275448203, "12": 0.123637855052948, "13": 0.00030961475567892194, "14": 0.0002928535977844149, "15": 0.0002778139605652541, "16": 0.0002642436302267015, "17": 0.05268706753849983, "18": 0.04332028701901436, "19": 0.00023047035210765898}}, {"key": "chen2023democratizing", "year": "2023", "title": "Phoenix: Democratizing Chatgpt Across Languages", "topic_distr": {"0": 0.003200339851900935, "1": 0.0026119875255972147, "2": 0.0022077651228755713, "3": 0.2974325120449066, "4": 0.0016864105127751827, "5": 0.0015083703910931945, "6": 0.0013643339043483138, "7": 0.0012454077368602157, "8": 0.0011455526109784842, "9": 0.2578456401824951, "10": 0.000987241044640541, "11": 0.0009234335157088935, "12": 0.30665841698646545, "13": 0.0008177298004738986, "14": 0.11702335625886917, "15": 0.0007337401038967073, "16": 0.000697899202350527, "17": 0.0006653966847807169, "18": 0.0006357867969200015, "19": 0.0006086999201215804}}, {"key": "chen2023dipping", "year": "2023", "title": "Dipping Plms Sauce: Bridging Structure And Text For Effective Knowledge Graph Completion Via Conditional Soft Prompting", "topic_distr": {"0": 0.001433920580893755, "1": 0.00117073068395257, "2": 0.0009895467665046453, "3": 0.0008570729987695813, "4": 0.0007559031946584582, "5": 0.0006760992109775543, "6": 0.000611537485383451, "7": 0.0920601412653923, "8": 0.0005134728271514177, "9": 0.0004753591201733798, "10": 0.00044251259532757103, "11": 0.00041391202830709517, "12": 0.0003887839848175645, "13": 0.025455724447965622, "14": 0.0003466898633632809, "15": 0.00032888544956222177, "16": 0.4346855878829956, "17": 0.43783631920814514, "18": 0.00028497970197349787, "19": 0.0002728384861256927}}, {"key": "chen2023driving", "year": "2023", "title": "Driving With Llms: Fusing Object-level Vector Modality For Explainable Autonomous Driving", "topic_distr": {"0": 0.001370726153254509, "1": 0.0011193661484867334, "2": 0.0009461207664571702, "3": 0.2394905388355255, "4": 0.12378625571727753, "5": 0.08987311273813248, "6": 0.000584696710575372, "7": 0.040115129202604294, "8": 0.0934286117553711, "9": 0.0004544953117147088, "10": 0.00042309044511057436, "11": 0.1033208966255188, "12": 0.06390932202339172, "13": 0.01380641758441925, "14": 0.0003314734494779259, "15": 0.00031445047352463007, "16": 0.0002990905777551234, "17": 0.0002851613098755479, "18": 0.2099769562482834, "19": 0.01616404391825199}}, {"key": "chen2023evaluation", "year": "2023", "title": "Evaluation Of Chatgpt Family Of Models For Biomedical Reasoning And Classification", "topic_distr": {"0": 0.08043249696493149, "1": 0.04213237762451172, "2": 0.001062876428477466, "3": 0.3417106866836548, "4": 0.02103564143180847, "5": 0.0007262153667397797, "6": 0.000656867865473032, "7": 0.0005996101535856724, "8": 0.000551534176338464, "9": 0.22211259603500366, "10": 0.00047531400923617184, "11": 0.00044459340278990567, "12": 0.0004176027432549745, "13": 0.044041600078344345, "14": 0.00037238840013742447, "15": 0.1368585228919983, "16": 0.0003360083792358637, "17": 0.10543394088745117, "18": 0.0003061039315070957, "19": 0.00029306276701390743}}, {"key": "chen2023extending", "year": "2023", "title": "Extending Context Window Of Large Language Models Via Positional Interpolation", "topic_distr": {"0": 0.0015212796861305833, "1": 0.001241890829987824, "2": 0.29461121559143066, "3": 0.05880725756287575, "4": 0.0008020565728656948, "5": 0.0007173807825893164, "6": 0.0006488766521215439, "7": 0.0005923154531046748, "8": 0.019764278084039688, "9": 0.0005043835262767971, "10": 0.4024673402309418, "11": 0.000439184601418674, "12": 0.0004125222912989557, "13": 0.2155129313468933, "14": 0.00036785801057703793, "15": 0.00034896648139692843, "16": 0.0003319205716252327, "17": 0.0003164623922202736, "18": 0.00030237995088100433, "19": 0.0002894974313676357}}, {"key": "chen2023how", "year": "2023", "title": "How Robust Is GPT-3.5 To Predecessors? A Comprehensive Study On Language Understanding Tasks", "topic_distr": {"0": 0.001343947253189981, "1": 0.19210198521614075, "2": 0.0009257918572984636, "3": 0.13781322538852692, "4": 0.0007071976433508098, "5": 0.0006325363065116107, "6": 0.0005721345078200102, "7": 0.0005222627660259604, "8": 0.00048038840759545565, "9": 0.01885223761200905, "10": 0.00041400035843253136, "11": 0.00038724258774891496, "12": 0.5073941946029663, "13": 0.03865574300289154, "14": 0.00032435174216516316, "15": 0.00030769448494538665, "16": 0.00029266459750942886, "17": 0.09775051474571228, "18": 0.00026661771698854864, "19": 0.00025525878299959004}}, {"key": "chen2023llm", "year": "2023", "title": "Llm-empowered Chatbots For Psychiatrist And Patient Simulation: Application And Evaluation", "topic_distr": {"0": 0.04361431673169136, "1": 0.07231097668409348, "2": 0.0014593217056244612, "3": 0.11158547550439835, "4": 0.22898049652576447, "5": 0.03787856549024582, "6": 0.0009018696146085858, "7": 0.0008232555701397359, "8": 0.000757248024456203, "9": 0.4595400094985962, "10": 0.0006525988574139774, "11": 0.0006104199565015733, "12": 0.0005733621655963361, "13": 0.0005405463743954897, "14": 0.0005112835788168013, "15": 0.00048502636491321027, "16": 0.0004613343917299062, "17": 0.03749125078320503, "18": 0.0004202760464977473, "19": 0.0004023707006126642}}, {"key": "chen2023meditron", "year": "2023", "title": "MEDITRON-70B: Scaling Medical Pretraining For Large Language Models", "topic_distr": {"0": 0.001340583898127079, "1": 0.001095127547159791, "2": 0.0009258100180886686, "3": 0.210079625248909, "4": 0.0007071922882460058, "5": 0.000632531417068094, "6": 0.10137826949357986, "7": 0.0005222586914896965, "8": 0.00048038465320132673, "9": 0.018470976501703262, "10": 0.00041399712790735066, "11": 0.00038723956095054746, "12": 0.409930944442749, "13": 0.1674496978521347, "14": 0.0003243492101319134, "15": 0.0003076920984312892, "16": 0.00029266232741065323, "17": 0.00027903245063498616, "18": 0.0002666156506165862, "19": 0.08471500873565674}}, {"key": "chen2023minigpt", "year": "2023", "title": "Minigpt-v2: Large Language Model As A Unified Interface For Vision-language Multi-task Learning", "topic_distr": {"0": 0.0015789263416081667, "1": 0.0012891135411337018, "2": 0.0010897679021582007, "3": 0.18186376988887787, "4": 0.0008324638474732637, "5": 0.07165943086147308, "6": 0.0006734763737767935, "7": 0.0006147709209471941, "8": 0.0005654793349094689, "9": 0.0005235053831711411, "10": 0.00048733202856965363, "11": 0.0004558346699923277, "12": 0.00042816155473701656, "13": 0.13977284729480743, "14": 0.12131910771131516, "15": 0.0003621962678153068, "16": 0.00034450413659214973, "17": 0.0003284598933532834, "18": 0.4755104184150696, "19": 0.00030047266045585275}}, {"key": "chen2023pali", "year": "2023", "title": "Pali-3 Vision Language Models: Smaller, Faster, Stronger", "topic_distr": {"0": 0.0019809664227068424, "1": 0.0674029141664505, "2": 0.0013665583683177829, "3": 0.0011836091289296746, "4": 0.001043894444592297, "5": 0.00093368737725541, "6": 0.0008445281418971717, "7": 0.0007709124474786222, "8": 0.0007091016741469502, "9": 0.000656466989312321, "10": 0.08446861803531647, "11": 0.0005716090672649443, "12": 0.04579956829547882, "13": 0.17100365459918976, "14": 0.14241138100624084, "15": 0.00045418806257657707, "16": 0.00043200241634622216, "17": 0.0004118832293897867, "18": 0.36523181200027466, "19": 0.11232264339923859}}, {"key": "chen2023prompting", "year": "2023", "title": "Prompting Or Fine-tuning? A Comparative Study Of Large Language Models For Taxonomy Construction", "topic_distr": {"0": 0.04273238405585289, "1": 0.0007958666537888348, "2": 0.1153518557548523, "3": 0.2665530741214752, "4": 0.0005138352862559259, "5": 0.00045958615373820066, "6": 0.06576408445835114, "7": 0.00037946380325593054, "8": 0.0003490388917271048, "9": 0.02952890284359455, "10": 0.00030080287251621485, "11": 0.000281361339148134, "12": 0.2931964695453644, "13": 0.0002491544291842729, "14": 0.00023566631716676056, "15": 0.000223563562030904, "16": 0.07075745612382889, "17": 0.11194828897714615, "18": 0.0001937181514222175, "19": 0.000185465018148534}}, {"key": "chen2023scaling", "year": "2023", "title": "Internvl: Scaling Up Vision Foundation Models And Aligning For Generic Visual-linguistic Tasks", "topic_distr": {"0": 0.0019190502353012562, "1": 0.0015670245047658682, "2": 0.001324456068687141, "3": 0.11176257580518723, "4": 0.001011761836707592, "5": 0.022865425795316696, "6": 0.0008185310289263725, "7": 0.0007471814169548452, "8": 0.0006872733938507736, "9": 0.12914976477622986, "10": 0.000592294498346746, "11": 0.0005540131824091077, "12": 0.10130625218153, "13": 0.09862817823886871, "14": 0.059976521879434586, "15": 0.0004402067861519754, "16": 0.0004187040904071182, "17": 0.0003992042038589716, "18": 0.4654664397239685, "19": 0.0003651890147011727}}, {"key": "chen2023teaching", "year": "2023", "title": "Teaching Large Language Models To Self-debug", "topic_distr": {"0": 0.0011344411177560687, "1": 0.0009258621139451861, "2": 0.0007826846558600664, "3": 0.6276216506958008, "4": 0.0005978833069093525, "5": 0.045095294713974, "6": 0.19810079038143158, "7": 0.0004415344155859202, "8": 0.000406132749048993, "9": 0.0003759866231121123, "10": 0.0003500065649859607, "11": 0.00032738488516770303, "12": 0.00030750976293347776, "13": 0.06751856207847595, "14": 0.013331152498722076, "15": 0.00026013285969384015, "16": 0.0002474262146279216, "17": 0.0002359030768275261, "18": 0.00022540549980476499, "19": 0.041714299470186234}}, {"key": "chen2023transforming", "year": "2023", "title": "NL2TL: Transforming Natural Languages To Temporal Logics Using Large Language Models", "topic_distr": {"0": 0.0012114729033783078, "1": 0.03577297925949097, "2": 0.0008359396015293896, "3": 0.292277067899704, "4": 0.0006385587621480227, "5": 0.03670203313231468, "6": 0.0005166042246855795, "7": 0.0004715729446616024, "8": 0.00043376284884288907, "9": 0.10170765221118927, "10": 0.0455939806997776, "11": 0.1530030518770218, "12": 0.06816627085208893, "13": 0.06391316652297974, "14": 0.0760887861251831, "15": 0.00027783025871030986, "16": 0.00026425914256833494, "17": 0.00025195206399075687, "18": 0.07959486544132233, "19": 0.04227817431092262}}, {"key": "chen2023unified", "year": "2023", "title": "A Unified Generative Retriever For Knowledge-intensive Language Tasks Via Prompt Learning", "topic_distr": {"0": 0.0010142649989575148, "1": 0.0008279825560748577, "2": 0.23148570954799652, "3": 0.0006062482134439051, "4": 0.0005346863763406873, "5": 0.00047823748900555074, "6": 0.00043256973731331527, "7": 0.00039486357127316296, "8": 0.2224535346031189, "9": 0.0003362442657817155, "10": 0.00031301035778596997, "11": 0.0002927797904703766, "12": 0.00027500552823767066, "13": 0.00025926585658453405, "14": 0.0002452303597237915, "15": 0.11498349159955978, "16": 0.06819000840187073, "17": 0.3564823269844055, "18": 0.00020157979452051222, "19": 0.00019299173436593264}}, {"key": "chen2023unlearn", "year": "2023", "title": "Unlearn What You Want To Forget: Efficient Unlearning For Llms", "topic_distr": {"0": 0.0016212357440963387, "1": 0.1118372231721878, "2": 0.34783774614334106, "3": 0.054795537143945694, "4": 0.0008541160495951772, "5": 0.0007639423129148781, "6": 0.0006909922230988741, "7": 0.025600368157029152, "8": 0.0005801863735541701, "9": 0.08413591235876083, "10": 0.1624598205089569, "11": 0.0004676900280173868, "12": 0.0004392972041387111, "13": 0.0947982668876648, "14": 0.00039173397817648947, "15": 0.0003716162755154073, "16": 0.11138702929019928, "17": 0.0003370025078766048, "18": 0.00032200603163801134, "19": 0.00030828735907562077}}, {"key": "chen2023visual", "year": "2023", "title": "LL3DA: Visual Interactive Instruction Tuning For Omni-3d Understanding, Reasoning, And Planning", "topic_distr": {"0": 0.0014678006991744041, "1": 0.0011981839779764414, "2": 0.0010129294823855162, "3": 0.17727233469486237, "4": 0.0007737596170045435, "5": 0.0006920700543560088, "6": 0.0006259832880459726, "7": 0.0005714176804758608, "8": 0.0005256021395325661, "9": 0.11179254949092865, "10": 0.00045296570169739425, "11": 0.07656938582658768, "12": 0.000397967902245, "13": 0.14932440221309662, "14": 0.00035487941931933165, "15": 0.00033665442606434226, "16": 0.00032020994694903493, "17": 0.0003052971151191741, "18": 0.47572633624076843, "19": 0.0002792835293803364}}, {"key": "chen2023when", "year": "2023", "title": "When Large Language Models Meet Personalization: Perspectives Of Challenges And Opportunities", "topic_distr": {"0": 0.0010403887135908008, "1": 0.0008487508166581392, "2": 0.0007175178616307676, "3": 0.21035848557949066, "4": 0.10807812213897705, "5": 0.000490231323055923, "6": 0.00044341827742755413, "7": 0.00040476646972820163, "8": 0.00037231281748972833, "9": 0.41102129220962524, "10": 0.0003208604466635734, "11": 0.04823421314358711, "12": 0.10269596427679062, "13": 0.06859007477760315, "14": 0.000251380552072078, "15": 0.00023847079137340188, "16": 0.045273009687662125, "17": 0.0002162586897611618, "18": 0.00020663527538999915, "19": 0.00019783183233812451}}, {"key": "chen2024bge", "year": "2024", "title": "BGE M3-embedding: Multi-lingual, Multi-functionality, Multi-granularity Text Embeddings Through Self-knowledge Distillation", "topic_distr": {"0": 0.0014176082331687212, "1": 0.001157426624558866, "2": 0.14916807413101196, "3": 0.0008474569185636938, "4": 0.0007474215235561132, "5": 0.0006685130065307021, "6": 0.03946457430720329, "7": 0.000551967415958643, "8": 0.09180999547243118, "9": 0.0004700253193732351, "10": 0.2350853681564331, "11": 0.0004092676972504705, "12": 0.00038442161167040467, "13": 0.2518410086631775, "14": 0.0003427998162806034, "15": 0.0003251951711717993, "16": 0.0003093104169238359, "17": 0.0002949052141048014, "18": 0.22443482279777527, "19": 0.00026977708330377936}}, {"key": "chen2024hallucination", "year": "2024", "title": "Hallucination Detection: Robustly Discerning Reliable Answers In Large Language Models", "topic_distr": {"0": 0.37512052059173584, "1": 0.0010394032578915358, "2": 0.0008785149548202753, "3": 0.2355748862028122, "4": 0.0006710957968607545, "5": 0.047600749880075455, "6": 0.0005429270677268505, "7": 0.0004956012708134949, "8": 0.10519304871559143, "9": 0.0004220269911456853, "10": 0.00039286562241613865, "11": 0.00036747384001500905, "12": 0.11854992806911469, "13": 0.0003254098119214177, "14": 0.016828592866659164, "15": 0.09495917707681656, "16": 0.0002777240879368037, "17": 0.0002647899091243744, "18": 0.00025300687411800027, "19": 0.0002422278339508921}}, {"key": "chen2024how", "year": "2024", "title": "How Far Are We To GPT-4V? Closing The Gap To Commercial Multimodal Models With Open-source Suites", "topic_distr": {"0": 0.0014497983502224088, "1": 0.0011842484818771482, "2": 0.0010010681580752134, "3": 0.1854056417942047, "4": 0.0007647097227163613, "5": 0.05316118896007538, "6": 0.0006186626851558685, "7": 0.0005647352081723511, "8": 0.014685943722724915, "9": 0.00048089769552461803, "10": 0.00044766845530830324, "11": 0.00041873464942909777, "12": 0.2249673455953598, "13": 0.00037080288166180253, "14": 0.08089345693588257, "15": 0.0003327174053993076, "16": 0.0003164652152918279, "17": 0.0003017268027178943, "18": 0.43235814571380615, "19": 0.00027601743931882083}}, {"key": "chen2024pixart", "year": "2024", "title": "Pixart-\\sigma: Weak-to-strong Training Of Diffusion Transformer For 4K Text-to-image Generation", "topic_distr": {"0": 0.001223062165081501, "1": 0.057719822973012924, "2": 0.0008441056706942618, "3": 0.0007310832152143121, "4": 0.00064478674903512, "5": 0.0005767136462964118, "6": 0.000521642214152962, "7": 0.10663576424121857, "8": 0.0004379929159767926, "9": 0.08872247487306595, "10": 0.04015669599175453, "11": 0.00035306744393892586, "12": 0.0003316332004033029, "13": 0.2966775894165039, "14": 0.0002957268734462559, "15": 0.0002805396798066795, "16": 0.00026683619944378734, "17": 0.040465716272592545, "18": 0.36288201808929443, "19": 0.00023273155966307968}}, {"key": "cheng2019robust", "year": "2019", "title": "Robust Neural Machine Translation With Doubly Adversarial Inputs", "topic_distr": {"0": 0.0020106693264096975, "1": 0.34031862020492554, "2": 0.11959066241979599, "3": 0.025531325489282608, "4": 0.0010607854928821325, "5": 0.0009487943025305867, "6": 0.00085819250671193, "7": 0.04972166568040848, "8": 0.0007205748115666211, "9": 0.0006670884904451668, "10": 0.000620993843767792, "11": 0.0005808576242998242, "12": 0.0005455944919958711, "13": 0.052809495478868484, "14": 0.4019128084182739, "15": 0.00046153677976690233, "16": 0.00043899216689169407, "17": 0.0004185474244877696, "18": 0.00039992225356400013, "19": 0.00038288405630737543}}, {"key": "cheng2020robust", "year": "2020", "title": "Advaug: Robust Adversarial Augmentation For Neural Machine Translation", "topic_distr": {"0": 0.0019195906352251768, "1": 0.18990233540534973, "2": 0.4443604052066803, "3": 0.0011472880141809583, "4": 0.0010118680074810982, "5": 0.0009050403023138642, "6": 0.022686369717121124, "7": 0.0007472594152204692, "8": 0.000687345105689019, "9": 0.026795072481036186, "10": 0.0005923563148826361, "11": 0.0005540710408240557, "12": 0.000520434114150703, "13": 0.0004906475660391152, "14": 0.3056749701499939, "15": 0.0004402527119964361, "16": 0.00041874777525663376, "17": 0.00039924588054418564, "18": 0.0003814796218648553, "19": 0.00036522714071907103}}, {"key": "cheng2021effective", "year": "2021", "title": "An Effective Non-autoregressive Model For Spoken Language Understanding", "topic_distr": {"0": 0.0015215803869068623, "1": 0.0012420143466442823, "2": 0.23626503348350525, "3": 0.0009093938861042261, "4": 0.0008020491804927588, "5": 0.07508321851491928, "6": 0.2734279930591583, "7": 0.0005923093413002789, "8": 0.0005448187002912164, "9": 0.0005043782875873148, "10": 0.22500894963741302, "11": 0.00043918006122112274, "12": 0.00041251801303587854, "13": 0.08159937709569931, "14": 0.0003678541979752481, "15": 0.0003489628725219518, "16": 0.10002207010984421, "17": 0.000316459103487432, "18": 0.00030237683677114546, "19": 0.0002894944336730987}}, {"key": "cheng2022binding", "year": "2022", "title": "Binding Language Models In Symbolic Languages", "topic_distr": {"0": 0.0011441829847171903, "1": 0.04041566327214241, "2": 0.0007899037445895374, "3": 0.5369681119918823, "4": 0.04131705313920975, "5": 0.10539905726909637, "6": 0.06353631615638733, "7": 0.000445603858679533, "8": 0.04786532372236252, "9": 0.0003794519288931042, "10": 0.0003532324335537851, "11": 0.00033040225389413536, "12": 0.00031034398125484586, "13": 0.00029258173890411854, "14": 0.0002767426485661417, "15": 0.0002625304041430354, "16": 0.00024970664526335895, "17": 0.09879482537508011, "18": 0.00022748297487851232, "19": 0.06064145267009735}}, {"key": "cheng2022recipe", "year": "2022", "title": "Vindlu: A Recipe For Effective Video-and-language Pretraining", "topic_distr": {"0": 0.0010666915914043784, "1": 0.0008705161162652075, "2": 0.10880167037248611, "3": 0.14961044490337372, "4": 0.0005621142336167395, "5": 0.0005027694278396666, "6": 0.00045475919614546, "7": 0.00041511881863698363, "8": 0.0003818351251538843, "9": 0.0003534925344865769, "10": 0.0003290667955297977, "11": 0.00030779847293160856, "12": 0.00028911244589835405, "13": 0.0002725653466768563, "14": 0.00025780987925827503, "15": 0.0002445699356030673, "16": 0.0002326234825886786, "17": 0.000221789741772227, "18": 0.25900357961654663, "19": 0.47582170367240906}}, {"key": "cheng2023batch", "year": "2023", "title": "Batch Prompting: Efficient Inference With Large Language Model Apis", "topic_distr": {"0": 0.0012725023552775383, "1": 0.001039308961480856, "2": 0.0008785288664512336, "3": 0.5465356111526489, "4": 0.0006710926536470652, "5": 0.0006002431618981063, "6": 0.0005429250304587185, "7": 0.0004955994663760066, "8": 0.012802655808627605, "9": 0.0004220254486426711, "10": 0.00039286419632844627, "11": 0.00036747250123880804, "12": 0.00034516374580562115, "13": 0.337904691696167, "14": 0.000307792448438704, "15": 0.0002919856342487037, "16": 0.0002777230693027377, "17": 0.09435659646987915, "18": 0.0002530059718992561, "19": 0.00024222694628406316}}, {"key": "cheong2024am", "year": "2024", "title": "(A)I Am Not A Lawyer, But...: Engaging Legal Experts Towards Responsible LLM Policies For Legal Advice", "topic_distr": {"0": 0.21228861808776855, "1": 0.0008280891925096512, "2": 0.0007000037003308535, "3": 0.11322885006666183, "4": 0.02781621366739273, "5": 0.00047826539957895875, "6": 0.0004325950867496431, "7": 0.00039488670881837606, "8": 0.053497180342674255, "9": 0.5655553340911865, "10": 0.0003130286931991577, "11": 0.0002927969617303461, "12": 0.0002750216517597437, "13": 0.00025928104878403246, "14": 0.0002452447370160371, "15": 0.00023265006893780082, "16": 0.022556394338607788, "17": 0.000210980128031224, "18": 0.00020159161067567766, "19": 0.0001930030557559803}}, {"key": "cherti2022reproducible", "year": "2022", "title": "Reproducible Scaling Laws For Contrastive Language-image Learning", "topic_distr": {"0": 0.17372815310955048, "1": 0.0009178047766909003, "2": 0.10235452651977539, "3": 0.0006718336371704936, "4": 0.0005925277364440262, "5": 0.0005299721378833055, "6": 0.00047936433111317456, "7": 0.0004375791468191892, "8": 0.000402494624722749, "9": 0.026245687156915665, "10": 0.0003468712093308568, "11": 0.0003244521503802389, "12": 0.11664693802595139, "13": 0.369352787733078, "14": 0.00027175890863873065, "15": 0.00025780260330066085, "16": 0.0002452097542118281, "17": 0.0002337898622499779, "18": 0.17064116895198822, "19": 0.035319238901138306}}, {"key": "chevalierboisvert2018platform", "year": "2018", "title": "Babyai: A Platform To Study The Sample Efficiency Of Grounded Language Learning", "topic_distr": {"0": 0.0013292923104017973, "1": 0.11889039725065231, "2": 0.0009159676264971495, "3": 0.0007933340384624898, "4": 0.0006996873999014497, "5": 0.0006258186185732484, "6": 0.07584740221500397, "7": 0.0005167161580175161, "8": 0.00047528650611639023, "9": 0.1374288946390152, "10": 0.0004096034972462803, "11": 0.37329500913619995, "12": 0.00035987060982733965, "13": 0.19259458780288696, "14": 0.0003209069836884737, "15": 0.09441523253917694, "16": 0.00028955639572814107, "17": 0.00027607116498984396, "18": 0.0002637861471157521, "19": 0.00025254784850403666}}, {"key": "chew2023llm", "year": "2023", "title": "Llm-assisted Content Analysis: Using Large Language Models To Support Deductive Coding", "topic_distr": {"0": 0.12115547060966492, "1": 0.09564924985170364, "2": 0.0006943127373233438, "3": 0.46220511198043823, "4": 0.0005303704529069364, "5": 0.00047437730245292187, "6": 0.00042907826718874276, "7": 0.0003916764399036765, "8": 0.024876978248357773, "9": 0.2911683917045593, "10": 0.0003104838833678514, "11": 0.00029041661764495075, "12": 0.0002727858372963965, "13": 0.0002571732038632035, "14": 0.00024325097911059856, "15": 0.0002307587128598243, "16": 0.0002194868866354227, "17": 0.0002092649374390021, "18": 0.00019995275943074375, "19": 0.00019143401004839689}}, {"key": "chi2019cross", "year": "2019", "title": "Cross-lingual Natural Language Generation Via Pre-training", "topic_distr": {"0": 0.001949399127624929, "1": 0.0015918777789920568, "2": 0.28597819805145264, "3": 0.0011651995591819286, "4": 0.0010276581160724163, "5": 0.0009191625867970288, "6": 0.0008313902653753757, "7": 0.12287957966327667, "8": 0.07079575955867767, "9": 0.0006462546880356967, "10": 0.2662729322910309, "11": 0.0005627168575301766, "12": 0.0005285550723783672, "13": 0.0004983037360943854, "14": 0.24231673777103424, "15": 0.0004471225256565958, "16": 0.00042528199264779687, "17": 0.00040547578828409314, "18": 0.00038743228651583195, "19": 0.00037092622369527817}}, {"key": "chi2019just", "year": "2019", "title": "Just Ask:an Interactive Learning Framework For Vision And Language Navigation", "topic_distr": {"0": 0.07638487219810486, "1": 0.07401109486818314, "2": 0.14049023389816284, "3": 0.039152733981609344, "4": 0.08400849997997284, "5": 0.0005115453386679292, "6": 0.0004626970330718905, "7": 0.00042236471199430525, "8": 0.04204805940389633, "9": 0.0003596627211663872, "10": 0.00033481064019724727, "11": 0.4718190133571625, "12": 0.0002941589045803994, "13": 0.000277322978945449, "14": 0.00026230994262732565, "15": 0.00024883891455829144, "16": 0.017283229157328606, "17": 0.0002256610750919208, "18": 0.05119650065898895, "19": 0.000206433076527901}}, {"key": "chi2021multilingual", "year": "2021", "title": "MT6: Multilingual Pretrained Text-to-text Transformer With Translation Pairs", "topic_distr": {"0": 0.0021487008780241013, "1": 0.0017558089457452297, "2": 0.0014844272518530488, "3": 0.028005758300423622, "4": 0.0011339246993884444, "5": 0.0010142121464014053, "6": 0.0009173635044135153, "7": 0.0008373989257961512, "8": 0.04770675301551819, "9": 0.0007130832527764142, "10": 0.265998512506485, "11": 0.0006209068815223873, "12": 0.0005832124152220786, "13": 0.0005498328246176243, "14": 0.41658127307891846, "15": 0.06304948031902313, "16": 0.00046926000504754484, "17": 0.16559329628944397, "18": 0.00042749629938043654, "19": 0.0004092833260074258}}, {"key": "chi2021xlm", "year": "2021", "title": "XLM-E: Cross-lingual Language Model Pre-training Via ELECTRA", "topic_distr": {"0": 0.003778638318181038, "1": 0.003086030250415206, "2": 0.0026091088075190783, "3": 0.0022597406059503555, "4": 0.0019930070266127586, "5": 0.001782599021680653, "6": 0.001612375839613378, "7": 0.0014718285528942943, "8": 0.0013538191560655832, "9": 0.001253328868187964, "10": 0.39760059118270874, "11": 0.0010913178557530046, "12": 0.0010250654304400086, "13": 0.10788127034902573, "14": 0.261188268661499, "15": 0.20693109929561615, "16": 0.000824780436232686, "17": 0.0007863687351346016, "18": 0.0007513756863772869, "19": 0.0007193642668426037}}, {"key": "chia2023towards", "year": "2023", "title": "INSTRUCTEVAL: Towards Holistic Evaluation Of Instruction-tuned Large Language Models", "topic_distr": {"0": 0.08742861449718475, "1": 0.03604631870985031, "2": 0.00074220314854756, "3": 0.3447207808494568, "4": 0.0005669615347869694, "5": 0.0005071048508398235, "6": 0.00045868061715736985, "7": 0.0004186983860563487, "8": 0.00038512767059728503, "9": 0.1481924057006836, "10": 0.00033190433168783784, "11": 0.03585534170269966, "12": 0.3038695752620697, "13": 0.02476343885064125, "14": 0.00026003297534771264, "15": 0.0002466788573656231, "16": 0.00023462939134333283, "17": 0.0002237022272311151, "18": 0.00021374758216552436, "19": 0.014534017071127892}}, {"key": "chiang2023can", "year": "2023", "title": "Can Large Language Models Be An Alternative To Human Evaluations?", "topic_distr": {"0": 0.30055269598960876, "1": 0.060561295598745346, "2": 0.0007056430331431329, "3": 0.3601994514465332, "4": 0.0005390449077822268, "5": 0.000482135743368417, "6": 0.0004360958992037922, "7": 0.109318807721138, "8": 0.025561755523085594, "9": 0.00033898523543030024, "10": 0.0003155619197059423, "11": 0.028159504756331444, "12": 0.00027724727988243103, "13": 0.0002613792894408107, "14": 0.0002472293854225427, "15": 0.11120962351560593, "16": 0.00022307662584353238, "17": 0.0002126875042449683, "18": 0.00020322301134001464, "19": 0.00019456494192127138}}, {"key": "chiang2024chatbot", "year": "2024", "title": "Chatbot Arena: An Open Platform For Evaluating Llms By Human Preference", "topic_distr": {"0": 0.10479392856359482, "1": 0.0012127069057896733, "2": 0.0010249183978885412, "3": 0.1355469673871994, "4": 0.14191707968711853, "5": 0.09092598408460617, "6": 0.0006334105273708701, "7": 0.0005781974759884179, "8": 0.009095982648432255, "9": 0.20795251429080963, "10": 0.0004583400732371956, "11": 0.000428716535679996, "12": 0.13000456988811493, "13": 0.020033208653330803, "14": 0.00035909004509449005, "15": 0.15382365882396698, "16": 0.0003240091900806874, "17": 0.0003089194360654801, "18": 0.0002951726783066988, "19": 0.00028259720420464873}}, {"key": "chintagunta2021medically", "year": "2021", "title": "Medically Aware GPT-3 As A Data Generator For Medical Dialogue Summarization", "topic_distr": {"0": 0.0014856179477646947, "1": 0.3231534957885742, "2": 0.31752675771713257, "3": 0.0008877158397808671, "4": 0.0007829305832274258, "5": 0.046944510191679, "6": 0.0006334029021672904, "7": 0.16973204910755157, "8": 0.08519186079502106, "9": 0.0004923554952256382, "10": 0.0004583345726132393, "11": 0.00042871138430200517, "12": 0.049992259591817856, "13": 0.00037963761133141816, "14": 0.00035908573772758245, "15": 0.00034064470673911273, "16": 0.0003240052901674062, "17": 0.0003089157398790121, "18": 0.0002951691276393831, "19": 0.0002825937990564853}}, {"key": "cho2019mixture", "year": "2019", "title": "Mixture Content Selection For Diverse Sequence Generation", "topic_distr": {"0": 0.0012350525939837098, "1": 0.0010084104724228382, "2": 0.0008524224394932389, "3": 0.0007382979383692145, "4": 0.0006511486717499793, "5": 0.0005824046093039215, "6": 0.0005267898668535054, "7": 0.3282797634601593, "8": 0.036532554775476456, "9": 0.00040948326932266355, "10": 0.4174695611000061, "11": 0.0003565515798982233, "12": 0.0003349058097228408, "13": 0.20943377912044525, "14": 0.0002986451727338135, "15": 0.0002833080943673849, "16": 0.0002694693976081908, "17": 0.0002569196803960949, "18": 0.00024548688088543713, "19": 0.00023502820113208145}}, {"key": "cho2020x", "year": "2020", "title": "X-LXMERT: Paint, Caption And Answer Questions With Multi-modal Transformers", "topic_distr": {"0": 0.0014182928716763854, "1": 0.0011575164971873164, "2": 0.26558834314346313, "3": 0.0008474027854390442, "4": 0.0007473709410987794, "5": 0.0006684687687084079, "6": 0.0006046355119906366, "7": 0.0005519307451322675, "8": 0.09985985606908798, "9": 0.00046999409096315503, "10": 0.12321426719427109, "11": 0.00040924051427282393, "12": 0.00038439605850726366, "13": 0.0003623955126386136, "14": 0.00034277705708518624, "15": 0.06703215092420578, "16": 0.0003092898696195334, "17": 0.00029488562722690403, "18": 0.43546706438064575, "19": 0.00026975918444804847}}, {"key": "cho2021unifying", "year": "2021", "title": "Unifying Vision-and-language Tasks Via Text Generation", "topic_distr": {"0": 0.00118687201756984, "1": 0.0009698054054751992, "2": 0.31976544857025146, "3": 0.0007101331721059978, "4": 0.0006263082032091916, "5": 0.0005601863958872855, "6": 0.0005066933808848262, "7": 0.0004625260189641267, "8": 0.08118010312318802, "9": 0.000393861933844164, "10": 0.00036664673825725913, "11": 0.00034294952638447285, "12": 0.00032212951919063926, "13": 0.0003036927373614162, "14": 0.00028725218726322055, "15": 0.12978212535381317, "16": 0.00025918942992575467, "17": 0.156564399600029, "18": 0.3051835894584656, "19": 0.0002260621404275298}}, {"key": "cho2022dall", "year": "2022", "title": "Dall-eval: Probing The Reasoning Skills And Social Biases Of Text-to-image Generation Models", "topic_distr": {"0": 0.1753917634487152, "1": 0.0009175774175673723, "2": 0.0007755972328595817, "3": 0.2354332059621811, "4": 0.0005924803554080427, "5": 0.0005299291806295514, "6": 0.00047932544839568436, "7": 0.09956243634223938, "8": 0.000402461999328807, "9": 0.00037258831434883177, "10": 0.04683063551783562, "11": 0.03758629411458969, "12": 0.0003047304053325206, "13": 0.00028728944016620517, "14": 0.0002717368770390749, "15": 0.0002577817067503929, "16": 0.00024518987629562616, "17": 0.00023377090110443532, "18": 0.37938234210014343, "19": 0.02014285884797573}}, {"key": "choe2019bridging", "year": "2019", "title": "Bridging The Gap For Tokenizer-free Language Models", "topic_distr": {"0": 0.0025446149520576, "1": 0.0020786463283002377, "2": 0.4307153820991516, "3": 0.0015218004118651152, "4": 0.0013421602779999375, "5": 0.0012004635063931346, "6": 0.00108582922257483, "7": 0.0009911798406392336, "8": 0.0009117082809098065, "9": 0.0008440346573479474, "10": 0.18401753902435303, "11": 0.0007349308580160141, "12": 0.000690314220264554, "13": 0.13956318795681, "14": 0.0006155730807222426, "15": 0.0005839600344188511, "16": 0.0539541132748127, "17": 0.0005295677110552788, "18": 0.0005060021649114788, "19": 0.17556896805763245}}, {"key": "choi2018fine", "year": "2018", "title": "Fine-grained Attention Mechanism For Neural Machine Translation", "topic_distr": {"0": 0.0018095560371875763, "1": 0.0014759248588234186, "2": 0.657483696937561, "3": 0.0010807354701682925, "4": 0.000953169132117182, "5": 0.0008525393204763532, "6": 0.0007711290963925421, "7": 0.0007039114716462791, "8": 0.000647472741547972, "9": 0.0005994125967845321, "10": 0.0005579941789619625, "11": 0.0005219297599978745, "12": 0.000490244128741324, "13": 0.00046218547504395247, "14": 0.3297014832496643, "15": 0.0004147140134591609, "16": 0.00039445655420422554, "17": 0.00037608592538163066, "18": 0.0003593502624426037, "19": 0.00034404059988446534}}, {"key": "choi2023do", "year": "2023", "title": "Do Llms Understand Social Knowledge? Evaluating The Sociability Of Large Language Models With Socket Benchmark", "topic_distr": {"0": 0.22691120207309723, "1": 0.04366721212863922, "2": 0.0008697094162926078, "3": 0.2369653880596161, "4": 0.0006643527885898948, "5": 0.000594214943703264, "6": 0.05175815522670746, "7": 0.0004906220128759742, "8": 0.0004512845480348915, "9": 0.07063261419534683, "10": 0.0003889185609295964, "11": 0.03730953112244606, "12": 0.30876410007476807, "13": 0.000322140462230891, "14": 0.0003047012141905725, "15": 0.00028905313229188323, "16": 0.00027493381639942527, "17": 0.0002621295861899853, "18": 0.00025046494556590915, "19": 0.018829260021448135}}, {"key": "choudhury2024large", "year": "2024", "title": "Large Language Models And User Trust: Consequence Of Self-referential Learning Loop And The Deskilling Of Healthcare Professionals", "topic_distr": {"0": 0.35442909598350525, "1": 0.0646628811955452, "2": 0.0007359358132816851, "3": 0.0006374212098307908, "4": 0.0005621786694973707, "5": 0.010629255324602127, "6": 0.00045480954577215016, "7": 0.0004151647735852748, "8": 0.0003818774130195379, "9": 0.5645209550857544, "10": 0.0003291032335255295, "11": 0.0003078325535170734, "12": 0.00028914446011185646, "13": 0.00027259555645287037, "14": 0.0002578384301159531, "15": 0.0002445970312692225, "16": 0.0002326492394786328, "17": 0.00022181430540513247, "18": 0.0002119436685461551, "19": 0.0002029140741797164}}, {"key": "chowdhery2022scaling", "year": "2022", "title": "Palm: Scaling Language Modeling With Pathways", "topic_distr": {"0": 0.12823453545570374, "1": 0.0698929950594902, "2": 0.0007686807657591999, "3": 0.05262412875890732, "4": 0.0005871847970411181, "5": 0.0005251930560916662, "6": 0.0004750415391754359, "7": 0.0004336331912782043, "8": 0.0003988650278188288, "9": 0.00036925837048329413, "10": 0.04719017818570137, "11": 0.00032152634230442345, "12": 0.15332360565662384, "13": 0.33047473430633545, "14": 0.08052411675453186, "15": 0.06358206272125244, "16": 0.00024299853248521686, "17": 0.00023168160987552255, "18": 0.00022137188352644444, "19": 0.06957816332578659}}, {"key": "christmann2022conversational", "year": "2022", "title": "Conversational Question Answering On Heterogeneous Sources", "topic_distr": {"0": 0.0014850794104859233, "1": 0.0012128724483773112, "2": 0.0010250774212181568, "3": 0.11397644877433777, "4": 0.051348473876714706, "5": 0.0007003704085946083, "6": 0.2332102656364441, "7": 0.0005782709340564907, "8": 0.24677519500255585, "9": 0.0004924239474348724, "10": 0.0004583982808981091, "11": 0.00042877098894678056, "12": 0.0004027408722322434, "13": 0.0003796903765760362, "14": 0.00035913565079681575, "15": 0.07241246849298477, "16": 0.23830312490463257, "17": 0.0003089586680289358, "18": 0.00029521016404032707, "19": 0.035847049206495285}}, {"key": "christopoulou2022pangu", "year": "2022", "title": "Pangu-coder: Program Synthesis With Function-level Language Modeling", "topic_distr": {"0": 0.17042995989322662, "1": 0.08364765346050262, "2": 0.001103847287595272, "3": 0.15813083946704865, "4": 0.0008432074100710452, "5": 0.0007541867671534419, "6": 0.27784600853919983, "7": 0.0006227050325833261, "8": 0.0005727773532271385, "9": 0.0005302616627886891, "10": 0.09991498291492462, "11": 0.00046171760186553, "12": 0.0004336873535066843, "13": 0.04422236979007721, "14": 0.00038673149538226426, "15": 0.00036687072133645415, "16": 0.00034895027056336403, "17": 0.15876103937625885, "18": 0.00031789400964044034, "19": 0.00030435051303356886}}, {"key": "chrysostomou2021improving", "year": "2021", "title": "Improving The Faithfulness Of Attention-based Explanations With Task-specific Information For Text Classification", "topic_distr": {"0": 0.00137052102945745, "1": 0.07883124053478241, "2": 0.4106386601924896, "3": 0.0008194142137654126, "4": 0.0007226874004118145, "5": 0.16663336753845215, "6": 0.0005846656858921051, "7": 0.1609276533126831, "8": 0.0004909101407974958, "9": 0.00045447121374309063, "10": 0.175645112991333, "11": 0.00039572420064359903, "12": 0.0003717002982739359, "13": 0.0003504263877402991, "14": 0.00033145587076433003, "15": 0.00031443379702977836, "16": 0.00029907471616752446, "17": 0.00028514620498754084, "18": 0.00027245734236203134, "19": 0.0002608496288303286}}, {"key": "chu2020multi", "year": "2020", "title": "Multi-step Joint-modality Attention Network For Scene-aware Dialogue System", "topic_distr": {"0": 0.001684848335571587, "1": 0.001375923166051507, "2": 0.3488270938396454, "3": 0.0010075966129079461, "4": 0.09720195084810257, "5": 0.12210891395807266, "6": 0.034311242401599884, "7": 0.0006562724593095481, "8": 0.0006036533741280437, "9": 0.0005588458152487874, "10": 0.0005202305037528276, "11": 0.0004866068484261632, "12": 0.0004570655873976648, "13": 0.0004309058713261038, "14": 0.0004075785691384226, "15": 0.0003866471815854311, "16": 0.0003677606873679906, "17": 0.00035063334507867694, "18": 0.3879355192184448, "19": 0.00032075674971565604}}, {"key": "chu2022meta", "year": "2022", "title": "Meta Policy Learning For Cold-start Conversational Recommendation", "topic_distr": {"0": 0.0011229533702135086, "1": 0.0009174366714432836, "2": 0.0007755898404866457, "3": 0.0006717591895721853, "4": 0.7450539469718933, "5": 0.0005299162585288286, "6": 0.00047931363224051893, "7": 0.00043753290083259344, "8": 0.00040245207492262125, "9": 0.0003725791466422379, "10": 0.06397969275712967, "11": 0.18321916460990906, "12": 0.0003047228674404323, "13": 0.0002872823679354042, "14": 0.00027173018315806985, "15": 0.0002577753330115229, "16": 0.00024518382269889116, "17": 0.0002337651385460049, "18": 0.00022336270194500685, "19": 0.0002138466079486534}}, {"key": "chuang2023debiasing", "year": "2023", "title": "Debiasing Vision-language Models Via Biased Prompts", "topic_distr": {"0": 0.2401949018239975, "1": 0.0015205350937321782, "2": 0.2399432212114334, "3": 0.0011129943886771798, "4": 0.0009816139936447144, "5": 0.0008779811323620379, "6": 0.0007941413787193596, "7": 0.0007249178597703576, "8": 0.0006667948910035193, "9": 0.0006173005094751716, "10": 0.0005746460519731045, "11": 0.0005375054315663874, "12": 0.0005048741586506367, "13": 0.06939966976642609, "14": 0.00045021084952168167, "15": 0.13251037895679474, "16": 0.0004062280640937388, "17": 0.13918931782245636, "18": 0.1686384081840515, "19": 0.00035430758725851774}}, {"key": "chuang2023soft", "year": "2023", "title": "Spec: A Soft Prompt-based Calibration On Performance Variability Of Large Language Model In Clinical Notes Summarization", "topic_distr": {"0": 0.0012235604226589203, "1": 0.0813506618142128, "2": 0.0008441641693934798, "3": 0.3260848820209503, "4": 0.0006448433268815279, "5": 0.0005767637048847973, "6": 0.0005216877325437963, "7": 0.05535317212343216, "8": 0.0004380311584100127, "9": 0.18393348157405853, "10": 0.00037749670445919037, "11": 0.00035309826489537954, "12": 0.0698615089058876, "13": 0.11336709558963776, "14": 0.00029575268854387105, "15": 0.0002805641561280936, "16": 0.0513598769903183, "17": 0.11265752464532852, "18": 0.0002431092580081895, "19": 0.00023275187413673848}}, {"key": "chung2020bert", "year": "2020", "title": "A Bert-based Distractor Generation Scheme With Multi-tasking And Negative Answer Training Strategies", "topic_distr": {"0": 0.001891043153591454, "1": 0.0015431091887876391, "2": 0.18212231993675232, "3": 0.001129800919443369, "4": 0.23146158456802368, "5": 0.0008912391494959593, "6": 0.0008061332046054304, "7": 0.09015689790248871, "8": 0.06621162593364716, "9": 0.0006266218842938542, "10": 0.026257000863552094, "11": 0.0005456219078041613, "12": 0.0005124979070387781, "13": 0.00048316558240912855, "14": 0.11964302510023117, "15": 0.2741774916648865, "16": 0.00041236222023144364, "17": 0.00039315770845860243, "18": 0.00037566234823316336, "19": 0.00035965771530754864}}, {"key": "chung2020rethinking", "year": "2020", "title": "Rethinking Embedding Coupling In Pre-trained Language Models", "topic_distr": {"0": 0.001541507663205266, "1": 0.001257300260476768, "2": 0.20937635004520416, "3": 0.0009206749382428825, "4": 0.00081199238775298, "5": 0.0007262678700499237, "6": 0.0006569153629243374, "7": 0.04067996144294739, "8": 0.0005515740485861897, "9": 0.0005106321768835187, "10": 0.39002883434295654, "11": 0.0004446255334187299, "12": 0.0004176329239271581, "13": 0.3105284869670868, "14": 0.039938297122716904, "15": 0.0003532897389959544, "16": 0.0003360326518304646, "17": 0.00032038294011726975, "18": 0.0003061260504182428, "19": 0.0002930839254986495}}, {"key": "chung2022scaling", "year": "2022", "title": "Scaling Instruction-finetuned Language Models", "topic_distr": {"0": 0.0017563450383022428, "1": 0.0014344851952046156, "2": 0.0012125287903472781, "3": 0.2211509346961975, "4": 0.0009262288804166019, "5": 0.0008284438517875969, "6": 0.0007493345183320343, "7": 0.0006840166752226651, "8": 0.0006291730678640306, "9": 0.0005824712570756674, "10": 0.0005422234535217285, "11": 0.0005071783671155572, "12": 0.13996896147727966, "13": 0.2307901829481125, "14": 0.00042480911361053586, "15": 0.019197484478354454, "16": 0.0003833079244941473, "17": 0.16807766258716583, "18": 0.0003491938696242869, "19": 0.20980499684810638}}, {"key": "chung2023increasing", "year": "2023", "title": "Increasing Diversity While Maintaining Accuracy: Text Data Generation With Large Language Models And Human Interventions", "topic_distr": {"0": 0.17478685081005096, "1": 0.14494867622852325, "2": 0.0489632710814476, "3": 0.14447109401226044, "4": 0.031686779111623764, "5": 0.000600233324803412, "6": 0.0005429160664789379, "7": 0.2871621251106262, "8": 0.00045585536281578243, "9": 0.00042201843461953104, "10": 0.00039285767707042396, "11": 0.0003674664185382426, "12": 0.00034515801235102117, "13": 0.07012029737234116, "14": 0.0003077873552683741, "15": 0.00029198077390901744, "16": 0.0002777184417936951, "17": 0.09336172044277191, "18": 0.0002530017518438399, "19": 0.00024222292995546013}}, {"key": "chung2024large", "year": "2024", "title": "Large Language Model Capabilities In Perioperative Risk Prediction And Prognostication", "topic_distr": {"0": 0.002269209362566471, "1": 0.21011342108249664, "2": 0.14595353603363037, "3": 0.17525312304496765, "4": 0.0011958932736888528, "5": 0.11699637770652771, "6": 0.0009674978209659457, "7": 0.0913921669125557, "8": 0.000812352227512747, "9": 0.08161064237356186, "10": 0.0007000878686085343, "11": 0.0006548396777361631, "12": 0.0006150852423161268, "13": 0.030140802264213562, "14": 0.0005484892171807587, "15": 0.0005203213077038527, "16": 0.0004949052236042917, "17": 0.1388787478208542, "18": 0.0004508591373451054, "19": 0.0004316508420743048}}, {"key": "clark2017simple", "year": "2017", "title": "Simple And Effective Multi-paragraph Reading Comprehension", "topic_distr": {"0": 0.0019489453407004476, "1": 0.0015916230622678995, "2": 0.5263950824737549, "3": 0.0011650720844045281, "4": 0.0010275422828271985, "5": 0.0009190607815980911, "6": 0.0008312982972711325, "7": 0.12043049186468124, "8": 0.27405062317848206, "9": 0.0006461831508204341, "10": 0.0006015329854562879, "11": 0.0005626545753329992, "12": 0.0005284965736791492, "13": 0.06679409742355347, "14": 0.0004712756199296564, "15": 0.0004470730491448194, "16": 0.0004252349608577788, "17": 0.00040543091017752886, "18": 0.0003873894165735692, "19": 0.0003708851872943342}}, {"key": "clark2018think", "year": "2018", "title": "Think You Have Solved Question Answering? Try ARC, The AI2 Reasoning Challenge", "topic_distr": {"0": 0.0014190643560141325, "1": 0.001157358638010919, "2": 0.3293043375015259, "3": 0.0008473791531287134, "4": 0.000747351034078747, "5": 0.0006684500258415937, "6": 0.0006046186317689717, "7": 0.0005519153201021254, "8": 0.2803691029548645, "9": 0.049414120614528656, "10": 0.00043750606710091233, "11": 0.00040922907646745443, "12": 0.09657245129346848, "13": 0.0003623854136094451, "14": 0.000342767481924966, "15": 0.23563632369041443, "16": 0.0003092812548857182, "17": 0.0002948773908428848, "18": 0.00028175549232400954, "19": 0.0002697516465559602}}, {"key": "clark2019exploring", "year": "2019", "title": "Boolq: Exploring The Surprising Difficulty Of Natural Yes/no Questions", "topic_distr": {"0": 0.0018090482335537672, "1": 0.13427114486694336, "2": 0.4751627445220947, "3": 0.18344464898109436, "4": 0.0009531645919196308, "5": 0.0008525357698090374, "6": 0.0007711257785558701, "7": 0.0007039083866402507, "8": 0.12509329617023468, "9": 0.000599409977439791, "10": 0.0725388452410698, "11": 0.0005219275481067598, "12": 0.0004902419750578701, "13": 0.00046218346687965095, "14": 0.000437162903835997, "15": 0.0004147122090216726, "16": 0.0003944548370782286, "17": 0.0003760842955671251, "18": 0.0003593487199395895, "19": 0.00034403911558911204}}, {"key": "clark2020pre", "year": "2020", "title": "ELECTRA: Pre-training Text Encoders As Discriminators Rather Than Generators", "topic_distr": {"0": 0.0011552226496860385, "1": 0.052419666200876236, "2": 0.29787591099739075, "3": 0.000690462882630527, "4": 0.0006089597591198981, "5": 0.0005446699215099216, "6": 0.0004926585825160146, "7": 0.10170111060142517, "8": 0.00041365702054463327, "9": 0.00038295239210128784, "10": 0.2847200930118561, "11": 0.0003334502107463777, "12": 0.0003132068959530443, "13": 0.22471870481967926, "14": 0.00027929560746997595, "15": 0.00026495225029066205, "16": 0.00025201018434017897, "17": 0.03238365799188614, "18": 0.0002295815065735951, "19": 0.00021980046585667878}}, {"key": "clark2020transformers", "year": "2020", "title": "Transformers As Soft Reasoners Over Language", "topic_distr": {"0": 0.17010602355003357, "1": 0.0012127490481361747, "2": 0.001024972996674478, "3": 0.0008877454092726111, "4": 0.0007829510723240674, "5": 0.11351517587900162, "6": 0.0006334197823889554, "7": 0.0005782059160992503, "8": 0.0005318461335264146, "9": 0.05486404150724411, "10": 0.09649880230426788, "11": 0.19002777338027954, "12": 0.0004026956157758832, "13": 0.00037964771036058664, "14": 0.17551016807556152, "15": 0.00034065378713421524, "16": 0.13246941566467285, "17": 0.05965588986873627, "18": 0.0002951769856736064, "19": 0.0002826013369485736}}, {"key": "clark2021all", "year": "2021", "title": "All That's 'human' Is Not Gold: Evaluating Human Evaluation Of Generated Text", "topic_distr": {"0": 0.2570516765117645, "1": 0.10177568346261978, "2": 0.10316668450832367, "3": 0.0008194737019948661, "4": 0.12306476384401321, "5": 0.0006464363541454077, "6": 0.0005847071879543364, "7": 0.19196312129497528, "8": 0.0004909449489787221, "9": 0.00045450343168340623, "10": 0.0004230980121064931, "11": 0.00039575222763232887, "12": 0.10870764404535294, "13": 0.00035045124241150916, "14": 0.0003314793575555086, "15": 0.10865600407123566, "16": 0.00029909590375609696, "17": 0.0002851664030458778, "18": 0.00027247663820162416, "19": 0.0002608681097626686}}, {"key": "clark2021pre", "year": "2021", "title": "CANINE: Pre-training An Efficient Tokenization-free Encoder For Language Representation", "topic_distr": {"0": 0.04204827547073364, "1": 0.00139503157697618, "2": 0.37516355514526367, "3": 0.0010215097572654486, "4": 0.0009009281639009714, "5": 0.0008058130624704063, "6": 0.0007288643973879516, "7": 0.057225603610277176, "8": 0.02170442044734955, "9": 0.0005665594362653792, "10": 0.3301301896572113, "11": 0.0004933233722113073, "12": 0.00046337436651811004, "13": 0.06652989238500595, "14": 0.03294481337070465, "15": 0.0003919839800801128, "16": 0.00037283680285327137, "17": 0.06644820421934128, "18": 0.000339654681738466, "19": 0.00032518411171622574}}, {"key": "clavi\u00e92023large", "year": "2023", "title": "Large Language Models In The Workplace: A Case Study On Prompt Engineering For Job Type Classification", "topic_distr": {"0": 0.17720381915569305, "1": 0.0010835900902748108, "2": 0.0009159326436929405, "3": 0.2212628573179245, "4": 0.0006996597512625158, "5": 0.0006257934728637338, "6": 0.0005660353344865143, "7": 0.044095005840063095, "8": 0.0004752672975882888, "9": 0.10169793665409088, "10": 0.00040958693716675043, "11": 0.00038311444222927094, "12": 0.0003598560579121113, "13": 0.0003392600337974727, "14": 0.00032089403248392045, "15": 0.00030441436683759093, "16": 0.00028954469598829746, "17": 0.4484511613845825, "18": 0.0002637754660099745, "19": 0.00025253763305954635}}, {"key": "clement2020multi", "year": "2020", "title": "Pymt5: Multi-mode Translation Of Natural Language And Python Code With Transformers", "topic_distr": {"0": 0.001600010204128921, "1": 0.0013057966716587543, "2": 0.10512510687112808, "3": 0.0009560209582559764, "4": 0.0008431668975390494, "5": 0.0007541504455730319, "6": 0.2561779022216797, "7": 0.19529008865356445, "8": 0.0005727498210035264, "9": 0.04685415327548981, "10": 0.09512639045715332, "11": 0.000461695424746722, "12": 0.0004336665151640773, "13": 0.0004088460118509829, "14": 0.29241958260536194, "15": 0.00036685311351902783, "16": 0.00034893350675702095, "17": 0.0003326829755678773, "18": 0.00031787873012945056, "19": 0.0003043359029106796}}, {"key": "clinchant2019use", "year": "2019", "title": "On The Use Of BERT For Neural Machine Translation", "topic_distr": {"0": 0.15908309817314148, "1": 0.2549544870853424, "2": 0.001324487035162747, "3": 0.0011471733450889587, "4": 0.0010117576457560062, "5": 0.000904942222405225, "6": 0.0008185278275050223, "7": 0.0007471785065717995, "8": 0.0006872707162983716, "9": 0.0006362564745359123, "10": 0.1920279711484909, "11": 0.0005540110287256539, "12": 0.0005203777691349387, "13": 0.0004905944224447012, "14": 0.2569032311439514, "15": 0.00044020506902597845, "16": 0.0004187024605926126, "17": 0.0003992026613559574, "18": 0.0003814383235294372, "19": 0.12654906511306763}}, {"key": "cobbe2021training", "year": "2021", "title": "Training Verifiers To Solve Math Word Problems", "topic_distr": {"0": 0.0017590983770787716, "1": 0.20939548313617706, "2": 0.2858634293079376, "3": 0.4423500895500183, "4": 0.0009262969251722097, "5": 0.0008285042713396251, "6": 0.0007493889424949884, "7": 0.0006840662681497633, "8": 0.0006292187026701868, "9": 0.0005825135158374906, "10": 0.000542262801900506, "11": 0.0005072151543572545, "12": 0.0004764228069689125, "13": 0.000449155195383355, "14": 0.00042483993456698954, "15": 0.00040302210254594684, "16": 0.00038333574775606394, "17": 0.0003654830507002771, "18": 0.0003492192190606147, "19": 0.052330970764160156}}, {"key": "coenen2021human", "year": "2021", "title": "Wordcraft: A Human-ai Collaborative Editor For Story Writing", "topic_distr": {"0": 0.08324843645095825, "1": 0.002263415837660432, "2": 0.0019132272573187947, "3": 0.0016570661682635546, "4": 0.25687921047210693, "5": 0.0013071727007627487, "6": 0.0011823488166555762, "7": 0.13944000005722046, "8": 0.0009927501669153571, "9": 0.2328106164932251, "10": 0.040325406938791275, "11": 0.23295389115810394, "12": 0.000751676328945905, "13": 0.0007086548721417785, "14": 0.0006702914251945913, "15": 0.0006358682876452804, "16": 0.0006048081559129059, "17": 0.0005766410613432527, "18": 0.0005509807961061597, "19": 0.0005275069270282984}}, {"key": "cohan2019pretrained", "year": "2019", "title": "Pretrained Language Models For Sequential Sentence Classification", "topic_distr": {"0": 0.0016410773387178779, "1": 0.054980818182229996, "2": 0.3022664487361908, "3": 0.0009812909411266446, "4": 0.0008654572884552181, "5": 0.0007740861037746072, "6": 0.07952260226011276, "7": 0.0006391353090293705, "8": 0.0005878902738913894, "9": 0.023829232901334763, "10": 0.476406991481781, "11": 0.0004739001742564142, "12": 0.00044513033935800195, "13": 0.00041965371929109097, "14": 0.00039693553117103875, "15": 0.00037655074265785515, "16": 0.000358157412847504, "17": 0.00034147730912081897, "18": 0.000326281733578071, "19": 0.054366860538721085}}, {"key": "cohan2020document", "year": "2020", "title": "SPECTER: Document-level Representation Learning Using Citation-informed Transformers", "topic_distr": {"0": 0.0015201729256659746, "1": 0.0012420563725754619, "2": 0.1633950173854828, "3": 0.044923584908246994, "4": 0.1072499006986618, "5": 0.000717367569450289, "6": 0.0006488647777587175, "7": 0.0005923046264797449, "8": 0.0005448143929243088, "9": 0.06450077891349792, "10": 0.353392094373703, "11": 0.0004391765978652984, "12": 0.0963919460773468, "13": 0.00038890488212928176, "14": 0.0003678512875922024, "15": 0.00034896013676188886, "16": 0.10615355521440506, "17": 0.0003164566005580127, "18": 0.000302374450257048, "19": 0.05656379461288452}}, {"key": "cohen2022is", "year": "2022", "title": "\"this Is My Unicorn, Fluffy\": Personalizing Frozen Vision-language Representations", "topic_distr": {"0": 0.001417220220901072, "1": 0.0011575882090255618, "2": 0.06314351409673691, "3": 0.0008474031346850097, "4": 0.14271636307239532, "5": 0.0006684701074846089, "6": 0.0006046367343515158, "7": 0.0005519318510778248, "8": 0.0005076786619611084, "9": 0.00046999502228572965, "10": 0.00043751916382461786, "11": 0.11638607084751129, "12": 0.000384396844310686, "13": 0.000362396240234375, "14": 0.00034277772647328675, "15": 0.00032517421641387045, "16": 0.000309290480799973, "17": 0.00029488620930351317, "18": 0.5899695158004761, "19": 0.07910322397947311}}, {"key": "colas2022language", "year": "2022", "title": "Language And Culture Internalisation For Human-like Autotelic AI", "topic_distr": {"0": 0.22561083734035492, "1": 0.000960875884629786, "2": 0.0008121734717860818, "3": 0.0007034489535726607, "4": 0.0006204134551808238, "5": 0.0005549140041694045, "6": 0.000501924310810864, "7": 0.0004581726680044085, "8": 0.00042143696919083595, "9": 0.27919378876686096, "10": 0.00036319580976851285, "11": 0.4310961067676544, "12": 0.05688800290226936, "13": 0.00030083436286076903, "14": 0.00028454852872528136, "15": 0.000269935408141464, "16": 0.0002567499177530408, "17": 0.00024479255080223083, "18": 0.00023389940906781703, "19": 0.0002239344030385837}}, {"key": "collins2023evaluating", "year": "2023", "title": "Evaluating Language Models For Mathematics Through Interactions", "topic_distr": {"0": 0.2546582818031311, "1": 0.062124431133270264, "2": 0.0008360377978533506, "3": 0.36284127831459045, "4": 0.0401981845498085, "5": 0.0005712161073461175, "6": 0.035247135907411575, "7": 0.00047163275303319097, "8": 0.00043381782597862184, "9": 0.2018290013074875, "10": 0.00037386565236374736, "11": 0.03821863234043121, "12": 0.00032847197144292295, "13": 0.0003096721775364131, "14": 0.00029290790553204715, "15": 0.00027786550344899297, "16": 0.00026429264107719064, "17": 0.00025198401999659836, "18": 0.0002407708379905671, "19": 0.0002305130910826847}}, {"key": "communication2023multilingual", "year": "2023", "title": "Seamless: Multilingual Expressive And Streaming Speech Translation", "topic_distr": {"0": 0.10602236539125443, "1": 0.11466962099075317, "2": 0.06558910757303238, "3": 0.0006484974874183536, "4": 0.030002649873495102, "5": 0.0005115653038956225, "6": 0.06956393271684647, "7": 0.028894413262605667, "8": 0.0003885150363203138, "9": 0.0003596766327973455, "10": 0.00033482356229797006, "11": 0.00031318317633122206, "12": 0.1273481398820877, "13": 0.020248685032129288, "14": 0.24296416342258453, "15": 0.08078814297914505, "16": 0.03169724717736244, "17": 0.00022566979168914258, "18": 0.0792231485247612, "19": 0.0002064410364255309}}, {"key": "conneau2019unsupervised", "year": "2019", "title": "Unsupervised Cross-lingual Representation Learning At Scale", "topic_distr": {"0": 0.0015594844007864594, "1": 0.001273168483749032, "2": 0.0010761173907667398, "3": 0.0009320456883870065, "4": 0.0008220257004722953, "5": 0.0007352417451329529, "6": 0.0006650324212387204, "7": 0.0006070629460737109, "8": 0.0005583894671872258, "9": 0.0005169417127035558, "10": 0.1912790685892105, "11": 0.0004501194634940475, "12": 0.0004227932950016111, "13": 0.15512363612651825, "14": 0.581429123878479, "15": 0.0003576550807338208, "16": 0.00034018477890640497, "17": 0.0003243417013436556, "18": 0.00030990864615887403, "19": 0.061217665672302246}}, {"key": "copet2023simple", "year": "2023", "title": "Simple And Controllable Music Generation", "topic_distr": {"0": 0.001809220644645393, "1": 0.09735502302646637, "2": 0.255643755197525, "3": 0.0010807369835674763, "4": 0.0009531634277664125, "5": 0.0008525336161255836, "6": 0.0007711239159107208, "7": 0.31236961483955383, "8": 0.0006474683759734035, "9": 0.0005994085222482681, "10": 0.18142476677894592, "11": 0.0005219262675382197, "12": 0.0004902408109046519, "13": 0.00046218233183026314, "14": 0.00043716185609810054, "15": 0.0004147111903876066, "16": 0.0003944538766518235, "17": 0.0003760833933483809, "18": 0.0901651531457901, "19": 0.05323122441768646}}, {"key": "coreyes2018guiding", "year": "2018", "title": "Guiding Policies With Language Via Meta-learning", "topic_distr": {"0": 0.1287875771522522, "1": 0.0009434481617063284, "2": 0.10692451894283295, "3": 0.0415874645113945, "4": 0.02775263972580433, "5": 0.000544798094779253, "6": 0.02947075478732586, "7": 0.00044982030522078276, "8": 0.0004137542855460197, "9": 0.000383042439352721, "10": 0.0003565748338587582, "11": 0.5837715268135071, "12": 0.00031328052864409983, "13": 0.00029535024077631533, "14": 0.0002793612948153168, "15": 0.0002650145615916699, "16": 0.0002520694397389889, "17": 0.07675952464342117, "18": 0.00022963549417909235, "19": 0.00021985215425956994}}, {"key": "cornia2019meshed", "year": "2019", "title": "Meshed-memory Transformer For Image Captioning", "topic_distr": {"0": 0.035058487206697464, "1": 0.0012271031737327576, "2": 0.28302597999572754, "3": 0.0008984371670521796, "4": 0.0007923837983980775, "5": 0.0007087288540787995, "6": 0.0006410511559806764, "7": 0.03020428493618965, "8": 0.000538253749255091, "9": 0.000498300651088357, "10": 0.19984926283359528, "11": 0.0004338880244176835, "12": 0.00040754725341685116, "13": 0.0003842216683551669, "14": 0.08842740207910538, "15": 0.0003447579510975629, "16": 0.030977416783571243, "17": 0.0003126458323094994, "18": 0.3249838650226593, "19": 0.00028600607765838504}}, {"key": "cornia2019training", "year": "2019", "title": "Smart: Training Shallow Memory-aware Transformers For Robotic Explainability", "topic_distr": {"0": 0.03791915252804756, "1": 0.0012271329760551453, "2": 0.1191142201423645, "3": 0.0008984855376183987, "4": 0.0007924272795207798, "5": 0.1045476421713829, "6": 0.0006410861387848854, "7": 0.07589239627122879, "8": 0.0005382831441238523, "9": 0.0004983278340660036, "10": 0.13097549974918365, "11": 0.12969085574150085, "12": 0.05066775903105736, "13": 0.10830279439687729, "14": 0.00036344147520139813, "15": 0.0003447767812758684, "16": 0.00032793552963994443, "17": 0.0003126629162579775, "18": 0.23665912449359894, "19": 0.0002860217064153403}}, {"key": "cosler2023interactively", "year": "2023", "title": "Nl2spec: Interactively Translating Unstructured Natural Language To Temporal Logics With Large Language Models", "topic_distr": {"0": 0.0015992244007065892, "1": 0.001305841957218945, "2": 0.0011038994416594505, "3": 0.5065215826034546, "4": 0.0008432513568550348, "5": 0.11524046212434769, "6": 0.1512312889099121, "7": 0.06912802159786224, "8": 0.0005728068645112216, "9": 0.12148649990558624, "10": 0.0004936468903906643, "11": 0.0004617414087988436, "12": 0.0004337097052484751, "13": 0.00040888675721362233, "14": 0.02749832719564438, "15": 0.00036688963882625103, "16": 0.0003489682567305863, "17": 0.00033271609572693706, "18": 0.0003179103950969875, "19": 0.00030436619999818504}}, {"key": "coyne2023analyzing", "year": "2023", "title": "Analyzing The Performance Of GPT-3.5 And GPT-4 In Grammatical Error Correction", "topic_distr": {"0": 0.19742166996002197, "1": 0.0014343883376568556, "2": 0.21168117225170135, "3": 0.3627970516681671, "4": 0.0009262589737772942, "5": 0.0008284691721200943, "6": 0.0007493571611121297, "7": 0.07768131047487259, "8": 0.0006291921017691493, "9": 0.0005824888357892632, "10": 0.0005422398680821061, "11": 0.0005071936757303774, "12": 0.00047640263801440597, "13": 0.0004491361905820668, "14": 0.0004248219483997673, "15": 0.00040300501859746873, "16": 0.0003833195078186691, "17": 0.14139898121356964, "18": 0.0003492044343147427, "19": 0.00033432699274271727}}, {"key": "creswell2022faithful", "year": "2022", "title": "Faithful Reasoning Using Large Language Models", "topic_distr": {"0": 0.0015791881596669555, "1": 0.0012891707010567188, "2": 0.001089869998395443, "3": 0.6207990050315857, "4": 0.09326475858688354, "5": 0.0007446366944350302, "6": 0.0006735302158631384, "7": 0.1758764237165451, "8": 0.021715976297855377, "9": 0.000523547176271677, "10": 0.0004873709403909743, "11": 0.00045587107888422906, "12": 0.0004281957517378032, "13": 0.00040368837653659284, "14": 0.00038183448486961424, "15": 0.0003622251970227808, "16": 0.0003445316688157618, "17": 0.029328254982829094, "18": 0.0003138686588499695, "19": 0.04993802309036255}}, {"key": "creswell2022selection", "year": "2022", "title": "Selection-inference: Exploiting Large Language Models For Interpretable Logical Reasoning", "topic_distr": {"0": 0.13011789321899414, "1": 0.0009888195199891925, "2": 0.0008358948398381472, "3": 0.6798376441001892, "4": 0.0006385231390595436, "5": 0.000571110809687525, "6": 0.0005165744805708528, "7": 0.0004715458198916167, "8": 0.04345199093222618, "9": 0.0004015426675323397, "10": 0.00037379676359705627, "11": 0.00034963744110427797, "12": 0.0003284114063717425, "13": 0.03569728136062622, "14": 0.0002928539179265499, "15": 0.0002778142807073891, "16": 0.00026424392126500607, "17": 0.10411321371793747, "18": 0.00024072645464912057, "19": 0.00023047059949021786}}, {"key": "crowson2022vqgan", "year": "2022", "title": "VQGAN-CLIP: Open Domain Image Generation And Editing With Natural Language Guidance", "topic_distr": {"0": 0.0682351291179657, "1": 0.001591323409229517, "2": 0.0013451972045004368, "3": 0.0011651325039565563, "4": 0.0010275976965203881, "5": 0.0009191103745251894, "6": 0.0008313431171700358, "7": 0.3087558448314667, "8": 0.0006980309262871742, "9": 0.0006462180172093213, "10": 0.0006015654071234167, "11": 0.0005626849015243351, "12": 0.09722230583429337, "13": 0.09055844694375992, "14": 0.0004713010275736451, "15": 0.00044709714711643755, "16": 0.00042525786557234824, "17": 0.10073299705982208, "18": 0.32339251041412354, "19": 0.0003709051525220275}}, {"key": "cruzbenito2020automated", "year": "2020", "title": "Automated Source Code Generation And Auto-completion Using Deep Learning: Comparing And Discussing Current Language-model-related Approaches", "topic_distr": {"0": 0.0011889933375641704, "1": 0.000970075954683125, "2": 0.3355467915534973, "3": 0.0007102001691237092, "4": 0.000626367109362036, "5": 0.013737590052187443, "6": 0.23575043678283691, "7": 0.00046256909263320267, "8": 0.0004254808882251382, "9": 0.21322119235992432, "10": 0.08745688945055008, "11": 0.0003429814532864839, "12": 0.10772830992937088, "13": 0.00030372102628462017, "14": 0.0002872789336834103, "15": 0.0002725255908444524, "16": 0.00025921358610503376, "17": 0.00024714149185456336, "18": 0.00023614379460923374, "19": 0.00022608318249695003}}, {"key": "csaky2019deep", "year": "2019", "title": "Deep Learning Based Chatbot Models", "topic_distr": {"0": 0.15044859051704407, "1": 0.04907534644007683, "2": 0.09882519394159317, "3": 0.0005288803367875516, "4": 0.0004664515727199614, "5": 0.0004172063199803233, "6": 0.2808580994606018, "7": 0.000344472355209291, "8": 0.00031685299472883344, "9": 0.2051607370376587, "10": 0.05188578739762306, "11": 0.05002850294113159, "12": 0.08721402287483215, "13": 0.00022617918148171157, "14": 0.023279434069991112, "15": 0.0002029481256613508, "16": 0.0001930347498273477, "17": 0.00018404473667033017, "18": 0.00017585483146831393, "19": 0.0001683627488091588}}, {"key": "cuay\u00e1huitl2019ensemble", "year": "2019", "title": "Ensemble-based Deep Reinforcement Learning For Chatbots", "topic_distr": {"0": 0.0011558764381334186, "1": 0.2533723711967468, "2": 0.20846480131149292, "3": 0.0006904651527293026, "4": 0.0006089630187489092, "5": 0.06729905307292938, "6": 0.0705544725060463, "7": 0.0004497164045460522, "8": 0.011830056086182594, "9": 0.1330288052558899, "10": 0.00035649247001856565, "11": 0.2500945031642914, "12": 0.0003132081765215844, "13": 0.00029528202139772475, "14": 0.0002792967716231942, "15": 0.0002649533562362194, "16": 0.00025201120297424495, "17": 0.00024027455947361887, "18": 0.00022958245244808495, "19": 0.00021980136807542294}}, {"key": "cuconasu2024power", "year": "2024", "title": "The Power Of Noise: Redefining Retrieval For RAG Systems", "topic_distr": {"0": 0.04270993545651436, "1": 0.0009094381821341813, "2": 0.11862332373857498, "3": 0.09546705335378647, "4": 0.02675313502550125, "5": 0.000525230192579329, "6": 0.03164028748869896, "7": 0.00043366383761167526, "8": 0.27442091703414917, "9": 0.1597968190908432, "10": 0.0003437675186432898, "11": 0.00032154907239601016, "12": 0.06612057238817215, "13": 0.0002847419527824968, "14": 0.00026932728360407054, "15": 0.0002554958628024906, "16": 0.07300180196762085, "17": 0.07287398725748062, "18": 0.00022138752683531493, "19": 0.03502756357192993}}, {"key": "cui2021contrastive", "year": "2021", "title": "Contrastive Vision-language Pre-training With Limited Resources", "topic_distr": {"0": 0.001598341972567141, "1": 0.17104515433311462, "2": 0.17989878356456757, "3": 0.0009560683974996209, "4": 0.0008432130562141538, "5": 0.0007541912491433322, "6": 0.0006821722490713, "7": 0.0006227087578736246, "8": 0.0005727807874791324, "9": 0.021929534152150154, "10": 0.0004936244222335517, "11": 0.0004617203667294234, "12": 0.23319202661514282, "13": 0.06877895444631577, "14": 0.00038673379458487034, "15": 0.0003668729041237384, "16": 0.00034895233693532646, "17": 0.0003327009326312691, "18": 0.31643110513687134, "19": 0.00030435234657488763}}, {"key": "cui2021enhancing", "year": "2021", "title": "ROSITA: Enhancing Vision-and-language Semantic Alignments Via Cross- And Intra-modal Knowledge Integration", "topic_distr": {"0": 0.0013133889297023416, "1": 0.0010720202699303627, "2": 0.0009062172612175345, "3": 0.0007848982932046056, "4": 0.0006922460743226111, "5": 0.0006191630382090807, "6": 0.0005600382573902607, "7": 0.0005112208891659975, "8": 0.00047023186925798655, "9": 0.000435327849118039, "10": 0.00040524741052649915, "11": 0.00037905536009930074, "12": 0.0003560434270184487, "13": 0.00033566562342457473, "14": 0.00031749418121762574, "15": 0.00030118910945020616, "16": 0.578252911567688, "17": 0.0002731351996771991, "18": 0.35741427540779114, "19": 0.05460023507475853}}, {"key": "cui2022democratizing", "year": "2022", "title": "Democratizing Contrastive Language-image Pre-training: A CLIP Benchmark Of Data, Model, And Supervision", "topic_distr": {"0": 0.06155378371477127, "1": 0.07719302177429199, "2": 0.37586233019828796, "3": 0.0007933034794405103, "4": 0.0006996606825850904, "5": 0.0006257945788092911, "6": 0.0005660364986397326, "7": 0.0005166963674128056, "8": 0.0004752682871185243, "9": 0.0004399903991725296, "10": 0.03771840035915375, "11": 0.00038311522803269327, "12": 0.11329558491706848, "13": 0.02117159776389599, "14": 0.00032089470187202096, "15": 0.000304415007121861, "16": 0.00028954530716873705, "17": 0.00027606060029938817, "18": 0.2543167769908905, "19": 0.0531977042555809}}, {"key": "cui2022generative", "year": "2022", "title": "M6-rec: Generative Pretrained Language Models Are Open-ended Recommender Systems", "topic_distr": {"0": 0.0009458258282393217, "1": 0.0007717586122453213, "2": 0.06881586462259293, "3": 0.09504912048578262, "4": 0.2147100567817688, "5": 0.06497779488563538, "6": 0.000403140380512923, "7": 0.00036799951340071857, "8": 0.00033849378814920783, "9": 0.03847980126738548, "10": 0.0002917150850407779, "11": 0.00027286086697131395, "12": 0.0002562958688940853, "13": 0.1718384176492691, "14": 0.00022854639973957092, "15": 0.09186293184757233, "16": 0.0002062188577838242, "17": 0.05676780641078949, "18": 0.14026574790477753, "19": 0.05314963683485985}}, {"key": "cui2022linguistically", "year": "2022", "title": "LERT: A Linguistically-motivated Pre-trained Language Model", "topic_distr": {"0": 0.0019189617596566677, "1": 0.18622644245624542, "2": 0.0013244840083643794, "3": 0.0011471762554720044, "4": 0.001011763117276132, "5": 0.0009049472864717245, "6": 0.0008185325423255563, "7": 0.0007471828139387071, "8": 0.0006872746744193137, "9": 0.0006362601416185498, "10": 0.5091311931610107, "11": 0.0005540142301470041, "12": 0.11308220773935318, "13": 0.000490597274620086, "14": 0.0004640385159291327, "15": 0.0004402076010592282, "16": 0.00041870487621054053, "17": 0.17924940586090088, "18": 0.00038144050631672144, "19": 0.00036518971319310367}}, {"key": "cui2022prototypical", "year": "2022", "title": "Prototypical Verbalizer For Prompt-based Few-shot Tuning", "topic_distr": {"0": 0.00145124108530581, "1": 0.0772087499499321, "2": 0.2513304054737091, "3": 0.0008671608520671725, "4": 0.000764797383453697, "5": 0.0006840545684099197, "6": 0.06005808711051941, "7": 0.06361278146505356, "8": 0.01413899939507246, "9": 0.0004809522069990635, "10": 0.00044771924149245024, "11": 0.00041878214688040316, "12": 0.0003933584375772625, "13": 0.0003708449366968125, "14": 0.0003507690562400967, "15": 0.00033275515306741, "16": 0.03380448743700981, "17": 0.47374823689460754, "18": 0.00028833281248807907, "19": 0.01924748346209526}}, {"key": "cui2023drive", "year": "2023", "title": "Receive, Reason, And React: Drive As You Say With Large Language Models In Autonomous Vehicles", "topic_distr": {"0": 0.04797772318124771, "1": 0.018870776519179344, "2": 0.049994293600320816, "3": 0.27567437291145325, "4": 0.0732882171869278, "5": 0.11869284510612488, "6": 0.0004926972324028611, "7": 0.0004497499030549079, "8": 0.00041368952952325344, "9": 0.27458444237709045, "10": 0.00035651904181577265, "11": 0.07417234033346176, "12": 0.0003132315177936107, "13": 0.0002953039947897196, "14": 0.0002793175517581403, "15": 0.00026497308863326907, "16": 0.06318975239992142, "17": 0.00024029244377743453, "18": 0.00022959955094847828, "19": 0.00021981773898005486}}, {"key": "cui2023efficient", "year": "2023", "title": "Efficient And Effective Text Encoding For Chinese Llama And Alpaca", "topic_distr": {"0": 0.0010058836778625846, "1": 0.0008214047993533313, "2": 0.0006943371263332665, "3": 0.1365814208984375, "4": 0.0005304015357978642, "5": 0.00047440535854548216, "6": 0.0004291036748327315, "7": 0.0003916996356565505, "8": 0.0003602936340030283, "9": 0.029017550870776176, "10": 0.00031050227698870003, "11": 0.0002904338180087507, "12": 0.4664829671382904, "13": 0.16702479124069214, "14": 0.00024326538550667465, "15": 0.11387992650270462, "16": 0.08086090534925461, "17": 0.00020927733567077667, "18": 0.00019996459013782442, "19": 0.00019144534599035978}}, {"key": "c\u00f4t\u00e92018learning", "year": "2018", "title": "Textworld: A Learning Environment For Text-based Games", "topic_distr": {"0": 0.0014676970895379782, "1": 0.0011984283337369561, "2": 0.06997431069612503, "3": 0.135565847158432, "4": 0.0007738277781754732, "5": 0.03834915906190872, "6": 0.05614221468567848, "7": 0.0005714672151952982, "8": 0.0005256476579234004, "9": 0.00048663027700968087, "10": 0.00045300493366084993, "11": 0.5194026827812195, "12": 0.06838668137788773, "13": 0.0003752230841200799, "14": 0.0003549101820681244, "15": 0.10477571934461594, "16": 0.0003202376828994602, "17": 0.0003053235705010593, "18": 0.0002917368256021291, "19": 0.00027930771466344595}}, {"key": "dabre2021pre", "year": "2021", "title": "Indicbart: A Pre-trained Model For Indic Natural Language Generation", "topic_distr": {"0": 0.0022276972886174917, "1": 0.0018186714733019471, "2": 0.0015372775960713625, "3": 0.0013315111864358187, "4": 0.0011743295472115278, "5": 0.0010503509547561407, "6": 0.0009500511805526912, "7": 0.03568253666162491, "8": 0.0007977032801136374, "9": 0.0007384919445030391, "10": 0.0006874633836559951, "11": 0.000643031089566648, "12": 0.000603993539698422, "13": 0.0005694245337508619, "14": 0.947860598564148, "15": 0.0005109384655952454, "16": 0.0004859807377215475, "17": 0.00046334764920175076, "18": 0.0004427288949955255, "19": 0.0004238669644109905}}, {"key": "dahl2024large", "year": "2024", "title": "Large Legal Fictions: Profiling Legal Hallucinations In Large Language Models", "topic_distr": {"0": 0.43318822979927063, "1": 0.000901556748431176, "2": 0.0695994645357132, "3": 0.11333448439836502, "4": 0.0005820514634251595, "5": 0.0005206021014600992, "6": 0.00047088900464586914, "7": 0.0004298426501918584, "8": 0.0003953784180339426, "9": 0.3779161870479584, "10": 0.0003407384501770139, "11": 0.0003187157562933862, "12": 0.0002993669477291405, "13": 0.0002822329697664827, "14": 0.000266954128164798, "15": 0.00025324459420517087, "16": 0.00024087438941933215, "17": 0.00022965639072936028, "18": 0.00021943679894320667, "19": 0.00021008795010857284}}, {"key": "dai2019transformer", "year": "2019", "title": "Transformer-xl: Attentive Language Models Beyond A Fixed-length Context", "topic_distr": {"0": 0.0016629589954391122, "1": 0.0013578551588580012, "2": 0.23321126401424408, "3": 0.0009942232863977551, "4": 0.0008768649422563612, "5": 0.0007842901395633817, "6": 0.16451773047447205, "7": 0.0006475605187006295, "8": 0.0005956399254500866, "9": 0.0005514271906577051, "10": 0.41814911365509033, "11": 0.00048014719504863024, "12": 0.00045099807903170586, "13": 0.03153633698821068, "14": 0.00040216799243353307, "15": 0.0502745658159256, "16": 0.0003628786944318563, "17": 0.0003459787112660706, "18": 0.00033058281405828893, "19": 0.09246736019849777}}, {"key": "dai2020funnel", "year": "2020", "title": "Funnel-transformer: Filtering Out Sequential Redundancy For Efficient Language Processing", "topic_distr": {"0": 0.0015207596588879824, "1": 0.0012422628933563828, "2": 0.13551415503025055, "3": 0.0009094243869185448, "4": 0.0008020771783776581, "5": 0.0007173975463956594, "6": 0.000648892077151686, "7": 0.0005923295975662768, "8": 0.0005448373849503696, "9": 0.0005043955752626061, "10": 0.5881430506706238, "11": 0.0004391951079014689, "12": 0.0004125321574974805, "13": 0.19236603379249573, "14": 0.00036786679993383586, "15": 0.0003489748341962695, "16": 0.0003319285169709474, "17": 0.00031646995921619236, "18": 0.00030238719773478806, "19": 0.07397504895925522}}, {"key": "dai2021knowledge", "year": "2021", "title": "Knowledge Neurons In Pretrained Transformers", "topic_distr": {"0": 0.23919592797756195, "1": 0.0015671628061681986, "2": 0.001324704848229885, "3": 0.0011473221238702536, "4": 0.0010118881473317742, "5": 0.0009050600929185748, "6": 0.0008186343475244939, "7": 0.000747275713365525, "8": 0.0006873601232655346, "9": 0.0006363392458297312, "10": 0.2008356899023056, "11": 0.0005540830898098648, "12": 0.0005204454646445811, "13": 0.026850569993257523, "14": 0.0004640962288249284, "15": 0.0004402623453643173, "16": 0.32243114709854126, "17": 0.0003992545825894922, "18": 0.0003814879455603659, "19": 0.19908133149147034}}, {"key": "dai2022dialog", "year": "2022", "title": "Dialog Inpainting: Turning Documents Into Dialogs", "topic_distr": {"0": 0.0014501778641715646, "1": 0.1167447492480278, "2": 0.36786752939224243, "3": 0.0008670551469549537, "4": 0.1777617484331131, "5": 0.0006839740672148764, "6": 0.13740316033363342, "7": 0.0005647329962812364, "8": 0.1926795244216919, "9": 0.00048089580377563834, "10": 0.00044766670907847583, "11": 0.0004187330196145922, "12": 0.0003933123080059886, "13": 0.00037080145557411015, "14": 0.00035072790342383087, "15": 0.0003327161248307675, "16": 0.00031646399293094873, "17": 0.00030172563856467605, "18": 0.00028829899383708835, "19": 0.00027601636247709394}}, {"key": "dai2022enabling", "year": "2022", "title": "Enabling Multimodal Generation On CLIP Via Vision-language Knowledge Distillation", "topic_distr": {"0": 0.001539152697660029, "1": 0.001257629133760929, "2": 0.001062815892510116, "3": 0.0009205441456288099, "4": 0.0008118803962133825, "5": 0.0007261675782501698, "6": 0.0006568247335962951, "7": 0.000599570746999234, "8": 0.0005514979129657149, "9": 0.0005105616874061525, "10": 0.0004752827517222613, "11": 0.0004445641825441271, "12": 0.00041757526923902333, "13": 0.1777830421924591, "14": 0.0003723638947121799, "15": 0.18506653606891632, "16": 0.060336802154779434, "17": 0.000320338731398806, "18": 0.5658537745475769, "19": 0.0002930434711743146}}, {"key": "dai2022few", "year": "2022", "title": "Promptagator: Few-shot Dense Retrieval From 8 Examples", "topic_distr": {"0": 0.0011244507040828466, "1": 0.11851543188095093, "2": 0.24892327189445496, "3": 0.1481618881225586, "4": 0.0005925250588916242, "5": 0.0005299699259921908, "6": 0.07626231014728546, "7": 0.00043757722596637905, "8": 0.2435491383075714, "9": 0.0003726168943103403, "10": 0.02758440189063549, "11": 0.0003244507242925465, "12": 0.0003047537466045469, "13": 0.0002873114717658609, "14": 0.0002717577153816819, "15": 0.00025780146825127304, "16": 0.030947687104344368, "17": 0.05293368175625801, "18": 0.00022338533017318696, "19": 0.048395540565252304}}, {"key": "dai2022why", "year": "2022", "title": "Why Can GPT Learn In-context? Language Models Implicitly Perform Gradient Descent As Meta-optimizers", "topic_distr": {"0": 0.12670476734638214, "1": 0.0009344182908535004, "2": 0.21308384835720062, "3": 0.06299927830696106, "4": 0.0006033745012246072, "5": 0.03546302393078804, "6": 0.00048813963076099753, "7": 0.0004455895395949483, "8": 0.0004098627541679889, "9": 0.0003794397343881428, "10": 0.22795206308364868, "11": 0.18877945840358734, "12": 0.04465378448367119, "13": 0.000292572338366881, "14": 0.0002767337718978524, "15": 0.00026252196403220296, "16": 0.0002496986126061529, "17": 0.00023806965327821672, "18": 0.00022747565526515245, "19": 0.09555591642856598}}, {"key": "dai2023leveraging", "year": "2023", "title": "Auggpt: Leveraging Chatgpt For Text Data Augmentation", "topic_distr": {"0": 0.0010860487818717957, "1": 0.4817458391189575, "2": 0.15916498005390167, "3": 0.05205802991986275, "4": 0.000571909302379936, "5": 0.0005115300882607698, "6": 0.0004626832960639149, "7": 0.0004223521682433784, "8": 0.0003884885227307677, "9": 0.05595782399177551, "10": 0.0003348007157910615, "11": 0.0003131618141196668, "12": 0.0002941501734312624, "13": 0.08390672504901886, "14": 0.0002623021719045937, "15": 0.07411658763885498, "16": 0.00023667690402362496, "17": 0.08774387091398239, "18": 0.00021561287576332688, "19": 0.00020642695017158985}}, {"key": "dai2023llm", "year": "2023", "title": "Llm-in-the-loop: Leveraging Large Language Model For Thematic Analysis", "topic_distr": {"0": 0.15876995027065277, "1": 0.09935648739337921, "2": 0.0009461225126869977, "3": 0.4654066860675812, "4": 0.0007227239548228681, "5": 0.0006464224425144494, "6": 0.0005846946150995791, "7": 0.000533728045411408, "8": 0.0004909344133920968, "9": 0.23042069375514984, "10": 0.0004230889317113906, "11": 0.0003957437293138355, "12": 0.0003717186627909541, "13": 0.00035044370451942086, "14": 0.00033147225622087717, "15": 0.00031444933847524226, "16": 0.000299089471809566, "17": 0.039102260023355484, "18": 0.00027247078833170235, "19": 0.0002608625218272209}}, {"key": "dai2023towards", "year": "2023", "title": "Instructblip: Towards General-purpose Vision-language Models With Instruction Tuning", "topic_distr": {"0": 0.001467841793783009, "1": 0.0011983576696366072, "2": 0.0010129522997885942, "3": 0.3460347354412079, "4": 0.0007737677660770714, "5": 0.0006920783780515194, "6": 0.0006259907968342304, "7": 0.0005714244907721877, "8": 0.03165902569890022, "9": 0.0004865939263254404, "10": 0.045879922807216644, "11": 0.00042369458242319524, "12": 0.10829556733369827, "13": 0.00037519505713135004, "14": 0.00035488366847857833, "15": 0.0003366584423929453, "16": 0.00032021375955082476, "17": 0.15731599926948547, "18": 0.1988895684480667, "19": 0.10328557342290878}}, {"key": "dai2023uncovering", "year": "2023", "title": "Uncovering Chatgpt's Capabilities In Recommender Systems", "topic_distr": {"0": 0.0012732025934383273, "1": 0.0010391066316515207, "2": 0.0008785033132880926, "3": 0.2501118779182434, "4": 0.21924646198749542, "5": 0.0006002142908982933, "6": 0.0005428988370113075, "7": 0.0004955755430273712, "8": 0.013046536594629288, "9": 0.2604559659957886, "10": 0.0003928452206309885, "11": 0.0003674547770060599, "12": 0.07007544487714767, "13": 0.05064074695110321, "14": 0.0003077776054851711, "15": 0.0002919715188909322, "16": 0.00027770965243689716, "17": 0.12946048378944397, "18": 0.0002529937482904643, "19": 0.00024221526109613478}}, {"key": "dan2023large", "year": "2023", "title": "Educhat: A Large-scale Language Model-based Chatbot System For Intelligent Education", "topic_distr": {"0": 0.0015782630071043968, "1": 0.001289255334995687, "2": 0.0010897149331867695, "3": 0.0009438688866794109, "4": 0.0008324513910338283, "5": 0.0007445653900504112, "6": 0.0006734656053595245, "7": 0.0006147609674371779, "8": 0.05817573890089989, "9": 0.693301796913147, "10": 0.0004873241705354303, "11": 0.07020586729049683, "12": 0.0004281546571291983, "13": 0.00040364961023442447, "14": 0.0003817978431470692, "15": 0.000362190417945385, "16": 0.010808074846863747, "17": 0.1570647656917572, "18": 0.00031383850728161633, "19": 0.00030046780011616647}}, {"key": "dancette2021beyond", "year": "2021", "title": "Beyond Question-based Biases: Assessing Multimodal Shortcut Learning In Visual Question Answering", "topic_distr": {"0": 0.31201377511024475, "1": 0.000893611169885844, "2": 0.2670741379261017, "3": 0.000654142873827368, "4": 0.0005769262206740677, "5": 0.0005160178407095373, "6": 0.0004667424946092069, "7": 0.0004260575515218079, "8": 0.10720715671777725, "9": 0.0003628073609434068, "10": 0.0003377379907760769, "11": 0.00031590924481861293, "12": 0.06389040499925613, "13": 0.00027974770637229085, "14": 0.00026460341177880764, "15": 0.00025101457140408456, "16": 0.00023875331680756062, "17": 0.0002276340965181589, "18": 0.24379457533359528, "19": 0.0002082379796775058}}, {"key": "dang2022beyond", "year": "2022", "title": "Beyond Text Generation: Supporting Writers With Continuous Automatic Text Summaries", "topic_distr": {"0": 0.09315253049135208, "1": 0.0011708522215485573, "2": 0.0009896361734718084, "3": 0.0008571486687287688, "4": 0.0007559714722447097, "5": 0.0006761602126061916, "6": 0.0006115924916230142, "7": 0.42513787746429443, "8": 0.0005135189858265221, "9": 0.42109811305999756, "10": 0.00044255240936763585, "11": 0.0004139492812100798, "12": 0.05196888744831085, "13": 0.00036656527663581073, "14": 0.0003467210626695305, "15": 0.00032891504815779626, "16": 0.00031284859869629145, "17": 0.00029827860998921096, "18": 0.00028500534244813025, "19": 0.0002728630497585982}}, {"key": "dang2022how", "year": "2022", "title": "How To Prompt? Opportunities And Challenges Of Zero- And Few-shot Learning For Human-ai Interaction In Creative Applications Of Generative Models", "topic_distr": {"0": 0.023930653929710388, "1": 0.0011981765273958445, "2": 0.001012958469800651, "3": 0.163605198264122, "4": 0.0007737845298834145, "5": 0.0006920923478901386, "6": 0.0006260032532736659, "7": 0.0005714359576813877, "8": 0.0005256189615465701, "9": 0.6357801556587219, "10": 0.00045298016630113125, "11": 0.00042370305163785815, "12": 0.0003979806206189096, "13": 0.0003752025659196079, "14": 0.00035489076981320977, "15": 0.04684733599424362, "16": 0.00032022016239352524, "17": 0.12154055386781693, "18": 0.0002917208767030388, "19": 0.0002792924642562866}}, {"key": "dang2023choice", "year": "2023", "title": "Choice Over Control: How Users Write With Large Language Models Using Diegetic And Non-diegetic Prompting", "topic_distr": {"0": 0.0017344801453873515, "1": 0.0014144128654152155, "2": 0.00119578477460891, "3": 0.0010356802958995104, "4": 0.0009134248830378056, "5": 0.0008169909124262631, "6": 0.0007389751845039427, "7": 0.11080627143383026, "8": 0.0006204749806784093, "9": 0.5446637272834778, "10": 0.0005347274127416313, "11": 0.0005001667886972427, "12": 0.0004698023258242756, "13": 0.0004429136461112648, "14": 0.000418936280766502, "15": 0.00039742159424349666, "16": 0.040523964911699295, "17": 0.29209771752357483, "18": 0.000344366388162598, "19": 0.0003296950599178672}}, {"key": "daniluk2017frustratingly", "year": "2017", "title": "Frustratingly Short Attention Spans In Neural Language Modeling", "topic_distr": {"0": 0.0012227374827489257, "1": 0.0009984916541725397, "2": 0.566035270690918, "3": 0.0007310553337447345, "4": 0.0006447631167247891, "5": 0.0005766921094618738, "6": 0.11704809218645096, "7": 0.10214345157146454, "8": 0.0004379767633508891, "9": 0.00040546691161580384, "10": 0.10985514521598816, "11": 0.00035305440542288125, "12": 0.0003316209476906806, "13": 0.00031264094286598265, "14": 0.00029571595950983465, "15": 0.0002805293188430369, "16": 0.07122122496366501, "17": 0.00025439972523599863, "18": 0.00024307906278409064, "19": 0.026608571410179138}}, {"key": "dao2021intent", "year": "2021", "title": "Intent Detection And Slot Filling For Vietnamese", "topic_distr": {"0": 0.0020773576106876135, "1": 0.0016973561141639948, "2": 0.041302766650915146, "3": 0.0012427526526153088, "4": 0.03165197744965553, "5": 0.0009803470456972718, "6": 0.6623631119728088, "7": 0.0008094375371001661, "8": 0.0007445378578267992, "9": 0.0006892728270031512, "10": 0.2013932466506958, "11": 0.0006001743022352457, "12": 0.03383003920316696, "13": 0.0005314734880812466, "14": 0.0005027018487453461, "15": 0.0004768853832501918, "16": 0.0004535910557024181, "17": 0.01784411445260048, "18": 0.0004132218600716442, "19": 0.00039561704033985734}}, {"key": "dao2022fast", "year": "2022", "title": "Flashattention: Fast And Memory-efficient Exact Attention With Io-awareness", "topic_distr": {"0": 0.0010747445048764348, "1": 0.0008779565105214715, "2": 0.4652096927165985, "3": 0.0006428190390579402, "4": 0.0005669404636137187, "5": 0.0005070864572189748, "6": 0.0004586639697663486, "7": 0.0004186832520645112, "8": 0.0003851137589663267, "9": 0.00035652780206874013, "10": 0.1805609166622162, "11": 0.00031044139177538455, "12": 0.00029159491532482207, "13": 0.34695544838905334, "14": 0.0002600235748104751, "15": 0.00024666995159350336, "16": 0.0002346209075767547, "17": 0.00022369415091816336, "18": 0.00021373986965045333, "19": 0.00020463374676182866}}, {"key": "dao2023can", "year": "2023", "title": "Can Chatgpt Pass The Vietnamese National High School Graduation Examination?", "topic_distr": {"0": 0.1685994267463684, "1": 0.07540959119796753, "2": 0.0009566235239617527, "3": 0.20986397564411163, "4": 0.0007307588239200413, "5": 0.0006536095752380788, "6": 0.0005911954212933779, "7": 0.0005396622000262141, "8": 0.031463202089071274, "9": 0.5078507661819458, "10": 0.000427792954724282, "11": 0.0004001437337137759, "12": 0.0003758515522349626, "13": 0.000354340038029477, "14": 0.0003351576451677829, "15": 0.00031794546521268785, "16": 0.00030241484637372196, "17": 0.0002883307752199471, "18": 0.00027550020604394376, "19": 0.0002637628640513867}}, {"key": "dao2023flashattention", "year": "2023", "title": "Flashattention-2: Faster Attention With Better Parallelism And Work Partitioning", "topic_distr": {"0": 0.001057473593391478, "1": 0.0008633583784103394, "2": 0.3694102466106415, "3": 0.000632028968539089, "4": 0.0005574210081249475, "5": 0.0004985717823728919, "6": 0.00045096242683939636, "7": 0.011103658005595207, "8": 0.0003786472079809755, "9": 0.021710259839892387, "10": 0.23289330303668976, "11": 0.00030522869201377034, "12": 0.00028669866151176393, "13": 0.2997247278690338, "14": 0.0002556574472691864, "15": 0.0002425280399620533, "16": 0.013968010433018208, "17": 0.00021993802511133254, "18": 0.04524008557200432, "19": 0.00020119767577853054}}, {"key": "dao2023performance", "year": "2023", "title": "Performance Comparison Of Large Language Models On VNHSGE English Dataset: Openai Chatgpt, Microsoft Bing Chat, And Google Bard", "topic_distr": {"0": 0.0018343592528253794, "1": 0.0014976845122873783, "2": 0.0012660205829888582, "3": 0.2801211476325989, "4": 0.0009670996223576367, "5": 0.0008649994852021337, "6": 0.0007823992054909468, "7": 0.0007141991518437862, "8": 0.0006569355609826744, "9": 0.46922290325164795, "10": 0.0005661493050865829, "11": 0.0005295578157529235, "12": 0.0004974090843461454, "13": 0.0004689403285738081, "14": 0.23809392750263214, "15": 0.00042077506077475846, "16": 0.0004002215573564172, "17": 0.00038158244569785893, "18": 0.0003646021941676736, "19": 0.0003490687522571534}}, {"key": "dao2024transformers", "year": "2024", "title": "Transformers Are Ssms: Generalized Models And Efficient Algorithms Through Structured State Space Duality", "topic_distr": {"0": 0.09152519702911377, "1": 0.0016976373735815287, "2": 0.18330635130405426, "3": 0.0012430179631337523, "4": 0.06454704701900482, "5": 0.0009805485606193542, "6": 0.0008869144367054105, "7": 0.0008096040110103786, "8": 0.0007446909439750016, "9": 0.0006894145626574755, "10": 0.440133273601532, "11": 0.0006002977024763823, "12": 0.0005638544098474085, "13": 0.12636180222034454, "14": 0.0005028052255511284, "15": 0.00047698343405500054, "16": 0.08368898183107376, "17": 0.0004325553309172392, "18": 0.00041330684325657785, "19": 0.0003956983855459839}}, {"key": "das2016visual", "year": "2016", "title": "Visual Dialog", "topic_distr": {"0": 0.07356011122465134, "1": 0.018564730882644653, "2": 0.043626729398965836, "3": 0.0005918448441661894, "4": 0.18540450930595398, "5": 0.000466875295387581, "6": 0.058526214212179184, "7": 0.0003854822716675699, "8": 0.07338541746139526, "9": 0.058418698608875275, "10": 0.0003055737470276654, "11": 0.07132404297590256, "12": 0.00026847186381928623, "13": 0.00025310611817985773, "14": 0.015188599936664104, "15": 0.00022710938355885446, "16": 0.00021601581829600036, "17": 0.00020595552632585168, "18": 0.3988920748233795, "19": 0.00018840657139662653}}, {"key": "das2018neural", "year": "2018", "title": "Neural Modular Control For Embodied Question Answering", "topic_distr": {"0": 0.0015228852862492204, "1": 0.001242365688085556, "2": 0.21126002073287964, "3": 0.0009095148998312652, "4": 0.07998472452163696, "5": 0.0007174658239819109, "6": 0.0006489536608569324, "7": 0.08814375102519989, "8": 0.055151794105768204, "9": 0.000504443421959877, "10": 0.0004695872194133699, "11": 0.42565321922302246, "12": 0.00041257127304561436, "13": 0.10088108479976654, "14": 0.0003679016954265535, "15": 0.0003490079252514988, "16": 0.00033196000731550157, "17": 0.00031649996526539326, "18": 0.00030241586500778794, "19": 0.030829865485429764}}, {"key": "das2019multi", "year": "2019", "title": "Multi-step Retriever-reader Interaction For Scalable Open-domain Question Answering", "topic_distr": {"0": 0.0017564024310559034, "1": 0.0014344085939228535, "2": 0.203957200050354, "3": 0.0010502329096198082, "4": 0.0009262605453841388, "5": 0.0008284703362733126, "6": 0.0007493583834730089, "7": 0.0006840384448878467, "8": 0.6707404255867004, "9": 0.0005824897671118379, "10": 0.11359776556491852, "11": 0.0005071944906376302, "12": 0.00047640339471399784, "13": 0.0004491369181778282, "14": 0.00042482264689169824, "15": 0.00040300568798556924, "16": 0.00038332011899910867, "17": 0.00036546814953908324, "18": 0.00034920498728752136, "19": 0.00033432754571549594}}, {"key": "dasgupta2022language", "year": "2022", "title": "Language Models Show Human-like Content Effects On Reasoning Tasks", "topic_distr": {"0": 0.5358250141143799, "1": 0.0008557711844332516, "2": 0.0007234351942315698, "3": 0.11504767835140228, "4": 0.0005526304594241083, "5": 0.0004942873492836952, "6": 0.0004470870771910995, "7": 0.000408115447498858, "8": 0.06645673513412476, "9": 0.00034752883948385715, "10": 0.0003235151816625148, "11": 0.21892578899860382, "12": 0.0002842349058482796, "13": 0.0002679669705685228, "14": 0.000253460428211838, "15": 0.00024044385645538568, "16": 0.04412670060992241, "17": 0.00021804797870572656, "18": 0.00020834495080634952, "19": 0.013993198052048683}}, {"key": "dathathri2019plug", "year": "2019", "title": "Plug And Play Language Models: A Simple Approach To Controlled Text Generation", "topic_distr": {"0": 0.05113595351576805, "1": 0.022572124376893044, "2": 0.0008122326689772308, "3": 0.049919698387384415, "4": 0.0006204477977007627, "5": 0.0005549445049837232, "6": 0.0005019520758651197, "7": 0.590242862701416, "8": 0.00042146025225520134, "9": 0.000390176399378106, "10": 0.05538410693407059, "11": 0.0003397403925191611, "12": 0.0003191152063664049, "13": 0.11869295686483383, "14": 0.000284564244793728, "15": 0.00026995030930265784, "16": 0.0002567640913184732, "17": 0.0002448060840833932, "18": 0.0002339123166166246, "19": 0.10680224001407623}}, {"key": "dautume2019episodic", "year": "2019", "title": "Episodic Memory In Lifelong Language Learning", "topic_distr": {"0": 0.0018623456126078963, "1": 0.1581377536058426, "2": 0.4554643929004669, "3": 0.0011131576029583812, "4": 0.0009817532263696194, "5": 0.00087810552213341, "6": 0.0007942538359202445, "7": 0.000725020479876548, "8": 0.04328320547938347, "9": 0.07383354008197784, "10": 0.06805391609668732, "11": 0.0005375815089792013, "12": 0.03335196152329445, "13": 0.00047604559222236276, "14": 0.0004502745869103819, "15": 0.00042715054587461054, "16": 0.15851768851280212, "17": 0.00038736406713724136, "18": 0.0003701265377458185, "19": 0.00035435776226222515}}, {"key": "dechoudhury2023benefits", "year": "2023", "title": "Benefits And Harms Of Large Language Models In Digital Mental Health", "topic_distr": {"0": 0.1284555047750473, "1": 0.17301583290100098, "2": 0.0007359941373579204, "3": 0.00063748424872756, "4": 0.000562235654797405, "5": 0.0005028783343732357, "6": 0.00045485765440389514, "7": 0.0004152086330577731, "8": 0.0003819177218247205, "9": 0.49790236353874207, "10": 0.00032913798349909484, "11": 0.010726260021328926, "12": 0.1708773374557495, "13": 0.0002726243401411921, "14": 0.0002578656713012606, "15": 0.013603084720671177, "16": 0.00023267381766345352, "17": 0.00022183773398865014, "18": 0.00021196604939177632, "19": 0.00020293549459893256}}, {"key": "deepseekai2024deepseek", "year": "2024", "title": "Deepseek-v2: A Strong, Economical, And Efficient Mixture-of-experts Language Model", "topic_distr": {"0": 0.0017816328909248114, "1": 0.001455159392207861, "2": 0.16534194350242615, "3": 0.0010653049685060978, "4": 0.000939555058721453, "5": 0.0008403618121519685, "6": 0.16039596498012543, "7": 0.0006938569131307304, "8": 0.0006382243591360748, "9": 0.0005908506573177874, "10": 0.0897660180926323, "11": 0.09464643150568008, "12": 0.0004832415434066206, "13": 0.3606356680393219, "14": 0.0004309204232413322, "15": 0.0004087903071194887, "16": 0.0003888221981469542, "17": 0.0003707139694597572, "18": 0.00035421736538410187, "19": 0.11877234280109406}}, {"key": "deepseekai2025deepseek", "year": "2025", "title": "Deepseek-r1: Incentivizing Reasoning Capability In Llms Via Reinforcement Learning", "topic_distr": {"0": 0.0022294537629932165, "1": 0.0018192763673141599, "2": 0.0015374916838482022, "3": 0.5219133496284485, "4": 0.0011744819348677993, "5": 0.0010504871606826782, "6": 0.0009501738823018968, "7": 0.0008673493284732103, "8": 0.0007978063658811152, "9": 0.0007385873468592763, "10": 0.0006875522085465491, "11": 0.32196375727653503, "12": 0.04982053115963936, "13": 0.0005694981082342565, "14": 0.0005386680131778121, "15": 0.0005110044730827212, "16": 0.0004860435437876731, "17": 0.0004634075448848307, "18": 0.0004427861131262034, "19": 0.09143829345703125}}, {"key": "dehghani2023scaling", "year": "2023", "title": "Scaling Vision Transformers To 22 Billion Parameters", "topic_distr": {"0": 0.1233363226056099, "1": 0.03867790475487709, "2": 0.10859441757202148, "3": 0.0008984939195215702, "4": 0.000792430539149791, "5": 0.0007087703561410308, "6": 0.0006410886999219656, "7": 0.0005852064350619912, "8": 0.000538285297807306, "9": 0.0640595480799675, "10": 0.07593932747840881, "11": 0.00043391346116550267, "12": 0.00040757114766165614, "13": 0.28757041692733765, "14": 0.00036344293039292097, "15": 0.00034477817825973034, "16": 0.000327936839312315, "17": 0.0003126641677226871, "18": 0.22144605219364166, "19": 0.07402140647172928}}, {"key": "dejong2021mention", "year": "2021", "title": "Mention Memory: Incorporating Textual Knowledge Into Transformers Through Entity Mention Attention", "topic_distr": {"0": 0.0012597419554367661, "1": 0.0010292934020981193, "2": 0.16168971359729767, "3": 0.0007532485178671777, "4": 0.0006643288070335984, "5": 0.0005941937561146915, "6": 0.0005374529282562435, "7": 0.0004906043177470565, "8": 0.07811187952756882, "9": 0.00041777186561375856, "10": 0.20882651209831238, "11": 0.0003637687477748841, "12": 0.00034168484853580594, "13": 0.00032212884980253875, "14": 0.00030469021294265985, "15": 0.0002890427131205797, "16": 0.4536069333553314, "17": 0.00026212012744508684, "18": 0.00025045592337846756, "19": 0.08988442271947861}}, {"key": "delarosa2022efficient", "year": "2022", "title": "BERTIN: Efficient Pre-training Of A Spanish Language Model Using Perplexity Sampling", "topic_distr": {"0": 0.10578527301549911, "1": 0.09953416138887405, "2": 0.17275071144104004, "3": 0.0012857537949457765, "4": 0.001133976154960692, "5": 0.0010142580140382051, "6": 0.0009174048900604248, "7": 0.07063182443380356, "8": 0.0007702920702286065, "9": 0.0007131153834052384, "10": 0.2584097385406494, "11": 0.0006209348211996257, "12": 0.0005832387250848114, "13": 0.2830823063850403, "14": 0.0005200907471589744, "15": 0.0004933812306262553, "16": 0.0004692811635322869, "17": 0.000447425787569955, "18": 0.0004275155661161989, "19": 0.00040930177783593535}}, {"key": "delatorre2023real", "year": "2023", "title": "LLMR: Real-time Prompting Of Interactive Worlds Using Large Language Models", "topic_distr": {"0": 0.0015597393503412604, "1": 0.34875091910362244, "2": 0.0010761570883914828, "3": 0.20369142293930054, "4": 0.0008220701711252332, "5": 0.0007352802786044776, "6": 0.0006650671130046248, "7": 0.0006070946692489088, "8": 0.0005584185710176826, "9": 0.169078066945076, "10": 0.00048124699969775975, "11": 0.20510393381118774, "12": 0.0004228153557050973, "13": 0.00039861592813394964, "14": 0.0003770366311073303, "15": 0.000357673765392974, "16": 0.06438342481851578, "17": 0.00032435861066915095, "18": 0.0003099247987847775, "19": 0.00029672085656784475}}, {"key": "delbrouck2017multimodal", "year": "2017", "title": "Multimodal Compact Bilinear Pooling For Multimodal Neural Machine Translation", "topic_distr": {"0": 0.001558226067572832, "1": 0.0012729006120935082, "2": 0.35161206126213074, "3": 0.0009320953977294266, "4": 0.0008220727322623134, "5": 0.0007352826651185751, "6": 0.0006650693248957396, "7": 0.019705645740032196, "8": 0.03476687893271446, "9": 0.0005169704090803862, "10": 0.00048124860040843487, "11": 0.0004501444345805794, "12": 0.0004228167817927897, "13": 0.00039861726691015065, "14": 0.1920713633298874, "15": 0.00035767495865002275, "16": 0.0003402036672923714, "17": 0.0003243597166147083, "18": 0.39226967096328735, "19": 0.0002967218460980803}}, {"key": "deldjoo2024review", "year": "2024", "title": "A Review Of Modern Recommender Systems Using Generative Models (gen-recsys)", "topic_distr": {"0": 0.1276213824748993, "1": 0.06455804407596588, "2": 0.0011792962905019522, "3": 0.0010214486392214894, "4": 0.22388367354869843, "5": 0.0008057630620896816, "6": 0.0007288195192813873, "7": 0.0006652898737229407, "8": 0.00061194779118523, "9": 0.15446311235427856, "10": 0.0005273786373436451, "11": 0.0004932929878123105, "12": 0.18123917281627655, "13": 0.0004368266963865608, "14": 0.00041317884461022913, "15": 0.07239785045385361, "16": 0.00037281386903487146, "17": 0.0003554511640686542, "18": 0.16790011525154114, "19": 0.0003251640882808715}}, {"key": "deldjoo2024understanding", "year": "2024", "title": "Understanding Biases In Chatgpt-based Recommender Systems: Provider Fairness, Temporal Stability, And Recency", "topic_distr": {"0": 0.17466162145137787, "1": 0.0007327034254558384, "2": 0.0006194012821651995, "3": 0.034241434186697006, "4": 0.4272705316543579, "5": 0.00042320648208260536, "6": 0.00038279386353679, "7": 0.000349426525644958, "8": 0.000321409956086427, "9": 0.1849043071269989, "10": 0.00027699218480847776, "11": 0.0002590895746834576, "12": 0.00024336058413609862, "13": 0.000229432072956115, "14": 0.0002170116495108232, "15": 0.00020586691971402615, "16": 0.00019581096421461552, "17": 0.17411647737026215, "18": 0.00017838396888691932, "19": 0.00017078414384741336}}, {"key": "deng2020residual", "year": "2020", "title": "Residual Energy-based Models For Text Generation", "topic_distr": {"0": 0.14449691772460938, "1": 0.0012732743052765727, "2": 0.1479540318250656, "3": 0.0009321098914369941, "4": 0.0008220811141654849, "5": 0.017471229657530785, "6": 0.0006650768918916583, "7": 0.28046178817749023, "8": 0.0005584267782978714, "9": 0.0005169762880541384, "10": 0.28420594334602356, "11": 0.0004501495568547398, "12": 0.00042282158392481506, "13": 0.00039862177800387144, "14": 0.08183015882968903, "15": 0.00035767900408245623, "16": 0.00034020753810182214, "17": 0.00032436338369734585, "18": 0.00030992936808615923, "19": 0.036208223551511765}}, {"key": "deng2022optimizing", "year": "2022", "title": "Rlprompt: Optimizing Discrete Text Prompts With Reinforcement Learning", "topic_distr": {"0": 0.0009385277517139912, "1": 0.03453013300895691, "2": 0.025439472869038582, "3": 0.07003379613161087, "4": 0.0004945294349454343, "5": 0.009140746667981148, "6": 0.0004000822955276817, "7": 0.06521748006343842, "8": 0.00033592607360333204, "9": 0.0003109911922365427, "10": 0.07214778661727905, "11": 0.15033942461013794, "12": 0.00025435167481191456, "13": 0.05713685601949692, "14": 0.00022681271366309375, "15": 0.00021516464767046273, "16": 0.00020465454144869, "17": 0.3957509398460388, "18": 0.00018644047668203712, "19": 0.11669591814279556}}, {"key": "deng2022unified", "year": "2022", "title": "A Unified Multi-task Learning Framework For Multi-goal Conversational Recommender Systems", "topic_distr": {"0": 0.001327509875409305, "1": 0.0010833751875907183, "2": 0.22321730852127075, "3": 0.19254837930202484, "4": 0.39164817333221436, "5": 0.0006257932400330901, "6": 0.09643224626779556, "7": 0.0005166948540136218, "8": 0.0004752669483423233, "9": 0.00043998914770781994, "10": 0.00040958664612844586, "11": 0.00038311415119096637, "12": 0.00035985579597763717, "13": 0.00033925980096682906, "14": 0.0003208937996532768, "15": 0.0003044141340069473, "16": 0.0002895444631576538, "17": 0.0887623056769371, "18": 0.00026377529138699174, "19": 0.0002525374584365636}}, {"key": "deng2022what", "year": "2022", "title": "What Do Llms Know About Financial Markets? A Case Study On Reddit Market Sentiment Analysis", "topic_distr": {"0": 0.1103334054350853, "1": 0.09500318020582199, "2": 0.000989614985883236, "3": 0.20092152059078217, "4": 0.000755953136831522, "5": 0.0006761442637071013, "6": 0.0006115781725384295, "7": 0.09951406717300415, "8": 0.0005135069950483739, "9": 0.11129892617464066, "10": 0.00044254204840399325, "11": 0.00041393956053070724, "12": 0.0003888098581228405, "13": 0.1509295552968979, "14": 0.0003467129427008331, "15": 0.00032890733564272523, "16": 0.00031284126453101635, "17": 0.22566096484661102, "18": 0.00028499867767095566, "19": 0.0002728566469158977}}, {"key": "deng2023foundation", "year": "2023", "title": "K2: A Foundation Language Model For Geoscience Knowledge Understanding And Utilization", "topic_distr": {"0": 0.0012857556575909257, "1": 0.15992815792560577, "2": 0.0008876296342350543, "3": 0.232049822807312, "4": 0.03779435530304909, "5": 0.0006064705085009336, "6": 0.05415605008602142, "7": 0.0005007410072721541, "8": 0.00046059221494942904, "9": 0.09296467900276184, "10": 0.044639118015766144, "11": 0.0003712848119903356, "12": 0.23772044479846954, "13": 0.00032878454658202827, "14": 0.000310985604301095, "15": 0.000295014790026471, "16": 0.0710025355219841, "17": 0.00026753597194328904, "18": 0.00025563075905665755, "19": 0.06417437642812729}}, {"key": "denny2022conversing", "year": "2022", "title": "Conversing With Copilot: Exploring Prompt Engineering For Solving CS1 Problems Using Natural Language", "topic_distr": {"0": 0.17024032771587372, "1": 0.0010184197453781962, "2": 0.0008609583601355553, "3": 0.0007457031751982868, "4": 0.0006576766609214246, "5": 0.0005882431869395077, "6": 0.19144929945468903, "7": 0.00048569138743914664, "8": 0.0004467492690309882, "9": 0.24176554381847382, "10": 0.0003850100329145789, "11": 0.20425444841384888, "12": 0.00033826319850049913, "13": 0.0003189030394423753, "14": 0.00030163905466906726, "15": 0.0002861482498701662, "16": 0.0002721708151511848, "17": 0.1698824018239975, "18": 0.01546496246010065, "19": 0.00023738433083053678}}, {"key": "desai2020calibration", "year": "2020", "title": "Calibration Of Pre-trained Transformers", "topic_distr": {"0": 0.1256643533706665, "1": 0.0017265884671360254, "2": 0.19180139899253845, "3": 0.33930304646492004, "4": 0.001114732469432056, "5": 0.0009970460087060928, "6": 0.0009018363780342042, "7": 0.0008232252439484, "8": 0.0007572200847789645, "9": 0.000701013719663024, "10": 0.24625612795352936, "11": 0.0006103974883444607, "12": 0.0005733410362154245, "13": 0.05511941388249397, "14": 0.0005112647195346653, "15": 0.03141520544886589, "16": 0.000461317365989089, "17": 0.0004398329183459282, "18": 0.0004202605632599443, "19": 0.0004023558576591313}}, {"key": "deshpande2023toxicity", "year": "2023", "title": "Toxicity In Chatgpt: Analyzing Persona-assigned Language Models", "topic_distr": {"0": 0.4208165109157562, "1": 0.08059978485107422, "2": 0.0008199281292036176, "3": 0.0007101784576661885, "4": 0.0006263458635658026, "5": 0.03776286914944649, "6": 0.0005067235324531794, "7": 0.0004625535220839083, "8": 0.0004254665691405535, "9": 0.3757752478122711, "10": 0.0003666685370262712, "11": 0.000342969928169623, "12": 0.0003221486695110798, "13": 0.02428695373237133, "14": 0.0002872692421078682, "15": 0.04269777983427048, "16": 0.012481244280934334, "17": 0.00024713316815905273, "18": 0.00023613584926351905, "19": 0.0002260755718452856}}, {"key": "dettmers2022matrix", "year": "2022", "title": "Llm.int8(): 8-bit Matrix Multiplication For Transformers At Scale", "topic_distr": {"0": 0.0013417963637039065, "1": 0.0010951946023851633, "2": 0.21443763375282288, "3": 0.16604529321193695, "4": 0.0007071978179737926, "5": 0.0006325367139652371, "6": 0.0005721347406506538, "7": 0.0005222629988566041, "8": 0.00048038861132226884, "9": 0.0004447306564543396, "10": 0.1418469399213791, "11": 0.00038724273326806724, "12": 0.0003637337649706751, "13": 0.46939727663993835, "14": 0.000324351858580485, "15": 0.00030769463046453893, "16": 0.0002926647139247507, "17": 0.00027903474983759224, "18": 0.00026661783340387046, "19": 0.00025525889941491187}}, {"key": "dettmers2023efficient", "year": "2023", "title": "Qlora: Efficient Finetuning Of Quantized Llms", "topic_distr": {"0": 0.08509805053472519, "1": 0.0007957258494570851, "2": 0.16790615022182465, "3": 0.0005825941334478557, "4": 0.0005138223059475422, "5": 0.0004595762293320149, "6": 0.00041569056338630617, "7": 0.00037945571239106357, "8": 0.00034903144114650786, "9": 0.0857015922665596, "10": 0.00030079646967351437, "11": 0.03591424971818924, "12": 0.14688336849212646, "13": 0.342067688703537, "14": 0.00023566128220409155, "15": 0.0002235587890027091, "16": 0.00021263865346554667, "17": 0.02341143973171711, "18": 0.0001937140041263774, "19": 0.10835520178079605}}, {"key": "dettmers2023sparse", "year": "2023", "title": "Spqr: A Sparse-quantized Representation For Near-lossless LLM Weight Compression", "topic_distr": {"0": 0.0010306894546374679, "1": 0.0008416202035732567, "2": 0.15899482369422913, "3": 0.17304936051368713, "4": 0.0005435319617390633, "5": 0.019718803465366364, "6": 0.0004397253505885601, "7": 0.011334439739584923, "8": 0.00036921206628903747, "9": 0.06325478106737137, "10": 0.025086471810936928, "11": 0.0002976229880005121, "12": 0.0002795546897687018, "13": 0.531978964805603, "14": 0.00024928696802817285, "15": 0.00023648473143111914, "16": 0.0002249332028441131, "17": 0.00021445761376526207, "18": 0.00020491435134317726, "19": 0.011650328524410725}}, {"key": "devlin2018pre", "year": "2018", "title": "BERT: Pre-training Of Deep Bidirectional Transformers For Language Understanding", "topic_distr": {"0": 0.0016189347952604294, "1": 0.05050721764564514, "2": 0.38974300026893616, "3": 0.0009684049873612821, "4": 0.0008540945127606392, "5": 0.0007639249670319259, "6": 0.0006909766234457493, "7": 0.0006307457224465907, "8": 0.06192066892981529, "9": 0.0005371086299419403, "10": 0.4883597195148468, "11": 0.0004676795215345919, "12": 0.0004392873088363558, "13": 0.00041414512088522315, "14": 0.0003917251597158611, "15": 0.00037160792271606624, "16": 0.00035345606738701463, "17": 0.0003369949117768556, "18": 0.0003219987847842276, "19": 0.00030828043236397207}}, {"key": "devries2020as", "year": "2020", "title": "As Good As New. How To Successfully Recycle English GPT-2 To Make Models For Other Languages", "topic_distr": {"0": 0.18355216085910797, "1": 0.13030728697776794, "2": 0.12223485112190247, "3": 0.0008984488667920232, "4": 0.0007923945668153465, "5": 0.0007087384583428502, "6": 0.0006410599453374743, "7": 0.0005851801251992583, "8": 0.000538261141628027, "9": 0.0004983074613846838, "10": 0.20759807527065277, "11": 0.00043389396159909666, "12": 0.00040755284135229886, "13": 0.0003842269361484796, "14": 0.11665454506874084, "15": 0.14103351533412933, "16": 0.0003279221127741039, "17": 0.09181885421276093, "18": 0.00029873734456487, "19": 0.0002860100066754967}}, {"key": "dhillon2024shaping", "year": "2024", "title": "Shaping Human-ai Collaboration: Varied Scaffolding Levels In Co-writing With Language Models", "topic_distr": {"0": 0.07584335654973984, "1": 0.0014147545443847775, "2": 0.0011958626564592123, "3": 0.0010357447899878025, "4": 0.1095953956246376, "5": 0.0008170400396920741, "6": 0.0007390197133645415, "7": 0.18187561631202698, "8": 0.0006205122917890549, "9": 0.4819808304309845, "10": 0.0005347596015781164, "11": 0.000500196882057935, "12": 0.00046983061474747956, "13": 0.10267974436283112, "14": 0.00041896148468367755, "15": 0.0003974455175921321, "16": 0.0003780315746553242, "17": 0.03882879018783569, "18": 0.0003443871100898832, "19": 0.0003297149087302387}}, {"key": "dhingra2023mind", "year": "2023", "title": "Mind Meets Machine: Unravelling Gpt-4's Cognitive Psychology", "topic_distr": {"0": 0.23721474409103394, "1": 0.0010498472256585956, "2": 0.0008876058273017406, "3": 0.3980255126953125, "4": 0.0006780004478059709, "5": 0.0006064212648198009, "6": 0.0005485131405293941, "7": 0.0005007004365324974, "8": 0.0004605549038387835, "9": 0.13819856941699982, "10": 0.000396907766116783, "11": 0.0003712547186296433, "12": 0.14312636852264404, "13": 0.00032875791657716036, "14": 0.03619289770722389, "15": 0.00029499089578166604, "16": 0.04035048186779022, "17": 0.0002675142895895988, "18": 0.00025561003712937236, "19": 0.00024472008226439357}}, {"key": "dhoffschmidt2020french", "year": "2020", "title": "Fquad: French Question Answering Dataset", "topic_distr": {"0": 0.001780971186235547, "1": 0.05736634507775307, "2": 0.38864800333976746, "3": 0.0010652100900188088, "4": 0.0009394732769578695, "5": 0.0008402897510677576, "6": 0.0007600492681376636, "7": 0.0006937973666936159, "8": 0.2244909703731537, "9": 0.0005908000166527927, "10": 0.0005499767139554024, "11": 0.0005144304595887661, "12": 0.31901174783706665, "13": 0.0004555445921141654, "14": 0.0004308834613766521, "15": 0.00040875523700378835, "16": 0.00038878884515725076, "17": 0.000370682158973068, "18": 0.00035418698098510504, "19": 0.00033909728517755866}}, {"key": "dhuliawala2023chain", "year": "2023", "title": "Chain-of-verification Reduces Hallucination In Large Language Models", "topic_distr": {"0": 0.40665915608406067, "1": 0.0019583108369261026, "2": 0.0016556588234379888, "3": 0.2348695546388626, "4": 0.0012647436233237386, "5": 0.0011312197893857956, "6": 0.07371263951063156, "7": 0.13134340941905975, "8": 0.14082717895507812, "9": 0.0007953502936288714, "10": 0.0007403928902931511, "11": 0.0006925396737642586, "12": 0.0006504965131171048, "13": 0.0006132659618742764, "14": 0.0005800664657726884, "15": 0.0005502768908627331, "16": 0.0005233976407907903, "17": 0.0004990219604223967, "18": 0.0004768157086800784, "19": 0.0004565015551634133}}, {"key": "diao2022black", "year": "2022", "title": "Black-box Prompt Learning For Pre-trained Language Models", "topic_distr": {"0": 0.0010954044992104173, "1": 0.06714621186256409, "2": 0.0007552927127107978, "3": 0.08630414307117462, "4": 0.0005769551498815417, "5": 0.051947224885225296, "6": 0.00046676481724716723, "7": 0.0004260779242031276, "8": 0.00039191555697470903, "9": 0.12401466071605682, "10": 0.06914596259593964, "11": 0.00031592434970662, "12": 0.0002967449836432934, "13": 0.1199873760342598, "14": 0.00026461604284122586, "15": 0.0002510265912860632, "16": 0.00023876472550909966, "17": 0.47594916820526123, "18": 0.00021751488384325057, "19": 0.000208247933187522}}, {"key": "dibia2023tool", "year": "2023", "title": "LIDA: A Tool For Automatic Generation Of Grammar-agnostic Visualizations And Infographics Using Large Language Models", "topic_distr": {"0": 0.0015394482761621475, "1": 0.03445032984018326, "2": 0.0010629554744809866, "3": 0.0009206661488860846, "4": 0.09129293262958527, "5": 0.07906516641378403, "6": 0.2527971863746643, "7": 0.11658312380313873, "8": 0.0005515702650882304, "9": 0.1734629124403, "10": 0.0004753451212309301, "11": 0.0004446225066203624, "12": 0.00041763007175177336, "13": 0.000393727415939793, "14": 0.01630917191505432, "15": 0.00035328735248185694, "16": 0.000336030381731689, "17": 0.00032038078643381596, "18": 0.22893044352531433, "19": 0.0002930819464381784}}, {"key": "dinan2018wizard", "year": "2018", "title": "Wizard Of Wikipedia: Knowledge-powered Conversational Agents", "topic_distr": {"0": 0.08270248025655746, "1": 0.0011707437224686146, "2": 0.18489970266819, "3": 0.08757334202528, "4": 0.0007559950463473797, "5": 0.04912430793046951, "6": 0.1682693213224411, "7": 0.07385281473398209, "8": 0.0005135347601026297, "9": 0.0004754164256155491, "10": 0.0004425659717526287, "11": 0.1217026486992836, "12": 0.09600777179002762, "13": 0.00036657651071436703, "14": 0.0003467316855676472, "15": 0.0003289251180831343, "16": 0.13061097264289856, "17": 0.0002982877485919744, "18": 0.00028501407359726727, "19": 0.0002728714025579393}}, {"key": "dinan2019build", "year": "2019", "title": "Build It Break It Fix It For Dialogue Safety: Robustness From Adversarial Human Attack", "topic_distr": {"0": 0.2012377381324768, "1": 0.26852479577064514, "2": 0.12396600097417831, "3": 0.0010077119804918766, "4": 0.0008887593867257237, "5": 0.060877975076436996, "6": 0.1641705334186554, "7": 0.0006563449860550463, "8": 0.0006037200801074505, "9": 0.07474289834499359, "10": 0.0005202880129218102, "11": 0.00048666063230484724, "12": 0.09971699863672256, "13": 0.0004309535142965615, "14": 0.00040762362186796963, "15": 0.0003866899060085416, "16": 0.00036780134541913867, "17": 0.0003506721113808453, "18": 0.0003350673650857061, "19": 0.0003207922272849828}}, {"key": "dinan2019second", "year": "2019", "title": "The Second Conversational Intelligence Challenge (convai2)", "topic_distr": {"0": 0.12075257301330566, "1": 0.0021667820401489735, "2": 0.4834446609020233, "3": 0.001586541417054832, "4": 0.0013992696767672896, "5": 0.0012515416601672769, "6": 0.1862320452928543, "7": 0.0010333530372008681, "8": 0.024883633479475975, "9": 0.13764986395835876, "10": 0.000819144188426435, "11": 0.0007662010611966252, "12": 0.0007196860387921333, "13": 0.00067849550396204, "14": 0.0006417647236958146, "15": 0.0006088066147640347, "16": 0.0005790683790110052, "17": 0.0005521000130102038, "18": 0.0005275317816995084, "19": 0.033706892281770706}}, {"key": "ding2020ernie", "year": "2020", "title": "Ernie-doc: A Retrospective Long-document Modeling Transformer", "topic_distr": {"0": 0.001662180875428021, "1": 0.001357794157229364, "2": 0.31461453437805176, "3": 0.000994222704321146, "4": 0.0008768592379055917, "5": 0.0007842859486117959, "6": 0.0007093931781128049, "7": 0.0006475569098256528, "8": 0.08630989491939545, "9": 0.0005514241638593376, "10": 0.33308181166648865, "11": 0.0004801445466000587, "12": 0.00045099560520611703, "13": 0.07965157926082611, "14": 0.00040216578054241836, "15": 0.12218448519706726, "16": 0.0003628767153713852, "17": 0.0003459768195170909, "18": 0.0003305810096208006, "19": 0.05420120060443878}}, {"key": "ding2021mastering", "year": "2021", "title": "Cogview: Mastering Text-to-image Generation Via Transformers", "topic_distr": {"0": 0.002898163627833128, "1": 0.0023687148932367563, "2": 0.0020020517986267805, "3": 0.0017340370686724782, "4": 0.07894293963909149, "5": 0.0013678899267688394, "6": 0.0012372679775580764, "7": 0.0011294180294498801, "8": 0.0010388627415522933, "9": 0.0009617507457733154, "10": 0.19728121161460876, "11": 0.0008374304161407053, "12": 0.000786591146606952, "13": 0.0007415713625960052, "14": 0.000701426004525274, "15": 0.3269212245941162, "16": 0.0006329010939225554, "17": 0.0006034256075508893, "18": 0.23965829610824585, "19": 0.1381548047065735}}, {"key": "ding2021open", "year": "2021", "title": "Openprompt: An Open-source Framework For Prompt-learning", "topic_distr": {"0": 0.0014853730099275708, "1": 0.0012128049274906516, "2": 0.001024979748763144, "3": 0.0008877574582584202, "4": 0.0007829606183804572, "5": 0.0007002996862865984, "6": 0.0006334269419312477, "7": 0.05187569186091423, "8": 0.0005318521289154887, "9": 0.08667727559804916, "10": 0.12968169152736664, "11": 0.00042872762423940003, "12": 0.10968908667564392, "13": 0.0003796519886236638, "14": 0.00035909932921640575, "15": 0.0003406576288398355, "16": 0.00032401757198385894, "17": 0.612406849861145, "18": 0.00029518030351027846, "19": 0.0002826045092660934}}, {"key": "ding2021prompt", "year": "2021", "title": "Prompt-learning For Fine-grained Entity Typing", "topic_distr": {"0": 0.0016407569637522101, "1": 0.058282431215047836, "2": 0.0011329044355079532, "3": 0.0009812162024900317, "4": 0.1597602665424347, "5": 0.0007740271394141018, "6": 0.0007001141202636063, "7": 0.0006390867056325078, "8": 0.0005878455122001469, "9": 0.0005442113615572453, "10": 0.13802096247673035, "11": 0.0004738641146104783, "12": 0.0004450964624993503, "13": 0.00041962179238907993, "14": 0.00039690532139502466, "15": 0.00037652207538485527, "16": 0.04906613379716873, "17": 0.531430721282959, "18": 0.0003262569080106914, "19": 0.05400102958083153}}, {"key": "ding2022delta", "year": "2022", "title": "Delta Tuning: A Comprehensive Study Of Parameter Efficient Methods For Pre-trained Language Models", "topic_distr": {"0": 0.13581319153308868, "1": 0.0007434794679284096, "2": 0.1594899445772171, "3": 0.0005443453555926681, "4": 0.00048009041347540915, "5": 0.00042940452112816274, "6": 0.0003884000179823488, "7": 0.015333692543208599, "8": 0.00032611715141683817, "9": 0.00030191036057658494, "10": 0.00028104885132052004, "11": 0.0002628840447869152, "12": 0.16498516499996185, "13": 0.15333351492881775, "14": 0.00022018987510818988, "15": 0.00020888191647827625, "16": 0.00019867869559675455, "17": 0.36630481481552124, "18": 0.00018099647422786802, "19": 0.00017328534158878028}}, {"key": "ding2022faster", "year": "2022", "title": "Cogview2: Faster And Better Text-to-image Generation Via Hierarchical Transformers", "topic_distr": {"0": 0.003041086718440056, "1": 0.002483684103935957, "2": 0.20909754931926727, "3": 0.0018188455142080784, "4": 0.0016041554044932127, "5": 0.001434793695807457, "6": 0.15264946222305298, "7": 0.16674934327602386, "8": 0.0010896733729168773, "9": 0.0010087898699566722, "10": 0.2207459956407547, "11": 0.0008783890516497195, "12": 0.0008250632090494037, "13": 0.0007778415456414223, "14": 0.0007357326685450971, "15": 0.0006979487370699644, "16": 0.0006638561608269811, "17": 0.0006329391035251319, "18": 0.20074336230754852, "19": 0.03232153132557869}}, {"key": "ding2022is", "year": "2022", "title": "Is GPT-3 A Good Data Annotator?", "topic_distr": {"0": 0.17332617938518524, "1": 0.5458307266235352, "2": 0.0014349193079397082, "3": 0.0012427907204255462, "4": 0.001096090069040656, "5": 0.00098037114366889, "6": 0.0008867536089383066, "7": 0.06449229270219803, "8": 0.0007445559604093432, "9": 0.0006892895908094943, "10": 0.0006416608230210841, "11": 0.0006001888541504741, "12": 0.15786707401275635, "13": 0.0005314864101819694, "14": 0.04746377840638161, "15": 0.0004768969665747136, "16": 0.00045360205695033073, "17": 0.00043247692519798875, "18": 0.00041323190089315176, "19": 0.00039562664460390806}}, {"key": "ding2022multimodal", "year": "2022", "title": "Mukea: Multimodal Knowledge Extraction And Accumulation For Knowledge-based Visual Question Answering", "topic_distr": {"0": 0.0012238930212333798, "1": 0.0009985007345676422, "2": 0.0008441251702606678, "3": 0.000731121632270515, "4": 0.0006448187632486224, "5": 0.000576742400880903, "6": 0.0005216683493927121, "7": 0.0004761956224683672, "8": 0.15269681811332703, "9": 0.00040550221456214786, "10": 0.0003774826764129102, "11": 0.00035308513906784356, "12": 0.0003316498186904937, "13": 0.0003126681549474597, "14": 0.0002957416872959584, "15": 0.0002805537369567901, "16": 0.3635599613189697, "17": 0.0002544218732509762, "18": 0.4748823642730713, "19": 0.0002327432157471776}}, {"key": "ding2022vision", "year": "2022", "title": "VLT: Vision-language Transformer And Query Generation For Referring Segmentation", "topic_distr": {"0": 0.0011658589355647564, "1": 0.0009517872822470963, "2": 0.449701726436615, "3": 0.0006968938978388906, "4": 0.0006146320374682546, "5": 0.000549742893781513, "6": 0.08217383176088333, "7": 0.00045390319428406656, "8": 0.0666118636727333, "9": 0.0003865191829390824, "10": 0.0682489275932312, "11": 0.0003365559387020767, "12": 0.00031612408929504454, "13": 0.00029803102370351553, "14": 0.0002818969660438597, "15": 0.00026741999317891896, "16": 0.022994110360741615, "17": 0.0002425114653306082, "18": 0.30348584055900574, "19": 0.00022184767294675112}}, {"key": "ding2023enhancing", "year": "2023", "title": "Enhancing Chat Language Models By Scaling High-quality Instructional Conversations", "topic_distr": {"0": 0.0013720260467380285, "1": 0.3032386302947998, "2": 0.0009461071458645165, "3": 0.20910310745239258, "4": 0.0007227262831293046, "5": 0.0006464247708208859, "6": 0.27028337121009827, "7": 0.0005337298498488963, "8": 0.0004909360432066023, "9": 0.14828670024871826, "10": 0.00042309032869525254, "11": 0.0003957450680900365, "12": 0.061443429440259933, "13": 0.00035044486867263913, "14": 0.0003314733621664345, "15": 0.0003144503862131387, "16": 0.000299090490443632, "17": 0.00028516125166788697, "18": 0.00027247171965427697, "19": 0.0002608633949421346}}, {"key": "ding2023hpc", "year": "2023", "title": "HPC-GPT: Integrating Large Language Model For High-performance Computing", "topic_distr": {"0": 0.0018075663829222322, "1": 0.0014763862127438188, "2": 0.0012477205600589514, "3": 0.5128391981124878, "4": 0.0009531277464702725, "5": 0.0008525014272890985, "6": 0.06424370408058167, "7": 0.0007038799813017249, "8": 0.020426476374268532, "9": 0.1050623431801796, "10": 0.0005579692660830915, "11": 0.0005219064769335091, "12": 0.1893376111984253, "13": 0.09764386713504791, "14": 0.0004371452669147402, "15": 0.00041469547431916, "16": 0.00039443891728296876, "17": 0.00037606910336762667, "18": 0.00035933422623202205, "19": 0.0003440252039581537}}, {"key": "ding2023integrating", "year": "2023", "title": "Integrating Action Knowledge And Llms For Task Planning And Situation Handling In Open Worlds", "topic_distr": {"0": 0.07633516192436218, "1": 0.0009343868587166071, "2": 0.0007898854673840106, "3": 0.2709078788757324, "4": 0.17056596279144287, "5": 0.024920472875237465, "6": 0.00048815400805324316, "7": 0.0004456026654224843, "8": 0.00040987483225762844, "9": 0.0003794509102590382, "10": 0.00035323150223121047, "11": 0.21352256834506989, "12": 0.06705357879400253, "13": 0.0002925809531006962, "14": 0.0002767419209703803, "15": 0.00026252970565110445, "16": 0.17137861251831055, "17": 0.0002380766673013568, "18": 0.00022748236369807273, "19": 0.00021779075905214995}}, {"key": "ding2023scaling", "year": "2023", "title": "Longnet: Scaling Transformers To 1,000,000,000 Tokens", "topic_distr": {"0": 0.0015584586653858423, "1": 0.0012730055022984743, "2": 0.3259403705596924, "3": 0.000932111928705126, "4": 0.0008220863528549671, "5": 0.0007352958782576025, "6": 0.0006650810828432441, "7": 0.0006071073585189879, "8": 0.0005584302707575262, "9": 0.032463353127241135, "10": 0.3797513544559479, "11": 0.0004501523799262941, "12": 0.0004228242323733866, "13": 0.2518143653869629, "14": 0.00037704454734921455, "15": 0.0003576812450774014, "16": 0.0003402096626814455, "17": 0.0003243654209654778, "18": 0.00030993131804279983, "19": 0.00029672705568373203}}, {"key": "dinh2022language", "year": "2022", "title": "LIFT: Language-interfaced Fine-tuning For Non-language Machine Learning Tasks", "topic_distr": {"0": 0.09065180271863937, "1": 0.02647329680621624, "2": 0.20034359395503998, "3": 0.10036297142505646, "4": 0.0005347072146832943, "5": 0.009329509921371937, "6": 0.00043258650111965835, "7": 0.025999555364251137, "8": 0.01701708696782589, "9": 0.00033625730429776013, "10": 0.27781277894973755, "11": 0.00029279114096425474, "12": 0.0002750161802396178, "13": 0.0002592758974060416, "14": 0.01489061489701271, "15": 0.00023264545598067343, "16": 0.00022128145792521536, "17": 0.15013225376605988, "18": 0.015085489489138126, "19": 0.06931646913290024}}, {"key": "do2020e", "year": "2020", "title": "E-snli-ve: Corrected Visual-textual Entailment With Natural Language Explanations", "topic_distr": {"0": 0.11154082417488098, "1": 0.0016699493862688541, "2": 0.0014113581273704767, "3": 0.3124103546142578, "4": 0.0010781079763546586, "5": 0.4916931390762329, "6": 0.0008722068159841001, "7": 0.0007961784140206873, "8": 0.000732341839466244, "9": 0.0006779821123927832, "10": 0.0006311346660368145, "11": 0.0005903430283069611, "12": 0.0005545041058212519, "13": 0.000522767601069063, "14": 0.0004944672691635787, "15": 0.00046907368232496083, "16": 0.00044616093509830534, "17": 0.0004253823426552117, "18": 0.07259461283683777, "19": 0.0003891365777235478}}, {"key": "dodge2020fine", "year": "2020", "title": "Fine-tuning Pretrained Language Models: Weight Initializations, Data Orders, And Early Stopping", "topic_distr": {"0": 0.11239168792963028, "1": 0.001072298618964851, "2": 0.5419917702674866, "3": 0.0007849222747609019, "4": 0.0006922682514414191, "5": 0.0006191831198520958, "6": 0.0005600563599728048, "7": 0.0005112374783493578, "8": 0.0004702470905613154, "9": 0.00043534193537198007, "10": 0.0902746245265007, "11": 0.0003790676419157535, "12": 0.0003560549521353096, "13": 0.12579424679279327, "14": 0.00031750445486977696, "15": 0.00030119885923340917, "16": 0.0002864862617570907, "17": 0.0002731440181378275, "18": 0.00026098923990502954, "19": 0.12222764641046524}}, {"key": "dohan2022language", "year": "2022", "title": "Language Model Cascades", "topic_distr": {"0": 0.002715301001444459, "1": 0.00221450999379158, "2": 0.19658751785755157, "3": 0.6818777918815613, "4": 0.036585383117198944, "5": 0.0012788475723937154, "6": 0.0011567285982891917, "7": 0.001055898959748447, "8": 0.000971238303463906, "9": 0.000899145903531462, "10": 0.0008370164432562888, "11": 0.0007829182432033122, "12": 0.000735388312023133, "13": 0.0006932990509085357, "14": 0.0006557669257745147, "15": 0.0006220897193998098, "16": 0.06871191412210464, "17": 0.0005641458556056023, "18": 0.0005390416481532156, "19": 0.0005160763976164162}}, {"key": "donahue2019improving", "year": "2019", "title": "Lakhnes: Improving Multi-instrumental Music Generation With Cross-domain Pre-training", "topic_distr": {"0": 0.0017832540906965733, "1": 0.16971048712730408, "2": 0.001230096910148859, "3": 0.22373557090759277, "4": 0.000939622987061739, "5": 0.0008404232794418931, "6": 0.0007601698162034154, "7": 0.0006939074373804033, "8": 0.0006382708088494837, "9": 0.0005908937309868634, "10": 0.22789989411830902, "11": 0.028412245213985443, "12": 0.00048327675904147327, "13": 0.0004556168569251895, "14": 0.13380904495716095, "15": 0.12254129350185394, "16": 0.0003888505161739886, "17": 0.00037074097781442106, "18": 0.08437720686197281, "19": 0.0003391510690562427}}, {"key": "donahue2020enabling", "year": "2020", "title": "Enabling Language Models To Fill In The Blanks", "topic_distr": {"0": 0.0017564618028700352, "1": 0.0014344531809911132, "2": 0.0012127343798056245, "3": 0.08853128552436829, "4": 0.0009263556567020714, "5": 0.0008285552612505853, "6": 0.000749434984754771, "7": 0.6074142456054688, "8": 0.04365162178874016, "9": 0.15459659695625305, "10": 0.0005422962130978703, "11": 0.000507246411871165, "12": 0.00047645214363001287, "13": 0.0004491828731261194, "14": 0.00042486609891057014, "15": 0.000403046899009496, "16": 0.00038335935096256435, "17": 0.00036550554796122015, "18": 0.00034924072679132223, "19": 0.09499703347682953}}, {"key": "dong2019unified", "year": "2019", "title": "Unified Language Model Pre-training For Natural Language Understanding And Generation", "topic_distr": {"0": 0.001598972943611443, "1": 0.0013054815353825688, "2": 0.23434558510780334, "3": 0.000955943251028657, "4": 0.018506309017539024, "5": 0.0007540931110270321, "6": 0.030850201845169067, "7": 0.19546489417552948, "8": 0.07900144904851913, "9": 0.0005301959463395178, "10": 0.43332555890083313, "11": 0.0004616603837348521, "12": 0.0004336335987318307, "13": 0.000408814987167716, "14": 0.000386683561373502, "15": 0.00036682526115328074, "16": 0.0003489070222713053, "17": 0.00033265771344304085, "18": 0.00031785460305400193, "19": 0.00030431279446929693}}, {"key": "dong2021how", "year": "2021", "title": "How Should Pre-trained Language Models Be Fine-tuned Towards Adversarial Robustness?", "topic_distr": {"0": 0.0017565960297361016, "1": 0.440660297870636, "2": 0.31623998284339905, "3": 0.0010502724908292294, "4": 0.0009262965177185833, "5": 0.0008285033982247114, "6": 0.0007493883604183793, "7": 0.0006840657442808151, "8": 0.0006292182370088995, "9": 0.0005825131083838642, "10": 0.13965250551700592, "11": 0.000507214805111289, "12": 0.000476422457722947, "13": 0.00044915487524122, "14": 0.0004248396144248545, "15": 0.0004030217824038118, "16": 0.09293065965175629, "17": 0.0003654827596619725, "18": 0.0003492189571261406, "19": 0.0003343409043736756}}, {"key": "dong2022masked", "year": "2022", "title": "Maskclip: Masked Self-distillation Advances Contrastive Language-image Pretraining", "topic_distr": {"0": 0.0013129216386005282, "1": 0.0010720273712649941, "2": 0.2298949509859085, "3": 0.0007849510875530541, "4": 0.0006922953762114048, "5": 0.0006192071014083922, "6": 0.0005600780714303255, "7": 0.0005112572689540684, "8": 0.00047026530955918133, "9": 0.0004353587864898145, "10": 0.18269634246826172, "11": 0.0003790823102463037, "12": 0.00035606874735094607, "13": 0.022277476266026497, "14": 0.0003175167366862297, "15": 0.0003012105298694223, "16": 0.09973347932100296, "17": 0.00027315461193211377, "18": 0.31906723976135254, "19": 0.1382451206445694}}, {"key": "dou2018exploiting", "year": "2018", "title": "Exploiting Deep Representations For Neural Machine Translation", "topic_distr": {"0": 0.0018607079982757568, "1": 0.0015203994698822498, "2": 0.3737608790397644, "3": 0.001113081001676619, "4": 0.03271783888339996, "5": 0.0008780485368333757, "6": 0.000794202322140336, "7": 0.00072497344808653, "8": 0.0006668459973298013, "9": 0.0006173478323034942, "10": 0.27860620617866516, "11": 0.0005375466425903141, "12": 0.03860096633434296, "13": 0.0004760146839544177, "14": 0.18323194980621338, "15": 0.0004271228099241853, "16": 0.08235406875610352, "17": 0.00038733892142772675, "18": 0.00037010249798186123, "19": 0.0003543347411323339}}, {"key": "dou2021empirical", "year": "2021", "title": "An Empirical Study Of Training End-to-end Vision-and-language Transformers", "topic_distr": {"0": 0.0016192080220207572, "1": 0.0013226052979007363, "2": 0.0011180560104548931, "3": 0.0009683581301942468, "4": 0.0008540491689927876, "5": 0.0007638839306309819, "6": 0.0006909394869580865, "7": 0.0006307117873802781, "8": 0.0005801421357318759, "9": 0.0005370797007344663, "10": 0.35086867213249207, "11": 0.00046765434672124684, "12": 0.00043926367652602494, "13": 0.00041412285645492375, "14": 0.0003917040885426104, "15": 0.00037158792838454247, "16": 0.0003534370334818959, "17": 0.00033697678009048104, "18": 0.40957313776016235, "19": 0.2276984304189682}}, {"key": "dou2021is", "year": "2021", "title": "Is GPT-3 Text Indistinguishable From Human Text? Scarecrow: A Framework For Scrutinizing Machine Text", "topic_distr": {"0": 0.12128271162509918, "1": 0.10299568623304367, "2": 0.0007000270998105407, "3": 0.10405583679676056, "4": 0.0005347357946448028, "5": 0.00047828175593167543, "6": 0.0004326098714955151, "7": 0.30630239844322205, "8": 0.0003632376028690487, "9": 0.00033627546508796513, "10": 0.021846413612365723, "11": 0.032389212399721146, "12": 0.13230295479297638, "13": 0.04030800983309746, "14": 0.09372469037771225, "15": 0.0411200225353241, "16": 0.00022129340504761785, "17": 0.00021098733122926205, "18": 0.00020159849373158067, "19": 0.00019300963322166353}}, {"key": "dou2022coarse", "year": "2022", "title": "Coarse-to-fine Vision-language Pre-training With Fusion In The Backbone", "topic_distr": {"0": 0.0011335544986650348, "1": 0.07801967859268188, "2": 0.3549393117427826, "3": 0.0006778882234357297, "4": 0.0005978701519779861, "5": 0.0005347509286366403, "6": 0.0004836866573896259, "7": 0.0004415247531142086, "8": 0.00040612384327687323, "9": 0.00037597838672809303, "10": 0.0649307370185852, "11": 0.0003273776965215802, "12": 0.00030750303994864225, "13": 0.0002899034006986767, "14": 0.00027420930564403534, "15": 0.02124721184372902, "16": 0.00024742077221162617, "17": 0.00023589791089762002, "18": 0.4743135869503021, "19": 0.00021579764143098146}}, {"key": "doughty2023comparative", "year": "2023", "title": "A Comparative Study Of Ai-generated (GPT-4) And Human-crafted Mcqs In Programming Education", "topic_distr": {"0": 0.2920302152633667, "1": 0.07352974265813828, "2": 0.0013044942170381546, "3": 0.17877328395843506, "4": 0.0009964830242097378, "5": 0.0008912802441045642, "6": 0.1735125184059143, "7": 0.0007358984439633787, "8": 0.0006768950261175632, "9": 0.27299293875694275, "10": 0.0005833504255861044, "11": 0.0005456471699289978, "12": 0.0005125216557644308, "13": 0.00048318799235858023, "14": 0.0004570303426589817, "15": 0.00043355932575650513, "16": 0.0004123813414480537, "17": 0.00039317592745646834, "18": 0.00037567978142760694, "19": 0.00035967439180240035}}, {"key": "driess2023palm", "year": "2023", "title": "Palm-e: An Embodied Multimodal Language Model", "topic_distr": {"0": 0.0014688496012240648, "1": 0.019818123430013657, "2": 0.001012965221889317, "3": 0.16127713024616241, "4": 0.000773782841861248, "5": 0.0006920906016603112, "6": 0.0006260017398744822, "7": 0.0005714345024898648, "8": 0.000525617622770369, "9": 0.00048660245374776423, "10": 0.07677990198135376, "11": 0.23143646121025085, "12": 0.0003979796019848436, "13": 0.07839290797710419, "14": 0.00035488989669829607, "15": 0.000336664350470528, "16": 0.0003202193765901029, "17": 0.00030530610820278525, "18": 0.4241437613964081, "19": 0.00027929176576435566}}, {"key": "drozdov2022compositional", "year": "2022", "title": "Compositional Semantic Parsing With Large Language Models", "topic_distr": {"0": 0.03527145832777023, "1": 0.0013404834317043424, "2": 0.25407156348228455, "3": 0.4434583783149719, "4": 0.0008654058910906315, "5": 0.0007740414584986866, "6": 0.0007001269259490073, "7": 0.0006390983471646905, "8": 0.0005878562806174159, "9": 0.0844605565071106, "10": 0.0005066165467724204, "11": 0.17434798181056976, "12": 0.00044510458246804774, "13": 0.00041962944669649005, "14": 0.0003969125682488084, "15": 0.00037652894388884306, "16": 0.0003581367200240493, "17": 0.0003414575767237693, "18": 0.00032626287429593503, "19": 0.0003123628266621381}}, {"key": "du2017learning", "year": "2017", "title": "Learning To Ask: Neural Question Generation For Reading Comprehension", "topic_distr": {"0": 0.001890862942673266, "1": 0.0015433628577739, "2": 0.3889487087726593, "3": 0.0011298621539026499, "4": 0.0009964912896975875, "5": 0.0008912869961932302, "6": 0.0008061765693128109, "7": 0.10649067908525467, "8": 0.23104871809482574, "9": 0.0006266555865295231, "10": 0.000583354732953012, "11": 0.0005456512444652617, "12": 0.0005125254392623901, "13": 0.0004831915721297264, "14": 0.00045703371870331466, "15": 0.26150447130203247, "16": 0.0004123843973502517, "17": 0.000393178837839514, "18": 0.00037568254629150033, "19": 0.00035967706935480237}}, {"key": "du2021efficient", "year": "2021", "title": "Glam: Efficient Scaling Of Language Models With Mixture-of-experts", "topic_distr": {"0": 0.001889305072836578, "1": 0.0891590565443039, "2": 0.0013043694198131561, "3": 0.0011297445744276047, "4": 0.0009963884949684143, "5": 0.0008911959012039006, "6": 0.0008060942636802793, "7": 0.0007358287693932652, "8": 0.0006768309394828975, "9": 0.0006265916163101792, "10": 0.0005832951865158975, "11": 0.0005455955397337675, "12": 0.08329816162586212, "13": 0.8149262070655823, "14": 0.0004569870652630925, "15": 0.00043351828935556114, "16": 0.0004123422841075808, "17": 0.0003931387036573142, "18": 0.0003756442165467888, "19": 0.00035964034032076597}}, {"key": "du2021general", "year": "2021", "title": "GLM: General Language Model Pretraining With Autoregressive Blank Infilling", "topic_distr": {"0": 0.0015030212234705687, "1": 0.0012271074810996652, "2": 0.13477429747581482, "3": 0.15566952526569366, "4": 0.0007923573139123619, "5": 0.000708704988937825, "6": 0.0006410296773537993, "7": 0.16976578533649445, "8": 0.0005382357630878687, "9": 0.0004982839454896748, "10": 0.34927400946617126, "11": 0.00043387350160628557, "12": 0.00040753360372036695, "13": 0.050698913633823395, "14": 0.00036340946098789573, "15": 0.0003447463968768716, "16": 0.0003279066295363009, "17": 0.0003126353840343654, "18": 0.00029872325831092894, "19": 0.1314198523759842}}, {"key": "du2021towards", "year": "2021", "title": "Towards Interpreting And Mitigating Shortcut Learning Behavior Of NLU Models", "topic_distr": {"0": 0.14155980944633484, "1": 0.20987460017204285, "2": 0.2632206678390503, "3": 0.0009206904796883464, "4": 0.0008120119455270469, "5": 0.04651198163628578, "6": 0.0006569286924786866, "7": 0.0005996656254865229, "8": 0.0005515852244570851, "9": 0.0005106425378471613, "10": 0.1903577744960785, "11": 0.08692567050457001, "12": 0.00041764136403799057, "13": 0.055098988115787506, "14": 0.0003724228299688548, "15": 0.00035329689853824675, "16": 0.0003360394621267915, "17": 0.0003203894302714616, "18": 0.0003061322495341301, "19": 0.00029308986268006265}}, {"key": "du2022contrastive", "year": "2022", "title": "Contrastive Learning With Bidirectional Transformers For Sequential Recommendation", "topic_distr": {"0": 0.0012469969224184752, "1": 0.054135650396347046, "2": 0.0008610099903307855, "3": 0.0007457404863089323, "4": 0.35857224464416504, "5": 0.0005882731638848782, "6": 0.000532098114490509, "7": 0.00048571627121418715, "8": 0.0004467721446417272, "9": 0.00041360946488566697, "10": 0.5793496966362, "11": 0.0003601444186642766, "12": 0.00033828054438345134, "13": 0.00031891936669126153, "14": 0.0003016545088030398, "15": 0.0002861628890968859, "16": 0.00027218475588597357, "17": 0.00025950855342671275, "18": 0.0002479605609551072, "19": 0.0002373964962316677}}, {"key": "du2022retrieval", "year": "2022", "title": "Retrieval-augmented Generative Question Answering For Event Argument Extraction", "topic_distr": {"0": 0.001539780991151929, "1": 0.0012574041029438376, "2": 0.33585619926452637, "3": 0.08606500178575516, "4": 0.0008119621779769659, "5": 0.0007262391154654324, "6": 0.00065688940230757, "7": 0.0005996297695674002, "8": 0.09923253953456879, "9": 0.0005106119788251817, "10": 0.00047532955068163574, "11": 0.00044460795470513403, "12": 0.0004176163929514587, "13": 0.00039371452294290066, "14": 0.0003724005655385554, "15": 0.08920995891094208, "16": 0.0003360193513799459, "17": 0.3804948925971985, "18": 0.0003061139432247728, "19": 0.0002930723421741277}}, {"key": "du2022shortcut", "year": "2022", "title": "Shortcut Learning Of Large Language Models In Natural Language Understanding", "topic_distr": {"0": 0.10690342634916306, "1": 0.10257988423109055, "2": 0.0013043457875028253, "3": 0.18548689782619476, "4": 0.000996374525129795, "5": 0.0008911836193874478, "6": 0.0008060829131864011, "7": 0.0007358184666372836, "8": 0.0006768214516341686, "9": 0.0006265828269533813, "10": 0.0005832870374433696, "11": 0.09714805334806442, "12": 0.49834689497947693, "13": 0.0004831354890484363, "14": 0.00045698066242039204, "15": 0.0004335122066549957, "16": 0.00041233652154915035, "17": 0.00039313320303335786, "18": 0.00037563894875347614, "19": 0.00035963530535809696}}, {"key": "du2022survey", "year": "2022", "title": "A Survey Of Vision-language Pre-trained Models", "topic_distr": {"0": 0.0018334378255531192, "1": 0.001497729099355638, "2": 0.0012659583007916808, "3": 0.0010965034598484635, "4": 0.000967073196079582, "5": 0.00086497503798455, "6": 0.0007823772029951215, "7": 0.000714179128408432, "8": 0.0006569171673618257, "9": 0.000608155969530344, "10": 0.15854807198047638, "11": 0.0005295429727993906, "12": 0.5882519483566284, "13": 0.00046892717364244163, "14": 0.00044354156125336885, "15": 0.0004207632737234235, "16": 0.0004002103232778609, "17": 0.00038157173548825085, "18": 0.23991909623146057, "19": 0.00034905897337011993}}, {"key": "du2023enhancing", "year": "2023", "title": "Enhancing Job Recommendation Through Llm-based Generative Adversarial Networks", "topic_distr": {"0": 0.0009316573850810528, "1": 0.05708367004990578, "2": 0.000642484868876636, "3": 0.17667412757873535, "4": 0.3220173716545105, "5": 0.0004389778769109398, "6": 0.0003970591933466494, "7": 0.00036244839429855347, "8": 0.00033338775392621756, "9": 0.0003086412907578051, "10": 0.00028731467318721116, "11": 0.00026874488685280085, "12": 0.00025242974516004324, "13": 0.000237982181715779, "14": 0.0002250988909509033, "15": 0.16369666159152985, "16": 0.27528610825538635, "17": 0.00019364898616913706, "18": 0.0001850316912168637, "19": 0.00017714864225126803}}, {"key": "du2023guiding", "year": "2023", "title": "Guiding Pretraining In Reinforcement Learning With Large Language Models", "topic_distr": {"0": 0.0014672217657789588, "1": 0.0011982052819803357, "2": 0.0010128833819180727, "3": 0.3172897696495056, "4": 0.07018881291151047, "5": 0.0006920439191162586, "6": 0.0006259593646973372, "7": 0.03658655658364296, "8": 0.0005255820578895509, "9": 0.0004865695082116872, "10": 0.0004529483849182725, "11": 0.3902030885219574, "12": 0.00039795268094167113, "13": 0.00037517622695304453, "14": 0.0003548658569343388, "15": 0.0003366415621712804, "16": 0.0462225116789341, "17": 0.00030528544448316097, "18": 0.00029170038760639727, "19": 0.13098621368408203}}, {"key": "du2023improving", "year": "2023", "title": "Improving Factuality And Reasoning In Language Models Through Multiagent Debate", "topic_distr": {"0": 0.16516003012657166, "1": 0.0011442205868661404, "2": 0.000967338855843991, "3": 0.6706453561782837, "4": 0.000738933973480016, "5": 0.0006609215633943677, "6": 0.025704680010676384, "7": 0.06623441725969315, "8": 0.0005019459640607238, "9": 0.0004646878514904529, "10": 0.00043257870129309595, "11": 0.01996776834130287, "12": 0.04521578177809715, "13": 0.0003583040670491755, "14": 0.0003389070916455239, "15": 0.0003215023607481271, "16": 0.0003057979920413345, "17": 0.00029155638185329735, "18": 0.00027858224348165095, "19": 0.0002667135850060731}}, {"key": "du2023manually", "year": "2023", "title": "Classeval: A Manually-crafted Benchmark For Evaluating Llms On Class-level Code Generation", "topic_distr": {"0": 0.1057121530175209, "1": 0.018904220312833786, "2": 0.0007687738398090005, "3": 0.43811747431755066, "4": 0.0005872604670003057, "5": 0.000525261159054935, "6": 0.2889433801174164, "7": 0.0004336895071901381, "8": 0.0003989168326370418, "9": 0.00036930630449205637, "10": 0.00034378786222077906, "11": 0.00032156810630112886, "12": 0.04056471586227417, "13": 0.00028475880390033126, "14": 0.00026934323250316083, "15": 0.1025473102927208, "16": 0.00024303009558934718, "17": 0.0002317116886842996, "18": 0.0002214006381109357, "19": 0.00021196813031565398}}, {"key": "dua2022successive", "year": "2022", "title": "Successive Prompting For Decomposing Complex Questions", "topic_distr": {"0": 0.0011545652523636818, "1": 0.0399269238114357, "2": 0.2071855068206787, "3": 0.5146081447601318, "4": 0.0006089636008255184, "5": 0.0005446732975542545, "6": 0.0004926615511067212, "7": 0.0004497173067647964, "8": 0.1921330988407135, "9": 0.0003829547204077244, "10": 0.0003564931976143271, "11": 0.0003334522480145097, "12": 0.000313208787702024, "13": 0.0002952826034743339, "14": 0.0002792973245959729, "15": 0.00026495388010516763, "16": 0.0002520117268431932, "17": 0.00024027502513490617, "18": 0.00022958290355745703, "19": 0.03994825854897499}}, {"key": "dubois2023simulation", "year": "2023", "title": "Alpacafarm: A Simulation Framework For Methods That Learn From Human Feedback", "topic_distr": {"0": 0.15647035837173462, "1": 0.000885767862200737, "2": 0.0007486363756470382, "3": 0.26145273447036743, "4": 0.2318378984928131, "5": 0.0005115001695230603, "6": 0.00046265622950159013, "7": 0.0004223274881951511, "8": 0.0003884658217430115, "9": 0.0003596310561988503, "10": 0.00033478112891316414, "11": 0.15381205081939697, "12": 0.06337320059537888, "13": 0.1275445520877838, "14": 0.000262286834185943, "15": 0.00024881697027012706, "16": 0.00023666306515224278, "17": 0.00022564119717571884, "18": 0.00021560027380473912, "19": 0.00020641488663386554}}, {"key": "duckworth2019parallel", "year": "2019", "title": "Parallel Scheduled Sampling", "topic_distr": {"0": 0.07859206944704056, "1": 0.0011443446855992079, "2": 0.3248671591281891, "3": 0.0008378407801501453, "4": 0.07257828116416931, "5": 0.0006609281990677118, "6": 0.0005978152039460838, "7": 0.2778680920600891, "8": 0.0005019509699195623, "9": 0.0004646924789994955, "10": 0.00043258300866000354, "11": 0.0004046242102049291, "12": 0.0003800600243266672, "13": 0.1434084177017212, "14": 0.06426085531711578, "15": 0.00032150556216947734, "16": 0.00030580104794353247, "17": 0.00029155926313251257, "18": 0.03181472420692444, "19": 0.00026671626255847514}}, {"key": "dugan2022real", "year": "2022", "title": "Real Or Fake Text?: Investigating Human Ability To Detect Boundaries Between Human-written And Machine-generated Text", "topic_distr": {"0": 0.37693414092063904, "1": 0.2568735182285309, "2": 0.0008199797593988478, "3": 0.0007101978990249336, "4": 0.0006263631512410939, "5": 0.0005602357559837401, "6": 0.025414811447262764, "7": 0.1998404562473297, "8": 0.026067297905683517, "9": 0.0003938965674024075, "10": 0.00036667895619757473, "11": 0.000342979677952826, "12": 0.05614961311221123, "13": 0.013804711401462555, "14": 0.000287277449388057, "15": 0.00027252416475676, "16": 0.00025921224732883275, "17": 0.03981386125087738, "18": 0.00023614258680026978, "19": 0.00022608201834373176}}, {"key": "dunn2017new", "year": "2017", "title": "Searchqa: A New Q&A Dataset Augmented With Context From A Search Engine", "topic_distr": {"0": 0.0015424176817759871, "1": 0.0012577342567965388, "2": 0.34891870617866516, "3": 0.0009207377443090081, "4": 0.0008120459388010204, "5": 0.0007263151346705854, "6": 0.21063293516635895, "7": 0.0005996925756335258, "8": 0.0005516099627129734, "9": 0.0005106654716655612, "10": 0.0004753793473355472, "11": 0.0004446545208338648, "12": 0.17445270717144012, "13": 0.00039375576307065785, "14": 0.10594551265239716, "15": 0.15055939555168152, "16": 0.0003360545670147985, "17": 0.0003204038366675377, "18": 0.00030614601564593613, "19": 0.00029310304671525955}}, {"key": "du\u0161ek2018findings", "year": "2018", "title": "Findings Of The E2E NLG Challenge", "topic_distr": {"0": 0.08921684324741364, "1": 0.11670347303152084, "2": 0.220723494887352, "3": 0.0011472670594230294, "4": 0.18298660218715668, "5": 0.05169882997870445, "6": 0.06893658638000488, "7": 0.067596435546875, "8": 0.0006873278180137277, "9": 0.0006363093270920217, "10": 0.0005923414137214422, "11": 0.0005540570709854364, "12": 0.19556087255477905, "13": 0.0004906352260150015, "14": 0.0004640744300559163, "15": 0.00044024165254086256, "16": 0.0004187372687738389, "17": 0.00039923583972267807, "18": 0.00038147001760080457, "19": 0.00036521797301247716}}, {"key": "dziri2018augmenting", "year": "2018", "title": "Augmenting Neural Response Generation With Context-aware Topical Attention", "topic_distr": {"0": 0.032564423978328705, "1": 0.001339996699243784, "2": 0.14269034564495087, "3": 0.0009812089847400784, "4": 0.0008653885452076793, "5": 0.0007740246364846826, "6": 0.5987748503684998, "7": 0.000639084551949054, "8": 0.0005878435913473368, "9": 0.0005442095571197569, "10": 0.1071421429514885, "11": 0.0004738625430036336, "12": 0.000445094978203997, "13": 0.000419620395405218, "14": 0.0003969040117226541, "15": 0.00037652082392014563, "16": 0.07410801202058792, "17": 0.00034145021345466375, "18": 0.036222655326128006, "19": 0.0003123561036773026}}, {"key": "dziri2021neural", "year": "2021", "title": "Neural Path Hunter: Reducing Hallucination In Dialogue Systems Via Path Grounding", "topic_distr": {"0": 0.20269109308719635, "1": 0.0011191277299076319, "2": 0.0009461598820053041, "3": 0.2016063928604126, "4": 0.0007227482856251299, "5": 0.10964612662792206, "6": 0.24677009880542755, "7": 0.0704110786318779, "8": 0.0004909512936137617, "9": 0.00045450928155332804, "10": 0.0004231034545227885, "11": 0.05773552879691124, "12": 0.0003717314393725246, "13": 0.00035045575350522995, "14": 0.00033148363581858575, "15": 0.0003144601359963417, "16": 0.06744463741779327, "17": 0.0002851700992323458, "18": 0.0002724801597651094, "19": 0.037612706422805786}}, {"key": "dziri2022faithful", "year": "2022", "title": "Faithdial: A Faithful Benchmark For Information-seeking Dialogue", "topic_distr": {"0": 0.13934233784675598, "1": 0.001144286128692329, "2": 0.15996204316616058, "3": 0.0008378321072086692, "4": 0.0007389316451735795, "5": 0.09589488059282303, "6": 0.4025305509567261, "7": 0.10826501995325089, "8": 0.0005019441596232355, "9": 0.0004646862216759473, "10": 0.0004325771878939122, "11": 0.0004046187677886337, "12": 0.07774683088064194, "13": 0.00035830281558446586, "14": 0.0003389058983884752, "15": 0.0003215012256987393, "16": 0.009877942502498627, "17": 0.00029155536321923137, "18": 0.0002785812830552459, "19": 0.0002667126536834985}}, {"key": "dziri2022origin", "year": "2022", "title": "On The Origin Of Hallucinations In Conversational Models: Is It The Datasets Or The Models?", "topic_distr": {"0": 0.5628633499145508, "1": 0.08218108117580414, "2": 0.0014842948876321316, "3": 0.0012856017565354705, "4": 0.001133848913013935, "5": 0.0010141435777768493, "6": 0.15746521949768066, "7": 0.0008373413002118468, "8": 0.0007702043512836099, "9": 0.0007130341255106032, "10": 0.0006637646583840251, "11": 0.0006208640988916159, "12": 0.1856507509946823, "13": 0.0005497949314303696, "14": 0.0005200314917601645, "15": 0.0004933250602334738, "16": 0.00046922769979573786, "17": 0.00044737482676282525, "18": 0.0004274668463040143, "19": 0.00040925515349954367}}, {"key": "dziri2023faith", "year": "2023", "title": "Faith And Fate: Limits Of Transformers On Compositionality", "topic_distr": {"0": 0.0015411910135298967, "1": 0.001257275347597897, "2": 0.001062988885678351, "3": 0.6681591272354126, "4": 0.0008119982667267323, "5": 0.0007262727012857795, "6": 0.0006569198449142277, "7": 0.0005996575346216559, "8": 0.022959977388381958, "9": 0.0005106356693431735, "10": 0.1483278125524521, "11": 0.11833273619413376, "12": 0.0004176357469987124, "13": 0.00039373277104459703, "14": 0.0003724178241100162, "15": 0.014412368647754192, "16": 0.018537651747465134, "17": 0.000320385122904554, "18": 0.0003061281458940357, "19": 0.00029308590455912054}}, {"key": "eddine2022pretrained", "year": "2022", "title": "Arabart: A Pretrained Arabic Sequence-to-sequence Model For Abstractive Summarization", "topic_distr": {"0": 0.003115931060165167, "1": 0.002545599825680256, "2": 0.0021521083544939756, "3": 0.0018640098860487342, "4": 0.0016439725877717137, "5": 0.0014704115455970168, "6": 0.0013299997663125396, "7": 0.11644843220710754, "8": 0.001116724219173193, "9": 0.001033832784742117, "10": 0.4473004639148712, "11": 0.0009001948637887836, "12": 0.0008455452625639737, "13": 0.000797151296865195, "14": 0.14474277198314667, "15": 0.08115078508853912, "16": 0.0006803362630307674, "17": 0.0006486516795121133, "18": 0.0006197869661264122, "19": 0.18959330022335052}}, {"key": "edunov2019pre", "year": "2019", "title": "Pre-trained Language Model Representations For Language Generation", "topic_distr": {"0": 0.06529945880174637, "1": 0.0018189232796430588, "2": 0.20442244410514832, "3": 0.0013315685791894794, "4": 0.0011743929935619235, "5": 0.0010504086967557669, "6": 0.0009501033928245306, "7": 0.053176917135715485, "8": 0.0007977471686899662, "9": 0.0007385325734503567, "10": 0.4624532163143158, "11": 0.0006430664798244834, "12": 0.0006040267762728035, "13": 0.0005694559076800942, "14": 0.20264273881912231, "15": 0.0005109665798954666, "16": 0.0004860074841417372, "17": 0.00046337314415723085, "18": 0.00044275325490161777, "19": 0.0004238903056830168}}, {"key": "efrat2020turking", "year": "2020", "title": "The Turking Test: Can Language Models Understand Instructions?", "topic_distr": {"0": 0.30539196729660034, "1": 0.00127320340834558, "2": 0.14909173548221588, "3": 0.1830967217683792, "4": 0.0008220804738812149, "5": 0.000735290115699172, "6": 0.0006650760187767446, "7": 0.0006071027601137757, "8": 0.0005584260215982795, "9": 0.0005169755895622075, "10": 0.0004812534316442907, "11": 0.23015090823173523, "12": 0.0004228210018482059, "13": 0.0003986212541349232, "14": 0.06328727304935455, "15": 0.0003576785384211689, "16": 0.00034020707244053483, "17": 0.000324362947139889, "18": 0.00030992896063253284, "19": 0.06116833910346031}}, {"key": "ehsan2019automated", "year": "2019", "title": "Automated Rationale Generation: A Technique For Explainable AI And Its Effects On Human Perceptions", "topic_distr": {"0": 0.20926131308078766, "1": 0.0377311035990715, "2": 0.0008524552104063332, "3": 0.0007383327465504408, "4": 0.048933595418930054, "5": 0.14392594993114471, "6": 0.0005268129170872271, "7": 0.20052257180213928, "8": 0.00044233445078134537, "9": 0.022839972749352455, "10": 0.0003812053182628006, "11": 0.3316047489643097, "12": 0.000334920478053391, "13": 0.00031575161847285926, "14": 0.00029865821124985814, "15": 0.0002833204925991595, "16": 0.00026948118465952575, "17": 0.0002569309144746512, "18": 0.00024549762019887567, "19": 0.0002350384893361479}}, {"key": "eichenberg2021magma", "year": "2021", "title": "MAGMA -- Multimodal Augmentation Of Generative Models Through Adapter-based Finetuning", "topic_distr": {"0": 0.0015024666208773851, "1": 0.03993496671319008, "2": 0.30499938130378723, "3": 0.0008984068990685046, "4": 0.0007923573721200228, "5": 0.0007087053963914514, "6": 0.0006410299683921039, "7": 0.000585152767598629, "8": 0.0005382359959185123, "9": 0.0004982841783203185, "10": 0.0004638535901904106, "11": 0.00043387370533309877, "12": 0.00040753380744718015, "13": 0.14123524725437164, "14": 0.00036340963561087847, "15": 0.08113515377044678, "16": 0.03469338268041611, "17": 0.0003126355295535177, "18": 0.20560148358345032, "19": 0.18425439298152924}}, {"key": "eisenschlos2019efficient", "year": "2019", "title": "Multifit: Efficient Multi-lingual Language Model Fine-tuning", "topic_distr": {"0": 0.003115908009931445, "1": 0.2075316309928894, "2": 0.2963745892047882, "3": 0.0018641072092577815, "4": 0.001644065254367888, "5": 0.0014704938512295485, "6": 0.001330074155703187, "7": 0.0012141343904659152, "8": 0.0011167866177856922, "9": 0.001033890643157065, "10": 0.0009624505182728171, "11": 0.0009002452134154737, "12": 0.0008455925271846354, "13": 0.32360273599624634, "14": 0.0007540392107330263, "15": 0.0007153151673264802, "16": 0.0006803742726333439, "17": 0.0006486878846772015, "18": 0.0006198215996846557, "19": 0.1535751074552536}}, {"key": "eisenschlos2021multi", "year": "2021", "title": "MATE: Multi-view Attention For Table Transformer Efficiency", "topic_distr": {"0": 0.03621760383248329, "1": 0.0011982227442786098, "2": 0.36060136556625366, "3": 0.0008772642468102276, "4": 0.0007737088017165661, "5": 0.0006920252344571054, "6": 0.000625942659098655, "7": 0.000571380543988198, "8": 0.13135357201099396, "9": 0.00048655649879947305, "10": 0.1276806890964508, "11": 0.0004236619861330837, "12": 0.00039794202893972397, "13": 0.13112585246562958, "14": 0.0003548563690856099, "15": 0.00033663256908766925, "16": 0.00032018913771025836, "17": 0.0003052772954106331, "18": 0.00029169258777983487, "19": 0.2053656280040741}}, {"key": "ekstedt2020transformer", "year": "2020", "title": "Turngpt: A Transformer-based Language Model For Predicting Turn-taking In Spoken Dialog", "topic_distr": {"0": 0.1966133564710617, "1": 0.001851820619776845, "2": 0.48188698291778564, "3": 0.001355800312012434, "4": 0.09489960223436356, "5": 0.0010695167584344745, "6": 0.15775679051876068, "7": 0.0008830619044601917, "8": 0.0008122591534629464, "9": 0.0007519673672504723, "10": 0.057351525872945786, "11": 0.0006547645898535848, "12": 0.0006150147528387606, "13": 0.0005798149504698813, "14": 0.0005484263529069722, "15": 0.0005202616448514163, "16": 0.000494848529342562, "17": 0.0004718024574685842, "18": 0.0004508074780460447, "19": 0.00043160136556252837}}, {"key": "eldan2023how", "year": "2023", "title": "Tinystories: How Small Can Language Models Be And Still Speak Coherent English?", "topic_distr": {"0": 0.04780184477567673, "1": 0.1778532862663269, "2": 0.0006063145119696856, "3": 0.1645451784133911, "4": 0.0004631454648915678, "5": 0.00041424939990974963, "6": 0.0003746919974219054, "7": 0.2586439847946167, "8": 0.007741065695881844, "9": 0.00029125483706593513, "10": 0.1198713630437851, "11": 0.0002536059182602912, "12": 0.037704888731241226, "13": 0.11680491268634796, "14": 0.00021241858485154808, "15": 0.00020150972704868764, "16": 0.00019166662241332233, "17": 0.0001827403175411746, "18": 0.0001746084599290043, "19": 0.0656673014163971}}, {"key": "elkins2023how", "year": "2023", "title": "How Useful Are Educational Questions Generated By Large Language Models?", "topic_distr": {"0": 0.08063533157110214, "1": 0.001376437721773982, "2": 0.06585367769002914, "3": 0.001007712446153164, "4": 0.00088875851361081, "5": 0.0007949284045025706, "6": 0.0007190194446593523, "7": 0.35284730792045593, "8": 0.13809654116630554, "9": 0.1636408269405365, "10": 0.0005202872562222183, "11": 0.0004866599338129163, "12": 0.06791993975639343, "13": 0.12304387986660004, "14": 0.00040762301068753004, "15": 0.0003866893530357629, "16": 0.00036780082155019045, "17": 0.0003506715875118971, "18": 0.00033506687032058835, "19": 0.0003207917616236955}}, {"key": "elliott2017imagination", "year": "2017", "title": "Imagination Improves Multimodal Translation", "topic_distr": {"0": 0.002544007496908307, "1": 0.0020781783387064934, "2": 0.13805805146694183, "3": 0.0015216611791402102, "4": 0.001342042931355536, "5": 0.0012003579176962376, "6": 0.0010857334127649665, "7": 0.0009910924127325416, "8": 0.0009116278379224241, "9": 0.000843960209749639, "10": 0.000785643991548568, "11": 0.0007348660728894174, "12": 0.0006902533350512385, "13": 0.0006507473299279809, "14": 0.31521743535995483, "15": 0.03865121677517891, "16": 0.10874595493078232, "17": 0.0005295209703035653, "18": 0.38293319940567017, "19": 0.0004844018549192697}}, {"key": "ellis2019program", "year": "2019", "title": "Write, Execute, Assess: Program Synthesis With A REPL", "topic_distr": {"0": 0.001920489245094359, "1": 0.001567058963701129, "2": 0.0013246816815808415, "3": 0.4435390830039978, "4": 0.001011901767924428, "5": 0.000905070046428591, "6": 0.10987436026334763, "7": 0.049538444727659225, "8": 0.0006873677484691143, "9": 0.0006363463471643627, "10": 0.000592375872656703, "11": 0.26615166664123535, "12": 0.0005204512854106724, "13": 0.03457752615213394, "14": 0.00046410138020291924, "15": 0.0004402672639116645, "16": 0.0851028710603714, "17": 0.0003992590354755521, "18": 0.0003814921947196126, "19": 0.0003652391897048801}}, {"key": "elsahar2018zero", "year": "2018", "title": "Zero-shot Question Generation From Knowledge Graphs For Unseen Predicates And Entity Types", "topic_distr": {"0": 0.052284158766269684, "1": 0.00248412205837667, "2": 0.22970592975616455, "3": 0.001818734803237021, "4": 0.0016040530754253268, "5": 0.0014347080141305923, "6": 0.001297705457545817, "7": 0.21482139825820923, "8": 0.19947414100170135, "9": 0.0010087297996506095, "10": 0.000939028337597847, "11": 0.12551312148571014, "12": 0.0008250141981989145, "13": 0.0007777952705509961, "14": 0.0007356888963840902, "15": 0.0006979072350077331, "16": 0.1627611368894577, "17": 0.0006329014431685209, "18": 0.0006047376082278788, "19": 0.0005789735005237162}}, {"key": "eric2017copy", "year": "2017", "title": "A Copy-augmented Sequence-to-sequence Architecture Gives Good Performance On Task-oriented Dialogue", "topic_distr": {"0": 0.0021493735257536173, "1": 0.0017559080151841044, "2": 0.4279128909111023, "3": 0.001285737962462008, "4": 0.0011339718475937843, "5": 0.1449659913778305, "6": 0.24979057908058167, "7": 0.0008374314638786018, "8": 0.0007702872972004116, "9": 0.06500628590583801, "10": 0.0006638361373916268, "11": 0.09982767701148987, "12": 0.0005832350580021739, "13": 0.0005498541868291795, "14": 0.0005200874875299633, "15": 0.0004933782038278878, "16": 0.00046927822404541075, "17": 0.00044742299360223114, "18": 0.0004275128885637969, "19": 0.00040929921669885516}}, {"key": "eriguchi2016tree", "year": "2016", "title": "Tree-to-sequence Attentional Neural Machine Translation", "topic_distr": {"0": 0.002596516627818346, "1": 0.002121854107826948, "2": 0.39653581380844116, "3": 0.0015535830752924085, "4": 0.08658154308795929, "5": 0.0012255405308678746, "6": 0.0011085119331255555, "7": 0.0010118852369487286, "8": 0.0009307535365223885, "9": 0.0008616662234999239, "10": 0.07199886441230774, "11": 0.0007502833032049239, "12": 0.0007047345861792564, "13": 0.0006643998203799129, "14": 0.3408067524433136, "15": 0.0005961587303318083, "16": 0.08839942514896393, "17": 0.0005406301934272051, "18": 0.0005165723850950599, "19": 0.0004945644177496433}}, {"key": "erik2023consistency", "year": "2023", "title": "Consistency Analysis Of Chatgpt", "topic_distr": {"0": 0.13986144959926605, "1": 0.19284050166606903, "2": 0.0011182890739291906, "3": 0.21785950660705566, "4": 0.000854242651257664, "5": 0.000764056749176234, "6": 0.0006910954834893346, "7": 0.0006308541633188725, "8": 0.0005802731029689312, "9": 0.31156083941459656, "10": 0.0005000812816433609, "11": 0.00046775993541814387, "12": 0.0004393628623802215, "13": 0.08940323442220688, "14": 0.00039179250597953796, "15": 0.00037167183472774923, "16": 0.04069754108786583, "17": 0.00033705285750329494, "18": 0.0003220541693735868, "19": 0.0003083334304392338}}, {"key": "es2023automated", "year": "2023", "title": "Ragas: Automated Evaluation Of Retrieval Augmented Generation", "topic_distr": {"0": 0.16389209032058716, "1": 0.0011197604471817613, "2": 0.0009461698937229812, "3": 0.19225601851940155, "4": 0.10026192665100098, "5": 0.0006464479374699295, "6": 0.0005847176071256399, "7": 0.14097052812576294, "8": 0.20157277584075928, "9": 0.00045451155165210366, "10": 0.07029680162668228, "11": 0.00039575929986312985, "12": 0.00037173330201767385, "13": 0.00035045749973505735, "14": 0.0003314852947369218, "15": 0.00031446170760318637, "16": 0.12441584467887878, "17": 0.00028517149621620774, "18": 0.00027248149854131043, "19": 0.0002608727663755417}}, {"key": "eslami2021does", "year": "2021", "title": "Does CLIP Benefit Visual Question Answering In The Medical Domain As Much As It Does In The General Domain?", "topic_distr": {"0": 0.09185098856687546, "1": 0.025660274550318718, "2": 0.1311814785003662, "3": 0.05475888028740883, "4": 0.0005219791200943291, "5": 0.00046687154099345207, "6": 0.0004222892166581005, "7": 0.000385479157557711, "8": 0.05157450959086418, "9": 0.00032825302332639694, "10": 0.000305571302305907, "11": 0.0002858215302694589, "12": 0.10013504326343536, "13": 0.00025310408091172576, "14": 0.00023940215760376304, "15": 0.1237148642539978, "16": 0.00021601407206617296, "17": 0.00020595386740751565, "18": 0.4173048138618469, "19": 0.00018840505799744278}}, {"key": "espejel2023gpt", "year": "2023", "title": "GPT-3.5, GPT-4, Or BARD? Evaluating Llms Reasoning Ability In Zero-shot Setting And Performance Boosting Through Prompts", "topic_distr": {"0": 0.10373131930828094, "1": 0.0012573739513754845, "2": 0.0010629628086462617, "3": 0.4905969798564911, "4": 0.0008119794074445963, "5": 0.0007262558792717755, "6": 0.0006569045945070684, "7": 0.0005996436229906976, "8": 0.0005515649681910872, "9": 0.0005106237949803472, "10": 0.0004753405519295484, "11": 0.0004446182574611157, "12": 0.14139814674854279, "13": 0.12099185585975647, "14": 0.0003724091802723706, "15": 0.0003532839473336935, "16": 0.039109330624341965, "17": 0.09575017541646957, "18": 0.00030612104455940425, "19": 0.0002930791233666241}}, {"key": "ezencan2020comparison", "year": "2020", "title": "A Comparison Of LSTM And BERT For Small Corpus", "topic_distr": {"0": 0.0011351531138643622, "1": 0.10641536116600037, "2": 0.3291374444961548, "3": 0.0006779365940019488, "4": 0.0005979104898869991, "5": 0.0005347869009710848, "6": 0.000483719224575907, "7": 0.025724489241838455, "8": 0.027615737169981003, "9": 0.11021418124437332, "10": 0.25980302691459656, "11": 0.00032739972812123597, "12": 0.000307523732772097, "13": 0.0002899229002650827, "14": 0.0002742277574725449, "15": 0.041575003415346146, "16": 0.0002474374196026474, "17": 0.09419748187065125, "18": 0.00022541572980117053, "19": 0.00021581216424237937}}, {"key": "fabbri2020template", "year": "2020", "title": "Template-based Question Generation From Retrieved Sentences For Improved Unsupervised Question Answering", "topic_distr": {"0": 0.0015017262194305658, "1": 0.10431484878063202, "2": 0.47596248984336853, "3": 0.0008983997977338731, "4": 0.0007923528319224715, "5": 0.0007087006815709174, "6": 0.0006410258356481791, "7": 0.05498926714062691, "8": 0.23503711819648743, "9": 0.0004982809186913073, "10": 0.0004638505633920431, "11": 0.000433870853157714, "12": 0.00040753112989477813, "13": 0.0003842064761556685, "14": 0.000363407249096781, "15": 0.0003447443014010787, "16": 0.00032790465047582984, "17": 0.12134552747011185, "18": 0.00029872142476961017, "19": 0.0002859947853721678}}, {"key": "faggioli2023perspectives", "year": "2023", "title": "Perspectives On Large Language Models For Relevance Judgment", "topic_distr": {"0": 0.3579225540161133, "1": 0.0012733074836432934, "2": 0.0010762505698949099, "3": 0.11634384095668793, "4": 0.0008221345487982035, "5": 0.0007353390101343393, "6": 0.1605486422777176, "7": 0.0006071427487768233, "8": 0.0005584628670476377, "9": 0.3563532531261444, "10": 0.0004812851548194885, "11": 0.00045017863158136606, "12": 0.0004228488833177835, "13": 0.00039864753489382565, "14": 0.0003770665207412094, "15": 0.0003577021125238389, "16": 0.0003402294823899865, "17": 0.0003243843384552747, "18": 0.00030994939152151346, "19": 0.0002967443724628538}}, {"key": "fan2018can", "year": "2018", "title": "\"bilingual Expert\" Can Find Translation Errors", "topic_distr": {"0": 0.08822184801101685, "1": 0.021754488348960876, "2": 0.07535137981176376, "3": 0.026410680264234543, "4": 0.0005769871640950441, "5": 0.0005160720320418477, "6": 0.126661479473114, "7": 0.07535817474126816, "8": 0.0003919379669241607, "9": 0.00036284548696130514, "10": 0.10220146179199219, "11": 0.0003159424231853336, "12": 0.0002967619802802801, "13": 0.10557366907596588, "14": 0.3382892608642578, "15": 0.036824773997068405, "16": 0.0002387783897574991, "17": 0.00022765800531487912, "18": 0.00021752734028268605, "19": 0.00020825985120609403}}, {"key": "fan2018hierarchical", "year": "2018", "title": "Hierarchical Neural Story Generation", "topic_distr": {"0": 0.0019490976119413972, "1": 0.0015912903472781181, "2": 0.12271448969841003, "3": 0.0011650786036625504, "4": 0.0010275447275489569, "5": 0.0009190625278279185, "6": 0.19815601408481598, "7": 0.41832661628723145, "8": 0.05322534218430519, "9": 0.0006461843149736524, "10": 0.0006015340914018452, "11": 0.0005626556230708957, "12": 0.0005284975050017238, "13": 0.000498249486554414, "14": 0.11908857524394989, "15": 0.0004470738349482417, "16": 0.00042523571755737066, "17": 0.07736916095018387, "18": 0.00038739011506550014, "19": 0.0003708858275786042}}, {"key": "fan2019heterogeneous", "year": "2019", "title": "Heterogeneous Memory Enhanced Multimodal Attention Model For Video Question Answering", "topic_distr": {"0": 0.01859958842396736, "1": 0.0010608733864501119, "2": 0.232153981924057, "3": 0.0007767879287712276, "4": 0.000685095670633018, "5": 0.0006127670640125871, "6": 0.0005542529979720712, "7": 0.0005059399991296232, "8": 0.15111874043941498, "9": 0.0004308308707550168, "10": 0.0004010611737612635, "11": 0.00037513970164582133, "12": 0.0003523654886521399, "13": 0.0003321981930639595, "14": 0.00031421444145962596, "15": 0.00029807782266288996, "16": 0.1842793971300125, "17": 0.0002703136997297406, "18": 0.4066310524940491, "19": 0.000247280957410112}}, {"key": "fan2019long", "year": "2019", "title": "ELI5: Long Form Question Answering", "topic_distr": {"0": 0.001759188249707222, "1": 0.0014344672672450542, "2": 0.26239192485809326, "3": 0.0010502658551558852, "4": 0.08955493569374084, "5": 0.011922587640583515, "6": 0.0689086765050888, "7": 0.0006840595160610974, "8": 0.3336646258831024, "9": 0.0005825077532790601, "10": 0.07023546099662781, "11": 0.000507210148498416, "12": 0.15459471940994263, "13": 0.0004491507716011256, "14": 0.00042483574361540377, "15": 0.00040301811532117426, "16": 0.00038333196425810456, "17": 0.00036547941272147, "18": 0.00034921575570479035, "19": 0.00033433784847147763}}, {"key": "fan2019reducing", "year": "2019", "title": "Reducing Transformer Depth On Demand With Structured Dropout", "topic_distr": {"0": 0.0014510853216052055, "1": 0.0011841781670227647, "2": 0.3825107216835022, "3": 0.0008670682436786592, "4": 0.0007647197926416993, "5": 0.00068398576695472, "6": 0.0006186708342283964, "7": 0.000564742658752948, "8": 0.056686047464609146, "9": 0.0004809040401596576, "10": 0.15687653422355652, "11": 0.00041874017915688455, "12": 0.0003933190309908241, "13": 0.2574101984500885, "14": 0.1149066835641861, "15": 0.0003327218000777066, "16": 0.0003164694062434137, "17": 0.0003017307899426669, "18": 0.00028830391238443553, "19": 0.02294314093887806}}, {"key": "fan2020addressing", "year": "2020", "title": "Addressing Some Limitations Of Transformers With Feedback Memory", "topic_distr": {"0": 0.0014851873274892569, "1": 0.0012125992216169834, "2": 0.22076165676116943, "3": 0.0008877634536474943, "4": 0.05763804540038109, "5": 0.0007003115606494248, "6": 0.0006334377103485167, "7": 0.0005782223306596279, "8": 0.0005318612093105912, "9": 0.0004923825617879629, "10": 0.3833548128604889, "11": 0.13263440132141113, "12": 0.00040270702447742224, "13": 0.05937568470835686, "14": 0.06736204028129578, "15": 0.0003406634205020964, "16": 0.07072144746780396, "17": 0.0003089327074121684, "18": 0.0002951853384729475, "19": 0.0002826093405019492}}, {"key": "fan2020beyond", "year": "2020", "title": "Beyond English-centric Multilingual Machine Translation", "topic_distr": {"0": 0.04843074455857277, "1": 0.1470302790403366, "2": 0.1257680058479309, "3": 0.0008877786458469927, "4": 0.0007829820970073342, "5": 0.0007003186619840562, "6": 0.0006334441713988781, "7": 0.0005782282096333802, "8": 0.0005318666226230562, "9": 0.0004923875676468015, "10": 0.0004583644331432879, "11": 0.00042873932397924364, "12": 0.00040271112811751664, "13": 0.03252309188246727, "14": 0.570161759853363, "15": 0.0003406669129617512, "16": 0.0003240264195483178, "17": 0.0003089358506258577, "18": 0.000295188365271315, "19": 0.06892041862010956}}, {"key": "fan2023bibliometric", "year": "2023", "title": "A Bibliometric Review Of Large Language Models Research From 2017 To 2023", "topic_distr": {"0": 0.06451033055782318, "1": 0.0011441354872658849, "2": 0.0009672822197899222, "3": 0.0008378048660233617, "4": 0.0007389088859781623, "5": 0.0006608999101445079, "6": 0.00059778947615996, "7": 0.0005456814542412758, "8": 0.0005019294330850244, "9": 0.509701132774353, "10": 0.0004325644695200026, "11": 0.0004046068643219769, "12": 0.41679564118385315, "13": 0.0003582922799978405, "14": 0.000338895944878459, "15": 0.00032149176695384085, "16": 0.0003057879221159965, "17": 0.00029154677758924663, "18": 0.0002785730757750571, "19": 0.00026670482475310564}}, {"key": "fan2023improving", "year": "2023", "title": "Improving CLIP Training With Language Rewrites", "topic_distr": {"0": 0.0011546321911737323, "1": 0.23069946467876434, "2": 0.11705639213323593, "3": 0.0006904635229147971, "4": 0.0006089610396884382, "5": 0.0005446706200018525, "6": 0.0004926592228002846, "7": 0.1114003136754036, "8": 0.00041365757351741195, "9": 0.00038295291597023606, "10": 0.0003564915095921606, "11": 0.000333450676407665, "12": 0.00031320733251050115, "13": 0.12346823513507843, "14": 0.0002792959858197719, "15": 0.00026495259953662753, "16": 0.04005684703588486, "17": 0.00024027389008551836, "18": 0.3710232675075531, "19": 0.00021980075689498335}}, {"key": "fan2024survey", "year": "2024", "title": "A Survey On RAG Meeting Llms: Towards Retrieval-augmented Large Language Models", "topic_distr": {"0": 0.08452025055885315, "1": 0.0007659464026801288, "2": 0.000647392706014216, "3": 0.16905401647090912, "4": 0.0004945241962559521, "5": 0.0004423153877723962, "6": 0.00040007801726460457, "7": 0.0426604226231575, "8": 0.08890708535909653, "9": 0.18418797850608826, "10": 0.0002894991193898022, "11": 0.0002707881503738463, "12": 0.304216206073761, "13": 0.0002397915523033589, "14": 0.00022681029804516584, "15": 0.00021516234846785665, "16": 0.12190165370702744, "17": 0.0001951212907442823, "18": 0.00018643848306965083, "19": 0.00017849549476522952}}, {"key": "fang2019towards", "year": "2019", "title": "Towards Transfer Learning For End-to-end Speech Synthesis From Deep Pre-trained Language Models", "topic_distr": {"0": 0.0008856569183990359, "1": 0.24077600240707397, "2": 0.1645352989435196, "3": 0.0005288817919790745, "4": 0.04192567616701126, "5": 0.04176708683371544, "6": 0.00037736608646810055, "7": 0.04172311723232269, "8": 0.00031685258727520704, "9": 0.00029333349084481597, "10": 0.21678054332733154, "11": 0.00025541585637256503, "12": 0.00023990990302991122, "13": 0.05044130980968475, "14": 0.0651249885559082, "15": 0.00020294786372687668, "16": 0.0590582937002182, "17": 0.0001840445038396865, "18": 0.07441488653421402, "19": 0.00016836253053043038}}, {"key": "fang2021compressing", "year": "2021", "title": "Compressing Visual-linguistic Model Via Knowledge Distillation", "topic_distr": {"0": 0.0011565316235646605, "1": 0.061836790293455124, "2": 0.20857387781143188, "3": 0.000690585293341428, "4": 0.029991207644343376, "5": 0.0005447650910355151, "6": 0.0004927446134388447, "7": 0.0004497930931393057, "8": 0.028031088411808014, "9": 0.0003830192727036774, "10": 0.11853312700986862, "11": 0.00033350844751112163, "12": 0.02034279890358448, "13": 0.2341558337211609, "14": 0.00027934438548982143, "15": 0.00026499852538108826, "16": 0.05325689911842346, "17": 0.00024031552311498672, "18": 0.2402229607105255, "19": 0.00021983885380905122}}, {"key": "fang2021transformer", "year": "2021", "title": "Transformer-based Conditional Variational Autoencoder For Controllable Story Generation", "topic_distr": {"0": 0.0014854406472295523, "1": 0.09164275974035263, "2": 0.0010250061750411987, "3": 0.0008877915679477155, "4": 0.0007829915848560631, "5": 0.0007003278005868196, "6": 0.23846901953220367, "7": 0.24637813866138458, "8": 0.0005318735493347049, "9": 0.024507837370038033, "10": 0.2281704992055893, "11": 0.0004287449410185218, "12": 0.0004027163959108293, "13": 0.000379667297238484, "14": 0.023185350000858307, "15": 0.0003406713658478111, "16": 0.13979440927505493, "17": 0.0003089398960582912, "18": 0.00029519220697693527, "19": 0.0002826159179676324}}, {"key": "fang2022neural", "year": "2022", "title": "Neural Machine Translation With Phrase-level Universal Visual Representations", "topic_distr": {"0": 0.0013709176564589143, "1": 0.04633474349975586, "2": 0.1452644318342209, "3": 0.0008194343536160886, "4": 0.0007227084715850651, "5": 0.0006464094039984047, "6": 0.0005846828571520746, "7": 0.000533717276994139, "8": 0.0004909245180897415, "9": 0.00045448451419360936, "10": 0.0004230804042890668, "11": 0.0003957357839681208, "12": 0.00037171118310652673, "13": 0.00035043666139245033, "14": 0.21603521704673767, "15": 0.0003144429938402027, "16": 0.08712516725063324, "17": 0.0002851545577868819, "18": 0.49721577763557434, "19": 0.00026085725403390825}}, {"key": "fang2023bias", "year": "2023", "title": "Bias Of Ai-generated Content: An Examination Of News Produced By Large Language Models", "topic_distr": {"0": 0.3531970977783203, "1": 0.0010287088807672262, "2": 0.0008696498116478324, "3": 0.32434144616127014, "4": 0.0006643298547714949, "5": 0.0005941929412074387, "6": 0.000537452579010278, "7": 0.0004906040267087519, "8": 0.0004512679879553616, "9": 0.10049580782651901, "10": 0.00038890427094884217, "11": 0.0003637685440480709, "12": 0.00034168464480899274, "13": 0.00032212864607572556, "14": 0.0003046900383196771, "15": 0.14926795661449432, "16": 0.0002749237173702568, "17": 0.06557513028383255, "18": 0.0002504557487554848, "19": 0.0002397853968432173}}, {"key": "fang2023eva", "year": "2023", "title": "EVA-02: A Visual Representation For Neon Genesis", "topic_distr": {"0": 0.001558322343043983, "1": 0.03454035148024559, "2": 0.0010761998128145933, "3": 0.11360009759664536, "4": 0.0008220807649195194, "5": 0.0007352908723987639, "6": 0.0006650768336839974, "7": 0.0006071035168133676, "8": 0.0005584267200902104, "9": 0.0005169762298464775, "10": 0.1456574946641922, "11": 0.00045014949864707887, "12": 0.22393903136253357, "13": 0.22631539404392242, "14": 0.00037704213173128664, "15": 0.0003576789749786258, "16": 0.0003402074798941612, "17": 0.0003243633545935154, "18": 0.24726201593875885, "19": 0.00029672516393475235}}, {"key": "fang2023is", "year": "2023", "title": "Is Chatgpt A Highly Fluent Grammatical Error Correction System? A Comprehensive Evaluation", "topic_distr": {"0": 0.0013567476999014616, "1": 0.0011070548789575696, "2": 0.0009357883245684206, "3": 0.5714530944824219, "4": 0.0007148301810957491, "5": 0.0006393622024916112, "6": 0.0005783085362054408, "7": 0.0849713385105133, "8": 0.00048557238187640905, "9": 0.12172697484493256, "10": 0.0004184679128229618, "11": 0.00039142140303738415, "12": 0.12497206777334213, "13": 0.000346616143360734, "14": 0.04994315281510353, "15": 0.03885378688573837, "16": 0.0002958228287752718, "17": 0.000282045773928985, "18": 0.0002694948634598404, "19": 0.00025801334413699806}}, {"key": "fang2023mol", "year": "2023", "title": "Mol-instructions: A Large-scale Biomolecular Instruction Dataset For Large Language Models", "topic_distr": {"0": 0.0017321548657491803, "1": 0.0014144513988867402, "2": 0.001195636112242937, "3": 0.5484098196029663, "4": 0.000913352589122951, "5": 0.0008169263019226491, "6": 0.0007389167440123856, "7": 0.0006745069404132664, "8": 0.0006204258534125984, "9": 0.000574373290874064, "10": 0.0005346850957721472, "11": 0.0005001272074878216, "12": 0.4063524007797241, "13": 0.00044287857599556446, "14": 0.00041890310239978135, "15": 0.00039739013300277293, "16": 0.00037797889672219753, "17": 0.0003603756777010858, "18": 0.033194996416568756, "19": 0.00032966898288577795}}, {"key": "fast2017conversational", "year": "2017", "title": "Iris: A Conversational Agent For Complex Tasks", "topic_distr": {"0": 0.0014691357500851154, "1": 0.08240687847137451, "2": 0.0010129527654498816, "3": 0.0008773243171162903, "4": 0.0007737639243714511, "5": 0.21246472001075745, "6": 0.15617623925209045, "7": 0.0005714208236895502, "8": 0.0005256049917079508, "9": 0.0004865907831117511, "10": 0.0004529681755229831, "11": 0.4857810139656067, "12": 0.00039797008503228426, "13": 0.05471537634730339, "14": 0.00035488136927597225, "15": 0.0003366562887094915, "16": 0.00032021169317886233, "17": 0.0003052988031413406, "18": 0.0002917131350841373, "19": 0.0002792850718833506}}, {"key": "fathullah2023prompting", "year": "2023", "title": "Prompting Large Language Models With Speech Recognition Abilities", "topic_distr": {"0": 0.0011441747192293406, "1": 0.09747776389122009, "2": 0.0007898678304627538, "3": 0.29703277349472046, "4": 0.0006033754907548428, "5": 0.0005396748310886323, "6": 0.0004881404456682503, "7": 0.06475810706615448, "8": 0.014313102699816227, "9": 0.00037944037467241287, "10": 0.1826871782541275, "11": 0.0003303921839687973, "12": 0.0003103345225099474, "13": 0.03173049911856651, "14": 0.09759242087602615, "15": 0.0002625224005896598, "16": 0.0002496990200597793, "17": 0.00023807004617992789, "18": 0.20885466039180756, "19": 0.00021778470545541495}}, {"key": "fayek2019temporal", "year": "2019", "title": "Temporal Reasoning Via Audio Question Answering", "topic_distr": {"0": 0.0012610977282747626, "1": 0.0010287791956216097, "2": 0.0008696232689544559, "3": 0.000753195839934051, "4": 0.0006642838707193732, "5": 0.000594153068959713, "6": 0.0005374164320528507, "7": 0.03148484602570534, "8": 0.2659350633621216, "9": 0.00041774348937906325, "10": 0.00038887810660526156, "11": 0.09886235743761063, "12": 0.11346669495105743, "13": 0.0003221069637220353, "14": 0.0003046695201192051, "15": 0.0002890230680350214, "16": 0.00027490523643791676, "17": 0.00026210234500467777, "18": 0.4820432960987091, "19": 0.00023976925876922905}}, {"key": "fecher2023friend", "year": "2023", "title": "Friend Or Foe? Exploring The Implications Of Large Language Models On The Science System", "topic_distr": {"0": 0.17855685949325562, "1": 0.00127293705008924, "2": 0.0010761298472061753, "3": 0.0009320850949734449, "4": 0.0008220601594075561, "5": 0.0007352695101872087, "6": 0.0006650574505329132, "7": 0.0006070858216844499, "8": 0.0005584104801528156, "9": 0.7975402474403381, "10": 0.0004812400438822806, "11": 0.013925308361649513, "12": 0.0004228092439007014, "13": 0.0003986101655755192, "14": 0.0003770311886910349, "15": 0.00035766855580732226, "16": 0.00034019758459180593, "17": 0.0003243539249524474, "18": 0.0003099203167948872, "19": 0.00029671654920093715}}, {"key": "fedus2018better", "year": "2018", "title": "Maskgan: Better Text Generation Via Filling In The______", "topic_distr": {"0": 0.0011061503319069743, "1": 0.0718761757016182, "2": 0.23524244129657745, "3": 0.0006599181215278804, "4": 0.0005820204969495535, "5": 0.0005205748602747917, "6": 0.00047086403355933726, "7": 0.6503565907478333, "8": 0.0003953574341721833, "9": 0.00036601111060008407, "10": 0.00034072037669830024, "11": 0.00031869884696789086, "12": 0.00029935105703771114, "13": 0.00028221801039762795, "14": 0.02371908538043499, "15": 0.00025323114823549986, "16": 0.00024086161283776164, "17": 0.00022964421077631414, "18": 0.012529987841844559, "19": 0.0002100768033415079}}, {"key": "fei2020retrofitting", "year": "2020", "title": "Retrofitting Structure-aware Transformer Language Model For End Tasks", "topic_distr": {"0": 0.003116413950920105, "1": 0.002547202166169882, "2": 0.5008980631828308, "3": 0.0018645419040694833, "4": 0.0016444511711597443, "5": 0.0014708384405821562, "6": 0.0013303857995197177, "7": 0.0012144189095124602, "8": 0.0011170483194291592, "9": 0.001034132787026465, "10": 0.2084290087223053, "11": 0.0009004560997709632, "12": 0.0008457906078547239, "13": 0.0007973826141096652, "14": 0.0007542158709838986, "15": 0.00071548274718225, "16": 0.2694578468799591, "17": 0.0006488399230875075, "18": 0.0006199668277986348, "19": 0.0005935538792982697}}, {"key": "fei2023reasoning", "year": "2023", "title": "Reasoning Implicit Sentiment With Chain-of-thought Prompting", "topic_distr": {"0": 0.0972735583782196, "1": 0.16939492523670197, "2": 0.0013046106323599815, "3": 0.242352694272995, "4": 0.0009965645149350166, "5": 0.000891352363396436, "6": 0.09957495331764221, "7": 0.0007359577575698495, "8": 0.0006769495666958392, "9": 0.000626701454166323, "10": 0.0005833974573761225, "11": 0.0005456911749206483, "12": 0.0005125629832036793, "13": 0.00048322693328373134, "14": 0.00045706715900450945, "15": 0.00043359427945688367, "16": 0.1432453691959381, "17": 0.23917540907859802, "18": 0.00037571004941128194, "19": 0.00035970337921753526}}, {"key": "fei2023scene", "year": "2023", "title": "Scene Graph As Pivoting: Inference-time Image-free Unsupervised Multimodal Machine Translation With Visual Scene Hallucination", "topic_distr": {"0": 0.050096895545721054, "1": 0.14562684297561646, "2": 0.06087980046868324, "3": 0.0009205939131788909, "4": 0.0008119288831949234, "5": 0.0007262105937115848, "6": 0.0006568636745214462, "7": 0.0005996062536723912, "8": 0.0005515305674634874, "9": 0.0005105919553898275, "10": 0.00047531092423014343, "11": 0.00044459052151069045, "12": 0.00041760000749491155, "13": 0.00039369906880892813, "14": 0.24655461311340332, "15": 0.00035326191573403776, "16": 0.04197992384433746, "17": 0.00032035770709626377, "18": 0.4473867416381836, "19": 0.0002930608461610973}}, {"key": "fei2023transferable", "year": "2023", "title": "Transferable Decoding With Visual Entities For Zero-shot Image Captioning", "topic_distr": {"0": 0.0899677649140358, "1": 0.0010288008488714695, "2": 0.0008696551085449755, "3": 0.13675877451896667, "4": 0.0006643115193583071, "5": 0.0005941776908002794, "6": 0.0005374387255869806, "7": 0.12264896929264069, "8": 0.00045125637552700937, "9": 0.00041776083526201546, "10": 0.00038889425923116505, "11": 0.00036375917261466384, "12": 0.00034167582634836435, "13": 0.0003221203514840454, "14": 0.0003046821802854538, "15": 0.041714657098054886, "16": 0.0002749166451394558, "17": 0.15165555477142334, "18": 0.45045503973960876, "19": 0.00023977922683116049}}, {"key": "fei2023unifying", "year": "2023", "title": "Lasuie: Unifying Information Extraction With Latent Adaptive Structure-aware Generative Language Model", "topic_distr": {"0": 0.0887201651930809, "1": 0.07834568619728088, "2": 0.0009784409776329994, "3": 0.0008474424248561263, "4": 0.0007474098820239305, "5": 0.0006685020634904504, "6": 0.2148221880197525, "7": 0.0005519583355635405, "8": 0.0005077029927633703, "9": 0.0004700175777543336, "10": 0.00043754014768637717, "11": 0.00040926094516180456, "12": 0.0003844152670353651, "13": 0.00036241361522115767, "14": 0.0003427941701374948, "15": 0.10322827100753784, "16": 0.5073292851448059, "17": 0.00029490035376511514, "18": 0.0002817774366121739, "19": 0.00026977265952154994}}, {"key": "feng2020data", "year": "2020", "title": "Genaug: Data Augmentation For Finetuning Text Generators", "topic_distr": {"0": 0.0017828812124207616, "1": 0.480762779712677, "2": 0.0012298086658120155, "3": 0.0010651880875229836, "4": 0.0009394542430527508, "5": 0.0008402708335779607, "6": 0.000760032155085355, "7": 0.32773086428642273, "8": 0.0006381552666425705, "9": 0.0005907867453061044, "10": 0.0005499643739312887, "11": 0.0005144189344719052, "12": 0.06826978176832199, "13": 0.0004555343766696751, "14": 0.00043087376980111003, "15": 0.000408746040193364, "16": 0.07090197503566742, "17": 0.0003706738352775574, "18": 0.00035417903563939035, "19": 0.04140360653400421}}, {"key": "feng2020goal", "year": "2020", "title": "Doc2dial: A Goal-oriented Document-grounded Dialogue Dataset", "topic_distr": {"0": 0.0018620874034240842, "1": 0.06293501704931259, "2": 0.0012850950006395578, "3": 0.001113040721975267, "4": 0.0009816534584388137, "5": 0.17669057846069336, "6": 0.2128070592880249, "7": 0.0007249462651088834, "8": 0.22505825757980347, "9": 0.0006173246656544507, "10": 0.000574668578337878, "11": 0.0005375264445319772, "12": 0.0705799087882042, "13": 0.00047599684330634773, "14": 0.00045022848644293845, "15": 0.00042710680281743407, "16": 0.06001335009932518, "17": 0.00038732439861632884, "18": 0.18212448060512543, "19": 0.0003543214697856456}}, {"key": "feng2020pre", "year": "2020", "title": "Codebert: A Pre-trained Model For Programming And Natural Languages", "topic_distr": {"0": 0.0015410803025588393, "1": 0.0012577010784298182, "2": 0.0010629674652591348, "3": 0.0009206433896906674, "4": 0.0008119710255414248, "5": 0.0007262486615218222, "6": 0.5822958946228027, "7": 0.0005996376276016235, "8": 0.0005515594384633005, "9": 0.0005106186727061868, "10": 0.20656529068946838, "11": 0.0004446137754712254, "12": 0.00041762186447158456, "13": 0.11984780430793762, "14": 0.00037240542587824166, "15": 0.0003532803966663778, "16": 0.0003360237751621753, "17": 0.00032037447090260684, "18": 0.00030611795955337584, "19": 0.08075813204050064}}, {"key": "feng2021language", "year": "2021", "title": "Language Model As An Annotator: Exploring Dialogpt For Dialogue Summarization", "topic_distr": {"0": 0.0018343596020713449, "1": 0.08173215389251709, "2": 0.13716961443424225, "3": 0.12910878658294678, "4": 0.0009671497973613441, "5": 0.16052840650081635, "6": 0.1612796038389206, "7": 0.13230928778648376, "8": 0.0006569689721800387, "9": 0.0006082039326429367, "10": 0.0005661780596710742, "11": 0.0005295847076922655, "12": 0.0004974343464709818, "13": 0.00046896416461095214, "14": 0.00044357654405757785, "15": 0.00042079645209014416, "16": 0.18978357315063477, "17": 0.0003816018288489431, "18": 0.00036462073330767453, "19": 0.000349086505593732}}, {"key": "feng2021survey", "year": "2021", "title": "A Survey On Dialogue Summarization: Recent Advances And New Frontiers", "topic_distr": {"0": 0.0012998688034713268, "1": 0.0413542240858078, "2": 0.000896882324013859, "3": 0.14682239294052124, "4": 0.0006851070211268961, "5": 0.13485556840896606, "6": 0.0005542619037441909, "7": 0.08293678611516953, "8": 0.00046538180322386324, "9": 0.06862236559391022, "10": 0.00040106760570779443, "11": 0.0003751456970348954, "12": 0.4733045995235443, "13": 0.0003322034899611026, "14": 0.000314219476422295, "15": 0.045720525085926056, "16": 0.0002835222112480551, "17": 0.0002703180070966482, "18": 0.0002582889865152538, "19": 0.0002472848864272237}}, {"key": "feng2023chatting", "year": "2023", "title": "Chatpose: Chatting About 3D Human Pose", "topic_distr": {"0": 0.2326633483171463, "1": 0.0007714577368460596, "2": 0.0006522084004245698, "3": 0.15032605826854706, "4": 0.01631324738264084, "5": 0.0004456259193830192, "6": 0.00040307239396497607, "7": 0.00036793743493035436, "8": 0.0003384366864338517, "9": 0.00031331542413681746, "10": 0.0002916658704634756, "11": 0.00027281485381536186, "12": 0.0002562526206020266, "13": 0.00024158625456038862, "14": 0.00022850785171613097, "15": 0.19798783957958221, "16": 0.09677048027515411, "17": 0.0001965816627489403, "18": 0.30097970366477966, "19": 0.00017983143334276974}}, {"key": "feng2023compositional", "year": "2023", "title": "Layoutgpt: Compositional Visual Planning And Generation With Large Language Models", "topic_distr": {"0": 0.0012724902480840683, "1": 0.0010391687974333763, "2": 0.0008784859091974795, "3": 0.3105390965938568, "4": 0.056960031390190125, "5": 0.0006002269219607115, "6": 0.0005429102457128465, "7": 0.21461771428585052, "8": 0.0004558505315799266, "9": 0.00042201398173347116, "10": 0.00039285351522266865, "11": 0.0003674625186249614, "12": 0.0003451543743722141, "13": 0.00032539977109991014, "14": 0.00030778409563936293, "15": 0.00029197768890298903, "16": 0.00027771550230681896, "17": 0.0002647817600518465, "18": 0.4098566472530365, "19": 0.00024222036881837994}}, {"key": "feng2023interactive", "year": "2023", "title": "Promptmagician: Interactive Prompt Engineering For Text-to-image Creation", "topic_distr": {"0": 0.0014171923976391554, "1": 0.0011573275551199913, "2": 0.0009784162975847721, "3": 0.0008474294445477426, "4": 0.20426645874977112, "5": 0.0006684899562969804, "6": 0.0006046547787263989, "7": 0.0005519482656382024, "8": 0.000507693795952946, "9": 0.2743636965751648, "10": 0.0004375322023406625, "11": 0.0004092535236850381, "12": 0.00038440831121988595, "13": 0.0003624070668593049, "14": 0.00034278794191777706, "15": 0.00032518390798941255, "16": 0.032437294721603394, "17": 0.3038758933544159, "18": 0.17579218745231628, "19": 0.0002697677700780332}}, {"key": "feng2023sentence", "year": "2023", "title": "Sentence Simplification Via Large Language Models", "topic_distr": {"0": 0.17751429975032806, "1": 0.0020785080268979073, "2": 0.32034069299697876, "3": 0.4875549077987671, "4": 0.001342108123935759, "5": 0.001200412749312818, "6": 0.0010857830056920648, "7": 0.0009911376982927322, "8": 0.0009116695146076381, "9": 0.0008439987432211637, "10": 0.0007856798474676907, "11": 0.0007348996587097645, "12": 0.0006902848836034536, "13": 0.0006507770740427077, "14": 0.0006155468872748315, "15": 0.0005839351797476411, "16": 0.0005554117960855365, "17": 0.0005295451846905053, "18": 0.0005059806862846017, "19": 0.0004844239738304168}}, {"key": "ferrara2023should", "year": "2023", "title": "Should Chatgpt Be Biased? Challenges And Risks Of Bias In Large Language Models", "topic_distr": {"0": 0.3803631067276001, "1": 0.0010504632955417037, "2": 0.0008875943603925407, "3": 0.000768775527831167, "4": 0.0006780282710678875, "5": 0.013461345806717873, "6": 0.0005485350266098976, "7": 0.030254123732447624, "8": 0.0004605732683558017, "9": 0.568427324295044, "10": 0.0003969235986005515, "11": 0.0003712695324793458, "12": 0.0003487302456051111, "13": 0.0003287710133008659, "14": 0.0003109728277195245, "15": 0.00029500265372917056, "16": 0.0002805927360896021, "17": 0.0002675249706953764, "18": 0.0002556202234700322, "19": 0.0002447298320475966}}, {"key": "ferreira2019neural", "year": "2019", "title": "Neural Data-to-text Generation: A Comparison Between Pipeline And End-to-end Architectures", "topic_distr": {"0": 0.0016014456050470471, "1": 0.05194256827235222, "2": 0.29139643907546997, "3": 0.0009560298640280962, "4": 0.000843175919726491, "5": 0.0007541578379459679, "6": 0.0006821420392952859, "7": 0.1341620236635208, "8": 0.0005727554089389741, "9": 0.0005302412901073694, "10": 0.18432599306106567, "11": 0.1357029229402542, "12": 0.035659488290548325, "13": 0.0004088499990757555, "14": 0.0003867166815325618, "15": 0.15877120196819305, "16": 0.00034893688280135393, "17": 0.000332686206093058, "18": 0.000317881815135479, "19": 0.0003043388423975557}}, {"key": "filippova2020controlled", "year": "2020", "title": "Controlled Hallucinations: Learning To Generate Faithfully From Noisy Data", "topic_distr": {"0": 0.04710656777024269, "1": 0.2945839762687683, "2": 0.001304567325860262, "3": 0.10635823756456375, "4": 0.0009965175995603204, "5": 0.0008913116762414575, "6": 0.0008061989210546017, "7": 0.35235053300857544, "8": 0.0006769188330508769, "9": 0.0006266729906201363, "10": 0.0005833709146827459, "11": 0.0005456663784570992, "12": 0.0005125397001393139, "13": 0.07270535826683044, "14": 0.0004570464079733938, "15": 0.11795355379581451, "16": 0.00041239583515562117, "17": 0.0003931897517759353, "18": 0.0003756929945666343, "19": 0.00035968705196864903}}, {"key": "firat2016multi", "year": "2016", "title": "Multi-way, Multilingual Neural Machine Translation With A Shared Attention Mechanism", "topic_distr": {"0": 0.0021865200251340866, "1": 0.0017862956738099456, "2": 0.5033286809921265, "3": 0.0013080982025712729, "4": 0.00115369469858706, "5": 0.001031895400956273, "6": 0.0009333581547252834, "7": 0.0008519993862137198, "8": 0.0007836871664039791, "9": 0.000725516234524548, "10": 0.0006753842462785542, "11": 0.0006317326915450394, "12": 0.0005933810025453568, "13": 0.0005594194517470896, "14": 0.4811643660068512, "15": 0.0005019609816372395, "16": 0.00047744179028086364, "17": 0.0004552063765004277, "18": 0.00043494990677572787, "19": 0.0004164193815086037}}, {"key": "fisch2019mrqa", "year": "2019", "title": "MRQA 2019 Shared Task: Evaluating Generalization In Reading Comprehension", "topic_distr": {"0": 0.0018365069990977645, "1": 0.05011645704507828, "2": 0.3816145956516266, "3": 0.0010966617846861482, "4": 0.0009672057931311429, "5": 0.0008650931413285434, "6": 0.0007824840722605586, "7": 0.0007142765680328012, "8": 0.2286798655986786, "9": 0.0006082389736548066, "10": 0.1468026041984558, "11": 0.0005296152085065842, "12": 0.18255732953548431, "13": 0.000468991172965616, "14": 0.0004436020681168884, "15": 0.0004208206955809146, "16": 0.00040026495116762817, "17": 0.00038162380224093795, "18": 0.00036464171716943383, "19": 0.0003491066163405776}}, {"key": "fleming2023clinician", "year": "2023", "title": "Medalign: A Clinician-generated Dataset For Instruction Following With Electronic Medical Records", "topic_distr": {"0": 0.04922493174672127, "1": 0.1409645825624466, "2": 0.044527649879455566, "3": 0.24909326434135437, "4": 0.04213482141494751, "5": 0.0005549505585804582, "6": 0.0777459517121315, "7": 0.05175359547138214, "8": 0.03504089266061783, "9": 0.00039018059032969177, "10": 0.00036321976222097874, "11": 0.0805278867483139, "12": 0.2258632779121399, "13": 0.0003008542116731405, "14": 0.00028456730069592595, "15": 0.0002699532196857035, "16": 0.0002567668561823666, "17": 0.0002448087325319648, "18": 0.00023391484864987433, "19": 0.00022394918778445572}}, {"key": "flemotomos2021automated", "year": "2021", "title": "Automated Quality Assessment Of Cognitive Behavioral Therapy Sessions Through Highly Contextualized Language Representations", "topic_distr": {"0": 0.13837476074695587, "1": 0.0009345728321932256, "2": 0.0007899020565673709, "3": 0.20396287739276886, "4": 0.11756555736064911, "5": 0.05750478804111481, "6": 0.06751874834299088, "7": 0.0004455972521100193, "8": 0.0004098698263987899, "9": 0.00037944631185382605, "10": 0.13969850540161133, "11": 0.00033039733534678817, "12": 0.00031033935374580324, "13": 0.00029257737332955003, "14": 0.0002767385449260473, "15": 0.0002625265042297542, "16": 0.0002497029199730605, "17": 0.00023807377147022635, "18": 0.00022747959883417934, "19": 0.2702275812625885}}, {"key": "forbes2019do", "year": "2019", "title": "Do Neural Language Representations Learn Physical Commonsense?", "topic_distr": {"0": 0.112000972032547, "1": 0.1561470925807953, "2": 0.0011794199235737324, "3": 0.0010215208167210221, "4": 0.000900936545804143, "5": 0.0008058216772042215, "6": 0.0007288724300451577, "7": 0.0006653381860814989, "8": 0.0006119922618381679, "9": 0.0005665657226927578, "10": 0.07913555949926376, "11": 0.3924752175807953, "12": 0.06070021912455559, "13": 0.00043685841956175864, "14": 0.10755255073308945, "15": 0.00039198831655085087, "16": 0.08365873247385025, "17": 0.00035547700827009976, "18": 0.00033965843613259494, "19": 0.0003251876914873719}}, {"key": "fraiwan2023review", "year": "2023", "title": "A Review Of Chatgpt Applications In Education, Marketing, Software Engineering, And Healthcare: Benefits, Drawbacks, And Research Directions", "topic_distr": {"0": 0.0014015758642926812, "1": 0.06978164613246918, "2": 0.000967386004049331, "3": 0.000837885367218405, "4": 0.0007389780366793275, "5": 0.0006609616684727371, "6": 0.000597845355514437, "7": 0.000545732444152236, "8": 0.0005019763484597206, "9": 0.6559209823608398, "10": 0.000432604894740507, "11": 0.0004046446701977402, "12": 0.2321835458278656, "13": 0.0003583257785066962, "14": 0.0003389276098459959, "15": 0.00032152183121070266, "16": 0.000305816502077505, "17": 0.03315434977412224, "18": 0.00027859912370331585, "19": 0.0002667297376319766}}, {"key": "frank2021vision", "year": "2021", "title": "Vision-and-language Or Vision-for-language? On Cross-modal Influence In Multimodal Transformers", "topic_distr": {"0": 0.17902755737304688, "1": 0.0013400712050497532, "2": 0.11337663978338242, "3": 0.0009811775526031852, "4": 0.0008653597324155271, "5": 0.0007740005967207253, "6": 0.000700090080499649, "7": 0.0006390647613443434, "8": 0.0005878253723494709, "9": 0.000544192676898092, "10": 0.10523732751607895, "11": 0.00047384784556925297, "12": 0.00044508115388453007, "13": 0.00041960738599300385, "14": 0.0003968917008023709, "15": 0.0003765091532841325, "16": 0.0003581178607419133, "17": 0.0003414396196603775, "18": 0.48269760608673096, "19": 0.11041756719350815}}, {"key": "frankford2024ai", "year": "2024", "title": "Ai-tutoring In Software Engineering Education", "topic_distr": {"0": 0.001469191163778305, "1": 0.0011984535958617926, "2": 0.0010129098081961274, "3": 0.20304428040981293, "4": 0.0510772205889225, "5": 0.0006920643500052392, "6": 0.0006259781075641513, "7": 0.0005714129074476659, "8": 0.0005255977739579976, "9": 0.6392300128936768, "10": 0.0004529619181994349, "11": 0.00042368596768938005, "12": 0.09741301834583282, "13": 0.00037518746103160083, "14": 0.0003548764798324555, "15": 0.0003366516320966184, "16": 0.0003202072693966329, "17": 0.0003052945830859244, "18": 0.0002917091187555343, "19": 0.00027928120107389987}}, {"key": "frantar2022accurate", "year": "2022", "title": "GPTQ: Accurate Post-training Quantization For Generative Pre-trained Transformers", "topic_distr": {"0": 0.0010669415351003408, "1": 0.0008704822976142168, "2": 0.2129654437303543, "3": 0.0006373348878696561, "4": 0.0005621003801934421, "5": 0.0005027573206461966, "6": 0.0004547482240013778, "7": 0.0004151088069193065, "8": 0.00038182592834345996, "9": 0.0003534840070642531, "10": 0.03823664039373398, "11": 0.0003077910514548421, "12": 0.0002891054900828749, "13": 0.6376044154167175, "14": 0.00025780368014238775, "15": 0.10422481596469879, "16": 0.00023261788010131568, "17": 0.00022178440121933818, "18": 0.0002119151031365618, "19": 0.00020288671657908708}}, {"key": "frantar2023massive", "year": "2023", "title": "Sparsegpt: Massive Language Models Can Be Accurately Pruned In One-shot", "topic_distr": {"0": 0.002230146899819374, "1": 0.0018184742657467723, "2": 0.33383968472480774, "3": 0.0013316116528585553, "4": 0.001174424309283495, "5": 0.001050436170771718, "6": 0.0009501284803263843, "7": 0.000867307826410979, "8": 0.000797768181655556, "9": 0.0007385520148091018, "10": 0.000687519321218133, "11": 0.0006430834182538092, "12": 0.0006040426669642329, "13": 0.5761182904243469, "14": 0.0005386422271840274, "15": 0.054362956434488297, "16": 0.00048602026072330773, "17": 0.0004633853386621922, "18": 0.0004427649255376309, "19": 0.020854778587818146}}, {"key": "fried2018speaker", "year": "2018", "title": "Speaker-follower Models For Vision-and-language Navigation", "topic_distr": {"0": 0.03855247050523758, "1": 0.08600278943777084, "2": 0.23622596263885498, "3": 0.17745548486709595, "4": 0.0006780569674447179, "5": 0.011919086799025536, "6": 0.0005485587171278894, "7": 0.0005007420550100505, "8": 0.00046059320447966456, "9": 0.00042640461470000446, "10": 0.00039694076986052096, "11": 0.4445008635520935, "12": 0.00034874535049311817, "13": 0.00032878524507395923, "14": 0.0003109862736891955, "15": 0.00029501543031074107, "16": 0.00028060487238690257, "17": 0.0002675365540198982, "18": 0.0002556312829256058, "19": 0.0002447404258418828}}, {"key": "fried2022generative", "year": "2022", "title": "Incoder: A Generative Model For Code Infilling And Synthesis", "topic_distr": {"0": 0.0017559895059093833, "1": 0.0014347460819408298, "2": 0.0012126328656449914, "3": 0.38521820306777954, "4": 0.0009263171814382076, "5": 0.0008285227231681347, "6": 0.23008733987808228, "7": 0.06633538007736206, "8": 0.0006292329053394496, "9": 0.000582526670768857, "10": 0.08095438778400421, "11": 0.0005072266212664545, "12": 0.0004764335753861815, "13": 0.0004491653526201844, "14": 0.00042484953883104026, "15": 0.13200466334819794, "16": 0.0003833443915937096, "17": 0.00036549128708429635, "18": 0.0003492271061986685, "19": 0.09507431834936142}}, {"key": "fu2019from", "year": "2019", "title": "From Language To Goals: Inverse Reinforcement Learning For Vision-based Instruction Following", "topic_distr": {"0": 0.0013878516620025039, "1": 0.0011317371390759945, "2": 0.18635782599449158, "3": 0.0008286011288873851, "4": 0.049567900598049164, "5": 0.0006536405417136848, "6": 0.0005912233027629554, "7": 0.0005396876367740333, "8": 0.0004964161780662835, "9": 0.0004595685750246048, "10": 0.000427813152782619, "11": 0.6775914430618286, "12": 0.0003758693055715412, "13": 0.0003543567727319896, "14": 0.034651536494493484, "15": 0.0003179604827892035, "16": 0.0003024291363544762, "17": 0.00028834439581260085, "18": 0.04341199994087219, "19": 0.0002637753204908222}}, {"key": "fu2020lrc", "year": "2020", "title": "LRC-BERT: Latent-representation Contrastive Knowledge Distillation For Natural Language Understanding", "topic_distr": {"0": 0.0014022408286109567, "1": 0.10915178805589676, "2": 0.17018117010593414, "3": 0.0008378756465390325, "4": 0.0007389700622297823, "5": 0.0006609531119465828, "6": 0.0005978376138955355, "7": 0.0005457254010252655, "8": 0.0005019698292016983, "9": 0.03182551637291908, "10": 0.28853729367256165, "11": 0.000404639431508258, "12": 0.00038007431430742145, "13": 0.2969732880592346, "14": 0.00033892321516759694, "15": 0.00032151766936294734, "16": 0.09576333314180374, "17": 0.0002915702643804252, "18": 0.0002785955148283392, "19": 0.00026672627427615225}}, {"key": "fu2021automatic", "year": "2021", "title": "DOC2PPT: Automatic Presentation Slides Generation From Scientific Documents", "topic_distr": {"0": 0.001709158532321453, "1": 0.0013951831497251987, "2": 0.0011794732417911291, "3": 0.06585254520177841, "4": 0.0009009760688059032, "5": 0.0008058565435931087, "6": 0.0007289039203897119, "7": 0.28291046619415283, "8": 0.09733787178993225, "9": 0.0005665901699103415, "10": 0.0005274397553876042, "11": 0.08357082307338715, "12": 0.04045024514198303, "13": 0.0004368772788438946, "14": 0.0004132266913075, "15": 0.0003920052549801767, "16": 0.12916375696659088, "17": 0.00035549234598875046, "18": 0.29097792506217957, "19": 0.0003252017486374825}}, {"key": "fu2021violet", "year": "2021", "title": "VIOLET : End-to-end Video-language Transformers With Masked Visual-token Modeling", "topic_distr": {"0": 0.0011569379130378366, "1": 0.0009433146333321929, "2": 0.20558789372444153, "3": 0.0006905479822307825, "4": 0.0006090326351113617, "5": 0.0005447352887131274, "6": 0.000492717488668859, "7": 0.00044976832577958703, "8": 0.0004137064970564097, "9": 0.0003829981724265963, "10": 0.3499492406845093, "11": 0.00033349008299410343, "12": 0.0003132443525828421, "13": 0.0002953161019831896, "14": 0.0002793290186673403, "15": 0.00026498394436202943, "16": 0.0002520403068047017, "17": 0.023471765220165253, "18": 0.4133491516113281, "19": 0.00021982674661558121}}, {"key": "fu2022complexity", "year": "2022", "title": "Complexity-based Prompting For Multi-step Reasoning", "topic_distr": {"0": 0.0009449334465898573, "1": 0.03391924500465393, "2": 0.1795215904712677, "3": 0.5681240558624268, "4": 0.0004982335958629847, "5": 0.0004456327296793461, "6": 0.00040307859308086336, "7": 0.04676853120326996, "8": 0.03633690997958183, "9": 0.0003133202553726733, "10": 0.0002916703524533659, "11": 0.0002728190447669476, "12": 0.0002562565787229687, "13": 0.00024158996529877186, "14": 0.000228511358727701, "15": 0.00021677605400327593, "16": 0.00020618723647203296, "17": 0.13064299523830414, "18": 0.00018783676205202937, "19": 0.00017983419820666313}}, {"key": "fu2022empirical", "year": "2022", "title": "An Empirical Study Of End-to-end Video-language Transformers With Masked Visual Modeling", "topic_distr": {"0": 0.0014035903150215745, "1": 0.0011445144191384315, "2": 0.0009675161563791335, "3": 0.000837979547213763, "4": 0.0007390553364530206, "5": 0.0006610302370972931, "6": 0.0005979074630886316, "7": 0.0005457891384139657, "8": 0.03612189739942551, "9": 0.0004647642490454018, "10": 0.23966851830482483, "11": 0.0004046866961289197, "12": 0.00038011869764886796, "13": 0.00035836297320201993, "14": 0.0003389627963770181, "15": 0.00032155521330423653, "16": 0.0003058482543565333, "17": 0.0002916043158620596, "18": 0.3900798559188843, "19": 0.3243664801120758}}, {"key": "fu2022hungry", "year": "2022", "title": "Hungry Hungry Hippos: Towards Language Modeling With State Space Models", "topic_distr": {"0": 0.0009605868253856897, "1": 0.04756162315607071, "2": 0.2972216308116913, "3": 0.0005736402818001807, "4": 0.0005059238756075501, "5": 0.0004525113326963037, "6": 0.00040930029354058206, "7": 0.024916119873523712, "8": 0.0003436658880673349, "9": 0.0003181564970873296, "10": 0.40824541449546814, "11": 0.00027703013620339334, "12": 0.05387876182794571, "13": 0.1431492269039154, "14": 0.00023203853925224394, "15": 0.00022012209228705615, "16": 0.0002093698421958834, "17": 0.00019961906946264207, "18": 0.020142721012234688, "19": 0.00018261003424413502}}, {"key": "fu2023chatgpt", "year": "2023", "title": "Chatgpt For Vulnerability Detection, Classification, And Repair: How Far Are We?", "topic_distr": {"0": 0.0013561482774093747, "1": 0.11015653610229492, "2": 0.0009358368697576225, "3": 0.5027837157249451, "4": 0.0007148738950490952, "5": 0.000639402074739337, "6": 0.11500566452741623, "7": 0.0005279314937070012, "8": 0.00048560259165242314, "9": 0.20752111077308655, "10": 0.0004184939607512206, "11": 0.00039144576294347644, "12": 0.00036768161226063967, "13": 0.0003466377092991024, "14": 0.00032787228701636195, "15": 0.00031103426590561867, "16": 0.00029584122239612043, "17": 0.05688657611608505, "18": 0.0002695116272661835, "19": 0.0002580294094514102}}, {"key": "fu2023comparing", "year": "2023", "title": "Comparing Sentence-level Suggestions To Message-level Suggestions In Ai-mediated Communication", "topic_distr": {"0": 0.0017592544900253415, "1": 0.13650713860988617, "2": 0.0012127358932048082, "3": 0.0010503750527277589, "4": 0.13661541044712067, "5": 0.0008285825024358928, "6": 0.000749459897633642, "7": 0.08131378889083862, "8": 0.0006292783073149621, "9": 0.5748517513275146, "10": 0.060788799077272415, "11": 0.0005072631756775081, "12": 0.0004764679179061204, "13": 0.00044919774518348277, "14": 0.0004248801851645112, "15": 0.0004030602576676756, "16": 0.0003833720402326435, "17": 0.00036551765515469015, "18": 0.00034925228101201355, "19": 0.00033437280217185616}}, {"key": "fu2023comprehensive", "year": "2023", "title": "MME: A Comprehensive Evaluation Benchmark For Multimodal Large Language Models", "topic_distr": {"0": 0.16348160803318024, "1": 0.03785664215683937, "2": 0.0008696768200024962, "3": 0.29733753204345703, "4": 0.0006643366650678217, "5": 0.0005941998097114265, "6": 0.0005374586908146739, "7": 0.0004906096146441996, "8": 0.00045127313933335245, "9": 0.0004177763476036489, "10": 0.00038890872383490205, "11": 0.00036377267679199576, "12": 0.2002076804637909, "13": 0.04986903443932533, "14": 0.00030469350167550147, "15": 0.0002890458272304386, "16": 0.0002749268605839461, "17": 0.0002621229796204716, "18": 0.24509890377521515, "19": 0.00023978813260328025}}, {"key": "fu2023evaluate", "year": "2023", "title": "Gptscore: Evaluate As You Desire", "topic_distr": {"0": 0.0015224362723529339, "1": 0.0012421273859217763, "2": 0.0010499173076823354, "3": 0.3303629755973816, "4": 0.0008020225795917213, "5": 0.0007173499907366931, "6": 0.0006488491781055927, "7": 0.12960903346538544, "8": 0.0005448012962006032, "9": 0.07301472872495651, "10": 0.00046951157855801284, "11": 0.00043916600407101214, "12": 0.00041250482900068164, "13": 0.0003888955106958747, "14": 0.0003678424400277436, "15": 0.43744444847106934, "16": 0.00033190654357895255, "17": 0.00031644897535443306, "18": 0.020025601610541344, "19": 0.00028948517865501344}}, {"key": "fu2023improving", "year": "2023", "title": "Improving Language Model Negotiation With Self-play And In-context Learning From AI Feedback", "topic_distr": {"0": 0.15770164132118225, "1": 0.000885643414221704, "2": 0.11866062134504318, "3": 0.2442360520362854, "4": 0.15344437956809998, "5": 0.0005115107633173466, "6": 0.00046266577555797994, "7": 0.00042233619024045765, "8": 0.0003884738252963871, "9": 0.1592034250497818, "10": 0.00033478805562481284, "11": 0.16178154945373535, "12": 0.00029413902666419744, "13": 0.0002773042651824653, "14": 0.00026229224749840796, "15": 0.0002488221216481179, "16": 0.00023666794004384428, "17": 0.00022564585378859192, "18": 0.00021560471213888377, "19": 0.00020641913579311222}}, {"key": "fu2023specializing", "year": "2023", "title": "Specializing Smaller Language Models Towards Multi-step Reasoning", "topic_distr": {"0": 0.0012121243635192513, "1": 0.0009888646891340613, "2": 0.0008358867489732802, "3": 0.6464958786964417, "4": 0.0006385131855495274, "5": 0.0005711024859920144, "6": 0.0005165670299902558, "7": 0.00047153898049145937, "8": 0.00043373159132897854, "9": 0.0004015368758700788, "10": 0.0003737913502845913, "11": 0.0003496323770377785, "12": 0.07018526643514633, "13": 0.14370299875736237, "14": 0.0002928496978711337, "15": 0.0002778102643787861, "16": 0.00026424010866321623, "17": 0.1315164715051651, "18": 0.000240722976741381, "19": 0.00023046726710163057}}, {"key": "fu2023towards", "year": "2023", "title": "Gpt4aigchip: Towards Next-generation AI Accelerator Design Automation Via Large Language Models", "topic_distr": {"0": 0.0010761180892586708, "1": 0.0008779851486906409, "2": 0.0007422071066685021, "3": 0.46184733510017395, "4": 0.0005669772508554161, "5": 0.0005071188206784427, "6": 0.0004586932482197881, "7": 0.04284508526325226, "8": 0.0003851383225992322, "9": 0.42645859718322754, "10": 0.0003319134993944317, "11": 0.04835418239235878, "12": 0.0002916135126724839, "13": 0.00027492328081279993, "14": 0.00026004016399383545, "15": 0.00024668566766195, "16": 0.01383327879011631, "17": 0.00022370841179508716, "18": 0.00021375349024310708, "19": 0.00020464678527787328}}, {"key": "fukui2016multimodal", "year": "2016", "title": "Multimodal Compact Bilinear Pooling For Visual Question Answering And Visual Grounding", "topic_distr": {"0": 0.0014495410723611712, "1": 0.0011844065738841891, "2": 0.24831528961658478, "3": 0.000867084541823715, "4": 0.0007647311431355774, "5": 0.0006839952548034489, "6": 0.0006186795071698725, "7": 0.0005647505167871714, "8": 0.15306946635246277, "9": 0.00048091073404066265, "10": 0.00044768062070943415, "11": 0.00041874602902680635, "12": 0.00039332450251094997, "13": 0.00037081295158714056, "14": 0.0003507387882564217, "15": 0.00033272645669057965, "16": 0.0003164738300256431, "17": 0.0003017350099980831, "18": 0.5887928605079651, "19": 0.0002760249190032482}}, {"key": "gafni2022make", "year": "2022", "title": "Make-a-scene: Scene-based Text-to-image Generation With Human Priors", "topic_distr": {"0": 0.0013411382678896189, "1": 0.0010951176518574357, "2": 0.12822672724723816, "3": 0.0008018437074497342, "4": 0.000707189436070621, "5": 0.0006325290887616575, "6": 0.0005721275811083615, "7": 0.4518890976905823, "8": 0.00048038261593319476, "9": 0.0004447250976227224, "10": 0.0004139953525736928, "11": 0.0003872379020322114, "12": 0.00036372922477312386, "13": 0.00034291151678189635, "14": 0.0003243478131480515, "15": 0.00030769078875891864, "16": 0.020207883790135384, "17": 0.06043563038110733, "18": 0.2646495997905731, "19": 0.06637609004974365}}, {"key": "gallotta2024large", "year": "2024", "title": "Large Language Models And Games: A Survey And Roadmap", "topic_distr": {"0": 0.0016620358219370246, "1": 0.0013576863566413522, "2": 0.0011478656670078635, "3": 0.20227080583572388, "4": 0.0008768487023189664, "5": 0.0007842768100090325, "6": 0.0007093849126249552, "7": 0.000647549401037395, "8": 0.0005956297391094267, "9": 0.15204112231731415, "10": 0.0005133157246746123, "11": 0.12424106895923615, "12": 0.5105876922607422, "13": 0.0004251783830113709, "14": 0.0004021611239295453, "15": 0.0003815079398918897, "16": 0.000362872495315969, "17": 0.0003459728031884879, "18": 0.0003305771679151803, "19": 0.0003164933295920491}}, {"key": "gan2022vision", "year": "2022", "title": "Vision-language Pre-training: Basics, Recent Advances, And Future Trends", "topic_distr": {"0": 0.001757219317369163, "1": 0.0014345545787364244, "2": 0.0012125466018915176, "3": 0.001050227670930326, "4": 0.0009262618841603398, "5": 0.0008284723153337836, "6": 0.0007493602461181581, "7": 0.0006840401329100132, "8": 0.08579956740140915, "9": 0.14997167885303497, "10": 0.0005422420799732208, "11": 0.0005071957712061703, "12": 0.35519418120384216, "13": 0.00044913802412338555, "14": 0.0004248236946295947, "15": 0.00040300667751580477, "16": 0.00038332107942551374, "17": 0.0003654690517578274, "18": 0.396982342004776, "19": 0.00033432836062274873}}, {"key": "gan2023large", "year": "2023", "title": "Large Language Models In Education: Vision And Opportunities", "topic_distr": {"0": 0.10378237813711166, "1": 0.0008562516886740923, "2": 0.0007235796074382961, "3": 0.0006267197313718498, "4": 0.0005527372704818845, "5": 0.0004943821695633233, "6": 0.0004471727879717946, "7": 0.0004081937368027866, "8": 0.0003754652861971408, "9": 0.5730407238006592, "10": 0.00032357723102904856, "11": 0.0003026637132279575, "12": 0.31644943356513977, "13": 0.0002680183679331094, "14": 0.0002535090607125312, "15": 0.0002404899860266596, "16": 0.0002287428214913234, "17": 0.0002180898009100929, "18": 0.0002083849103655666, "19": 0.00019950693240389228}}, {"key": "ganesh2020compressing", "year": "2020", "title": "Compressing Large-scale Transformer-based Models: A Case Study On BERT", "topic_distr": {"0": 0.00183479196857661, "1": 0.0014981393469497561, "2": 0.0012661464279517531, "3": 0.0010966290719807148, "4": 0.0009671798325143754, "5": 0.0008650716044940054, "6": 0.000782464281655848, "7": 0.0007142585818655789, "8": 0.0006569902179762721, "9": 0.19889983534812927, "10": 0.19110828638076782, "11": 0.000529601878952235, "12": 0.2889484763145447, "13": 0.3084721863269806, "14": 0.000443590892245993, "15": 0.0004208100726827979, "16": 0.0004002548230346292, "17": 0.00038161416887305677, "18": 0.0003646325203590095, "19": 0.0003490977978799492}}, {"key": "ganguli2023capacity", "year": "2023", "title": "The Capacity For Moral Self-correction In Large Language Models", "topic_distr": {"0": 0.4921030104160309, "1": 0.0014548614853993058, "2": 0.0012299080844968557, "3": 0.10945776849985123, "4": 0.0009395150700584054, "5": 0.0008403268875554204, "6": 0.0007600827375426888, "7": 0.0006938279839232564, "8": 0.0006381977582350373, "9": 0.0005908260936848819, "10": 0.0005500009865500033, "11": 0.3001420497894287, "12": 0.000483221432659775, "13": 0.08782387524843216, "14": 0.00043090246617794037, "15": 0.0004087732813786715, "16": 0.00038880601641722023, "17": 0.00037069854442961514, "18": 0.0003542026097420603, "19": 0.0003391122445464134}}, {"key": "gao2019jointly", "year": "2019", "title": "Jointly Optimizing Diversity And Relevance In Neural Response Generation", "topic_distr": {"0": 0.0016423296183347702, "1": 0.0013399700401350856, "2": 0.0011329801054671407, "3": 0.0009811557829380035, "4": 0.0008653378463350236, "5": 0.0007739802240394056, "6": 0.9875366687774658, "7": 0.0006390479393303394, "8": 0.0005878098891116679, "9": 0.0005441783578135073, "10": 0.0005065765581093729, "11": 0.00047383536002598703, "12": 0.00044506945414468646, "13": 0.0004195963265374303, "14": 0.00039688125252723694, "15": 0.00037649922887794673, "16": 0.0003581084602046758, "17": 0.00034143062657676637, "18": 0.0003262371174059808, "19": 0.00031233817571774125}}, {"key": "gao2019multi", "year": "2019", "title": "Multi-modality Latent Interaction Network For Visual Question Answering", "topic_distr": {"0": 0.0011242255568504333, "1": 0.0009175662999041378, "2": 0.24446240067481995, "3": 0.0006717910291627049, "4": 0.0005924934521317482, "5": 0.0005299416370689869, "6": 0.07456144690513611, "7": 0.031239546835422516, "8": 0.1219867542386055, "9": 0.00037259707460179925, "10": 0.06554942578077316, "11": 0.00032443346572108567, "12": 0.0003047375357709825, "13": 0.00028729619225487113, "14": 0.0002717432507779449, "15": 0.00025778773124329746, "16": 0.0002451956388540566, "17": 0.00023377638717647642, "18": 0.4558529555797577, "19": 0.00021385689615271986}}, {"key": "gao2020dataset", "year": "2020", "title": "The Pile: An 800GB Dataset Of Diverse Text For Language Modeling", "topic_distr": {"0": 0.02950061857700348, "1": 0.267654687166214, "2": 0.0012851160718128085, "3": 0.21514785289764404, "4": 0.0009816824458539486, "5": 0.0008780408534221351, "6": 0.0007941952790133655, "7": 0.0007249669870361686, "8": 0.0006668400601483881, "9": 0.0799858421087265, "10": 0.0005746849928982556, "11": 0.0005375418113544583, "12": 0.2606269419193268, "13": 0.000476010434795171, "14": 0.0004502413503360003, "15": 0.00042711899732239544, "16": 0.00040625559631735086, "17": 0.03008224070072174, "18": 0.0003700992092490196, "19": 0.1084289699792862}}, {"key": "gao2020from", "year": "2020", "title": "From Machine Reading Comprehension To Dialogue State Tracking: Bridging The Gap", "topic_distr": {"0": 0.001222632359713316, "1": 0.07112592458724976, "2": 0.49837756156921387, "3": 0.07776597142219543, "4": 0.0006447655614465475, "5": 0.2514151930809021, "6": 0.05620789900422096, "7": 0.0004761562158819288, "8": 0.0004379786259960383, "9": 0.00040546865784563124, "10": 0.00037745144800283015, "11": 0.000353055918822065, "12": 0.000331622373778373, "13": 0.00031264228164218366, "14": 0.0392681285738945, "15": 0.0002805305121000856, "16": 0.0002668274973984808, "17": 0.00025440080207772553, "18": 0.00024308009597007185, "19": 0.00023272396356333047}}, {"key": "gao2020making", "year": "2020", "title": "Making Pre-trained Language Models Better Few-shot Learners", "topic_distr": {"0": 0.0014687948860228062, "1": 0.0011984918965026736, "2": 0.2332485020160675, "3": 0.2224111258983612, "4": 0.0007737536216154695, "5": 0.0006920656305737793, "6": 0.06819053739309311, "7": 0.0005714138387702405, "8": 0.0005255985888652503, "9": 0.0004865848459303379, "10": 0.0004529626457951963, "11": 0.000423686666181311, "12": 0.0810159221291542, "13": 0.20628568530082703, "14": 0.0003548770328052342, "15": 0.00033665215596556664, "16": 0.00032020779326558113, "17": 0.18067210912704468, "18": 0.0002917095844168216, "19": 0.0002792816376313567}}, {"key": "gao2020meaningful", "year": "2020", "title": "Meaningful Answer Generation Of E-commerce Question-answering", "topic_distr": {"0": 0.000843268062453717, "1": 0.0006881480221636593, "2": 0.0005817307392135262, "3": 0.0005038466770201921, "4": 0.0004443722718860954, "5": 0.00039745779940858483, "6": 0.0003595039015635848, "7": 0.1514025777578354, "8": 0.5094214081764221, "9": 0.0002794488682411611, "10": 0.0002601394080556929, "11": 0.00024332602333743125, "12": 0.13531552255153656, "13": 0.00021547295909840614, "14": 0.0002038082166109234, "15": 0.18464379012584686, "16": 0.013692919164896011, "17": 0.000175332956132479, "18": 0.0001675307285040617, "19": 0.00016039327601902187}}, {"key": "gao2020paraphrase", "year": "2020", "title": "Paraphrase Augmented Task-oriented Dialog Generation", "topic_distr": {"0": 0.0014660683227702975, "1": 0.15959623456001282, "2": 0.0010128137655556202, "3": 0.0008772134897299111, "4": 0.2525380551815033, "5": 0.0006919886800460517, "6": 0.16870152950286865, "7": 0.0005713501595892012, "8": 0.0005255400319583714, "9": 0.000486530625494197, "10": 0.0004529121797531843, "11": 0.0004236394597683102, "12": 0.0003979208704549819, "13": 0.07044679671525955, "14": 0.00035483750980347395, "15": 0.34026017785072327, "16": 0.0003201721119694412, "17": 0.00030526105547323823, "18": 0.00029167707543820143, "19": 0.00027925052563659847}}, {"key": "gao2020robust", "year": "2020", "title": "Robust Conversational AI With Grounded Text Generation", "topic_distr": {"0": 0.0015025704633444548, "1": 0.1039576455950737, "2": 0.0010372961405664682, "3": 0.0008984216256067157, "4": 0.1256663054227829, "5": 0.0007087171543389559, "6": 0.2168620079755783, "7": 0.0005851623136550188, "8": 0.0005382447270676494, "9": 0.09040839970111847, "10": 0.1891639232635498, "11": 0.0004338807484600693, "12": 0.0740213543176651, "13": 0.000384215236408636, "14": 0.0003634155436884612, "15": 0.06353699415922165, "16": 0.1290341019630432, "17": 0.00031264059362001717, "18": 0.00029872823506593704, "19": 0.00028600130463019013}}, {"key": "gao2021clip", "year": "2021", "title": "Clip-adapter: Better Vision-language Models With Feature Adapters", "topic_distr": {"0": 0.001286398502998054, "1": 0.0010499842464923859, "2": 0.1325969696044922, "3": 0.0007687805336900055, "4": 0.01903119497001171, "5": 0.0006064502522349358, "6": 0.0005485393339768052, "7": 0.0005007243016734719, "8": 0.00046057687723077834, "9": 0.0004263895098119974, "10": 0.00039692671271041036, "11": 0.01891390047967434, "12": 0.0003487330104690045, "13": 0.057008370757102966, "14": 0.00031097527244128287, "15": 0.0002950049820356071, "16": 0.00028059491887688637, "17": 0.39858478307724, "18": 0.36633995175361633, "19": 0.0002447317529004067}}, {"key": "gao2021code", "year": "2021", "title": "Code Structure Guided Transformer For Source Code Summarization", "topic_distr": {"0": 0.0502704419195652, "1": 0.0009432851220481098, "2": 0.15287713706493378, "3": 0.1331966370344162, "4": 0.0006090275128372014, "5": 0.0005447292351163924, "6": 0.21179696917533875, "7": 0.08606921136379242, "8": 0.0004137020150665194, "9": 0.00038299403968267143, "10": 0.1968594342470169, "11": 0.0003334864741191268, "12": 0.0003132409474346787, "13": 0.00029531290056183934, "14": 0.0002793259918689728, "15": 0.0002649810630828142, "16": 0.16386035084724426, "17": 0.00024029970518313348, "18": 0.00022960647766012698, "19": 0.000219824374653399}}, {"key": "gao2021pre", "year": "2021", "title": "Condenser: A Pre-training Architecture For Dense Retrieval", "topic_distr": {"0": 0.0015396494418382645, "1": 0.0012575793080031872, "2": 0.0010628924937918782, "3": 0.0009205839596688747, "4": 0.05524589866399765, "5": 0.0007261991268023849, "6": 0.0006568532553501427, "7": 0.0005995967658236623, "8": 0.06008938327431679, "9": 0.0005105838645249605, "10": 0.3939763307571411, "11": 0.0004445834783837199, "12": 0.0004175934009253979, "13": 0.0003936928405892104, "14": 0.00037238007644191384, "15": 0.07012012600898743, "16": 0.06663907319307327, "17": 0.0003203526430297643, "18": 0.00030609709210693836, "19": 0.3444004952907562}}, {"key": "gao2021rethink", "year": "2021", "title": "Rethink Training Of BERT Rerankers In Multi-stage Retrieval Pipeline", "topic_distr": {"0": 0.0022262143902480602, "1": 0.1253969371318817, "2": 0.001537514734081924, "3": 0.0013316655531525612, "4": 0.001174474018625915, "5": 0.0010504795936867595, "6": 0.3490448594093323, "7": 0.0008673437987454236, "8": 0.14668448269367218, "9": 0.0007385826320387423, "10": 0.2006014585494995, "11": 0.0006431100773625076, "12": 0.0006040677544660866, "13": 0.0005694944993592799, "14": 0.0005386645789258182, "15": 0.0005110012134537101, "16": 0.00048604042967781425, "17": 0.0004634045762941241, "18": 0.0004427832900546491, "19": 0.16508737206459045}}, {"key": "gao2021unsupervised", "year": "2021", "title": "Unsupervised Corpus Aware Language Model Pre-training For Dense Passage Retrieval", "topic_distr": {"0": 0.0014855052577331662, "1": 0.08538898080587387, "2": 0.39237740635871887, "3": 0.0008877535001374781, "4": 0.0007829608512111008, "5": 0.0007002991042099893, "6": 0.0006334264762699604, "7": 0.0005782120279036462, "8": 0.19534669816493988, "9": 0.0779685527086258, "10": 0.10464761406183243, "11": 0.00042872733320109546, "12": 0.0004026998649351299, "13": 0.00037965172668918967, "14": 0.00035909906728193164, "15": 0.0003406573669053614, "16": 0.0003240173391532153, "17": 0.00030892720678821206, "18": 0.00029518009978346527, "19": 0.13636358082294464}}, {"key": "gao2022dialogue", "year": "2022", "title": "Dialfred: Dialogue-enabled Agents For Embodied Instruction Following", "topic_distr": {"0": 0.0016859510214999318, "1": 0.001376481493934989, "2": 0.001163401873782277, "3": 0.001007641782052815, "4": 0.1098233312368393, "5": 0.0007948725833557546, "6": 0.023846151307225227, "7": 0.0006562978378497064, "8": 0.1527123749256134, "9": 0.025272898375988007, "10": 0.0005202505853958428, "11": 0.5287944078445435, "12": 0.14974650740623474, "13": 0.0004309225478209555, "14": 0.0004075943143106997, "15": 0.0003866621118504554, "16": 0.00036777491914108396, "17": 0.0003506469074636698, "18": 0.00033504326711408794, "19": 0.00032076917705126107}}, {"key": "gao2022multi", "year": "2022", "title": "MIST: Multi-modal Iterative Spatial-temporal Transformer For Long-form Video Question Answering", "topic_distr": {"0": 0.0011041359975934029, "1": 0.0009012693190015852, "2": 0.21227669715881348, "3": 0.0006599350599572062, "4": 0.0005820327205583453, "5": 0.0423302985727787, "6": 0.0004708734049927443, "7": 0.00042982836021110415, "8": 0.17073434591293335, "9": 0.00036601838655769825, "10": 0.06438121944665909, "11": 0.0003187051916029304, "12": 0.0002993570233229548, "13": 0.07394914329051971, "14": 0.0002669452806003392, "15": 0.0002532361831981689, "16": 0.00024086638586595654, "17": 0.08742519468069077, "18": 0.3427998423576355, "19": 0.00021008097974117845}}, {"key": "gao2022program", "year": "2022", "title": "PAL: Program-aided Language Models", "topic_distr": {"0": 0.001154331723228097, "1": 0.0009430457139387727, "2": 0.08071018010377884, "3": 0.9115159511566162, "4": 0.0006089066155254841, "5": 0.0005446221912279725, "6": 0.0004926153342239559, "7": 0.0004496751062106341, "8": 0.0004136207280680537, "9": 0.0003829187771771103, "10": 0.00035645972820930183, "11": 0.0003334209613967687, "12": 0.00031317942193709314, "13": 0.00029525489662773907, "14": 0.0002792711020447314, "15": 0.0002649289963301271, "16": 0.00025198806542903185, "17": 0.00024025248421821743, "18": 0.00022956136672291905, "19": 0.0002197811845690012}}, {"key": "gao2022researching", "year": "2022", "title": "RARR: Researching And Revising What Language Models Say, Using Language Models", "topic_distr": {"0": 0.09666809439659119, "1": 0.11048176884651184, "2": 0.0011328741675242782, "3": 0.16655072569847107, "4": 0.1193169355392456, "5": 0.0007740059518255293, "6": 0.000700094853527844, "7": 0.3088453710079193, "8": 0.059077031910419464, "9": 0.0005441964021883905, "10": 0.0005065933219157159, "11": 0.00047385107609443367, "12": 0.000445084209786728, "13": 0.0004196102381683886, "14": 0.0003968944074586034, "15": 0.0003765117144212127, "16": 0.0003581203054636717, "17": 0.00034144194796681404, "18": 0.00032624794403091073, "19": 0.13226450979709625}}, {"key": "gao2023chat", "year": "2023", "title": "Chat-rec: Towards Interactive And Explainable Llms-augmented Recommender System", "topic_distr": {"0": 0.0011142489966005087, "1": 0.0009092412074096501, "2": 0.0007686798926442862, "3": 0.0006657778867520392, "4": 0.6799885034561157, "5": 0.045813944190740585, "6": 0.00047504412941634655, "7": 0.0004336355486884713, "8": 0.0003988672106061131, "9": 0.20306570827960968, "10": 0.0003437451086938381, "11": 0.00032152808853425086, "12": 0.00030200855690054595, "13": 0.0002847233845386654, "14": 0.00026930973399430513, "15": 0.0002554791863076389, "16": 0.00024299985670950264, "17": 0.0639132559299469, "18": 0.0002213730913354084, "19": 0.00021194176224526018}}, {"key": "gao2023enabling", "year": "2023", "title": "Enabling Large Language Models To Generate Text With Citations", "topic_distr": {"0": 0.10031509399414062, "1": 0.0009093948756344616, "2": 0.0007686804747208953, "3": 0.4656907618045807, "4": 0.048991601914167404, "5": 0.0005251963157206774, "6": 0.0004750444495584816, "7": 0.14546777307987213, "8": 0.15202583372592926, "9": 0.0003692606114782393, "10": 0.0003437453415244818, "11": 0.0003215283213648945, "12": 0.08207857608795166, "13": 0.0002847235882654786, "14": 0.0002693099086172879, "15": 0.0002554793609306216, "16": 0.00024300001678057015, "17": 0.0002316830214112997, "18": 0.00022137323685456067, "19": 0.00021194190776441246}}, {"key": "gao2023llama", "year": "2023", "title": "Llama-adapter V2: Parameter-efficient Visual Instruction Model", "topic_distr": {"0": 0.0735190212726593, "1": 0.03632060065865517, "2": 0.0006999959005042911, "3": 0.20257601141929626, "4": 0.0005347217665985227, "5": 0.0004782680480275303, "6": 0.0004325974150560796, "7": 0.0003948888333979994, "8": 0.0003632271254900843, "9": 0.00033626577351242304, "10": 0.0003130303812213242, "11": 0.056103892624378204, "12": 0.05077407509088516, "13": 0.20939943194389343, "14": 0.00024524604668840766, "15": 0.00023265130585059524, "16": 0.070357546210289, "17": 0.01849762164056301, "18": 0.27822786569595337, "19": 0.0001930040743900463}}, {"key": "gao2023physically", "year": "2023", "title": "Physically Grounded Vision-language Models For Robotic Manipulation", "topic_distr": {"0": 0.06986505538225174, "1": 0.001050033257342875, "2": 0.0008875940111465752, "3": 0.0819096565246582, "4": 0.0006780289695598185, "5": 0.0006064465851522982, "6": 0.0005485360743477941, "7": 0.0005007213912904263, "8": 0.00046057417057454586, "9": 0.00042638700688257813, "10": 0.0003969243844039738, "11": 0.1414511799812317, "12": 0.06535453349351883, "13": 0.00032877165358513594, "14": 0.0003109734388999641, "15": 0.0002950032358057797, "16": 0.0002805932890623808, "17": 0.0002675254945643246, "18": 0.6341367363929749, "19": 0.00024473032681271434}}, {"key": "gao2023text", "year": "2023", "title": "Text-to-sql Empowered By Large Language Models: A Benchmark Evaluation", "topic_distr": {"0": 0.001433408702723682, "1": 0.0011705928482115269, "2": 0.0009895776165649295, "3": 0.3235824704170227, "4": 0.0007559319492429495, "5": 0.0006761242402717471, "6": 0.0006115600699558854, "7": 0.0005582516896538436, "8": 0.01363342721015215, "9": 0.00047537669888697565, "10": 0.08960313349962234, "11": 0.0004139273369219154, "12": 0.25256630778312683, "13": 0.0003665458643808961, "14": 0.0003467026981525123, "15": 0.0003288976149633527, "16": 0.0003128320095129311, "17": 0.3116171360015869, "18": 0.00028499026666395366, "19": 0.0002728485851548612}}, {"key": "garcia2023unreasonable", "year": "2023", "title": "The Unreasonable Effectiveness Of Few-shot Learning For Machine Translation", "topic_distr": {"0": 0.001211395370773971, "1": 0.0009887982159852982, "2": 0.000835859274957329, "3": 0.0007239556289277971, "4": 0.0006384981097653508, "5": 0.0005710890982300043, "6": 0.0005165549227967858, "7": 0.07074905931949615, "8": 0.00043372143409214914, "9": 0.04309087619185448, "10": 0.00037378259003162384, "11": 0.03156919777393341, "12": 0.00032839897903613746, "13": 0.00030960337608121336, "14": 0.7910280227661133, "15": 0.055643804371356964, "16": 0.0002642339386511594, "17": 0.0002519280242267996, "18": 0.0002407173451501876, "19": 0.00023046188289299607}}, {"key": "garg2019transfer", "year": "2019", "title": "TANDA: Transfer And Adapt Pre-trained Transformer Models For Answer Sentence Selection", "topic_distr": {"0": 0.0012605880619958043, "1": 0.08114062249660492, "2": 0.20903706550598145, "3": 0.16581083834171295, "4": 0.0006643421365879476, "5": 0.0005942048155702651, "6": 0.0005374631145969033, "7": 0.0004906136309728026, "8": 0.09249428659677505, "9": 0.0004177797818556428, "10": 0.05511259660124779, "11": 0.00036377564538270235, "12": 0.00034169130958616734, "13": 0.11224959790706635, "14": 0.08716028928756714, "15": 0.0002890481846407056, "16": 0.0002749291015788913, "17": 0.19126997888088226, "18": 0.000250460667302832, "19": 0.00023979009711183608}}, {"key": "garridomerch\u00e1n2023simulating", "year": "2023", "title": "Simulating H.P. Lovecraft Horror Literature With The Chatgpt Large Language Model", "topic_distr": {"0": 0.0867893397808075, "1": 0.0010289574274793267, "2": 0.0008697116281837225, "3": 0.10562179982662201, "4": 0.0006643541855737567, "5": 0.000594215642195195, "6": 0.0005374730098992586, "7": 0.112993985414505, "8": 0.0004512851592153311, "9": 0.2838657796382904, "10": 0.0003889190556947142, "11": 0.00036378236836753786, "12": 0.23686394095420837, "13": 0.0003221408696845174, "14": 0.00030470159254036844, "15": 0.032249994575977325, "16": 0.00027493416564539075, "17": 0.13532446324825287, "18": 0.00025046529481187463, "19": 0.00023979450634215027}}, {"key": "gaur2021information", "year": "2021", "title": "ISEEQ: Information Seeking Question Generation Using Dynamic Meta-information Retrieval And Knowledge Graphs", "topic_distr": {"0": 0.0009669744176790118, "1": 0.0007895019953139126, "2": 0.17834186553955078, "3": 0.0005780470673926175, "4": 0.18271279335021973, "5": 0.0004559903754852712, "6": 0.0004124471452087164, "7": 0.07880061864852905, "8": 0.2825109362602234, "9": 0.09366507083177567, "10": 0.0002984495076816529, "11": 0.04672623053193092, "12": 0.0576719231903553, "13": 0.0002472051128279418, "14": 0.00023382253129966557, "15": 0.0002218144800281152, "16": 0.0747889056801796, "17": 0.000201153801754117, "18": 0.00019220255489926785, "19": 0.00018401400302536786}}, {"key": "gauthier2019linking", "year": "2019", "title": "Linking Artificial And Human Neural Representations Of Language", "topic_distr": {"0": 0.15870322287082672, "1": 0.0013226500013843179, "2": 0.4654797315597534, "3": 0.0009684728574939072, "4": 0.0008541554561816156, "5": 0.0007639785180799663, "6": 0.0006910250522196293, "7": 0.08817653357982635, "8": 0.03210318833589554, "9": 0.0005371462902985513, "10": 0.24699446558952332, "11": 0.0004677122924476862, "12": 0.00043931810068897903, "13": 0.0004141741374041885, "14": 0.0003917526046279818, "15": 0.000371633970644325, "16": 0.0003534808347467333, "17": 0.000337018514983356, "18": 0.00032202136935666203, "19": 0.00030830202740617096}}, {"key": "gavrilov2019self", "year": "2019", "title": "Self-attentive Model For Headline Generation", "topic_distr": {"0": 0.0027713149320334196, "1": 0.06728152930736542, "2": 0.16327916085720062, "3": 0.06470714509487152, "4": 0.0014614121755585074, "5": 0.0013071256689727306, "6": 0.0011823062086477876, "7": 0.164560467004776, "8": 0.0009927144274115562, "9": 0.0009190279524773359, "10": 0.24476276338100433, "11": 0.0008002301910892129, "12": 0.0007516493205912411, "13": 0.0007086293771862984, "14": 0.0006702673272229731, "15": 0.28158438205718994, "16": 0.0006047864444553852, "17": 0.0005766203394159675, "18": 0.0005509610055014491, "19": 0.0005274879513308406}}, {"key": "ge2023expressive", "year": "2023", "title": "Expressive Text-to-image Generation With Rich Text", "topic_distr": {"0": 0.0012245108373463154, "1": 0.07154609262943268, "2": 0.16998586058616638, "3": 0.0007311892113648355, "4": 0.0006448770291171968, "5": 0.040973830968141556, "6": 0.000521714857313782, "7": 0.3996714651584625, "8": 0.00043805394670926034, "9": 0.0004055383906234056, "10": 0.0003775163786485791, "11": 0.0003531166585162282, "12": 0.0003316794172860682, "13": 0.0003126960655208677, "14": 0.00029576808447018266, "15": 0.0002805787662509829, "16": 0.00026687339413911104, "17": 0.0720934271812439, "18": 0.23931244015693665, "19": 0.0002327639958821237}}, {"key": "gehman2020evaluating", "year": "2020", "title": "Realtoxicityprompts: Evaluating Neural Toxic Degeneration In Language Models", "topic_distr": {"0": 0.14547042548656464, "1": 0.1914970427751541, "2": 0.05279078707098961, "3": 0.000801845162641257, "4": 0.0007071915315464139, "5": 0.000632530718576163, "6": 0.0005721293855458498, "7": 0.24910639226436615, "8": 0.00048038410022854805, "9": 0.0004447264946065843, "10": 0.0004139966331422329, "11": 0.0003872391243930906, "12": 0.0003637303598225117, "13": 0.00034291259362362325, "14": 0.0003243488317821175, "15": 0.0003076917491853237, "16": 0.00029266197816468775, "17": 0.10135027021169662, "18": 0.0002666153304744512, "19": 0.2534470558166504}}, {"key": "gehrmann2018end", "year": "2018", "title": "End-to-end Content And Plan Selection For Data-to-text Generation", "topic_distr": {"0": 0.0017572370124980807, "1": 0.11703936010599136, "2": 0.28804460167884827, "3": 0.0010502506047487259, "4": 0.04459710791707039, "5": 0.0008284870418719947, "6": 0.08837562054395676, "7": 0.30423370003700256, "8": 0.000629205780569464, "9": 0.0005825015832670033, "10": 0.0005422516842372715, "11": 0.000507204735185951, "12": 0.14910313487052917, "13": 0.0004491459985729307, "14": 0.000424831232521683, "15": 0.00040301380795426667, "16": 0.0003833278897218406, "17": 0.00036547554191201925, "18": 0.00034921205951832235, "19": 0.0003343342978041619}}, {"key": "gehrmann2019statistical", "year": "2019", "title": "GLTR: Statistical Detection And Visualization Of Generated Text", "topic_distr": {"0": 0.09476924687623978, "1": 0.04336193948984146, "2": 0.0014844335382804275, "3": 0.11711889505386353, "4": 0.001133928308263421, "5": 0.0010142141254618764, "6": 0.0009173650178126991, "7": 0.3356989324092865, "8": 0.0007702585426159203, "9": 0.0007130843005143106, "10": 0.0006638113991357386, "11": 0.0006209078128449619, "12": 0.0005832132883369923, "13": 0.0005498336395248771, "14": 0.0005200681043788791, "15": 0.39832645654678345, "16": 0.00046926073264330626, "17": 0.00044740631710737944, "18": 0.0004274969396647066, "19": 0.00040928396629169583}}, {"key": "gehrmann2021gem", "year": "2021", "title": "The GEM Benchmark: Natural Language Generation, Its Evaluation And Metrics", "topic_distr": {"0": 0.00195100880227983, "1": 0.0015914894174784422, "2": 0.001345223281532526, "3": 0.15179148316383362, "4": 0.001027595717459917, "5": 0.0009191082790493965, "6": 0.0008313410799019039, "7": 0.0007588748703710735, "8": 0.0006980292382650077, "9": 0.0006462164456024766, "10": 0.0006015639519318938, "11": 0.0525130033493042, "12": 0.6383689641952515, "13": 0.0004982742248103023, "14": 0.05699267238378525, "15": 0.08787613362073898, "16": 0.0004252568178344518, "17": 0.00040545177762396634, "18": 0.00038740935269743204, "19": 0.00037090425030328333}}, {"key": "geiping2022training", "year": "2022", "title": "Cramming: Training A Language Model On A Single GPU In One Day", "topic_distr": {"0": 0.0014025212731212378, "1": 0.0011447074357420206, "2": 0.24664349853992462, "3": 0.0008380027138628066, "4": 0.0007390794926322997, "5": 0.0006610515993088484, "6": 0.000597926729824394, "7": 0.0005458067753352225, "8": 0.043949734419584274, "9": 0.0004647792666219175, "10": 0.05519050359725952, "11": 0.03440176323056221, "12": 0.09523022919893265, "13": 0.345394104719162, "14": 0.04812389239668846, "15": 0.0003215656033717096, "16": 0.0003058581496588886, "17": 0.0002916137455031276, "18": 0.000278637045994401, "19": 0.12347468733787537}}, {"key": "gekhman2024does", "year": "2024", "title": "Does Fine-tuning Llms On New Knowledge Encourage Hallucinations?", "topic_distr": {"0": 0.18595968186855316, "1": 0.15304695069789886, "2": 0.0009783616987988353, "3": 0.07918258011341095, "4": 0.0007473576115444303, "5": 0.0006684556719847023, "6": 0.0006046238704584539, "7": 0.0005519200349226594, "8": 0.01841065101325512, "9": 0.0637781098484993, "10": 0.00043750982149504125, "11": 0.0004092325980309397, "12": 0.0003843886370304972, "13": 0.00036238852771930397, "14": 0.0003427704214118421, "15": 0.00032516728970222175, "16": 0.41600316762924194, "17": 0.0002948799228761345, "18": 0.00028175790794193745, "19": 0.07723001390695572}}, {"key": "geminiteam2023family", "year": "2023", "title": "Gemini: A Family Of Highly Capable Multimodal Models", "topic_distr": {"0": 0.0016854838468134403, "1": 0.0013762328308075666, "2": 0.0011634199181571603, "3": 0.2200009971857071, "4": 0.0008887227158993483, "5": 0.03064984455704689, "6": 0.0007189901662059128, "7": 0.0006563173956237733, "8": 0.0006036947015672922, "9": 0.11299212276935577, "10": 0.0005202661268413067, "11": 0.00048664017231203616, "12": 0.397224098443985, "13": 0.00043093538261018693, "14": 0.00040760645060800016, "15": 0.00038667363696731627, "16": 0.0003677858621813357, "17": 0.00035065735573880374, "18": 0.22876878082752228, "19": 0.0003207787231076509}}, {"key": "geminiteam2024gemini", "year": "2024", "title": "Gemini 1.5: Unlocking Multimodal Understanding Across Millions Of Tokens Of Context", "topic_distr": {"0": 0.0012607156531885266, "1": 0.0010288432240486145, "2": 0.2394808977842331, "3": 0.0999085009098053, "4": 0.0006643411470577121, "5": 0.01359796617180109, "6": 0.0005374625907279551, "7": 0.024880418553948402, "8": 0.07530677318572998, "9": 0.03304241970181465, "10": 0.0003889115178026259, "11": 0.00036377529613673687, "12": 0.15231285989284515, "13": 0.14051976799964905, "14": 0.029004886746406555, "15": 0.000289047893602401, "16": 0.00027492883964441717, "17": 0.00026212484226562083, "18": 0.1866355836391449, "19": 0.0002397898497292772}}, {"key": "gemmateam2024gemma", "year": "2024", "title": "Gemma 2: Improving Open Language Models At A Practical Size", "topic_distr": {"0": 0.0022670987527817488, "1": 0.029307903721928596, "2": 0.3927398920059204, "3": 0.0013557688798755407, "4": 0.0011957347160205245, "5": 0.0010694974334910512, "6": 0.0009673693566583097, "7": 0.0008830459555611014, "8": 0.0008122444269247353, "9": 0.0007519537466578186, "10": 0.0006999949691817164, "11": 0.0006547527736984193, "12": 0.13788795471191406, "13": 0.42648908495903015, "14": 0.000548416399396956, "15": 0.0005202522152103484, "16": 0.0004948395653627813, "17": 0.0004717939009424299, "18": 0.00045079929986968637, "19": 0.0004315935366321355}}, {"key": "gemmateam2024open", "year": "2024", "title": "Gemma: Open Models Based On Gemini Research And Technology", "topic_distr": {"0": 0.10996074229478836, "1": 0.0016696513630449772, "2": 0.001411407720297575, "3": 0.0936589241027832, "4": 0.0010781654855236411, "5": 0.0009643397061154246, "6": 0.0008722534985281527, "7": 0.0007962210802361369, "8": 0.0007323810714296997, "9": 0.0006780184339731932, "10": 0.0006311684846878052, "11": 0.09171856194734573, "12": 0.505698025226593, "13": 0.13506776094436646, "14": 0.0004944937536492944, "15": 0.000469098798930645, "16": 0.0004461848293431103, "17": 0.00042540510185062885, "18": 0.0004064747772645205, "19": 0.052820734679698944}}, {"key": "geng2020dynamic", "year": "2020", "title": "Dynamic Graph Representation Learning For Video Dialog Via Multi-modal Shuffled Transformers", "topic_distr": {"0": 0.0012120219180360436, "1": 0.0009888781933113933, "2": 0.0008359200437553227, "3": 0.0007240105769596994, "4": 0.11100556701421738, "5": 0.0005711322301067412, "6": 0.0005165939801372588, "7": 0.057647597044706345, "8": 0.09085625410079956, "9": 0.00040155783062800765, "10": 0.1929638683795929, "11": 0.06993062794208527, "12": 0.00032842380460351706, "13": 0.00030962677556090057, "14": 0.00029286497738212347, "15": 0.00027782475808635354, "16": 0.08431293070316315, "17": 0.0002519470581319183, "18": 0.3863418996334076, "19": 0.00023047930153552443}}, {"key": "geng2022recommendation", "year": "2022", "title": "Recommendation As Language Processing (RLP): A Unified Pretrain, Personalized Prompt & Predict Paradigm (P5)", "topic_distr": {"0": 0.0008665036293677986, "1": 0.0007073384476825595, "2": 0.11676830798387527, "3": 0.0005178919527679682, "4": 0.31224068999290466, "5": 0.00040853640530258417, "6": 0.00036952461232431233, "7": 0.0003373139479663223, "8": 0.000310268544126302, "9": 0.04519866034388542, "10": 0.1223769262433052, "11": 0.0002501084527466446, "12": 0.04867970570921898, "13": 0.00022147900017444044, "14": 0.0002094891096930951, "15": 0.011900732293725014, "16": 0.011692143976688385, "17": 0.20268221199512482, "18": 0.1042458638548851, "19": 0.020016290247440338}}, {"key": "geng2023towards", "year": "2023", "title": "VIP5: Towards Multimodal Foundation Models For Recommendation", "topic_distr": {"0": 0.0012225924292579293, "1": 0.0009985787328332663, "2": 0.0008440598612651229, "3": 0.0007310619694180787, "4": 0.15870985388755798, "5": 0.0005766958929598331, "6": 0.0005216262070462108, "7": 0.0004761571763083339, "8": 0.000437979499110952, "9": 0.09053608030080795, "10": 0.000377452204702422, "11": 0.0003530566464178264, "12": 0.09437914937734604, "13": 0.18223793804645538, "14": 0.0002957178221549839, "15": 0.00028053109417669475, "16": 0.00026682805037125945, "17": 0.09398674219846725, "18": 0.37253516912460327, "19": 0.00023272442922461778}}, {"key": "gero2024supporting", "year": "2024", "title": "Supporting Sensemaking Of Large Language Model Outputs At Scale", "topic_distr": {"0": 0.1900968998670578, "1": 0.0014144283486530185, "2": 0.0011957365786656737, "3": 0.38870543241500854, "4": 0.0009134025895036757, "5": 0.0008169705979526043, "6": 0.0007389566162601113, "7": 0.0006745433202013373, "8": 0.0006204593228176236, "9": 0.3510153591632843, "10": 0.0005347139085642993, "11": 0.0005001541576348245, "12": 0.0004697904805652797, "13": 0.00044290247024036944, "14": 0.00041892571607604623, "15": 0.00039741158252581954, "16": 0.0003779992985073477, "17": 0.0003603951190598309, "18": 0.05997581407427788, "19": 0.000329686765326187}}, {"key": "geva2020injecting", "year": "2020", "title": "Injecting Numerical Reasoning Skills Into Language Models", "topic_distr": {"0": 0.0016407240182161331, "1": 0.09219390898942947, "2": 0.25257259607315063, "3": 0.4281955361366272, "4": 0.0008653309778310359, "5": 0.0007739751017652452, "6": 0.0007000670302659273, "7": 0.03944673761725426, "8": 0.0005878059891983867, "9": 0.0005441747489385307, "10": 0.02871573343873024, "11": 0.00047383224591612816, "12": 0.00044506651465781033, "13": 0.0004195935616735369, "14": 0.00039687863318249583, "15": 0.0003764967550523579, "16": 0.00035810607369057834, "17": 0.00034142835647799075, "18": 0.00032623496372252703, "19": 0.15062575042247772}}, {"key": "geva2022transformer", "year": "2022", "title": "Transformer Feed-forward Layers Build Predictions By Promoting Concepts In The Vocabulary Space", "topic_distr": {"0": 0.17702201008796692, "1": 0.0014977530809119344, "2": 0.2608623206615448, "3": 0.001096636289730668, "4": 0.0009671894949860871, "5": 0.0008650797535665333, "6": 0.0007824718486517668, "7": 0.1407015025615692, "8": 0.0006569965626113117, "9": 0.0006082294858060777, "10": 0.23686878383159637, "11": 0.0005296069430187345, "12": 0.0004974552430212498, "13": 0.13591153919696808, "14": 0.00044359517050907016, "15": 0.0004208141181152314, "16": 0.00040025869384407997, "17": 0.0003816178650595248, "18": 0.00036463604192249477, "19": 0.039121512323617935}}, {"key": "ghandeharioun2019approximating", "year": "2019", "title": "Approximating Interactive Human Evaluation With Self-play For Open-domain Dialog Systems", "topic_distr": {"0": 0.10482124239206314, "1": 0.09124727547168732, "2": 0.043116990476846695, "3": 0.0006658764323219657, "4": 0.30777689814567566, "5": 0.0005252747796475887, "6": 0.21049320697784424, "7": 0.00043370045023038983, "8": 0.00039892690256237984, "9": 0.0003693156177178025, "10": 0.00034379653516225517, "11": 0.07668896019458771, "12": 0.025468338280916214, "13": 0.08580394834280014, "14": 0.00026935001369565725, "15": 0.00025551742874085903, "16": 0.0506562702357769, "17": 0.0002317175385542214, "18": 0.00022140621149446815, "19": 0.0002119734708685428}}, {"key": "ghazvininejad2023dictionary", "year": "2023", "title": "Dictionary-based Phrase-level Prompting Of Large Language Models For Machine Translation", "topic_distr": {"0": 0.001484984066337347, "1": 0.001212423318065703, "2": 0.15691502392292023, "3": 0.41013556718826294, "4": 0.0007828861707821488, "5": 0.000700234086252749, "6": 0.0006333675119094551, "7": 0.08960103988647461, "8": 0.0005318022449500859, "9": 0.000492328021209687, "10": 0.00045830896124243736, "11": 0.00042868746095336974, "12": 0.00040266240830533206, "13": 0.0003796163946390152, "14": 0.1925191730260849, "15": 0.00034062567283399403, "16": 0.04990310221910477, "17": 0.09250041097402573, "18": 0.0002951526257675141, "19": 0.00028257802478037775}}, {"key": "gheini2021cross", "year": "2021", "title": "Cross-attention Is All You Need: Adapting Pretrained Transformers For Machine Translation", "topic_distr": {"0": 0.0018363449489697814, "1": 0.0818779245018959, "2": 0.18399566411972046, "3": 0.001096657128073275, "4": 0.0009672039304859936, "5": 0.000865092093590647, "6": 0.0007824829081073403, "7": 0.0007142756367102265, "8": 0.0006570059340447187, "9": 0.16552363336086273, "10": 0.08307933062314987, "11": 0.0005296145100146532, "12": 0.0004974623443558812, "13": 0.08954471349716187, "14": 0.26971352100372314, "15": 0.0004208201135043055, "16": 0.09245501458644867, "17": 0.0003816232783719897, "18": 0.00036464122240431607, "19": 0.024696964770555496}}, {"key": "gholami2023can", "year": "2023", "title": "Can A Student Large Language Model Perform As Well As It's Teacher?", "topic_distr": {"0": 0.001950561534613371, "1": 0.0015919875586405396, "2": 0.0013455745065584779, "3": 0.0011654581176117063, "4": 0.0010278717381879687, "5": 0.0009193555451929569, "6": 0.0008315648883581161, "7": 0.0007590792374685407, "8": 0.0006982171908020973, "9": 0.000646390428300947, "10": 0.000601725943852216, "11": 0.06297729909420013, "12": 0.16969932615756989, "13": 0.5210263133049011, "14": 0.00047142678522504866, "15": 0.0004472164437174797, "16": 0.03661211580038071, "17": 0.1964699923992157, "18": 0.00038751368992961943, "19": 0.00037100413464941084}}, {"key": "gholami2023do", "year": "2023", "title": "Do Generative Large Language Models Need Billions Of Parameters?", "topic_distr": {"0": 0.00197989190928638, "1": 0.0016164921689778566, "2": 0.0013666197191923857, "3": 0.15294206142425537, "4": 0.0010439151665195823, "5": 0.0009337047813460231, "6": 0.0008445435087196529, "7": 0.10885012894868851, "8": 0.0007091145380400121, "9": 0.4013688266277313, "10": 0.0006111172842793167, "11": 0.0005716194282285869, "12": 0.0005369171849451959, "13": 0.324077844619751, "14": 0.0004787845246028155, "15": 0.0004541963280644268, "16": 0.0004320102743804455, "17": 0.0004118907090742141, "18": 0.00039356175693683326, "19": 0.0003767945454455912}}, {"key": "gholami2024ai", "year": "2024", "title": "AI And Memory Wall", "topic_distr": {"0": 0.002011762233451009, "1": 0.001642951974645257, "2": 0.09590829908847809, "3": 0.0012028171913698316, "4": 0.0010608359007164836, "5": 0.0009488389478065073, "6": 0.000858232902828604, "7": 0.0007834226125851274, "8": 0.0007206088048405945, "9": 0.17434757947921753, "10": 0.1770005226135254, "11": 0.0005808849819004536, "12": 0.08923730999231339, "13": 0.41535744071006775, "14": 0.03623650223016739, "15": 0.0004615585203282535, "16": 0.0004390128597151488, "17": 0.00041856715688481927, "18": 0.0003999411128461361, "19": 0.0003829021006822586}}, {"key": "ghosh2023chatgpt", "year": "2023", "title": "Chatgpt Perpetuates Gender Bias In Machine Translation And Ignores Non-gendered Pronouns: Findings Across Bengali And Five Other Low-resource Languages", "topic_distr": {"0": 0.29024598002433777, "1": 0.0011442661052569747, "2": 0.03778949752449989, "3": 0.1721540242433548, "4": 0.08811333030462265, "5": 0.0006609881529584527, "6": 0.02362961880862713, "7": 0.0005457539227791131, "8": 0.0005019960808567703, "9": 0.218595489859581, "10": 0.0004326219204813242, "11": 0.018980123102664948, "12": 0.0003800941922236234, "13": 0.0003583398647606373, "14": 0.1450035721063614, "15": 0.00032153449137695134, "16": 0.0003058285510633141, "17": 0.00029158551478758454, "18": 0.00027861009584739804, "19": 0.0002667402441147715}}, {"key": "ghosh2023clip", "year": "2023", "title": "Clipsyntel: CLIP And LLM Synergy For Multimodal Question Summarization In Healthcare", "topic_distr": {"0": 0.0008781853248365223, "1": 0.0007172746118158102, "2": 0.0006063457112759352, "3": 0.0005251835682429373, "4": 0.0004631892661564052, "5": 0.0004142880789004266, "6": 0.00037472706753760576, "7": 0.15272454917430878, "8": 0.11423582583665848, "9": 0.16089563071727753, "10": 0.0002711550041567534, "11": 0.0002536296669859439, "12": 0.22460249066352844, "13": 0.009143004193902016, "14": 0.00021243846276775002, "15": 0.0002015285863308236, "16": 0.0001916845649247989, "17": 0.00018275743059348315, "18": 0.3245507478713989, "19": 0.008555303327739239}}, {"key": "gilardi2023chatgpt", "year": "2023", "title": "Chatgpt Outperforms Crowd-workers For Text-annotation Tasks", "topic_distr": {"0": 0.001891296822577715, "1": 0.2570992708206177, "2": 0.14939823746681213, "3": 0.001129880896769464, "4": 0.0009965039789676666, "5": 0.0008912995690479875, "6": 0.07855121791362762, "7": 0.0007359144510701299, "8": 0.0006769097526557744, "9": 0.26083797216415405, "10": 0.0005833631148561835, "11": 0.0005456590442918241, "12": 0.0005125328316353261, "13": 0.24371838569641113, "14": 0.0004570402670651674, "15": 0.0004335687553975731, "16": 0.0004123903054278344, "17": 0.0003931844839826226, "18": 0.0003756879305001348, "19": 0.0003596822207327932}}, {"key": "gilbert2023semantic", "year": "2023", "title": "Semantic Compression With Large Language Models", "topic_distr": {"0": 0.07691457867622375, "1": 0.000835040642414242, "2": 0.0007057443144731224, "3": 0.345176100730896, "4": 0.0005390997393988073, "5": 0.0004821849288418889, "6": 0.0574038103222847, "7": 0.09516415745019913, "8": 0.03768087178468704, "9": 0.04393995553255081, "10": 0.0003155939921271056, "11": 0.00029519645613618195, "12": 0.00027727545239031315, "13": 0.18702316284179688, "14": 0.0002472545311320573, "15": 0.04151280224323273, "16": 0.1108766496181488, "17": 0.00021270912839099765, "18": 0.00020324367505963892, "19": 0.00019458471797406673}}, {"key": "gill2023transformative", "year": "2023", "title": "Transformative Effects Of Chatgpt On Modern Education: Emerging Era Of AI Chatbots", "topic_distr": {"0": 0.20906101167201996, "1": 0.05613633617758751, "2": 0.017657198011875153, "3": 0.031147724017500877, "4": 0.0005622045719064772, "5": 0.0005028505111113191, "6": 0.00045483256690204144, "7": 0.0004151857865508646, "8": 0.01990699954330921, "9": 0.6404581069946289, "10": 0.00032911988091655076, "11": 0.011936155147850513, "12": 0.0002891590993385762, "13": 0.00027260935166850686, "14": 0.00025785149773582816, "15": 0.0002446094003971666, "16": 0.009731336496770382, "17": 0.00022182552493177354, "18": 0.0002119543933076784, "19": 0.0002029243332799524}}, {"key": "girdhar2023emu", "year": "2023", "title": "Emu Video: Factorizing Text-to-video Generation By Explicit Image Conditioning", "topic_distr": {"0": 0.001863026642240584, "1": 0.035695891827344894, "2": 0.001285090809687972, "3": 0.08068330585956573, "4": 0.0009816597448661923, "5": 0.07920683920383453, "6": 0.0007941773510538042, "7": 0.42259013652801514, "8": 0.0006668250425718725, "9": 0.030078783631324768, "10": 0.0005746720707975328, "11": 0.0005375297041609883, "12": 0.0005048970342613757, "13": 0.0004759996954817325, "14": 0.0004502311930991709, "15": 0.00042710936395451427, "16": 0.000406246428610757, "17": 0.04079914465546608, "18": 0.3016241192817688, "19": 0.00035432359436526895}}, {"key": "glaese2022improving", "year": "2022", "title": "Improving Alignment Of Dialogue Agents Via Targeted Human Judgements", "topic_distr": {"0": 0.458139032125473, "1": 0.016146192327141762, "2": 0.0009062427561730146, "3": 0.0007849326357245445, "4": 0.0006922740722075105, "5": 0.2272801697254181, "6": 0.0005600602016784251, "7": 0.0005112409708090127, "8": 0.0004702503210864961, "9": 0.00043534490396268666, "10": 0.00040526330121792853, "11": 0.27358824014663696, "12": 0.00035605739685706794, "13": 0.0180355254560709, "14": 0.0003175066376570612, "15": 0.0003012009256053716, "16": 0.0002864882117137313, "17": 0.00027314588078297675, "18": 0.00026099104434251785, "19": 0.00024987183860503137}}, {"key": "glass2019span", "year": "2019", "title": "Span Selection Pre-training For Question Answering", "topic_distr": {"0": 0.05480682849884033, "1": 0.0009703269461169839, "2": 0.4801422655582428, "3": 0.0007102409144863486, "4": 0.0006264005787670612, "5": 0.0005602684104815125, "6": 0.000506767479237169, "7": 0.00046259365626610816, "8": 0.1430005133152008, "9": 0.0003939195303246379, "10": 0.22502459585666656, "11": 0.0003429996722843498, "12": 0.0003221766382921487, "13": 0.09060163795948029, "14": 0.0002872941840905696, "15": 0.0002725400554481894, "16": 0.0002592273522168398, "17": 0.00024715461768209934, "18": 0.00023615635291207582, "19": 0.00022609518782701343}}, {"key": "glass2022generate", "year": "2022", "title": "Re2g: Retrieve, Rerank, Generate", "topic_distr": {"0": 0.001299946685321629, "1": 0.0010609226301312447, "2": 0.2196422666311264, "3": 0.0007768018404021859, "4": 0.023292111232876778, "5": 0.0006127748056314886, "6": 0.10578001290559769, "7": 0.10245239734649658, "8": 0.16747897863388062, "9": 0.0004308363131713122, "10": 0.08300386369228363, "11": 0.0003751444455701858, "12": 0.0208236426115036, "13": 0.2712985575199127, "14": 0.00031421842868439853, "15": 0.0002980815770570189, "16": 0.00028352125082165003, "17": 0.00027031710487790406, "18": 0.0002582881134003401, "19": 0.0002472840715199709}}, {"key": "glm2024family", "year": "2024", "title": "Chatglm: A Family Of Large Language Models From GLM-130B To GLM-4 All Tools", "topic_distr": {"0": 0.07106974720954895, "1": 0.10537564009428024, "2": 0.000782753573730588, "3": 0.3466589152812958, "4": 0.06459730863571167, "5": 0.0005348038976080716, "6": 0.04233197495341301, "7": 0.0004415685834828764, "8": 0.00040616418118588626, "9": 0.00037601569783873856, "10": 0.00035003366065211594, "11": 0.0003274102055002004, "12": 0.1554703414440155, "13": 0.0632764995098114, "14": 0.00027423654682934284, "15": 0.14680194854736328, "16": 0.00024744533584453166, "17": 0.00023592132492922246, "18": 0.00022542293299920857, "19": 0.0002158190618501976}}, {"key": "goel2022cyclic", "year": "2022", "title": "Cyclip: Cyclic Contrastive Language-image Pretraining", "topic_distr": {"0": 0.0013441371265798807, "1": 0.16061323881149292, "2": 0.17331580817699432, "3": 0.0008018671651370823, "4": 0.0007072146981954575, "5": 0.0006325509748421609, "6": 0.0005721477209590375, "7": 0.0005222748732194304, "8": 0.0004803995252586901, "9": 0.0004447407554835081, "10": 0.25035831332206726, "11": 0.00038725155172869563, "12": 0.0003637420304585248, "13": 0.0003429235948715359, "14": 0.000324359250953421, "15": 0.00030770161538384855, "16": 0.0002926713787019253, "17": 0.0002790410944726318, "18": 0.3576633334159851, "19": 0.05024627223610878}}, {"key": "goldfarbtarrant2020content", "year": "2020", "title": "Content Planning For Neural Story Generation With Aristotelian Rescoring", "topic_distr": {"0": 0.002238234970718622, "1": 0.0018187175737693906, "2": 0.0015373086789622903, "3": 0.0013315067626535892, "4": 0.001174328150227666, "5": 0.001050350023433566, "6": 0.0009500503074377775, "7": 0.9297317862510681, "8": 0.0007977025816217065, "9": 0.0007384912460111082, "10": 0.0006874627433717251, "11": 0.0006430305074900389, "12": 0.0006039930158294737, "13": 0.0005694240098819137, "14": 0.0005385979311540723, "15": 0.000510937999933958, "16": 0.00048598030116409063, "17": 0.053725484758615494, "18": 0.00044272851664572954, "19": 0.00042386658606119454}}, {"key": "golovneva2022suite", "year": "2022", "title": "ROSCOE: A Suite Of Metrics For Scoring Step-by-step Reasoning", "topic_distr": {"0": 0.09456545114517212, "1": 0.019780699163675308, "2": 0.000820006534922868, "3": 0.5576390624046326, "4": 0.06622150540351868, "5": 0.06525057554244995, "6": 0.0005067486199550331, "7": 0.127277672290802, "8": 0.024654937908053398, "9": 0.00039390483289025724, "10": 0.00036668666871264577, "11": 0.040368445217609406, "12": 0.0003221646184101701, "13": 0.0003037258284166455, "14": 0.00028728347388096154, "15": 0.00027252989821136, "16": 0.00025921768974512815, "17": 0.00024714539176784456, "18": 0.00023614754900336266, "19": 0.0002260867622680962}}, {"key": "gonen2022demystifying", "year": "2022", "title": "Demystifying Prompts In Language Models Via Perplexity Estimation", "topic_distr": {"0": 0.12500238418579102, "1": 0.001616800669580698, "2": 0.213450089097023, "3": 0.16588187217712402, "4": 0.0010439780307933688, "5": 0.0009337621158920228, "6": 0.0008445955463685095, "7": 0.0007709739729762077, "8": 0.0007091582519933581, "9": 0.0006565193762071431, "10": 0.0006111550028435886, "11": 0.0005716547020711005, "12": 0.0005369503051042557, "13": 0.0005062184645794332, "14": 0.00047881403588689864, "15": 0.00045422432594932616, "16": 0.0004320369043853134, "17": 0.3541308045387268, "18": 0.0003935860295314342, "19": 0.1309744268655777}}, {"key": "gong2022future", "year": "2022", "title": "Future Transformer For Long-term Action Anticipation", "topic_distr": {"0": 0.04063141345977783, "1": 0.0013761887094005942, "2": 0.29383450746536255, "3": 0.0010076978942379355, "4": 0.0008887504227459431, "5": 0.0007949213613756001, "6": 0.0007190129836089909, "7": 0.07026419043540955, "8": 0.0006037138518877327, "9": 0.0005589018110185862, "10": 0.09818059206008911, "11": 0.38584381341934204, "12": 0.07959206402301788, "13": 0.0004309490614105016, "14": 0.0004076194018125534, "15": 0.000386685918783769, "16": 0.0003677975619211793, "17": 0.0003506684734020382, "18": 0.023439690470695496, "19": 0.00032078890944831073}}, {"key": "gong2022sequence", "year": "2022", "title": "Diffuseq: Sequence To Sequence Text Generation With Diffusion Models", "topic_distr": {"0": 0.12176240980625153, "1": 0.0012421264545992017, "2": 0.0010500311618670821, "3": 0.15764310956001282, "4": 0.0008020990062505007, "5": 0.0007174180936999619, "6": 0.0006489106453955173, "7": 0.32898688316345215, "8": 0.0005448528681881726, "9": 0.0005044099525548518, "10": 0.22125287353992462, "11": 0.0004392075934447348, "12": 0.00041254391544498503, "13": 0.0003889323561452329, "14": 0.0003678772773128003, "15": 0.07075702399015427, "16": 0.0003319379757158458, "17": 0.0003164789522998035, "18": 0.09154140204191208, "19": 0.0002895125944633037}}, {"key": "gong2023multimodal", "year": "2023", "title": "Multimodal-gpt: A Vision And Language Model For Dialogue With Humans", "topic_distr": {"0": 0.11445598304271698, "1": 0.15512607991695404, "2": 0.0010010768892243505, "3": 0.000867072434630245, "4": 0.0007647213060408831, "5": 0.16135720908641815, "6": 0.000618671125266701, "7": 0.0005647428915835917, "8": 0.054478131234645844, "9": 0.00048090421478264034, "10": 0.016380229964852333, "11": 0.16622881591320038, "12": 0.0003933191765099764, "13": 0.031207047402858734, "14": 0.00035073404433205724, "15": 0.0003327219164930284, "16": 0.0003164695226587355, "17": 0.07778536528348923, "18": 0.21701470017433167, "19": 0.00027602119371294975}}, {"key": "gontier2020measuring", "year": "2020", "title": "Measuring Systematic Generalization In Neural Proof Generation With Transformers", "topic_distr": {"0": 0.15024767816066742, "1": 0.0010720863938331604, "2": 0.0009062816970981658, "3": 0.3672293424606323, "4": 0.0006922897882759571, "5": 0.0006192015716806054, "6": 0.08875831216573715, "7": 0.0005112526705488563, "8": 0.00047026111860759556, "9": 0.0004353548865765333, "10": 0.15628644824028015, "11": 0.12136589735746384, "12": 0.0003560655750334263, "13": 0.0003356864908710122, "14": 0.0003175139136146754, "15": 0.0003012078523170203, "16": 0.03787371143698692, "17": 0.07171054929494858, "18": 0.00026099703973159194, "19": 0.00024987757205963135}}, {"key": "gopalakrishnan2023topical", "year": "2023", "title": "Topical-chat: Towards Knowledge-grounded Open-domain Conversations", "topic_distr": {"0": 0.0019202741095796227, "1": 0.001566927065141499, "2": 0.08953501284122467, "3": 0.0011472668265923858, "4": 0.0010118447244167328, "5": 0.0009050191147252917, "6": 0.24081122875213623, "7": 0.0007472420111298561, "8": 0.0006873290985822678, "9": 0.17420712113380432, "10": 0.0005923425778746605, "11": 0.16598662734031677, "12": 0.17391559481620789, "13": 0.0004906361573375762, "14": 0.00046407530317083, "15": 0.0004402424965519458, "16": 0.14442524313926697, "17": 0.00039923659642226994, "18": 0.000381470745196566, "19": 0.00036521864240057766}}, {"key": "gordon2019explaining", "year": "2019", "title": "Explaining Sequence-level Knowledge Distillation As Data-augmentation For Neural Machine Translation", "topic_distr": {"0": 0.0020466987043619156, "1": 0.09218589216470718, "2": 0.3291301429271698, "3": 0.0012223960366100073, "4": 0.0010781019227579236, "5": 0.0009642828954383731, "6": 0.0008722021011635661, "7": 0.0007961741066537797, "8": 0.0007323378813453019, "9": 0.0006779784453101456, "10": 0.0006311312317848206, "11": 0.0005903398268856108, "12": 0.0005545010790228844, "13": 0.48214995861053467, "14": 0.0842316672205925, "15": 0.0004690711502917111, "16": 0.00044615851948037744, "17": 0.00042538001434877515, "18": 0.0004064507957082242, "19": 0.0003891344531439245}}, {"key": "gou2023large", "year": "2023", "title": "CRITIC: Large Language Models Can Self-correct With Tool-interactive Critiquing", "topic_distr": {"0": 0.0014354122104123235, "1": 0.0011706772493198514, "2": 0.000989592750556767, "3": 0.6825674176216125, "4": 0.12800797820091248, "5": 0.0006761407712474465, "6": 0.000611575145740062, "7": 0.08952399343252182, "8": 0.03690098226070404, "9": 0.0004753883695229888, "10": 0.00044253983651287854, "11": 0.0004139374941587448, "12": 0.05457327514886856, "13": 0.0003665548574645072, "14": 0.00034671122557483613, "15": 0.00032890570582821965, "16": 0.0003128396929241717, "17": 0.00029827014077454805, "18": 0.0002849972515832633, "19": 0.0002728553081396967}}, {"key": "gou2023multi", "year": "2023", "title": "Mvp: Multi-view Prompting Improves Aspect Sentiment Tuple Prediction", "topic_distr": {"0": 0.0013868676032871008, "1": 0.10489773005247116, "2": 0.36797529458999634, "3": 0.0008286325028166175, "4": 0.0007308186613954604, "5": 0.0006536630680784583, "6": 0.000591243791859597, "7": 0.10490702092647552, "8": 0.0004964333493262529, "9": 0.0004595844657160342, "10": 0.000427827937528491, "11": 0.01650673896074295, "12": 0.0003758822858799249, "13": 0.0003543690254446119, "14": 0.00033518506097607315, "15": 0.00031797148403711617, "16": 0.08614199608564377, "17": 0.3120734393596649, "18": 0.0002755227324087173, "19": 0.00026378442998975515}}, {"key": "goyal2019using", "year": "2019", "title": "Using Natural Language For Reward Shaping In Reinforcement Learning", "topic_distr": {"0": 0.0012470486108213663, "1": 0.001018851762637496, "2": 0.22181344032287598, "3": 0.0007456495077349246, "4": 0.0006576309096999466, "5": 0.0005882020341232419, "6": 0.0005320336786098778, "7": 0.0004856574523728341, "8": 0.00044671804062090814, "9": 0.00041355937719345093, "10": 0.00038498311187140644, "11": 0.7694044709205627, "12": 0.00033823956619016826, "13": 0.00031888074590824544, "14": 0.00030161795439198613, "15": 0.00028612822643481195, "16": 0.0002721517812460661, "17": 0.0002594771212898195, "18": 0.00024793052580207586, "19": 0.00023736774164717644}}, {"key": "goyal2021larger", "year": "2021", "title": "Larger-scale Transformers For Multilingual Masked Language Modeling", "topic_distr": {"0": 0.002654554322361946, "1": 0.002166748745366931, "2": 0.0018317133653908968, "3": 0.0015864737797528505, "4": 0.0013991999439895153, "5": 0.0012514814734458923, "6": 0.0011319757904857397, "7": 0.0010333037935197353, "8": 0.0009504548506811261, "9": 0.0008799051865935326, "10": 0.3605065643787384, "11": 0.0007661646232008934, "12": 0.0007196518126875162, "13": 0.10275915265083313, "14": 0.4005275070667267, "15": 0.0006087776855565608, "16": 0.0005790407885797322, "17": 0.0005520737613551319, "18": 0.0005275066941976547, "19": 0.11756774038076401}}, {"key": "goyal2022news", "year": "2022", "title": "News Summarization And Evaluation In The Era Of GPT-3", "topic_distr": {"0": 0.2617056965827942, "1": 0.0010953402379527688, "2": 0.0009258322534151375, "3": 0.18074262142181396, "4": 0.06525726616382599, "5": 0.0006325595895759761, "6": 0.000572155462577939, "7": 0.22029413282871246, "8": 0.0004804059863090515, "9": 0.0004447467508725822, "10": 0.00041401549242436886, "11": 0.0003872567613143474, "12": 0.16671498119831085, "13": 0.00034292819327674806, "14": 0.00032436358742415905, "15": 0.09857209771871567, "16": 0.00029267530771903694, "17": 0.00027904484886676073, "18": 0.00026662746677175164, "19": 0.00025526812532916665}}, {"key": "gozalobrizuela2023chatgpt", "year": "2023", "title": "Chatgpt Is Not All You Need. A State Of The Art Review Of Large Generative AI Models", "topic_distr": {"0": 0.0013561639934778214, "1": 0.10139168798923492, "2": 0.0009359222603961825, "3": 0.08580154925584793, "4": 0.0007149339071474969, "5": 0.0006394560332410038, "6": 0.0005783930537290871, "7": 0.04151291027665138, "8": 0.02031540870666504, "9": 0.4090941846370697, "10": 0.00041852908907458186, "11": 0.0003914786211680621, "12": 0.00036771249142475426, "13": 0.00034666681312955916, "14": 0.000327899819239974, "15": 0.16366039216518402, "16": 0.0002958660479635, "17": 0.00028208698495291173, "18": 0.1713106632232666, "19": 0.00025805106270127}}, {"key": "greshake2023not", "year": "2023", "title": "Not What You've Signed Up For: Compromising Real-world Llm-integrated Applications With Indirect Prompt Injection", "topic_distr": {"0": 0.04889099672436714, "1": 0.18162137269973755, "2": 0.0007057550246827304, "3": 0.2636379301548004, "4": 0.1035487949848175, "5": 0.00048220614553429186, "6": 0.00043615952017717063, "7": 0.0003981404297519475, "8": 0.00036621803883463144, "9": 0.2923082709312439, "10": 0.00031560793286189437, "11": 0.00029520949465222657, "12": 0.0002772877342067659, "13": 0.000261417415458709, "14": 0.0002472654450684786, "15": 0.00023456702183466405, "16": 0.000223109163925983, "17": 0.10535184293985367, "18": 0.00020325265359133482, "19": 0.00019459333270788193}}, {"key": "groeneveld2024accelerating", "year": "2024", "title": "Olmo: Accelerating The Science Of Language Models", "topic_distr": {"0": 0.13421480357646942, "1": 0.08039739727973938, "2": 0.08051425218582153, "3": 0.001007753424346447, "4": 0.0008887974545359612, "5": 0.0007949633290991187, "6": 0.04826226085424423, "7": 0.000656372809316963, "8": 0.0006037456914782524, "9": 0.13799308240413666, "10": 0.0005203100736252964, "11": 0.00048668126692064106, "12": 0.4120093286037445, "13": 0.056839048862457275, "14": 0.0004076408804394305, "15": 0.0003867062914650887, "16": 0.000367816915968433, "17": 0.00035068695433437824, "18": 0.000335081567754969, "19": 0.042963311076164246}}, {"key": "gruver2023large", "year": "2023", "title": "Large Language Models Are Zero-shot Time Series Forecasters", "topic_distr": {"0": 0.07297268509864807, "1": 0.001008585561066866, "2": 0.319338321685791, "3": 0.22683565318584442, "4": 0.0006512292311526835, "5": 0.0005824760883115232, "6": 0.0005268538370728493, "7": 0.07659764587879181, "8": 0.018739284947514534, "9": 0.00040953303687274456, "10": 0.00038123500416986644, "11": 0.0003565949446056038, "12": 0.0502055287361145, "13": 0.00031577618210576475, "14": 0.00029868146521039307, "15": 0.0002833425533026457, "16": 0.00026950216852128506, "17": 0.000256950908806175, "18": 0.13980014622211456, "19": 0.09016995131969452}}, {"key": "gruver2024fine", "year": "2024", "title": "Fine-tuned Language Models Generate Stable Inorganic Materials As Text", "topic_distr": {"0": 0.2649553418159485, "1": 0.06356647610664368, "2": 0.0015106020728126168, "3": 0.18890108168125153, "4": 0.001153911231085658, "5": 0.0010320889996364713, "6": 0.0009335331269539893, "7": 0.4344881474971771, "8": 0.0007838340243324637, "9": 0.000725652149412781, "10": 0.0006755107897333801, "11": 0.0006318510277196765, "12": 0.0005934922373853624, "13": 0.0005595242255367339, "14": 0.0005292341229505837, "15": 0.0005020550452172756, "16": 0.00047753125545568764, "17": 0.0004552916798274964, "18": 0.0004350313975010067, "19": 0.03708979859948158}}, {"key": "gr\u00f6nroos2018memad", "year": "2018", "title": "The Memad Submission To The WMT18 Multimodal Translation Task", "topic_distr": {"0": 0.13128973543643951, "1": 0.0017263536574319005, "2": 0.0014593033120036125, "3": 0.001263936748728156, "4": 0.0011147396871820092, "5": 0.000997051247395575, "6": 0.18647819757461548, "7": 0.0008232296095229685, "8": 0.0007572241011075675, "9": 0.0007010173867456615, "10": 0.06976065039634705, "11": 0.000610400689765811, "12": 0.000573344121221453, "13": 0.06723036617040634, "14": 0.38196104764938354, "15": 0.00048501105629839003, "16": 0.0004613198107108474, "17": 0.00043983524665236473, "18": 0.15146486461162567, "19": 0.00040235798223875463}}, {"key": "gu2017non", "year": "2017", "title": "Non-autoregressive Neural Machine Translation", "topic_distr": {"0": 0.0016854751156643033, "1": 0.0013762470334768295, "2": 0.24478796124458313, "3": 0.0010076502803713083, "4": 0.0008887099102139473, "5": 0.0007948853308334947, "6": 0.0007189805619418621, "7": 0.2288244366645813, "8": 0.0006036866107024252, "9": 0.0005588765488937497, "10": 0.0005202591419219971, "11": 0.03852604329586029, "12": 0.00045709076221100986, "13": 0.2543489933013916, "14": 0.22313977777957916, "15": 0.00038666845648549497, "16": 0.0003677809436339885, "17": 0.00035065264091826975, "18": 0.00033504876773804426, "19": 0.0003207744157407433}}, {"key": "gu2018universal", "year": "2018", "title": "Universal Neural Machine Translation For Extremely Low Resource Languages", "topic_distr": {"0": 0.0014869681326672435, "1": 0.001212507952004671, "2": 0.001025028876028955, "3": 0.0008877998916432261, "4": 0.0007830055546946824, "5": 0.0007003405480645597, "6": 0.0006334639037959278, "7": 0.0005782462540082633, "8": 0.0005318831535987556, "9": 0.0004924029344692826, "10": 0.24572592973709106, "11": 0.0004287526826374233, "12": 0.0004027236718684435, "13": 0.05026216432452202, "14": 0.6017683744430542, "15": 0.09186962246894836, "16": 0.0003240365185774863, "17": 0.0003089454839937389, "18": 0.0002951975620817393, "19": 0.00028262101113796234}}, {"key": "gu2019insertion", "year": "2019", "title": "Insertion-based Decoding With Automatically Inferred Generation Order", "topic_distr": {"0": 0.0015211142599582672, "1": 0.0012420200509950519, "2": 0.4362196922302246, "3": 0.0009093976113945246, "4": 0.0008020514505915344, "5": 0.0007173757185228169, "6": 0.0006488723447546363, "7": 0.3158317804336548, "8": 0.0005448207375593483, "9": 0.0005043801502324641, "10": 0.13698889315128326, "11": 0.0004391816910356283, "12": 0.00041251955553889275, "13": 0.00038890939322300255, "14": 0.03150222450494766, "15": 0.00034896418219432235, "16": 0.00033191838883794844, "17": 0.00031646029674448073, "18": 0.07003991305828094, "19": 0.0002894955105148256}}, {"key": "gu2019levenshtein", "year": "2019", "title": "Levenshtein Transformer", "topic_distr": {"0": 0.0015790570760145783, "1": 0.0012892914237454534, "2": 0.27059289813041687, "3": 0.0009440109715797007, "4": 0.0008325812523253262, "5": 0.0007446804665960371, "6": 0.0006735697388648987, "7": 0.22584594786167145, "8": 0.0005655577406287193, "9": 0.0005235779099166393, "10": 0.21080169081687927, "11": 0.00045589785440824926, "12": 0.00042822089744731784, "13": 0.07645545899868011, "14": 0.20661784708499908, "15": 0.00036224647192284465, "16": 0.00034455189597792923, "17": 0.00032850541174411774, "18": 0.0003138870815746486, "19": 0.00030051430803723633}}, {"key": "gu2020beyond", "year": "2020", "title": "Beyond I.I.D.: Three Levels Of Generalization For Question Answering On Knowledge Bases", "topic_distr": {"0": 0.2511102855205536, "1": 0.16405582427978516, "2": 0.0011038142256438732, "3": 0.0009560294565744698, "4": 0.02096906118094921, "5": 0.0007541613886132836, "6": 0.0006821452989242971, "7": 0.0006226841360330582, "8": 0.12222196906805038, "9": 0.0005302438512444496, "10": 0.17529402673244476, "11": 0.03939097374677658, "12": 0.00043367280159145594, "13": 0.0004088519490323961, "14": 0.00038671851507388055, "15": 0.00036685841041617095, "16": 0.06590812653303146, "17": 0.15418237447738647, "18": 0.0003178833285346627, "19": 0.00030434029758907855}}, {"key": "gu2020discourse", "year": "2020", "title": "Dialogbert: Discourse-aware Response Generation Via Learning To Recover And Rank Utterances", "topic_distr": {"0": 0.0014188408385962248, "1": 0.0011574258096516132, "2": 0.19032536447048187, "3": 0.0008474396890960634, "4": 0.0007474047597497702, "5": 0.0006684979307465255, "6": 0.5487980842590332, "7": 0.0351671539247036, "8": 0.000507699849549681, "9": 0.00047001466737128794, "10": 0.16565640270709991, "11": 0.0004092584422323853, "12": 0.0003844129096250981, "13": 0.00036241140333004296, "14": 0.00034279204555787146, "15": 0.00032518780790269375, "16": 0.05156521126627922, "17": 0.0002948985493276268, "18": 0.0002817756903823465, "19": 0.0002697710006032139}}, {"key": "gu2020speaker", "year": "2020", "title": "Speaker-aware BERT For Multi-turn Response Selection In Retrieval-based Chatbots", "topic_distr": {"0": 0.15454836189746857, "1": 0.001616522204130888, "2": 0.19650615751743317, "3": 0.001183663378469646, "4": 0.001043940894305706, "5": 0.0009337280062027276, "6": 0.33859187364578247, "7": 0.0007709456840530038, "8": 0.0007091322331689298, "9": 0.0006564952782355249, "10": 0.09500642865896225, "11": 0.0005716336891055107, "12": 0.000536930572707206, "13": 0.0005061998963356018, "14": 0.00047879645717330277, "15": 0.00045420764945447445, "16": 0.2047027200460434, "17": 0.00041190098272636533, "18": 0.0003935715649276972, "19": 0.00037680394598282874}}, {"key": "gu2021pre", "year": "2021", "title": "PPT: Pre-trained Prompt Tuning For Few-shot Learning", "topic_distr": {"0": 0.0012732946779578924, "1": 0.001039214781485498, "2": 0.0008784430683590472, "3": 0.0007608538144268095, "4": 0.0006710437010042369, "5": 0.0006001992733217776, "6": 0.0005428853328339756, "7": 0.0004955632030032575, "8": 0.00045582957682199776, "9": 0.00042199459858238697, "10": 0.00039283547084778547, "11": 0.00036744563840329647, "12": 0.00034513851278461516, "13": 0.00032538484083488584, "14": 0.00030776995117776096, "15": 0.0002919642720371485, "16": 0.0002777027548290789, "17": 0.9900572299957275, "18": 0.00025298746186308563, "19": 0.00024220923660323024}}, {"key": "gu2022investigating", "year": "2022", "title": "EVA2.0: Investigating Open-domain Chinese Dialogue Systems With Large-scale Pre-training", "topic_distr": {"0": 0.12316366285085678, "1": 0.0013228587340563536, "2": 0.0011181171284988523, "3": 0.1238384023308754, "4": 0.08275753259658813, "5": 0.11183863878250122, "6": 0.09800051897764206, "7": 0.0502292700111866, "8": 0.0005801827064715326, "9": 0.0005371173028834164, "10": 0.0005000033997930586, "11": 0.0004676870594266802, "12": 0.21404452621936798, "13": 0.06900524348020554, "14": 0.0003917314752470702, "15": 0.12088380008935928, "16": 0.00035346177173778415, "17": 0.000337000354193151, "18": 0.00032200399436987936, "19": 0.00030828540911898017}}, {"key": "gu2022proposal", "year": "2022", "title": "Don't Generate, Discriminate: A Proposal For Grounding Language Models To Real-world Environments", "topic_distr": {"0": 0.001247619278728962, "1": 0.001018758863210678, "2": 0.0008610786171630025, "3": 0.21488536894321442, "4": 0.000657754426356405, "5": 0.0005883125704713166, "6": 0.09136801958084106, "7": 0.0004857487801928073, "8": 0.03304778039455414, "9": 0.0004136371426284313, "10": 0.015438737347722054, "11": 0.28723782300949097, "12": 0.0003383031871635467, "13": 0.00031894072890281677, "14": 0.0003016746777575463, "15": 0.05370273441076279, "16": 0.08674366027116776, "17": 0.05663507431745529, "18": 0.00024797715013846755, "19": 0.15446095168590546}}, {"key": "gu2023knowledge", "year": "2023", "title": "Minillm: Knowledge Distillation Of Large Language Models", "topic_distr": {"0": 0.024777410551905632, "1": 0.001119330176152289, "2": 0.0009461194858886302, "3": 0.23299400508403778, "4": 0.0007227202877402306, "5": 0.0006464198231697083, "6": 0.040782127529382706, "7": 0.0005337258335202932, "8": 0.0004909323761239648, "9": 0.00045449179015122354, "10": 0.0004230871854815632, "11": 0.0003957421286031604, "12": 0.00037171714939177036, "13": 0.409606009721756, "14": 0.0003314708883408457, "15": 0.04775051772594452, "16": 0.05545740947127342, "17": 0.15065690875053406, "18": 0.03127902001142502, "19": 0.000260861444985494}}, {"key": "gu2023linear", "year": "2023", "title": "Mamba: Linear-time Sequence Modeling With Selective State Spaces", "topic_distr": {"0": 0.0010752326343208551, "1": 0.0008779765339568257, "2": 0.39845243096351624, "3": 0.0006428636843338609, "4": 0.0005669766687788069, "5": 0.0005071185296401381, "6": 0.00045869298628531396, "7": 0.00041870970744639635, "8": 0.00038513808976858854, "9": 0.00035655032843351364, "10": 0.28494247794151306, "11": 0.03393317386507988, "12": 0.044516973197460175, "13": 0.1477832794189453, "14": 0.00026004001847468317, "15": 0.0002466855221427977, "16": 0.0002346357359783724, "17": 0.0002237082808278501, "18": 0.06872475147247314, "19": 0.015392587520182133}}, {"key": "gu2023systematic", "year": "2023", "title": "A Systematic Survey Of Prompt Engineering On Vision-language Foundation Models", "topic_distr": {"0": 0.05158085376024246, "1": 0.0009887597989290953, "2": 0.0008359421626664698, "3": 0.0007240426493808627, "4": 0.000638573314063251, "5": 0.0005711562698706985, "6": 0.0005166156333871186, "7": 0.09389374405145645, "8": 0.00043377242400310934, "9": 0.00040157465264201164, "10": 0.0003738265368156135, "11": 0.00034966529347002506, "12": 0.33365190029144287, "13": 0.00030963975586928427, "14": 0.0002928772591985762, "15": 0.00027783639961853623, "16": 0.03661619499325752, "17": 0.35877087712287903, "18": 0.11854171007871628, "19": 0.00023048896400723606}}, {"key": "guan2020knowledge", "year": "2020", "title": "A Knowledge-enhanced Pretraining Model For Commonsense Story Generation", "topic_distr": {"0": 0.0014027849538251758, "1": 0.001144682290032506, "2": 0.0009674822795204818, "3": 0.0008379454375244677, "4": 0.0007390339742414653, "5": 0.0006610111449845135, "6": 0.09745410829782486, "7": 0.3937036693096161, "8": 0.0005020140088163316, "9": 0.0004647508612833917, "10": 0.00043263734551146626, "11": 0.00040467502549290657, "12": 0.00038010775460861623, "13": 0.0003583526413422078, "14": 0.0003389530465938151, "15": 0.0003215459582861513, "16": 0.13732843101024628, "17": 0.3214866518974304, "18": 0.0002786200202535838, "19": 0.040792498737573624}}, {"key": "guan2021long", "year": "2021", "title": "Long Text Generation By Modeling Sentence-level And Discourse-level Coherence", "topic_distr": {"0": 0.0017331850249320269, "1": 0.14380799233913422, "2": 0.0011958276154473424, "3": 0.0010357331484556198, "4": 0.000913475698325783, "5": 0.0008170364308170974, "6": 0.0007390163373202085, "7": 0.5650195479393005, "8": 0.000620509497821331, "9": 0.0005744507652707398, "10": 0.23642201721668243, "11": 0.0005001946119591594, "12": 0.00046982846106402576, "13": 0.0004429382970556617, "14": 0.00041895959293469787, "15": 0.0003974437131546438, "16": 0.0003780298575293273, "17": 0.0003604242519941181, "18": 0.00034438553848303854, "19": 0.043809060007333755}}, {"key": "guan2023leveraging", "year": "2023", "title": "Leveraging Pre-trained Large Language Models To Construct And Utilize World Models For Model-based Task Planning", "topic_distr": {"0": 0.057474225759506226, "1": 0.0008630673983134329, "2": 0.0007296063704416156, "3": 0.5028843283653259, "4": 0.12064212560653687, "5": 0.0004985025152564049, "6": 0.00045089959166944027, "7": 0.00041159565444104373, "8": 0.000378594413632527, "9": 0.000350492395227775, "10": 0.00032627396285533905, "11": 0.1123935803771019, "12": 0.00028665870195254683, "13": 0.00027025205781683326, "14": 0.00025562182418070734, "15": 0.0002424942358629778, "16": 0.20091044902801514, "17": 0.0002199073787778616, "18": 0.00021012160868849605, "19": 0.00020116963423788548}}, {"key": "guan2023mitigating", "year": "2023", "title": "Mitigating Large Language Model Hallucinations Via Autonomous Knowledge Graph-based Retrofitting", "topic_distr": {"0": 0.13270053267478943, "1": 0.0010498398914933205, "2": 0.0008875282946974039, "3": 0.37177544832229614, "4": 0.0006779805407859385, "5": 0.050057921558618546, "6": 0.039203427731990814, "7": 0.0005006850115023553, "8": 0.02303428202867508, "9": 0.00042635604040697217, "10": 0.0003968955425079912, "11": 0.0003712433099281043, "12": 0.0003487056237645447, "13": 0.0003287477884441614, "14": 0.00031095085432752967, "15": 0.00029498181538656354, "16": 0.3768666088581085, "17": 0.0002675060532055795, "18": 0.00025560217909514904, "19": 0.0002447125443723053}}, {"key": "gudibande2023false", "year": "2023", "title": "The False Promise Of Imitating Proprietary Llms", "topic_distr": {"0": 0.0010672584176063538, "1": 0.1263016015291214, "2": 0.0007359349983744323, "3": 0.27671051025390625, "4": 0.0005621626623906195, "5": 0.0005028120940551162, "6": 0.0004547977587208152, "7": 0.0765763372182846, "8": 0.0003818674886133522, "9": 0.09051348268985748, "10": 0.0003290946769993752, "11": 0.16392405331134796, "12": 0.09186301380395889, "13": 0.0002725884842220694, "14": 0.00025783173623494804, "15": 0.00024459068663418293, "16": 0.06987468153238297, "17": 0.00022180854284670204, "18": 0.00021193816792219877, "19": 0.09899363666772842}}, {"key": "guerreiro2022looking", "year": "2022", "title": "Looking For A Needle In A Haystack: A Comprehensive Study Of Hallucinations In Neural Machine Translation", "topic_distr": {"0": 0.22764962911605835, "1": 0.1504565328359604, "2": 0.30985915660858154, "3": 0.0007382748299278319, "4": 0.0006511275423690677, "5": 0.0005823858664371073, "6": 0.02197408676147461, "7": 0.0004808552621398121, "8": 0.0004423009231686592, "9": 0.0004094701143912971, "10": 0.00038117641815915704, "11": 0.0003565401420928538, "12": 0.09075523167848587, "13": 0.00031572766602039337, "14": 0.1229870468378067, "15": 0.07095359265804291, "16": 0.0002694607537705451, "17": 0.0002569114149082452, "18": 0.00024547899374738336, "19": 0.00023502064868807793}}, {"key": "guerreiro2023hallucinations", "year": "2023", "title": "Hallucinations In Large Multilingual Translation Models", "topic_distr": {"0": 0.20277591049671173, "1": 0.0011069690808653831, "2": 0.0009357777889817953, "3": 0.1971782147884369, "4": 0.000714849098585546, "5": 0.000639378500636667, "6": 0.0005783232627436519, "7": 0.0005279120523482561, "8": 0.00048558475100435317, "9": 0.07360953837633133, "10": 0.00041847859392873943, "11": 0.0003914313856512308, "12": 0.19939687848091125, "13": 0.0003466249618213624, "14": 0.31947770714759827, "15": 0.00031102282810024917, "16": 0.0002958303375635296, "17": 0.00028205293347127736, "18": 0.0002695017319638282, "19": 0.0002580199216026813}}, {"key": "guhur2021pretraining", "year": "2021", "title": "Airbert: In-domain Pretraining For Vision-and-language Navigation", "topic_distr": {"0": 0.0012340988032519817, "1": 0.0946565717458725, "2": 0.22942164540290833, "3": 0.0007382974145002663, "4": 0.0006511479732580483, "5": 0.0005824036779813468, "6": 0.0820348933339119, "7": 0.0004808699886780232, "8": 0.0004423144564498216, "9": 0.0004094826290383935, "10": 0.021808044984936714, "11": 0.42888298630714417, "12": 0.000334905314957723, "13": 0.000315737328492105, "14": 0.0002986447070725262, "15": 0.020577313378453255, "16": 0.0002694689901545644, "17": 0.000256919302046299, "18": 0.06783077120780945, "19": 0.048773471266031265}}, {"key": "gui2021knowledge", "year": "2021", "title": "KAT: A Knowledge Augmented Transformer For Vision-and-language", "topic_distr": {"0": 0.0013556414050981402, "1": 0.001107118558138609, "2": 0.21554812788963318, "3": 0.0008105317829176784, "4": 0.000714855850674212, "5": 0.050547439604997635, "6": 0.048296403139829636, "7": 0.0005279180477373302, "8": 0.08096048980951309, "9": 0.0004495462344493717, "10": 0.0930699035525322, "11": 0.0003914358385372907, "12": 0.00036767226993106306, "13": 0.0003466289199423045, "14": 0.0003278639633208513, "15": 0.00031102634966373444, "16": 0.40942466259002686, "17": 0.0002820561348926276, "18": 0.09490266442298889, "19": 0.0002580228610895574}}, {"key": "gulcehre2023reinforced", "year": "2023", "title": "Reinforced Self-training (rest) For Language Modeling", "topic_distr": {"0": 0.0014852185267955065, "1": 0.0638616755604744, "2": 0.0010248974431306124, "3": 0.15052495896816254, "4": 0.29254385828971863, "5": 0.0007002566126175225, "6": 0.0006333880010060966, "7": 0.1387883871793747, "8": 0.0005318194744177163, "9": 0.0004923439119011164, "10": 0.0004583238041959703, "11": 0.1932515949010849, "12": 0.0004026754177175462, "13": 0.03788125887513161, "14": 0.11586806923151016, "15": 0.00034063670318573713, "16": 0.000323997694067657, "17": 0.0003089084639213979, "18": 0.0002951621718239039, "19": 0.00028258716338314116}}, {"key": "gunasekar2023textbooks", "year": "2023", "title": "Textbooks Are All You Need", "topic_distr": {"0": 0.00304336822591722, "1": 0.10019055008888245, "2": 0.002099732868373394, "3": 0.21380765736103058, "4": 0.0016039777547121048, "5": 0.0014346404932439327, "6": 0.0012976443395018578, "7": 0.0011845314875245094, "8": 0.001089557190425694, "9": 0.001008682302199304, "10": 0.05666382983326912, "11": 0.0008782954537309706, "12": 0.0008249753154814243, "13": 0.5634903907775879, "14": 0.0007356542628258467, "15": 0.0006978744058869779, "16": 0.0006637854385189712, "17": 0.0006328716408461332, "18": 0.0006047091446816921, "19": 0.04804728552699089}}, {"key": "gunjal2023detecting", "year": "2023", "title": "Detecting And Preventing Hallucinations In Large Vision Language Models", "topic_distr": {"0": 0.3201366364955902, "1": 0.08506252616643906, "2": 0.0007756233098916709, "3": 0.0006717861979268491, "4": 0.0005924864672124386, "5": 0.0005299351178109646, "6": 0.00047933077439665794, "7": 0.04330521821975708, "8": 0.030710449442267418, "9": 0.00037259244709275663, "10": 0.0003468469367362559, "11": 0.10411775857210159, "12": 0.0003047337813768536, "13": 0.02385845221579075, "14": 0.00027173987473361194, "15": 0.0002577845589257777, "16": 0.0002451926120556891, "17": 0.00023377349134534597, "18": 0.38751325011253357, "19": 0.0002138542477041483}}, {"key": "guo2017long", "year": "2017", "title": "Long Text Generation Via Adversarial Training With Leaked Information", "topic_distr": {"0": 0.0009302005055360496, "1": 0.05825132131576538, "2": 0.20425006747245789, "3": 0.0005564845632761717, "4": 0.05508574843406677, "5": 0.0004389820678625256, "6": 0.051099684089422226, "7": 0.24423806369304657, "8": 0.0003333907516207546, "9": 0.0003086440556216985, "10": 0.0002873172634281218, "11": 0.07705656439065933, "12": 0.00025243201525881886, "13": 0.00023798432084731758, "14": 0.01606276072561741, "15": 0.23525108397006989, "16": 0.00020310995751060545, "17": 0.00019365073239896446, "18": 0.05478533357381821, "19": 0.00017715024296194315}}, {"key": "guo2018non", "year": "2018", "title": "Non-autoregressive Neural Machine Translation With Enhanced Decoder Input", "topic_distr": {"0": 0.0016405689530074596, "1": 0.0013399106683209538, "2": 0.0011327789397910237, "3": 0.0009811160853132606, "4": 0.0008653058321215212, "5": 0.0007739520515315235, "6": 0.0007000461919233203, "7": 0.15342599153518677, "8": 0.0005877885269001126, "9": 0.0005441585672087967, "10": 0.3861514925956726, "11": 0.0004738181596621871, "12": 0.0004450532724149525, "13": 0.06294436752796173, "14": 0.3171769976615906, "15": 0.00037648555007763207, "16": 0.05339963734149933, "17": 0.0003414182283449918, "18": 0.00032622527214698493, "19": 0.01637287810444832}}, {"key": "guo2018topic", "year": "2018", "title": "Topic-based Evaluation For Conversational Bots", "topic_distr": {"0": 0.03764296695590019, "1": 0.04515146464109421, "2": 0.1963738650083542, "3": 0.0008773163426667452, "4": 0.39574316143989563, "5": 0.0006920659216120839, "6": 0.25320398807525635, "7": 0.0005714140716008842, "8": 0.040455471724271774, "9": 0.0004865850496571511, "10": 0.0004529628495220095, "11": 0.00042368684080429375, "12": 0.0003979653993155807, "13": 0.0003751882177311927, "14": 0.00035487720742821693, "15": 0.0003366523305885494, "16": 0.0003202079387847334, "17": 0.000305295194266364, "18": 0.0002917097008321434, "19": 0.02554311230778694}}, {"key": "guo2019conditional", "year": "2019", "title": "Conditional Text Generation For Harmonious Human-machine Interaction", "topic_distr": {"0": 0.054020173847675323, "1": 0.0010949939023703337, "2": 0.000925712171010673, "3": 0.0008017943473532796, "4": 0.0007071532891131938, "5": 0.000632495095487684, "6": 0.0005720971385017037, "7": 0.31659209728240967, "8": 0.0004803570336662233, "9": 0.20521564781665802, "10": 0.0004139732918702066, "11": 0.00038721729652024806, "12": 0.34611883759498596, "13": 0.0003428932686802, "14": 0.00032433055457659066, "15": 0.07027671486139297, "16": 0.0002926454762928188, "17": 0.0002790164144244045, "18": 0.0002666003128979355, "19": 0.0002552421356085688}}, {"key": "guo2019fine", "year": "2019", "title": "Fine-tuning By Curriculum Learning For Non-autoregressive Neural Machine Translation", "topic_distr": {"0": 0.001619318500161171, "1": 0.0013224930735304952, "2": 0.3441842198371887, "3": 0.0009683846728876233, "4": 0.0008540767012163997, "5": 0.0007639082032255828, "6": 0.0006909614894539118, "7": 0.0870431661605835, "8": 0.0005801605875603855, "9": 0.0005370968137867749, "10": 0.10182793438434601, "11": 0.00046766921877861023, "12": 0.00043927764636464417, "13": 0.15844546258449554, "14": 0.2985635995864868, "15": 0.0003715997445397079, "16": 0.0003534482966642827, "17": 0.0003369874903000891, "18": 0.0003219917125534266, "19": 0.00030827365117147565}}, {"key": "guo2019reweighted", "year": "2019", "title": "Reweighted Proximal Pruning For Large-scale Language Representation", "topic_distr": {"0": 0.001487583271227777, "1": 0.0012127018999308348, "2": 0.34245815873146057, "3": 0.0008878220105543733, "4": 0.000783020630478859, "5": 0.029629167169332504, "6": 0.0006334764184430242, "7": 0.0005782576045021415, "8": 0.0005318936891853809, "9": 0.179062157869339, "10": 0.302520215511322, "11": 0.00042876112274825573, "12": 0.0004027316172141582, "13": 0.13747335970401764, "14": 0.00035912738530896604, "15": 0.000340684229740873, "16": 0.0003240428923163563, "17": 0.00030895156669430435, "18": 0.00029520338284783065, "19": 0.00028262659907341003}}, {"key": "guo2020cross", "year": "2020", "title": "Multireqa: A Cross-domain Evaluation For Retrieval Question Answering Models", "topic_distr": {"0": 0.0018911228980869055, "1": 0.07202247530221939, "2": 0.0013044142397120595, "3": 0.19314426183700562, "4": 0.000996411545202136, "5": 0.0008912159828469157, "6": 0.0008061124244704843, "7": 0.0007358453585766256, "8": 0.3455936312675476, "9": 0.0006266057607717812, "10": 0.04821289703249931, "11": 0.0005456078215502203, "12": 0.16748909652233124, "13": 0.00048315312596969306, "14": 0.06575016677379608, "15": 0.0004335280682425946, "16": 0.00041235159733332694, "17": 0.00039314755122177303, "18": 0.0003756526857614517, "19": 0.09789231419563293}}, {"key": "guo2020incorporating", "year": "2020", "title": "Incorporating BERT Into Parallel Sequence Decoding With Adapters", "topic_distr": {"0": 0.0011231738608330488, "1": 0.0009174598380923271, "2": 0.18923825025558472, "3": 0.0006717946962453425, "4": 0.0005924946744926274, "5": 0.0005299425683915615, "6": 0.00047933749738149345, "7": 0.15708675980567932, "8": 0.0004024720983579755, "9": 0.00037259768578223884, "10": 0.3776702582836151, "11": 0.0003244339895900339, "12": 0.0003047380596399307, "13": 0.08167783915996552, "14": 0.10860143601894379, "15": 0.0002577881678007543, "16": 0.07907826453447342, "17": 0.00023377678007818758, "18": 0.00022337381960824132, "19": 0.00021385724539868534}}, {"key": "guo2020sequence", "year": "2020", "title": "Sequence-level Mixed Sample Data Augmentation", "topic_distr": {"0": 0.001862074714154005, "1": 0.21648146212100983, "2": 0.46799466013908386, "3": 0.0011129436315968633, "4": 0.04824274405837059, "5": 0.0008779423078522086, "6": 0.0007941062794998288, "7": 0.0007248857291415334, "8": 0.0006667653215117753, "9": 0.0006172731518745422, "10": 0.0005746206152252853, "11": 0.131559357047081, "12": 0.0005048518069088459, "13": 0.00047595708747394383, "14": 0.12556539475917816, "15": 0.0004270711506251246, "16": 0.00040621007792651653, "17": 0.0003872920642606914, "18": 0.0003700577362906188, "19": 0.00035429190029390156}}, {"key": "guo2021efficient", "year": "2021", "title": "Longt5: Efficient Text-to-text Transformer For Long Sequences", "topic_distr": {"0": 0.002044501481577754, "1": 0.0016693465877324343, "2": 0.628693163394928, "3": 0.0012223983649164438, "4": 0.0010781065793707967, "5": 0.0009642868535593152, "6": 0.00087220553541556, "7": 0.03555438667535782, "8": 0.06449560821056366, "9": 0.0006779811228625476, "10": 0.14495956897735596, "11": 0.0005903422133997083, "12": 0.0005545032909139991, "13": 0.11399293690919876, "14": 0.0004944665706716478, "15": 0.0004690730129368603, "16": 0.0004461602948140353, "17": 0.0004253817314747721, "18": 0.00040645242552272975, "19": 0.00038913602475076914}}, {"key": "guo2022retrieval", "year": "2022", "title": "Retrieval Augmentation Of Large Language Models For Lay Language Generation", "topic_distr": {"0": 0.0012353351339697838, "1": 0.06703245639801025, "2": 0.0008525082375854254, "3": 0.0007383839110843837, "4": 0.000651222129818052, "5": 0.07413899153470993, "6": 0.30466902256011963, "7": 0.21000982820987701, "8": 0.000442364951595664, "9": 0.00040952939889393747, "10": 0.023722698912024498, "11": 0.0003565917431842536, "12": 0.00033494355739094317, "13": 0.15004727244377136, "14": 0.0002986788167618215, "15": 0.10845526307821274, "16": 0.05586738511919975, "17": 0.0002569486096035689, "18": 0.00024551452952437103, "19": 0.00023505468561779708}}, {"key": "guo2022texts", "year": "2022", "title": "Texts As Images In Prompt Tuning For Multi-label Image Recognition", "topic_distr": {"0": 0.0012988210655748844, "1": 0.0010612827027216554, "2": 0.06155509501695633, "3": 0.059279993176460266, "4": 0.0006851406069472432, "5": 0.000612807460129261, "6": 0.000554289435967803, "7": 0.0005059732357040048, "8": 0.00046540494076907635, "9": 0.0004308591887820512, "10": 0.0004010875418316573, "11": 0.00037516438169404864, "12": 0.00035238865530118346, "13": 0.00033222002093680203, "14": 0.00031423510517925024, "15": 0.00029809740954078734, "16": 0.00028353629750199616, "17": 0.5054157972335815, "18": 0.36553046107292175, "19": 0.0002472971973475069}}, {"key": "guo2022unified", "year": "2022", "title": "A Unified End-to-end Retriever-reader Framework For Knowledge-based VQA", "topic_distr": {"0": 0.12624220550060272, "1": 0.0588686540722847, "2": 0.16704438626766205, "3": 0.0006112351547926664, "4": 0.0005390834412537515, "5": 0.0004821703187189996, "6": 0.0004361270694062114, "7": 0.00039811080205254257, "8": 0.07092492282390594, "9": 0.00033900944981724024, "10": 0.0003155844460707158, "11": 0.00029518752126023173, "12": 0.0900849848985672, "13": 0.0002613979740999639, "14": 0.00024724705144762993, "15": 0.00023454955953639, "16": 0.31805419921875, "17": 0.0002127026964444667, "18": 0.1642136573791504, "19": 0.00019457883900031447}}, {"key": "guo2023how", "year": "2023", "title": "How Close Is Chatgpt To Human Experts? Comparison Corpus, Evaluation, And Detection", "topic_distr": {"0": 0.23749952018260956, "1": 0.13513165712356567, "2": 0.000610625371336937, "3": 0.12052762508392334, "4": 0.00046644307440146804, "5": 0.00041719869477674365, "6": 0.03350488469004631, "7": 0.0003444660978857428, "8": 0.024516919627785683, "9": 0.2275272011756897, "10": 0.0002730600244831294, "11": 0.00025541154900565743, "12": 0.10734488815069199, "13": 0.00022617506328970194, "14": 0.00021393095084931701, "15": 0.11041870713233948, "16": 0.00019303124281577766, "17": 0.00018404138972982764, "18": 0.00017585164459887892, "19": 0.00016835969290696084}}, {"key": "guo2023what", "year": "2023", "title": "What Can Large Language Models Do In Chemistry? A Comprehensive Benchmark On Eight Tasks", "topic_distr": {"0": 0.0011051940964534879, "1": 0.0009012477239593863, "2": 0.0007619012612849474, "3": 0.6947021484375, "4": 0.0005820132791996002, "5": 0.0005205679917708039, "6": 0.000470858154585585, "7": 0.0004298144776839763, "8": 0.00039535248652100563, "9": 0.0782662108540535, "10": 0.0003407160984352231, "11": 0.0003186948597431183, "12": 0.21950294077396393, "13": 0.00028221445973031223, "14": 0.0002669366367626935, "15": 0.0002532279759179801, "16": 0.00024085860059130937, "17": 0.00022964134404901415, "18": 0.0002194224070990458, "19": 0.0002100741839967668}}, {"key": "guo2024deepseek", "year": "2024", "title": "Deepseek-coder: When The Large Language Model Meets Programming -- The Rise Of Code Intelligence", "topic_distr": {"0": 0.0022672179620712996, "1": 0.0018522980390116572, "2": 0.0015653854934498668, "3": 0.32254156470298767, "4": 0.0011957947863265872, "5": 0.0010695498203858733, "6": 0.2927234470844269, "7": 0.0008830892620608211, "8": 0.000812284299172461, "9": 0.11250107735395432, "10": 0.0007000293117016554, "11": 0.0006547848461195827, "12": 0.19385650753974915, "13": 0.06445909291505814, "14": 0.000548443291336298, "15": 0.0005202777683734894, "16": 0.0004948638379573822, "17": 0.00047181706759147346, "18": 0.0004508214187808335, "19": 0.000431614724220708}}, {"key": "gupta2019casa", "year": "2019", "title": "CASA-NLU: Context-aware Self-attentive Natural Language Understanding For Task-oriented Chatbots", "topic_distr": {"0": 0.0015412599314004183, "1": 0.0012573188869282603, "2": 0.24450626969337463, "3": 0.0009206262766383588, "4": 0.09851430356502533, "5": 0.0007262284052558243, "6": 0.36374416947364807, "7": 0.0005996208055876195, "8": 0.0005515440134331584, "9": 0.019477929919958115, "10": 0.2649236023426056, "11": 0.0004446013190317899, "12": 0.00041761016473174095, "13": 0.0003937086439691484, "14": 0.00037239500670693815, "15": 0.0003532705013640225, "16": 0.00033601437462493777, "17": 0.00032036550692282617, "18": 0.00030610940302722156, "19": 0.0002930679765995592}}, {"key": "gupta2020bert", "year": "2020", "title": "BERT Based Multilingual Machine Comprehension In English And Hindi", "topic_distr": {"0": 0.0015991702675819397, "1": 0.0013055355520918965, "2": 0.3379327952861786, "3": 0.0009559686877764761, "4": 0.0008431268506683409, "5": 0.0007541138329543173, "6": 0.1408085972070694, "7": 0.0006226449040696025, "8": 0.12111470103263855, "9": 0.0005302104400470853, "10": 0.09699778258800507, "11": 0.0004616730147972703, "12": 0.07397066801786423, "13": 0.00040882619214244187, "14": 0.22002358734607697, "15": 0.0003668353019747883, "16": 0.00034891656832769513, "17": 0.0003326668229419738, "18": 0.0003178633050993085, "19": 0.00030432111816480756}}, {"key": "gupta2020global", "year": "2020", "title": "GMAT: Global Memory Augmentation For Transformers", "topic_distr": {"0": 0.001272579189389944, "1": 0.04185571148991585, "2": 0.2257409542798996, "3": 0.0007609044550918043, "4": 0.0006710870075039566, "5": 0.0006002376321703196, "6": 0.0005429199663922191, "7": 0.0004955948679707944, "8": 0.0004558586806524545, "9": 0.00042202151962555945, "10": 0.3745436668395996, "11": 0.0003674690960906446, "12": 0.0003451605443842709, "13": 0.18929937481880188, "14": 0.00030778959626331925, "15": 0.00029198292759247124, "16": 0.16126668453216553, "17": 0.00026478650397621095, "18": 0.0002530036144889891, "19": 0.000242224705289118}}, {"key": "gupta2022visual", "year": "2022", "title": "Visual Programming: Compositional Visual Reasoning Without Training", "topic_distr": {"0": 0.0014340276829898357, "1": 0.0011708082165569067, "2": 0.000989639200270176, "3": 0.37746506929397583, "4": 0.0007559809600934386, "5": 0.0006761684198863804, "6": 0.0006115998839959502, "7": 0.05759107694029808, "8": 0.028276562690734863, "9": 0.08199647814035416, "10": 0.0004425577644724399, "11": 0.23960958421230316, "12": 0.00038882368244230747, "13": 0.0003665697295218706, "14": 0.0003467252536211163, "15": 0.00032891903538256884, "16": 0.02829233929514885, "17": 0.0002982822188641876, "18": 0.17868590354919434, "19": 0.0002728663384914398}}, {"key": "gurnee2023language", "year": "2023", "title": "Language Models Represent Space And Time", "topic_distr": {"0": 0.2662185728549957, "1": 0.0012891959631815553, "2": 0.0010898516047745943, "3": 0.30817699432373047, "4": 0.0008325256058014929, "5": 0.0007446316885761917, "6": 0.0006735255592502654, "7": 0.0006148157990537584, "8": 0.0005655206623487175, "9": 0.0005235435673967004, "10": 0.00048736759345047176, "11": 0.0004558679647743702, "12": 0.0004281928122509271, "13": 0.00040368561167269945, "14": 0.00038183186552487314, "15": 0.015500571578741074, "16": 0.0945465937256813, "17": 0.00032848387490957975, "18": 0.30643776059150696, "19": 0.0003004946047440171}}, {"key": "guti\u00e9rrez2022thinking", "year": "2022", "title": "Thinking About GPT-3 In-context Learning For Biomedical IE? Think Again", "topic_distr": {"0": 0.0011449274607002735, "1": 0.06248950585722923, "2": 0.2035304754972458, "3": 0.0006841314025223255, "4": 0.0006033741519786417, "5": 0.000539673725143075, "6": 0.0004881395143456757, "7": 0.0004455894522834569, "8": 0.0004098626668564975, "9": 0.00037943964707665145, "10": 0.00035322102485224605, "11": 0.030266618356108665, "12": 0.16576024889945984, "13": 0.1593879610300064, "14": 0.0002767337136901915, "15": 0.16230890154838562, "16": 0.000249698554398492, "17": 0.21023626625537872, "18": 0.00022747561160940677, "19": 0.00021778429800178856}}, {"key": "guti\u00e9rrezfandi\u00f1o2021spanish", "year": "2021", "title": "Maria: Spanish Language Models", "topic_distr": {"0": 0.07821713387966156, "1": 0.0020790870767086744, "2": 0.05995112285017967, "3": 0.001521932310424745, "4": 0.001342281699180603, "5": 0.0012005718890577555, "6": 0.001085927477106452, "7": 0.0009912694804370403, "8": 0.0960896760225296, "9": 0.0008441110257990658, "10": 0.1279483437538147, "11": 0.0007349973893724382, "12": 0.32222968339920044, "13": 0.07181770354509354, "14": 0.0006156287854537368, "15": 0.1339137703180313, "16": 0.0005554857198148966, "17": 0.0005296156159602106, "18": 0.0005060479743406177, "19": 0.09782558679580688}}, {"key": "guu2017from", "year": "2017", "title": "From Language To Programs: Bridging Reinforcement Learning And Maximum Marginal Likelihood", "topic_distr": {"0": 0.0015401897253468633, "1": 0.0012573723215609789, "2": 0.08455203473567963, "3": 0.42503494024276733, "4": 0.0008120013517327607, "5": 0.0007262752042151988, "6": 0.023093732073903084, "7": 0.09814124554395676, "8": 0.0005515796365216374, "9": 0.00051063735736534, "10": 0.0004753531829919666, "11": 0.31699568033218384, "12": 0.0004176371730864048, "13": 0.043909937143325806, "14": 0.00037241907557472587, "15": 0.00035329331876710057, "16": 0.0003360360860824585, "17": 0.0003203861997462809, "18": 0.0003061291645281017, "19": 0.0002930869231931865}}, {"key": "guu2020retrieval", "year": "2020", "title": "REALM: Retrieval-augmented Language Model Pre-training", "topic_distr": {"0": 0.0015208023833110929, "1": 0.001242040074430406, "2": 0.33439475297927856, "3": 0.0009093649568967521, "4": 0.0008020217646844685, "5": 0.028345739468932152, "6": 0.0006488481885753572, "7": 0.0005922894924879074, "8": 0.2299075573682785, "9": 0.0005043614073656499, "10": 0.12219590693712234, "11": 0.00043916533468291163, "12": 0.00041250421782024205, "13": 0.01602761074900627, "14": 0.0003678418870549649, "15": 0.00034895120188593864, "16": 0.2604319751262665, "17": 0.00031644850969314575, "18": 0.0003023667086381465, "19": 0.0002894847420975566}}, {"key": "g\u00f3mezrodr\u00edguez2023confederacy", "year": "2023", "title": "A Confederacy Of Models: A Comprehensive Evaluation Of Llms On Creative Writing", "topic_distr": {"0": 0.08255890011787415, "1": 0.14685675501823425, "2": 0.0012661529472097754, "3": 0.37594684958457947, "4": 0.0009671999141573906, "5": 0.0008650885429233313, "6": 0.0007824799395166337, "7": 0.13758860528469086, "8": 0.0006570033146999776, "9": 0.16149383783340454, "10": 0.0005662076873704791, "11": 0.0005296124145388603, "12": 0.08709222823381424, "13": 0.00046898869914002717, "14": 0.00044359973981045187, "15": 0.00042081845458596945, "16": 0.00040026282658800483, "17": 0.00038162179407663643, "18": 0.0003646397963166237, "19": 0.00034910475369542837}}, {"key": "ha2024understanding", "year": "2024", "title": "Clochat: Understanding How People Customize, Interact, And Experience Personas In Large Language Models", "topic_distr": {"0": 0.17878584563732147, "1": 0.001095377840101719, "2": 0.0009259425569325686, "3": 0.0008019532542675734, "4": 0.12664775550365448, "5": 0.03567224740982056, "6": 0.0005722065689042211, "7": 0.0005223284824751318, "8": 0.00048044888535514474, "9": 0.4171920418739319, "10": 0.0004140524542890489, "11": 0.1512964814901352, "12": 0.00036377939977683127, "13": 0.000342958839610219, "14": 0.00032439257483929396, "15": 0.023961463943123817, "16": 0.059799674898386, "17": 0.0002790697617456317, "18": 0.00026665127370506525, "19": 0.00025529094273224473}}, {"key": "haase2023artificial", "year": "2023", "title": "Artificial Muses: Generative Artificial Intelligence Chatbots Have Risen To Human-level Creativity", "topic_distr": {"0": 0.43415069580078125, "1": 0.0015198317123576999, "2": 0.0012849000049754977, "3": 0.0011129132471978664, "4": 0.0009815485682338476, "5": 0.0008779231575317681, "6": 0.0007940889918245375, "7": 0.0007248699548654258, "8": 0.0006667508278042078, "9": 0.553398609161377, "10": 0.0005746081005781889, "11": 0.0005374699248932302, "12": 0.0005048408056609333, "13": 0.0004759467556141317, "14": 0.0004501811054069549, "15": 0.0004270618373993784, "16": 0.0004062012303620577, "17": 0.0003872836532536894, "18": 0.0003700497036334127, "19": 0.00035428418777883053}}, {"key": "hacker2023regulating", "year": "2023", "title": "Regulating Chatgpt And Other Large Generative AI Models", "topic_distr": {"0": 0.1845102161169052, "1": 0.0008489470346830785, "2": 0.1129511222243309, "3": 0.0982290655374527, "4": 0.0005481093539856374, "5": 0.0004902430227957666, "6": 0.00044342895853333175, "7": 0.04602592810988426, "8": 0.00037232175236567855, "9": 0.4824032485485077, "10": 0.0003208681591786444, "11": 0.017509207129478455, "12": 0.053744107484817505, "13": 0.0002657744335010648, "14": 0.000251386605668813, "15": 0.00023847652482800186, "16": 0.00022682770213577896, "17": 0.00021626388479489833, "18": 0.00020664025214500725, "19": 0.0001978365908144042}}, {"key": "hackl2023is", "year": "2023", "title": "Is GPT-4 A Reliable Rater? Evaluating Consistency In GPT-4 Text Ratings", "topic_distr": {"0": 0.37068915367126465, "1": 0.06963597238063812, "2": 0.0009358485694974661, "3": 0.0008105578599497676, "4": 0.20978741347789764, "5": 0.0006394019001163542, "6": 0.0005783444503322244, "7": 0.13360287249088287, "8": 0.0004856025625485927, "9": 0.15745161473751068, "10": 0.00041849393164739013, "11": 0.000391445733839646, "12": 0.0003676815831568092, "13": 0.00034663768019527197, "14": 0.0003278722579125315, "15": 0.0003110342368017882, "16": 0.00029584119329228997, "17": 0.05239669978618622, "18": 0.00026951159816235304, "19": 0.0002580293803475797}}, {"key": "hagendorff2022thinking", "year": "2022", "title": "Thinking Fast And Slow In Large Language Models", "topic_distr": {"0": 0.5952803492546082, "1": 0.0016427957452833652, "2": 0.001388867269270122, "3": 0.24451659619808197, "4": 0.0010608603479340672, "5": 0.0009488597279414535, "6": 0.0008582515874877572, "7": 0.000783439667429775, "8": 0.0007206245209090412, "9": 0.14794881641864777, "10": 0.0006210366263985634, "11": 0.0005808976711705327, "12": 0.0005456321523524821, "13": 0.0005144033930264413, "14": 0.00048655588761903346, "15": 0.00046156859025359154, "16": 0.00043902243487536907, "17": 0.0004185762663837522, "18": 0.0003999498439952731, "19": 0.0003829104534815997}}, {"key": "hagendorff2023deception", "year": "2023", "title": "Deception Abilities Emerged In Large Language Models", "topic_distr": {"0": 0.27816587686538696, "1": 0.027081305161118507, "2": 0.0011793385492637753, "3": 0.371371328830719, "4": 0.0009009041823446751, "5": 0.0008057919330894947, "6": 0.0007288454798981547, "7": 0.0006653136806562543, "8": 0.0006119696772657335, "9": 0.25059211254119873, "10": 0.0005273974966257811, "11": 0.06427137553691864, "12": 0.0004633624048437923, "13": 0.0004368422960396856, "14": 0.0004131936002522707, "15": 0.00039197385194711387, "16": 0.0003728271694853902, "17": 0.00035546388244256377, "18": 0.0003396458923816681, "19": 0.00032517570070922375}}, {"key": "hagendorff2024mapping", "year": "2024", "title": "Mapping The Ethics Of Generative AI: A Comprehensive Scoping Review", "topic_distr": {"0": 0.1493838131427765, "1": 0.0422346256673336, "2": 0.0011481201509013772, "3": 0.0009944243356585503, "4": 0.0008770376443862915, "5": 0.0007844455540180206, "6": 0.0007095374749042094, "7": 0.0006476885755546391, "8": 0.0005957577377557755, "9": 0.7147519588470459, "10": 0.0005134260281920433, "11": 0.00048024216084741056, "12": 0.08431363105773926, "13": 0.00042526976903900504, "14": 0.0004022475332021713, "15": 0.0003815899253822863, "16": 0.00036295049358159304, "17": 0.00034604716347530484, "18": 0.0003306482103653252, "19": 0.0003165613452438265}}, {"key": "hagos2024recent", "year": "2024", "title": "Recent Advances In Generative AI And Large Language Models: Current Status, Challenges, And Perspectives", "topic_distr": {"0": 0.0014517224626615644, "1": 0.0011844669934362173, "2": 0.0010011628037318587, "3": 0.05153133347630501, "4": 0.0007647971506230533, "5": 0.0006840542191639543, "6": 0.0006187326507642865, "7": 0.0005647991201840341, "8": 0.0005195142002776265, "9": 0.6254549622535706, "10": 0.00044771909597329795, "11": 0.00041878203046508133, "12": 0.2750948667526245, "13": 0.03839690983295441, "14": 0.0003507689689286053, "15": 0.0003327550657559186, "16": 0.00031650104210712016, "17": 0.00030176094151102006, "18": 0.0002883327251765877, "19": 0.0002760486677289009}}, {"key": "hambardzumyan2021word", "year": "2021", "title": "WARP: Word-level Adversarial Reprogramming", "topic_distr": {"0": 0.0018890800420194864, "1": 0.138201043009758, "2": 0.12429021298885345, "3": 0.0011298584286123514, "4": 0.0009964870987460017, "5": 0.0008912839693948627, "6": 0.000806173833552748, "7": 0.0744234025478363, "8": 0.0006768977618776262, "9": 0.0006266534910537302, "10": 0.1135057583451271, "11": 0.08642029017210007, "12": 0.0005125237512402236, "13": 0.00048318994231522083, "14": 0.09360598027706146, "15": 0.000433561101090163, "16": 0.00041238300036638975, "17": 0.3599598705768585, "18": 0.0003756812948267907, "19": 0.0003596758469939232}}, {"key": "han2020effective", "year": "2020", "title": "ECONET: Effective Continual Pretraining Of Language Models For Event Temporal Reasoning", "topic_distr": {"0": 0.0018335815984755754, "1": 0.0014976032543927431, "2": 0.001266156672500074, "3": 0.0010966133559122682, "4": 0.0009671602747403085, "5": 0.0008650540839880705, "6": 0.0007824485073797405, "7": 0.0007142442045733333, "8": 0.02556525357067585, "9": 0.0006082113832235336, "10": 0.0005661849863827229, "11": 0.0005295912269502878, "12": 0.0004974404582753778, "13": 0.0004689698980655521, "14": 0.0004435819573700428, "15": 0.000420801603468135, "16": 0.15238073468208313, "17": 0.3988873362541199, "18": 0.37682077288627625, "19": 0.03378831595182419}}, {"key": "han2021prompt", "year": "2021", "title": "PTR: Prompt Tuning With Rules For Text Classification", "topic_distr": {"0": 0.001358803827315569, "1": 0.0011071237968280911, "2": 0.0009358091047033668, "3": 0.0008105285814963281, "4": 0.0007148528820835054, "5": 0.0006393830990418792, "6": 0.0005783273954875767, "7": 0.0005279158358462155, "8": 0.0004855882143601775, "9": 0.00044954431359656155, "10": 0.000418481562519446, "11": 0.00039143417961895466, "12": 0.00036767072742804885, "13": 0.0003466274356469512, "14": 0.0003278625663369894, "15": 0.05980006232857704, "16": 0.05353198200464249, "17": 0.8766804933547974, "18": 0.00026950365281663835, "19": 0.00025802175514400005}}, {"key": "han2023effective", "year": "2023", "title": "E^2VPT: An Effective And Efficient Approach For Visual Prompt Tuning", "topic_distr": {"0": 0.001486539957113564, "1": 0.001212306204251945, "2": 0.1257046014070511, "3": 0.0008877203217707574, "4": 0.0007829308160580695, "5": 0.0007002732600085437, "6": 0.0006334030767902732, "7": 0.0005781907238997519, "8": 0.0005318321054801345, "9": 0.0004923556698486209, "10": 0.04082314670085907, "11": 0.000428711500717327, "12": 0.00040268502198159695, "13": 0.3021925091743469, "14": 0.0003590858250390738, "15": 0.0003406447940506041, "16": 0.03977816551923752, "17": 0.39569181203842163, "18": 0.08669047802686691, "19": 0.00028259388636797667}}, {"key": "han2023imagebind", "year": "2023", "title": "Imagebind-llm: Multi-modality Instruction Tuning", "topic_distr": {"0": 0.001466543646529317, "1": 0.0011985490564256907, "2": 0.048887256532907486, "3": 0.18471135199069977, "4": 0.0007737517007626593, "5": 0.000692063826136291, "6": 0.000625977641902864, "7": 0.027933118864893913, "8": 0.0005255973665043712, "9": 0.0004865837108809501, "10": 0.22482933104038239, "11": 0.0004236856766510755, "12": 0.00039796429337002337, "13": 0.00037518716999329627, "14": 0.0003548762178979814, "15": 0.0003366513701621443, "16": 0.00032020703656598926, "17": 0.037988919764757156, "18": 0.4673931300640106, "19": 0.00027928099734708667}}, {"key": "han2023medalpaca", "year": "2023", "title": "Medalpaca -- An Open-source Collection Of Medical Conversational AI Models And Training Data", "topic_distr": {"0": 0.09944156557321548, "1": 0.06902198493480682, "2": 0.0013886169763281941, "3": 0.17043623328208923, "4": 0.0010607611620798707, "5": 0.0009487727656960487, "6": 0.0008581730653531849, "7": 0.0007833679555915296, "8": 0.0007205585134215653, "9": 0.4154946804046631, "10": 0.0006209797575138509, "11": 0.0005808444693684578, "12": 0.2355407476425171, "13": 0.0005143563030287623, "14": 0.0004865113296546042, "15": 0.0004615263023879379, "16": 0.00043898221338167787, "17": 0.0004185379366390407, "18": 0.0003999132022727281, "19": 0.0003828753833658993}}, {"key": "han2023one", "year": "2023", "title": "Onellm: One Framework To Align All Modalities With Language", "topic_distr": {"0": 0.0013129618018865585, "1": 0.001072158687748015, "2": 0.0009062937460839748, "3": 0.14509908854961395, "4": 0.03960695490241051, "5": 0.000619215948972851, "6": 0.0005600859876722097, "7": 0.0005112644867040217, "8": 0.00047027194523252547, "9": 0.0004353649273980409, "10": 0.0004052819567732513, "11": 0.0003790876653511077, "12": 0.0003560737823136151, "13": 0.0003356942324899137, "14": 0.0003175212477799505, "15": 0.000301214779028669, "16": 0.0002865013957489282, "17": 0.00027315845363773406, "18": 0.8065019249916077, "19": 0.0002498833346180618}}, {"key": "hancock2019learning", "year": "2019", "title": "Learning From Dialogue After Deployment: Feed Yourself, Chatbot!", "topic_distr": {"0": 0.0017825989052653313, "1": 0.06969744712114334, "2": 0.2334820181131363, "3": 0.0010653045028448105, "4": 0.05864910036325455, "5": 0.13510064780712128, "6": 0.14701886475086212, "7": 0.0006938563892617822, "8": 0.0006382238352671266, "9": 0.11978106200695038, "10": 0.0005500234547071159, "11": 0.22830945253372192, "12": 0.00048324119416065514, "13": 0.00045558332931250334, "14": 0.0004309200739953667, "15": 0.0004087899869773537, "16": 0.0003888219071086496, "17": 0.00037071367842145264, "18": 0.00035421710344962776, "19": 0.0003391261270735413}}, {"key": "hao2019modeling", "year": "2019", "title": "Modeling Recurrence For Transformer", "topic_distr": {"0": 0.0018897473346441984, "1": 0.0015430441126227379, "2": 0.5204405784606934, "3": 0.0011298144236207008, "4": 0.0009964469354599714, "5": 0.0008912482298910618, "6": 0.02875586971640587, "7": 0.000735871959477663, "8": 0.0006768706953153014, "9": 0.0006266284035518765, "10": 0.21360592544078827, "11": 0.0005456275539472699, "12": 0.0005125032621435821, "13": 0.00048317061737179756, "14": 0.14487433433532715, "15": 0.0004335437552072108, "16": 0.00041236652759835124, "17": 0.00039316178299486637, "18": 0.08069350570440292, "19": 0.00035966146970167756}}, {"key": "hao2019multi", "year": "2019", "title": "Multi-granularity Self-attention For Neural Machine Translation", "topic_distr": {"0": 0.001417524996213615, "1": 0.0011575508397072554, "2": 0.4743330776691437, "3": 0.0008475201902911067, "4": 0.0007474781014025211, "5": 0.0006685637054033577, "6": 0.0177031010389328, "7": 0.0005520092090591788, "8": 0.0005077498499304056, "9": 0.00047006094246171415, "10": 0.10685613006353378, "11": 0.0004092987219337374, "12": 0.00038445074460469186, "13": 0.00036244705552235246, "14": 0.2022133320569992, "15": 0.00032521982211619616, "16": 0.19019798934459686, "17": 0.0002949275658465922, "18": 0.0002818034263327718, "19": 0.00026979754329659045}}, {"key": "hao2019visualizing", "year": "2019", "title": "Visualizing And Understanding The Effectiveness Of BERT", "topic_distr": {"0": 0.00162186985835433, "1": 0.0013228349853307009, "2": 0.373266339302063, "3": 0.1584259271621704, "4": 0.00085417804075405, "5": 0.0007639986579306424, "6": 0.0006910432712174952, "7": 0.0006308065494522452, "8": 0.0005802292726002634, "9": 0.0005371604347601533, "10": 0.35038894414901733, "11": 0.02339046262204647, "12": 0.0004393296840135008, "13": 0.08500262349843979, "14": 0.0003917629364877939, "15": 0.00037164377863518894, "16": 0.00035349014797247946, "17": 0.00033702742075547576, "18": 0.00032202983857132494, "19": 0.0003083101473748684}}, {"key": "hao2020towards", "year": "2020", "title": "Towards Learning A Generic Agent For Vision-and-language Navigation Via Pre-training", "topic_distr": {"0": 0.0014008111320436, "1": 0.001144485897384584, "2": 0.3346861004829407, "3": 0.0008378096390515566, "4": 0.0007389132515527308, "5": 0.000660903169773519, "6": 0.0005977924447506666, "7": 0.0005456841900013387, "8": 0.0005019319360144436, "9": 0.0004646748711820692, "10": 0.0004325666232034564, "11": 0.43047893047332764, "12": 0.0003800456179305911, "13": 0.0003582940553314984, "14": 0.00033889763290062547, "15": 0.00032149336766451597, "16": 0.00030578943551518023, "17": 0.00029154823278076947, "18": 0.2252466231584549, "19": 0.0002667061344254762}}, {"key": "hao2022language", "year": "2022", "title": "Language Models Are General-purpose Interfaces", "topic_distr": {"0": 0.0012863080482929945, "1": 0.0010498632909730077, "2": 0.23805688321590424, "3": 0.0007687698816880584, "4": 0.0006780220428481698, "5": 0.0006064408225938678, "6": 0.0005485306028276682, "7": 0.0005007163854315877, "8": 0.0004605695721693337, "9": 0.0364055372774601, "10": 0.15248870849609375, "11": 0.09567694365978241, "12": 0.09991995990276337, "13": 0.0003287683648522943, "14": 0.0003109703247901052, "15": 0.00029500029631890357, "16": 0.0002805904659908265, "17": 0.0002675228170119226, "18": 0.2376026064157486, "19": 0.13246724009513855}}, {"key": "hao2022new", "year": "2022", "title": "Mixgen: A New Multi-modal Data Augmentation", "topic_distr": {"0": 0.0017316947923973203, "1": 0.19123542308807373, "2": 0.15459120273590088, "3": 0.0010356165003031492, "4": 0.0009133720304816961, "5": 0.0008169435313902795, "6": 0.0007389323436655104, "7": 0.0006745212594978511, "8": 0.027389120310544968, "9": 0.0005743854562751949, "10": 0.0005346963880583644, "11": 0.0005001378012821078, "12": 0.0004697750846389681, "13": 0.07606616616249084, "14": 0.00041891197906807065, "15": 0.0003973985731136054, "16": 0.00037798690027557313, "17": 0.00036038330290466547, "18": 0.5408437252044678, "19": 0.00032967596780508757}}, {"key": "hao2022optimizing", "year": "2022", "title": "Optimizing Prompts For Text-to-image Generation", "topic_distr": {"0": 0.0014681988395750523, "1": 0.0011983462609350681, "2": 0.0010130821028724313, "3": 0.0008774324087426066, "4": 0.18339355289936066, "5": 0.02095099911093712, "6": 0.0006260632653720677, "7": 0.11566635966300964, "8": 0.0005256693111732602, "9": 0.0004866503004450351, "10": 0.00045302356011234224, "11": 0.04951068013906479, "12": 0.0003980187466368079, "13": 0.022758670151233673, "14": 0.00035492476308718324, "15": 0.02938794530928135, "16": 0.00032025083783082664, "17": 0.4990602433681488, "18": 0.07127056270837784, "19": 0.00027931921067647636}}, {"key": "hao2023augmenting", "year": "2023", "title": "Toolkengpt: Augmenting Frozen Language Models With Massive Tools Via Tool Embeddings", "topic_distr": {"0": 0.0009816361125558615, "1": 0.0008020896930247545, "2": 0.13010017573833466, "3": 0.4849568009376526, "4": 0.0005178520223125815, "5": 0.0004631802730727941, "6": 0.00041895045433193445, "7": 0.022309282794594765, "8": 0.0231441929936409, "9": 0.10761719942092896, "10": 0.04482272267341614, "11": 0.11456391960382462, "12": 0.00026634708046913147, "13": 0.00025110295973718166, "14": 0.00023750937543809414, "15": 0.00022531197464559227, "16": 0.04433384910225868, "17": 0.023605741560459137, "18": 0.00019523313676472753, "19": 0.00018691546574700624}}, {"key": "hao2023reasoning", "year": "2023", "title": "Reasoning With Language Model Is Planning With World Model", "topic_distr": {"0": 0.01422696840018034, "1": 0.0007380501483567059, "2": 0.0006240060902200639, "3": 0.5795152187347412, "4": 0.00047665587044321, "5": 0.00042633371776901186, "6": 0.04754789546132088, "7": 0.000352008588379249, "8": 0.0003237850032746792, "9": 0.0002997513220179826, "10": 0.00027903899899683893, "11": 0.3535509705543518, "12": 0.00024515888071618974, "13": 0.0002311274438397959, "14": 0.00021861522691324353, "15": 0.00020738814782816917, "16": 0.0001972578902496025, "17": 0.0001880712079582736, "18": 0.00017970212502405047, "19": 0.00017204612959176302}}, {"key": "haque2024exploring", "year": "2024", "title": "Exploring Chatgpt And Its Impact On Society", "topic_distr": {"0": 0.11266376823186874, "1": 0.0008559165871702135, "2": 0.06425250321626663, "3": 0.0006266903365030885, "4": 0.0005527132889255881, "5": 0.0004943614476360381, "6": 0.0004471541033126414, "7": 0.039114609360694885, "8": 0.0003754495410248637, "9": 0.6798328161239624, "10": 0.04157862439751625, "11": 0.00030265102395787835, "12": 0.0002842774847522378, "13": 0.046523284167051315, "14": 0.011000039055943489, "15": 0.00024047990154940635, "16": 0.0002287332172272727, "17": 0.00021808066230732948, "18": 0.0002083761792164296, "19": 0.00019949856505263597}}, {"key": "hariri2023unlocking", "year": "2023", "title": "Unlocking The Potential Of Chatgpt: A Comprehensive Exploration Of Its Applications, Advantages, Limitations, And Future Directions In Natural Language Processing", "topic_distr": {"0": 0.09875068068504333, "1": 0.001039331778883934, "2": 0.000878536666277796, "3": 0.09848833084106445, "4": 0.01989774778485298, "5": 0.0006002587033435702, "6": 0.04488787427544594, "7": 0.0004956121556460857, "8": 0.0004558746295515448, "9": 0.437043696641922, "10": 0.03958148509263992, "11": 0.0003674819599837065, "12": 0.20601077377796173, "13": 0.00032541697146371007, "14": 0.013418849557638168, "15": 0.00029199314303696156, "16": 0.0002777301997411996, "17": 0.03669310361146927, "18": 0.00025301246205344796, "19": 0.0002422331745037809}}, {"key": "harkous2020have", "year": "2020", "title": "Have Your Text And Use It Too! End-to-end Neural Data-to-text Generation With Semantic Fidelity", "topic_distr": {"0": 0.16613167524337769, "1": 0.0013059497578069568, "2": 0.39002522826194763, "3": 0.0009560000617057085, "4": 0.0008431520545855165, "5": 0.0007541363011114299, "6": 0.0006821224233135581, "7": 0.2272181510925293, "8": 0.0005727389361709356, "9": 0.035109296441078186, "10": 0.0004935883334837854, "11": 0.0004616866062860936, "12": 0.00043365824967622757, "13": 0.0004088382120244205, "14": 0.00038670553476549685, "15": 0.06549723446369171, "16": 0.10776495933532715, "17": 0.0003326766309328377, "18": 0.00031787267653271556, "19": 0.00030433008214458823}}, {"key": "harte2023leveraging", "year": "2023", "title": "Leveraging Large Language Models For Sequential Recommendation", "topic_distr": {"0": 0.0015800439286977053, "1": 0.001289371750317514, "2": 0.13614557683467865, "3": 0.4023582339286804, "4": 0.25529444217681885, "5": 0.000744611257687211, "6": 0.0006735071656294167, "7": 0.0006147989770397544, "8": 0.0005655051791109145, "9": 0.08548378199338913, "10": 0.11193102598190308, "11": 0.00045585547923110425, "12": 0.0004281811125110835, "13": 0.00040367458132095635, "14": 0.0003818214463535696, "15": 0.00036221282789483666, "16": 0.00034451988176442683, "17": 0.0003284749109297991, "18": 0.00031385791953653097, "19": 0.0003004863974638283}}, {"key": "hartmann2023political", "year": "2023", "title": "The Political Ideology Of Conversational AI: Converging Evidence On Chatgpt's Pro-environmental, Left-libertarian Orientation", "topic_distr": {"0": 0.25277596712112427, "1": 0.0012128412490710616, "2": 0.10620978474617004, "3": 0.0008877763757482171, "4": 0.0007829821552149951, "5": 0.0007003200589679182, "6": 0.06392116844654083, "7": 0.000578228966332972, "8": 0.0005318672629073262, "9": 0.48626747727394104, "10": 0.00045836501521989703, "11": 0.0004287398769520223, "12": 0.00040271165198646486, "13": 0.0003796628152485937, "14": 0.0003591095737647265, "15": 0.0003406673204153776, "16": 0.0003240268270019442, "17": 0.08286052197217941, "18": 0.00029518871451728046, "19": 0.0002826125710271299}}, {"key": "hartsock2024vision", "year": "2024", "title": "Vision-language Models For Medical Report Generation And Visual Question Answering: A Review", "topic_distr": {"0": 0.001154043828137219, "1": 0.0009430124773643911, "2": 0.0007971235900186002, "3": 0.0006904301117174327, "4": 0.0006089318776503205, "5": 0.0005446446593850851, "6": 0.0004926357069052756, "7": 0.0004496937326621264, "8": 0.03262289986014366, "9": 0.058765050023794174, "10": 0.00035647451295517385, "11": 0.0003334347566124052, "12": 0.5828078389167786, "13": 0.0246984101831913, "14": 0.0002792826562654227, "15": 0.03131744638085365, "16": 0.0002519985137041658, "17": 0.00024026243772823364, "18": 0.26242655515670776, "19": 0.00021979027951601893}}, {"key": "hartvigsen2022large", "year": "2022", "title": "Toxigen: A Large-scale Machine-generated Dataset For Adversarial And Implicit Hate Speech Detection", "topic_distr": {"0": 0.11175395548343658, "1": 0.36628052592277527, "2": 0.08538538217544556, "3": 0.0007609383319504559, "4": 0.0006711159367114305, "5": 0.0006002630107104778, "6": 0.0005429426091723144, "7": 0.10632704198360443, "8": 0.0004558776563499123, "9": 0.00042203906923532486, "10": 0.0003928768855985254, "11": 0.0003674843756016344, "12": 0.0003451748925726861, "13": 0.00032541912514716387, "14": 0.07135225087404251, "15": 0.12125689536333084, "16": 0.0002777320332825184, "17": 0.09004990756511688, "18": 0.00025301415007561445, "19": 0.042179107666015625}}, {"key": "hasan2023zero", "year": "2023", "title": "Zero- And Few-shot Prompting With Llms: A Comparative Study With Fine-tuned Models For Bangla Sentiment Analysis", "topic_distr": {"0": 0.0015220933128148317, "1": 0.13789579272270203, "2": 0.0010499432682991028, "3": 0.34496769309043884, "4": 0.000802049704361707, "5": 0.0007173744379542768, "6": 0.020009508356451988, "7": 0.0005923105636611581, "8": 0.0005448198644444346, "9": 0.16572508215904236, "10": 0.017160164192318916, "11": 0.0004391809634398669, "12": 0.26788341999053955, "13": 0.0003889087529387325, "14": 0.01777798868715763, "15": 0.021283382549881935, "16": 0.00033191783586516976, "17": 0.0003164597728755325, "18": 0.00030237744795158505, "19": 0.0002894950157497078}}, {"key": "hashimoto2018retrieve", "year": "2018", "title": "A Retrieve-and-edit Framework For Predicting Structured Outputs", "topic_distr": {"0": 0.0021134375128895044, "1": 0.0017265868373215199, "2": 0.11240574717521667, "3": 0.16894568502902985, "4": 0.0011147217592224479, "5": 0.0009970358805730939, "6": 0.3129551410675049, "7": 0.21905365586280823, "8": 0.06584793329238892, "9": 0.0007010066765360534, "10": 0.0006525682983919978, "11": 0.0006103913765400648, "12": 0.000573335331864655, "13": 0.059932734817266464, "14": 0.000511259597260505, "15": 0.00048500363482162356, "16": 0.0501113124191761, "17": 0.00043982849456369877, "18": 0.0004202563432045281, "19": 0.00040235184133052826}}, {"key": "haviv2021learning", "year": "2021", "title": "Bertese: Learning To Speak To BERT", "topic_distr": {"0": 0.0018070681253448129, "1": 0.0014759813202545047, "2": 0.0012478283606469631, "3": 0.001080758753232658, "4": 0.0009531814721412957, "5": 0.0008525503217242658, "6": 0.0007711389916948974, "7": 0.0007039204938337207, "8": 0.11207205057144165, "9": 0.0005994202801957726, "10": 0.07656504213809967, "11": 0.2232857346534729, "12": 0.0004902504151687026, "13": 0.0946073830127716, "14": 0.0004371704126242548, "15": 0.29163017868995667, "16": 0.1903408318758011, "17": 0.0003760907566174865, "18": 0.00035935488995164633, "19": 0.0003440449945628643}}, {"key": "haviv2022transformer", "year": "2022", "title": "Transformer Language Models Without Positional Encodings Still Learn Positional Information", "topic_distr": {"0": 0.15385350584983826, "1": 0.0015200497582554817, "2": 0.4425044357776642, "3": 0.0011129589984193444, "4": 0.0009815831435844302, "5": 0.000877954182215035, "6": 0.0007941168732941151, "7": 0.0007248955080285668, "8": 0.0006667742854915559, "9": 0.000617281417362392, "10": 0.19953159987926483, "11": 0.0005374888423830271, "12": 0.0005048586172051728, "13": 0.0004759634903166443, "14": 0.00045019693789072335, "15": 0.00042707688407972455, "16": 0.08641921728849411, "17": 0.00038729727384634316, "18": 0.0003700627130456269, "19": 0.1072426587343216}}, {"key": "hayati2018retrieval", "year": "2018", "title": "Retrieval-based Neural Code Generation", "topic_distr": {"0": 0.0015415189554914832, "1": 0.04028588905930519, "2": 0.0010629324242472649, "3": 0.12568633258342743, "4": 0.0008119563572108746, "5": 0.0007262350991368294, "6": 0.30226314067840576, "7": 0.19013763964176178, "8": 0.047320909798145294, "9": 0.000510609126649797, "10": 0.0004753269022330642, "11": 0.11336452513933182, "12": 0.00041761406464502215, "13": 0.00039371231105178595, "14": 0.08291115611791611, "15": 0.0003532737900968641, "16": 0.09081766754388809, "17": 0.0003203685046173632, "18": 0.0003061122552026063, "19": 0.0002930707123596221}}, {"key": "hayawi2023imitation", "year": "2023", "title": "The Imitation Game: Detecting Human And Ai-generated Texts In The Era Of Chatgpt And BARD", "topic_distr": {"0": 0.08634256571531296, "1": 0.1927526444196701, "2": 0.0009783473797142506, "3": 0.1832691878080368, "4": 0.0007473581354133785, "5": 0.0006684564868919551, "6": 0.0006046245689503849, "7": 0.12054052948951721, "8": 0.0005076684174127877, "9": 0.31960293650627136, "10": 0.00043751034536398947, "11": 0.049982644617557526, "12": 0.0003843891026917845, "13": 0.04135749116539955, "14": 0.0003427708288654685, "15": 0.0003251676680520177, "16": 0.0003092842816840857, "17": 0.00029488030122593045, "18": 0.00028175825718790293, "19": 0.00026975429500453174}}, {"key": "hazell2023spear", "year": "2023", "title": "Spear Phishing With Large Language Models", "topic_distr": {"0": 0.001315023866482079, "1": 0.173258438706398, "2": 0.0009062546887435019, "3": 0.0007849403191357851, "4": 0.0006922819302417338, "5": 0.000619195110630244, "6": 0.0005600672448053956, "7": 0.0005112473736517131, "8": 0.0004702562000602484, "9": 0.668030321598053, "10": 0.000405268365284428, "11": 0.0003790749760810286, "12": 0.0003560618497431278, "13": 0.0003356829984113574, "14": 0.00031751059577800333, "15": 0.061897192150354385, "16": 0.0002864918205887079, "17": 0.08836380392313004, "18": 0.000260994303971529, "19": 0.00024987495271489024}}, {"key": "he2017chinese", "year": "2017", "title": "Dureader: A Chinese Machine Reading Comprehension Dataset From Real-world Applications", "topic_distr": {"0": 0.0015597216552123427, "1": 0.0695832371711731, "2": 0.167464941740036, "3": 0.0009320969693362713, "4": 0.0008220726158469915, "5": 0.0007352826069109142, "6": 0.0006650692084804177, "7": 0.000607096531894058, "8": 0.3418610095977783, "9": 0.0005169702926650643, "10": 0.0004812485130969435, "11": 0.00045014434726908803, "12": 0.3732859492301941, "13": 0.0003986171795986593, "14": 0.00037703782436437905, "15": 0.0003576748713385314, "16": 0.0003402036090847105, "17": 0.038954999297857285, "18": 0.00030992578831501305, "19": 0.00029672178789041936}}, {"key": "he2021effectiveness", "year": "2021", "title": "On The Effectiveness Of Adapter-based Tuning For Pretrained Language Model Adaptation", "topic_distr": {"0": 0.0015802786219865084, "1": 0.05122282728552818, "2": 0.2329278141260147, "3": 0.0009439921705052257, "4": 0.0008325608796440065, "5": 0.0007446641102433205, "6": 0.0006735549541190267, "7": 0.0006148426327854395, "8": 0.0005655453423969448, "9": 0.0005235664430074394, "10": 0.0004873888974543661, "11": 0.0004558878717944026, "12": 0.00042821152601391077, "13": 0.15642671287059784, "14": 0.024751944467425346, "15": 0.00036223852657712996, "16": 0.042274512350559235, "17": 0.48356905579566956, "18": 0.00031388021307066083, "19": 0.0003005077305715531}}, {"key": "he2021fast", "year": "2021", "title": "Fastmoe: A Fast Mixture-of-expert Training System", "topic_distr": {"0": 0.0015988711966201663, "1": 0.04920104518532753, "2": 0.1293553113937378, "3": 0.0009560518083162606, "4": 0.12152646481990814, "5": 0.0007541762315668166, "6": 0.07196610420942307, "7": 0.00062269635964185, "8": 0.0005727693205699325, "9": 0.2473515123128891, "10": 0.06249963864684105, "11": 0.0004617111408151686, "12": 0.00043368127080611885, "13": 0.3106424808502197, "14": 0.0003867260820697993, "15": 0.00036686559906229377, "16": 0.0003489453811198473, "17": 0.00033269429695792496, "18": 0.00031788955675438046, "19": 0.0003043462638743222}}, {"key": "he2021generative", "year": "2021", "title": "GALAXY: A Generative Pre-trained Model For Task-oriented Dialog With Semi-supervised Learning And Explicit Policy Injection", "topic_distr": {"0": 0.001449806964956224, "1": 0.0011841936502605677, "2": 0.2918088436126709, "3": 0.0008670543320477009, "4": 0.38349366188049316, "5": 0.0006839727284386754, "6": 0.0006186590762808919, "7": 0.0005647318903356791, "8": 0.0005194524419493973, "9": 0.0004808948724530637, "10": 0.00044766583596356213, "11": 0.0004187322047073394, "12": 0.00039331152220256627, "13": 0.07095109671354294, "14": 0.00035072723403573036, "15": 0.09159950911998749, "16": 0.15330162644386292, "17": 0.0003017250564880669, "18": 0.0002882984117604792, "19": 0.00027601580950431526}}, {"key": "he2021improving", "year": "2021", "title": "Debertav3: Improving Deberta Using Electra-style Pre-training With Gradient-disentangled Embedding Sharing", "topic_distr": {"0": 0.0013125271070748568, "1": 0.001072350307367742, "2": 0.0009063132456503808, "3": 0.0913582518696785, "4": 0.0006923091132193804, "5": 0.0006192196742631495, "6": 0.0005600894219242036, "7": 0.01931249350309372, "8": 0.00047027485561557114, "9": 0.00043536763405427337, "10": 0.39157634973526, "11": 0.0003790900227613747, "12": 0.00035607596510089934, "13": 0.1849214881658554, "14": 0.3046559989452362, "15": 0.00030121664167381823, "16": 0.00028650317108258605, "17": 0.000273160170763731, "18": 0.0002610046649351716, "19": 0.000249884877121076}}, {"key": "he2021nlp", "year": "2021", "title": "Generate, Annotate, And Learn: NLP With Synthetic Text", "topic_distr": {"0": 0.0013127699494361877, "1": 0.10450343787670135, "2": 0.26449620723724365, "3": 0.0007848997483961284, "4": 0.0006922509055584669, "5": 0.0006191674037836492, "6": 0.000560042099095881, "7": 0.0005112244398333132, "8": 0.0004702351288869977, "9": 0.00043533084681257606, "10": 0.000405250204494223, "11": 0.00037905797944404185, "12": 0.00035604590084403753, "13": 0.12200457602739334, "14": 0.00031749636400491, "15": 0.23145081102848053, "16": 0.046262890100479126, "17": 0.1379551887512207, "18": 0.0002609826042316854, "19": 0.08622216433286667}}, {"key": "he2021parallel", "year": "2021", "title": "Parallel Refinements For Lexically Constrained Text Generation With BART", "topic_distr": {"0": 0.0013695049565285444, "1": 0.001118952059186995, "2": 0.0009460479486733675, "3": 0.0008193883113563061, "4": 0.0007226694724522531, "5": 0.0006463741301558912, "6": 0.0005846509011462331, "7": 0.781400740146637, "8": 0.0004908977425657213, "9": 0.0004544597177300602, "10": 0.05227958410978317, "11": 0.0003957141889259219, "12": 0.0003716908977366984, "13": 0.09692765027284622, "14": 0.06003978103399277, "15": 0.0003144258516840637, "16": 0.0002990671491716057, "17": 0.00028513898723758757, "18": 0.0002724504447542131, "19": 0.0002608430222608149}}, {"key": "he2022prompt", "year": "2022", "title": "Hyperprompt: Prompt-based Task-conditioning Of Transformers", "topic_distr": {"0": 0.0018607992678880692, "1": 0.0015198314795270562, "2": 0.13322864472866058, "3": 0.0011129614431411028, "4": 0.0009815848898142576, "5": 0.0008779553463682532, "6": 0.0007941180374473333, "7": 0.03190424665808678, "8": 0.0006667752168141305, "9": 0.0006172822904773057, "10": 0.2941755950450897, "11": 0.000537489540874958, "12": 0.0005048592574894428, "13": 0.1940108984708786, "14": 0.0004501975781749934, "15": 0.0004270774661563337, "16": 0.0004062160733155906, "17": 0.18206338584423065, "18": 0.15350574254989624, "19": 0.0003542971389833838}}, {"key": "he2022rethinking", "year": "2022", "title": "Rethinking With Retrieval: Faithful Large Language Model Inference", "topic_distr": {"0": 0.001466998364776373, "1": 0.0011983852600678802, "2": 0.06987642496824265, "3": 0.5349956750869751, "4": 0.0007737127016298473, "5": 0.04948090761899948, "6": 0.000625945976935327, "7": 0.049038030207157135, "8": 0.039240483194589615, "9": 0.00048655911814421415, "10": 0.0004529386933427304, "11": 0.0004236642562318593, "12": 0.00039794418262317777, "13": 0.00037516822339966893, "14": 0.00035485828993842006, "15": 0.00033663437352515757, "16": 0.19716648757457733, "17": 0.05273826792836189, "18": 0.00029169415938667953, "19": 0.00027926688198931515}}, {"key": "he2022space", "year": "2022", "title": "SPACE-3: Unified Dialog Model Pre-training For Task-oriented Dialog Understanding And Generation", "topic_distr": {"0": 0.0008425679989159107, "1": 0.0006881790468469262, "2": 0.0005817385390400887, "3": 0.0005038484232500196, "4": 0.5509225130081177, "5": 0.0003974588180426508, "6": 0.16987991333007812, "7": 0.0003281674289610237, "8": 0.00030185538344085217, "9": 0.0002794494794216007, "10": 0.19660943746566772, "11": 0.00024332654720637947, "12": 0.00022855451970826834, "13": 0.00021547342475969344, "14": 0.00020380865316838026, "15": 0.00019334196986164898, "16": 0.00018389782053418458, "17": 0.00017533333448227495, "18": 0.0001675310923019424, "19": 0.07705357670783997}}, {"key": "he2023exploring", "year": "2023", "title": "Exploring Human-like Translation Strategy With Large Language Models", "topic_distr": {"0": 0.13938096165657043, "1": 0.0009429827332496643, "2": 0.023563450202345848, "3": 0.424741268157959, "4": 0.0006089642993174493, "5": 0.0005446721334010363, "6": 0.0004926605615764856, "7": 0.1276555359363556, "8": 0.0004136587376706302, "9": 0.040936440229415894, "10": 0.00035649247001856565, "11": 0.0003334515786264092, "12": 0.0003132081765215844, "13": 0.00029528202139772475, "14": 0.1754504293203354, "15": 0.0002649533562362194, "16": 0.0630159080028534, "17": 0.00024027455947361887, "18": 0.00022958245244808495, "19": 0.00021980136807542294}}, {"key": "he2023icl", "year": "2023", "title": "ICL-D3IE: In-context Learning With Diverse Demonstrations Updating For Document Information Extraction", "topic_distr": {"0": 0.001113786012865603, "1": 0.0009094210690818727, "2": 0.14313608407974243, "3": 0.4929959177970886, "4": 0.0005872067995369434, "5": 0.0005252126720733941, "6": 0.00047505932161584496, "7": 0.0004336494021117687, "8": 0.05150143429636955, "9": 0.0003692721656989306, "10": 0.0003437560808379203, "11": 0.12357544153928757, "12": 0.00030201819026842713, "13": 0.0002847324649337679, "14": 0.00026931831962428987, "15": 0.15489964187145233, "16": 0.00024300761288031936, "17": 0.00023169026826508343, "18": 0.027591409161686897, "19": 0.00021194852888584137}}, {"key": "he2023large", "year": "2023", "title": "Large Language Models As Zero-shot Conversational Recommenders", "topic_distr": {"0": 0.0015598402824252844, "1": 0.11738025397062302, "2": 0.0010761922458186746, "3": 0.2576390504837036, "4": 0.236756831407547, "5": 0.0007352979737333953, "6": 0.16039220988750458, "7": 0.000607109337579459, "8": 0.0005584320751950145, "9": 0.0005169811774976552, "10": 0.0004812586703337729, "11": 0.0004501538351178169, "12": 0.19784024357795715, "13": 0.0003986255906056613, "14": 0.00037704576971009374, "15": 0.00035768240923061967, "16": 0.00034021076862700284, "17": 0.00032436646870337427, "18": 0.00030993230757303536, "19": 0.021898318082094193}}, {"key": "he2024quality", "year": "2024", "title": "Quality Of Answers Of Generative Large Language Models Vs Peer Patients For Interpreting Lab Test Results For Lay Patients: Evaluation Study", "topic_distr": {"0": 0.2320253849029541, "1": 0.04832913354039192, "2": 0.0005627358332276344, "3": 0.2594350278377533, "4": 0.0004298753337934613, "5": 0.00038449084968306124, "6": 0.14286276698112488, "7": 0.00031746039167046547, "8": 0.10242892801761627, "9": 0.1077604740858078, "10": 0.00025165246916003525, "11": 0.00023538760433439165, "12": 0.06656000018119812, "13": 0.0002084432344418019, "14": 0.037356484681367874, "15": 0.000187033845577389, "16": 0.0001778978476068005, "17": 0.00016961278743110597, "18": 0.00016206510190386325, "19": 0.00015516050916630775}}, {"key": "hedderich2024piece", "year": "2024", "title": "A Piece Of Theatre: Investigating How Teachers Design LLM Chatbots To Assist Adolescent Cyberbullying Education", "topic_distr": {"0": 0.08223338425159454, "1": 0.040286432951688766, "2": 0.0010763744357973337, "3": 0.06901257485151291, "4": 0.036200035363435745, "5": 0.016829147934913635, "6": 0.017951056361198425, "7": 0.0006072216783650219, "8": 0.0005585353937931359, "9": 0.5854636430740356, "10": 0.00048134769895114005, "11": 0.03881877660751343, "12": 0.0004229038313496858, "13": 0.08407237380743027, "14": 0.00037711553159169853, "15": 0.0003577485913410783, "16": 0.0003402736911084503, "17": 0.024304242804646492, "18": 0.0003099896421190351, "19": 0.00029678293503820896}}, {"key": "hegde2020unsupervised", "year": "2020", "title": "Unsupervised Paraphrase Generation Using Pre-trained Language Models", "topic_distr": {"0": 0.0642625167965889, "1": 0.2857902944087982, "2": 0.001459168386645615, "3": 0.09334219992160797, "4": 0.0011146427132189274, "5": 0.000996965914964676, "6": 0.0009017642005346715, "7": 0.1187853217124939, "8": 0.0007571594906039536, "9": 0.0007009575492702425, "10": 0.0006525226053781807, "11": 0.0006103485939092934, "12": 0.0005732951685786247, "13": 0.0005404831608757377, "14": 0.09741028398275375, "15": 0.213083878159523, "16": 0.0004612804332282394, "17": 0.00043979770271107554, "18": 0.00042022691923193634, "19": 0.1176968589425087}}, {"key": "helcl2018cuni", "year": "2018", "title": "CUNI System For The WMT18 Multimodal Translation Task", "topic_distr": {"0": 0.0024929428473114967, "1": 0.0020366902463138103, "2": 0.42659738659858704, "3": 0.001491262810304761, "4": 0.001315238536335528, "5": 0.0011763828806579113, "6": 0.0010640480322763324, "7": 0.0009712972678244114, "8": 0.0008934198995120823, "9": 0.0008271037368103862, "10": 0.0007699522539041936, "11": 0.0007201885455287993, "12": 0.0006764668505638838, "13": 0.0006377499084919691, "14": 0.10562727600336075, "15": 0.0005722460919059813, "16": 0.02677236869931221, "17": 0.0005189448711462319, "18": 0.42436426877975464, "19": 0.0004747268685605377}}, {"key": "hellas2023exploring", "year": "2023", "title": "Exploring The Responses Of Large Language Models To Beginner Programmers' Help Requests", "topic_distr": {"0": 0.2238227128982544, "1": 0.03428986296057701, "2": 0.0006149585242383182, "3": 0.2738673686981201, "4": 0.0004697668191511184, "5": 0.0004201718547847122, "6": 0.06605806201696396, "7": 0.0003469207731541246, "8": 0.0003191051073372364, "9": 0.39764317870140076, "10": 0.0002750058483798057, "11": 0.0002572316152509302, "12": 0.0002416154311504215, "13": 0.0002277868043165654, "14": 0.00021545543859247118, "15": 0.00020439062791410834, "16": 0.0001944067917065695, "17": 0.0001853528810897842, "18": 0.0001771047682268545, "19": 0.00016955944010987878}}, {"key": "henderson2019efficient", "year": "2019", "title": "Convert: Efficient And Accurate Conversational Representations From Transformers", "topic_distr": {"0": 0.0012228924315422773, "1": 0.0009987738449126482, "2": 0.22707700729370117, "3": 0.0007311777444556355, "4": 0.03339948132634163, "5": 0.0005767878610640764, "6": 0.15933212637901306, "7": 0.0004762332537211478, "8": 0.00043804946471937, "9": 0.047008808702230453, "10": 0.26116710901260376, "11": 0.0003531130205374211, "12": 0.018409477546811104, "13": 0.1717727780342102, "14": 0.00029576505767181516, "15": 0.0002805759140755981, "16": 0.0002668706583790481, "17": 0.01737796701490879, "18": 0.0002431194152450189, "19": 0.05857187509536743}}, {"key": "henderson2019training", "year": "2019", "title": "Training Neural Response Selection For Task-oriented Dialogue Systems", "topic_distr": {"0": 0.0019208131125196815, "1": 0.0015676843468099833, "2": 0.0013247012393549085, "3": 0.0011473610065877438, "4": 0.0010119262151420116, "5": 0.1732710599899292, "6": 0.31778931617736816, "7": 0.0007473025470972061, "8": 0.000687384803313762, "9": 0.0006363620632328093, "10": 0.0005923905409872532, "11": 0.0005541029968298972, "12": 0.0005204641493037343, "13": 0.21190513670444489, "14": 0.00046411287621594965, "15": 0.20266492664813995, "16": 0.0004187719605397433, "17": 0.00039926893077790737, "18": 0.00038150165346451104, "19": 0.08199538290500641}}, {"key": "hendrycks2020pretrained", "year": "2020", "title": "Pretrained Transformers Improve Out-of-distribution Robustness", "topic_distr": {"0": 0.16200374066829681, "1": 0.2747901976108551, "2": 0.13947437703609467, "3": 0.0010215692454949021, "4": 0.0009009783389046788, "5": 0.0008058580569922924, "6": 0.0007289054919965565, "7": 0.000665368395857513, "8": 0.0006120200268924236, "9": 0.0005665913922712207, "10": 0.20190465450286865, "11": 0.0004933511954732239, "12": 0.00046340053086169064, "13": 0.07671672105789185, "14": 0.00041322759352624416, "15": 0.00039200609899125993, "16": 0.0003728578449226916, "17": 0.0333329513669014, "18": 0.000339673861162737, "19": 0.10400155186653137}}, {"key": "hendrycks2021expert", "year": "2021", "title": "CUAD: An Expert-annotated NLP Dataset For Legal Contract Review", "topic_distr": {"0": 0.0017326663946732879, "1": 0.12947118282318115, "2": 0.0011958082905039191, "3": 0.001035696011967957, "4": 0.0009134386200457811, "5": 0.0008170034852810204, "6": 0.0007389865349978209, "7": 0.0006745706195943058, "8": 0.0006204844103194773, "9": 0.1648709923028946, "10": 0.0458846278488636, "11": 0.0005001744139008224, "12": 0.46339476108551025, "13": 0.1172175481915474, "14": 0.00041894265450537205, "15": 0.0003974276769440621, "16": 0.00037801460712216794, "17": 0.00036040970007888973, "18": 0.0003443716268520802, "19": 0.06903286278247833}}, {"key": "hendy2023how", "year": "2023", "title": "How Good Are GPT Models At Machine Translation? A Comprehensive Evaluation", "topic_distr": {"0": 0.001124772010371089, "1": 0.03784554824233055, "2": 0.0007756197010166943, "3": 0.18625129759311676, "4": 0.0005924889701418579, "5": 0.0005299376207403839, "6": 0.0004793331027030945, "7": 0.00043755065416917205, "8": 0.0004024684021715075, "9": 0.11734794825315475, "10": 0.022385533899068832, "11": 0.0003244310209993273, "12": 0.18931593000888824, "13": 0.00028729403857141733, "14": 0.3930845260620117, "15": 0.04789910465478897, "16": 0.0002451938053127378, "17": 0.00023377464094664901, "18": 0.00022337176778819412, "19": 0.00021385529544204473}}, {"key": "herbold2023write", "year": "2023", "title": "AI, Write An Essay For Me: A Large-scale Comparison Of Human-written Versus Chatgpt-generated Essays", "topic_distr": {"0": 0.17024531960487366, "1": 0.28291404247283936, "2": 0.0007486942922696471, "3": 0.0006484688492491841, "4": 0.0005719183827750385, "5": 0.0005115381209179759, "6": 0.0004626905429176986, "7": 0.00042235880391672254, "8": 0.0003884946054313332, "9": 0.4160376787185669, "10": 0.00033480595448054373, "11": 0.00031316670356318355, "12": 0.00029415477183647454, "13": 0.00027731910813599825, "14": 0.0002623062755446881, "15": 0.12468267232179642, "16": 0.00023668060021009296, "17": 0.00022565791732631624, "18": 0.00021561625180765986, "19": 0.00020643018069677055}}, {"key": "hernandez2022scaling", "year": "2022", "title": "Scaling Laws And Interpretability Of Learning From Repeated Data", "topic_distr": {"0": 0.17925509810447693, "1": 0.24198412895202637, "2": 0.2475213259458542, "3": 0.0006428354536183178, "4": 0.0005669543170370162, "5": 0.060343846678733826, "6": 0.00045867537846788764, "7": 0.0004186936712358147, "8": 0.01194471400231123, "9": 0.00035653667873702943, "10": 0.0003319006063975394, "11": 0.0003104491042904556, "12": 0.0002916021621786058, "13": 0.2541898787021637, "14": 0.00026003006496466696, "15": 0.0002466760925017297, "16": 0.00023462674289476126, "17": 0.0002236997097497806, "18": 0.00021374518109951168, "19": 0.00020463882538024336}}, {"key": "hertz2022prompt", "year": "2022", "title": "Prompt-to-prompt Image Editing With Cross Attention Control", "topic_distr": {"0": 0.001049203798174858, "1": 0.14256049692630768, "2": 0.1770947128534317, "3": 0.0006267359713092446, "4": 0.012774023227393627, "5": 0.0004943970707245171, "6": 0.0004471862339414656, "7": 0.2999579608440399, "8": 0.00037547654937952757, "9": 0.00034760593553073704, "10": 0.036367181688547134, "11": 0.028061209246516228, "12": 0.0002842979447450489, "13": 0.0002680264296941459, "14": 0.0002535166568122804, "15": 0.00024049720377661288, "16": 0.00022874967544339597, "17": 0.09827592968940735, "18": 0.20009328424930573, "19": 0.00019951291324105114}}, {"key": "herzig2021open", "year": "2021", "title": "Open Domain Question Answering Over Tables Via Dense Retrieval", "topic_distr": {"0": 0.0018607147503644228, "1": 0.0015202368376776576, "2": 0.0012849877821281552, "3": 0.0011129333870485425, "4": 0.0009815581142902374, "5": 0.0008779307245276868, "6": 0.0007940956857055426, "7": 0.0007248760666698217, "8": 0.39112380146980286, "9": 0.0006172649445943534, "10": 0.11960595846176147, "11": 0.0005374744650907815, "12": 0.0005048450548201799, "13": 0.00047595074283890426, "14": 0.00045018488890491426, "15": 0.00042706544627435505, "16": 0.0004062046646140516, "17": 0.00038728691288270056, "18": 0.0003700528177432716, "19": 0.47593653202056885}}, {"key": "herzig2021unlocking", "year": "2021", "title": "Unlocking Compositional Generalization In Pre-trained Models Using Intermediate Representations", "topic_distr": {"0": 0.0015606300439685583, "1": 0.0012735698837786913, "2": 0.49735888838768005, "3": 0.11409730464220047, "4": 0.000822122732643038, "5": 0.0007353282999247313, "6": 0.0006651105941273272, "7": 0.0006071343668736517, "8": 0.0005584551254287362, "9": 0.0005170024815015495, "10": 0.06425284594297409, "11": 0.2550709843635559, "12": 0.00042284303344786167, "13": 0.02151464857161045, "14": 0.00037706131115555763, "15": 0.00035769716487266123, "16": 0.038877349346876144, "17": 0.00032437985646538436, "18": 0.00030994508415460587, "19": 0.0002967402688227594}}, {"key": "heyman2020neural", "year": "2020", "title": "Neural Code Search Revisited: Enhancing Code Snippet Retrieval Through Natural Language Intent", "topic_distr": {"0": 0.0016637209337204695, "1": 0.0013580300146713853, "2": 0.08659008890390396, "3": 0.0009942653123289347, "4": 0.0008769003325141966, "5": 0.0007843230268917978, "6": 0.7312906980514526, "7": 0.0006475875852629542, "8": 0.11667872220277786, "9": 0.0005514502408914268, "10": 0.0005133459344506264, "11": 0.0004801672766916454, "12": 0.05500583350658417, "13": 0.0004252034123055637, "14": 0.00040218481444753706, "15": 0.0003815304080490023, "16": 0.0003628938866313547, "17": 0.0003459931758698076, "18": 0.0003305966383777559, "19": 0.0003165119851473719}}, {"key": "hieber2017toolkit", "year": "2017", "title": "Sockeye: A Toolkit For Neural Machine Translation", "topic_distr": {"0": 0.0013557348866015673, "1": 0.0011070542968809605, "2": 0.22773660719394684, "3": 0.0008105392917059362, "4": 0.0007148628938011825, "5": 0.0006393917719833553, "6": 0.12068214267492294, "7": 0.0005279229953885078, "8": 0.00048559479182586074, "9": 0.14167658984661102, "10": 0.1747572273015976, "11": 0.0003914394765160978, "12": 0.00036767570418305695, "13": 0.00034663212136365473, "14": 0.32698413729667664, "15": 0.0003110292600467801, "16": 0.0002958364493679255, "17": 0.00028205878334119916, "18": 0.00026950729079544544, "19": 0.00025802524760365486}}, {"key": "hill2020grounded", "year": "2020", "title": "Grounded Language Learning Fast And Slow", "topic_distr": {"0": 0.1571996808052063, "1": 0.0009608188993297517, "2": 0.2071436494588852, "3": 0.0007035068701952696, "4": 0.01551605574786663, "5": 0.0005549589986912906, "6": 0.0005019651143811643, "7": 0.0004582098626997322, "8": 0.00042147119529545307, "9": 0.00039018652751110494, "10": 0.0003632252919487655, "11": 0.37143674492836, "12": 0.00031912350095808506, "13": 0.00030085878097452223, "14": 0.000284571637166664, "15": 0.0002699573233257979, "16": 0.16588179767131805, "17": 0.049714215099811554, "18": 0.02735506370663643, "19": 0.00022395259293261915}}, {"key": "hill2020human", "year": "2020", "title": "Human Instruction-following With Deep Reinforcement Learning Via Transfer-learning From Text", "topic_distr": {"0": 0.11371031403541565, "1": 0.03545992076396942, "2": 0.05613767355680466, "3": 0.0007311204099096358, "4": 0.1287807822227478, "5": 0.000576743099372834, "6": 0.0005216689314693213, "7": 0.00047619614633731544, "8": 0.0004380153550300747, "9": 0.0004055026511196047, "10": 0.0633683055639267, "11": 0.5772197842597961, "12": 0.020287929102778435, "13": 0.0003126685041934252, "14": 0.0002957420074380934, "15": 0.0002805540570989251, "16": 0.000266849878244102, "17": 0.00025442216428928077, "18": 0.0002431004832033068, "19": 0.0002327434776816517}}, {"key": "ho2020constructing", "year": "2020", "title": "Constructing A Multi-hop QA Dataset For Comprehensive Evaluation Of Reasoning Steps", "topic_distr": {"0": 0.0011879969388246536, "1": 0.041925277560949326, "2": 0.0327930822968483, "3": 0.3890382647514343, "4": 0.0006264118710532784, "5": 0.11491815745830536, "6": 0.0005067767342552543, "7": 0.0004626020381692797, "8": 0.36435672640800476, "9": 0.0003939266607630998, "10": 0.00036670698318630457, "11": 0.00034300590050406754, "12": 0.00032218245905824006, "13": 0.0003037426504306495, "14": 0.00028729939367622137, "15": 0.000272545003099367, "16": 0.051185883581638336, "17": 0.0002471590705681592, "18": 0.00023616061662323773, "19": 0.00022609929146710783}}, {"key": "ho2022large", "year": "2022", "title": "Large Language Models Are Reasoning Teachers", "topic_distr": {"0": 0.0012477359268814325, "1": 0.08819478005170822, "2": 0.05591234192252159, "3": 0.572717547416687, "4": 0.0006576496525667608, "5": 0.0005882191471755505, "6": 0.0005320492200553417, "7": 0.0004856716259382665, "8": 0.0004467311082407832, "9": 0.00041357145528309047, "10": 0.0003849943750537932, "11": 0.019188769161701202, "12": 0.00033824946149252355, "13": 0.2572869658470154, "14": 0.0003016267728526145, "15": 0.0002861366083379835, "16": 0.0002721597265917808, "17": 0.0002594847173895687, "18": 0.0002479377726558596, "19": 0.00023737468291074038}}, {"key": "hoang2019efficient", "year": "2019", "title": "Efficient Adaptation Of Pretrained Transformers For Abstractive Summarization", "topic_distr": {"0": 0.07662686705589294, "1": 0.0015432264190167189, "2": 0.0013044646475464106, "3": 0.0011298108147457242, "4": 0.000996445887722075, "5": 0.0008912466000765562, "6": 0.0008061400149017572, "7": 0.08280595391988754, "8": 0.0006768693565391004, "9": 0.0006266271811909974, "10": 0.7572289109230042, "11": 0.0005456265062093735, "12": 0.0005125022144056857, "13": 0.07187382131814957, "14": 0.00045701299677602947, "15": 0.0004335428820922971, "16": 0.00041236571269109845, "17": 0.0003931610262952745, "18": 0.00037566552055068314, "19": 0.0003596607712097466}}, {"key": "hodel2023emergent", "year": "2023", "title": "Response: Emergent Analogical Reasoning In Large Language Models", "topic_distr": {"0": 0.3410784900188446, "1": 0.0018190165283158422, "2": 0.0015373937785625458, "3": 0.5673935413360596, "4": 0.0011743871727958322, "5": 0.0010504031088203192, "6": 0.0009500981541350484, "7": 0.0008672800613567233, "8": 0.0007977426867000759, "9": 0.000738528382498771, "10": 0.0006874973187223077, "11": 0.0006430628709495068, "12": 0.07782749086618423, "13": 0.0005694526480510831, "14": 0.000538625055924058, "15": 0.0005109636695124209, "16": 0.0004860047483816743, "17": 0.00046337052481248975, "18": 0.0004427507519721985, "19": 0.0004238879191689193}}, {"key": "hoffmann2022training", "year": "2022", "title": "Training Compute-optimal Large Language Models", "topic_distr": {"0": 0.09861285239458084, "1": 0.10295689105987549, "2": 0.14382240176200867, "3": 0.0009094772394746542, "4": 0.0008021224639378488, "5": 0.0007174370111897588, "6": 0.0006489278748631477, "7": 0.0005923622520640492, "8": 0.0005448674201034009, "9": 0.0005044233403168619, "10": 0.11509627103805542, "11": 0.0004392192931845784, "12": 0.06915901601314545, "13": 0.4632364809513092, "14": 0.0003678870853036642, "15": 0.0003489940718282014, "16": 0.00033194682328030467, "17": 0.00031648739241063595, "18": 0.0003024038451258093, "19": 0.0002895203069783747}}, {"key": "hofst\u00e4tter2020improving", "year": "2020", "title": "Improving Efficient Neural Ranking Models With Cross-architecture Knowledge Distillation", "topic_distr": {"0": 0.0008672253461554646, "1": 0.0007072672597132623, "2": 0.31275349855422974, "3": 0.0005178817082196474, "4": 0.10207180678844452, "5": 0.0004085284599568695, "6": 0.0003695174236781895, "7": 0.0003373073705006391, "8": 0.07179068773984909, "9": 0.00028723254217766225, "10": 0.07363102585077286, "11": 0.0002501035633031279, "12": 0.018160559237003326, "13": 0.3193505108356476, "14": 0.00020948503515683115, "15": 0.00019872683333233, "16": 0.054232075810432434, "17": 0.04351953789591789, "18": 0.00017219707660842687, "19": 0.00016486083040945232}}, {"key": "holmes2023evaluating", "year": "2023", "title": "Evaluating Large Language Models On A Highly-specialized Topic, Radiation Oncology Physics", "topic_distr": {"0": 0.18666094541549683, "1": 0.0294438935816288, "2": 0.0006522546173073351, "3": 0.37632837891578674, "4": 0.0004982540849596262, "5": 0.00044565132702700794, "6": 0.0004030951822642237, "7": 0.0003679582441691309, "8": 0.06185512617230415, "9": 0.19894592463970184, "10": 0.00029168237233534455, "11": 0.0002728302788455039, "12": 0.14237667620182037, "13": 0.00024159991880878806, "14": 0.00022852077381685376, "15": 0.00021678497432731092, "16": 0.0002061957202386111, "17": 0.00019659278041217476, "18": 0.00018784448911901563, "19": 0.00017984160513151437}}, {"key": "holtzman2019curious", "year": "2019", "title": "The Curious Case Of Neural Text Degeneration", "topic_distr": {"0": 0.21702539920806885, "1": 0.0011443565599620342, "2": 0.19217759370803833, "3": 0.0008378676138818264, "4": 0.00073895079549402, "5": 0.0006609372212551534, "6": 0.0005978232948109508, "7": 0.44677960872650146, "8": 0.0005019578384235501, "9": 0.00046469885273836553, "10": 0.0004325889458414167, "11": 0.00040462976903654635, "12": 0.00038006523391231894, "13": 0.00035831256536766887, "14": 0.04250403121113777, "15": 0.0003215099568478763, "16": 0.00030580523889511824, "17": 0.0002915632794611156, "18": 0.0002785888500511646, "19": 0.09379370510578156}}, {"key": "hong2020recurrent", "year": "2020", "title": "A Recurrent Vision-and-language BERT For Navigation", "topic_distr": {"0": 0.0019178629154339433, "1": 0.0015669080894440413, "2": 0.21456685662269592, "3": 0.0011472157202661037, "4": 0.0010117959463968873, "5": 0.0009049767977558076, "6": 0.0008185591432265937, "7": 0.0007472071447409689, "8": 0.0006872970261611044, "9": 0.0006362808053381741, "10": 0.25377488136291504, "11": 0.33047544956207275, "12": 0.0005203976761549711, "13": 0.08611556142568588, "14": 0.00046405362081713974, "15": 0.030643127858638763, "16": 0.0004187184968031943, "17": 0.0003992179408669472, "18": 0.07281848788261414, "19": 0.00036520158755593}}, {"key": "hong2020sub", "year": "2020", "title": "Sub-instruction Aware Vision-and-language Navigation", "topic_distr": {"0": 0.001372569939121604, "1": 0.0011194816324859858, "2": 0.4165153503417969, "3": 0.0008194615948013961, "4": 0.0007227309397421777, "5": 0.0006464299513027072, "6": 0.08183203637599945, "7": 0.000533734099008143, "8": 0.0004909400013275445, "9": 0.0004544988623820245, "10": 0.000423093733843416, "11": 0.378468781709671, "12": 0.0003717229119502008, "13": 0.00035044769174419343, "14": 0.00033147603971883655, "15": 0.00031445291824638844, "16": 0.0002990929060615599, "17": 0.00028516355087049305, "18": 0.11438767611980438, "19": 0.0002608654904179275}}, {"key": "hong2022large", "year": "2022", "title": "Cogvideo: Large-scale Pretraining For Text-to-video Generation Via Transformers", "topic_distr": {"0": 0.0021891617216169834, "1": 0.0017872954485937953, "2": 0.0015103711048141122, "3": 0.0013081950601190329, "4": 0.001153773395344615, "5": 0.0010319649009034038, "6": 0.0844106525182724, "7": 0.0008520567789673805, "8": 0.0007837399607524276, "9": 0.0007255650707520545, "10": 0.17346811294555664, "11": 0.0006317751831375062, "12": 0.0005934209912084043, "13": 0.11715792119503021, "14": 0.029527636244893074, "15": 0.2548563480377197, "16": 0.00047747395001351833, "17": 0.00045523702283389866, "18": 0.20102739334106445, "19": 0.1260518878698349}}, {"key": "hong2023injecting", "year": "2023", "title": "3D-LLM: Injecting The 3D World Into Large Language Models", "topic_distr": {"0": 0.0011550836497917771, "1": 0.0009430361678823829, "2": 0.12118373066186905, "3": 0.2515096366405487, "4": 0.014415590092539787, "5": 0.012630593031644821, "6": 0.0004926528781652451, "7": 0.00044970939052291214, "8": 0.0004136522766202688, "9": 0.0003829479683190584, "10": 0.0003564869111869484, "11": 0.01814185455441475, "12": 0.00031320328707806766, "13": 0.0002952773938886821, "14": 0.0002792924060486257, "15": 0.0002649491943884641, "16": 0.10708192735910416, "17": 0.00024027080507948995, "18": 0.4692303240299225, "19": 0.00021979793382342905}}, {"key": "hong2023meta", "year": "2023", "title": "Metagpt: Meta Programming For A Multi-agent Collaborative Framework", "topic_distr": {"0": 0.027052564546465874, "1": 0.0013225434813648462, "2": 0.001118097803555429, "3": 0.44634488224983215, "4": 0.06955758482217789, "5": 0.0007639481336809695, "6": 0.09579764306545258, "7": 0.0006307644653134048, "8": 0.0005801905645057559, "9": 0.11856762319803238, "10": 0.0005000102100893855, "11": 0.18692870438098907, "12": 0.0004393003764562309, "13": 0.0483119897544384, "14": 0.0003917368012480438, "15": 0.0003716189821716398, "16": 0.0003534665738698095, "17": 0.0003370049234945327, "18": 0.0003220083599444479, "19": 0.00030828960007056594}}, {"key": "hong2023visual", "year": "2023", "title": "Cogagent: A Visual Language Model For GUI Agents", "topic_distr": {"0": 0.0017337488243356347, "1": 0.0014146812027320266, "2": 0.0011958661489188671, "3": 0.19468171894550323, "4": 0.0009135060827247798, "5": 0.05786362290382385, "6": 0.0007390413084067404, "7": 0.0006746206781826913, "8": 0.0006205304525792599, "9": 0.1873892843723297, "10": 0.0005347752594389021, "11": 0.10309571772813797, "12": 0.00046984435175545514, "13": 0.00044295325642451644, "14": 0.00041897373739629984, "15": 0.0003974571591243148, "16": 0.04670555144548416, "17": 0.00036043644649907947, "18": 0.40001794695854187, "19": 0.0003297245712019503}}, {"key": "hong2024monolithic", "year": "2024", "title": "ORPO: Monolithic Preference Optimization Without Reference Model", "topic_distr": {"0": 0.1576797068119049, "1": 0.0017261318862438202, "2": 0.15142931044101715, "3": 0.0012639876222237945, "4": 0.14964373409748077, "5": 0.0009970915270969272, "6": 0.0009018778218887746, "7": 0.0823194682598114, "8": 0.0007572548929601908, "9": 0.0007010459084995091, "10": 0.0006526047945953906, "11": 0.0006104254862293601, "12": 0.1512710154056549, "13": 0.2645057439804077, "14": 0.0005112882354296744, "15": 0.00048503075959160924, "16": 0.0004613385535776615, "17": 0.00043985311640426517, "18": 0.00042027985909953713, "19": 0.033222831785678864}}, {"key": "honovich2022unnatural", "year": "2022", "title": "Unnatural Instructions: Tuning Language Models With (almost) No Human Labor", "topic_distr": {"0": 0.0017575289821252227, "1": 0.2458571195602417, "2": 0.0012126098154112697, "3": 0.39915409684181213, "4": 0.0237372238188982, "5": 0.0008285038638859987, "6": 0.000749388593249023, "7": 0.0006840659771114588, "8": 0.0006292184698395431, "9": 0.02834204211831093, "10": 0.0005422625690698624, "11": 0.16387628018856049, "12": 0.0004764226032420993, "13": 0.0004491550207603723, "14": 0.0004248397599440068, "15": 0.0004030219279229641, "16": 0.0003833355731330812, "17": 0.12980931997299194, "18": 0.0003492190735414624, "19": 0.0003343410207889974}}, {"key": "hoover2019visual", "year": "2019", "title": "Exbert: A Visual Analysis Tool To Explore Learned Representations In Transformers Models", "topic_distr": {"0": 0.10786058008670807, "1": 0.0013062363723292947, "2": 0.18788881599903107, "3": 0.0009560409234836698, "4": 0.0008431848254986107, "5": 0.06831689178943634, "6": 0.0006821494898758829, "7": 0.0006226879777386785, "8": 0.0005727616953663528, "9": 0.23636484146118164, "10": 0.2846736013889313, "11": 0.0004617049708031118, "12": 0.00043367547914385796, "13": 0.00040885445196181536, "14": 0.000386720901587978, "15": 0.0003668606805149466, "16": 0.06139937788248062, "17": 0.0003326898440718651, "18": 0.04581795632839203, "19": 0.00030434218933805823}}, {"key": "hosseiniasl2020simple", "year": "2020", "title": "A Simple Language Model For Task-oriented Dialogue", "topic_distr": {"0": 0.0016009995015338063, "1": 0.06229354813694954, "2": 0.5151327252388, "3": 0.0009560503531247377, "4": 0.0008431934984400868, "5": 0.14988285303115845, "6": 0.12381685525178909, "7": 0.0006226938567124307, "8": 0.0005727670504711568, "9": 0.0005302521167322993, "10": 0.0004936125478707254, "11": 0.11714030057191849, "12": 0.0004336795536801219, "13": 0.023622991517186165, "14": 0.0003867245395667851, "15": 0.0003668641147669405, "16": 0.0003489439841359854, "17": 0.00033269295818172395, "18": 0.00031788827618584037, "19": 0.000304345041513443}}, {"key": "hosseiniasl2022generative", "year": "2022", "title": "A Generative Language Model For Few-shot Aspect-based Sentiment Analysis", "topic_distr": {"0": 0.0011336508905515075, "1": 0.2307080328464508, "2": 0.41393253207206726, "3": 0.0006778812385164201, "4": 0.0005978631088510156, "5": 0.0005347445257939398, "6": 0.024271955713629723, "7": 0.00044151951442472637, "8": 0.00040611904114484787, "9": 0.0003759739047382027, "10": 0.10962405800819397, "11": 0.0003273738257121295, "12": 0.0003074993728660047, "13": 0.0002898999664466828, "14": 0.00027420607511885464, "15": 0.2151721566915512, "16": 0.0002474178618285805, "17": 0.00023589510237798095, "18": 0.00022539788915310055, "19": 0.00021579508029390126}}, {"key": "hou2018sequence", "year": "2018", "title": "Sequence-to-sequence Data Augmentation For Dialogue Language Understanding", "topic_distr": {"0": 0.0015212168218567967, "1": 0.2324976921081543, "2": 0.0010498999617993832, "3": 0.0009093369008041918, "4": 0.11124597489833832, "5": 0.0007173276389949024, "6": 0.5131418704986572, "7": 0.0005922717391513288, "8": 0.0005447841249406338, "9": 0.0005043462733738124, "10": 0.0004694968229159713, "11": 0.0004391521797515452, "12": 0.00041249184869229794, "13": 0.0003888832579832524, "14": 0.0003678308567032218, "15": 0.0003489407245069742, "16": 0.13394026458263397, "17": 0.00031643902184441686, "18": 0.0003023576573468745, "19": 0.0002894760691560805}}, {"key": "hou2022learning", "year": "2022", "title": "Learning Vector-quantized Item Representation For Transferable Sequential Recommenders", "topic_distr": {"0": 0.0011240614112466574, "1": 0.0009174307924695313, "2": 0.0007756681879982352, "3": 0.000671824614983052, "4": 0.32778364419937134, "5": 0.0005299658514559269, "6": 0.0004793586558662355, "7": 0.00043757393723353744, "8": 0.00040248982259072363, "9": 0.00037261410034261644, "10": 0.21978889405727386, "11": 0.0003244483086746186, "12": 0.0003047514765057713, "13": 0.0002873093180824071, "14": 0.00027175567811354995, "15": 0.3806043565273285, "16": 0.00024520684382878244, "17": 0.00023378706828225404, "18": 0.0642310306429863, "19": 0.00021386667503975332}}, {"key": "hou2023large", "year": "2023", "title": "Large Language Models Are Zero-shot Rankers For Recommender Systems", "topic_distr": {"0": 0.05510120838880539, "1": 0.001106863608583808, "2": 0.0009357837843708694, "3": 0.40730732679367065, "4": 0.4925296902656555, "5": 0.000639361678622663, "6": 0.0005783080705441535, "7": 0.037597931921482086, "8": 0.0004855720035266131, "9": 0.0004495292960200459, "10": 0.0004184675635769963, "11": 0.00039142108289524913, "12": 0.0003676584456115961, "13": 0.0003466158523224294, "14": 0.00032785162329673767, "15": 0.00031101464992389083, "16": 0.00029582256684079766, "17": 0.00028204554109834135, "18": 0.00026949463062919676, "19": 0.00025801314041018486}}, {"key": "houlsby2019parameter", "year": "2019", "title": "Parameter-efficient Transfer Learning For NLP", "topic_distr": {"0": 0.0016624763375148177, "1": 0.0013583305990323424, "2": 0.42394667863845825, "3": 0.0009942544857040048, "4": 0.0008768922998569906, "5": 0.0007843156927265227, "6": 0.0007094201864674687, "7": 0.0006475815898738801, "8": 0.0005956593086011708, "9": 0.0005514451186172664, "10": 0.16199825704097748, "11": 0.0004801628238055855, "12": 0.0004510127764660865, "13": 0.2837672531604767, "14": 0.1194387748837471, "15": 0.000381526886485517, "16": 0.0003628905105870217, "17": 0.00034598997444845736, "18": 0.0003305935824755579, "19": 0.00031650904566049576}}, {"key": "hrinchuk2019correction", "year": "2019", "title": "Correction Of Automatic Speech Recognition With Transformer Sequence-to-sequence Model", "topic_distr": {"0": 0.0023535271175205708, "1": 0.14117294549942017, "2": 0.43593332171440125, "3": 0.0014068677555769682, "4": 0.0012407968752086163, "5": 0.0011098014656454325, "6": 0.0010038248728960752, "7": 0.22397808730602264, "8": 0.0008428539731539786, "9": 0.0007802912150509655, "10": 0.0007263743900693953, "11": 0.0006794272339902818, "12": 0.0006381800631061196, "13": 0.0006016544648446143, "14": 0.0005690835532732308, "15": 0.000539858010597527, "16": 0.0005134876701049507, "17": 0.1849939525127411, "18": 0.00046778772957623005, "19": 0.00044785821228288114}}, {"key": "hsieh2023distilling", "year": "2023", "title": "Distilling Step-by-step! Outperforming Larger Language Models With Less Training Data And Smaller Model Sizes", "topic_distr": {"0": 0.001022655749693513, "1": 0.054913006722927094, "2": 0.052790723741054535, "3": 0.24380122125148773, "4": 0.0005390581209212542, "5": 0.00048214770504273474, "6": 0.0004361066094134003, "7": 0.00039809211739338934, "8": 0.000366173597285524, "9": 0.0003389935300219804, "10": 0.00031556966132484376, "11": 0.00029517366783693433, "12": 0.0002772540901787579, "13": 0.5234101414680481, "14": 0.0002472354390192777, "15": 0.00023453855828847736, "16": 0.00022308209736365825, "17": 0.00021269272838253528, "18": 0.00020322800264693797, "19": 0.11949287354946136}}, {"key": "hsu2019knowledge", "year": "2019", "title": "Knowledge-enriched Visual Storytelling", "topic_distr": {"0": 0.0014011982129886746, "1": 0.0011443386320024729, "2": 0.2137383222579956, "3": 0.0008378096972592175, "4": 0.06469422578811646, "5": 0.0006609021802432835, "6": 0.0005977915716357529, "7": 0.35023418068885803, "8": 0.0005019311211071908, "9": 0.00046467414358630776, "10": 0.0004325659538153559, "11": 0.0004046082613058388, "12": 0.00038004503585398197, "13": 0.061300575733184814, "14": 0.00033889710903167725, "15": 0.0003214928728993982, "16": 0.1386028677225113, "17": 0.09654545038938522, "18": 0.06713143736124039, "19": 0.0002667057269718498}}, {"key": "hsu2022language", "year": "2022", "title": "Language Model Compression With Weighted Low-rank Factorization", "topic_distr": {"0": 0.15141716599464417, "1": 0.0010084756650030613, "2": 0.21427509188652039, "3": 0.0007382931071333587, "4": 0.0006511436076834798, "5": 0.0005823998944833875, "6": 0.0005267856176942587, "7": 0.0004808668454643339, "8": 0.0004423115751706064, "9": 0.00040947998058982193, "10": 0.0003811855858657509, "11": 0.0003565487277228385, "12": 0.00033490313217043877, "13": 0.6268064975738525, "14": 0.0002986427571158856, "15": 0.0002833058242686093, "16": 0.000269467243924737, "17": 0.0002569176140241325, "18": 0.0002454849018249661, "19": 0.000235026323935017}}, {"key": "htut2019do", "year": "2019", "title": "Do Attention Heads In BERT Track Syntactic Dependencies?", "topic_distr": {"0": 0.15101440250873566, "1": 0.0010610187891870737, "2": 0.5826773643493652, "3": 0.0007768349605612457, "4": 0.0006851398502476513, "5": 0.0006128067616373301, "6": 0.0005542889120988548, "7": 0.0005059727700427175, "8": 0.0004654045042116195, "9": 0.0004308587813284248, "10": 0.15575040876865387, "11": 0.0003751640033442527, "12": 0.000352388306055218, "13": 0.000332219700794667, "14": 0.0003142348141409457, "15": 0.00029809714760631323, "16": 0.10301751643419266, "17": 0.0002703311911318451, "18": 0.00025830158847384155, "19": 0.0002472969645168632}}, {"key": "hu2017reinforced", "year": "2017", "title": "Reinforced Mnemonic Reader For Machine Reading Comprehension", "topic_distr": {"0": 0.0015797518426552415, "1": 0.02798171155154705, "2": 0.5964723229408264, "3": 0.0009438992128707469, "4": 0.10308245569467545, "5": 0.0007445937371812761, "6": 0.0006734913331456482, "7": 0.0006147845415398479, "8": 0.14970983564853668, "9": 0.0005235169664956629, "10": 0.00048734285519458354, "11": 0.00045584479812532663, "12": 0.0004281710716895759, "13": 0.05163920670747757, "14": 0.00038181248237378895, "15": 0.0003622043295763433, "16": 0.06297627091407776, "17": 0.00032846719841472805, "18": 0.0003138505562674254, "19": 0.00030047932523302734}}, {"key": "hu2018attention", "year": "2018", "title": "Attention-guided Answer Distillation For Machine Reading Comprehension", "topic_distr": {"0": 0.0014018804067745805, "1": 0.08407406508922577, "2": 0.4138740301132202, "3": 0.0008378805941902101, "4": 0.000738976348657161, "5": 0.0006609593401663005, "6": 0.0005978432018309832, "7": 0.0005457305232994258, "8": 0.11357817053794861, "9": 0.00046471430687233806, "10": 0.0004326033522374928, "11": 0.00040464321500621736, "12": 0.027463681995868683, "13": 0.19325360655784607, "14": 0.0003389263874851167, "15": 0.0003215206670574844, "16": 0.07372888177633286, "17": 0.08673655241727829, "18": 0.00027859810506924987, "19": 0.00026672877720557153}}, {"key": "hu2019iterative", "year": "2019", "title": "Iterative Answer Prediction With Pointer-augmented Multimodal Transformers For Textvqa", "topic_distr": {"0": 0.0013145406264811754, "1": 0.0010720685822889209, "2": 0.2585673928260803, "3": 0.0007849372923374176, "4": 0.000692281813826412, "5": 0.0006191952270455658, "6": 0.0005600672448053956, "7": 0.029811518266797066, "8": 0.11125380545854568, "9": 0.00043535034637898207, "10": 0.13237258791923523, "11": 0.0003790749760810286, "12": 0.0003560618497431278, "13": 0.0003356829984113574, "14": 0.00031751059577800333, "15": 0.00030120470910333097, "16": 0.0002864918205887079, "17": 0.00027314931503497064, "18": 0.46001723408699036, "19": 0.00024987495271489024}}, {"key": "hu2019towards", "year": "2019", "title": "Retrieve, Read, Rerank: Towards End-to-end Multi-document Reading Comprehension", "topic_distr": {"0": 0.0014009317383170128, "1": 0.0011441721580922604, "2": 0.6304696798324585, "3": 0.0008378247148357332, "4": 0.0007389271631836891, "5": 0.00066091533517465, "6": 0.0005978035624139011, "7": 0.03255684673786163, "8": 0.27033042907714844, "9": 0.0004646834859158844, "10": 0.000432574626756832, "11": 0.00040461638127453625, "12": 0.00038005266105756164, "13": 0.0003583006910048425, "14": 0.00033890389022417367, "15": 0.0003214993339497596, "16": 0.0003057951107621193, "17": 0.00029155361698940396, "18": 0.00027857962413690984, "19": 0.057685960084199905}}, {"key": "hu2020massively", "year": "2020", "title": "XTREME: A Massively Multilingual Multi-task Benchmark For Evaluating Cross-lingual Generalization", "topic_distr": {"0": 0.0015041276346892118, "1": 0.0012271672021597624, "2": 0.001037304988130927, "3": 0.000898425467312336, "4": 0.0007923748926259577, "5": 0.0007087201229296625, "6": 0.000641043356154114, "7": 0.0005851649912074208, "8": 0.010999903082847595, "9": 0.000498294597491622, "10": 0.00046386325266212225, "11": 0.0004338827566243708, "12": 0.43909627199172974, "13": 0.00038421701174229383, "14": 0.3713488280773163, "15": 0.00034475376014597714, "16": 0.00032791364355944097, "17": 0.09901163727045059, "18": 0.00029872963204979897, "19": 0.06939733028411865}}, {"key": "hu2021low", "year": "2021", "title": "Lora: Low-rank Adaptation Of Large Language Models", "topic_distr": {"0": 0.0014346115058287978, "1": 0.0011709907557815313, "2": 0.06576913595199585, "3": 0.0008571842918172479, "4": 0.0007560000522062182, "5": 0.000676186173222959, "6": 0.0006116160657256842, "7": 0.0005583027959801257, "8": 0.0005135387764312327, "9": 0.000475420180009678, "10": 0.14512036740779877, "11": 0.0004139652010053396, "12": 0.04783939570188522, "13": 0.5542170405387878, "14": 0.00034673442132771015, "15": 0.00032892770832404494, "16": 0.03940878435969353, "17": 0.13894392549991608, "18": 0.0002850163436960429, "19": 0.0002728735562413931}}, {"key": "hu2022empowering", "year": "2022", "title": "Empowering Language Models With Knowledge Graph Reasoning For Question Answering", "topic_distr": {"0": 0.04373573884367943, "1": 0.001227129832841456, "2": 0.0580487921833992, "3": 0.0008985436870716512, "4": 0.0007924790261313319, "5": 0.0007088130223564804, "6": 0.0006411272333934903, "7": 0.000585241534281522, "8": 0.13602003455162048, "9": 0.0004983597900718451, "10": 0.08178141713142395, "11": 0.104908287525177, "12": 0.00040759562398307025, "13": 0.0003842672740574926, "14": 0.0003634647582657635, "15": 0.0003447988710831851, "16": 0.43072178959846497, "17": 0.015921443700790405, "18": 0.00029876871849410236, "19": 0.121711865067482}}, {"key": "hu2022fine", "year": "2022", "title": "A Fine-grained Comparison Of Pragmatic Language Understanding In Humans And Language Models", "topic_distr": {"0": 0.49514052271842957, "1": 0.058277469128370285, "2": 0.14814898371696472, "3": 0.1751081943511963, "4": 0.0008654367411509156, "5": 0.0007740699220448732, "6": 0.027611304074525833, "7": 0.0006391216884367168, "8": 0.0005878777010366321, "9": 0.000544241105671972, "10": 0.00050663499860093, "11": 0.00047389004612341523, "12": 0.0887908861041069, "13": 0.0004196447553113103, "14": 0.00039692706195637584, "15": 0.00037654268089681864, "16": 0.0003581497585400939, "17": 0.0003414700331632048, "18": 0.0003262747486587614, "19": 0.00031237423536367714}}, {"key": "hu2022learning", "year": "2022", "title": "In-context Learning For Few-shot Dialogue State Tracking", "topic_distr": {"0": 0.0017824869137257338, "1": 0.0014550219057127833, "2": 0.3513515293598175, "3": 0.0010652757482603192, "4": 0.0009395231027156115, "5": 0.18418528139591217, "6": 0.0007600892568007112, "7": 0.0006938339211046696, "8": 0.0006382031715475023, "9": 0.0005908310995437205, "10": 0.0005500056431628764, "11": 0.04613262414932251, "12": 0.0004832255362998694, "13": 0.00045556860277429223, "14": 0.0004309061332605779, "15": 0.0004087767447344959, "16": 0.00038880930515006185, "17": 0.3442838788032532, "18": 0.0003542056365404278, "19": 0.06304995715618134}}, {"key": "hu2022prompt", "year": "2022", "title": "Promptcap: Prompt-guided Task-aware Image Captioning", "topic_distr": {"0": 0.0010408477392047644, "1": 0.0008488792809657753, "2": 0.084230437874794, "3": 0.0006214632885530591, "4": 0.0005481006228365004, "5": 0.0004902353975921869, "6": 0.0004434220609255135, "7": 0.045643437653779984, "8": 0.1287684142589569, "9": 0.0003446799819357693, "10": 0.00032086315331980586, "11": 0.000300125073408708, "12": 0.00028190488228574395, "13": 0.0002657703298609704, "14": 0.0002513827057555318, "15": 0.00023847282864153385, "16": 0.03131354600191116, "17": 0.09884285926818848, "18": 0.5511471629142761, "19": 0.05405799299478531}}, {"key": "hu2022retrieval", "year": "2022", "title": "REVEAL: Retrieval-augmented Visual-language Pre-training With Multi-source Multimodal Knowledge Memory", "topic_distr": {"0": 0.0014185927575454116, "1": 0.0011574632953852415, "2": 0.07745424658060074, "3": 0.0008473224588669837, "4": 0.0007473035948351026, "5": 0.0006684080581180751, "6": 0.0006045808549970388, "7": 0.040109921246767044, "8": 0.1838545799255371, "9": 0.0004699515993706882, "10": 0.000437478709500283, "11": 0.00040920349420048296, "12": 0.0003843613085336983, "13": 0.0003623627417255193, "14": 0.00034274603240191936, "15": 0.00032514415215700865, "16": 0.38447853922843933, "17": 0.00029485896811820567, "18": 0.3053632378578186, "19": 0.00026973476633429527}}, {"key": "hu2023bad", "year": "2023", "title": "Bad Actor, Good Advisor: Exploring The Role Of Large Language Models In Fake News Detection", "topic_distr": {"0": 0.04869159683585167, "1": 0.02169737033545971, "2": 0.0007115699700079858, "3": 0.4396146237850189, "4": 0.0005435522180050611, "5": 0.0004861673805862665, "6": 0.0004397424927446991, "7": 0.0004014110891148448, "8": 0.00036922647268511355, "9": 0.05431625619530678, "10": 0.03915617614984512, "11": 0.06582231819629669, "12": 0.00027956560370512307, "13": 0.06031624600291252, "14": 0.0002492966887075454, "15": 0.2056022435426712, "16": 0.060687076300382614, "17": 0.00021446598111651838, "18": 0.00020492234034463763, "19": 0.00019619187514763325}}, {"key": "hu2023improving", "year": "2023", "title": "Improving Large Language Models For Clinical Named Entity Recognition Via Prompt Engineering", "topic_distr": {"0": 0.03483832627534866, "1": 0.06629285216331482, "2": 0.0007235188386403024, "3": 0.1955213099718094, "4": 0.0005526888417080045, "5": 0.0004943385720252991, "6": 0.00044713326497003436, "7": 0.0004081576189491898, "8": 0.0003754320496227592, "9": 0.08386743813753128, "10": 0.00032354859285987914, "11": 0.0003026369377039373, "12": 0.06014605984091759, "13": 0.14920346438884735, "14": 0.00025348662165924907, "15": 0.015454893000423908, "16": 0.04600708931684494, "17": 0.3443797528743744, "18": 0.00020836647308897227, "19": 0.00019948926637880504}}, {"key": "hu2023llm", "year": "2023", "title": "Llm-adapters: An Adapter Family For Parameter-efficient Fine-tuning Of Large Language Models", "topic_distr": {"0": 0.0012107141083106399, "1": 0.0009888504864647985, "2": 0.000835824990645051, "3": 0.6060382127761841, "4": 0.0006384857115335763, "5": 0.000571077864151448, "6": 0.000516544736456126, "7": 0.000471518695121631, "8": 0.00043371293577365577, "9": 0.0004015195881947875, "10": 0.00037377525586634874, "11": 0.00034961733035743237, "12": 0.06808881461620331, "13": 0.31752336025238037, "14": 0.0002928370959125459, "15": 0.00027779830270446837, "16": 0.00026422872906550765, "17": 0.00025192307657562196, "18": 0.0002407126157777384, "19": 0.00023045735724736005}}, {"key": "hu2023prompting", "year": "2023", "title": "Prompting Is Not A Substitute For Probability Measurements In Large Language Models", "topic_distr": {"0": 0.2886558771133423, "1": 0.001257741474546492, "2": 0.04654618352651596, "3": 0.3559296429157257, "4": 0.0008120242855511606, "5": 0.0007262949948199093, "6": 0.0006569399847649038, "7": 0.09619992226362228, "8": 0.021136125549674034, "9": 0.0005106513272039592, "10": 0.00047536619240418077, "11": 0.0004446422099135816, "12": 0.00041764858178794384, "13": 0.0003937448491342366, "14": 0.0003724292619153857, "15": 0.0003533029812388122, "16": 0.09702230989933014, "17": 0.08748994767665863, "18": 0.0003061375464312732, "19": 0.0002930949267465621}}, {"key": "hu2023simple", "year": "2023", "title": "BLIVA: A Simple Multimodal LLM For Better Handling Of Text-rich Visual Questions", "topic_distr": {"0": 0.0008733347640372813, "1": 0.000712227076292038, "2": 0.0006021091830916703, "3": 0.2824898660182953, "4": 0.00045993810635991395, "5": 0.000411380548030138, "6": 0.0003720971872098744, "7": 0.03363051638007164, "8": 0.03704988583922386, "9": 0.0002892378543037921, "10": 0.000269251991994679, "11": 0.0002518496476113796, "12": 0.17056898772716522, "13": 0.00022302089200820774, "14": 0.00021094753174111247, "15": 0.0002001142274821177, "16": 0.00019033928401768208, "17": 0.0491911880671978, "18": 0.4218376576900482, "19": 0.00016601179959252477}}, {"key": "hu2024findings", "year": "2024", "title": "Findings Of The Second Babylm Challenge: Sample-efficient Pretraining On Developmentally Plausible Corpora", "topic_distr": {"0": 0.08900532871484756, "1": 0.001095466548576951, "2": 0.32457631826400757, "3": 0.0008019096567295492, "4": 0.0007072506123222411, "5": 0.0006325826398096979, "6": 0.000572176359128207, "7": 0.03931872546672821, "8": 0.018458008766174316, "9": 0.0004447630199138075, "10": 0.0244187843054533, "11": 0.0003872709348797798, "12": 0.2445337027311325, "13": 0.00034294076613150537, "14": 0.0003243754617869854, "15": 0.00030771701131016016, "16": 0.000292686017928645, "17": 0.00027905506431125104, "18": 0.14757584035396576, "19": 0.10592509061098099}}, {"key": "hu2024prompting", "year": "2024", "title": "Prompting Large Language Models With Rationale Heuristics For Knowledge-based Visual Question Answering", "topic_distr": {"0": 0.0017562427092343569, "1": 0.0014341796049848199, "2": 0.0012125716311857104, "3": 0.5532805323600769, "4": 0.0009262647363357246, "5": 0.0008284756913781166, "6": 0.0007493632729165256, "7": 0.000684042926877737, "8": 0.10339124500751495, "9": 0.0005824936088174582, "10": 0.0005422442918643355, "11": 0.0936686098575592, "12": 0.00047640653792768717, "13": 0.0004491398576647043, "14": 0.00042482541175559163, "15": 0.00040300830733031034, "16": 0.0003833226510323584, "17": 0.13382111489772797, "18": 0.10465151816606522, "19": 0.0003343297285027802}}, {"key": "hua2019sentence", "year": "2019", "title": "Sentence-level Content Planning And Style Specification For Neural Text Generation", "topic_distr": {"0": 0.0013416192959994078, "1": 0.0010950993746519089, "2": 0.0009257564670406282, "3": 0.0008018168737180531, "4": 0.0007071709842421114, "5": 0.0006325111025944352, "6": 0.0005721115157939494, "7": 0.9897654056549072, "8": 0.0004803690826520324, "9": 0.000444712582975626, "10": 0.0004139837110415101, "11": 0.0003872270171996206, "12": 0.0003637189802248031, "13": 0.0003429018834140152, "14": 0.00032433870364911854, "15": 0.00030768211581744254, "16": 0.00029265283956192434, "17": 0.0002790233993437141, "18": 0.00026660700677894056, "19": 0.00025524853845126927}}, {"key": "hua2022transformer", "year": "2022", "title": "Transformer Quality In Linear Time", "topic_distr": {"0": 0.002227516146376729, "1": 0.0018186988309025764, "2": 0.39245933294296265, "3": 0.001331591745838523, "4": 0.0011744105722755194, "5": 0.0010504231322556734, "6": 0.0009501166641712189, "7": 0.00086729705799371, "8": 0.0007977582863532007, "9": 0.0007385428179986775, "10": 0.5032781958580017, "11": 0.0006430754438042641, "12": 0.0006040351581759751, "13": 0.06556423753499985, "14": 0.0005386355333030224, "15": 0.000510973681230098, "16": 0.0004860142362304032, "17": 0.00046337960520759225, "18": 0.0004427594249136746, "19": 0.024053022265434265}}, {"key": "hua2024large", "year": "2024", "title": "Large Language Models In Mental Health Care: A Scoping Review", "topic_distr": {"0": 0.0009448519558645785, "1": 0.31523454189300537, "2": 0.0006522777839563787, "3": 0.1298220157623291, "4": 0.0004982613609172404, "5": 0.00044565796270035207, "6": 0.00040310126496478915, "7": 0.00036796380300074816, "8": 0.011620988138020039, "9": 0.27405592799186707, "10": 0.0002916867670137435, "11": 0.0002728344115894288, "12": 0.21934393048286438, "13": 0.04483009874820709, "14": 0.0002285242371726781, "15": 0.00021678826306015253, "16": 0.0002061988489003852, "17": 0.00019659576355479658, "18": 0.0001878473412944004, "19": 0.00017984432633966208}}, {"key": "huang2019cosmos", "year": "2019", "title": "Cosmos QA: Machine Reading Comprehension With Contextual Commonsense Reasoning", "topic_distr": {"0": 0.0012239040806889534, "1": 0.0009985968936234713, "2": 0.48421794176101685, "3": 0.07093431800603867, "4": 0.0006447943742386997, "5": 0.0005767210968770087, "6": 0.0005216491408646107, "7": 0.01316273957490921, "8": 0.3142516314983368, "9": 0.00040548728429712355, "10": 0.00037746879388578236, "11": 0.0003530721296556294, "12": 0.09620172530412674, "13": 0.00031265662983059883, "14": 0.0002957308024633676, "15": 0.00028054340509697795, "16": 0.01451077964156866, "17": 0.00025441250181756914, "18": 0.000243091257289052, "19": 0.00023273465922102332}}, {"key": "huang2019transferable", "year": "2019", "title": "Transferable Representation Learning In Vision-and-language Navigation", "topic_distr": {"0": 0.07456442713737488, "1": 0.0013057345058768988, "2": 0.07538947463035583, "3": 0.0009560753242112696, "4": 0.0008432224858552217, "5": 0.0007542003295384347, "6": 0.089405357837677, "7": 0.0006227162666618824, "8": 0.0005727876559831202, "9": 0.0005302712088450789, "10": 0.12115801125764847, "11": 0.43143415451049805, "12": 0.0004336951533332467, "13": 0.00040887302020564675, "14": 0.0003867384511977434, "15": 0.00036687732790596783, "16": 0.0003489565278869122, "17": 0.0003327049489598721, "18": 0.1998814046382904, "19": 0.0003043559845536947}}, {"key": "huang2019universal", "year": "2019", "title": "Unicoder: A Universal Language Encoder By Pre-training With Multiple Cross-lingual Tasks", "topic_distr": {"0": 0.002011174103245139, "1": 0.0016429233364760876, "2": 0.6423661112785339, "3": 0.001202707295306027, "4": 0.0010607363656163216, "5": 0.0009487505303695798, "6": 0.0008581529255025089, "7": 0.000783349561970681, "8": 0.04475545138120651, "9": 0.0006670577568002045, "10": 0.24136292934417725, "11": 0.000580830848775804, "12": 0.02656916156411171, "13": 0.0005143442540429533, "14": 0.03257454186677933, "15": 0.00046151550486683846, "16": 0.00043897193972952664, "17": 0.0004185281286481768, "18": 0.000399903830839321, "19": 0.00038286641938611865}}, {"key": "huang2020trans", "year": "2020", "title": "TRANS-BLSTM: Transformer With Bidirectional LSTM For Language Understanding", "topic_distr": {"0": 0.0015023405430838466, "1": 0.0012271113228052855, "2": 0.2627977132797241, "3": 0.0008984534651972353, "4": 0.0007923994562588632, "5": 0.0007087430567480624, "6": 0.000641064194496721, "7": 0.0005851839669048786, "8": 0.061615239828825, "9": 0.0004983107792213559, "10": 0.49969619512557983, "11": 0.00043389684287831187, "12": 0.05144454911351204, "13": 0.0003842294972855598, "14": 0.11520446091890335, "15": 0.0003447649360168725, "16": 0.0003279242664575577, "17": 0.0003126522060483694, "18": 0.00029873932362534106, "19": 0.0002860118984244764}}, {"key": "huang2020unsupervised", "year": "2020", "title": "Unsupervised Multimodal Neural Machine Translation With Pseudo Visual Pivoting", "topic_distr": {"0": 0.0015413261717185378, "1": 0.0012573786079883575, "2": 0.29224419593811035, "3": 0.0009206528775393963, "4": 0.0008119746344164014, "5": 0.0007262513390742242, "6": 0.0006569004617631435, "7": 0.0005996398394927382, "8": 0.0005515614757314324, "9": 0.0005106205935589969, "10": 0.00047533755423501134, "11": 0.0004446154343895614, "12": 0.0004176234360784292, "13": 0.0003937211586162448, "14": 0.28812989592552185, "15": 0.00035328170633874834, "16": 0.00033602502662688494, "17": 0.00032037566415965557, "18": 0.40901559591293335, "19": 0.00029307728982530534}}, {"key": "huang2021seeing", "year": "2021", "title": "Seeing Out Of The Box: End-to-end Pre-training For Vision-language Representation Learning", "topic_distr": {"0": 0.0012230075662955642, "1": 0.0009985520737245679, "2": 0.35712289810180664, "3": 0.0007310946239158511, "4": 0.0006447969353757799, "5": 0.0005767233669757843, "6": 0.0005216511781327426, "7": 0.00047617993550375104, "8": 0.00043800045386888087, "9": 0.0004054888559039682, "10": 0.06645658612251282, "11": 0.0003530735266394913, "12": 0.00033163890475407243, "13": 0.000312657852191478, "14": 0.00029573196661658585, "15": 0.0002805445110425353, "16": 0.0002668407978489995, "17": 0.00025441349134780467, "18": 0.5680773854255676, "19": 0.00023273556143976748}}, {"key": "huang2021unifying", "year": "2021", "title": "Unifying Multimodal Transformer For Bi-directional Image And Text Generation", "topic_distr": {"0": 0.0015580360777676105, "1": 0.0012730166781693697, "2": 0.11046426743268967, "3": 0.0009320478420704603, "4": 0.0008220287272706628, "5": 0.0007352433749474585, "6": 0.0006650338182225823, "7": 0.000607064226642251, "8": 0.0005583906313404441, "9": 0.0005169427604414523, "10": 0.2844429314136505, "11": 0.00045012039481662214, "12": 0.00042279419722035527, "13": 0.0003985959629062563, "14": 0.00037701777182519436, "15": 0.21944336593151093, "16": 0.0003401855065021664, "17": 0.0003243423707317561, "18": 0.37537187337875366, "19": 0.00029670598451048136}}, {"key": "huang2022are", "year": "2022", "title": "Are Large Pre-trained Language Models Leaking Your Personal Information?", "topic_distr": {"0": 0.17741358280181885, "1": 0.028625555336475372, "2": 0.001484291860833764, "3": 0.0012856157263740897, "4": 0.0011338579934090376, "5": 0.0010141526581719518, "6": 0.0009173096041195095, "7": 0.0008373496821150184, "8": 0.05567276105284691, "9": 0.19289420545101166, "10": 0.0006637713522650301, "11": 0.0006208703271113336, "12": 0.0005831781309098005, "13": 0.0005498005193658173, "14": 0.0005200367304496467, "15": 0.4245621860027313, "16": 0.00046923241461627185, "17": 0.10991549491882324, "18": 0.0004274711536709219, "19": 0.00040925925713963807}}, {"key": "huang2022inner", "year": "2022", "title": "Inner Monologue: Embodied Reasoning Through Planning With Language Models", "topic_distr": {"0": 0.09317957609891891, "1": 0.0009176328312605619, "2": 0.0007756010163575411, "3": 0.40732815861701965, "4": 0.0005924790166318417, "5": 0.013188441284000874, "6": 0.07643004506826401, "7": 0.0004375425633043051, "8": 0.000402460980694741, "9": 0.00037258738302625716, "10": 0.0003468422219157219, "11": 0.40399089455604553, "12": 0.00030472961952909827, "13": 0.00028728871257044375, "14": 0.00027173617854714394, "15": 0.0002577810373622924, "16": 0.00024518926511518657, "17": 0.0002337703190278262, "18": 0.0002233676495961845, "19": 0.00021385133732110262}}, {"key": "huang2022language", "year": "2022", "title": "Language Models As Zero-shot Planners: Extracting Actionable Knowledge For Embodied Agents", "topic_distr": {"0": 0.0015036625554785132, "1": 0.0012271743034943938, "2": 0.0010373262921348214, "3": 0.40125593543052673, "4": 0.0007923979428596795, "5": 0.0007087411941029131, "6": 0.0006410622736439109, "7": 0.0005851822788827121, "8": 0.000538263120688498, "9": 0.0004983092658221722, "10": 0.00046387696056626737, "11": 0.4290967583656311, "12": 0.00040755432564765215, "13": 0.00038422836223617196, "14": 0.00036342794192023575, "15": 0.00034476391738280654, "16": 0.0813804566860199, "17": 0.0003126512747257948, "18": 0.00029873845051042736, "19": 0.07815946638584137}}, {"key": "huang2022large", "year": "2022", "title": "Large Language Models Can Self-improve", "topic_distr": {"0": 0.04784753546118736, "1": 0.0015430316561833024, "2": 0.0637865960597992, "3": 0.6212567687034607, "4": 0.0009965072385966778, "5": 0.0859033539891243, "6": 0.0008061907719820738, "7": 0.0007359168957918882, "8": 0.04425094649195671, "9": 0.0006266666459850967, "10": 0.0005833650357089937, "11": 0.0005456608487293124, "12": 0.0005125345196574926, "13": 0.04128909856081009, "14": 0.00045704180956818163, "15": 0.00043357021058909595, "16": 0.00041239167330786586, "17": 0.08727745711803436, "18": 0.0003756892110686749, "19": 0.00035968341398984194}}, {"key": "huang2022pre", "year": "2022", "title": "Layoutlmv3: Pre-training For Document AI With Unified Text And Image Masking", "topic_distr": {"0": 0.0014369762502610683, "1": 0.001170863164588809, "2": 0.0009895556140691042, "3": 0.0008570770150981843, "4": 0.0007559037767350674, "5": 0.0006761003169231117, "6": 0.0006115383584983647, "7": 0.0005582318990491331, "8": 0.08960504829883575, "9": 0.059981126338243484, "10": 0.44727393984794617, "11": 0.00041391263948753476, "12": 0.0003887845668941736, "13": 0.00036653285496868193, "14": 0.0003466903872322291, "15": 0.00032888594432733953, "16": 0.0003128209209535271, "17": 0.0002982522128149867, "18": 0.3933549225330353, "19": 0.0002728388935793191}}, {"key": "huang2022towards", "year": "2022", "title": "Towards Reasoning In Large Language Models: A Survey", "topic_distr": {"0": 0.08832847326993942, "1": 0.0012889719801023602, "2": 0.0010897449683398008, "3": 0.2532022297382355, "4": 0.0008324528462253511, "5": 0.0007445679511874914, "6": 0.0006734678754583001, "7": 0.0006147631793282926, "8": 0.0005654722335748374, "9": 0.0907268226146698, "10": 0.00048732588766142726, "11": 0.10811687260866165, "12": 0.45089396834373474, "13": 0.0004036510654259473, "14": 0.0003817991819232702, "15": 0.00036219172761775553, "16": 0.0003444998001214117, "17": 0.00032845576060935855, "18": 0.00031383964233100414, "19": 0.00030046887695789337}}, {"key": "huang2023c", "year": "2023", "title": "C-eval: A Multi-level Multi-discipline Chinese Evaluation Suite For Foundation Models", "topic_distr": {"0": 0.001467682421207428, "1": 0.0011982297291979194, "2": 0.001012918190099299, "3": 0.40989744663238525, "4": 0.026210712268948555, "5": 0.0006920714513398707, "6": 0.0006259845104068518, "7": 0.0005714187864214182, "8": 0.04623666778206825, "9": 0.039422646164894104, "10": 0.0004529665457084775, "11": 0.0004236903041601181, "12": 0.4695243239402771, "13": 0.00037519127363339067, "14": 0.00035488008870743215, "15": 0.0003366550663486123, "16": 0.00032021052902564406, "17": 0.00030529769719578326, "18": 0.0002917120873462409, "19": 0.0002792840532492846}}, {"key": "huang2023chatgpt", "year": "2023", "title": "Chatgpt For Shaping The Future Of Dentistry: The Potential Of Multi-modal Large Language Model", "topic_distr": {"0": 0.05095064640045166, "1": 0.0010187439620494843, "2": 0.0008609013166278601, "3": 0.1497933715581894, "4": 0.0006576438900083303, "5": 0.0005882133264094591, "6": 0.0005320439231581986, "7": 0.0004856667947024107, "8": 0.00044672665535472333, "9": 0.44348108768463135, "10": 0.0654449388384819, "11": 0.00036010771873407066, "12": 0.09753802418708801, "13": 0.1523093581199646, "14": 0.0003016237751580775, "15": 0.00028613372705876827, "16": 0.0002721570199355483, "17": 0.00025948212714865804, "18": 0.017037950456142426, "19": 0.01737518608570099}}, {"key": "huang2023diversity", "year": "2023", "title": "Diversity-aware Meta Visual Prompting", "topic_distr": {"0": 0.0010750370565801859, "1": 0.09775842726230621, "2": 0.0007422324270009995, "3": 0.18022184073925018, "4": 0.000566971895750612, "5": 0.0005071142222732306, "6": 0.0004586891154758632, "7": 0.00041870615677908063, "8": 0.0003851348301395774, "9": 0.0003565473307389766, "10": 0.00033191050169989467, "11": 0.0003104583884123713, "12": 0.00029161086422391236, "13": 0.106257364153862, "14": 0.00026003780658356845, "15": 0.0002466834557708353, "16": 0.00023463375691790134, "17": 0.4435183107852936, "18": 0.1438429057598114, "19": 0.022215349599719048}}, {"key": "huang2023empower", "year": "2023", "title": "Vtimellm: Empower LLM To Grasp Video Moments", "topic_distr": {"0": 0.0012149412650614977, "1": 0.04893536865711212, "2": 0.0008361866930499673, "3": 0.23976458609104156, "4": 0.0006387158064171672, "5": 0.01518965233117342, "6": 0.0005167300696484745, "7": 0.0004716878174804151, "8": 0.000433868495747447, "9": 0.0004016636230517179, "10": 0.0003739093372132629, "11": 0.00034974273876287043, "12": 0.0003285103302914649, "13": 0.0003097083535976708, "14": 0.00029294213163666427, "15": 0.0002778979542199522, "16": 0.014703252352774143, "17": 0.02836749702692032, "18": 0.6463626027107239, "19": 0.00023054001212585717}}, {"key": "huang2023is", "year": "2023", "title": "Is Chatgpt Better Than Human Annotators? Potential And Limitations Of Chatgpt In Explaining Implicit Hate Speech", "topic_distr": {"0": 0.0023552419152110815, "1": 0.3087961971759796, "2": 0.001624363474547863, "3": 0.0014069202588871121, "4": 0.0012408437905833125, "5": 0.30893605947494507, "6": 0.0010038625914603472, "7": 0.000916358083486557, "8": 0.0008428856381215155, "9": 0.2645963728427887, "10": 0.0007264016894623637, "11": 0.0006794527289457619, "12": 0.04027083143591881, "13": 0.0006016770494170487, "14": 0.000569104973692447, "15": 0.0005398783250711858, "16": 0.0005135069950483739, "17": 0.06346435099840164, "18": 0.0004678053082898259, "19": 0.00044787503429688513}}, {"key": "huang2023language", "year": "2023", "title": "Language Is Not All You Need: Aligning Perception With Language Models", "topic_distr": {"0": 0.0012351882178336382, "1": 0.0010084890527650714, "2": 0.0008524226141162217, "3": 0.11013840138912201, "4": 0.000651155598461628, "5": 0.01332836039364338, "6": 0.0005267956294119358, "7": 0.0004808759840670973, "8": 0.03074837103486061, "9": 0.02473161742091179, "10": 0.00038119283271953464, "11": 0.08464159071445465, "12": 0.00033490947680547833, "13": 0.00031574125750921667, "14": 0.0002986484323628247, "15": 0.0002833112084772438, "16": 0.01126696914434433, "17": 0.08350471407175064, "18": 0.5408619046211243, "19": 0.09440936148166656}}, {"key": "huang2023large", "year": "2023", "title": "Large Language Models Cannot Self-correct Reasoning Yet", "topic_distr": {"0": 0.001686425064690411, "1": 0.001376452622935176, "2": 0.0011634413385763764, "3": 0.46864524483680725, "4": 0.0008887498406693339, "5": 0.0007949204882606864, "6": 0.03420746326446533, "7": 0.06473926454782486, "8": 0.0006037133280187845, "9": 0.3752234876155853, "10": 0.0005202821339480579, "11": 0.0004866551607847214, "12": 0.0004571109893731773, "13": 0.00043094868306070566, "14": 0.00040761902346275747, "15": 0.00038668556953780353, "16": 0.046975016593933105, "17": 0.0003506681532599032, "18": 0.00033506358158774674, "19": 0.00032078861841000617}}, {"key": "huang2023lawyer", "year": "2023", "title": "Lawyer Llama Technical Report", "topic_distr": {"0": 0.018583618104457855, "1": 0.001132054952904582, "2": 0.0009566505323164165, "3": 0.27537593245506287, "4": 0.0007307758205570281, "5": 0.0006536240689456463, "6": 0.0005912084016017616, "7": 0.0005396740161813796, "8": 0.04954929277300835, "9": 0.24933753907680511, "10": 0.0004278023261576891, "11": 0.1280265897512436, "12": 0.07590778917074203, "13": 0.00035434780875220895, "14": 0.00033516500843688846, "15": 0.038581691682338715, "16": 0.10374881327152252, "17": 0.00028833711985498667, "18": 0.00027550625964067876, "19": 0.054603639990091324}}, {"key": "huang2023make", "year": "2023", "title": "Make-an-audio: Text-to-audio Generation With Prompt-enhanced Diffusion Models", "topic_distr": {"0": 0.0016416951548308134, "1": 0.08255010098218918, "2": 0.0011328199179843068, "3": 0.0009811469353735447, "4": 0.0008653313270770013, "5": 0.000773975218180567, "6": 0.0007000672048889101, "7": 0.0006390438065864146, "8": 0.0005878061056137085, "9": 0.0005441748653538525, "10": 0.0005065732984803617, "11": 0.00047383233322761953, "12": 0.0004450666019693017, "13": 0.00041959364898502827, "14": 0.0003968787204939872, "15": 0.19203776121139526, "16": 0.0003581061610020697, "17": 0.11116533726453781, "18": 0.5007256865501404, "19": 0.103054940700531}}, {"key": "huang2023not", "year": "2023", "title": "Not All Languages Are Created Equal In Llms: Improving Multilingual Capability By Cross-lingual-thought Prompting", "topic_distr": {"0": 0.0016402009641751647, "1": 0.0013398953014984727, "2": 0.050662536174058914, "3": 0.8225489854812622, "4": 0.0008653327240608633, "5": 0.000773975916672498, "6": 0.0007000677869655192, "7": 0.01621387153863907, "8": 0.0005878066294826567, "9": 0.0005441753310151398, "10": 0.000506573764141649, "11": 0.0004738327406812459, "12": 0.0004450670094229281, "13": 0.0004195940273348242, "14": 0.10056349635124207, "15": 0.0003764971625059843, "16": 0.00035810648114420474, "17": 0.0003414287348277867, "18": 0.0003262353129684925, "19": 0.0003123364585917443}}, {"key": "huang2023survey", "year": "2023", "title": "A Survey On Hallucination In Large Language Models: Principles, Taxonomy, Challenges, And Open Questions", "topic_distr": {"0": 0.319459468126297, "1": 0.0009344405261799693, "2": 0.0007898133480921388, "3": 0.0006841009017080069, "4": 0.0006033466197550297, "5": 0.0005396491033025086, "6": 0.00048811716260388494, "7": 0.00044556905049830675, "8": 0.044512249529361725, "9": 0.34773609042167664, "10": 0.0003532048431225121, "11": 0.00033037643879652023, "12": 0.26757702231407166, "13": 0.00029255886329337955, "14": 0.00027672102442011237, "15": 0.014044332318007946, "16": 0.0002496871165931225, "17": 0.00023805869568604976, "18": 0.00022746519243810326, "19": 0.0002177743153879419}}, {"key": "huang2023understanding", "year": "2023", "title": "Audiogpt: Understanding And Generating Speech, Music, Sound, And Talking Head", "topic_distr": {"0": 0.001341477851383388, "1": 0.11765435338020325, "2": 0.034220192581415176, "3": 0.2720842957496643, "4": 0.0007071736035868526, "5": 0.05611646547913551, "6": 0.12173063308000565, "7": 0.0005222444888204336, "8": 0.00048037158558145165, "9": 0.16660024225711823, "10": 0.00041398583562113345, "11": 0.0003872290253639221, "12": 0.0003637208719737828, "13": 0.0003429036296438426, "14": 0.0003243403625674546, "15": 0.00030768371652811766, "16": 0.0002926543529611081, "17": 0.00027902485453523695, "18": 0.2255757451057434, "19": 0.0002552498481236398}}, {"key": "huang2024pushing", "year": "2024", "title": "Billm: Pushing The Limit Of Post-training Quantization For Llms", "topic_distr": {"0": 0.0011998828267678618, "1": 0.0009791733464226127, "2": 0.000827890879008919, "3": 0.000717039976734668, "4": 0.0006323966663330793, "5": 0.0005656318389810622, "6": 0.09774670004844666, "7": 0.0004670220660045743, "8": 0.00042957684490829706, "9": 0.23688843846321106, "10": 0.0003702107642311603, "11": 0.0003462832246441394, "12": 0.0003252608294133097, "13": 0.6251917481422424, "14": 0.0002900444669649005, "15": 0.00027514909743331373, "16": 0.00026170891942456365, "17": 0.0002495206135790795, "18": 0.00023841708025429398, "19": 0.03199787437915802}}, {"key": "huang2024trustworthiness", "year": "2024", "title": "Trustllm: Trustworthiness In Large Language Models", "topic_distr": {"0": 0.15108206868171692, "1": 0.0007895454182289541, "2": 0.0006674301694147289, "3": 0.4596644937992096, "4": 0.0005098319961689413, "5": 0.0004560067900456488, "6": 0.0004124620172660798, "7": 0.0003765086003113538, "8": 0.0003463206230662763, "9": 0.19379734992980957, "10": 0.0002984602760989219, "11": 0.0002791701117530465, "12": 0.18982914090156555, "13": 0.000247214047703892, "14": 0.00023383097141049802, "15": 0.00022182248358149081, "16": 0.00021098715660627931, "17": 0.00020116106315981597, "18": 0.00019220949616283178, "19": 0.000184020638698712}}, {"key": "huo2021bridging", "year": "2021", "title": "Wenlan: Bridging Vision And Language By Large-scale Multi-modal Pre-training", "topic_distr": {"0": 0.0897381380200386, "1": 0.0012894589453935623, "2": 0.0010899404296651483, "3": 0.0009440120775252581, "4": 0.13987953960895538, "5": 0.0007446810486726463, "6": 0.0006735703209415078, "7": 0.0006148566608317196, "8": 0.0005655582644976676, "9": 0.0005235783755779266, "10": 0.0004873999860137701, "11": 0.00045589826186187565, "12": 0.0004282212757971138, "13": 0.13501526415348053, "14": 0.0003818572440650314, "15": 0.07177244126796722, "16": 0.09798047691583633, "17": 0.0003285057027824223, "18": 0.4567860960960388, "19": 0.00030051456997171044}}, {"key": "huo2023retrieving", "year": "2023", "title": "Retrieving Supporting Evidence For Generative Question Answering", "topic_distr": {"0": 0.25078293681144714, "1": 0.028452549129724503, "2": 0.030429892241954803, "3": 0.278159499168396, "4": 0.0004443878133315593, "5": 0.0003974720893893391, "6": 0.0003595168818719685, "7": 0.00032817854662425816, "8": 0.3396136462688446, "9": 0.00027945893816649914, "10": 0.00026014880859293044, "11": 0.00024333481269422919, "12": 0.00022856227587908506, "13": 0.00021548072982113808, "14": 0.00020381556532811373, "15": 0.013734965585172176, "16": 0.00018390406330581754, "17": 0.00017533928621560335, "18": 0.00016753676754888147, "19": 0.05533941835165024}}, {"key": "hutchins2022block", "year": "2022", "title": "Block-recurrent Transformers", "topic_distr": {"0": 0.0014165297616273165, "1": 0.0011572405928745866, "2": 0.39912864565849304, "3": 0.0008473777561448514, "4": 0.0007473529549315572, "5": 0.0006684522377327085, "6": 0.0006046206690371037, "7": 0.0005519171827472746, "8": 0.0005076651577837765, "9": 0.00046998256584629416, "10": 0.43983328342437744, "11": 0.00040923047345131636, "12": 0.0003843866288661957, "13": 0.15144973993301392, "14": 0.00034276864607818425, "15": 0.00032516560168005526, "16": 0.0003092822735197842, "17": 0.00029487840947695076, "18": 0.0002817564527504146, "19": 0.00026975254877470434}}, {"key": "ilievski2018goal", "year": "2018", "title": "Goal-oriented Chatbot Dialog Management Bootstrapping With Transfer Learning", "topic_distr": {"0": 0.0011043791892006993, "1": 0.03951821103692055, "2": 0.2725830376148224, "3": 0.0006599025800824165, "4": 0.08466257154941559, "5": 0.12202921509742737, "6": 0.0004708532360382378, "7": 0.0004298099665902555, "8": 0.0003953483537770808, "9": 0.06203155592083931, "10": 0.0003407125477679074, "11": 0.2601591944694519, "12": 0.00029934418853372335, "13": 0.0002822115202434361, "14": 0.15388047695159912, "15": 0.0002532253274694085, "16": 0.00024085608310997486, "17": 0.00022963892843108624, "18": 0.00021942010789643973, "19": 0.00021007198665756732}}, {"key": "imani2023mathematical", "year": "2023", "title": "Mathprompter: Mathematical Reasoning Using Large Language Models", "topic_distr": {"0": 0.0014183040475472808, "1": 0.0011572047369554639, "2": 0.0009783442365005612, "3": 0.9563198089599609, "4": 0.0007473406731151044, "5": 0.0006684412946924567, "6": 0.0006046108901500702, "7": 0.000551908160559833, "8": 0.0005076568922959268, "9": 0.0004699748824350536, "10": 0.0004375004209578037, "11": 0.00040922380867414176, "12": 0.0003843803715426475, "13": 0.018880663439631462, "14": 0.00034276305814273655, "15": 0.0003251602756790817, "16": 0.014950383454561234, "17": 0.00029487357824109495, "18": 0.00028175185434520245, "19": 0.00026974815409630537}}, {"key": "inan2023llama", "year": "2023", "title": "Llama Guard: Llm-based Input-output Safeguard For Human-ai Conversations", "topic_distr": {"0": 0.0012360825203359127, "1": 0.0010084633249789476, "2": 0.0008524461300112307, "3": 0.20954492688179016, "4": 0.0006511686951853335, "5": 0.0005824224790558219, "6": 0.08043692260980606, "7": 0.05516047775745392, "8": 0.0004423286591190845, "9": 0.1650974303483963, "10": 0.000381200312403962, "11": 0.00035656249383464456, "12": 0.30573320388793945, "13": 0.02142057940363884, "14": 0.00029865431133657694, "15": 0.000283316767308861, "16": 0.00026947763399221003, "17": 0.15576381981372833, "18": 0.00024549438967369497, "19": 0.00023503538977820426}}, {"key": "inie2023designing", "year": "2023", "title": "Designing Participatory AI: Creative Professionals' Worries And Expectations About Generative AI", "topic_distr": {"0": 0.0018891444196924567, "1": 0.0015427481848746538, "2": 0.001304325764067471, "3": 0.0011297358432784677, "4": 0.0009963810443878174, "5": 0.0008911897893995047, "6": 0.0008060886757448316, "7": 0.0007358236471191049, "8": 0.0006768262246623635, "9": 0.7155275344848633, "10": 0.0005832911119796336, "11": 0.0005455917562358081, "12": 0.0005124696181155741, "13": 0.0004831388941965997, "14": 0.00045698389294557273, "15": 0.18856900930404663, "16": 0.000412339431932196, "17": 0.06008625775575638, "18": 0.02249150164425373, "19": 0.0003596378373913467}}, {"key": "irie2019language", "year": "2019", "title": "Language Modeling With Deep Transformers", "topic_distr": {"0": 0.0015041863080114126, "1": 0.08372388035058975, "2": 0.42056161165237427, "3": 0.0008984393789432943, "4": 0.0007923829834908247, "5": 0.0007087282720021904, "6": 0.0006410506903193891, "7": 0.02333047054708004, "8": 0.0005382533418014646, "9": 0.0004983002436347306, "10": 0.46364355087280273, "11": 0.00043388770427554846, "12": 0.0004075469623785466, "13": 0.0003842214064206928, "14": 0.00036342136445455253, "15": 0.0003447576891630888, "16": 0.00032791736884973943, "17": 0.00031264559947885573, "18": 0.0002987330371979624, "19": 0.00028600587393157184}}, {"key": "ishmam2023from", "year": "2023", "title": "From Image To Language: A Critical Analysis Of Visual Question Answering (VQA) Approaches, Challenges, And Opportunities", "topic_distr": {"0": 0.0010393172269687057, "1": 0.02246171422302723, "2": 0.0007175152422860265, "3": 0.03464602679014206, "4": 0.0005480980034917593, "5": 0.0004902323707938194, "6": 0.0004434193251654506, "7": 0.0004047674301546067, "8": 0.07274836301803589, "9": 0.07787393778562546, "10": 0.0003208611742593348, "11": 0.04465281963348389, "12": 0.29893237352371216, "13": 0.00026576867094263434, "14": 0.0002513811341486871, "15": 0.04573768749833107, "16": 0.00022682278358843178, "17": 0.0002162591990781948, "18": 0.39782479405403137, "19": 0.00019783229799941182}}, {"key": "ive2019distilling", "year": "2019", "title": "Distilling Translations With Visual Awareness", "topic_distr": {"0": 0.001950276317074895, "1": 0.0015915210824459791, "2": 0.5349429249763489, "3": 0.057499807327985764, "4": 0.0010276457760483027, "5": 0.000919153681024909, "6": 0.0008313822327181697, "7": 0.0007589124725200236, "8": 0.0006980638136155903, "9": 0.000646248459815979, "10": 0.0006015937542542815, "11": 0.0005627113860100508, "12": 0.0005285499501042068, "13": 0.021730121225118637, "14": 0.11046969890594482, "15": 0.00044711818918585777, "16": 0.00042527788900770247, "17": 0.0004054718592669815, "18": 0.2635926306247711, "19": 0.000370922643924132}}, {"key": "ivgi2022efficient", "year": "2022", "title": "Efficient Long-text Understanding With Short-text Models", "topic_distr": {"0": 0.0015037902630865574, "1": 0.001227070577442646, "2": 0.3018589913845062, "3": 0.0008984851301647723, "4": 0.07794451713562012, "5": 0.0007087662233971059, "6": 0.0006410849746316671, "7": 0.06876099854707718, "8": 0.0005382821545936167, "9": 0.0004983269027434289, "10": 0.31436046957969666, "11": 0.0004339109000284225, "12": 0.0004075687611475587, "13": 0.00038424195372499526, "14": 0.00036344080581329763, "15": 0.03163917362689972, "16": 0.00032793491845950484, "17": 0.00031266233418136835, "18": 0.00029874901520088315, "19": 0.19689151644706726}}, {"key": "iyer2022opt", "year": "2022", "title": "OPT-IML: Scaling Language Model Instruction Meta Learning Through The Lens Of Generalization", "topic_distr": {"0": 0.0011662031756713986, "1": 0.05042283982038498, "2": 0.0008046049624681473, "3": 0.20938344299793243, "4": 0.0006146218511275947, "5": 0.01621539145708084, "6": 0.0004972388851456344, "7": 0.00045389565639197826, "8": 0.000417502858908847, "9": 0.00038651275099255145, "10": 0.0003598053881432861, "11": 0.12609443068504333, "12": 0.27478498220443726, "13": 0.08333650976419449, "14": 0.0002818922803271562, "15": 0.00026741556939668953, "16": 0.00025435315910726786, "17": 0.23380479216575623, "18": 0.00023171596694737673, "19": 0.00022184399131219834}}, {"key": "izacard2020leveraging", "year": "2020", "title": "Leveraging Passage Retrieval With Generative Models For Open Domain Question Answering", "topic_distr": {"0": 0.002011968055739999, "1": 0.001642512041144073, "2": 0.2180221527814865, "3": 0.0012026609620079398, "4": 0.0010606960859149694, "5": 0.0009487150236964226, "6": 0.0008581206784583628, "7": 0.0007833201088942587, "8": 0.36014968156814575, "9": 0.0006670326692983508, "10": 0.0006209418643265963, "11": 0.0005808090209029615, "12": 0.10131262242794037, "13": 0.1339939534664154, "14": 0.00048648164374753833, "15": 0.12156800925731659, "16": 0.00043895543785765767, "17": 0.00041851241257973015, "18": 0.0003998887841589749, "19": 0.05283299833536148}}, {"key": "izacard2022few", "year": "2022", "title": "Atlas: Few-shot Learning With Retrieval Augmented Language Models", "topic_distr": {"0": 0.0017345088999718428, "1": 0.00141488341614604, "2": 0.10447561740875244, "3": 0.3042474091053009, "4": 0.0009134514257311821, "5": 0.0008170147775672376, "6": 0.0007389966631308198, "7": 0.0006745799328200519, "8": 0.1447449028491974, "9": 0.0005744354566559196, "10": 0.0005347429541870952, "11": 0.0005001813406124711, "12": 0.0004698159755207598, "13": 0.1913479119539261, "14": 0.00041894844616763294, "15": 0.07896879315376282, "16": 0.09972702711820602, "17": 0.00036041467683389783, "18": 0.0003443763707764447, "19": 0.06699203699827194}}, {"key": "jablonka2023examples", "year": "2023", "title": "14 Examples Of How Llms Can Transform Materials Science And Chemistry: A Reflection On A Large Language Model Hackathon", "topic_distr": {"0": 0.06782438606023788, "1": 0.0014552221400663257, "2": 0.0012298650108277798, "3": 0.001065242337062955, "4": 0.0009394996450282633, "5": 0.000840313034132123, "6": 0.0007600702811032534, "7": 0.0006938165752217174, "8": 0.0006381872808560729, "9": 0.7720426321029663, "10": 0.0005499919061549008, "11": 0.0005144447204656899, "12": 0.10438576340675354, "13": 0.00045555722317658365, "14": 0.0004308953939471394, "15": 0.000408766558393836, "16": 0.044701337814331055, "17": 0.0003706924326252192, "18": 0.00035419678897596896, "19": 0.00033910665661096573}}, {"key": "jahan2023comprehensive", "year": "2023", "title": "A Comprehensive Evaluation Of Large Language Models On Benchmark Biomedical Text Processing Tasks", "topic_distr": {"0": 0.0010392501717433333, "1": 0.0008488476742058992, "2": 0.000717382354196161, "3": 0.45659542083740234, "4": 0.0005480037652887404, "5": 0.0004901490174233913, "6": 0.0004433439171407372, "7": 0.0004046985995955765, "8": 0.00037225038977339864, "9": 0.0003446192422416061, "10": 0.0003208066336810589, "11": 0.0003000721917487681, "12": 0.12879711389541626, "13": 0.0002657235017977655, "14": 0.00025133840972557664, "15": 0.35069647431373596, "16": 0.0002267842210130766, "17": 0.00021622242638841271, "18": 0.0002066006272798404, "19": 0.05691490322351456}}, {"key": "jahan2023evaluation", "year": "2023", "title": "Evaluation Of Chatgpt On Biomedical Tasks: A Zero-shot Comparison With Fine-tuned Generative Transformers", "topic_distr": {"0": 0.0014021217357367277, "1": 0.043889787048101425, "2": 0.000967290485277772, "3": 0.19101986289024353, "4": 0.0007389024831354618, "5": 0.0006608938565477729, "6": 0.0005977840628474951, "7": 0.0005456765647977591, "8": 0.03539777919650078, "9": 0.1657208502292633, "10": 0.0732511430978775, "11": 0.0004046032263431698, "12": 0.0003800402919296175, "13": 0.0003582890494726598, "14": 0.000338892888976261, "15": 0.4677742123603821, "16": 0.015715021640062332, "17": 0.0002915441582445055, "18": 0.0002785705728456378, "19": 0.00026670240913517773}}, {"key": "jain2019attention", "year": "2019", "title": "Attention Is Not Explanation", "topic_distr": {"0": 0.23287628591060638, "1": 0.0011707475641742349, "2": 0.39446601271629333, "3": 0.07448519766330719, "4": 0.0007559912046417594, "5": 0.1475270837545395, "6": 0.0006116090808063745, "7": 0.0005582964513450861, "8": 0.0005135329556651413, "9": 0.00047541476669721305, "10": 0.14354579150676727, "11": 0.00041396048618480563, "12": 0.0003888295032083988, "13": 0.0003665752010419965, "14": 0.00034673046320676804, "15": 0.000328923953929916, "16": 0.00031285706791095436, "17": 0.00029828670085407794, "18": 0.00028501308406703174, "19": 0.0002728704421315342}}, {"key": "jain2019stay", "year": "2019", "title": "Stay On The Path: Instruction Fidelity In Vision-and-language Navigation", "topic_distr": {"0": 0.0014019786613062024, "1": 0.0011445144191384315, "2": 0.12793301045894623, "3": 0.0008378548664040864, "4": 0.0007389540551230311, "5": 0.0006609393749386072, "6": 0.0005978252156637609, "7": 0.0005457140505313873, "8": 0.0005019594100303948, "9": 0.0004647003370337188, "10": 0.0004325903137214482, "11": 0.520077109336853, "12": 0.30320510268211365, "13": 0.0003583137004170567, "14": 0.00033891620114445686, "15": 0.00032151100458577275, "16": 0.0003058061993215233, "17": 0.0002915642107836902, "18": 0.039574939757585526, "19": 0.0002667207445483655}}, {"key": "jain2020contrastive", "year": "2020", "title": "Contrastive Code Representation Learning", "topic_distr": {"0": 0.001598908333107829, "1": 0.18643818795681, "2": 0.0011038087541237473, "3": 0.11960915476083755, "4": 0.0008431776659563184, "5": 0.0007541603408753872, "6": 0.19704009592533112, "7": 0.0006226833793334663, "8": 0.0005727573879994452, "9": 0.0005302431527525187, "10": 0.4875251352787018, "11": 0.0004617015365511179, "12": 0.00043367224861867726, "13": 0.00040885142516344786, "14": 0.0003867180203087628, "15": 0.00036685794475488365, "16": 0.0003489381051622331, "17": 0.00033268737024627626, "18": 0.00031788292108103633, "19": 0.0003043399192392826}}, {"key": "jain2020indic", "year": "2020", "title": "Indic-transformers: An Analysis Of Transformer Language Models For Indian Languages", "topic_distr": {"0": 0.001686661271378398, "1": 0.05822577700018883, "2": 0.15719078481197357, "3": 0.0010076938197016716, "4": 0.0008887426229193807, "5": 0.000794914725702256, "6": 0.0007190071046352386, "7": 0.0006563328206539154, "8": 0.0006037089042365551, "9": 0.000558897212613374, "10": 0.4347364604473114, "11": 0.00048665161011740565, "12": 0.18887680768966675, "13": 0.0543171651661396, "14": 0.09748942404985428, "15": 0.00038668274646624923, "16": 0.00036779450601898134, "17": 0.000350665592122823, "18": 0.0003350611368659884, "19": 0.00032078626099973917}}, {"key": "jain2020learning", "year": "2020", "title": "Learning To Faithfully Rationalize By Construction", "topic_distr": {"0": 0.06861335784196854, "1": 0.0008558804402127862, "2": 0.16673751175403595, "3": 0.0006266683340072632, "4": 0.0005526934401132166, "5": 0.0741453543305397, "6": 0.18787316977977753, "7": 0.3138822615146637, "8": 0.0003754358331207186, "9": 0.00034756824607029557, "10": 0.0003235518524888903, "11": 0.025276461616158485, "12": 0.0002842671237885952, "13": 0.00026799735496751964, "14": 0.00025348918279632926, "15": 0.00024047112674452364, "16": 0.00022872487897984684, "17": 0.15870730578899384, "18": 0.00020836856856476516, "19": 0.00019949127454310656}}, {"key": "jakesch2022human", "year": "2022", "title": "Human Heuristics For Ai-generated Language Are Flawed", "topic_distr": {"0": 0.4563763737678528, "1": 0.025067787617444992, "2": 0.0011038328520953655, "3": 0.0009560839971527457, "4": 0.0008432228351011872, "5": 0.0007542004459537566, "6": 0.030040806159377098, "7": 0.19960254430770874, "8": 0.0005727878306061029, "9": 0.22489555180072784, "10": 0.0004936304758302867, "11": 0.00046172604197636247, "12": 0.00043369526974856853, "13": 0.0004088731366209686, "14": 0.00038673856761306524, "15": 0.05629820004105568, "16": 0.00034895664430223405, "17": 0.0003327050362713635, "18": 0.0003178998304065317, "19": 0.0003043560718651861}}, {"key": "jakesch2023co", "year": "2023", "title": "Co-writing With Opinionated Language Models Affects Users' Views", "topic_distr": {"0": 0.4470304250717163, "1": 0.0014763545477762818, "2": 0.0012480119476094842, "3": 0.08925091475248337, "4": 0.0009533732663840055, "5": 0.0008527224999852479, "6": 0.0007712942897342145, "7": 0.0007040621712803841, "8": 0.0006476113921962678, "9": 0.45270612835884094, "10": 0.0005581136792898178, "11": 0.0005220415769144893, "12": 0.0004903490771539509, "13": 0.00046228442806750536, "14": 0.000437258422607556, "15": 0.0004148028092458844, "16": 0.000394541013520211, "17": 0.00037616645568050444, "18": 0.0003594272129703313, "19": 0.00034411426167935133}}, {"key": "jang2021towards", "year": "2021", "title": "Towards Continual Knowledge Learning Of Language Models", "topic_distr": {"0": 0.09478263556957245, "1": 0.0008559913258068264, "2": 0.06621034443378448, "3": 0.0006266984273679554, "4": 0.000552721437998116, "5": 0.0004943687235936522, "6": 0.04843321442604065, "7": 0.000408182357205078, "8": 0.025799816474318504, "9": 0.00034758582478389144, "10": 0.00032356823794543743, "11": 0.14120036363601685, "12": 0.0002842815010808408, "13": 0.0714375227689743, "14": 0.0002535020175855607, "15": 0.00024048329214565456, "16": 0.4281596839427948, "17": 0.00021808373276144266, "18": 0.00020837911870330572, "19": 0.11916258931159973}}, {"key": "jang2022can", "year": "2022", "title": "Can Large Language Models Truly Understand Prompts? A Case Study With Negated Prompts", "topic_distr": {"0": 0.1462095081806183, "1": 0.0010833749547600746, "2": 0.0009158883476629853, "3": 0.2019404023885727, "4": 0.0006996379815973341, "5": 0.0006257743225432932, "6": 0.0005660182214342058, "7": 0.0005166796618141234, "8": 0.00047525292029604316, "9": 0.0004399761965032667, "10": 0.0004095745680388063, "11": 0.00038310285890474916, "12": 0.0003598452021833509, "13": 0.10315791517496109, "14": 0.00032088434090837836, "15": 0.0003044051700271666, "16": 0.00028953593573533, "17": 0.3522968292236328, "18": 0.0002637675206642598, "19": 0.18874165415763855}}, {"key": "jang2023exploring", "year": "2023", "title": "Exploring The Benefits Of Training Expert Language Models Over Instruction Tuning", "topic_distr": {"0": 0.001212113769724965, "1": 0.0009887482738122344, "2": 0.43464532494544983, "3": 0.1510162651538849, "4": 0.0006385224987752736, "5": 0.0005711116245947778, "6": 0.0005165752954781055, "7": 0.0004715465474873781, "8": 0.0004337385471444577, "9": 0.00040154330781660974, "10": 0.0003737973456736654, "11": 0.058484457433223724, "12": 0.0003284119302406907, "13": 0.09669601917266846, "14": 0.0002928543835878372, "15": 0.00027781471726484597, "16": 0.03042963705956936, "17": 0.08597379922866821, "18": 0.0002407268329989165, "19": 0.13600698113441467}}, {"key": "jang2023gpt", "year": "2023", "title": "GPT-4 Can Pass The Korean National Licensing Examination For Korean Medicine Doctors", "topic_distr": {"0": 0.1691051721572876, "1": 0.0920339897274971, "2": 0.0007174740312620997, "3": 0.08413606137037277, "4": 0.0005480756517499685, "5": 0.0004902130458503962, "6": 0.0004434018337633461, "7": 0.00040475145215168595, "8": 0.030780622735619545, "9": 0.11178313195705414, "10": 0.0003208485431969166, "11": 0.0003001113946083933, "12": 0.13830189406871796, "13": 0.2761348485946655, "14": 0.0239240899682045, "15": 0.00023846194380894303, "16": 0.020742332562804222, "17": 0.049190063029527664, "18": 0.00020662762108258903, "19": 0.00019782449817284942}}, {"key": "jean2019context", "year": "2019", "title": "Context-aware Learning For Neural Machine Translation", "topic_distr": {"0": 0.0020444418769329786, "1": 0.0016695237718522549, "2": 0.5139220952987671, "3": 0.06857015937566757, "4": 0.09836189448833466, "5": 0.0009643615921959281, "6": 0.0008722732891328633, "7": 0.0007962390664033592, "8": 0.00073239766061306, "9": 0.0006780337425880134, "10": 0.000631182745564729, "11": 0.0005903880228288472, "12": 0.000554546364583075, "13": 0.0005228074151091278, "14": 0.3069532811641693, "15": 0.0004691094218287617, "16": 0.0004461949283722788, "17": 0.00042541473521851003, "18": 0.00040648397407494485, "19": 0.00038916623452678323}}, {"key": "jeblick2022chatgpt", "year": "2022", "title": "Chatgpt Makes Medicine Easy To Swallow: An Exploratory Case Study On Simplified Radiology Reports", "topic_distr": {"0": 0.23001378774642944, "1": 0.0014351250138133764, "2": 0.034556590020656586, "3": 0.16360391676425934, "4": 0.0009263966931030154, "5": 0.0008285933290608227, "6": 0.0007494696183130145, "7": 0.0006841400172561407, "8": 0.01890580542385578, "9": 0.3843010365962982, "10": 0.0005423212423920631, "11": 0.0005072698113508523, "12": 0.16023583710193634, "13": 0.0004492035659495741, "14": 0.0004248856857884675, "15": 0.0004030654963571578, "16": 0.0003833770169876516, "17": 0.0003655223990790546, "18": 0.0003492568212095648, "19": 0.0003343771677464247}}, {"key": "jentzsch2023chatgpt", "year": "2023", "title": "Chatgpt Is Fun, But It Is Not Funny! Humor Is Still Challenging Large Language Models", "topic_distr": {"0": 0.33160391449928284, "1": 0.07490244507789612, "2": 0.0010500247590243816, "3": 0.18832361698150635, "4": 0.0008020757813937962, "5": 0.08981058746576309, "6": 0.0006488915532827377, "7": 0.0005923290736973286, "8": 0.0005448368610814214, "9": 0.2566796541213989, "10": 0.00046954225399531424, "11": 0.01737891137599945, "12": 0.0004125317791476846, "13": 0.0003889209183398634, "14": 0.0003678664506878704, "15": 0.034783560782670975, "16": 0.0003319282259326428, "17": 0.0003164696681778878, "18": 0.0003023869066964835, "19": 0.00028950406704097986}}, {"key": "jeong2023study", "year": "2023", "title": "A Study On The Implementation Of Generative AI Services Using An Enterprise Data-based LLM Application Architecture", "topic_distr": {"0": 0.0009526251815259457, "1": 0.09986984729766846, "2": 0.06778571754693985, "3": 0.14741745591163635, "4": 0.0005020539392717183, "5": 0.0004490500141400844, "6": 0.0004061695944983512, "7": 0.00037076466833241284, "8": 0.05450143292546272, "9": 0.4258420169353485, "10": 0.00029390701092779636, "11": 0.00027491117361932993, "12": 0.05009361729025841, "13": 0.0002434425987303257, "14": 0.00023026370035950094, "15": 0.10151451081037521, "16": 0.04868357628583908, "17": 0.00019809219520539045, "18": 0.00018927718338090926, "19": 0.00018121326866094023}}, {"key": "jeretic2020are", "year": "2020", "title": "Are Natural Language Inference Models Imppressive? Learning Implicature And Presupposition", "topic_distr": {"0": 0.39617469906806946, "1": 0.0014347208198159933, "2": 0.1610027551651001, "3": 0.0010503139346837997, "4": 0.0009263275424018502, "5": 0.03787046670913696, "6": 0.0007494144374504685, "7": 0.0006840896094217896, "8": 0.0006292401812970638, "9": 0.000582533364649862, "10": 0.21451693773269653, "11": 0.18119262158870697, "12": 0.00047643904690630734, "13": 0.00044917050399817526, "14": 0.000424854428274557, "15": 0.00040303581045009196, "16": 0.000383348815375939, "17": 0.0003654954780358821, "18": 0.0003492311225272715, "19": 0.0003343525459058583}}, {"key": "jeronymo2023inpars", "year": "2023", "title": "Inpars-v2: Large Language Models As Efficient Dataset Generators For Information Retrieval", "topic_distr": {"0": 0.0017803306691348553, "1": 0.18023425340652466, "2": 0.0012298858491703868, "3": 0.43092358112335205, "4": 0.0009394832304678857, "5": 0.0008402986568398774, "6": 0.0007600571843795478, "7": 0.0006938046426512301, "8": 0.2631729245185852, "9": 0.0005908061866648495, "10": 0.0005499824765138328, "11": 0.000514435872901231, "12": 0.0004832051636185497, "13": 0.07146821171045303, "14": 0.0004308879724703729, "15": 0.0004087595152668655, "16": 0.0003887929196935147, "17": 0.0003706860588863492, "18": 0.0003541907062754035, "19": 0.04386542737483978}}, {"key": "jesse2023large", "year": "2023", "title": "Large Language Models And Simple, Stupid Bugs", "topic_distr": {"0": 0.23837018013000488, "1": 0.0012731915339827538, "2": 0.0010762299643829465, "3": 0.55621337890625, "4": 0.000822113361209631, "5": 0.0007353196269832551, "6": 0.1441662609577179, "7": 0.0006071272073313594, "8": 0.0005584484897553921, "9": 0.0524187833070755, "10": 0.00048127281479537487, "11": 0.00045016707736067474, "12": 0.0004228380275890231, "13": 0.0003986372903455049, "14": 0.00037705685826949775, "15": 0.00035769291571341455, "16": 0.0003402207512408495, "17": 0.0003243760147597641, "18": 0.0003099414170719683, "19": 0.0002967367472592741}}, {"key": "ji2020language", "year": "2020", "title": "Language Generation With Multi-hop Reasoning On Commonsense Knowledge Graph", "topic_distr": {"0": 0.0014358902117237449, "1": 0.0011704838834702969, "2": 0.10477966070175171, "3": 0.0008571419166401029, "4": 0.0007559605874121189, "5": 0.00067615055013448, "6": 0.0006115839350968599, "7": 0.06175508722662926, "8": 0.07953688502311707, "9": 0.00047539520892314613, "10": 0.00044254621025174856, "11": 0.14985033869743347, "12": 0.0003888134961016476, "13": 0.0003665601252578199, "14": 0.00034671620232984424, "15": 0.15563838183879852, "16": 0.44005629420280457, "17": 0.0002982744190376252, "18": 0.0002850013552233577, "19": 0.0002728592080529779}}, {"key": "ji2022survey", "year": "2022", "title": "Survey Of Hallucination In Natural Language Generation", "topic_distr": {"0": 0.12874232232570648, "1": 0.0009257985511794686, "2": 0.0007826547953300178, "3": 0.0006779013783670962, "4": 0.03416650369763374, "5": 0.0269889235496521, "6": 0.0004836923617403954, "7": 0.15316729247570038, "8": 0.01878330111503601, "9": 0.00037598281051032245, "10": 0.04643808305263519, "11": 0.00032738156733103096, "12": 0.48224225640296936, "13": 0.00028990680584684014, "14": 0.04491107165813446, "15": 0.05977239832282066, "16": 0.0002474237116985023, "17": 0.00023590069031342864, "18": 0.00022540321515407413, "19": 0.00021580018801614642}}, {"key": "ji2023exploring", "year": "2023", "title": "Exploring The Impact Of Instruction Data Scaling On Large Language Models: An Empirical Study On Real-world Use Cases", "topic_distr": {"0": 0.08336477726697922, "1": 0.18233910202980042, "2": 0.06335846334695816, "3": 0.3188190460205078, "4": 0.0005669574602507055, "5": 0.0005071014165878296, "6": 0.00045867753215134144, "7": 0.00041869559208862484, "8": 0.00038512510946020484, "9": 0.06073324382305145, "10": 0.00033190211979672313, "11": 0.0003104505594819784, "12": 0.10757965594530106, "13": 0.096966952085495, "14": 0.0002600312582217157, "15": 0.017116082832217216, "16": 0.022880079224705696, "17": 0.043185241520404816, "18": 0.0002137461706297472, "19": 0.0002046397712547332}}, {"key": "jia2022mner", "year": "2022", "title": "MNER-QG: An End-to-end MRC Framework For Multimodal Named Entity Recognition With Query Grounding", "topic_distr": {"0": 0.0010666570160537958, "1": 0.0008707200177013874, "2": 0.08193758130073547, "3": 0.0006374433869495988, "4": 0.0005622014286927879, "5": 0.0005028456216678023, "6": 0.0004548280849121511, "7": 0.08083486557006836, "8": 0.04657315835356712, "9": 0.0003535460855346173, "10": 0.00032911665039137006, "11": 0.00030784509726800025, "12": 0.00028915624716319144, "13": 0.00027260667411610484, "14": 0.00025784893659874797, "15": 0.0002446069847792387, "16": 0.13191846013069153, "17": 0.2441217303276062, "18": 0.40826189517974854, "19": 0.00020292233966756612}}, {"key": "jia2022visual", "year": "2022", "title": "Visual Prompt Tuning", "topic_distr": {"0": 0.0017323214560747147, "1": 0.0014149476774036884, "2": 0.0011958724353462458, "3": 0.0010357588762417436, "4": 0.019491763785481453, "5": 0.000817054882645607, "6": 0.0007390329847112298, "7": 0.0006746131111867726, "8": 0.0006205234676599503, "9": 0.0005744636873714626, "10": 0.06894643604755402, "11": 0.0005002059042453766, "12": 0.00046983908396214247, "13": 0.411376953125, "14": 0.0004189690516795963, "15": 0.0003974527062382549, "16": 0.0003780383849516511, "17": 0.3402407765388489, "18": 0.14864520728588104, "19": 0.0003297208750154823}}, {"key": "jiang2017visual", "year": "2017", "title": "Memexqa: Visual Memex Question Answering", "topic_distr": {"0": 0.002046567155048251, "1": 0.0016699618427082896, "2": 0.0014114592922851443, "3": 0.09681600332260132, "4": 0.07616890966892242, "5": 0.0009643493103794754, "6": 0.0008722618804313242, "7": 0.0007962287054397166, "8": 0.28622207045555115, "9": 0.0006780248950235546, "10": 0.0006311745382845402, "11": 0.0005903802812099457, "12": 0.0005545390886254609, "13": 0.0005228006048128009, "14": 0.0004944984684698284, "15": 0.07997703552246094, "16": 0.03003583662211895, "17": 0.0004254091763868928, "18": 0.4187333285808563, "19": 0.0003891611413564533}}, {"key": "jiang2019how", "year": "2019", "title": "How Can We Know What Language Models Know?", "topic_distr": {"0": 0.18051020801067352, "1": 0.001144233625382185, "2": 0.0009673709864728153, "3": 0.0008378628990612924, "4": 0.0007389582460746169, "5": 0.0006609437405131757, "6": 0.000597829173784703, "7": 0.000545717659406364, "8": 0.06322740018367767, "9": 0.0004647033929359168, "10": 0.00043259316589683294, "11": 0.00040463372715748847, "12": 0.0003800689592026174, "13": 0.0003583160578273237, "14": 0.0003389184130355716, "15": 0.00032151310006156564, "16": 0.06593240797519684, "17": 0.5323283076286316, "18": 0.0002785915567073971, "19": 0.14952941238880157}}, {"key": "jiang2019improving", "year": "2019", "title": "Improving Neural Response Diversity With Frequency-aware Cross-entropy Loss", "topic_distr": {"0": 0.09803608804941177, "1": 0.0012890846701338887, "2": 0.33381226658821106, "3": 0.0009439243585802615, "4": 0.0008325012749992311, "5": 0.0007446105591952801, "6": 0.5588312149047852, "7": 0.0006147983949631453, "8": 0.0005655046552419662, "9": 0.0005235287826508284, "10": 0.00048735379823483527, "11": 0.0004558550426736474, "12": 0.0004281807050574571, "13": 0.00040367417386732996, "14": 0.0003818210680037737, "15": 0.0003622124786488712, "16": 0.00034451953251846135, "17": 0.00032847459078766406, "18": 0.0003138576284982264, "19": 0.00030048610642552376}}, {"key": "jiang2019language", "year": "2019", "title": "Language As An Abstraction For Hierarchical Deep Reinforcement Learning", "topic_distr": {"0": 0.0860356017947197, "1": 0.0011069029569625854, "2": 0.0009357970557175577, "3": 0.0008105169399641454, "4": 0.0007148413569666445, "5": 0.0006393726216629148, "6": 0.0005783179658465087, "7": 0.0005279072211124003, "8": 0.0004855802981182933, "9": 0.00044953697943128645, "10": 0.0004184747231192887, "11": 0.9048385620117188, "12": 0.00036766473203897476, "13": 0.0003466217895038426, "14": 0.00032785721123218536, "15": 0.0003110199759248644, "16": 0.00029582763090729713, "17": 0.0002820503432303667, "18": 0.0002694992290344089, "19": 0.0002580175641924143}}, {"key": "jiang2020how", "year": "2020", "title": "How Can We Know When Language Models Know? On The Calibration Of Language Models For Question Answering", "topic_distr": {"0": 0.2958848178386688, "1": 0.0010393995326012373, "2": 0.0008785672835074365, "3": 0.35856232047080994, "4": 0.0006711053429171443, "5": 0.0006002542795613408, "6": 0.0005429351003840566, "7": 0.1768350601196289, "8": 0.10876444727182388, "9": 0.0004220332484692335, "10": 0.00039287147228606045, "11": 0.0003674793115351349, "12": 0.00034517014864832163, "13": 0.00032541464315727353, "14": 0.00030779815278947353, "15": 0.00029199104756116867, "16": 0.016323525458574295, "17": 0.00026479383814148605, "18": 0.00025301065761595964, "19": 0.03692702203989029}}, {"key": "jiang2020x", "year": "2020", "title": "X-FACTR: Multilingual Factual Knowledge Retrieval From Pretrained Language Models", "topic_distr": {"0": 0.001485947985202074, "1": 0.0012126178480684757, "2": 0.001025008619762957, "3": 0.26615050435066223, "4": 0.06974194943904877, "5": 0.0007003323989920318, "6": 0.0006334565696306527, "7": 0.021372586488723755, "8": 0.05755957216024399, "9": 0.0004923972301185131, "10": 0.00045837339712306857, "11": 0.0004287477058824152, "12": 0.0671721026301384, "13": 0.00037966977106407285, "14": 0.11846666038036346, "15": 0.00034067354863509536, "16": 0.2552226781845093, "17": 0.00030894187511876225, "18": 0.0002951941278297454, "19": 0.13655252754688263}}, {"key": "jiang2022adaptive", "year": "2022", "title": "Adamct: Adaptive Mixture Of Cnn-transformer For Sequential Recommendation", "topic_distr": {"0": 0.0475897453725338, "1": 0.0011315245646983385, "2": 0.1489160656929016, "3": 0.0008285999647341669, "4": 0.31997841596603394, "5": 0.0006536389701068401, "6": 0.0005912219639867544, "7": 0.0005396864144131541, "8": 0.0004964150721207261, "9": 0.0004595674981828779, "10": 0.11395839601755142, "11": 0.00040016171988099813, "12": 0.027744656428694725, "13": 0.14392583072185516, "14": 0.0003351727209519595, "15": 0.0003179597551934421, "16": 0.17028480768203735, "17": 0.0002883437555283308, "18": 0.021296031773090363, "19": 0.0002637747093103826}}, {"key": "jiang2022evaluating", "year": "2022", "title": "Evaluating And Inducing Personality In Pre-trained Language Models", "topic_distr": {"0": 0.5782275199890137, "1": 0.0009608986438252032, "2": 0.0008122189901769161, "3": 0.23684526979923248, "4": 0.0006204649689607322, "5": 0.0005549601628445089, "6": 0.0005019661621190608, "7": 0.0004582109104376286, "8": 0.016215603798627853, "9": 0.0003901873715221882, "10": 0.00036322607775218785, "11": 0.00033974996767938137, "12": 0.08247064799070358, "13": 0.0003008594212587923, "14": 0.07970878481864929, "15": 0.00026995790540240705, "16": 0.0002567713090684265, "17": 0.00024481298169121146, "18": 0.00023391890863422304, "19": 0.0002239530731458217}}, {"key": "jiang2022general", "year": "2022", "title": "VIMA: General Robot Manipulation With Multimodal Prompts", "topic_distr": {"0": 0.0012113169068470597, "1": 0.0009890450164675713, "2": 0.0008358888444490731, "3": 0.16252639889717102, "4": 0.00063852418679744, "5": 0.0005711126723326743, "6": 0.0005165762268006802, "7": 0.00047154739149846137, "8": 0.0004337393038440496, "9": 0.0004015440063085407, "10": 0.024610506370663643, "11": 0.2631523609161377, "12": 0.00032841251231729984, "13": 0.08900391310453415, "14": 0.00029285490745678544, "15": 0.00027781521202996373, "16": 0.0002642448234837502, "17": 0.17680637538433075, "18": 0.27643734216690063, "19": 0.00023047137074172497}}, {"key": "jiang2022pseudo", "year": "2022", "title": "Pseudo-q: Generating Pseudo Language Queries For Visual Grounding", "topic_distr": {"0": 0.02752615511417389, "1": 0.0009259578655473888, "2": 0.1383361965417862, "3": 0.0006778906099498272, "4": 0.0005978725966997445, "5": 0.000534752500243485, "6": 0.00048368811258114874, "7": 0.0508711151778698, "8": 0.07210517674684525, "9": 0.0003759794926736504, "10": 0.00034999995841644704, "11": 0.00032737868605181575, "12": 0.0003075039421673864, "13": 0.07262551784515381, "14": 0.00027421012055128813, "15": 0.00026012794114649296, "16": 0.00024742152891121805, "17": 0.1927730143070221, "18": 0.44018423557281494, "19": 0.0002157982817152515}}, {"key": "jiang2023active", "year": "2023", "title": "Active Retrieval Augmented Generation", "topic_distr": {"0": 0.06941507756710052, "1": 0.0010720364516600966, "2": 0.0009063163306564093, "3": 0.11657992750406265, "4": 0.0006923260516487062, "5": 0.0006192343425936997, "6": 0.0005601027514785528, "7": 0.1337122917175293, "8": 0.15008345246315002, "9": 0.00043537793681025505, "10": 0.0004052940639667213, "11": 0.00037909901584498584, "12": 0.07804463058710098, "13": 0.0003357042733114213, "14": 0.0003175307356286794, "15": 0.2006530910730362, "16": 0.18704597651958466, "17": 0.0002731666318140924, "18": 0.00026101083494722843, "19": 0.05820833519101143}}, {"key": "jiang2023compressing", "year": "2023", "title": "Llmlingua: Compressing Prompts For Accelerated Inference Of Large Language Models", "topic_distr": {"0": 0.05778394266963005, "1": 0.001357868080958724, "2": 0.0011479469249024987, "3": 0.38431453704833984, "4": 0.0008768981206230819, "5": 0.0007843203493393958, "6": 0.0007094243774190545, "7": 0.0006475853733718395, "8": 0.0005956628010608256, "9": 0.06295336037874222, "10": 0.0005133442464284599, "11": 0.0004801656468771398, "12": 0.00045101542491465807, "13": 0.29580384492874146, "14": 0.0004021834465675056, "15": 0.0003815291274804622, "16": 0.0003628926642704755, "17": 0.1897864043712616, "18": 0.0003305955324321985, "19": 0.000316510908305645}}, {"key": "jiang2023delving", "year": "2023", "title": "Delving Into Multimodal Prompting For Fine-grained Visual Classification", "topic_distr": {"0": 0.0012852068757638335, "1": 0.0010499403579160571, "2": 0.0008876287029124796, "3": 0.10114455223083496, "4": 0.025913313031196594, "5": 0.0006064666667953134, "6": 0.0005485542351379991, "7": 0.0005007379222661257, "8": 0.00046058939187787473, "9": 0.0004264010931365192, "10": 0.00039693748112767935, "11": 0.00037128254189155996, "12": 0.0675429105758667, "13": 0.07467816770076752, "14": 0.0003109837125521153, "15": 0.0002950129855889827, "16": 0.00028060254408046603, "17": 0.21518664062023163, "18": 0.5078693628311157, "19": 0.0002447384176775813}}, {"key": "jiang2023exploring", "year": "2023", "title": "Graphologue: Exploring Large Language Model Responses With Interactive Diagrams", "topic_distr": {"0": 0.0013721982249990106, "1": 0.0011193507816642523, "2": 0.06669075042009354, "3": 0.30355292558670044, "4": 0.0007227880996651947, "5": 0.0006464797188527882, "6": 0.10283785313367844, "7": 0.0005337749607861042, "8": 0.017117150127887726, "9": 0.38276585936546326, "10": 0.0004231261264067143, "11": 0.0003957785665988922, "12": 0.0003717513754963875, "13": 0.00035047452547587454, "14": 0.0003315014182589948, "15": 0.01894526369869709, "16": 0.10100441426038742, "17": 0.0002851853787433356, "18": 0.0002724947698879987, "19": 0.0002608854556456208}}, {"key": "jiang2023general", "year": "2023", "title": "Structgpt: A General Framework For Large Language Model To Reason Over Structured Data", "topic_distr": {"0": 0.0012593171559274197, "1": 0.09731362760066986, "2": 0.0008695874712429941, "3": 0.5325385928153992, "4": 0.0006642666412517428, "5": 0.10838762670755386, "6": 0.0005374018219299614, "7": 0.0004905576934106648, "8": 0.11007630825042725, "9": 0.0004177321388851851, "10": 0.0003888675710186362, "11": 0.0003637341724243015, "12": 0.0003416523686610162, "13": 0.00032209823257289827, "14": 0.0003046612546313554, "15": 0.00028901523910462856, "16": 0.1446826457977295, "17": 0.00026209524367004633, "18": 0.00025043211644515395, "19": 0.00023976275406312197}}, {"key": "jiang2023hallucination", "year": "2023", "title": "Hallucination Augmented Contrastive Learning For Multimodal Large Language Model", "topic_distr": {"0": 0.22263199090957642, "1": 0.0009260030928999186, "2": 0.15856963396072388, "3": 0.000677908246871084, "4": 0.0005978854605928063, "5": 0.0005347643746063113, "6": 0.0004836989101022482, "7": 0.00044153592898510396, "8": 0.0004061341460328549, "9": 0.0003759879036806524, "10": 0.00035000775824300945, "11": 0.0003273859911132604, "12": 0.0003075108106713742, "13": 0.0002899107348639518, "14": 0.0002742162614595145, "15": 0.12906213104724884, "16": 0.048170387744903564, "17": 0.00023590387718286365, "18": 0.43512123823165894, "19": 0.00021580311295110732}}, {"key": "jiang2023human", "year": "2023", "title": "Motiongpt: Human Motion As A Foreign Language", "topic_distr": {"0": 0.0017344068037346005, "1": 0.04225427657365799, "2": 0.0011957768583670259, "3": 0.0010356972925364971, "4": 0.0009134392603300512, "5": 0.0008170030196197331, "6": 0.0007389861275441945, "7": 0.2752267122268677, "8": 0.0006204841192811728, "9": 0.0005744272493757308, "10": 0.0005347352707758546, "11": 0.0005001741810701787, "12": 0.14929571747779846, "13": 0.07771380990743637, "14": 0.00041894245077855885, "15": 0.0003974274732172489, "16": 0.00037801440339535475, "17": 0.26160451769828796, "18": 0.18371571600437164, "19": 0.00032969992025755346}}, {"key": "jiang2023investigating", "year": "2023", "title": "Personallm: Investigating The Ability Of Large Language Models To Express Personality Traits", "topic_distr": {"0": 0.6365060806274414, "1": 0.0009793187491595745, "2": 0.0008278327877633274, "3": 0.21400390565395355, "4": 0.02851026877760887, "5": 0.0005656129214912653, "6": 0.0005116015672683716, "7": 0.00046700634993612766, "8": 0.00042956238030456007, "9": 0.0904204249382019, "10": 0.0003701983077917248, "11": 0.024233276024460793, "12": 0.00032524988637305796, "13": 0.0003066345234401524, "14": 0.00029003468807786703, "15": 0.00027513981331139803, "16": 0.0002617001300677657, "17": 0.00024951223167590797, "18": 0.00023840904759708792, "19": 0.00022825191263109446}}, {"key": "jiang2023llm", "year": "2023", "title": "Llm-blender: Ensembling Large Language Models With Pairwise Ranking And Generative Fusion", "topic_distr": {"0": 0.0014685119967907667, "1": 0.0011983186705037951, "2": 0.16849683225154877, "3": 0.46781525015830994, "4": 0.13672032952308655, "5": 0.0006920731393620372, "6": 0.0006259860238060355, "7": 0.0005714201251976192, "8": 0.0005256044096313417, "9": 0.00048659020103514194, "10": 0.00045296765165403485, "11": 0.00042369135189801455, "12": 0.00039796961937099695, "13": 0.0003751922049559653, "14": 0.00035488096182234585, "15": 0.07372000813484192, "16": 0.0003202113148290664, "17": 0.00030529845389537513, "18": 0.1447696089744568, "19": 0.00027928472263738513}}, {"key": "jiang2023mistral", "year": "2023", "title": "Mistral 7B", "topic_distr": {"0": 0.0029712922405451536, "1": 0.002425478771328926, "2": 0.14916953444480896, "3": 0.2649308443069458, "4": 0.0015659130876883864, "5": 0.0014005927368998528, "6": 0.0012668479466810822, "7": 0.05287621542811394, "8": 0.0010636992519721389, "9": 0.0009847438195720315, "10": 0.14070963859558105, "11": 0.10116107016801834, "12": 0.0008053965866565704, "13": 0.27484777569770813, "14": 0.0007181953405961394, "15": 0.0006813120562583208, "16": 0.0006480321753770113, "17": 0.0006178520270623267, "18": 0.000590357871260494, "19": 0.0005652063991874456}}, {"key": "jiang2023redundancy", "year": "2023", "title": "Mixphm: Redundancy-aware Parameter-efficient Tuning For Low-resource Visual Question Answering", "topic_distr": {"0": 0.0013874104479327798, "1": 0.0011316316667944193, "2": 0.1774343103170395, "3": 0.0008285969961434603, "4": 0.0007307888008654118, "5": 0.000653636350762099, "6": 0.0005912194610573351, "7": 0.0005396842025220394, "8": 0.07508587837219238, "9": 0.0004595656064338982, "10": 0.0004278103879187256, "11": 0.0004001600609626621, "12": 0.0003758668608497828, "13": 0.3228974938392639, "14": 0.00033517132396809757, "15": 0.00031795844552107155, "16": 0.0003024271863978356, "17": 0.11038462817668915, "18": 0.2161632776260376, "19": 0.08955247700214386}}, {"key": "jiao2019distilling", "year": "2019", "title": "Tinybert: Distilling BERT For Natural Language Understanding", "topic_distr": {"0": 0.0013550232397392392, "1": 0.0011070268228650093, "2": 0.06903024017810822, "3": 0.0008105653687380254, "4": 0.0007148836739361286, "5": 0.0006394107476808131, "6": 0.0005783523665741086, "7": 0.0005279386532492936, "8": 0.0004856091982219368, "9": 0.00044956375495530665, "10": 0.2847268879413605, "11": 0.00039145108894445, "12": 0.0003676866181194782, "13": 0.4313419759273529, "14": 0.019044063985347748, "15": 0.0003110384859610349, "16": 0.07452736794948578, "17": 0.10077664256095886, "18": 0.00026951529434882104, "19": 0.012544766999781132}}, {"key": "jiao2023is", "year": "2023", "title": "Is Chatgpt A Good Translator? Yes With GPT-4 As The Engine", "topic_distr": {"0": 0.17000220715999603, "1": 0.04455960914492607, "2": 0.04133190959692001, "3": 0.09933988004922867, "4": 0.0006146952509880066, "5": 0.0005497988313436508, "6": 0.031638674437999725, "7": 0.00045394935295917094, "8": 0.0004175522772129625, "9": 0.18657872080802917, "10": 0.00035984793794341385, "11": 0.0003365901648066938, "12": 0.00031615624902769923, "13": 0.00029806134989485145, "14": 0.33274346590042114, "15": 0.013747588731348515, "16": 0.0002543832524679601, "17": 0.076003298163414, "18": 0.00023174338275566697, "19": 0.00022187024296727031}}, {"key": "jin2018explicit", "year": "2018", "title": "Explicit State Tracking With Semi-supervision For Neural Dialogue Generation", "topic_distr": {"0": 0.0009898256976157427, "1": 0.0008082294370979071, "2": 0.15533438324928284, "3": 0.000591787276789546, "4": 0.0005219338927417994, "5": 0.6155374646186829, "6": 0.16885709762573242, "7": 0.05429010093212128, "8": 0.0003545411163941026, "9": 0.0003282244724687189, "10": 0.0003055447305087, "11": 0.00028579667559824884, "12": 0.00026844633975997567, "13": 0.00025308207841590047, "14": 0.00023938134836498648, "15": 0.0002270878030685708, "16": 0.00021599528554361314, "17": 0.00020593595399986953, "18": 0.00019677189993672073, "19": 0.00018838867254089564}}, {"key": "jin2019multi", "year": "2019", "title": "MMM: Multi-stage Multi-task Learning For Multi-choice Reading Comprehension", "topic_distr": {"0": 0.0013557870406657457, "1": 0.001107153482735157, "2": 0.5566672086715698, "3": 0.11405257880687714, "4": 0.000714847061317414, "5": 0.0006393772782757878, "6": 0.0005783221567980945, "7": 0.03552529215812683, "8": 0.2260635942220688, "9": 0.01943051442503929, "10": 0.00041847777902148664, "11": 0.040988240391016006, "12": 0.0003676674095913768, "13": 0.00034662432153709233, "14": 0.00032785962685011327, "15": 0.00031102224602364004, "16": 0.00029582978459075093, "17": 0.00028205240960232913, "18": 0.00026950120809488, "19": 0.0002580194268375635}}, {"key": "jin2020simple", "year": "2020", "title": "A Simple Baseline To Semi-supervised Domain Adaptation For Machine Translation", "topic_distr": {"0": 0.0013550252187997103, "1": 0.0011071480112150311, "2": 0.0009358363458886743, "3": 0.11201649159193039, "4": 0.000714865222107619, "5": 0.0006393941584974527, "6": 0.0005783373489975929, "7": 0.0005279249744489789, "8": 0.00048559659626334906, "9": 0.0004495520843192935, "10": 0.0004184887802693993, "11": 0.0003914409317076206, "12": 0.06826203316450119, "13": 0.0003466334310360253, "14": 0.522577166557312, "15": 0.0003110303950961679, "16": 0.0002958375553134829, "17": 0.2880595922470093, "18": 0.00026950828032568097, "19": 0.00025802620803005993}}, {"key": "jin2020what", "year": "2020", "title": "What Disease Does This Patient Have? A Large-scale Open Domain Question Answering Dataset From Medical Exams", "topic_distr": {"0": 0.0015994375571608543, "1": 0.0013057453325018287, "2": 0.2687046527862549, "3": 0.000956021249294281, "4": 0.0008431690512225032, "5": 0.0007541520171798766, "6": 0.0006821367423981428, "7": 0.0006226763362064958, "8": 0.1594434678554535, "9": 0.07670514285564423, "10": 0.000493598694447428, "11": 0.00046169632696546614, "12": 0.4849618971347809, "13": 0.0004088468267582357, "14": 0.00038671368383802474, "15": 0.0003668538120109588, "16": 0.00034893417614512146, "17": 0.00033268361585214734, "18": 0.00031787934130989015, "19": 0.0003043364849872887}}, {"key": "jin2021good", "year": "2021", "title": "A Good Prompt Is Worth Millions Of Parameters: Low-resource Prompt-based Learning For Vision-language Models", "topic_distr": {"0": 0.0014345470117405057, "1": 0.001170794595964253, "2": 0.18329589068889618, "3": 0.0008571100770495832, "4": 0.0007559320074506104, "5": 0.0006761257536709309, "6": 0.0006115615251474082, "7": 0.0005582530284300447, "8": 0.0005134930252097547, "9": 0.00047537783393636346, "10": 0.19423067569732666, "11": 0.00041392832645215094, "12": 0.00038879929343238473, "13": 0.2106475830078125, "14": 0.0003467035130597651, "15": 0.000328898400766775, "16": 0.000312832766212523, "17": 0.3017284870147705, "18": 0.10098014771938324, "19": 0.00027284922543913126}}, {"key": "jin2022when", "year": "2022", "title": "When To Make Exceptions: Exploring Language Models As Accounts Of Human Moral Judgment", "topic_distr": {"0": 0.5445629358291626, "1": 0.0009014265378937125, "2": 0.054090604186058044, "3": 0.23113633692264557, "4": 0.0005819936050102115, "5": 0.0005205494817346334, "6": 0.0004708413907792419, "7": 0.00042979916906915605, "8": 0.02561175264418125, "9": 0.13903270661830902, "10": 0.0003407039912417531, "11": 0.0003186835383530706, "12": 0.0002993366797454655, "13": 0.00028220441890880466, "14": 0.00026692714891396463, "15": 0.00025321898283436894, "16": 0.00024085002951323986, "17": 0.0002296331658726558, "18": 0.00021941459272056818, "19": 0.00021006670431233943}}, {"key": "jin2023action", "year": "2023", "title": "ADAPT: Action-aware Driving Caption Transformer", "topic_distr": {"0": 0.0014354005688801408, "1": 0.0011709011159837246, "2": 0.000989648629911244, "3": 0.06605697423219681, "4": 0.06335696578025818, "5": 0.20010443031787872, "6": 0.0006115974974818528, "7": 0.07293248176574707, "8": 0.0005135231767781079, "9": 0.06519807875156403, "10": 0.09789130091667175, "11": 0.1606900542974472, "12": 0.00038882213993929327, "13": 0.0293621513992548, "14": 0.0003467238857410848, "15": 0.0003289177257101983, "16": 0.00031285115983337164, "17": 0.00029828105471096933, "18": 0.23773805797100067, "19": 0.0002728652616497129}}, {"key": "jin2023augmenting", "year": "2023", "title": "Genegpt: Augmenting Large Language Models With Domain Tools For Improved Access To Biomedical Information", "topic_distr": {"0": 0.02156245894730091, "1": 0.0009430655045434833, "2": 0.0007972117746248841, "3": 0.6134055852890015, "4": 0.0006089778034947813, "5": 0.0005446855793707073, "6": 0.0004926726687699556, "7": 0.02036801166832447, "8": 0.07842326909303665, "9": 0.00038296336424537003, "10": 0.0003565012593753636, "11": 0.06457865238189697, "12": 0.03428448364138603, "13": 0.0002952892682515085, "14": 0.00027930361102335155, "15": 0.09020373225212097, "16": 0.07178344577550888, "17": 0.00024028046755120158, "18": 0.00022958809859119356, "19": 0.00021980676683597267}}, {"key": "jin2023better", "year": "2023", "title": "Better To Ask In English: Cross-lingual Evaluation Of Large Language Models For Healthcare Queries", "topic_distr": {"0": 0.08226651698350906, "1": 0.0009260980878025293, "2": 0.0007826890214346349, "3": 0.2780153155326843, "4": 0.0005978905246593058, "5": 0.0005347681581042707, "6": 0.09054603427648544, "7": 0.0004415388684719801, "8": 0.04141062870621681, "9": 0.16282503306865692, "10": 0.000350010086549446, "11": 0.013704543933272362, "12": 0.2694781422615051, "13": 0.00028991265571676195, "14": 0.0566461943089962, "15": 0.00026013547903858125, "16": 0.0002474286884535104, "17": 0.00023590544878970832, "18": 0.0002254077699035406, "19": 0.0002158045390387997}}, {"key": "jin2023chat", "year": "2023", "title": "Chat-univi: Unified Visual Representation Empowers Large Language Models With Image And Video Understanding", "topic_distr": {"0": 0.001066863420419395, "1": 0.0008707612287253141, "2": 0.0007359342416748405, "3": 0.19467490911483765, "4": 0.0005621713935397565, "5": 0.0005028207669965923, "6": 0.04817577451467514, "7": 0.0004151611647102982, "8": 0.0003818740660790354, "9": 0.017952874302864075, "10": 0.0003291003522463143, "11": 0.0003078298759646714, "12": 0.0002891419280786067, "13": 0.0002725931699387729, "14": 0.0002578361891210079, "15": 0.0002445948775857687, "16": 0.00023264720221050084, "17": 0.0002218123700004071, "18": 0.7323024272918701, "19": 0.00020291229884605855}}, {"key": "jin2023contrastive", "year": "2023", "title": "Medcpt: Contrastive Pre-trained Transformers With Large-scale Pubmed Search Logs For Zero-shot Biomedical Information Retrieval", "topic_distr": {"0": 0.0015206474345177412, "1": 0.103310227394104, "2": 0.06917493790388107, "3": 0.0009093384142033756, "4": 0.03175914287567139, "5": 0.0007173296762630343, "6": 0.025560563430190086, "7": 0.0005922734853811562, "8": 0.12555642426013947, "9": 0.0005043477867729962, "10": 0.19979600608348846, "11": 0.04986289143562317, "12": 0.0004124930710531771, "13": 0.07925792783498764, "14": 0.00036783196264877915, "15": 0.25186243653297424, "16": 0.057926908135414124, "17": 0.00031643998227082193, "18": 0.0003023585304617882, "19": 0.00028947691316716373}}, {"key": "jin2023large", "year": "2023", "title": "Large Language Models On Graphs: A Comprehensive Survey", "topic_distr": {"0": 0.001057695597410202, "1": 0.0008632283424958587, "2": 0.0007296223775483668, "3": 0.34512242674827576, "4": 0.0005573565722443163, "5": 0.0004985140985809267, "6": 0.00045091024367138743, "7": 0.0004116053460165858, "8": 0.00037860337761230767, "9": 0.0003505006607156247, "10": 0.00032628164626657963, "11": 0.00030519335996359587, "12": 0.3427729904651642, "13": 0.0002702584315557033, "14": 0.0002556278486736119, "15": 0.00024249996931757778, "16": 0.2042035311460495, "17": 0.00021991257381159812, "18": 0.1007821187376976, "19": 0.00020117437816224992}}, {"key": "jin2023time", "year": "2023", "title": "Time-llm: Time Series Forecasting By Reprogramming Large Language Models", "topic_distr": {"0": 0.06490065902471542, "1": 0.0585826113820076, "2": 0.12639875710010529, "3": 0.3526441156864166, "4": 0.0005669590318575501, "5": 0.0005071017076261342, "6": 0.0004586776194628328, "7": 0.06525831669569016, "8": 0.0003851251967716962, "9": 0.0003565383958630264, "10": 0.00033190217800438404, "11": 0.00031045061768963933, "12": 0.1806163340806961, "13": 0.00027491390937939286, "14": 0.00026003128732554615, "15": 0.00024667728575877845, "16": 0.00023462787794414908, "17": 0.0002237007865915075, "18": 0.1472378969192505, "19": 0.0002046398149104789}}, {"key": "jin2024hidden", "year": "2024", "title": "Hidden Flaws Behind Expert-level Accuracy Of Multimodal GPT-4 Vision In Medicine", "topic_distr": {"0": 0.19466517865657806, "1": 0.0011315328301861882, "2": 0.0009566687513142824, "3": 0.18646249175071716, "4": 0.00073077721754089, "5": 0.0006536265718750656, "6": 0.000591210788115859, "7": 0.0005396762862801552, "8": 0.0425691194832325, "9": 0.12386176735162735, "10": 0.04815826192498207, "11": 0.04759521409869194, "12": 0.13953275978565216, "13": 0.034270029515028, "14": 0.0003351664054207504, "15": 0.0003179537889081985, "16": 0.020482053980231285, "17": 0.0002883383131120354, "18": 0.15659445524215698, "19": 0.0002637697325553745}}, {"key": "jo2024understanding", "year": "2024", "title": "Understanding The Impact Of Long-term Memory On Self-disclosure With Large Language Model-driven Chatbots For Public Health Intervention", "topic_distr": {"0": 0.046280551701784134, "1": 0.22756071388721466, "2": 0.0010250729974359274, "3": 0.0008878704975359142, "4": 0.000783062307164073, "5": 0.0007003910141065717, "6": 0.014031735248863697, "7": 0.0005782879306934774, "8": 0.0005319215706549585, "9": 0.5958596467971802, "10": 0.000458411785075441, "11": 0.0004287836200091988, "12": 0.00040275274659506977, "13": 0.0003797015524469316, "14": 0.00035914621548727155, "15": 0.0003407020994927734, "16": 0.10850436240434647, "17": 0.00030896777752786875, "18": 0.0002952188369818032, "19": 0.0002826414129231125}}, {"key": "johnson2016multilingual", "year": "2016", "title": "Google's Multilingual Neural Machine Translation System: Enabling Zero-shot Translation", "topic_distr": {"0": 0.0009383367141708732, "1": 0.000765926786698401, "2": 0.39770859479904175, "3": 0.0208890363574028, "4": 0.022305618971586227, "5": 0.0004423840728122741, "6": 0.0004001400957349688, "7": 0.015307696536183357, "8": 0.0003359746187925339, "9": 0.01469718012958765, "10": 0.0002895440557040274, "11": 0.0002708301763050258, "12": 0.0002543884329497814, "13": 0.039112579077482224, "14": 0.48530176281929016, "15": 0.00021519574511330575, "16": 0.00020468411094043404, "17": 0.00019515157327987254, "18": 0.00018646741227712482, "19": 0.00017852320161182433}}, {"key": "jones2020robust", "year": "2020", "title": "Robust Encodings: A Framework For Combating Adversarial Typos", "topic_distr": {"0": 0.0013409099774435163, "1": 0.2891385853290558, "2": 0.2231656014919281, "3": 0.13724520802497864, "4": 0.0007071836735121906, "5": 0.05856228247284889, "6": 0.0005721222842112184, "7": 0.000522251648362726, "8": 0.0004803781630471349, "9": 0.000444720993982628, "10": 0.2850012481212616, "11": 0.00038723432226106524, "12": 0.0003637258487287909, "13": 0.00034290834446437657, "14": 0.00032434481545351446, "15": 0.0003076879365835339, "16": 0.0002926583692897111, "17": 0.0002790286671370268, "18": 0.0002666120417416096, "19": 0.00025525334058329463}}, {"key": "jones2022capturing", "year": "2022", "title": "Capturing Failures Of Large Language Models Via Human Cognitive Biases", "topic_distr": {"0": 0.5489934682846069, "1": 0.0011192794190719724, "2": 0.0009460623259656131, "3": 0.08743683993816376, "4": 0.0007226892048493028, "5": 0.0006463918252848089, "6": 0.12390703707933426, "7": 0.07932331413030624, "8": 0.0004909109557047486, "9": 0.08484162390232086, "10": 0.0004230687045492232, "11": 0.0003957248409278691, "12": 0.0003717009094543755, "13": 0.00035042696981690824, "14": 0.00033145639463327825, "15": 0.0003144342917948961, "16": 0.00029907518182881176, "17": 0.06855317950248718, "18": 0.0002724577789194882, "19": 0.000260850036283955}}, {"key": "jones2023does", "year": "2023", "title": "Does GPT-4 Pass The Turing Test?", "topic_distr": {"0": 0.3951477110385895, "1": 0.0015915186377242208, "2": 0.0013453474966809154, "3": 0.0803452879190445, "4": 0.10174977034330368, "5": 0.0009191760909743607, "6": 0.0008314026053994894, "7": 0.0007589309825561941, "8": 0.000698080868460238, "9": 0.24140608310699463, "10": 0.0006016084807924926, "11": 0.07760591804981232, "12": 0.0005285628722049296, "13": 0.0004983110702596605, "14": 0.000471334729809314, "15": 0.0004471291322261095, "16": 0.02212720923125744, "17": 0.0721682533621788, "18": 0.0003874380199704319, "19": 0.00037093169521540403}}, {"key": "joshi2017large", "year": "2017", "title": "Triviaqa: A Large Scale Distantly Supervised Challenge Dataset For Reading Comprehension", "topic_distr": {"0": 0.0016424948116764426, "1": 0.0013402237091213465, "2": 0.5320041179656982, "3": 0.09578295797109604, "4": 0.0008653305121697485, "5": 0.0007739742286503315, "6": 0.0007000662735663354, "7": 0.0006390429334715009, "8": 0.33887168765068054, "9": 0.0005441741086542606, "10": 0.0005065725999884307, "11": 0.02335326373577118, "12": 0.00044506596168503165, "13": 0.0004195930378045887, "14": 0.00039687813841737807, "15": 0.0003764962893910706, "16": 0.0003581056371331215, "17": 0.00034142794902436435, "18": 0.00032623455626890063, "19": 0.0003123357309959829}}, {"key": "joshi2022repair", "year": "2022", "title": "Repair Is Nearly Generation: Multilingual Program Repair With Llms", "topic_distr": {"0": 0.0013422103365883231, "1": 0.0010951540898531675, "2": 0.000925806351006031, "3": 0.6099032759666443, "4": 0.059191636741161346, "5": 0.0006325433496385813, "6": 0.05644295737147331, "7": 0.0005222685285843909, "8": 0.0004803936753887683, "9": 0.10482113808393478, "10": 0.0004140048986300826, "11": 0.00038724683690816164, "12": 0.0003637376066762954, "13": 0.0003429194330237806, "14": 0.09990304708480835, "15": 0.0003076978900935501, "16": 0.00029266782803460956, "17": 0.062109459191560745, "18": 0.00026662065647542477, "19": 0.00025526160607114434}}, {"key": "joshi2023chatgpt", "year": "2023", "title": "Chatgpt In The Classroom: An Analysis Of Its Strengths And Weaknesses For Solving Undergraduate Computer Science Questions", "topic_distr": {"0": 0.001539958524517715, "1": 0.17344845831394196, "2": 0.001062934985384345, "3": 0.000920647697057575, "4": 0.015346297062933445, "5": 0.0007262457511387765, "6": 0.0006568953976966441, "7": 0.11876951903104782, "8": 0.10566256940364838, "9": 0.5191856622695923, "10": 0.0004753338871523738, "11": 0.0004446120001375675, "12": 0.0004176202055532485, "13": 0.00039371810271404684, "14": 0.03551894426345825, "15": 0.00035327899968251586, "16": 0.024157725274562836, "17": 0.00032037319033406675, "18": 0.00030611673719249666, "19": 0.0002930750197265297}}, {"key": "joshi2023not", "year": "2023", "title": "\"it's Not Like Jarvis, But It's Pretty Close!\" -- Examining Chatgpt's Usage Among Undergraduate Students In Computer Science", "topic_distr": {"0": 0.0013416314031928778, "1": 0.001095196115784347, "2": 0.0009257880738005042, "3": 0.0008018413209356368, "4": 0.0007071904256008565, "5": 0.0006325294962152839, "6": 0.09722289443016052, "7": 0.0005222571780905128, "8": 0.00048038322711363435, "9": 0.8930368423461914, "10": 0.0004139959055464715, "11": 0.00038723842590115964, "12": 0.00036372969043441117, "13": 0.00034291198244318366, "14": 0.00032434824970550835, "15": 0.00030769119621254504, "16": 0.00029266145429573953, "17": 0.0002790316357277334, "18": 0.0002666148648131639, "19": 0.0002552560472395271}}, {"key": "ju2019technical", "year": "2019", "title": "Technical Report On Conversational Question Answering", "topic_distr": {"0": 0.0029690214432775974, "1": 0.1996479332447052, "2": 0.0020498367957770824, "3": 0.0017753929132595658, "4": 0.0015658277552574873, "5": 0.001400515204295516, "6": 0.1289442628622055, "7": 0.0011563554871827364, "8": 0.1522955745458603, "9": 0.0009846892207860947, "10": 0.08378174901008606, "11": 0.06675171107053757, "12": 0.0008053519413806498, "13": 0.3520509600639343, "14": 0.0007181555265560746, "15": 0.0006812743376940489, "16": 0.0006479962612502277, "17": 0.0006178177427500486, "18": 0.0005903251585550606, "19": 0.0005651750834658742}}, {"key": "ju2021prompting", "year": "2021", "title": "Prompting Visual-language Models For Efficient Video Understanding", "topic_distr": {"0": 0.0015602376079186797, "1": 0.0012732273899018764, "2": 0.001076272688806057, "3": 0.0009321753168478608, "4": 0.0008221397874876857, "5": 0.0007353428518399596, "6": 0.0006651238072663546, "7": 0.0006071464158594608, "8": 0.0005584661848843098, "9": 0.0005170127842575312, "10": 0.10873132944107056, "11": 0.03818540275096893, "12": 0.0004228514153510332, "13": 0.07686813175678253, "14": 0.000377068790839985, "15": 0.0003577042662072927, "16": 0.00034023154876194894, "17": 0.32399606704711914, "18": 0.3842184245586395, "19": 0.05775565281510353}}, {"key": "junczysdowmunt2019microsoft", "year": "2019", "title": "Microsoft Translator At WMT 2019: Towards Large-scale Document-level Neural Machine Translation", "topic_distr": {"0": 0.07198695838451385, "1": 0.13338035345077515, "2": 0.05858829990029335, "3": 0.0008672418189235032, "4": 0.034190911799669266, "5": 0.0006841201102361083, "6": 0.02697047032415867, "7": 0.024056673049926758, "8": 0.0005195642588660121, "9": 0.00048099839477799833, "10": 0.16548016667366028, "11": 0.0004188223392702639, "12": 0.00039339621434919536, "13": 0.02913084626197815, "14": 0.4090252220630646, "15": 0.020844751968979836, "16": 0.00031653151381760836, "17": 0.00030179001623764634, "18": 0.0002883604902308434, "19": 0.022074487060308456}}, {"key": "jung2022maieutic", "year": "2022", "title": "Maieutic Prompting: Logically Consistent Reasoning With Recursive Explanations", "topic_distr": {"0": 0.0015224654925987124, "1": 0.0012424925807863474, "2": 0.0010499764466658235, "3": 0.43925023078918457, "4": 0.0008020678069442511, "5": 0.0991782620549202, "6": 0.0006488860817626119, "7": 0.017432620748877525, "8": 0.04906604811549187, "9": 0.0005043908604420722, "10": 0.0004695383249782026, "11": 0.10272250324487686, "12": 0.0004125283157918602, "13": 0.00038891765871085227, "14": 0.0003678633947856724, "15": 0.00034897157456725836, "16": 0.00033192543196491897, "17": 0.23295655846595764, "18": 0.00030238437466323376, "19": 0.05100138857960701}}, {"key": "juraska2018deep", "year": "2018", "title": "A Deep Ensemble Model With Slot Alignment For Sequence-to-sequence Natural Language Generation", "topic_distr": {"0": 0.0024981515016406775, "1": 0.0702173113822937, "2": 0.2445799559354782, "3": 0.0014912951737642288, "4": 0.07743830978870392, "5": 0.001176405348815024, "6": 0.29717180132865906, "7": 0.000971315719652921, "8": 0.0008934368379414082, "9": 0.0008271194528788328, "10": 0.0007699668640270829, "11": 0.06924648582935333, "12": 0.14259156584739685, "13": 0.0006377620156854391, "14": 0.0006032364326529205, "15": 0.0868520736694336, "16": 0.0005443040281534195, "17": 0.0005189547082409263, "18": 0.0004958614590577781, "19": 0.0004747358907479793}}, {"key": "k2022can", "year": "2022", "title": "Can Language Models Learn From Explanations In Context?", "topic_distr": {"0": 0.001200622646138072, "1": 0.0009794769575819373, "2": 0.30887141823768616, "3": 0.20228178799152374, "4": 0.0006323633133433759, "5": 0.17246480286121368, "6": 0.0005115921958349645, "7": 0.05866860970854759, "8": 0.022464653477072716, "9": 0.00039766982081346214, "10": 0.0003701914974953979, "11": 0.0003462652093730867, "12": 0.00032524392008781433, "13": 0.0003066288772970438, "14": 0.00029002936207689345, "15": 0.000275134778348729, "16": 0.00026169532793574035, "17": 0.16464854776859283, "18": 0.00023840466747060418, "19": 0.06446488201618195}}, {"key": "kacupaj2021conversational", "year": "2021", "title": "Conversational Question Answering Over Knowledge Graphs With Transformer And Graph Attention Networks", "topic_distr": {"0": 0.0013706503668799996, "1": 0.0011190450750291348, "2": 0.4002014994621277, "3": 0.0008194180554710329, "4": 0.0007226906018331647, "5": 0.0006463932804763317, "6": 0.06946326792240143, "7": 0.0005337038892321289, "8": 0.17696942389011383, "9": 0.0004544731345959008, "10": 0.04418392851948738, "11": 0.01897025667130947, "12": 0.0003717018698807806, "13": 0.0003504278720356524, "14": 0.00033145726774819195, "15": 0.00031443513580597937, "16": 0.2823587954044342, "17": 0.00028514739824458957, "18": 0.00027245847741141915, "19": 0.0002608507056720555}}, {"key": "kadavath2022language", "year": "2022", "title": "Language Models (mostly) Know What They Know", "topic_distr": {"0": 0.2385166436433792, "1": 0.09505191445350647, "2": 0.22377453744411469, "3": 0.15505871176719666, "4": 0.0006511914543807507, "5": 0.0005824428517371416, "6": 0.000526824442204088, "7": 0.08385954797267914, "8": 0.1670917123556137, "9": 0.0004095101321581751, "10": 0.00038121367106214166, "11": 0.03185610473155975, "12": 0.0003349278122186661, "13": 0.0003157585160806775, "14": 0.0002986647596117109, "15": 0.00028332669171504676, "16": 0.00026948709273710847, "17": 0.00025693653151392937, "18": 0.0002455029753036797, "19": 0.00023504362616222352}}, {"key": "kaddour2023challenges", "year": "2023", "title": "Challenges And Applications Of Large Language Models", "topic_distr": {"0": 0.0030410669278353453, "1": 0.00248434254899621, "2": 0.0021000485867261887, "3": 0.001818845048546791, "4": 0.0016041332855820656, "5": 0.0014347792603075504, "6": 0.0012977693695574999, "7": 0.0011846456909552217, "8": 0.0010896623134613037, "9": 0.6373046040534973, "10": 0.0009390746126882732, "11": 0.1777583211660385, "12": 0.16325059533119202, "13": 0.000777833629399538, "14": 0.0007357251597568393, "15": 0.0006979416939429939, "16": 0.000663849466945976, "17": 0.0006329326424747705, "18": 0.0006047674687579274, "19": 0.0005790020804852247}}, {"key": "kalai2023calibrated", "year": "2023", "title": "Calibrated Language Models Must Hallucinate", "topic_distr": {"0": 0.47262752056121826, "1": 0.1990281492471695, "2": 0.11292558163404465, "3": 0.03168579190969467, "4": 0.0005669980891980231, "5": 0.0005071377963759005, "6": 0.000458710448583588, "7": 0.07696996629238129, "8": 0.00038515275809913874, "9": 0.00035656391992233694, "10": 0.0003319259558338672, "11": 0.0003104728239122778, "12": 0.0002916244266089052, "13": 0.0002749335835687816, "14": 0.00026004991377703846, "15": 0.02879844792187214, "16": 0.0002346446708543226, "17": 0.0002237167936982587, "18": 0.0002137615083483979, "19": 0.07354885339736938}}, {"key": "kalakonda2022action", "year": "2022", "title": "Action-gpt: Leveraging Large-scale Language Models For Improved And Generalized Action Generation", "topic_distr": {"0": 0.001641027512960136, "1": 0.0013399594463407993, "2": 0.0011327826650813222, "3": 0.33631041646003723, "4": 0.0008653146796859801, "5": 0.0007739600841887295, "6": 0.0007000534678809345, "7": 0.12051080167293549, "8": 0.0005877945804968476, "9": 0.0005441642133519053, "10": 0.0005065633449703455, "11": 0.11959531903266907, "12": 0.00044505789992399514, "13": 0.000419585412601009, "14": 0.00039687094977125525, "15": 0.00037648944999091327, "16": 0.23283152282238007, "17": 0.0405658483505249, "18": 0.14014410972595215, "19": 0.0003123300557490438}}, {"key": "kale2020template", "year": "2020", "title": "Template Guided Text Generation For Task-oriented Dialogue", "topic_distr": {"0": 0.10830485075712204, "1": 0.0011844340479001403, "2": 0.001001178752630949, "3": 0.17964628338813782, "4": 0.1272876113653183, "5": 0.0006840373971499503, "6": 0.22100730240345, "7": 0.18791840970516205, "8": 0.0005195013363845646, "9": 0.00048094012890942395, "10": 0.0004477079783100635, "11": 0.0004187716112937778, "12": 0.0003933485713787377, "13": 0.1688394844532013, "14": 0.0003507602377794683, "15": 0.00033274677116423845, "16": 0.0003164931549690664, "17": 0.0003017534618265927, "18": 0.00028832556563429534, "19": 0.0002760417992249131}}, {"key": "kale2020text", "year": "2020", "title": "Text-to-text Pre-training For Data-to-text Tasks", "topic_distr": {"0": 0.0028377689886838198, "1": 0.0023148702457547188, "2": 0.42452412843704224, "3": 0.10457362979650497, "4": 0.001494734431616962, "5": 0.0013369295047596097, "6": 0.0012092641554772854, "7": 0.045845139771699905, "8": 0.0010153495240956545, "9": 0.0009399828850291669, "10": 0.18907363712787628, "11": 0.0008184764301404357, "12": 0.17285072803497314, "13": 0.0007247869507409632, "14": 0.0474788174033165, "15": 0.0006503434851765633, "16": 0.000618576246779412, "17": 0.000589767936617136, "18": 0.0005635235575027764, "19": 0.0005395152838900685}}, {"key": "kaliamoorthi2021distilling", "year": "2021", "title": "Distilling Large Language Models Into Tiny And Effective Students Using Pqrnn", "topic_distr": {"0": 0.0012864603195339441, "1": 0.043931856751441956, "2": 0.1619926393032074, "3": 0.0007687562028877437, "4": 0.0006780092371627688, "5": 0.0006064294720999897, "6": 0.0005485205329023302, "7": 0.0005007071886211634, "8": 0.00046056113205850124, "9": 0.0004263749287929386, "10": 0.12507446110248566, "11": 0.00037125975359231234, "12": 0.00034872107789851725, "13": 0.4628061354160309, "14": 0.1988557130098343, "15": 0.0002949948830064386, "16": 0.00028058531461283565, "17": 0.00026751792756840587, "18": 0.0002556135004851967, "19": 0.00024472340010106564}}, {"key": "kalyan2021ammus", "year": "2021", "title": "AMMUS : A Survey Of Transformer-based Pretrained Models In Natural Language Processing", "topic_distr": {"0": 0.0012471663067117333, "1": 0.0010186448926106095, "2": 0.0008609177893958986, "3": 0.0007456695893779397, "4": 0.0006576505838893354, "5": 0.0005882204277440906, "6": 0.0005320499767549336, "7": 0.00048567235353402793, "8": 0.00044673174852505326, "9": 0.00041357206646353006, "10": 0.1864641010761261, "11": 0.0003601118514779955, "12": 0.6234169602394104, "13": 0.0003188905247952789, "14": 0.0003016272094100714, "15": 0.0002861370157916099, "16": 0.0002721601340454072, "17": 0.10480906069278717, "18": 0.00024793812190182507, "19": 0.07652677595615387}}, {"key": "kalyan2023survey", "year": "2023", "title": "A Survey Of GPT-3 Family Large Language Models Including Chatgpt And GPT-4", "topic_distr": {"0": 0.0009897901909425855, "1": 0.07137494534254074, "2": 0.0006832970539107919, "3": 0.0005918307579122484, "4": 0.016868753358721733, "5": 0.0004668615001719445, "6": 0.0004222801944706589, "7": 0.0003854709502775222, "8": 0.0003545643703546375, "9": 0.22261150181293488, "10": 0.015955353155732155, "11": 0.00028581544756889343, "12": 0.4234154224395752, "13": 0.11383716762065887, "14": 0.00023939706443343312, "15": 0.00022710271878167987, "16": 0.0002160094736609608, "17": 0.05491149052977562, "18": 0.00019678482203744352, "19": 0.07596616446971893}}, {"key": "kamalloo2023evaluating", "year": "2023", "title": "Evaluating Open-domain Question Answering In The Era Of Large Language Models", "topic_distr": {"0": 0.2432747632265091, "1": 0.0007717772969044745, "2": 0.028056472539901733, "3": 0.4227319657802582, "4": 0.09918677806854248, "5": 0.00044570237514562905, "6": 0.00040314154466614127, "7": 0.000368000561138615, "8": 0.18482334911823273, "9": 0.0003133692080155015, "10": 0.00029171592905186117, "11": 0.00027286168187856674, "12": 0.0002562965964898467, "13": 0.00024162771296687424, "14": 0.00022854706912767142, "15": 0.017563065513968468, "16": 0.00020621945441234857, "17": 0.00019661539408843964, "18": 0.000187866113265045, "19": 0.0001798622979549691}}, {"key": "kamath2022new", "year": "2022", "title": "A New Path: Scaling Vision-and-language Navigation With Synthetic Instructions And Imitation Learning", "topic_distr": {"0": 0.0009977220324799418, "1": 0.25634244084358215, "2": 0.04590960592031479, "3": 0.000596526893787086, "4": 0.0005261108744889498, "5": 0.00047056752373464406, "6": 0.0004256322863511741, "7": 0.03457169979810715, "8": 0.00035737891448661685, "9": 0.0003308516461402178, "10": 0.014893628656864166, "11": 0.5552636981010437, "12": 0.00027059504645876586, "13": 0.0002551077923271805, "14": 0.016346558928489685, "15": 0.00022890546824783087, "16": 0.00021772415493614972, "17": 0.00020758430764544755, "18": 0.060043804347515106, "19": 0.011743834242224693}}, {"key": "kanade2019learning", "year": "2019", "title": "Learning And Evaluating Contextual Embedding Of Source Code", "topic_distr": {"0": 0.0013131415471434593, "1": 0.08775150775909424, "2": 0.26056358218193054, "3": 0.0007849668036215007, "4": 0.0006923068431206048, "5": 0.0006192171713337302, "6": 0.12305852025747299, "7": 0.0005112655344419181, "8": 0.000470272934762761, "9": 0.0004353658587206155, "10": 0.3155229091644287, "11": 0.0003790884802583605, "12": 0.14571836590766907, "13": 0.06049018353223801, "14": 0.000317521917168051, "15": 0.00030121541931293905, "16": 0.0002865020069293678, "17": 0.0002731590357143432, "18": 0.0002610035880934447, "19": 0.00024988385848701}}, {"key": "kandasamy2017batch", "year": "2017", "title": "Batch Policy Gradient Methods For Improving Neural Conversation Models", "topic_distr": {"0": 0.0019490537233650684, "1": 0.10632985830307007, "2": 0.2511899471282959, "3": 0.0011651029344648123, "4": 0.06155623495578766, "5": 0.0009190842974931002, "6": 0.04862618446350098, "7": 0.0007588550797663629, "8": 0.0006980110774748027, "9": 0.08799976110458374, "10": 0.0006015482940711081, "11": 0.43467220664024353, "12": 0.0005285100196488202, "13": 0.0004982612445019186, "14": 0.0004712875816039741, "15": 0.0004470843996386975, "16": 0.00042524575837887824, "17": 0.00040544121293351054, "18": 0.00038739925366826355, "19": 0.0003708945878315717}}, {"key": "kandpal2022large", "year": "2022", "title": "Large Language Models Struggle To Learn Long-tail Knowledge", "topic_distr": {"0": 0.12632907927036285, "1": 0.001107333111576736, "2": 0.2912363111972809, "3": 0.0008105537272058427, "4": 0.000714870635420084, "5": 0.0006393991061486304, "6": 0.0005783419474028051, "7": 0.0005279290489852428, "8": 0.38125109672546387, "9": 0.0004495555767789483, "10": 0.00041849203989841044, "11": 0.0003914439876098186, "12": 0.0003676799242384732, "13": 0.09226582944393158, "14": 0.00032787080272100866, "15": 0.0003110328398179263, "16": 0.10146360099315643, "17": 0.00028206201386637986, "18": 0.0002695104049053043, "19": 0.00025802821619436145}}, {"key": "kang2019recommendation", "year": "2019", "title": "Recommendation As A Communication Game: Self-supervised Bot-play For Goal-oriented Dialogue", "topic_distr": {"0": 0.10274277627468109, "1": 0.0009984895586967468, "2": 0.0008440702222287655, "3": 0.0007310720393434167, "4": 0.28542011976242065, "5": 0.21761105954647064, "6": 0.13931609690189362, "7": 0.0004761642776429653, "8": 0.00043798601836897433, "9": 0.0004054754972457886, "10": 0.00037745782174170017, "11": 0.15102991461753845, "12": 0.0003316279617138207, "13": 0.0003126475785393268, "14": 0.00029572221683338284, "15": 0.00028053525602445006, "16": 0.00026683200849220157, "17": 0.0002544051094446331, "18": 0.00024308421416208148, "19": 0.09762445092201233}}, {"key": "kang2022knowledge", "year": "2022", "title": "KALA: Knowledge-augmented Language Model Adaptation", "topic_distr": {"0": 0.0015806080773472786, "1": 0.0012892395025119185, "2": 0.0010898405453190207, "3": 0.0009439525310881436, "4": 0.0008325256640091538, "5": 0.0007446326781064272, "6": 0.0006735266069881618, "7": 0.000614816730376333, "8": 0.05589139461517334, "9": 0.0005235443823039532, "10": 0.2440817803144455, "11": 0.00045586866326630116, "12": 0.0004281934816390276, "13": 0.06946223974227905, "14": 0.00038183244760148227, "15": 0.00036222327616997063, "16": 0.20196190476417542, "17": 0.4180675148963928, "18": 0.000313866970827803, "19": 0.00030049507040530443}}, {"key": "kang2023do", "year": "2023", "title": "Do Llms Understand User Preferences? Evaluating Llms On User Rating Prediction", "topic_distr": {"0": 0.11200963705778122, "1": 0.09700435400009155, "2": 0.0007174713537096977, "3": 0.3112858235836029, "4": 0.35525479912757874, "5": 0.0004901979118585587, "6": 0.0004433881549630314, "7": 0.00040473893750458956, "8": 0.000372287497157231, "9": 0.0003446536138653755, "10": 0.00032083861879073083, "11": 0.0003001021104864776, "12": 0.0002818833163473755, "13": 0.10358289629220963, "14": 0.0002513634681235999, "15": 0.00023845458053983748, "16": 0.01607642136514187, "17": 0.00021624399232678115, "18": 0.00020662123279180378, "19": 0.0001978183863684535}}, {"key": "kang2023exploiting", "year": "2023", "title": "Exploiting Programmatic Behavior Of Llms: Dual-use Through Standard Security Attacks", "topic_distr": {"0": 0.11857279390096664, "1": 0.3231258988380432, "2": 0.051741257309913635, "3": 0.4444309175014496, "4": 0.0009673501481302083, "5": 0.0008652236429043114, "6": 0.0007826020009815693, "7": 0.000714384310413152, "8": 0.0006571059348061681, "9": 0.0006083307089284062, "10": 0.0005662961048074067, "11": 0.0005296951276250184, "12": 0.0004975380143150687, "13": 0.05358019843697548, "14": 0.0004436690069269389, "15": 0.00042088417103514075, "16": 0.00040032531251199543, "17": 0.00038168136961758137, "18": 0.00036469672340899706, "19": 0.00034915926516987383}}, {"key": "kant2020spatially", "year": "2020", "title": "Spatially Aware Multimodal Transformers For Textvqa", "topic_distr": {"0": 0.0014507611049339175, "1": 0.0011842508101835847, "2": 0.42514848709106445, "3": 0.0008671174291521311, "4": 0.0007647615857422352, "5": 0.000684022787027061, "6": 0.0006187044782564044, "7": 0.0005647733341902494, "8": 0.045869436115026474, "9": 0.0004809301462955773, "10": 0.051496077328920364, "11": 0.0004187629383523017, "12": 0.00039334039320237935, "13": 0.0003708279400598258, "14": 0.0003507529618218541, "15": 0.0003327398735564202, "16": 0.12801454961299896, "17": 0.00030174717539921403, "18": 0.3404119312763214, "19": 0.00027603606577031314}}, {"key": "kao2021optimized", "year": "2021", "title": "FLAT: An Optimized Dataflow For Mitigating Attention Bottlenecks", "topic_distr": {"0": 0.001086131320334971, "1": 0.0008858354412950575, "2": 0.5774083137512207, "3": 0.0006485247286036611, "4": 0.0005719728069379926, "5": 0.0005115867825224996, "6": 0.00046273457701317966, "7": 0.0004223989963065833, "8": 0.00038853156729601324, "9": 0.06177770718932152, "10": 0.00033483782317489386, "11": 0.00031319650588557124, "12": 0.06963817775249481, "13": 0.25281548500061035, "14": 0.00026233124663122, "15": 0.0002488591126166284, "16": 0.031575631350278854, "17": 0.0002256793959531933, "18": 0.00021563677000813186, "19": 0.00020644982578232884}}, {"key": "kapanipathi2020leveraging", "year": "2020", "title": "Leveraging Abstract Meaning Representation For Knowledge Base Question Answering", "topic_distr": {"0": 0.0016422069165855646, "1": 0.038533683866262436, "2": 0.15538179874420166, "3": 0.15681153535842896, "4": 0.000865369860548526, "5": 0.000774008163716644, "6": 0.0007000968907959759, "7": 0.0006390709895640612, "8": 0.1969050168991089, "9": 0.0005441979737952352, "10": 0.0005065947771072388, "11": 0.08175971359014511, "12": 0.0004450854903552681, "13": 0.0004196114605292678, "14": 0.00039689557161182165, "15": 0.00037651282036677003, "16": 0.27606308460235596, "17": 0.00034144293749704957, "18": 0.0865817442536354, "19": 0.000312349438900128}}, {"key": "kaplan2020scaling", "year": "2020", "title": "Scaling Laws For Neural Language Models", "topic_distr": {"0": 0.0020804607775062323, "1": 0.0016979832435026765, "2": 0.4314438998699188, "3": 0.0012429681373760104, "4": 0.0010962459491565824, "5": 0.0009805118897929788, "6": 0.0008868812583386898, "7": 0.0008095736848190427, "8": 0.0007446631207130849, "9": 0.0006893887766636908, "10": 0.029108287766575813, "11": 0.0006002752343192697, "12": 0.0005638333386741579, "13": 0.5253801345825195, "14": 0.0005027864244766533, "15": 0.00047696559340693057, "16": 0.00045366736594587564, "17": 0.0004325391782913357, "18": 0.00041329136001877487, "19": 0.0003956836008001119}}, {"key": "karmakar2021what", "year": "2021", "title": "What Do Pre-trained Code Models Know About Code?", "topic_distr": {"0": 0.2626478672027588, "1": 0.0010722775477916002, "2": 0.0009065092890523374, "3": 0.051222436130046844, "4": 0.0006924670888110995, "5": 0.0006193605368025601, "6": 0.3174722492694855, "7": 0.000511384045239538, "8": 0.000470381899503991, "9": 0.00043546673259697855, "10": 0.17116428911685944, "11": 0.00037917631561867893, "12": 0.03608540818095207, "13": 0.02779318578541279, "14": 0.00031759546254761517, "15": 0.0003012852102983743, "16": 0.043814342468976974, "17": 0.035930659621953964, "18": 0.0002610640658531338, "19": 0.047902610152959824}}, {"key": "karpinska2023large", "year": "2023", "title": "Large Language Models Effectively Leverage Document-level Context For Literary Translation, But Critical Errors Persist", "topic_distr": {"0": 0.1830926239490509, "1": 0.10611946880817413, "2": 0.000946140440646559, "3": 0.22482207417488098, "4": 0.0007227426976896822, "5": 0.000646438857074827, "6": 0.0005847091670148075, "7": 0.0005337413167580962, "8": 0.10140489041805267, "9": 0.00045450497418642044, "10": 0.00042309946729801595, "11": 0.00039575359551236033, "12": 0.12084008008241653, "13": 0.030501816421747208, "14": 0.2270798683166504, "15": 0.0003144571674056351, "16": 0.00029909692239016294, "17": 0.00028516739257611334, "18": 0.00027247756952419877, "19": 0.00026086901198141277}}, {"key": "karpukhin2020dense", "year": "2020", "title": "Dense Passage Retrieval For Open-domain Question Answering", "topic_distr": {"0": 0.0020437934435904026, "1": 0.0016693732468411326, "2": 0.37516868114471436, "3": 0.0012223805533722043, "4": 0.0010780907468870282, "5": 0.000964271544944495, "6": 0.0008721917984075844, "7": 0.0007961647352203727, "8": 0.4015786945819855, "9": 0.0006779704708606005, "10": 0.10948553681373596, "11": 0.0005903329001739621, "12": 0.0005544945597648621, "13": 0.0005227585788816214, "14": 0.0004944587708450854, "15": 0.0004690656205639243, "16": 0.00044615325168706477, "17": 0.0004253750084899366, "18": 0.0004064460226800293, "19": 0.10053376108407974}}, {"key": "kasai2020non", "year": "2020", "title": "Non-autoregressive Machine Translation With Disentangled Context Transformer", "topic_distr": {"0": 0.0013413968263193965, "1": 0.0010950978612527251, "2": 0.28370314836502075, "3": 0.0008017862564884126, "4": 0.0007071439758874476, "5": 0.0006324875866994262, "6": 0.0005720903864130378, "7": 0.2171124964952469, "8": 0.0004803513584192842, "9": 0.0004446961684152484, "10": 0.1247330978512764, "11": 0.00038721272721886635, "12": 0.00036370556335896254, "13": 0.1175915077328682, "14": 0.24863263964653015, "15": 0.0003076707653235644, "16": 0.0002926420420408249, "17": 0.00027901309658773243, "18": 0.0002665971696842462, "19": 0.0002552391088102013}}, {"key": "kasai2023evaluating", "year": "2023", "title": "Evaluating GPT-4 And Chatgpt On Japanese Medical Licensing Examinations", "topic_distr": {"0": 0.12669335305690765, "1": 0.0010392440017312765, "2": 0.0008785951067693532, "3": 0.3512677848339081, "4": 0.017232082784175873, "5": 0.0006002925802022219, "6": 0.000542969792149961, "7": 0.0004956402699463069, "8": 0.01445308793336153, "9": 0.08911239355802536, "10": 0.00039289655978791416, "11": 0.00036750276922248304, "12": 0.33303555846214294, "13": 0.06225098296999931, "14": 0.00030781779787503183, "15": 0.000292009674012661, "16": 0.0002777459449134767, "17": 0.0002648107474669814, "18": 0.00025302681024186313, "19": 0.00024224691151175648}}, {"key": "kassner2019negated", "year": "2019", "title": "Negated And Misprimed Probes For Pretrained Language Models: Birds Can Talk, But Cannot Fly", "topic_distr": {"0": 0.1224970743060112, "1": 0.0022632437758147717, "2": 0.0019132670713588595, "3": 0.0016571268206462264, "4": 0.0014615206746384501, "5": 0.0013072220608592033, "6": 0.001182393403723836, "7": 0.0010793267283588648, "8": 0.04520697146654129, "9": 0.0009190957644023001, "10": 0.21494722366333008, "11": 0.0008002892136573792, "12": 0.0007517047342844307, "13": 0.0007086816476657987, "14": 0.0006703168037347496, "15": 0.0006358923274092376, "16": 0.17155620455741882, "17": 0.17327876389026642, "18": 0.0005510016344487667, "19": 0.25661271810531616}}, {"key": "kassner2021multilingual", "year": "2021", "title": "Multilingual LAMA: Investigating Knowledge In Multilingual Pretrained Language Models", "topic_distr": {"0": 0.16653962433338165, "1": 0.0013953332090750337, "2": 0.0011794407619163394, "3": 0.0010215387446805835, "4": 0.0009009537752717733, "5": 0.0008058371604420245, "6": 0.0007288864580914378, "7": 0.03704983741044998, "8": 0.040370263159275055, "9": 0.0005665766075253487, "10": 0.07228914648294449, "11": 0.000493338331580162, "12": 0.00046338842366822064, "13": 0.00043686683056876063, "14": 0.25014007091522217, "15": 0.00039199585444293916, "16": 0.21139724552631378, "17": 0.0003554838476702571, "18": 0.0003396649844944477, "19": 0.2131345272064209}}, {"key": "kaur2024from", "year": "2024", "title": "From Text To Transformation: A Comprehensive Review Of Large Language Models' Versatility", "topic_distr": {"0": 0.0812041386961937, "1": 0.0013226369628682733, "2": 0.00111808639485389, "3": 0.23797699809074402, "4": 0.0008541273418813944, "5": 0.0007639544201083481, "6": 0.0006910032825544477, "7": 0.0006307700532488525, "8": 0.0005801956867799163, "9": 0.219947949051857, "10": 0.14014028012752533, "11": 0.00046769753680564463, "12": 0.3118038773536682, "13": 0.0004141610988881439, "14": 0.0003917402646038681, "15": 0.00037162224180065095, "16": 0.0003534696879796684, "17": 0.00033700792118906975, "18": 0.00032201121211983263, "19": 0.0003082923067267984}}, {"key": "kayser2021e", "year": "2021", "title": "E-vil: A Dataset And Benchmark For Natural Language Explanations In Vision-language Tasks", "topic_distr": {"0": 0.0014022333780303597, "1": 0.001144503359682858, "2": 0.0009673724416643381, "3": 0.0008378549828194082, "4": 0.030129695311188698, "5": 0.16713032126426697, "6": 0.0005978231783956289, "7": 0.0005457121878862381, "8": 0.0005019577220082283, "9": 0.0004646987363230437, "10": 0.0004325888294260949, "11": 0.0004046296526212245, "12": 0.19912919402122498, "13": 0.0003583124780561775, "14": 0.0003389150369912386, "15": 0.3265182077884674, "16": 0.00030580515158362687, "17": 0.00029156319214962423, "18": 0.2682318687438965, "19": 0.0002667198423296213}}, {"key": "kazemitabaar2024evaluating", "year": "2024", "title": "Codeaid: Evaluating A Classroom Deployment Of An Llm-based Programming Assistant That Balances Student And Educator Needs", "topic_distr": {"0": 0.20512746274471283, "1": 0.0011318401666358113, "2": 0.0009567195666022599, "3": 0.05257529020309448, "4": 0.0007308131898753345, "5": 0.06554567068815231, "6": 0.18054404854774475, "7": 0.000539701955858618, "8": 0.049124136567115784, "9": 0.44038286805152893, "10": 0.0004278245032764971, "11": 0.000400173244997859, "12": 0.0003758792590815574, "13": 0.00035436617326922715, "14": 0.0003351823834236711, "15": 0.000317968922900036, "16": 0.00030243716901168227, "17": 0.00028835205012001097, "18": 0.00027552052051760256, "19": 0.0002637823054101318}}, {"key": "kazemnejad2023impact", "year": "2023", "title": "The Impact Of Positional Encoding On Length Generalization In Transformers", "topic_distr": {"0": 0.18980450928211212, "1": 0.000917472701985389, "2": 0.47623303532600403, "3": 0.0425834022462368, "4": 0.0005924968863837421, "5": 0.0005299450131133199, "6": 0.0004793396801687777, "7": 0.00043755670776590705, "8": 0.0004024739610031247, "9": 0.00037259943201206625, "10": 0.28528496623039246, "11": 0.00032443550298921764, "12": 0.00030473945662379265, "13": 0.00028729799669235945, "14": 0.00027174496790394187, "15": 0.0002577893901616335, "16": 0.0002451971813570708, "17": 0.0002337778714718297, "18": 0.00022337486734613776, "19": 0.0002138582494808361}}, {"key": "ke2020rethinking", "year": "2020", "title": "Rethinking Positional Encoding In Language Pre-training", "topic_distr": {"0": 0.0013138109352439642, "1": 0.0010721038561314344, "2": 0.5973697900772095, "3": 0.0007850425317883492, "4": 0.0006923775654286146, "5": 0.0006192794535309076, "6": 0.0005601434386335313, "7": 0.0005113169900141656, "8": 0.013950057327747345, "9": 0.00043540963088162243, "10": 0.3064340054988861, "11": 0.0003791266062762588, "12": 0.00035611033672466874, "13": 0.07383199781179428, "14": 0.00031755384407006204, "15": 0.0003012457164004445, "16": 0.00028653081972151995, "17": 0.00027318650973029435, "18": 0.0002610298397485167, "19": 0.00024990897509269416}}, {"key": "ke2022hierarchical", "year": "2022", "title": "Hitskt: A Hierarchical Transformer Model For Session-aware Knowledge Tracing", "topic_distr": {"0": 0.0009037794079631567, "1": 0.0007380098686553538, "2": 0.38430914282798767, "3": 0.0005403703544288874, "4": 0.1000189483165741, "5": 0.0004262698348611593, "6": 0.00038556463550776243, "7": 0.00035195579403080046, "8": 0.042736537754535675, "9": 0.2061968445777893, "10": 0.0749061182141304, "11": 0.00026096493820659816, "12": 0.0002451221225783229, "13": 0.00023109278117772192, "14": 0.00021858245600014925, "15": 0.00020735705038532615, "16": 0.18678361177444458, "17": 0.00018804300634656101, "18": 0.00017967517487704754, "19": 0.00017202032904606313}}, {"key": "keh2019myers", "year": "2019", "title": "Myers-briggs Personality Classification And Personality-specific Language Generation Using Pre-trained Language Models", "topic_distr": {"0": 0.4954880177974701, "1": 0.0024838855024427176, "2": 0.23777231574058533, "3": 0.0018186982488259673, "4": 0.0016040204791352153, "5": 0.0014346768148243427, "6": 0.001297677168622613, "7": 0.11128801107406616, "8": 0.001089584780856967, "9": 0.001008707913570106, "10": 0.13831941783428192, "11": 0.0008783176890574396, "12": 0.0008249962120316923, "13": 0.0007777783321216702, "14": 0.000735672889277339, "15": 0.0006978920428082347, "16": 0.0006638022605329752, "17": 0.0006328876479528844, "18": 0.0006047244532965124, "19": 0.0005789609276689589}}, {"key": "kenter2017attentive", "year": "2017", "title": "Attentive Memory Networks: Efficient Machine Reading For Conversational Search", "topic_distr": {"0": 0.06390757113695145, "1": 0.0008019790984690189, "2": 0.17477408051490784, "3": 0.0005872101755812764, "4": 0.03532262519001961, "5": 0.00046321848640218377, "6": 0.21393997967243195, "7": 0.00038246295298449695, "8": 0.17559589445590973, "9": 0.03032821975648403, "10": 0.00030318033532239497, "11": 0.0002835851046256721, "12": 0.00026636902475729585, "13": 0.13115783035755157, "14": 0.06805647164583206, "15": 0.00022533052833750844, "16": 0.10301744937896729, "17": 0.00020434237376321107, "18": 0.0001952492311829701, "19": 0.00018693087622523308}}, {"key": "kerr2023language", "year": "2023", "title": "LERF: Language Embedded Radiance Fields", "topic_distr": {"0": 0.17940618097782135, "1": 0.001455254852771759, "2": 0.0012299304362386465, "3": 0.0010652955388650298, "4": 0.000939546269364655, "5": 0.0008403541869483888, "6": 0.0007601074757985771, "7": 0.0006938505684956908, "8": 0.0006382184801623225, "9": 0.0005908452440053225, "10": 0.0005500188563019037, "11": 0.08765023201704025, "12": 0.10978258401155472, "13": 0.03525860607624054, "14": 0.00043091646512039006, "15": 0.0004087865527253598, "16": 0.00038881864747963846, "17": 0.052035000175237656, "18": 0.5255363583564758, "19": 0.0003391232748981565}}, {"key": "keskar2019conditional", "year": "2019", "title": "CTRL: A Conditional Transformer Language Model For Controllable Generation", "topic_distr": {"0": 0.026526382192969322, "1": 0.20675957202911377, "2": 0.09639249742031097, "3": 0.0010502934455871582, "4": 0.043820060789585114, "5": 0.0008285176008939743, "6": 0.0485747829079628, "7": 0.3818270266056061, "8": 0.0006292287725955248, "9": 0.0005825228290632367, "10": 0.09352882206439972, "11": 0.0005072233034297824, "12": 0.07819603383541107, "13": 0.00044916238402947783, "14": 0.0004248467448633164, "15": 0.0004030285344924778, "16": 0.0003833418886642903, "17": 0.0003654889005701989, "18": 0.0003492248069960624, "19": 0.01840195059776306}}, {"key": "khademi2023can", "year": "2023", "title": "Can Chatgpt And Bard Generate Aligned Assessment Items? A Reliability Analysis Against Human Performance", "topic_distr": {"0": 0.2456907033920288, "1": 0.0012731276219710708, "2": 0.0010761540615931153, "3": 0.14672258496284485, "4": 0.0697111114859581, "5": 0.0007352843531407416, "6": 0.000665071071125567, "7": 0.0006070982199162245, "8": 0.0005584218888543546, "9": 0.46617811918258667, "10": 0.0004812498518731445, "11": 0.00045014559873379767, "12": 0.0004228178586345166, "13": 0.00039861828554421663, "14": 0.0003770388721022755, "15": 0.06338123232126236, "16": 0.0003402045404072851, "17": 0.0003243605315219611, "18": 0.0003099266323260963, "19": 0.00029672260279767215}}, {"key": "khan2023introducing", "year": "2023", "title": "Introducing Language Guidance In Prompt-based Continual Learning", "topic_distr": {"0": 0.0012349914759397507, "1": 0.0010085817193612456, "2": 0.31285059452056885, "3": 0.000738313072361052, "4": 0.0006511610699817538, "5": 0.0005824152030982077, "6": 0.0005267994711175561, "7": 0.00048087950563058257, "8": 0.0004423231875989586, "9": 0.0004094907490070909, "10": 0.0003811956266872585, "11": 0.02862164005637169, "12": 0.00033491195063106716, "13": 0.00031574355671182275, "14": 0.00029865061515010893, "15": 0.0002833132748492062, "16": 0.18265260756015778, "17": 0.32837679982185364, "18": 0.13957452774047852, "19": 0.00023503249394707382}}, {"key": "khandelwal2018sharp", "year": "2018", "title": "Sharp Nearby, Fuzzy Far Away: How Neural Language Models Use Context", "topic_distr": {"0": 0.023778926581144333, "1": 0.0012574571883305907, "2": 0.5460257530212402, "3": 0.0009206199320033193, "4": 0.0008119519334286451, "5": 0.0007262281724251807, "6": 0.0006568796234205365, "7": 0.0005996208055876195, "8": 0.0005515440134331584, "9": 0.13597659766674042, "10": 0.00047532247845083475, "11": 0.0004446013190317899, "12": 0.00041761016473174095, "13": 0.0003937086439691484, "14": 0.00037239500670693815, "15": 0.0003532705013640225, "16": 0.00033601437462493777, "17": 0.00032036550692282617, "18": 0.00030610940302722156, "19": 0.28527504205703735}}, {"key": "khandelwal2019sample", "year": "2019", "title": "Sample Efficient Text Summarization Using A Single Pre-trained Transformer", "topic_distr": {"0": 0.0017568978946655989, "1": 0.1531236469745636, "2": 0.26624614000320435, "3": 0.00105021963827312, "4": 0.0009262472740374506, "5": 0.0008284606738016009, "6": 0.0007493495941162109, "7": 0.08487261086702347, "8": 0.0006291856989264488, "9": 0.000582482956815511, "10": 0.20853306353092194, "11": 0.000507188553456217, "12": 0.0004763978358823806, "13": 0.17370176315307617, "14": 0.00042481767013669014, "15": 0.0004030009440612048, "16": 0.00038331563700921834, "17": 0.0003654638712760061, "18": 0.0003492009127512574, "19": 0.10409052670001984}}, {"key": "khandelwal2020nearest", "year": "2020", "title": "Nearest Neighbor Machine Translation", "topic_distr": {"0": 0.0015591410920023918, "1": 0.0012732070172205567, "2": 0.47365814447402954, "3": 0.0009320986573584378, "4": 0.0008220707532018423, "5": 0.0007352823740802705, "6": 0.000665069033857435, "7": 0.0006070963572710752, "8": 0.04605266451835632, "9": 0.0005169701762497425, "10": 0.00048124839668162167, "11": 0.0004501442308537662, "12": 0.0004228165780659765, "13": 0.07330477237701416, "14": 0.3968903720378876, "15": 0.00035767478402704, "16": 0.00034020349266938865, "17": 0.00032435954199172556, "18": 0.0003099257010035217, "19": 0.000296721700578928}}, {"key": "khare2021multimodal", "year": "2021", "title": "MMBERT: Multimodal BERT Pretraining For Improved Medical VQA", "topic_distr": {"0": 0.0014508797321468592, "1": 0.0011842726962640882, "2": 0.09606318920850754, "3": 0.0008671109098941088, "4": 0.0007647515740245581, "5": 0.051467165350914, "6": 0.0006186962709762156, "7": 0.0005647658836096525, "8": 0.0005194836412556469, "9": 0.0004809238016605377, "10": 0.14604152739048004, "11": 0.0004187573795206845, "12": 0.17578238248825073, "13": 0.0003708230215124786, "14": 0.00035074830520898104, "15": 0.00033273547887802124, "16": 0.00031648241565562785, "17": 0.00030174318817444146, "18": 0.4588675796985626, "19": 0.06323602050542831}}, {"key": "kharitonov2021text", "year": "2021", "title": "Text-free Prosody-aware Generative Spoken Language Modeling", "topic_distr": {"0": 0.001286610378883779, "1": 0.14576496183872223, "2": 0.0008876646170392632, "3": 0.19763274490833282, "4": 0.0006780517287552357, "5": 0.0006064669578336179, "6": 0.1593545824289322, "7": 0.17729069292545319, "8": 0.0004605896829161793, "9": 0.0004264013550709933, "10": 0.14086875319480896, "11": 0.0003712827747222036, "12": 0.0003487427020445466, "13": 0.00032878274214453995, "14": 0.00031098388717509806, "15": 0.15064211189746857, "16": 0.00028060271870344877, "17": 0.00026753448764793575, "18": 0.021947726607322693, "19": 0.0002447385631967336}}, {"key": "khashabi2020crossing", "year": "2020", "title": "Unifiedqa: Crossing Format Boundaries With A Single QA System", "topic_distr": {"0": 0.0015403368743136525, "1": 0.001257346710190177, "2": 0.5061013102531433, "3": 0.0009206196991726756, "4": 0.0008119471021927893, "5": 0.0007262268918566406, "6": 0.0006568782264366746, "7": 0.0005996195832267404, "8": 0.20229396224021912, "9": 0.017388850450515747, "10": 0.0004753214889205992, "11": 0.0004446003877092153, "12": 0.00041760929161682725, "13": 0.0003937078290618956, "14": 0.00037239425000734627, "15": 0.0003532697737682611, "16": 0.0003360136761330068, "17": 0.11256060749292374, "18": 0.0003061087627429515, "19": 0.15204328298568726}}, {"key": "khatri2018advancing", "year": "2018", "title": "Advancing The State Of The Art In Open Domain Dialog Systems Through The Alexa Prize", "topic_distr": {"0": 0.0009170876001007855, "1": 0.1264282763004303, "2": 0.05226713418960571, "3": 0.1055900901556015, "4": 0.23725269734859467, "5": 0.00043254971387796104, "6": 0.24465803802013397, "7": 0.00035714078694581985, "8": 0.0003285057027824223, "9": 0.097597636282444, "10": 0.0002831073070410639, "11": 0.0002648094668984413, "12": 0.10106950253248215, "13": 0.00023449721629731357, "14": 0.0002218025765614584, "15": 0.00021041180298198014, "16": 0.03133904188871384, "17": 0.00019081322534475476, "18": 0.00018232212460134178, "19": 0.00017455451597925276}}, {"key": "khattab2020relevance", "year": "2020", "title": "Relevance-guided Supervision For Openqa With Colbert", "topic_distr": {"0": 0.0019484704826027155, "1": 0.001591569627635181, "2": 0.3125336170196533, "3": 0.0011651255190372467, "4": 0.05212618038058281, "5": 0.0009191038552671671, "6": 0.0008313371799886227, "7": 0.0007588712614960968, "8": 0.3801855146884918, "9": 0.0006462133605964482, "10": 0.09680923819541931, "11": 0.0005626808851957321, "12": 0.0005285212537273765, "13": 0.0004982718965038657, "14": 0.00047129765152931213, "15": 0.07728258520364761, "16": 0.00042525483877398074, "17": 0.0004054498567711562, "18": 0.0003874075482599437, "19": 0.0699232816696167}}, {"key": "khattab2021robust", "year": "2021", "title": "Baleen: Robust Multi-hop Reasoning At Scale Via Condensed Retrieval", "topic_distr": {"0": 0.001356762833893299, "1": 0.001107251737266779, "2": 0.31883472204208374, "3": 0.09193048626184464, "4": 0.000714906316716224, "5": 0.0006394307129085064, "6": 0.0005783704109489918, "7": 0.0005279551260173321, "8": 0.4112527072429657, "9": 0.0004495777830015868, "10": 0.03646242246031761, "11": 0.0003914632834494114, "12": 0.0003676980850286782, "13": 0.00034665322164073586, "14": 0.0003278869844507426, "15": 0.000311048177536577, "16": 0.00029585446463897824, "17": 0.00028207595460116863, "18": 0.13356466591358185, "19": 0.0002580409636721015}}, {"key": "khattab2022demonstrate", "year": "2022", "title": "Demonstrate-search-predict: Composing Retrieval And Language Models For Knowledge-intensive NLP", "topic_distr": {"0": 0.018835633993148804, "1": 0.06528349220752716, "2": 0.0011480237590149045, "3": 0.2839966416358948, "4": 0.0008769597043283284, "5": 0.000784375355578959, "6": 0.07952424138784409, "7": 0.0006476307171396911, "8": 0.17730732262134552, "9": 0.0005514869699254632, "10": 0.0005133801605552435, "11": 0.00048019926180131733, "12": 0.0004510470025707036, "13": 0.00042523175943642855, "14": 0.0004022116190753877, "15": 0.0003815558447968215, "16": 0.00036291807191446424, "17": 0.22077354788780212, "18": 0.00033061866997741163, "19": 0.14692343771457672}}, {"key": "khattab2023compiling", "year": "2023", "title": "Dspy: Compiling Declarative Language Model Calls Into Self-improving Pipelines", "topic_distr": {"0": 0.0011447477154433727, "1": 0.018530962988734245, "2": 0.0007899514166638255, "3": 0.5662713646888733, "4": 0.0006034155376255512, "5": 0.000539710046723485, "6": 0.00048817231436260045, "7": 0.00044561937102116644, "8": 0.07032597064971924, "9": 0.00037946514203213155, "10": 0.0003532447444740683, "11": 0.0811145082116127, "12": 0.0003103547787759453, "13": 0.00029259189614094794, "14": 0.0002767522819340229, "15": 0.0002625395427457988, "16": 0.04156431183218956, "17": 0.10101544111967087, "18": 0.00022749089112039655, "19": 0.1150633841753006}}, {"key": "khattak2022multi", "year": "2022", "title": "Maple: Multi-modal Prompt Learning", "topic_distr": {"0": 0.0010842676274478436, "1": 0.0008858545334078372, "2": 0.0007487773546017706, "3": 0.1139010563492775, "4": 0.0005719640757888556, "5": 0.0005115795647725463, "6": 0.0004627280868589878, "7": 0.0004223930591251701, "8": 0.0003885261248797178, "9": 0.0003596868773456663, "10": 0.0003348331374581903, "11": 0.0003131921112071723, "12": 0.00029417863697744906, "13": 0.0002773416053969413, "14": 0.01414081733673811, "15": 0.0002488556201569736, "16": 0.0002366998087381944, "17": 0.5162894129753113, "18": 0.3483213782310486, "19": 0.0002064469299511984}}, {"key": "khattak2023self", "year": "2023", "title": "Self-regulating Prompts: Foundational Model Adaptation Without Forgetting", "topic_distr": {"0": 0.0011769327102229, "1": 0.08393511921167374, "2": 0.1085410863161087, "3": 0.04461684077978134, "4": 0.0006204820820130408, "5": 0.0005549750057980418, "6": 0.0005019796080887318, "7": 0.00045822310494259, "8": 0.000421483360696584, "9": 0.0003901977906934917, "10": 0.00036323576932772994, "11": 0.036415986716747284, "12": 0.00031913272687233984, "13": 0.0003008674830198288, "14": 0.0002845798444468528, "15": 0.0002699651231523603, "16": 0.05060045048594475, "17": 0.43723341822624207, "18": 0.23277105391025543, "19": 0.00022395905398298055}}, {"key": "kheiri2023exploiting", "year": "2023", "title": "Sentimentgpt: Exploiting GPT For Advanced Sentiment Analysis And Its Departure From Current Machine Learning", "topic_distr": {"0": 0.18049311637878418, "1": 0.15481746196746826, "2": 0.09173364192247391, "3": 0.0007240096456371248, "4": 0.0006385442684404552, "5": 0.0005711308331228793, "6": 0.0405363105237484, "7": 0.00047156240907497704, "8": 0.0004337531281635165, "9": 0.2027609795331955, "10": 0.03846920654177666, "11": 0.00034964975202456117, "12": 0.2011205106973648, "13": 0.00030962598975747824, "14": 0.0002928642206825316, "15": 0.0002778240595944226, "16": 0.0002642532344907522, "17": 0.08526431769132614, "18": 0.0002407349384156987, "19": 0.0002304787194589153}}, {"key": "khojah2024beyond", "year": "2024", "title": "Beyond Code Generation: An Observational Study Of Chatgpt Usage In Software Engineering Practice", "topic_distr": {"0": 0.2343561202287674, "1": 0.000943108694627881, "2": 0.0007972112507559359, "3": 0.07085401564836502, "4": 0.0006089826347306371, "5": 0.0005446901777759194, "6": 0.05734778940677643, "7": 0.050940219312906265, "8": 0.00041367215453647077, "9": 0.5331493020057678, "10": 0.00035650405334308743, "11": 0.0003334624052513391, "12": 0.047573696821928024, "13": 0.000295291596557945, "14": 0.00027930582291446626, "15": 0.00026496194186620414, "16": 0.0002520193811506033, "17": 0.00024028234474826604, "18": 0.00022958988847676665, "19": 0.00021980849851388484}}, {"key": "khondaker2023comprehensive", "year": "2023", "title": "Gptaraeval: A Comprehensive Evaluation Of Chatgpt On Arabic NLP", "topic_distr": {"0": 0.11865826696157455, "1": 0.0010835304856300354, "2": 0.0009159105247817934, "3": 0.3650936484336853, "4": 0.000699659634847194, "5": 0.0006257934146560729, "6": 0.0005660355091094971, "7": 0.0005166954360902309, "8": 0.00047526744310744107, "9": 0.15257617831230164, "10": 0.0004095870826859027, "11": 0.00038311455864459276, "12": 0.31061190366744995, "13": 0.00033926015021279454, "14": 0.0003208941197954118, "15": 0.015561643056571484, "16": 0.030370255932211876, "17": 0.0002760601055342704, "18": 0.00026377555332146585, "19": 0.0002525377203710377}}, {"key": "khot2019dataset", "year": "2019", "title": "QASC: A Dataset For Question Answering Via Sentence Composition", "topic_distr": {"0": 0.13832001388072968, "1": 0.10521789640188217, "2": 0.13897575438022614, "3": 0.16247649490833282, "4": 0.0006146981613710523, "5": 0.0005498019745573401, "6": 0.0004973004688508809, "7": 0.0004539518849924207, "8": 0.3133545517921448, "9": 0.00038656065589748323, "10": 0.00035984994610771537, "11": 0.09369819611310959, "12": 0.00031615799525752664, "13": 0.0002980630088131875, "14": 0.00028192720492370427, "15": 0.0002674486895557493, "16": 0.04323521628975868, "17": 0.00024253746960312128, "18": 0.0002317446778761223, "19": 0.0002218714653281495}}, {"key": "khot2022decomposed", "year": "2022", "title": "Decomposed Prompting: A Modular Approach For Solving Complex Tasks", "topic_distr": {"0": 0.0011551686329767108, "1": 0.0009430620120838284, "2": 0.09134531021118164, "3": 0.5766805410385132, "4": 0.0006090007955208421, "5": 0.0005447058938443661, "6": 0.0004926910623908043, "7": 0.00044974422780796885, "8": 0.04869797080755234, "9": 0.00038297762512229383, "10": 0.02762870118021965, "11": 0.034351740032434464, "12": 0.0003132275596726686, "13": 0.0002953002694994211, "14": 0.00027931403019465506, "15": 0.0002649697125889361, "16": 0.03604601323604584, "17": 0.15816739201545715, "18": 0.0002295966405654326, "19": 0.021122554317116737}}, {"key": "khoury2023how", "year": "2023", "title": "How Secure Is Code Generated By Chatgpt?", "topic_distr": {"0": 0.16244278848171234, "1": 0.1477689892053604, "2": 0.000989608932286501, "3": 0.1830935925245285, "4": 0.0007559577934443951, "5": 0.0006761483964510262, "6": 0.1883157640695572, "7": 0.0005582717130891979, "8": 0.0005135101964697242, "9": 0.31142884492874146, "10": 0.00044254481326788664, "11": 0.0004139421507716179, "12": 0.00038881227374076843, "13": 0.0003665589902084321, "14": 0.0003467150963842869, "15": 0.00032890940201468766, "16": 0.00031284321448765695, "17": 0.0002982734877150506, "18": 0.0002850004530046135, "19": 0.0002728583640418947}}, {"key": "khraisha2023can", "year": "2023", "title": "Can Large Language Models Replace Humans In The Systematic Review Process? Evaluating Gpt-4's Efficacy In Screening And Extracting Data From Peer-reviewed And Grey Literature In Multiple Languages", "topic_distr": {"0": 0.24646668136119843, "1": 0.024768171831965446, "2": 0.0007756958366371691, "3": 0.2960034906864166, "4": 0.0005925421137362719, "5": 0.0005299846525304019, "6": 0.0004793755942955613, "7": 0.00043758947867900133, "8": 0.0004025041125714779, "9": 0.10567963868379593, "10": 0.00034687938750721514, "11": 0.000324459804687649, "12": 0.22697685658931732, "13": 0.000287319504423067, "14": 0.0002717653114814311, "15": 0.0002578086860012263, "16": 0.000245215545874089, "17": 0.09471677243709564, "18": 0.00022339158749673516, "19": 0.0002138742565875873}}, {"key": "khurana2024why", "year": "2024", "title": "Why And When Llm-based Assistants Can Go Wrong: Investigating The Effectiveness Of Prompt-based Interactions For Software Help-seeking", "topic_distr": {"0": 0.14699552953243256, "1": 0.057957470417022705, "2": 0.0006285531562753022, "3": 0.2777242660522461, "4": 0.03285762295126915, "5": 0.00042945341556333005, "6": 0.13080447912216187, "7": 0.00035458439378999174, "8": 0.00032615428790450096, "9": 0.2688024342060089, "10": 0.00028108086553402245, "11": 0.0002629139635246247, "12": 0.00024695281172171235, "13": 0.00023281871108338237, "14": 0.00022021494805812836, "15": 0.0002089056943077594, "16": 0.00019870132382493466, "17": 0.08111352473497391, "18": 0.0001810170797398314, "19": 0.00017330507398582995}}, {"key": "kiesler2023exploring", "year": "2023", "title": "Exploring The Potential Of Large Language Models To Generate Formative Programming Feedback", "topic_distr": {"0": 0.21723291277885437, "1": 0.0011572979856282473, "2": 0.000978318857960403, "3": 0.2004178762435913, "4": 0.0007473321747966111, "5": 0.0006684325635433197, "6": 0.1110096201300621, "7": 0.05842801183462143, "8": 0.019150879234075546, "9": 0.38679230213165283, "10": 0.00043749462929554284, "11": 0.00040921836625784636, "12": 0.00038437527837231755, "13": 0.0003623759257607162, "14": 0.00034275848884135485, "15": 0.0003251559683121741, "16": 0.0003092731349170208, "17": 0.00029486967832781374, "18": 0.000281748129054904, "19": 0.0002697445743251592}}, {"key": "kim2016sequence", "year": "2016", "title": "Sequence-level Knowledge Distillation", "topic_distr": {"0": 0.0012466016924008727, "1": 0.001018462353385985, "2": 0.34372618794441223, "3": 0.018616478890180588, "4": 0.0006577231688424945, "5": 0.0005882849218323827, "6": 0.0005321087082847953, "7": 0.0004857259336858988, "8": 0.00044678105041384697, "9": 0.0004136177012696862, "10": 0.0003850374196190387, "11": 0.00036015157820656896, "12": 0.00033828726736828685, "13": 0.37468430399894714, "14": 0.17884446680545807, "15": 0.00028616859344765544, "16": 0.07662474364042282, "17": 0.00025951373390853405, "18": 0.0002479654795024544, "19": 0.00023740122560411692}}, {"key": "kim2018multimodal", "year": "2018", "title": "Multimodal Dual Attention Memory For Video Story Question Answering", "topic_distr": {"0": 0.0014171551447361708, "1": 0.001157313585281372, "2": 0.5110960006713867, "3": 0.000847369956318289, "4": 0.04253586381673813, "5": 0.0006684461841359735, "6": 0.0006046152557246387, "7": 0.028335697948932648, "8": 0.07868103682994843, "9": 0.00046997834579087794, "10": 0.0004375036514829844, "11": 0.0004092268063686788, "12": 0.0003843831946142018, "13": 0.0003623834054451436, "14": 0.00034276556107215583, "15": 0.0003251626912970096, "16": 0.0003092795377597213, "17": 0.0002948757610283792, "18": 0.33105117082595825, "19": 0.00026975013315677643}}, {"key": "kim2019eighth", "year": "2019", "title": "The Eighth Dialog System Technology Challenge", "topic_distr": {"0": 0.0029020581860095263, "1": 0.0023680725134909153, "2": 0.0020021446980535984, "3": 0.0017341319471597672, "4": 0.33429259061813354, "5": 0.04672886058688164, "6": 0.20575784146785736, "7": 0.0011294828727841377, "8": 0.0010389224626123905, "9": 0.18958799540996552, "10": 0.0008953468641266227, "11": 0.0008374786120839417, "12": 0.14700964093208313, "13": 0.0007416140288114548, "14": 0.0007014663424342871, "15": 0.0006654422031715512, "16": 0.0006329374737106264, "17": 0.0006034602993167937, "18": 0.05981852859258652, "19": 0.0005520409904420376}}, {"key": "kim2019probing", "year": "2019", "title": "Probing What Different NLP Tasks Teach Machines About Function Word Comprehension", "topic_distr": {"0": 0.03496680036187172, "1": 0.00143441220279783, "2": 0.4791695177555084, "3": 0.0010502550285309553, "4": 0.0009262821404263377, "5": 0.0008284909417852759, "6": 0.000749377126339823, "7": 0.0006840555579401553, "8": 0.0006292088655754924, "9": 0.0005825043772347271, "10": 0.14091242849826813, "11": 0.0005072071799077094, "12": 0.0004764153272844851, "13": 0.0004491481522563845, "14": 0.00042483326978981495, "15": 0.00040301575791090727, "16": 0.0003833297232631594, "17": 0.0003654773172456771, "18": 0.00034921374754048884, "19": 0.334708034992218}}, {"key": "kim2020code", "year": "2020", "title": "Code Prediction By Feeding Trees To Transformers", "topic_distr": {"0": 0.001433668308891356, "1": 0.0011709126411005855, "2": 0.17510607838630676, "3": 0.0008570859208703041, "4": 0.0007559147197753191, "5": 0.000676109513733536, "6": 0.46190690994262695, "7": 0.0005582394078373909, "8": 0.0005134804523549974, "9": 0.00047536619240418077, "10": 0.2963234782218933, "11": 0.000413918198319152, "12": 0.057597801089286804, "13": 0.0003665377735160291, "14": 0.0003466950438451022, "15": 0.00032889036810956895, "16": 0.00031282511190511286, "17": 0.00029825622914358974, "18": 0.00028498395113274455, "19": 0.00027284256066195667}}, {"key": "kim2020length", "year": "2020", "title": "Length-adaptive Transformer: Train Once With Length Drop, Use Anytime With Search", "topic_distr": {"0": 0.0013572968309745193, "1": 0.001107159536331892, "2": 0.24019576609134674, "3": 0.0008105678134597838, "4": 0.000714884081389755, "5": 0.0006394088268280029, "6": 0.000578350736759603, "7": 0.0005279371398501098, "8": 0.09014246612787247, "9": 0.0004495624452829361, "10": 0.3530755937099457, "11": 0.0003914499538950622, "12": 0.0003676855412777513, "13": 0.28888365626335144, "14": 0.0003278758085798472, "15": 0.00031103758374229074, "16": 0.019309677183628082, "17": 0.00028206632123328745, "18": 0.0002695145085453987, "19": 0.00025803217431530356}}, {"key": "kim2020sequential", "year": "2020", "title": "Sequential Latent Knowledge Selection For Knowledge-grounded Dialogue", "topic_distr": {"0": 0.03591031953692436, "1": 0.02397003024816513, "2": 0.22627082467079163, "3": 0.0009439617861062288, "4": 0.000832537654787302, "5": 0.0007446427480317652, "6": 0.42111748456954956, "7": 0.0006148247630335391, "8": 0.0005655289278365672, "9": 0.000523551250807941, "10": 0.00048737472388893366, "11": 0.00045587460044771433, "12": 0.0004281990695744753, "13": 0.0004036914906464517, "14": 0.00038183745346032083, "15": 0.0003622279909905046, "16": 0.28504419326782227, "17": 0.0003284886770416051, "18": 0.0003138710744678974, "19": 0.00030049897031858563}}, {"key": "kim2020will", "year": "2020", "title": "Will I Sound Like Me? Improving Persona Consistency In Dialogues Through Pragmatic Self-consciousness", "topic_distr": {"0": 0.09873764216899872, "1": 0.14839661121368408, "2": 0.3177073001861572, "3": 0.000981171615421772, "4": 0.0008653543191030622, "5": 0.1340029388666153, "6": 0.0873989388346672, "7": 0.0006390598719008267, "8": 0.0005878208903595805, "9": 0.0005441884859465063, "10": 0.0005065859877504408, "11": 0.16634342074394226, "12": 0.0004450777778401971, "13": 0.0004196041845716536, "14": 0.0003968886740040034, "15": 0.018797166645526886, "16": 0.022250255569815636, "17": 0.0003414370003156364, "18": 0.00032624322921037674, "19": 0.00031234402558766305}}, {"key": "kim2021i", "year": "2021", "title": "I-BERT: Integer-only BERT Quantization", "topic_distr": {"0": 0.001434221980161965, "1": 0.0011707700323313475, "2": 0.10897540301084518, "3": 0.09303176403045654, "4": 0.0007559481309726834, "5": 0.0006761388503946364, "6": 0.00061157310847193, "7": 0.00055826356401667, "8": 0.0005135026876814663, "9": 0.05283153057098389, "10": 0.29362305998802185, "11": 0.00041393612627871335, "12": 0.0003888066275976598, "13": 0.4431705176830292, "14": 0.00034671006142161787, "15": 0.0003289045998826623, "16": 0.0003128386742901057, "17": 0.0002982691512443125, "18": 0.00028499632026068866, "19": 0.0002728543768171221}}, {"key": "kim2021learned", "year": "2021", "title": "Learned Token Pruning For Transformers", "topic_distr": {"0": 0.0014500393299385905, "1": 0.0011842527892440557, "2": 0.39790478348731995, "3": 0.0008670236566103995, "4": 0.0007646812009625137, "5": 0.0006839512498117983, "6": 0.0006186396931298077, "7": 0.0005647141952067614, "8": 0.0005194361438043416, "9": 0.00048087979666888714, "10": 0.39637601375579834, "11": 0.0004187190788798034, "12": 0.00039329921128228307, "13": 0.19590768218040466, "14": 0.0003507162327878177, "15": 0.0003327050362713635, "16": 0.0003164534573443234, "17": 0.0003017155977431685, "18": 0.0002882893895730376, "19": 0.0002760071656666696}}, {"key": "kim2021scalable", "year": "2021", "title": "Scalable And Efficient Moe Training For Multitask Multilingual Models", "topic_distr": {"0": 0.0010577113134786487, "1": 0.024632053449749947, "2": 0.17277991771697998, "3": 0.0006319929379969835, "4": 0.05061626434326172, "5": 0.0004985454143024981, "6": 0.0004509385034907609, "7": 0.00041163116111420095, "8": 0.0003786270972341299, "9": 0.0780273824930191, "10": 0.09088047593832016, "11": 0.00030521248118020594, "12": 0.00028668344020843506, "13": 0.43179208040237427, "14": 0.11268340796232224, "15": 0.03370516374707222, "16": 0.00023066907306201756, "17": 0.00021992635447531939, "18": 0.0002101397403748706, "19": 0.0002011869801208377}}, {"key": "kim2021self", "year": "2021", "title": "Self-guided Contrastive Learning For BERT Sentence Representations", "topic_distr": {"0": 0.0018618545727804303, "1": 0.08616376668214798, "2": 0.2360699623823166, "3": 0.0011131702922284603, "4": 0.000981769640929997, "5": 0.000878120306879282, "6": 0.0007942672236822546, "7": 0.0007250327034853399, "8": 0.0006669005379080772, "9": 0.0006173982983455062, "10": 0.47263631224632263, "11": 0.08912934362888336, "12": 0.0005049541941843927, "13": 0.027133679017424583, "14": 0.0004502821830101311, "15": 0.07875501364469528, "16": 0.0004062924417667091, "17": 0.00038737058639526367, "18": 0.0003701327950693667, "19": 0.0003543637285474688}}, {"key": "kim2021what", "year": "2021", "title": "What Changes Can Large-scale Language Models Bring? Intensive Study On Hyperclova: Billions-scale Korean Generative Pretrained Transformers", "topic_distr": {"0": 0.0015026017790660262, "1": 0.0012271989835426211, "2": 0.0010373403783887625, "3": 0.0008984592277556658, "4": 0.0007924037636257708, "5": 0.0007087463163770735, "6": 0.0006410669884644449, "7": 0.0005851865862496197, "8": 0.0005382670788094401, "9": 0.22365888953208923, "10": 0.08657138794660568, "11": 0.06569864600896835, "12": 0.0004075573233421892, "13": 0.17425039410591125, "14": 0.00036343061947263777, "15": 0.04608123004436493, "16": 0.0003279257216490805, "17": 0.24590106308460236, "18": 0.0002987406332977116, "19": 0.1485094130039215}}, {"key": "kim2023ai", "year": "2023", "title": "Ai-augmented Surveys: Leveraging Large Language Models And Surveys For Opinion Prediction", "topic_distr": {"0": 0.16199897229671478, "1": 0.0010834356071427464, "2": 0.10002363473176956, "3": 0.3127870559692383, "4": 0.0006996889715082943, "5": 0.000625820248387754, "6": 0.08180829882621765, "7": 0.0005167173221707344, "8": 0.00047528758295811713, "9": 0.16109773516654968, "10": 0.00040960442856885493, "11": 0.0003831307985819876, "12": 0.16130949556827545, "13": 0.00033927452750504017, "14": 0.0003209077112842351, "15": 0.015038934536278248, "16": 0.0002895570651162416, "17": 0.000276071805274114, "18": 0.00026378672919236124, "19": 0.0002525484305806458}}, {"key": "kim2023cot", "year": "2023", "title": "The Cot Collection: Improving Zero-shot And Few-shot Learning Of Language Models Via Chain-of-thought Fine-tuning", "topic_distr": {"0": 0.001299005700275302, "1": 0.0010610967874526978, "2": 0.11323636770248413, "3": 0.6139459609985352, "4": 0.0006850685458630323, "5": 0.0006127433734945953, "6": 0.0005542315193451941, "7": 0.0005059203249402344, "8": 0.00046535630826838315, "9": 0.00043081416515633464, "10": 0.0004010456323157996, "11": 0.10455947369337082, "12": 0.00035235180985182524, "13": 0.032862357795238495, "14": 0.00031420227605849504, "15": 0.00029806626844219863, "16": 0.0002835066698025912, "17": 0.047370944172143936, "18": 0.0002582748420536518, "19": 0.08050321042537689}}, {"key": "kim2023harnessing", "year": "2023", "title": "Mindfuldiary: Harnessing Large Language Model To Support Psychiatric Patients' Journaling", "topic_distr": {"0": 0.0017822361551225185, "1": 0.14737801253795624, "2": 0.0012300059897825122, "3": 0.30277299880981445, "4": 0.0009395874221809208, "5": 0.0008403923129662871, "6": 0.04931695759296417, "7": 0.0006938814767636359, "8": 0.031409699469804764, "9": 0.4038609564304352, "10": 0.0005500433617271483, "11": 0.0005144928582012653, "12": 0.00048325868556275964, "13": 0.0559348538517952, "14": 0.0004309356736484915, "15": 0.0004088047717232257, "16": 0.0003888359642587602, "17": 0.0003707270952872932, "18": 0.0003542299382388592, "19": 0.00033913837978616357}}, {"key": "kim2023interactive", "year": "2023", "title": "Evallm: Interactive Evaluation Of Large Language Model Prompts On User-defined Criteria", "topic_distr": {"0": 0.05222070962190628, "1": 0.049779221415519714, "2": 0.0010129715083166957, "3": 0.25085675716400146, "4": 0.2830102741718292, "5": 0.0006921092863194644, "6": 0.0006260187365114689, "7": 0.0005714499857276678, "8": 0.0005256318836472929, "9": 0.14367198944091797, "10": 0.0004529913130681962, "11": 0.00042371347080916166, "12": 0.08579789847135544, "13": 0.00037521179183386266, "14": 0.0003548995009623468, "15": 0.0003366734890732914, "16": 0.000320228049531579, "17": 0.1284002661705017, "18": 0.00029172803624533117, "19": 0.0002792993327602744}}, {"key": "kim2023language", "year": "2023", "title": "Language Models Can Solve Computer Tasks", "topic_distr": {"0": 0.0011545068118721247, "1": 0.0009428844787180424, "2": 0.08751362562179565, "3": 0.6292372941970825, "4": 0.0006089287344366312, "5": 0.0005446417490020394, "6": 0.0004926330875605345, "7": 0.0004496913170441985, "8": 0.00041363562922924757, "9": 0.0003829325723927468, "10": 0.0003564725921023637, "11": 0.2575778365135193, "12": 0.00031319071422331035, "13": 0.01852584257721901, "14": 0.0002792811719700694, "15": 0.00026493854238651693, "16": 0.00025199714582413435, "17": 0.0002402611426077783, "18": 0.00022956963221076876, "19": 0.00021978910081088543}}, {"key": "kim2023memory", "year": "2023", "title": "Memory-efficient Fine-tuning Of Compressed Large Language Models Via Sub-4-bit Integer Quantization", "topic_distr": {"0": 0.0010658784303814173, "1": 0.0008704469073563814, "2": 0.13180766999721527, "3": 0.29319441318511963, "4": 0.0005621054442599416, "5": 0.0005027616280131042, "6": 0.0004547520074993372, "7": 0.0004151122411713004, "8": 0.0003818290715571493, "9": 0.02153358794748783, "10": 0.0003290615859441459, "11": 0.0003077936125919223, "12": 0.00028910787659697235, "13": 0.4622488021850586, "14": 0.0002578058047220111, "15": 0.00024456606479361653, "16": 0.08489774167537689, "17": 0.00022178623476065695, "18": 0.00021191684936638921, "19": 0.00020288839004933834}}, {"key": "kim2023solar", "year": "2023", "title": "SOLAR 10.7B: Scaling Large Language Models With Simple Yet Effective Depth Up-scaling", "topic_distr": {"0": 0.0018891271902248263, "1": 0.0015429542399942875, "2": 0.0013044493971392512, "3": 0.41313880681991577, "4": 0.000996433780528605, "5": 0.0008912367047742009, "6": 0.0008061311091296375, "7": 0.0007358624134212732, "8": 0.0006768619059585035, "9": 0.0006266203126870096, "10": 0.03395922854542732, "11": 0.0005456205108202994, "12": 0.14348164200782776, "13": 0.35387080907821655, "14": 0.0004570079909171909, "15": 0.00043353813816793263, "16": 0.0004123611724935472, "17": 0.00039315668982453644, "18": 0.00037566141691058874, "19": 0.043462447822093964}}, {"key": "kim2024financial", "year": "2024", "title": "Financial Statement Analysis With Large Language Models", "topic_distr": {"0": 0.3558245897293091, "1": 0.0012891312362626195, "2": 0.2657585144042969, "3": 0.2525549530982971, "4": 0.0008324598893523216, "5": 0.0007445742376148701, "6": 0.0006734736380167305, "7": 0.0006147684180177748, "8": 0.0005654770648106933, "9": 0.11733576655387878, "10": 0.00048733004950918257, "11": 0.00045583280734717846, "12": 0.00042815980850718915, "13": 0.0004036544996779412, "14": 0.0003818024415522814, "15": 0.00036219481262378395, "16": 0.0003445027396082878, "17": 0.0003284585545770824, "18": 0.00031384231988340616, "19": 0.00030047143809497356}}, {"key": "kim2024large", "year": "2024", "title": "Large Language Models Meet Collaborative Filtering: An Efficient All-round Llm-based Recommender System", "topic_distr": {"0": 0.015663141384720802, "1": 0.000848675612360239, "2": 0.0007174700149334967, "3": 0.2589625120162964, "4": 0.3513263761997223, "5": 0.0004901971551589668, "6": 0.00044338745647110045, "7": 0.00040473832632414997, "8": 0.0003722869441844523, "9": 0.0761810764670372, "10": 0.00032083812402561307, "11": 0.0003001016448251903, "12": 0.00028188287978991866, "13": 0.07351067662239075, "14": 0.00025136308977380395, "15": 0.00023845421674195677, "16": 0.094574473798275, "17": 0.0002162436576327309, "18": 0.12469832599163055, "19": 0.0001978180807782337}}, {"key": "kim2024understanding", "year": "2024", "title": "Understanding Large-language Model (llm)-powered Human-robot Interaction", "topic_distr": {"0": 0.09561371058225632, "1": 0.04583214223384857, "2": 0.0012126866495236754, "3": 0.08476937562227249, "4": 0.0009263721294701099, "5": 0.0008285705698654056, "6": 0.000749449071008712, "7": 0.0006841211579740047, "8": 0.0006292691687121987, "9": 0.5452935695648193, "10": 0.0005423062830232084, "11": 0.17568281292915344, "12": 0.044525954872369766, "13": 0.00044919122592546046, "14": 0.0004248740151524544, "15": 0.0004030544077977538, "16": 0.00038336648140102625, "17": 0.000365512358257547, "18": 0.0003492472169455141, "19": 0.00033436797093600035}}, {"key": "kirk2021bias", "year": "2021", "title": "Bias Out-of-the-box: An Empirical Analysis Of Intersectional Occupational Biases In Popular Generative Language Models", "topic_distr": {"0": 0.2914724349975586, "1": 0.10929278284311295, "2": 0.18525469303131104, "3": 0.0008194820838980377, "4": 0.0690847784280777, "5": 0.0006464440375566483, "6": 0.0005847140564583242, "7": 0.0005337457405403256, "8": 0.037100184708833694, "9": 0.0004545087576843798, "10": 0.00042310295975767076, "11": 0.00039575688424520195, "12": 0.2369399219751358, "13": 0.00035045534605160356, "14": 0.0003314832574687898, "15": 0.06519792228937149, "16": 0.0002990994253195822, "17": 0.0002851697790902108, "18": 0.0002724798396229744, "19": 0.00026087116566486657}}, {"key": "kirk2023personalisation", "year": "2023", "title": "Personalisation Within Bounds: A Risk Taxonomy And Policy Framework For The Alignment Of Large Language Models With Personalised Feedback", "topic_distr": {"0": 0.2595178782939911, "1": 0.0007435085135512054, "2": 0.0006284553091973066, "3": 0.10987039655447006, "4": 0.23515556752681732, "5": 0.0004293904348742217, "6": 0.00038838727050460875, "7": 0.00035453238524496555, "8": 0.00032610641210339963, "9": 0.3903907835483551, "10": 0.00028103962540626526, "11": 0.00026287540094926953, "12": 0.0002469165774527937, "13": 0.00023278454318642616, "14": 0.00022018262825440615, "15": 0.00020887504797428846, "16": 0.00019867217633873224, "17": 0.00018941961752716452, "18": 0.00018099052249453962, "19": 0.000173279651789926}}, {"key": "kitaev2018multilingual", "year": "2018", "title": "Multilingual Constituency Parsing With Self-attention And Pre-training", "topic_distr": {"0": 0.00152150122448802, "1": 0.0012423471780493855, "2": 0.40917813777923584, "3": 0.08603116124868393, "4": 0.0008020997629500926, "5": 0.000717419374268502, "6": 0.0006489118677563965, "7": 0.00059234764194116, "8": 0.0005448539741337299, "9": 0.0005044109420850873, "10": 0.10052873939275742, "11": 0.0004392084665596485, "12": 0.00041254470124840736, "13": 0.18566365540027618, "14": 0.20958338677883148, "15": 0.0003489854570943862, "16": 0.00033193861600011587, "17": 0.00031647959258407354, "18": 0.0003023963945452124, "19": 0.00028951314743608236}}, {"key": "klein2019learning", "year": "2019", "title": "Learning To Answer By Learning To Ask: Getting The Best Of GPT-2 And BERT Worlds", "topic_distr": {"0": 0.001096495077945292, "1": 0.09927865862846375, "2": 0.2627685070037842, "3": 0.0006542851333506405, "4": 0.0005770490970462561, "5": 0.0005161279113963246, "6": 0.00046684208791702986, "7": 0.09693966060876846, "8": 0.2215239405632019, "9": 0.00036288477713242173, "10": 0.13831162452697754, "11": 0.00031597664928995073, "12": 0.0002967941400129348, "13": 0.0002798073983285576, "14": 0.03277289494872093, "15": 0.14294612407684326, "16": 0.00023880426306277514, "17": 0.0002276826708111912, "18": 0.00021755089983344078, "19": 0.000208282406674698}}, {"key": "klenitskiy2023turning", "year": "2023", "title": "Turning Dross Into Gold Loss: Is Bert4rec Really Better Than Sasrec?", "topic_distr": {"0": 0.0019501128699630499, "1": 0.18627165257930756, "2": 0.001345290569588542, "3": 0.00116517033893615, "4": 0.38565418124198914, "5": 0.0009191420977003872, "6": 0.0008313715807162225, "7": 0.000758902751840651, "8": 0.0006980548496358097, "9": 0.0006462401361204684, "10": 0.32778725028038025, "11": 0.0005627042264677584, "12": 0.0005285431980155408, "13": 0.08837386965751648, "14": 0.0004713171801995486, "15": 0.0004471124557312578, "16": 0.00042527244659140706, "17": 0.0004054666787851602, "18": 0.0003874235844705254, "19": 0.0003709178708959371}}, {"key": "kocaballi2023conversational", "year": "2023", "title": "Conversational Ai-powered Design: Chatgpt As Designer, User, And Product", "topic_distr": {"0": 0.10911524295806885, "1": 0.0011191284283995628, "2": 0.0009460481232963502, "3": 0.000819423352368176, "4": 0.06761200726032257, "5": 0.0006463947356678545, "6": 0.09232045710086823, "7": 0.000533705111593008, "8": 0.0004909133422188461, "9": 0.723092257976532, "10": 0.0004230707709211856, "11": 0.0003957267617806792, "12": 0.0003717027138918638, "13": 0.00035042865783907473, "14": 0.00033145802444778383, "15": 0.00031443583429791033, "16": 0.0002990766370203346, "17": 0.0002851480385288596, "18": 0.00027245908859185874, "19": 0.0002608513168524951}}, {"key": "kocetkov2022tb", "year": "2022", "title": "The Stack: 3 TB Of Permissively Licensed Source Code", "topic_distr": {"0": 0.0014859763905405998, "1": 0.07140912860631943, "2": 0.16440600156784058, "3": 0.1818067878484726, "4": 0.0007829556125216186, "5": 0.0007002962520346045, "6": 0.25222742557525635, "7": 0.0005782095831818879, "8": 0.0005318495095707476, "9": 0.10582172125577927, "10": 0.0004583497066050768, "11": 0.00042872552876360714, "12": 0.21707244217395782, "13": 0.00037965012597851455, "14": 0.0003590975538827479, "15": 0.00034065594081766903, "16": 0.0003240160003770143, "17": 0.00030892592621967196, "18": 0.0002951788483187556, "19": 0.00028260311228223145}}, {"key": "kocmi2023large", "year": "2023", "title": "Large Language Models Are State-of-the-art Evaluators Of Translation Quality", "topic_distr": {"0": 0.1921393722295761, "1": 0.03169633448123932, "2": 0.001001189579255879, "3": 0.34704211354255676, "4": 0.0007647942984476686, "5": 0.0006840515998192132, "6": 0.0006187304388731718, "7": 0.0005647970247082412, "8": 0.0005195123376324773, "9": 0.00048095034435391426, "10": 0.0004477174661587924, "11": 0.0004187805170658976, "12": 0.0003933568950742483, "13": 0.0003708434815052897, "14": 0.27185821533203125, "15": 0.033898286521434784, "16": 0.0003164998779539019, "17": 0.11622006446123123, "18": 0.00028833167743869126, "19": 0.0002760476490948349}}, {"key": "koco\u01442023jack", "year": "2023", "title": "Chatgpt: Jack Of All Trades, Master Of None", "topic_distr": {"0": 0.15589770674705505, "1": 0.11981777846813202, "2": 0.0006150036933831871, "3": 0.31220340728759766, "4": 0.00046978823957033455, "5": 0.00042019051034003496, "6": 0.04197017103433609, "7": 0.0003469363145995885, "8": 0.014821000397205353, "9": 0.1986706405878067, "10": 0.15289440751075745, "11": 0.00025724314036779106, "12": 0.0002416262577753514, "13": 0.00022779700520914048, "14": 0.0002154650865122676, "15": 0.00020439978106878698, "16": 0.00019441550830379128, "17": 0.0001853611902333796, "18": 0.00017711269902065396, "19": 0.00016956703620962799}}, {"key": "koh2023generating", "year": "2023", "title": "Generating Images With Multimodal Language Models", "topic_distr": {"0": 0.0010309049393981695, "1": 0.0008415948832407594, "2": 0.138204425573349, "3": 0.09931810945272446, "4": 0.0005435284110717475, "5": 0.010489667765796185, "6": 0.00043972342973574996, "7": 0.26028671860694885, "8": 0.016622673720121384, "9": 0.0003418049600441009, "10": 0.00031818682327866554, "11": 0.000297621707431972, "12": 0.00027955349651165307, "13": 0.00026355352019891143, "14": 0.00024928589118644595, "15": 0.00023648369824513793, "16": 0.0002249322278657928, "17": 0.00021445668244268745, "18": 0.4696005880832672, "19": 0.0001961833768291399}}, {"key": "koh2023grounding", "year": "2023", "title": "Grounding Language Models To Images For Multimodal Inputs And Outputs", "topic_distr": {"0": 0.0017580764833837748, "1": 0.03289502486586571, "2": 0.0012126141227781773, "3": 0.0010502863442525268, "4": 0.0009263085084967315, "5": 0.0205276720225811, "6": 0.0007493978482671082, "7": 0.15253883600234985, "8": 0.0006292262114584446, "9": 0.0005825204425491393, "10": 0.0005422692629508674, "11": 0.0005072212079539895, "12": 0.00047642848221585155, "13": 0.00044916055048815906, "14": 0.000424844998633489, "15": 0.0004030269046779722, "16": 0.00038334031705744565, "17": 0.07321997731924057, "18": 0.5665556788444519, "19": 0.14416806399822235}}, {"key": "kojima2022large", "year": "2022", "title": "Large Language Models Are Zero-shot Reasoners", "topic_distr": {"0": 0.03720196336507797, "1": 0.000795717176515609, "2": 0.08740019053220749, "3": 0.6622998714447021, "4": 0.0005138482665643096, "5": 0.010163458064198494, "6": 0.0004157116054557264, "7": 0.00037947495002299547, "8": 0.0003490491071715951, "9": 0.00032314014970324934, "10": 0.0003008117200806737, "11": 0.00028136957553215325, "12": 0.051397986710071564, "13": 0.0685054212808609, "14": 0.00023567322932649404, "15": 0.000223570124944672, "16": 0.0002126494364347309, "17": 0.06600049138069153, "18": 0.00019372382666915655, "19": 0.012805866077542305}}, {"key": "kolluru2020iterative", "year": "2020", "title": "Imojie: Iterative Memory-based Joint Open Information Extraction", "topic_distr": {"0": 0.0018896569963544607, "1": 0.0658625140786171, "2": 0.47284752130508423, "3": 0.001129840617068112, "4": 0.0009964756900444627, "5": 0.08335966616868973, "6": 0.12968531250953674, "7": 0.0007358930888585746, "8": 0.0006768900784663856, "9": 0.0006266463897190988, "10": 0.0418129600584507, "11": 0.0005456432118080556, "12": 0.0005125179304741323, "13": 0.00048318447079509497, "14": 0.00045702699571847916, "15": 0.19683733582496643, "16": 0.0004123783437535167, "17": 0.0003931730461772531, "18": 0.000375677045667544, "19": 0.00035967177245765924}}, {"key": "komeili2021internet", "year": "2021", "title": "Internet-augmented Dialogue Generation", "topic_distr": {"0": 0.11369369179010391, "1": 0.056056927889585495, "2": 0.21265417337417603, "3": 0.0008773613371886313, "4": 0.0007737914565950632, "5": 0.0006920999148860574, "6": 0.29391610622406006, "7": 0.0005714420112781227, "8": 0.06861031800508499, "9": 0.00048660882748663425, "10": 0.0004529849684331566, "11": 0.03954415023326874, "12": 0.0003979848406743258, "13": 0.059103768318891525, "14": 0.0003548945242073387, "15": 0.00033666877425275743, "16": 0.15060070157051086, "17": 0.0003053101245313883, "18": 0.0002917239617090672, "19": 0.00027929540374316275}}, {"key": "kong2019adversarial", "year": "2019", "title": "An Adversarial Approach To High-quality, Sentiment-controlled Neural Dialogue Generation", "topic_distr": {"0": 0.0017320334445685148, "1": 0.16927190124988556, "2": 0.026595929637551308, "3": 0.0010357621358707547, "4": 0.0009135030559264123, "5": 0.10395441949367523, "6": 0.3964894711971283, "7": 0.19531865417957306, "8": 0.0006205277750268579, "9": 0.0005744676454924047, "10": 0.0005347729311324656, "11": 0.0005002093384973705, "12": 0.00046984231448732316, "13": 0.0004429513355717063, "14": 0.0004189719329588115, "15": 0.00039745544199831784, "16": 0.0003780410042963922, "17": 0.0996769368648529, "18": 0.00034439569571986794, "19": 0.00032972314511425793}}, {"key": "kong2021bidirectional", "year": "2021", "title": "BLT: Bidirectional Layout Transformer For Controllable Layout Generation", "topic_distr": {"0": 0.02167249470949173, "1": 0.0012731069000437856, "2": 0.0010763161117210984, "3": 0.0009322220575995743, "4": 0.0008221810567192733, "5": 0.0007353797554969788, "6": 0.04478497803211212, "7": 0.3118317127227783, "8": 0.0005584942409768701, "9": 0.0005170386866666377, "10": 0.3733399510383606, "11": 0.021346189081668854, "12": 0.018306052312254906, "13": 0.07424650341272354, "14": 0.0003770877083297819, "15": 0.000357722194166854, "16": 0.0003402486036065966, "17": 0.0003244025574531406, "18": 0.12686114013195038, "19": 0.0002967610489577055}}, {"key": "kong2023better", "year": "2023", "title": "Better Zero-shot Reasoning With Role-play Prompting", "topic_distr": {"0": 0.08709541708230972, "1": 0.001107085612602532, "2": 0.0009359217947348952, "3": 0.6401126980781555, "4": 0.041409194469451904, "5": 0.0006394375232048333, "6": 0.0005783766391687095, "7": 0.0005279607721604407, "8": 0.0004856295417994261, "9": 0.137337327003479, "10": 0.00041851718560792506, "11": 0.00039146747440099716, "12": 0.00036770201404578984, "13": 0.0003466569469310343, "14": 0.0003278904769103974, "15": 0.0003110515244770795, "16": 0.04487750679254532, "17": 0.0002820789522957057, "18": 0.04219000041484833, "19": 0.0002580437285359949}}, {"key": "korbak2023pretraining", "year": "2023", "title": "Pretraining Language Models With Human Preferences", "topic_distr": {"0": 0.1978967934846878, "1": 0.0009345123544335365, "2": 0.10177072137594223, "3": 0.000684131111484021, "4": 0.10457880049943924, "5": 0.0005396726191975176, "6": 0.0004881385248154402, "7": 0.15537451207637787, "8": 0.0004098617937415838, "9": 0.0003794388612732291, "10": 0.00035322026815265417, "11": 0.059853337705135345, "12": 0.0003103332710452378, "13": 0.00029257163987495005, "14": 0.00027673313161358237, "15": 0.00026252135285176337, "16": 0.00024969803052954376, "17": 0.08562610298395157, "18": 0.00022747513139620423, "19": 0.2894914150238037}}, {"key": "kortemeyer2023performance", "year": "2023", "title": "Performance Of The Pre-trained Large Language Model GPT-4 On Automated Short Answer Grading", "topic_distr": {"0": 0.17935802042484283, "1": 0.0015432253712788224, "2": 0.001304439501836896, "3": 0.5428406596183777, "4": 0.0009964468190446496, "5": 0.0008912483463063836, "6": 0.0008061417611315846, "7": 0.0007358720758929849, "8": 0.10628482699394226, "9": 0.0006266284617595375, "10": 0.0005833295290358365, "11": 0.0005456276121549308, "12": 0.07166094332933426, "13": 0.08939119428396225, "14": 0.00045701395720243454, "15": 0.00043354378431104124, "16": 0.0004123665567021817, "17": 0.0003931618412025273, "18": 0.00037566630635410547, "19": 0.000359661498805508}}, {"key": "kosinski2023evaluating", "year": "2023", "title": "Evaluating Large Language Models In Theory Of Mind Tasks", "topic_distr": {"0": 0.29024195671081543, "1": 0.0016972643788903952, "2": 0.0014349209377542138, "3": 0.6964072585105896, "4": 0.0010961410589516163, "5": 0.000980414915829897, "6": 0.000886793655809015, "7": 0.0008094938239082694, "8": 0.0007445896044373512, "9": 0.000689320731908083, "10": 0.0006416898686438799, "11": 0.0006002160371281207, "12": 0.0005637776921503246, "13": 0.0005315103917382658, "14": 0.0005027368315495551, "15": 0.00047691853251308203, "16": 0.00045362257515080273, "17": 0.0004324964829720557, "18": 0.000413250585552305, "19": 0.00039564454345963895}}, {"key": "kotek2023gender", "year": "2023", "title": "Gender Bias And Stereotypes In Large Language Models", "topic_distr": {"0": 0.4053085446357727, "1": 0.0008085444569587708, "2": 0.02935401350259781, "3": 0.29951366782188416, "4": 0.0950043722987175, "5": 0.06641148775815964, "6": 0.00042229273822158575, "7": 0.00038548241718672216, "8": 0.0003545749350450933, "9": 0.00032825578819029033, "10": 0.0003055738634429872, "11": 0.0002858239458873868, "12": 0.09999056905508041, "13": 0.00025310623459517956, "14": 0.0002394041803199798, "15": 0.00022710947087034583, "16": 0.0002160158910555765, "17": 0.00020595559908542782, "18": 0.00019679067190736532, "19": 0.00018840664415620267}}, {"key": "kottur2019clevr", "year": "2019", "title": "Clevr-dialog: A Diagnostic Dataset For Multi-round Reasoning In Visual Dialog", "topic_distr": {"0": 0.0013722673757001758, "1": 0.0011193244718015194, "2": 0.000946090673096478, "3": 0.0008194301626645029, "4": 0.16767816245555878, "5": 0.046957168728113174, "6": 0.029509495943784714, "7": 0.0005337109323590994, "8": 0.03379901871085167, "9": 0.0004544791008811444, "10": 0.015944501385092735, "11": 0.0003957310691475868, "12": 0.13343597948551178, "13": 0.00035043247044086456, "14": 0.00033146163332276046, "15": 0.00031443926854990423, "16": 0.019265243783593178, "17": 0.0002851511526387185, "18": 0.5462270379066467, "19": 0.0002608541399240494}}, {"key": "kottur2021simmc", "year": "2021", "title": "SIMMC 2.0: A Task-oriented Dialog Dataset For Immersive Multimodal Conversations", "topic_distr": {"0": 0.021514011546969414, "1": 0.06783291697502136, "2": 0.0010011461563408375, "3": 0.0008671246469020844, "4": 0.30718469619750977, "5": 0.0006840305286459625, "6": 0.25881510972976685, "7": 0.0005647792713716626, "8": 0.0005194960394874215, "9": 0.0004809352394659072, "10": 0.0004477034090086818, "11": 0.021714434027671814, "12": 0.11802411079406738, "13": 0.000370831839973107, "14": 0.0003507566580083221, "15": 0.03770053759217262, "16": 0.0003164899244438857, "17": 0.00030175037682056427, "18": 0.16103310883045197, "19": 0.0002760389761533588}}, {"key": "koutsikakis2020greek", "year": "2020", "title": "GREEK-BERT: The Greeks Visiting Sesame Street", "topic_distr": {"0": 0.0020126965828239918, "1": 0.0016428012168034911, "2": 0.0013886162778362632, "3": 0.0012026939075440168, "4": 0.0010607248404994607, "5": 0.0009487406932748854, "6": 0.046080391854047775, "7": 0.000783341471105814, "8": 0.0007205341826193035, "9": 0.0006670508882962167, "10": 0.3992618918418884, "11": 0.00058082485338673, "12": 0.190015509724617, "13": 0.0005143388989381492, "14": 0.24834313988685608, "15": 0.00046151073183864355, "16": 0.0004389673995319754, "17": 0.1030934751033783, "18": 0.00039989969809539616, "19": 0.00038286246126517653}}, {"key": "kovaleva2019revealing", "year": "2019", "title": "Revealing The Dark Secrets Of BERT", "topic_distr": {"0": 0.2979764938354492, "1": 0.0014145232271403074, "2": 0.5157840847969055, "3": 0.0010357017163187265, "4": 0.0009134450810961425, "5": 0.036633655428886414, "6": 0.0007389915990643203, "7": 0.0006745753344148397, "8": 0.0006204887758940458, "9": 0.0005744315567426383, "10": 0.13999174535274506, "11": 0.0005001779063604772, "12": 0.0004698127740994096, "13": 0.00044292351230978966, "14": 0.0004189455939922482, "15": 0.0003974304418079555, "16": 0.00037801722646690905, "17": 0.00036041223211213946, "18": 0.00034437404247000813, "19": 0.00032970242318697274}}, {"key": "koziolek2023chatgpt", "year": "2023", "title": "Chatgpt For PLC/DCS Control Logic Generation", "topic_distr": {"0": 0.0015429214108735323, "1": 0.0012575342552736402, "2": 0.0010629765456542373, "3": 0.4143163561820984, "4": 0.0008120211423374712, "5": 0.0007262932485900819, "6": 0.1606936901807785, "7": 0.1802292764186859, "8": 0.0005515932571142912, "9": 0.18105173110961914, "10": 0.00047536491183564067, "11": 0.00044464104576036334, "12": 0.0004176474758423865, "13": 0.0003937438305001706, "14": 0.0003724282723851502, "15": 0.0003533020499162376, "16": 0.00033604438067413867, "17": 0.05436320602893829, "18": 0.00030613673152402043, "19": 0.0002930941409431398}}, {"key": "ko\u010disk\u00fd2017narrativeqa", "year": "2017", "title": "The Narrativeqa Reading Comprehension Challenge", "topic_distr": {"0": 0.15420426428318024, "1": 0.0011844212422147393, "2": 0.3345525562763214, "3": 0.0008671829709783196, "4": 0.017430150881409645, "5": 0.0006840728456154466, "6": 0.0006187495891936123, "7": 0.011314986273646355, "8": 0.36192286014556885, "9": 0.0004809652455151081, "10": 0.00044773134868592024, "11": 0.02544146031141281, "12": 0.0003933690895792097, "13": 0.0003708549775183201, "14": 0.0003507785440888256, "15": 0.0003327641461510211, "16": 0.08853670209646225, "17": 0.0003017692069988698, "18": 0.0002883406123146415, "19": 0.0002760562056209892}}, {"key": "kratzwald2019neural", "year": "2019", "title": "Rankqa: Neural Question Answering With Answer Re-ranking", "topic_distr": {"0": 0.058537937700748444, "1": 0.0009793209610506892, "2": 0.4525597095489502, "3": 0.0007170726894401014, "4": 0.0006324274581857026, "5": 0.0005656585562974215, "6": 0.0005116428947076201, "7": 0.0004670440685003996, "8": 0.24987900257110596, "9": 0.000397709256503731, "10": 0.00037022819742560387, "11": 0.0003462995227891952, "12": 0.021438583731651306, "13": 0.04819386452436447, "14": 0.0002900581166613847, "15": 0.062274713069200516, "16": 0.10112252086400986, "17": 0.00024953237152658403, "18": 0.00023842829978093505, "19": 0.00022827036445960402}}, {"key": "krause2020generative", "year": "2020", "title": "Gedi: Generative Discriminator Guided Sequence Generation", "topic_distr": {"0": 0.08282912522554398, "1": 0.000909375143237412, "2": 0.23971067368984222, "3": 0.0006658039055764675, "4": 0.0005872105248272419, "5": 0.0005252166884019971, "6": 0.00047506290138699114, "7": 0.3604378402233124, "8": 0.00039888295577839017, "9": 0.000369274930562824, "10": 0.06737831979990005, "11": 0.00032154077780433, "12": 0.00030202046036720276, "13": 0.13562710583209991, "14": 0.00026932035689242184, "15": 0.04727162420749664, "16": 0.00024300944642163813, "17": 0.00023169201449491084, "18": 0.0002213818224845454, "19": 0.06122550368309021}}, {"key": "kreutzer2018can", "year": "2018", "title": "Can Neural Machine Translation Be Improved With User Feedback?", "topic_distr": {"0": 0.0018642446957528591, "1": 0.0015203988878056407, "2": 0.0012850899947807193, "3": 0.0011130492202937603, "4": 0.44613006711006165, "5": 0.13383205235004425, "6": 0.0007941822404973209, "7": 0.0007249551126733422, "8": 0.0006668291171081364, "9": 0.0006173321744427085, "10": 0.0005746755632571876, "11": 0.03256864845752716, "12": 0.0005049001192674041, "13": 0.0004760026349686086, "14": 0.3753824234008789, "15": 0.00042711201240308583, "16": 0.00040624893154017627, "17": 0.0003873291134368628, "18": 0.0003700931556522846, "19": 0.0003543257771525532}}, {"key": "kreutzer2019joey", "year": "2019", "title": "Joey NMT: A Minimalist NMT Toolkit For Novices", "topic_distr": {"0": 0.0018888735212385654, "1": 0.0015431971987709403, "2": 0.06310825794935226, "3": 0.1557430624961853, "4": 0.0009964752243831754, "5": 0.08537161350250244, "6": 0.0008061629487201571, "7": 0.000735891459044069, "8": 0.0006768886232748628, "9": 0.0006266449927352369, "10": 0.25776419043540955, "11": 0.0005456419894471765, "12": 0.0005125168245285749, "13": 0.10234823822975159, "14": 0.30205756425857544, "15": 0.00043355522211641073, "16": 0.023712683469057083, "17": 0.0003931722021661699, "18": 0.0003756762307602912, "19": 0.0003596709866542369}}, {"key": "kreyssig2018neural", "year": "2018", "title": "Neural User Simulation For Corpus-based Policy Optimisation For Spoken Dialogue Systems", "topic_distr": {"0": 0.0394451804459095, "1": 0.0013058644253760576, "2": 0.0011037704534828663, "3": 0.0009560057078488171, "4": 0.40929532051086426, "5": 0.13577182590961456, "6": 0.19981718063354492, "7": 0.0006226656842045486, "8": 0.0005727411480620503, "9": 0.000530228135176003, "10": 0.0004935902543365955, "11": 0.20718573033809662, "12": 0.00043365993769839406, "13": 0.0004088398127350956, "14": 0.0003867070481646806, "15": 0.00036684752558358014, "16": 0.0003489282098598778, "17": 0.0003326779115013778, "18": 0.0003178739279974252, "19": 0.00030433127540163696}}, {"key": "krishna2021hurdles", "year": "2021", "title": "Hurdles To Progress In Long-form Question Answering", "topic_distr": {"0": 0.10762251168489456, "1": 0.0010722802253440022, "2": 0.2344905138015747, "3": 0.000784991541877389, "4": 0.0006923317559994757, "5": 0.0006192386499606073, "6": 0.0005601065931841731, "7": 0.09958115965127945, "8": 0.3439495861530304, "9": 0.05634722113609314, "10": 0.0004052968288306147, "11": 0.0003791016060858965, "12": 0.1514706313610077, "13": 0.0003357065434101969, "14": 0.0003175328893121332, "15": 0.00030122583848424256, "16": 0.0002865119313355535, "17": 0.00027316849445924163, "18": 0.0002610126102808863, "19": 0.00024989250232465565}}, {"key": "kr\u00fcgel2023moral", "year": "2023", "title": "The Moral Authority Of Chatgpt", "topic_distr": {"0": 0.46551042795181274, "1": 0.08774086087942123, "2": 0.0015105140628293157, "3": 0.09346381574869156, "4": 0.05714696645736694, "5": 0.0010320355650037527, "6": 0.000933484872803092, "7": 0.000852114986628294, "8": 0.1095484048128128, "9": 0.17698565125465393, "10": 0.0006754759233444929, "11": 0.000631818373221904, "12": 0.000593461561948061, "13": 0.0005594953545369208, "14": 0.0005292067653499544, "15": 0.0005020290846005082, "16": 0.00047750657540746033, "17": 0.0004552681348286569, "18": 0.0004350089293438941, "19": 0.00041647590114735067}}, {"key": "kuchaiev2019toolkit", "year": "2019", "title": "Nemo: A Toolkit For Building AI Applications Using Neural Modules", "topic_distr": {"0": 0.001734718563966453, "1": 0.06012265756726265, "2": 0.2718602418899536, "3": 0.0010358488652855158, "4": 0.000913573894649744, "5": 0.0008171232184395194, "6": 0.19590182602405548, "7": 0.0006746694562025368, "8": 0.0006205753306858242, "9": 0.18603292107582092, "10": 0.24717645347118378, "11": 0.0005002476973459125, "12": 0.00046987831592559814, "13": 0.0004429852997418493, "14": 0.0004190040344838053, "15": 0.0003974858846049756, "16": 0.00037806996260769665, "17": 0.00036046249442733824, "18": 0.02981148101389408, "19": 0.0003297484072390944}}, {"key": "kucharavy2023fundamentals", "year": "2023", "title": "Fundamentals Of Generative Large Language Models And Perspectives In Cyber-defense", "topic_distr": {"0": 0.0014859873335808516, "1": 0.05932844802737236, "2": 0.0010250299237668514, "3": 0.19174544513225555, "4": 0.0007829922251403332, "5": 0.000700328266248107, "6": 0.0006334526697173715, "7": 0.0005782360094599426, "8": 0.0005318737821653485, "9": 0.6780287027359009, "10": 0.0004583706031553447, "11": 0.06200814247131348, "12": 0.0004027165414299816, "13": 0.0003796674427576363, "14": 0.00035911393933929503, "15": 0.00034067148226313293, "16": 0.00032403075601905584, "17": 0.000308940012473613, "18": 0.0002951923233922571, "19": 0.0002826160052791238}}, {"key": "kuckreja2023grounded", "year": "2023", "title": "Geochat: Grounded Large Vision-language Model For Remote Sensing", "topic_distr": {"0": 0.057034242898225784, "1": 0.06074918806552887, "2": 0.0006473487592302263, "3": 0.12943585216999054, "4": 0.05218332260847092, "5": 0.026860691606998444, "6": 0.05923805385828018, "7": 0.0003651843289844692, "8": 0.051115039736032486, "9": 0.00031097105238586664, "10": 0.00028948349063284695, "11": 0.00027077351114712656, "12": 0.0002543352311477065, "13": 0.00023977858654689044, "14": 0.00022679804533254355, "15": 0.07886675745248795, "16": 0.00020464129920583218, "17": 0.00019511074060574174, "18": 0.48133397102355957, "19": 0.00017848584684543312}}, {"key": "kudugunta2019investigating", "year": "2019", "title": "Investigating Multilingual NMT Representations At Scale", "topic_distr": {"0": 0.18600322306156158, "1": 0.0010722674196586013, "2": 0.14939023554325104, "3": 0.04494538530707359, "4": 0.000692330242600292, "5": 0.00061923818429932, "6": 0.0005601061857305467, "7": 0.0005112829385325313, "8": 0.0004702889418695122, "9": 0.000435380672570318, "10": 0.21016258001327515, "11": 0.031397830694913864, "12": 0.00035608664620667696, "13": 0.00033570636878721416, "14": 0.3716762959957123, "15": 0.0003012256638612598, "16": 0.0002865117567125708, "17": 0.00027316834894008934, "18": 0.000261012464761734, "19": 0.00024989235680550337}}, {"key": "kulkarni2021learning", "year": "2021", "title": "Learning Rich Representation Of Keyphrases From Text", "topic_distr": {"0": 0.001523202401585877, "1": 0.0012421320425346494, "2": 0.16773925721645355, "3": 0.0009094003471545875, "4": 0.0008020541863515973, "5": 0.0007173786871135235, "6": 0.0006488750223070383, "7": 0.09350201487541199, "8": 0.058221083134412766, "9": 0.000504382245708257, "10": 0.09822965413331985, "11": 0.00043918349547311664, "12": 0.054431430995464325, "13": 0.0003889109939336777, "14": 0.0003678570792544633, "15": 0.05690969526767731, "16": 0.0003319197567179799, "17": 0.408428430557251, "18": 0.00030237919418141246, "19": 0.05436071753501892}}, {"key": "kumar2018automating", "year": "2018", "title": "Automating Reading Comprehension By Generating Question And Answer Pairs", "topic_distr": {"0": 0.0867401733994484, "1": 0.000841838656924665, "2": 0.2802714705467224, "3": 0.0006162940990179777, "4": 0.06848281621932983, "5": 0.00048616097774356604, "6": 0.0004397366719786078, "7": 0.25898873805999756, "8": 0.21499621868133545, "9": 0.00034181526280008256, "10": 0.04373307526111603, "11": 0.00029763064230792224, "12": 0.0002795618784148246, "13": 0.00026356143644079566, "14": 0.0002492933999747038, "15": 0.0002364908141316846, "16": 0.000224938994506374, "17": 0.00021446312894113362, "18": 0.04209955036640167, "19": 0.00019618927035480738}}, {"key": "kumar2018putting", "year": "2018", "title": "Putting The Horse Before The Cart:a Generator-evaluator Framework For Question Generation From Text", "topic_distr": {"0": 0.001273072906769812, "1": 0.0010393940610811114, "2": 0.11793513596057892, "3": 0.0007609232561662793, "4": 0.2693551480770111, "5": 0.0006002525915391743, "6": 0.10009743273258209, "7": 0.21169783174991608, "8": 0.17855724692344666, "9": 0.0004220320552121848, "10": 0.00039287033723667264, "11": 0.08044798672199249, "12": 0.00034516913001425564, "13": 0.0003254137118346989, "14": 0.016815904527902603, "15": 0.01889645680785179, "16": 0.00027772740577347577, "17": 0.0002647930814418942, "18": 0.0002530099300201982, "19": 0.00024223074433393776}}, {"key": "kumar2019cross", "year": "2019", "title": "Cross-lingual Training For Automatic Question Generation", "topic_distr": {"0": 0.0015992231201380491, "1": 0.17175057530403137, "2": 0.3150608241558075, "3": 0.0009559827740304172, "4": 0.000843134883325547, "5": 0.0007541219238191843, "6": 0.0006821096176281571, "7": 0.0006226515979506075, "8": 0.24726347625255585, "9": 0.0005302160861901939, "10": 0.0004935790784657001, "11": 0.0004616779333446175, "12": 0.0004336501006036997, "13": 0.0004088305577170104, "14": 0.05967516079545021, "15": 0.1682201325893402, "16": 0.0003489202936179936, "17": 0.0003326703736092895, "18": 0.00031786671024747193, "19": 0.02924513630568981}}, {"key": "kumar2019reinforcement", "year": "2019", "title": "Reinforcement Learning Based Curriculum Optimization For Neural Machine Translation", "topic_distr": {"0": 0.02309347502887249, "1": 0.08128715306520462, "2": 0.385562539100647, "3": 0.0010077349143102765, "4": 0.058601073920726776, "5": 0.0007949490682221949, "6": 0.0007190381293185055, "7": 0.0006563611095771194, "8": 0.0006037349230609834, "9": 0.0005589213105849922, "10": 0.0005203007603995502, "11": 0.10164528340101242, "12": 0.000457127345725894, "13": 0.10427463054656982, "14": 0.2004268616437912, "15": 0.0003866993938572705, "16": 0.03839750587940216, "17": 0.00035068069701083004, "18": 0.0003350755723658949, "19": 0.0003208000853192061}}, {"key": "kumar2020data", "year": "2020", "title": "Data Augmentation Using Pre-trained Transformer Models", "topic_distr": {"0": 0.0020797294564545155, "1": 0.3243592381477356, "2": 0.06939230114221573, "3": 0.001242719474248588, "4": 0.001096026855520904, "5": 0.0009803147986531258, "6": 0.0008867030264809728, "7": 0.12567345798015594, "8": 0.0007445135270245373, "9": 0.0006892503006383777, "10": 0.32194918394088745, "11": 0.000600154628045857, "12": 0.0005637200665660203, "13": 0.0005314560839906335, "14": 0.0005026854341849685, "15": 0.000476869783597067, "16": 0.00045357621274888515, "17": 0.14696930348873138, "18": 0.0004132083267904818, "19": 0.0003956040891353041}}, {"key": "kumar2020ma", "year": "2020", "title": "MA-DST: Multi-attention Based Scalable Dialog State Tracking", "topic_distr": {"0": 0.029847407713532448, "1": 0.0011705687502399087, "2": 0.2945948541164398, "3": 0.0008571079233661294, "4": 0.1852876991033554, "5": 0.20231248438358307, "6": 0.21185313165187836, "7": 0.0005582558806054294, "8": 0.0005134956445544958, "9": 0.00047538024955429137, "10": 0.0004425322695169598, "11": 0.06948721408843994, "12": 0.0003888012724928558, "13": 0.000366548600140959, "14": 0.00034670528839342296, "15": 0.0003289000887889415, "16": 0.0003128343669231981, "17": 0.0002982650476042181, "18": 0.000284992391243577, "19": 0.0002728506224229932}}, {"key": "kumar2022language", "year": "2022", "title": "Language Generation Models Can Cause Harm: So What Can We Do About It? An Actionable Survey", "topic_distr": {"0": 0.12015866488218307, "1": 0.0011985108722001314, "2": 0.0010129656875506043, "3": 0.0008773591835051775, "4": 0.0007737921550869942, "5": 0.05109439790248871, "6": 0.0006260102381929755, "7": 0.11907441914081573, "8": 0.0005256247241050005, "9": 0.2889408469200134, "10": 0.0004529851721599698, "11": 0.0004237077373545617, "12": 0.31477075815200806, "13": 0.0003752067277673632, "14": 0.00035489469883032143, "15": 0.0003366689197719097, "16": 0.00032022371306084096, "17": 0.080879807472229, "18": 0.00029172407812438905, "19": 0.017511462792754173}}, {"key": "kumar2023geotechnical", "year": "2023", "title": "Geotechnical Parrot Tales (GPT): Harnessing Large Language Models In Geotechnical Engineering", "topic_distr": {"0": 0.04871392622590065, "1": 0.04243993014097214, "2": 0.0010248825419694185, "3": 0.270379900932312, "4": 0.000782921037171036, "5": 0.0007002642378211021, "6": 0.0006333949277177453, "7": 0.000578183273319155, "8": 0.0005318252369761467, "9": 0.6306350827217102, "10": 0.0004583287809509784, "11": 0.0004287059709895402, "12": 0.0004026798123959452, "13": 0.0003796328091993928, "14": 0.0003590811975300312, "15": 0.00034064039937220514, "16": 0.00032400121563114226, "17": 0.0003089118399657309, "18": 0.0002951654023490846, "19": 0.0002825902483891696}}, {"key": "kurtic2022optimal", "year": "2022", "title": "The Optimal BERT Surgeon: Scalable And Accurate Second-order Pruning For Large Language Models", "topic_distr": {"0": 0.0009670642320998013, "1": 0.0007895278977230191, "2": 0.3259925842285156, "3": 0.0005781211657449603, "4": 0.0005098779802210629, "5": 0.00045604773913510144, "6": 0.0427858792245388, "7": 0.00037654238985851407, "8": 0.0003463517059572041, "9": 0.04740972816944122, "10": 0.17173118889331818, "11": 0.0002791951992549002, "12": 0.00026224562316201627, "13": 0.40627148747444153, "14": 0.00023385196982417256, "15": 0.00022184239060152322, "16": 0.00021100610319990665, "17": 0.0002011791366385296, "18": 0.00019222675473429263, "19": 0.00018403716967441142}}, {"key": "kuzman2023beginning", "year": "2023", "title": "Chatgpt: Beginning Of An End Of Manual Linguistic Data Annotation? Use Case Of Automatic Genre Identification", "topic_distr": {"0": 0.0015609822003170848, "1": 0.22426103055477142, "2": 0.218601793050766, "3": 0.31820982694625854, "4": 0.0008220825111493468, "5": 0.0007352923275902867, "6": 0.0006650781142525375, "7": 0.025780247524380684, "8": 0.0005584277678281069, "9": 0.15727782249450684, "10": 0.00048125494504347444, "11": 0.0004501503717619926, "12": 0.00042282234062440693, "13": 0.00039862250559963286, "14": 0.04814569279551506, "15": 0.0003576796443667263, "16": 0.00034020814928226173, "17": 0.000324363965773955, "18": 0.0003099299210589379, "19": 0.0002967257460113615}}, {"key": "kwon2023reward", "year": "2023", "title": "Reward Design With Language Models", "topic_distr": {"0": 0.0011344874510541558, "1": 0.017584996297955513, "2": 0.0007826412911526859, "3": 0.14371764659881592, "4": 0.13350293040275574, "5": 0.0005347440601326525, "6": 0.00048368037096224725, "7": 0.0004415190196596086, "8": 0.00040611857548356056, "9": 0.0003759734972845763, "10": 0.00034999437048099935, "11": 0.566031813621521, "12": 0.0003074990527238697, "13": 0.00028989961720071733, "14": 0.0002742057549767196, "15": 0.00026012377929873765, "16": 0.00024741757079027593, "17": 0.1328331083059311, "18": 0.00022539764177054167, "19": 0.0002157948474632576}}, {"key": "k\u00f6bis2020artificial", "year": "2020", "title": "Artificial Intelligence Versus Maya Angelou: Experimental Evidence That People Cannot Differentiate Ai-generated From Human-written Poetry", "topic_distr": {"0": 0.46041339635849, "1": 0.001273425412364304, "2": 0.05191522836685181, "3": 0.12026907503604889, "4": 0.0008221662719734013, "5": 0.0007353667751885951, "6": 0.0006651454605162144, "7": 0.0006071661482565105, "8": 0.0005584843456745148, "9": 0.0005170295480638742, "10": 0.00048130369395948946, "11": 0.0691201463341713, "12": 0.00042286518146283925, "13": 0.0003986629017163068, "14": 0.00037708107265643775, "15": 0.29015207290649414, "16": 0.0003402426082175225, "17": 0.00032439682399854064, "18": 0.0003099613240920007, "19": 0.0002967558102682233}}, {"key": "k\u00f6pf2023openassistant", "year": "2023", "title": "Openassistant Conversations -- Democratizing Large Language Model Alignment", "topic_distr": {"0": 0.10356862097978592, "1": 0.10149230062961578, "2": 0.0009673631866462529, "3": 0.28933408856391907, "4": 0.16383938491344452, "5": 0.000660957652144134, "6": 0.09049401432275772, "7": 0.0005457291263155639, "8": 0.0005019732634536922, "9": 0.00046471317182295024, "10": 0.0004326022753957659, "11": 0.08116766065359116, "12": 0.1259782463312149, "13": 0.00035832359571941197, "14": 0.0003389255434740335, "15": 0.00032151988125406206, "16": 0.03869668394327164, "17": 0.00029157224344089627, "18": 0.00027859743568114936, "19": 0.00026672810781747103}}, {"key": "labrak2024collection", "year": "2024", "title": "Biomistral: A Collection Of Open-source Pretrained Large Language Models For Medical Domains", "topic_distr": {"0": 0.0012228114064782858, "1": 0.0009985524229705334, "2": 0.0008440721430815756, "3": 0.3227221369743347, "4": 0.0006447848281823099, "5": 0.0005767124821431935, "6": 0.0005216413992457092, "7": 0.0004761710297316313, "8": 0.012594549916684628, "9": 0.06924761086702347, "10": 0.00037746320595033467, "11": 0.00035306692006997764, "12": 0.37535566091537476, "13": 0.05117984861135483, "14": 0.07460702210664749, "15": 0.015592257492244244, "16": 0.00026683579199016094, "17": 0.07194296270608902, "18": 0.0002430876629659906, "19": 0.0002327312104171142}}, {"key": "lahiri2022interactive", "year": "2022", "title": "Interactive Code Generation Via Test-driven User-intent Formalization", "topic_distr": {"0": 0.09837274998426437, "1": 0.001095162471756339, "2": 0.08101508021354675, "3": 0.0008018430671654642, "4": 0.11364562809467316, "5": 0.02960744872689247, "6": 0.3595850467681885, "7": 0.0005222557811066508, "8": 0.0004803819756489247, "9": 0.17860211431980133, "10": 0.0004139947996009141, "11": 0.00038723740726709366, "12": 0.0003637287300080061, "13": 0.05180849879980087, "14": 0.0003243474056944251, "15": 0.08188096433877945, "16": 0.00029266069759614766, "17": 0.00027903090813197196, "18": 0.0002666141663212329, "19": 0.0002552553778514266}}, {"key": "lai2021thank", "year": "2021", "title": "Thank You BART! Rewarding Pre-trained Models Improves Formality Style Transfer", "topic_distr": {"0": 0.0032810571137815714, "1": 0.362463116645813, "2": 0.0022656815126538277, "3": 0.001962388399988413, "4": 0.0017307393718510866, "5": 0.0015480183064937592, "6": 0.001400195644237101, "7": 0.2941604256629944, "8": 0.0011756636667996645, "9": 0.0010883973445743322, "10": 0.0010131909511983395, "11": 0.0765436589717865, "12": 0.0008901721448637545, "13": 0.0008392240270040929, "14": 0.2027387022972107, "15": 0.0007530265720561147, "16": 0.04418624937534332, "17": 0.0006828867481090128, "18": 0.0006524986238218844, "19": 0.0006246996927075088}}, {"key": "lai2023chatgpt", "year": "2023", "title": "Chatgpt Beyond English: Towards A Comprehensive Evaluation Of Large Language Models In Multilingual Learning", "topic_distr": {"0": 0.04528861120343208, "1": 0.0006701085949316621, "2": 0.11916524171829224, "3": 0.0844796821475029, "4": 0.00043270259629935026, "5": 0.00038702026358805597, "6": 0.0003500630846247077, "7": 0.00031954882433637977, "8": 0.033099398016929626, "9": 0.27576178312301636, "10": 0.00025330798234790564, "11": 0.00023693611728958786, "12": 0.2326449602842331, "13": 0.00020981449051760137, "14": 0.15438134968280792, "15": 0.051650382578372955, "16": 0.00017906815628521144, "17": 0.00017072859918698668, "18": 0.00016313124797306955, "19": 0.00015618125326000154}}, {"key": "lai2023psy", "year": "2023", "title": "Psy-llm: Scaling Up Global Mental Health Psychological Services With Ai-based Large Language Models", "topic_distr": {"0": 0.001273264642804861, "1": 0.1735650599002838, "2": 0.0008786219987086952, "3": 0.0007609929307363927, "4": 0.0006711637834087014, "5": 0.0006003056769259274, "6": 0.17272940278053284, "7": 0.0004956510383635759, "8": 0.03679940849542618, "9": 0.47391828894615173, "10": 0.000392905087210238, "11": 0.046152934432029724, "12": 0.0003451996890362352, "13": 0.03677520155906677, "14": 0.0003078244917560369, "15": 0.00029201601864770055, "16": 0.053281623870134354, "17": 0.00026481651002541184, "18": 0.00025303231086581945, "19": 0.00024225216475315392}}, {"key": "lai2023reasoning", "year": "2023", "title": "LISA: Reasoning Segmentation Via Large Language Model", "topic_distr": {"0": 0.0010851063998416066, "1": 0.08339565992355347, "2": 0.0007486492395401001, "3": 0.39743348956108093, "4": 0.06582815200090408, "5": 0.0005115164094604552, "6": 0.0004626706358976662, "7": 0.06379276514053345, "8": 0.000388477899832651, "9": 0.00035964223206974566, "10": 0.00033479154808446765, "11": 0.0003131532284896821, "12": 0.00029414211167022586, "13": 0.000277307175565511, "14": 0.00026229501236230135, "15": 0.00024882471188902855, "16": 0.1051095724105835, "17": 0.00022564821119885892, "18": 0.2787216603755951, "19": 0.00020642130402848125}}, {"key": "lake2019human", "year": "2019", "title": "Human Few-shot Learning Of Compositional Instructions", "topic_distr": {"0": 0.35074129700660706, "1": 0.0011572767980396748, "2": 0.23633268475532532, "3": 0.0008473799098283052, "4": 0.0007473524892702699, "5": 0.0006684517720714211, "6": 0.0006046203197911382, "7": 0.0005519168335013092, "8": 0.000507664866745472, "9": 0.0004699822748079896, "10": 0.0004375072894617915, "11": 0.36709094047546387, "12": 0.000384386396035552, "13": 0.0003623864031396806, "14": 0.037615325301885605, "15": 0.00032516539795324206, "16": 0.00030928209889680147, "17": 0.00029487820575013757, "18": 0.00028175627812743187, "19": 0.00026975240325555205}}, {"key": "lakew2019controlling", "year": "2019", "title": "Controlling The Output Length Of Neural Machine Translation", "topic_distr": {"0": 0.08896736055612564, "1": 0.0012419561389833689, "2": 0.22049733996391296, "3": 0.0009093994740396738, "4": 0.0008020509267225862, "5": 0.0007173757185228169, "6": 0.0006488722283393145, "7": 0.2666637599468231, "8": 0.0005448206211440265, "9": 0.04391483590006828, "10": 0.11879876255989075, "11": 0.00043918160372413695, "12": 0.00041251949733123183, "13": 0.00038890933501534164, "14": 0.23568400740623474, "15": 0.00034896412398666143, "16": 0.01811152696609497, "17": 0.0003164602385368198, "18": 0.00030237791361287236, "19": 0.00028949545230716467}}, {"key": "lamichhane2023evaluation", "year": "2023", "title": "Evaluation Of Chatgpt For Nlp-based Mental Health Applications", "topic_distr": {"0": 0.08875427395105362, "1": 0.36079391837120056, "2": 0.001163544598966837, "3": 0.0010077586630359292, "4": 0.0008887955918908119, "5": 0.0007949623395688832, "6": 0.000719049945473671, "7": 0.0006563719362020493, "8": 0.0006037448765709996, "9": 0.20903809368610382, "10": 0.0005203093751333654, "11": 0.00048668059753254056, "12": 0.07433236390352249, "13": 0.0004309712094254792, "14": 0.039916519075632095, "15": 0.00038670579669997096, "16": 0.0003678164503071457, "17": 0.21848221123218536, "18": 0.0003350811020936817, "19": 0.00032080538221634924}}, {"key": "lample2019cross", "year": "2019", "title": "Cross-lingual Language Model Pretraining", "topic_distr": {"0": 0.0016398574225604534, "1": 0.0013401428004726768, "2": 0.22858533263206482, "3": 0.0009810987394303083, "4": 0.0008652883116155863, "5": 0.0007739370921626687, "6": 0.0007000325131230056, "7": 0.0006390121416188776, "8": 0.0005877769435755908, "9": 0.0005441478569991887, "10": 0.0005065481527708471, "11": 0.0004738088173326105, "12": 0.00044504451216198504, "13": 0.017621325328946114, "14": 0.5779849886894226, "15": 0.020161958411335945, "16": 0.00035808837856166065, "17": 0.03529175743460655, "18": 0.000326218840200454, "19": 0.11017356067895889}}, {"key": "lan2019lite", "year": "2019", "title": "ALBERT: A Lite BERT For Self-supervised Learning Of Language Representations", "topic_distr": {"0": 0.01968536712229252, "1": 0.0013579598162323236, "2": 0.27236655354499817, "3": 0.0009942848701030016, "4": 0.0008769159903749824, "5": 0.0007843367056921124, "6": 0.0007094392785802484, "7": 0.0006475988775491714, "8": 0.0005956752575002611, "9": 0.0005514599033631384, "10": 0.3315914571285248, "11": 0.0004801756585948169, "12": 0.00045102485455572605, "13": 0.3108657896518707, "14": 0.0004021918575745076, "15": 0.00038153710193000734, "16": 0.00036290023126639426, "17": 0.0003459992294665426, "18": 0.00033060243004001677, "19": 0.05621876195073128}}, {"key": "lan2020novel", "year": "2020", "title": "PONE: A Novel Automatic Evaluation Metric For Open-domain Generative Dialogue Systems", "topic_distr": {"0": 0.07506074756383896, "1": 0.000848827650770545, "2": 0.15176157653331757, "3": 0.000621434417553246, "4": 0.3638307452201843, "5": 0.06799889355897903, "6": 0.00044340427848510444, "7": 0.0004047536349389702, "8": 0.00037230103043839335, "9": 0.0003446661285124719, "10": 0.00032085026032291353, "11": 0.00030011299531906843, "12": 0.0002818935317918658, "13": 0.00026575964875519276, "14": 0.0002513726067263633, "15": 0.3360450863838196, "16": 0.00022681507107336074, "17": 0.00021625183580908924, "18": 0.00020662874158006161, "19": 0.00019782557501457632}}, {"key": "landi2019multimodal", "year": "2019", "title": "Multimodal Attention Networks For Low-level Vision-and-language Navigation", "topic_distr": {"0": 0.0012348112650215626, "1": 0.0010084803216159344, "2": 0.31754541397094727, "3": 0.0007383445627056062, "4": 0.0006511903484351933, "5": 0.0005824413383379579, "6": 0.000526823103427887, "7": 0.019424332305788994, "8": 0.00044234300730749965, "9": 0.00040950908442027867, "10": 0.09940759837627411, "11": 0.32187557220458984, "12": 0.0003349269391037524, "13": 0.0003157577302772552, "14": 0.00029866400291211903, "15": 0.00028332596411928535, "16": 0.04006557911634445, "17": 0.0002569358912296593, "18": 0.19436295330524445, "19": 0.00023504302953369915}}, {"key": "lankford2024fine", "year": "2024", "title": "Adaptmllm: Fine-tuning Multilingual Language Models On Low-resource Languages With Integrated LLM Playgrounds", "topic_distr": {"0": 0.030047697946429253, "1": 0.0009343760902993381, "2": 0.10187783092260361, "3": 0.1893371194601059, "4": 0.0006034205434843898, "5": 0.0005397141212597489, "6": 0.0004881759232375771, "7": 0.0004456226888578385, "8": 0.0004098932258784771, "9": 0.21715499460697174, "10": 0.0003532473638188094, "11": 0.00033041619462892413, "12": 0.14927268028259277, "13": 0.0002925940789282322, "14": 0.252675324678421, "15": 0.00026254149270243943, "16": 0.0002497171808499843, "17": 0.00023808734840713441, "18": 0.054268743842840195, "19": 0.00021780052338726819}}, {"key": "lapid2023open", "year": "2023", "title": "Open Sesame! Universal Black Box Jailbreaking Of Large Language Models", "topic_distr": {"0": 0.2562738060951233, "1": 0.10752121359109879, "2": 0.0009783682180568576, "3": 0.3713483214378357, "4": 0.07306268811225891, "5": 0.0006684698746539652, "6": 0.11805960536003113, "7": 0.0005519317928701639, "8": 0.0005076786037534475, "9": 0.027041710913181305, "10": 0.0004375191347207874, "11": 0.00040924130007624626, "12": 0.0003843967861030251, "13": 0.02179490216076374, "14": 0.0003427776973694563, "15": 0.00032517418731004, "16": 0.01944575086236, "17": 0.00029488620930351317, "18": 0.00028176390333101153, "19": 0.00026975967921316624}}, {"key": "laskar2023systematic", "year": "2023", "title": "A Systematic Study And Comprehensive Evaluation Of Chatgpt On Benchmark Datasets", "topic_distr": {"0": 0.10775423794984818, "1": 0.000743431446608156, "2": 0.0006284278933890164, "3": 0.34028178453445435, "4": 0.0004800472524948418, "5": 0.00042936683166772127, "6": 0.00038836593739688396, "7": 0.014311034232378006, "8": 0.00032608851324766874, "9": 0.20132380723953247, "10": 0.00028102417127229273, "11": 0.000262860965449363, "12": 0.21425801515579224, "13": 0.00023277176660485566, "14": 0.021645132452249527, "15": 0.09591125696897507, "16": 0.00019866126240231097, "17": 0.00018940921290777624, "18": 0.00018098058353643864, "19": 0.00017327013483736664}}, {"key": "latcinnik2020explaining", "year": "2020", "title": "Explaining Question Answering Models Through Text Generation", "topic_distr": {"0": 0.0014857789501547813, "1": 0.0012124943314120173, "2": 0.4644600450992584, "3": 0.0008877458167262375, "4": 0.0007829522946849465, "5": 0.0007002943311817944, "6": 0.0006334214122034609, "7": 0.10604068636894226, "8": 0.24143874645233154, "9": 0.0004923698725178838, "10": 0.00045834793127141893, "11": 0.00042872389894910157, "12": 0.0004026966344099492, "13": 0.00037964869989082217, "14": 0.0003590961860027164, "15": 0.00034065466024912894, "16": 0.07330743968486786, "17": 0.00030892473296262324, "18": 0.00029517774237319827, "19": 0.1055847704410553}}, {"key": "latif2023fine", "year": "2023", "title": "Fine-tuning Chatgpt For Automatic Scoring", "topic_distr": {"0": 0.0009905906626954675, "1": 0.0008085062145255506, "2": 0.0006833022343926132, "3": 0.3644622266292572, "4": 0.04283957555890083, "5": 0.0004668595502153039, "6": 0.23888596892356873, "7": 0.00038546929135918617, "8": 0.01005580648779869, "9": 0.23077408969402313, "10": 0.05771438777446747, "11": 0.00028581422520801425, "12": 0.0002684628125280142, "13": 0.05010531470179558, "14": 0.0002393960312474519, "15": 0.00022710172925144434, "16": 0.00021600854233838618, "17": 0.00020594859961420298, "18": 0.00019678397802636027, "19": 0.0001884002413135022}}, {"key": "lauren\u00e7on2023bigscience", "year": "2023", "title": "The Bigscience ROOTS Corpus: A 1.6TB Composite Multilingual Dataset", "topic_distr": {"0": 0.07878266274929047, "1": 0.282744437456131, "2": 0.0015942283207550645, "3": 0.0013808365911245346, "4": 0.0012178408214822412, "5": 0.0010892689460888505, "6": 0.000985252670943737, "7": 0.0008993704104796052, "8": 0.020695671439170837, "9": 0.16436554491519928, "10": 0.0007129355217330158, "11": 0.0006668568821623921, "12": 0.11833976209163666, "13": 0.0005905230646021664, "14": 0.24060119688510895, "15": 0.08345039188861847, "16": 0.0005039874813519418, "17": 0.0004805157659575343, "18": 0.0004591330362018198, "19": 0.00043957223533652723}}, {"key": "lauscher2020from", "year": "2020", "title": "From Zero To Hero: On The Limitations Of Zero-shot Cross-lingual Transfer With Multilingual Transformers", "topic_distr": {"0": 0.0013863365165889263, "1": 0.0011319075711071491, "2": 0.0009566868538968265, "3": 0.25502321124076843, "4": 0.0007307924679480493, "5": 0.0006536396685987711, "6": 0.0005912226042710245, "7": 0.0005396869964897633, "8": 0.013127585873007774, "9": 0.0004595680220518261, "10": 0.20770063996315002, "11": 0.000400162156438455, "12": 0.0003758688399102539, "13": 0.00035435636527836323, "14": 0.39166784286499023, "15": 0.0003179601044394076, "16": 0.0003024287580046803, "17": 0.0002883440756704658, "18": 0.0002755128953140229, "19": 0.12371627986431122}}, {"key": "lauscher2021sustainable", "year": "2021", "title": "Sustainable Modular Debiasing Of Language Models", "topic_distr": {"0": 0.2187102884054184, "1": 0.016310889273881912, "2": 0.0008698647143319249, "3": 0.03688525781035423, "4": 0.12006142735481262, "5": 0.0005943309515714645, "6": 0.0005375773762352765, "7": 0.0004907178808934987, "8": 0.00045137276174500585, "9": 0.032723791897296906, "10": 0.17649872601032257, "11": 0.0003638529742602259, "12": 0.00034176395274698734, "13": 0.14737464487552643, "14": 0.02498595602810383, "15": 0.00028910962282679975, "16": 0.0759291797876358, "17": 0.09779918193817139, "18": 0.0002505138982087374, "19": 0.048531513661146164}}, {"key": "lazaridou2021mind", "year": "2021", "title": "Mind The Gap: Assessing Temporal Generalization In Neural Language Models", "topic_distr": {"0": 0.19834427535533905, "1": 0.000998695264570415, "2": 0.38519278168678284, "3": 0.0007312000961974263, "4": 0.0006448862259276211, "5": 0.0005768031114712358, "6": 0.07613813132047653, "7": 0.0004762458265759051, "8": 0.0004380610480438918, "9": 0.00040554493898525834, "10": 0.00037752249045297503, "11": 0.04446176439523697, "12": 0.17012646794319153, "13": 0.0003127011004835367, "14": 0.017219509929418564, "15": 0.00028058330644853413, "16": 0.10254449397325516, "17": 0.00025444867787882686, "18": 0.00024312584719154984, "19": 0.00023276776482816786}}, {"key": "lazaridou2022internet", "year": "2022", "title": "Internet-augmented Language Models Through Few-shot Prompting For Open-domain Question Answering", "topic_distr": {"0": 0.14780473709106445, "1": 0.0009432148654013872, "2": 0.183005690574646, "3": 0.0006905467016622424, "4": 0.0006090308888815343, "5": 0.0005447332514449954, "6": 0.0004927158006466925, "7": 0.00044976684148423374, "8": 0.13125967979431152, "9": 0.08727435767650604, "10": 0.0003565324586816132, "11": 0.030431712046265602, "12": 0.00031324330484494567, "13": 0.11290270835161209, "14": 0.00027932808734476566, "15": 0.0002649830421432853, "16": 0.023012986406683922, "17": 0.14483977854251862, "18": 0.00022960819478612393, "19": 0.13429462909698486}}, {"key": "le2019multimodal", "year": "2019", "title": "Multimodal Transformer Networks For End-to-end Video-grounded Dialogue Systems", "topic_distr": {"0": 0.0011343314545229077, "1": 0.0009260156657546759, "2": 0.245852530002594, "3": 0.0006779313553124666, "4": 0.0619717538356781, "5": 0.10710327327251434, "6": 0.035472266376018524, "7": 0.0315554104745388, "8": 0.0004061491636093706, "9": 0.00037600178620778024, "10": 0.08997500687837601, "11": 0.05400530621409416, "12": 0.0003075221902690828, "13": 0.0002899214450735599, "14": 0.00027422638959251344, "15": 0.000260143366176635, "16": 0.00024743619724176824, "17": 0.00023591260833200067, "18": 0.36871302127838135, "19": 0.00021581108740065247}}, {"key": "le2020bi", "year": "2020", "title": "Bist: Bi-directional Spatio-temporal Reasoning For Video-grounded Dialogues", "topic_distr": {"0": 0.001199211459606886, "1": 0.0009793620556592941, "2": 0.1610574871301651, "3": 0.0007170819444581866, "4": 0.11561513692140579, "5": 0.03905594348907471, "6": 0.12686386704444885, "7": 0.0004670501803047955, "8": 0.058250486850738525, "9": 0.0003977144369855523, "10": 0.051096051931381226, "11": 0.00034630406298674643, "12": 0.0003252804162912071, "13": 0.00030666327802464366, "14": 0.0002900619001593441, "15": 0.00027516562840901315, "16": 0.00026172466459684074, "17": 0.0002495356311555952, "18": 0.44201764464378357, "19": 0.0002282733330503106}}, {"key": "le2022mastering", "year": "2022", "title": "Coderl: Mastering Code Generation Through Pretrained Models And Deep Reinforcement Learning", "topic_distr": {"0": 0.00091686996165663, "1": 0.0007488456321880221, "2": 0.15877826511859894, "3": 0.45368561148643494, "4": 0.0004835558938793838, "5": 0.00043250477756373584, "6": 0.000391204230254516, "7": 0.0710897222161293, "8": 0.0003284716513007879, "9": 0.000304090091958642, "10": 0.000283077999483794, "11": 0.19404619932174683, "12": 0.00024870745255611837, "13": 0.00023447292915079743, "14": 0.00022177961363922805, "15": 0.00021039001876488328, "16": 0.00020011313608847558, "17": 0.00019079346384387463, "18": 0.0001823032507672906, "19": 0.11702300608158112}}, {"key": "le2023text", "year": "2023", "title": "Voicebox: Text-guided Multilingual Universal Speech Generation At Scale", "topic_distr": {"0": 0.0016639645909890532, "1": 0.2966659367084503, "2": 0.16035506129264832, "3": 0.0009942831238731742, "4": 0.0008769124979153275, "5": 0.0007843335042707622, "6": 0.0007094363681972027, "7": 0.2099839299917221, "8": 0.0005956728709861636, "9": 0.0005514576914720237, "10": 0.000513352919369936, "11": 0.00048017376684583724, "12": 0.05083607882261276, "13": 0.043193623423576355, "14": 0.026298092678189278, "15": 0.09052268415689468, "16": 0.0003628987760748714, "17": 0.00034599786158651114, "18": 0.11394964903593063, "19": 0.00031651626341044903}}, {"key": "lebret2016neural", "year": "2016", "title": "Neural Text Generation From Structured Data With Application To The Biography Domain", "topic_distr": {"0": 0.0019188006408512592, "1": 0.09037897735834122, "2": 0.2849659025669098, "3": 0.0011472670594230294, "4": 0.0010118429781869054, "5": 0.0009050184744410217, "6": 0.0008185968035832047, "7": 0.3230096995830536, "8": 0.0006873286329209805, "9": 0.0006363100837916136, "10": 0.0005923421122133732, "11": 0.03657752647995949, "12": 0.0005204216577112675, "13": 0.0004906358080916107, "14": 0.133035346865654, "15": 0.12173925340175629, "16": 0.00041873776353895664, "17": 0.0003992363053839654, "18": 0.0003814704832620919, "19": 0.00036521838046610355}}, {"key": "lee2018ranking", "year": "2018", "title": "Ranking Paragraphs For Improving Answer Recall In Open-domain Question Answering", "topic_distr": {"0": 0.0014505289727821946, "1": 0.001184303080663085, "2": 0.17892630398273468, "3": 0.0008671152172610164, "4": 0.052260786294937134, "5": 0.0006840198184363544, "6": 0.0006187017424963415, "7": 0.0387573316693306, "8": 0.5689358115196228, "9": 0.00048092802171595395, "10": 0.0004476967151276767, "11": 0.0004187610757071525, "12": 0.00039333864697255194, "13": 0.07902803272008896, "14": 0.00035075139021500945, "15": 0.025390319526195526, "16": 0.00031648518051952124, "17": 0.000301745836623013, "18": 0.00028831828967668116, "19": 0.04889872670173645}}, {"key": "lee2018zero", "year": "2018", "title": "Zero-shot Adaptive Transfer For Conversational Language Understanding", "topic_distr": {"0": 0.0015402253484353423, "1": 0.07923462986946106, "2": 0.0010629468597471714, "3": 0.0009206507820636034, "4": 0.0008119745180010796, "5": 0.0007262513390742242, "6": 0.19200077652931213, "7": 0.0005996397812850773, "8": 0.0005515614757314324, "9": 0.000510620535351336, "10": 0.0004753375251311809, "11": 0.04021953418850899, "12": 0.0004176233778707683, "13": 0.16268698871135712, "14": 0.09390832483768463, "15": 0.03295961022377014, "16": 0.13519230484962463, "17": 0.255581796169281, "18": 0.0003061190654989332, "19": 0.0002930772607214749}}, {"key": "lee2019contextualized", "year": "2019", "title": "Contextualized Sparse Representations For Real-time Open-domain Question Answering", "topic_distr": {"0": 0.0018067988567054272, "1": 0.0014759477926418185, "2": 0.3951862156391144, "3": 0.0010807550279423594, "4": 0.0009531830437481403, "5": 0.0008525518351234496, "6": 0.0007711403304710984, "7": 0.0007039217161945999, "8": 0.13188612461090088, "9": 0.0005994213279336691, "10": 0.17758068442344666, "11": 0.0005219373852014542, "12": 0.0004902512882836163, "13": 0.00046219219802878797, "14": 0.04124702513217926, "15": 0.0004147200670558959, "16": 0.18385164439678192, "17": 0.0003760913969017565, "18": 0.0003593555302359164, "19": 0.05938003584742546}}, {"key": "lee2019countering", "year": "2019", "title": "Countering Language Drift Via Visual Grounding", "topic_distr": {"0": 0.21492430567741394, "1": 0.0017263633199036121, "2": 0.0014593445230275393, "3": 0.001263946876861155, "4": 0.0011147467885166407, "5": 0.000997059396468103, "6": 0.0590144619345665, "7": 0.03976821526885033, "8": 0.0007572300964966416, "9": 0.0007010229164734483, "10": 0.0006525834323838353, "11": 0.42678189277648926, "12": 0.0005733486032113433, "13": 0.0005405335687100887, "14": 0.06011071056127548, "15": 0.0004850148980040103, "16": 0.00046132344868965447, "17": 0.0004398387100081891, "18": 0.06026465445756912, "19": 0.12796339392662048}}, {"key": "lee2019cross", "year": "2019", "title": "Cross-lingual Transfer Learning For Question Answering", "topic_distr": {"0": 0.0012729474110528827, "1": 0.09211396425962448, "2": 0.2621779441833496, "3": 0.0007609253516420722, "4": 0.0006711027235724032, "5": 0.0006002516602165997, "6": 0.0005429327138699591, "7": 0.0004956064512953162, "8": 0.14484919607639313, "9": 0.0004220313858240843, "10": 0.00039286972605623305, "11": 0.00036747768172062933, "12": 0.0003451686061453074, "13": 0.00032541321706958115, "14": 0.4314025044441223, "15": 0.0002919897378887981, "16": 0.062207672744989395, "17": 0.0002647926739882678, "18": 0.00025300952256657183, "19": 0.00024223036598414183}}, {"key": "lee2019latent", "year": "2019", "title": "Latent Retrieval For Weakly Supervised Open Domain Question Answering", "topic_distr": {"0": 0.001522501464933157, "1": 0.0012419001432135701, "2": 0.4056553840637207, "3": 0.0009093926637433469, "4": 0.09762777388095856, "5": 0.0007173742051236331, "6": 0.0006488710059784353, "7": 0.0005923103308305144, "8": 0.3697197437286377, "9": 0.0005043791607022285, "10": 0.00046952738193795085, "11": 0.00043918078881688416, "12": 0.0004125187115278095, "13": 0.0003889086074195802, "14": 0.0003678548091556877, "15": 0.00034896345459856093, "16": 0.00033191771944984794, "17": 0.0003164596564602107, "18": 0.00030237733153626323, "19": 0.11748266220092773}}, {"key": "lee2019patent", "year": "2019", "title": "Patent Claim Generation By Fine-tuning Openai GPT-2", "topic_distr": {"0": 0.0014352462021633983, "1": 0.05193736404180527, "2": 0.0009896797128021717, "3": 0.0008571900543756783, "4": 0.0007560045924037695, "5": 0.19751758873462677, "6": 0.0006116196163929999, "7": 0.28149452805519104, "8": 0.0005135417450219393, "9": 0.14777815341949463, "10": 0.0004425720253493637, "11": 0.00041396761662326753, "12": 0.11414293944835663, "13": 0.0003665815165732056, "14": 0.00034673642949201167, "15": 0.19922727346420288, "16": 0.00031286245211958885, "17": 0.0002982918231282383, "18": 0.00028501797351054847, "19": 0.00027287512784823775}}, {"key": "lee2019what", "year": "2019", "title": "What Would Elsa Do? Freezing Layers During Transformer Fine-tuning", "topic_distr": {"0": 0.001710094977170229, "1": 0.16278038918972015, "2": 0.3206122815608978, "3": 0.0010215535294264555, "4": 0.0009009690256789327, "5": 0.0008058497332967818, "6": 0.000728897750377655, "7": 0.0006653613527305424, "8": 0.07823289930820465, "9": 0.0005665854550898075, "10": 0.3452828824520111, "11": 0.0004933460149914026, "12": 0.0004633956414181739, "13": 0.0004368736408650875, "14": 0.00041322322795167565, "15": 0.0003920019662473351, "16": 0.0003728539159055799, "17": 0.00035548937739804387, "18": 0.0003396702522877604, "19": 0.0834253653883934}}, {"key": "lee2020contrastive", "year": "2020", "title": "Contrastive Learning With Adversarial Perturbations For Conditional Text Generation", "topic_distr": {"0": 0.05865444988012314, "1": 0.1784050166606903, "2": 0.0006020583678036928, "3": 0.0005214577540755272, "4": 0.0004599038802552968, "5": 0.00041135004721581936, "6": 0.00037206962588243186, "7": 0.33983513712882996, "8": 0.006361774168908596, "9": 0.00028921643388457596, "10": 0.05273778364062309, "11": 0.00025183099205605686, "12": 0.0002365426771575585, "13": 0.00022300437558442354, "14": 0.0803460106253624, "15": 0.15839822590351105, "16": 0.0001903251832118258, "17": 0.12136440724134445, "18": 0.00017338641919195652, "19": 0.0001659995032241568}}, {"key": "lee2020multimodal", "year": "2020", "title": "DSTC8-AVSD: Multimodal Semantic Transformer Network With Retrieval Style Word Generator", "topic_distr": {"0": 0.025081174448132515, "1": 0.001257535768672824, "2": 0.29958388209342957, "3": 0.0009206499089486897, "4": 0.08603624254465103, "5": 0.0007262535509653389, "6": 0.08085182309150696, "7": 0.1133214682340622, "8": 0.023341501131653786, "9": 0.0005106221069581807, "10": 0.11271259188652039, "11": 0.0004446167731657624, "12": 0.00041762468754313886, "13": 0.0003937223518732935, "14": 0.0003724079579114914, "15": 0.00035328278318047523, "16": 0.05092886462807655, "17": 0.0003203766536898911, "18": 0.2021322399377823, "19": 0.00029307816294021904}}, {"key": "lee2021context", "year": "2021", "title": "Compm: Context Modeling With Speaker's Pre-trained Memory Tracking For Emotion Recognition In Conversation", "topic_distr": {"0": 0.03602967783808708, "1": 0.001039608963765204, "2": 0.4431285858154297, "3": 0.0007609346648678184, "4": 0.0006711127352900803, "5": 0.022754039615392685, "6": 0.2051750272512436, "7": 0.0004956136690452695, "8": 0.00045587599743157625, "9": 0.09997545927762985, "10": 0.0003928754886146635, "11": 0.00036748306592926383, "12": 0.0003451736702118069, "13": 0.0003254179609939456, "14": 0.00030780129600316286, "15": 0.00029199401615187526, "16": 0.18672329187393188, "17": 0.0002647965447977185, "18": 0.00025301321875303984, "19": 0.00024223390209954232}}, {"key": "lee2021dialogue", "year": "2021", "title": "Dialogue State Tracking With A Language Model Using Schema-driven Prompting", "topic_distr": {"0": 0.001890402752906084, "1": 0.0015431881183758378, "2": 0.001304445555433631, "3": 0.0011297946330159903, "4": 0.000996431801468134, "5": 0.2653186023235321, "6": 0.1736883819103241, "7": 0.0007358600269071758, "8": 0.0006768597522750497, "9": 0.0006266182754188776, "10": 0.18986397981643677, "11": 0.0005456187063828111, "12": 0.0005124949384480715, "13": 0.0004831627884414047, "14": 0.0004570065066218376, "15": 0.0004335367411840707, "16": 0.040544554591178894, "17": 0.3185136914253235, "18": 0.00037566019454970956, "19": 0.0003596556489355862}}, {"key": "lee2021towards", "year": "2021", "title": "Towards Few-shot Fact-checking Via Perplexity", "topic_distr": {"0": 0.0013877718010917306, "1": 0.07947129011154175, "2": 0.38516926765441895, "3": 0.1355220228433609, "4": 0.0007307690102607012, "5": 0.0006536169676110148, "6": 0.000591202056966722, "7": 0.0005396682536229491, "8": 0.03668133541941643, "9": 0.12642668187618256, "10": 0.0004277977568563074, "11": 0.00040014824480749667, "12": 0.0003758557722903788, "13": 0.00035434402525424957, "14": 0.046462081372737885, "15": 0.00031794904498383403, "16": 0.0003024182515218854, "17": 0.18364651501178741, "18": 0.00027550332015380263, "19": 0.0002637658326420933}}, {"key": "lee2022designing", "year": "2022", "title": "Coauthor: Designing A Human-ai Collaborative Writing Dataset For Exploring Language Model Capabilities", "topic_distr": {"0": 0.14025217294692993, "1": 0.0012893322855234146, "2": 0.001089851837605238, "3": 0.14808623492717743, "4": 0.0008325334056280553, "5": 0.0007446376839652658, "6": 0.0006735309725627303, "7": 0.000614820746704936, "8": 0.0005655252025462687, "9": 0.4350641965866089, "10": 0.0004873715224675834, "11": 0.0004558716027531773, "12": 0.000428196246502921, "13": 0.00040368884219788015, "14": 0.0003818349214270711, "15": 0.02771146036684513, "16": 0.00034453204716555774, "17": 0.0003284865233581513, "18": 0.1698780059814453, "19": 0.07036767899990082}}, {"key": "lee2022do", "year": "2022", "title": "Do Language Models Plagiarize?", "topic_distr": {"0": 0.2932998239994049, "1": 0.24334879219532013, "2": 0.0006943307816982269, "3": 0.0006013747770339251, "4": 0.0005303866346366704, "5": 0.0004743918252643198, "6": 0.00042909145122393966, "7": 0.05185887590050697, "8": 0.00036028336035087705, "9": 0.06358445435762405, "10": 0.03837382793426514, "11": 0.0002904255234170705, "12": 0.0002727941900957376, "13": 0.05485997721552849, "14": 0.0002432584296911955, "15": 0.11179864406585693, "16": 0.0002194936096202582, "17": 0.0002092713548336178, "18": 0.0001999588857870549, "19": 0.13835056126117706}}, {"key": "lee2022evaluating", "year": "2022", "title": "Evaluating Human-language Model Interaction", "topic_distr": {"0": 0.2515943646430969, "1": 0.001184158492833376, "2": 0.0010011092526838183, "3": 0.09317506104707718, "4": 0.3488301932811737, "5": 0.014257874339818954, "6": 0.0006186786340549588, "7": 0.0924924686551094, "8": 0.02979833260178566, "9": 0.07631395012140274, "10": 0.0004476799804251641, "11": 0.00041874541784636676, "12": 0.0003933239495381713, "13": 0.00037081242771819234, "14": 0.0003507382934913039, "15": 0.0003327259619254619, "16": 0.0003164733643643558, "17": 0.00030173457344062626, "18": 0.00028830752125941217, "19": 0.0875132754445076}}, {"key": "lee2022screenshot", "year": "2022", "title": "Pix2struct: Screenshot Parsing As Pretraining For Visual Language Understanding", "topic_distr": {"0": 0.001313682645559311, "1": 0.06439142674207687, "2": 0.0009063152247108519, "3": 0.000784974719863385, "4": 0.0006923149921931326, "5": 0.04832112416625023, "6": 0.0005600928561761975, "7": 0.0005112707731314003, "8": 0.00047027773689478636, "9": 0.00043537028250284493, "10": 0.14930877089500427, "11": 0.00037909235106781125, "12": 0.0003560781478881836, "13": 0.00033569836523383856, "14": 0.02998429350554943, "15": 0.00030121850431896746, "16": 0.05484647676348686, "17": 0.06281419098377228, "18": 0.34638598561286926, "19": 0.23690134286880493}}, {"key": "lee2023applying", "year": "2023", "title": "Applying Large Language Models And Chain-of-thought For Automatic Scoring", "topic_distr": {"0": 0.0010232534259557724, "1": 0.0008348352275788784, "2": 0.0007057506591081619, "3": 0.693873405456543, "4": 0.058520589023828506, "5": 0.03127134218811989, "6": 0.05297510325908661, "7": 0.0003981298941653222, "8": 0.00036620834725908935, "9": 0.15756644308567047, "10": 0.00031559960916638374, "11": 0.00029520169482566416, "12": 0.0002772804000414908, "13": 0.00026141051785089076, "14": 0.0002472589258104563, "15": 0.00023456082271877676, "16": 0.00022310327040031552, "17": 0.00021271291188895702, "18": 0.00020324728393461555, "19": 0.00019458818132989109}}, {"key": "lee2023read", "year": "2023", "title": "Read-only Prompt Optimization For Vision-language Few-shot Learning", "topic_distr": {"0": 0.0014346142997965217, "1": 0.001170951989479363, "2": 0.0009896648116409779, "3": 0.0008571568178012967, "4": 0.031009946018457413, "5": 0.0006761672557331622, "6": 0.0006115990690886974, "7": 0.0005582872545346618, "8": 0.0005135245155543089, "9": 0.00047540696687065065, "10": 0.1061849296092987, "11": 0.0004139537049923092, "12": 0.0003888231294695288, "13": 0.2411368191242218, "14": 0.00034672478795982897, "15": 0.00032891856972128153, "16": 0.09806621074676514, "17": 0.44415876269340515, "18": 0.07040464878082275, "19": 0.0002728659601416439}}, {"key": "lehman2022evolution", "year": "2022", "title": "Evolution Through Large Models", "topic_distr": {"0": 0.0014852400636300445, "1": 0.18818902969360352, "2": 0.13363082706928253, "3": 0.25747737288475037, "4": 0.000782968825660646, "5": 0.0007003064383752644, "6": 0.04599153622984886, "7": 0.05666927620768547, "8": 0.00053185730939731, "9": 0.12106551229953766, "10": 0.00045835640048608184, "11": 0.13596387207508087, "12": 0.054763711988925934, "13": 0.0003796556848101318, "14": 0.00035910282167606056, "15": 0.00034066091757267714, "16": 0.00032402071519754827, "17": 0.00030893043731339276, "18": 0.0002951831847894937, "19": 0.0002826072450261563}}, {"key": "lehman2023do", "year": "2023", "title": "Do We Still Need Clinical Language Models?", "topic_distr": {"0": 0.053712911903858185, "1": 0.18468832969665527, "2": 0.0007174735656008124, "3": 0.33436596393585205, "4": 0.0005480634281411767, "5": 0.000490202393848449, "6": 0.00044339217129163444, "7": 0.00040474263369105756, "8": 0.020817480981349945, "9": 0.0003446567279752344, "10": 0.0003208415291737765, "11": 0.00030010484624654055, "12": 0.030028555542230606, "13": 0.28424251079559326, "14": 0.00025136576732620597, "15": 0.0002384567487752065, "16": 0.00022680890106130391, "17": 0.00021624595683533698, "18": 0.00020662310998886824, "19": 0.087435282766819}}, {"key": "lehr2024chatgpt", "year": "2024", "title": "Chatgpt As Research Scientist: Probing Gpt's Capabilities As A Research Librarian, Research Ethicist, Data Generator And Data Predictor", "topic_distr": {"0": 0.3398849368095398, "1": 0.1647864282131195, "2": 0.0007296538096852601, "3": 0.0006319606909528375, "4": 0.0005573616363108158, "5": 0.0004985186969861388, "6": 0.0004509143764153123, "7": 0.11755003035068512, "8": 0.000378606840968132, "9": 0.23834693431854248, "10": 0.00032628464396111667, "11": 0.0003051961539313197, "12": 0.11461371183395386, "13": 0.00027026093448512256, "14": 0.0002556302060838789, "15": 0.00024250219576060772, "16": 0.0002306567330379039, "17": 0.00021991459652781487, "18": 0.00021012849174439907, "19": 0.019510341808199883}}, {"key": "lei2016rationalizing", "year": "2016", "title": "Rationalizing Neural Predictions", "topic_distr": {"0": 0.07608692348003387, "1": 0.001726633752696216, "2": 0.5222315788269043, "3": 0.0012639868073165417, "4": 0.0011147847399115562, "5": 0.0009970928076654673, "6": 0.0009018785785883665, "7": 0.2379816770553589, "8": 0.04359159618616104, "9": 0.0007010464905761182, "10": 0.0006526053184643388, "11": 0.10891611129045486, "12": 0.0005733678699471056, "13": 0.0005405516712926328, "14": 0.0005112886428833008, "15": 0.00048503116704523563, "16": 0.00046133893192745745, "17": 0.00043985346565023065, "18": 0.0004202802083455026, "19": 0.0004023746878374368}}, {"key": "lei2020memory", "year": "2020", "title": "MART: Memory-augmented Recurrent Transformer For Coherent Video Paragraph Captioning", "topic_distr": {"0": 0.0014850038569420576, "1": 0.0012124099303036928, "2": 0.3657052516937256, "3": 0.0008877025684341788, "4": 0.0007829198148101568, "5": 0.0007002634229138494, "6": 0.1232328861951828, "7": 0.17501935362815857, "8": 0.0005318244802765548, "9": 0.0004923485685139894, "10": 0.043755099177360535, "11": 0.00042870535980910063, "12": 0.00040267923031933606, "13": 0.0003796322562266141, "14": 0.000359080673661083, "15": 0.0003406399046070874, "16": 0.06543570756912231, "17": 0.0003089113743044436, "18": 0.21825698018074036, "19": 0.0002825898118317127}}, {"key": "lei2021when", "year": "2021", "title": "When Attention Meets Fast Recurrence: Training Language Models With Reduced Compute", "topic_distr": {"0": 0.0018088722135871649, "1": 0.001475983764976263, "2": 0.4523150622844696, "3": 0.001080645713955164, "4": 0.0009530845563858747, "5": 0.0008524644654244184, "6": 0.0007710613426752388, "7": 0.0007038495969027281, "8": 0.0006474158144555986, "9": 0.0005993598606437445, "10": 0.10102883726358414, "11": 0.0005218838923610747, "12": 0.0004902009968645871, "13": 0.39917072653770447, "14": 0.03569203242659569, "15": 0.00041467754635959864, "16": 0.0003944218624383211, "17": 0.0003760528634302318, "18": 0.00035931868478655815, "19": 0.00034401033190079033}}, {"key": "lei2024materials", "year": "2024", "title": "Materials Science In The Era Of Large Language Models: A Perspective", "topic_distr": {"0": 0.09773537516593933, "1": 0.0011841836385428905, "2": 0.0010010701371356845, "3": 0.2960301637649536, "4": 0.0007647237507626414, "5": 0.0006839890265837312, "6": 0.0006186738610267639, "7": 0.000564745394513011, "8": 0.0005194648401811719, "9": 0.519198477268219, "10": 0.00044767651706933975, "11": 0.00041874218732118607, "12": 0.0003933209227398038, "13": 0.0003708095755428076, "14": 0.00035073558683507144, "15": 0.06036859005689621, "16": 0.018483195453882217, "17": 0.0003017322451341897, "18": 0.00028830530936829746, "19": 0.00027602241607382894}}, {"key": "leiter2023meta", "year": "2023", "title": "Chatgpt: A Meta-analysis After 2.5 Months", "topic_distr": {"0": 0.13536086678504944, "1": 0.1133648082613945, "2": 0.0010897950269281864, "3": 0.0009439047425985336, "4": 0.0008324856171384454, "5": 0.0007445969968102872, "6": 0.0006734943017363548, "7": 0.0006147872190922499, "8": 0.0005654943524859846, "9": 0.48453181982040405, "10": 0.0004873449506703764, "11": 0.0004558467771857977, "12": 0.2578997313976288, "13": 0.0004036668688058853, "14": 0.000381814141292125, "15": 0.00036220590118318796, "16": 0.00034451327519491315, "17": 0.0003284686245024204, "18": 0.0003138519241474569, "19": 0.0003004806349053979}}, {"key": "lelkes2021quiz", "year": "2021", "title": "Quiz-style Question Generation For News Stories", "topic_distr": {"0": 0.13363595306873322, "1": 0.0009094124543480575, "2": 0.0007687575416639447, "3": 0.17464198172092438, "4": 0.09793257713317871, "5": 0.0005252383998595178, "6": 0.00047508240095339715, "7": 0.0004336704732850194, "8": 0.14119061827659607, "9": 0.06911461800336838, "10": 0.03218076005578041, "11": 0.00032155399094335735, "12": 0.10519342869520187, "13": 0.0002847463183570653, "14": 0.0002693314163479954, "15": 0.24121421575546265, "16": 0.0002430194290354848, "17": 0.0002317015314474702, "18": 0.00022139091743156314, "19": 0.00021195883164182305}}, {"key": "lenat2023getting", "year": "2023", "title": "Getting From Generative AI To Trustworthy AI: What Llms Might Learn From Cyc", "topic_distr": {"0": 0.3017433285713196, "1": 0.0008083350257948041, "2": 0.0006833352381363511, "3": 0.19739477336406708, "4": 0.0005219855811446905, "5": 0.03528265655040741, "6": 0.000422294600866735, "7": 0.00038548410520888865, "8": 0.0003545764775481075, "9": 0.2365645468235016, "10": 0.0003055752022191882, "11": 0.14515851438045502, "12": 0.00026847311528399587, "13": 0.00025310731143690646, "14": 0.00023940522805787623, "15": 0.00022711046040058136, "16": 0.07879535108804703, "17": 0.00020595650130417198, "18": 0.0001967915304703638, "19": 0.0001884074736153707}}, {"key": "leng2023mitigating", "year": "2023", "title": "Mitigating Object Hallucinations In Large Vision-language Models Through Visual Contrastive Decoding", "topic_distr": {"0": 0.2860434949398041, "1": 0.031085534021258354, "2": 0.000878584454767406, "3": 0.14747610688209534, "4": 0.0006711348542012274, "5": 0.0006002805894240737, "6": 0.0005429588491097093, "7": 0.1611381471157074, "8": 0.0004558913060463965, "9": 0.00042205172940157354, "10": 0.0003928886726498604, "11": 0.0003674954059533775, "12": 0.0003451852535363287, "13": 0.00032542890403419733, "14": 0.000307811627862975, "15": 0.0002920038241427392, "16": 0.000277740356978029, "17": 0.0002648054505698383, "18": 0.3678702116012573, "19": 0.00024224203662015498}}, {"key": "lepikhin2020scaling", "year": "2020", "title": "Gshard: Scaling Giant Models With Conditional Computation And Automatic Sharding", "topic_distr": {"0": 0.0015419113915413618, "1": 0.0012578588211908937, "2": 0.16333205997943878, "3": 0.05336540937423706, "4": 0.0008120369166135788, "5": 0.0007263074512593448, "6": 0.060668766498565674, "7": 0.048882801085710526, "8": 0.0005516038509085774, "9": 0.0005106597673147917, "10": 0.0004753740504384041, "11": 0.04794427379965782, "12": 0.00041765550849959254, "13": 0.39074695110321045, "14": 0.22715729475021362, "15": 0.000353308831108734, "16": 0.00033605084172450006, "17": 0.00032040028600022197, "18": 0.0003061426104977727, "19": 0.0002930997870862484}}, {"key": "lester2021power", "year": "2021", "title": "The Power Of Scale For Parameter-efficient Prompt Tuning", "topic_distr": {"0": 0.0012994384160265326, "1": 0.001061060233041644, "2": 0.17307782173156738, "3": 0.000776787637732923, "4": 0.0006850939244031906, "5": 0.0006127663073129952, "6": 0.0005542522412724793, "7": 0.05862731486558914, "8": 0.0004653736832551658, "9": 0.0004308302595745772, "10": 0.0004010606207884848, "11": 0.0003751391777768731, "12": 0.0003523649647831917, "13": 0.15555281937122345, "14": 0.0003142140049021691, "15": 0.0002980773861054331, "16": 0.00028351726359687746, "17": 0.6043264865875244, "18": 0.000258284475421533, "19": 0.0002472805790603161}}, {"key": "leviathan2022fast", "year": "2022", "title": "Fast Inference From Transformers Via Speculative Decoding", "topic_distr": {"0": 0.0017817564075812697, "1": 0.0014549980405718088, "2": 0.25908395648002625, "3": 0.09310417622327805, "4": 0.0009395599481649697, "5": 0.0008403676329180598, "6": 0.0007601193501614034, "7": 0.30560559034347534, "8": 0.0006382284918799996, "9": 0.0005908545572310686, "10": 0.12997770309448242, "11": 0.0005144780152477324, "12": 0.0004832447157241404, "13": 0.2019323855638504, "14": 0.0004309232463128865, "15": 0.00040879298467189074, "16": 0.0003888247301802039, "17": 0.0003707163850776851, "18": 0.0003542196936905384, "19": 0.0003391286008991301}}, {"key": "levine2022standing", "year": "2022", "title": "Standing On The Shoulders Of Giant Frozen Language Models", "topic_distr": {"0": 0.0010672707576304674, "1": 0.0008705626823939383, "2": 0.0007359516457654536, "3": 0.2800293564796448, "4": 0.0005621765158139169, "5": 0.0005028250743634999, "6": 0.00045480948756448925, "7": 0.0004151647153776139, "8": 0.07479698210954666, "9": 0.09666547179222107, "10": 0.0003291031753178686, "11": 0.00030783252441324294, "12": 0.000289144431008026, "13": 0.12276061624288559, "14": 0.00025783840101212263, "15": 0.00024459700216539204, "16": 0.00023264921037480235, "17": 0.2706108093261719, "18": 0.02612679824233055, "19": 0.1227400079369545}}, {"key": "levy2022diverse", "year": "2022", "title": "Diverse Demonstrations Improve In-context Compositional Generalization", "topic_distr": {"0": 0.0015408321050927043, "1": 0.001257627154700458, "2": 0.347318172454834, "3": 0.05864061415195465, "4": 0.000811994366813451, "5": 0.0007262687431648374, "6": 0.019441906362771988, "7": 0.08748538792133331, "8": 0.0005515747470781207, "9": 0.0005106328753754497, "10": 0.00047534899204038084, "11": 0.3107256293296814, "12": 0.0004176334768999368, "13": 0.00039373061736114323, "14": 0.029300887137651443, "15": 0.0003532902046572417, "16": 0.00033603308838792145, "17": 0.13911326229572296, "18": 0.0003061264578718692, "19": 0.0002930843038484454}}, {"key": "levy2024same", "year": "2024", "title": "Same Task, More Tokens: The Impact Of Input Length On The Reasoning Performance Of Large Language Models", "topic_distr": {"0": 0.07848940789699554, "1": 0.0010085387621074915, "2": 0.4179322123527527, "3": 0.2801257371902466, "4": 0.0006511889514513314, "5": 0.0005824403488077223, "6": 0.0005268221721053123, "7": 0.0004809002566616982, "8": 0.012439467012882233, "9": 0.0641731470823288, "10": 0.00038121207035146654, "11": 0.0003565734950825572, "12": 0.1409476101398468, "13": 0.00031575720640830696, "14": 0.00029866350814700127, "15": 0.00028332549845799804, "16": 0.00026948595768772066, "17": 0.00025693545467220247, "18": 0.0002455019566696137, "19": 0.000235042636631988}}, {"key": "lewis2019denoising", "year": "2019", "title": "BART: Denoising Sequence-to-sequence Pre-training For Natural Language Generation, Translation, And Comprehension", "topic_distr": {"0": 0.0011557640973478556, "1": 0.0009431593935005367, "2": 0.30165693163871765, "3": 0.0006904535694047809, "4": 0.0006089500966481864, "5": 0.01297040656208992, "6": 0.0004926505498588085, "7": 0.2298639863729477, "8": 0.022354530170559883, "9": 0.0003829461638815701, "10": 0.14575952291488647, "11": 0.00033344479743391275, "12": 0.00031320180278271437, "13": 0.0002952759969048202, "14": 0.18966075778007507, "15": 0.00026494794292375445, "16": 0.00025200608070008457, "17": 0.00024026967003010213, "18": 0.00022957778128329664, "19": 0.0915311872959137}}, {"key": "lewis2019evaluating", "year": "2019", "title": "MLQA: Evaluating Cross-lingual Extractive Question Answering", "topic_distr": {"0": 0.04724550619721413, "1": 0.027768706902861595, "2": 0.2908046841621399, "3": 0.0007170287426561117, "4": 0.0006323887500911951, "5": 0.0005656248540617526, "6": 0.0005116123938933015, "7": 0.0004670162161346525, "8": 0.20770049095153809, "9": 0.0003976855368819088, "10": 0.00037020613672211766, "11": 0.00034627888817340136, "12": 0.18038895726203918, "13": 0.0003066409844905138, "14": 0.18173743784427643, "15": 0.059061843901872635, "16": 0.0002617056597955525, "17": 0.00024951749946922064, "18": 0.00023841408255975693, "19": 0.00022825674386695027}}, {"key": "lewis2019unsupervised", "year": "2019", "title": "Unsupervised Question Answering By Cloze Translation", "topic_distr": {"0": 0.0010142780374735594, "1": 0.13212749361991882, "2": 0.2280302494764328, "3": 0.0006062414613552392, "4": 0.000534679857082665, "5": 0.00047823155182413757, "6": 0.0004325644695200026, "7": 0.0003948587691411376, "8": 0.30760589241981506, "9": 0.0003362401621416211, "10": 0.00031300654518418014, "11": 0.0002927762398030609, "12": 0.00027500218129716814, "13": 0.00025926268426701427, "14": 0.16216659545898438, "15": 0.0002326335961697623, "16": 0.0002212701947428286, "17": 0.08547830581665039, "18": 0.00020157734979875386, "19": 0.078998863697052}}, {"key": "lewis2020pre", "year": "2020", "title": "Pre-training Via Paraphrasing", "topic_distr": {"0": 0.0018886267207562923, "1": 0.0015432820655405521, "2": 0.3253743350505829, "3": 0.0011298723984509706, "4": 0.000996502349153161, "5": 0.0008912981720641255, "6": 0.0008061866974458098, "7": 0.21875284612178802, "8": 0.06776392459869385, "9": 0.0006266635027714074, "10": 0.0861518383026123, "11": 0.0005456581129692495, "12": 0.0005125319003127515, "13": 0.00048319765483029187, "14": 0.17348149418830872, "15": 0.04232265055179596, "16": 0.000412389577832073, "17": 0.00039318378549069166, "18": 0.0003756872902158648, "19": 0.07554782927036285}}, {"key": "lewis2020retrieval", "year": "2020", "title": "Retrieval-augmented Generation For Knowledge-intensive NLP Tasks", "topic_distr": {"0": 0.0012348723830655217, "1": 0.0010084736859425902, "2": 0.3395346403121948, "3": 0.0007382964249700308, "4": 0.0006511464016512036, "5": 0.0005824021645821631, "6": 0.0005267877131700516, "7": 0.035162243992090225, "8": 0.08034621179103851, "9": 0.00040948158130049706, "10": 0.00038118709926493466, "11": 0.00035655012470670044, "12": 0.06503890454769135, "13": 0.01693996787071228, "14": 0.00029864395037293434, "15": 0.15411971509456635, "16": 0.18868112564086914, "17": 0.0002569186326581985, "18": 0.00024548586225137115, "19": 0.11348692327737808}}, {"key": "lewis2021million", "year": "2021", "title": "PAQ: 65 Million Probably-asked Questions And What You Can Do With Them", "topic_distr": {"0": 0.0012607569806277752, "1": 0.0010290099307894707, "2": 0.34107282757759094, "3": 0.16724669933319092, "4": 0.0006643712404184043, "5": 0.0005942307761870325, "6": 0.0005374866886995733, "7": 0.050471678376197815, "8": 0.26668789982795715, "9": 0.0004177980881650001, "10": 0.0003889289509970695, "11": 0.0003637916233856231, "12": 0.00034170629805885255, "13": 0.13719028234481812, "14": 0.0003047093632631004, "15": 0.0002890608739107847, "16": 0.030386295169591904, "17": 0.00026213660021312535, "18": 0.0002504716394469142, "19": 0.00023980061814654619}}, {"key": "lewkowycz2022solving", "year": "2022", "title": "Solving Quantitative Reasoning Problems With Language Models", "topic_distr": {"0": 0.002113536698743701, "1": 0.0017267721705138683, "2": 0.0014592198422178626, "3": 0.7229331135749817, "4": 0.0011146956821903586, "5": 0.0009970130631700158, "6": 0.0009018066921271384, "7": 0.0008231981773860753, "8": 0.0007571952301077545, "9": 0.14845959842205048, "10": 0.000652553397230804, "11": 0.0006103774067014456, "12": 0.0005733222351409495, "13": 0.0005405086558312178, "14": 0.0005112479557283223, "15": 0.00048499257536605, "16": 0.0004613022319972515, "17": 0.0004398184537421912, "18": 0.00042024673894047737, "19": 0.11401946097612381}}, {"key": "li2016context", "year": "2016", "title": "A Context-aware Attention Network For Interactive Question Answering", "topic_distr": {"0": 0.0644863024353981, "1": 0.0010082984808832407, "2": 0.3780191242694855, "3": 0.0007383288466371596, "4": 0.17953252792358398, "5": 0.02520441636443138, "6": 0.0005268111126497388, "7": 0.0004808900994248688, "8": 0.27774578332901, "9": 0.0004094997711945325, "10": 0.0692518949508667, "11": 0.0003565659571904689, "12": 0.0003349193139001727, "13": 0.00031575054163113236, "14": 0.0002986572217196226, "15": 0.0002833195321727544, "16": 0.0002694802824407816, "17": 0.0002569300413597375, "18": 0.0002454967761877924, "19": 0.00023503768898081034}}, {"key": "li2016deep", "year": "2016", "title": "Deep Reinforcement Learning For Dialogue Generation", "topic_distr": {"0": 0.0012867569457739592, "1": 0.00105014827568084, "2": 0.0008876609499566257, "3": 0.0007688095793128014, "4": 0.05719354748725891, "5": 0.1232077106833458, "6": 0.2549039125442505, "7": 0.08715444803237915, "8": 0.013386334292590618, "9": 0.0004264061280991882, "10": 0.0003969421668443829, "11": 0.37909314036369324, "12": 0.07826085388660431, "13": 0.0003287864092271775, "14": 0.00031098737963475287, "15": 0.0002950164780486375, "16": 0.0002806058619171381, "17": 0.0002675374853424728, "18": 0.00025563218514434993, "19": 0.0002447412989567965}}, {"key": "li2016fast", "year": "2016", "title": "A Simple, Fast Diverse Decoding Algorithm For Neural Generation", "topic_distr": {"0": 0.0017088463064283133, "1": 0.0013953641755506396, "2": 0.13013683259487152, "3": 0.06854207068681717, "4": 0.0009009813657030463, "5": 0.0008058577659539878, "6": 0.1309010088443756, "7": 0.26915398240089417, "8": 0.0006120195612311363, "9": 0.0005665909848175943, "10": 0.0005274405120871961, "11": 0.23170992732048035, "12": 0.00046340018161572516, "13": 0.00043687791912816465, "14": 0.16035358607769012, "15": 0.00039200580795295537, "16": 0.0003728575829882175, "17": 0.0003554928698576987, "18": 0.0003396735992282629, "19": 0.00032520221429876983}}, {"key": "li2016persona", "year": "2016", "title": "A Persona-based Neural Conversation Model", "topic_distr": {"0": 0.21653032302856445, "1": 0.002546628238633275, "2": 0.12422061711549759, "3": 0.0018643139628693461, "4": 0.21170347929000854, "5": 0.0014706631191074848, "6": 0.26457419991493225, "7": 0.0012142743216827512, "8": 0.0011169153731316328, "9": 0.0010340097360312939, "10": 0.0009625614038668573, "11": 0.0009003489394672215, "12": 0.0008456899668090045, "13": 0.0007972876774147153, "14": 0.16696065664291382, "15": 0.0007153975893743336, "16": 0.0006804526783525944, "17": 0.0006487626815214753, "18": 0.0006198930204845965, "19": 0.0005934832151979208}}, {"key": "li2016user", "year": "2016", "title": "A User Simulator For Task-completion Dialogues", "topic_distr": {"0": 0.09312693029642105, "1": 0.0009262125822715461, "2": 0.10644281655550003, "3": 0.0006779718678444624, "4": 0.19638413190841675, "5": 0.15360239148139954, "6": 0.00048374402103945613, "7": 0.00044157705269753933, "8": 0.00040617198101244867, "9": 0.00037602291558869183, "10": 0.00035004038363695145, "11": 0.23791924118995667, "12": 0.12358444929122925, "13": 0.00028993774321861565, "14": 0.0002742418146226555, "15": 0.08378947526216507, "16": 0.00024745010887272656, "17": 0.00023592586512677372, "18": 0.00022542726946994662, "19": 0.0002158232091460377}}, {"key": "li2017adversarial", "year": "2017", "title": "Adversarial Learning For Neural Dialogue Generation", "topic_distr": {"0": 0.001599961775355041, "1": 0.2092585265636444, "2": 0.0011037323856726289, "3": 0.0009559804457239807, "4": 0.09441694617271423, "5": 0.1042112335562706, "6": 0.2918994426727295, "7": 0.060947977006435394, "8": 0.0005727297393605113, "9": 0.0005302175413817167, "10": 0.0004935804172419012, "11": 0.16751790046691895, "12": 0.0004336512938607484, "13": 0.00040883166366256773, "14": 0.00038669933564960957, "15": 0.06395886093378067, "16": 0.00034892125404439867, "17": 0.0003326712758280337, "18": 0.00031786758336238563, "19": 0.00030432522180490196}}, {"key": "li2017data", "year": "2017", "title": "Data Distillation For Controlling Specificity In Dialogue Generation", "topic_distr": {"0": 0.14041703939437866, "1": 0.06430761516094208, "2": 0.19711802899837494, "3": 0.0006968975067138672, "4": 0.0006146346568129957, "5": 0.05699685588479042, "6": 0.15622586011886597, "7": 0.09351508319377899, "8": 0.00041751115350052714, "9": 0.000386520434403792, "10": 0.000359812518581748, "11": 0.1522526741027832, "12": 0.0003161251079291105, "13": 0.1348756104707718, "14": 0.0002818978682626039, "15": 0.00026742086629383266, "16": 0.00025435819406993687, "17": 0.0002425122365821153, "18": 0.0002317205653525889, "19": 0.0002218483859905973}}, {"key": "li2018dialogue", "year": "2018", "title": "Dialogue Generation: From Imitation Learning To Inverse Reinforcement Learning", "topic_distr": {"0": 0.001599494949914515, "1": 0.1493561714887619, "2": 0.16755814850330353, "3": 0.0009560853941366076, "4": 0.0008432220201939344, "5": 0.05172370374202728, "6": 0.1802970916032791, "7": 0.12604039907455444, "8": 0.0005727865500375628, "9": 0.0005302701611071825, "10": 0.0004936293698847294, "11": 0.31712889671325684, "12": 0.00043369430932216346, "13": 0.0004088722344022244, "14": 0.00038673769449815154, "15": 0.0003668766003102064, "16": 0.0003489558584988117, "17": 0.0003327042795717716, "18": 0.0003178991028107703, "19": 0.0003043554024770856}}, {"key": "li2018hybrid", "year": "2018", "title": "Hybrid Retrieval-generation Reinforced Agent For Medical Image Report Generation", "topic_distr": {"0": 0.0013278394471853971, "1": 0.001083768205717206, "2": 0.17939059436321259, "3": 0.0007933047018013895, "4": 0.06508897244930267, "5": 0.0006257963832467794, "6": 0.0005660380702465773, "7": 0.133839949965477, "8": 0.00047526959679089487, "9": 0.00043999162153340876, "10": 0.00040958894533105195, "11": 0.15896806120872498, "12": 0.11001855134963989, "13": 0.00033926169271580875, "14": 0.00032089557498693466, "15": 0.14624406397342682, "16": 0.11811146885156631, "17": 0.00027606135699898005, "18": 0.08142797648906708, "19": 0.000252538884524256}}, {"key": "li2018syntactically", "year": "2018", "title": "A Syntactically Constrained Bidirectional-asynchronous Approach For Emotional Conversation Generation", "topic_distr": {"0": 0.002598515711724758, "1": 0.002121495082974434, "2": 0.25638189911842346, "3": 0.0015534977428615093, "4": 0.0013701232383027673, "5": 0.0012254734756425023, "6": 0.3203817307949066, "7": 0.31159213185310364, "8": 0.000930702721234411, "9": 0.09557982534170151, "10": 0.0008020827081054449, "11": 0.0007502423250116408, "12": 0.0007046961109153926, "13": 0.0006643634987995028, "14": 0.000628397858235985, "15": 0.0005961261922493577, "16": 0.0005670072860084474, "17": 0.000540600623935461, "18": 0.0005165441543795168, "19": 0.0004945374093949795}}, {"key": "li2018visual", "year": "2018", "title": "Visual Question Answering As Reading Comprehension", "topic_distr": {"0": 0.0011657122522592545, "1": 0.0009518328588455915, "2": 0.32694292068481445, "3": 0.10387216508388519, "4": 0.0006146436790004373, "5": 0.0005497532547451556, "6": 0.0004972564638592303, "7": 0.00045391166349872947, "8": 0.0904989242553711, "9": 0.00038652640068903565, "10": 0.00035981807741336524, "11": 0.00033656222512945533, "12": 0.00031612999737262726, "13": 0.00029803658253513277, "14": 0.0002819022338371724, "15": 0.0002674249990377575, "16": 0.06957967579364777, "17": 0.0002425159909762442, "18": 0.40216243267059326, "19": 0.0002218518202425912}}, {"key": "li2019incremental", "year": "2019", "title": "Incremental Transformer With Deliberation Decoder For Document Grounded Conversations", "topic_distr": {"0": 0.12605376541614532, "1": 0.00139512843452394, "2": 0.0011793693993240595, "3": 0.0010214790236204863, "4": 0.0009009033674374223, "5": 0.0008057911763899028, "6": 0.4154684543609619, "7": 0.0006653128657490015, "8": 0.14136072993278503, "9": 0.000566544127650559, "10": 0.18926122784614563, "11": 0.0004933100426569581, "12": 0.0004633618809748441, "13": 0.00043684180127456784, "14": 0.0004131931345909834, "15": 0.000391973415389657, "16": 0.11810233443975449, "17": 0.0003554634749889374, "18": 0.00033964551403187215, "19": 0.0003251753223594278}}, {"key": "li2019multiresolution", "year": "2019", "title": "Empdg: Multiresolution Interactive Empathetic Dialogue Generation", "topic_distr": {"0": 0.0017102748388424516, "1": 0.03975214064121246, "2": 0.0011793591547757387, "3": 0.0010214769281446934, "4": 0.22639575600624084, "5": 0.09600874781608582, "6": 0.409847617149353, "7": 0.0006653121090494096, "8": 0.0006119682220742106, "9": 0.2186882197856903, "10": 0.0005273962742649019, "11": 0.0004933095187880099, "12": 0.0004633613571058959, "13": 0.0004368413065094501, "14": 0.0004131926689296961, "15": 0.0003919729497283697, "16": 0.00037282632547430694, "17": 0.000355463067535311, "18": 0.0003396451356820762, "19": 0.00032517494400963187}}, {"key": "li2019pretrained", "year": "2019", "title": "Pretrained Language Models For Document-level Neural Machine Translation", "topic_distr": {"0": 0.0015401181299239397, "1": 0.0012574681313708425, "2": 0.2756507694721222, "3": 0.0009206016547977924, "4": 0.0008119292324408889, "5": 0.0007262103608809412, "6": 0.15593519806861877, "7": 0.014140023849904537, "8": 0.0005515302764251828, "9": 0.0005105916643515229, "10": 0.09545116871595383, "11": 0.00044459025957621634, "12": 0.0004175997746642679, "13": 0.09188763797283173, "14": 0.29827767610549927, "15": 0.00035326171200722456, "16": 0.00033600599272176623, "17": 0.000320357532473281, "18": 0.0003061017778236419, "19": 0.06016112491488457}}, {"key": "li2019reinforcement", "year": "2019", "title": "Reinforcement Learning Based Emotional Editing Constraint Conversation Generation", "topic_distr": {"0": 0.05044541880488396, "1": 0.0014146191533654928, "2": 0.0011958843097090721, "3": 0.00103577203117311, "4": 0.13106223940849304, "5": 0.0008170642540790141, "6": 0.34253931045532227, "7": 0.16962793469429016, "8": 0.0006205307436175644, "9": 0.0005744703812524676, "10": 0.0005347754922695458, "11": 0.2162792831659317, "12": 0.08118069916963577, "13": 0.00044295346015132964, "14": 0.0004189739120192826, "15": 0.0003974573337472975, "16": 0.0003780428087338805, "17": 0.00036043659201823175, "18": 0.0003443973255343735, "19": 0.0003297247167211026}}, {"key": "li2019robust", "year": "2019", "title": "Robust Navigation With Language Pretraining And Stochastic Sampling", "topic_distr": {"0": 0.0014853425091132522, "1": 0.0012125290231779218, "2": 0.3845946788787842, "3": 0.0008877146756276488, "4": 0.0007829282549209893, "5": 0.029225340113043785, "6": 0.0006334003992378712, "7": 0.07406748086214066, "8": 0.0005318298353813589, "9": 0.000492353574372828, "10": 0.0004583327390719205, "11": 0.39402297139167786, "12": 0.07694104313850403, "13": 0.0003796360979322344, "14": 0.0003590842825360596, "15": 0.00034064333885908127, "16": 0.0003240040095988661, "17": 0.00030891448841430247, "18": 0.00029516793438233435, "19": 0.03265656158328056}}, {"key": "li2019say", "year": "2019", "title": "Don't Say That! Making Inconsistent Dialogue Unlikely With Unlikelihood Training", "topic_distr": {"0": 0.1954352706670761, "1": 0.056762050837278366, "2": 0.32698315382003784, "3": 0.0009207098628394306, "4": 0.0008120224811136723, "5": 0.046180613338947296, "6": 0.034478507936000824, "7": 0.10036824643611908, "8": 0.0005515938973985612, "9": 0.0005106505705043674, "10": 0.07606873661279678, "11": 0.11584935337305069, "12": 0.0004176479415036738, "13": 0.00039374426705762744, "14": 0.00037242870894260705, "15": 0.0426395945250988, "16": 0.0003360447590239346, "17": 0.0003203944943379611, "18": 0.0003061370807699859, "19": 0.00029309449018910527}}, {"key": "li2019simple", "year": "2019", "title": "Visualbert: A Simple And Performant Baseline For Vision And Language", "topic_distr": {"0": 0.0021892462391406298, "1": 0.0017875003395602107, "2": 0.27238914370536804, "3": 0.0013082859804853797, "4": 0.0011538541875779629, "5": 0.02347581461071968, "6": 0.0009334868518635631, "7": 0.0008521168492734432, "8": 0.0007837951998226345, "9": 0.0007256161770783365, "10": 0.18532902002334595, "11": 0.000631819711998105, "12": 0.0005934627843089402, "13": 0.0005594965186901391, "14": 0.0005292078712955117, "15": 0.0005020301905460656, "16": 0.0004775075940415263, "17": 0.00045526912435889244, "18": 0.5049068331718445, "19": 0.00041647677426226437}}, {"key": "li2019story", "year": "2019", "title": "Story Ending Prediction By Transferable BERT", "topic_distr": {"0": 0.0012487899512052536, "1": 0.085304394364357, "2": 0.2800069749355316, "3": 0.0007457821629941463, "4": 0.0006577461608685553, "5": 0.0005883047706447542, "6": 0.0005321266362443566, "7": 0.06745002418756485, "8": 0.0004467960970941931, "9": 0.014926009811460972, "10": 0.2454252690076828, "11": 0.024474777281284332, "12": 0.00033829864696599543, "13": 0.00031893645063973963, "14": 0.14101935923099518, "15": 0.04905357584357262, "16": 0.08671794086694717, "17": 0.00025952246505767107, "18": 0.0002479738323017955, "19": 0.0002374092146055773}}, {"key": "li2019unicoder", "year": "2019", "title": "Unicoder-vl: A Universal Encoder For Vision And Language By Cross-modal Pre-training", "topic_distr": {"0": 0.0019220111425966024, "1": 0.0015667119296267629, "2": 0.10895545780658722, "3": 0.00114721548743546, "4": 0.001011794083751738, "5": 0.0009049754007719457, "6": 0.0008185577462427318, "7": 0.0007472058641724288, "8": 0.0006872958620078862, "9": 0.0006362797576002777, "10": 0.3585769534111023, "11": 0.0005540313431993127, "12": 0.0005203968612477183, "13": 0.0004906124086119235, "14": 0.0004640528350137174, "15": 0.0004402211925480515, "16": 0.0004187177983112633, "17": 0.00039921727147884667, "18": 0.4926733672618866, "19": 0.027064967900514603}}, {"key": "li2020bridging", "year": "2020", "title": "Bridging Text And Video: A Universal Multimodal Transformer For Video-audio Scene-aware Dialog", "topic_distr": {"0": 0.0023082750849425793, "1": 0.0018856959650292993, "2": 0.0015942961908876896, "3": 0.0013808420626446605, "4": 0.11621005833148956, "5": 0.0010892704594880342, "6": 0.23023931682109833, "7": 0.07372012734413147, "8": 0.0008272611885331571, "9": 0.0007658558315597475, "10": 0.11115953326225281, "11": 0.0006668578134849668, "12": 0.0006263737450353801, "13": 0.0005905238213017583, "14": 0.0005585555336438119, "15": 0.0005298706237226725, "16": 0.0005039881216362119, "17": 0.00048051640624180436, "18": 0.454423189163208, "19": 0.00043957281741313636}}, {"key": "li2020closer", "year": "2020", "title": "A Closer Look At The Robustness Of Vision-and-language Pre-trained Models", "topic_distr": {"0": 0.001145131653174758, "1": 0.20649771392345428, "2": 0.12214609235525131, "3": 0.21784372627735138, "4": 0.0006033736863173544, "5": 0.0005396733758971095, "6": 0.00048813901958055794, "7": 0.01499722059816122, "8": 0.0004098622302990407, "9": 0.0003794392687268555, "10": 0.09206465631723404, "11": 0.00033039122354239225, "12": 0.2069336175918579, "13": 0.0002925719600170851, "14": 0.00027673342265188694, "15": 0.00026252164389006793, "16": 0.00024969829246401787, "17": 0.00023806934768799692, "18": 0.1340835690498352, "19": 0.0002177840651711449}}, {"key": "li2020comparison", "year": "2020", "title": "A Comparison Of Pre-trained Vision-and-language Models For Multimodal Representation Learning Across Medical Images And Reports", "topic_distr": {"0": 0.0018101099412888288, "1": 0.0014758995966985822, "2": 0.170399472117424, "3": 0.0010806926293298602, "4": 0.0009531292598694563, "5": 0.000852503813803196, "6": 0.000771096907556057, "7": 0.0007038820185698569, "8": 0.03200865909457207, "9": 0.0005993875092826784, "10": 0.1091012954711914, "11": 0.000521907932125032, "12": 0.2198374718427658, "13": 0.03598656505346298, "14": 0.00043714651837944984, "15": 0.09417750686407089, "16": 0.00039444005233235657, "17": 0.000376070209313184, "18": 0.32816874980926514, "19": 0.00034402619348838925}}, {"key": "li2020contextualized", "year": "2020", "title": "Contextualized Perturbation For Textual Adversarial Attack", "topic_distr": {"0": 0.001663067378103733, "1": 0.3564358353614807, "2": 0.0011480373796075583, "3": 0.048685137182474136, "4": 0.0008769611595198512, "5": 0.00078437669435516, "6": 0.07487726956605911, "7": 0.29436400532722473, "8": 0.0005957056418992579, "9": 0.0005514880176633596, "10": 0.1352524608373642, "11": 0.00048020013491623104, "12": 0.00045104784658178687, "13": 0.0004252325452398509, "14": 0.00040221234667114913, "15": 0.00038155654328875244, "16": 0.0003629187121987343, "17": 0.0003460168663877994, "18": 0.0003306192811578512, "19": 0.0815858542919159}}, {"key": "li2020efficient", "year": "2020", "title": "Efficient Transformer-based Large Scale Language Representations Using Hardware-friendly Block Structured Pruning", "topic_distr": {"0": 0.033730022609233856, "1": 0.0010952599113807082, "2": 0.25261130928993225, "3": 0.000801866059191525, "4": 0.0007072130683809519, "5": 0.0006325491704046726, "6": 0.0005721461493521929, "7": 0.0005222734180279076, "8": 0.0004803981864824891, "9": 0.06608040630817413, "10": 0.22955864667892456, "11": 0.00038725047488696873, "12": 0.00036374101182445884, "13": 0.3706073760986328, "14": 0.0003243583196308464, "15": 0.0003077007713727653, "16": 0.04041656106710434, "17": 0.0002790403086692095, "18": 0.00026662315940484405, "19": 0.0002552639925852418}}, {"key": "li2020empirical", "year": "2020", "title": "An Empirical Investigation Of Pre-trained Transformer Language Models For Open-domain Dialogue Generation", "topic_distr": {"0": 0.0015788744203746319, "1": 0.0012892312370240688, "2": 0.0010898198233917356, "3": 0.0009439071291126311, "4": 0.0008324856753461063, "5": 0.09861063957214355, "6": 0.3403930962085724, "7": 0.10759606212377548, "8": 0.0005654940032400191, "9": 0.0005235188873484731, "10": 0.06055945158004761, "11": 0.00045584645704366267, "12": 0.06254777312278748, "13": 0.09676895290613174, "14": 0.0003818138793576509, "15": 0.22457575798034668, "16": 0.0003445130423642695, "17": 0.00032846839167177677, "18": 0.00031385169131681323, "19": 0.0003004804311785847}}, {"key": "li2020mapping", "year": "2020", "title": "Mapping Natural Language Instructions To Mobile UI Action Sequences", "topic_distr": {"0": 0.001783337676897645, "1": 0.10343481600284576, "2": 0.17218151688575745, "3": 0.0010652919299900532, "4": 0.0009395446977578104, "5": 0.1817072629928589, "6": 0.000760104798246175, "7": 0.0006938480655662715, "8": 0.0006382162100635469, "9": 0.0005908431485295296, "10": 0.07117784023284912, "11": 0.38994231820106506, "12": 0.00048323540249839425, "13": 0.00045557788689620793, "14": 0.00043091492261737585, "15": 0.00040878509753383696, "16": 0.0003888172213919461, "17": 0.0003707092546392232, "18": 0.07220792770385742, "19": 0.00033912205253727734}}, {"key": "li2020multilingual", "year": "2020", "title": "Multilingual Speech Translation With Efficient Finetuning Of Pretrained Models", "topic_distr": {"0": 0.0014668239746242762, "1": 0.07174918800592422, "2": 0.0010128788417205215, "3": 0.0008772243745625019, "4": 0.0007736739353276789, "5": 0.0006919946754351258, "6": 0.0006259149522520602, "7": 0.035024773329496384, "8": 0.0005255447467789054, "9": 0.0004865349910687655, "10": 0.00045291625428944826, "11": 0.0004236432723701, "12": 0.0003979244502261281, "13": 0.19151897728443146, "14": 0.4049919843673706, "15": 0.00033661769703030586, "16": 0.0003201749932486564, "17": 0.00030526379123330116, "18": 0.10635600984096527, "19": 0.18166188895702362}}, {"key": "li2020object", "year": "2020", "title": "Oscar: Object-semantics Aligned Pre-training For Vision-language Tasks", "topic_distr": {"0": 0.0021161912009119987, "1": 0.0017263420158997178, "2": 0.22343795001506805, "3": 0.0012639344204217196, "4": 0.0011147389886900783, "5": 0.0009970520623028278, "6": 0.0009018417913466692, "7": 0.059315167367458344, "8": 0.0007572246249765158, "9": 0.0007010179106146097, "10": 0.0006525787757709622, "11": 0.0006104011554270983, "12": 0.0005733445286750793, "13": 0.0005405296687968075, "14": 0.0005112678045406938, "15": 0.058082833886146545, "16": 0.00046132015995681286, "17": 0.00043983556679449975, "18": 0.6453940868377686, "19": 0.0004023582732770592}}, {"key": "li2020organizing", "year": "2020", "title": "Optimus: Organizing Sentences Via Pre-trained Modeling Of A Latent Space", "topic_distr": {"0": 0.00166221521794796, "1": 0.02089010551571846, "2": 0.0011479954700917006, "3": 0.0009943173499777913, "4": 0.0008769466076046228, "5": 0.0007843630737625062, "6": 0.15738996863365173, "7": 0.000647620705422014, "8": 0.0005956953391432762, "9": 0.0704873725771904, "10": 0.4306843876838684, "11": 0.00048019184032455087, "12": 0.00045104004675522447, "13": 0.0004252251819707453, "14": 0.00040220539085567, "15": 0.31072431802749634, "16": 0.0003629124548751861, "17": 0.00034601090010255575, "18": 0.0003306135768070817, "19": 0.00031652816687710583}}, {"key": "li2020towards", "year": "2020", "title": "UNIMO: Towards Unified-modal Understanding And Generation Via Cross-modal Contrastive Learning", "topic_distr": {"0": 0.0014839184004813433, "1": 0.2032788097858429, "2": 0.0010248440084978938, "3": 0.0008876478532329202, "4": 0.0007828700472600758, "5": 0.0007002194179221988, "6": 0.0006333543569780886, "7": 0.0005781461950391531, "8": 0.0005317911854945123, "9": 0.0004923177766613662, "10": 0.000458299444289878, "11": 0.0004286785260774195, "12": 0.0004026540264021605, "13": 0.0003796085075009614, "14": 0.0003590582055039704, "15": 0.09670548141002655, "16": 0.14249202609062195, "17": 0.0003088920493610203, "18": 0.5477887988090515, "19": 0.0002825721458066255}}, {"key": "li2020train", "year": "2020", "title": "Train Large, Then Compress: Rethinking Model Size For Efficient Training And Inference Of Transformers", "topic_distr": {"0": 0.0012605221709236503, "1": 0.001028798520565033, "2": 0.2265762984752655, "3": 0.0007532464805990458, "4": 0.0006643307860940695, "5": 0.0005941950366832316, "6": 0.0005374544416554272, "7": 0.0004906057147309184, "8": 0.0004512695886660367, "9": 0.00041777308797463775, "10": 0.0994022935628891, "11": 0.03001478873193264, "12": 0.00034168583806604147, "13": 0.5867751240730286, "14": 0.033392492681741714, "15": 0.00028904355713166296, "16": 0.0002749247069004923, "17": 0.00026212091324850917, "18": 0.000250456650974229, "19": 0.016222599893808365}}, {"key": "li2020unqovering", "year": "2020", "title": "Unqovering Stereotyping Biases Via Underspecified Questions", "topic_distr": {"0": 0.596942126750946, "1": 0.0014763160143047571, "2": 0.0012477709678933024, "3": 0.11249624937772751, "4": 0.0009531701216474175, "5": 0.0008525376906618476, "6": 0.0007711273501627147, "7": 0.0007039099000394344, "8": 0.17036166787147522, "9": 0.0005994112580083311, "10": 0.07897748053073883, "11": 0.0005219285958446562, "12": 0.0004902430227957666, "13": 0.0312802717089653, "14": 0.0004371638351585716, "15": 0.0004147130821365863, "16": 0.00039445568108931184, "17": 0.0003760850813705474, "18": 0.0003593494766391814, "19": 0.000344039814081043}}, {"key": "li2020unsupervised", "year": "2020", "title": "Unsupervised Vision-and-language Pre-training Without Parallel Images And Captions", "topic_distr": {"0": 0.0017343214713037014, "1": 0.09460745006799698, "2": 0.21392987668514252, "3": 0.0010357252322137356, "4": 0.0009134623687714338, "5": 0.000817024614661932, "6": 0.0007390055689029396, "7": 0.0006745880818925798, "8": 0.0006205004756338894, "9": 0.0005744423833675683, "10": 0.0005347494152374566, "11": 0.0005001873360015452, "12": 0.0004698216507676989, "13": 0.030752034857869148, "14": 0.3311917185783386, "15": 0.00039743795059621334, "16": 0.00037802435690537095, "17": 0.0003604190133046359, "18": 0.31943953037261963, "19": 0.00032970862230286}}, {"key": "li2020widget", "year": "2020", "title": "Widget Captioning: Generating Natural Language Description For Mobile User Interface Elements", "topic_distr": {"0": 0.10830608010292053, "1": 0.0013058686163276434, "2": 0.001103825168684125, "3": 0.0009560397593304515, "4": 0.0008431882597506046, "5": 0.274527907371521, "6": 0.0006821519345976412, "7": 0.04647725820541382, "8": 0.0005727636744268239, "9": 0.00053024897351861, "10": 0.0004936096956953406, "11": 0.0004617065715137869, "12": 0.0004336769925430417, "13": 0.0004088559071533382, "14": 0.00038672226946800947, "15": 0.0003668619610834867, "16": 0.017114458605647087, "17": 0.00033269100822508335, "18": 0.4976792633533478, "19": 0.04701683670282364}}, {"key": "li2020zero", "year": "2020", "title": "Zero-resource Knowledge-grounded Dialogue Generation", "topic_distr": {"0": 0.0015601252671331167, "1": 0.10832315683364868, "2": 0.001076256507076323, "3": 0.0009321689140051603, "4": 0.000822130125015974, "5": 0.10359750688076019, "6": 0.31561094522476196, "7": 0.0609997920691967, "8": 0.0005584597238339484, "9": 0.0005170067306607962, "10": 0.00048128244816325605, "11": 0.0004501760995481163, "12": 0.000422846496803686, "13": 0.08397938311100006, "14": 0.00037706439616158605, "15": 0.00035770010435953736, "16": 0.12838563323020935, "17": 0.1909417062997818, "18": 0.00030994764529168606, "19": 0.0002967426844406873}}, {"key": "li2021adversarial", "year": "2021", "title": "Adversarial VQA: A New Benchmark For Evaluating The Robustness Of VQA Models", "topic_distr": {"0": 0.001248241518624127, "1": 0.3426567614078522, "2": 0.0008609510259702802, "3": 0.26906806230545044, "4": 0.0006576701998710632, "5": 0.0005882378900423646, "6": 0.0005320661002770066, "7": 0.0004856870509684086, "8": 0.02114124409854412, "9": 0.00041358458111062646, "10": 0.000385006598662585, "11": 0.0003601227654144168, "12": 0.17152535915374756, "13": 0.00031890018726699054, "14": 0.0003016363480128348, "15": 0.000286145688733086, "16": 0.00027216837042942643, "17": 0.00025949295377358794, "18": 0.18840128183364868, "19": 0.00023738222080282867}}, {"key": "li2021align", "year": "2021", "title": "Align And Prompt: Video-and-language Pre-training With Entity Prompts", "topic_distr": {"0": 0.0012725734850391746, "1": 0.0010393199045211077, "2": 0.0008784920210018754, "3": 0.0007608764572069049, "4": 0.0006710630841553211, "5": 0.0006002161535434425, "6": 0.0005429006414487958, "7": 0.0004955771146342158, "8": 0.0004558423825073987, "9": 0.00042200644384138286, "10": 0.10942995548248291, "11": 0.0003674559702631086, "12": 0.00034514820436015725, "13": 0.034083109349012375, "14": 0.0003077785950154066, "15": 0.0002919724793173373, "16": 0.0002777105546556413, "17": 0.3157268464565277, "18": 0.5317889451980591, "19": 0.00024221604689955711}}, {"key": "li2021contrast", "year": "2021", "title": "Contrast And Generation Make BART A Good Dialogue Emotion Recognizer", "topic_distr": {"0": 0.0012614534934982657, "1": 0.0010288251796737313, "2": 0.21988768875598907, "3": 0.0007532852469012141, "4": 0.0006643658853136003, "5": 0.0005942262359894812, "6": 0.27941662073135376, "7": 0.10102950036525726, "8": 0.00045129304635338485, "9": 0.1666010171175003, "10": 0.00038892586599104106, "11": 0.0003637887130025774, "12": 0.0003417035914026201, "13": 0.000322146515827626, "14": 0.0003047069476451725, "15": 0.00028905857470817864, "16": 0.06769724935293198, "17": 0.15811389684677124, "18": 0.00025046966038644314, "19": 0.00023979871184565127}}, {"key": "li2021dialogue", "year": "2021", "title": "Dialogue History Matters! Personalized Response Selectionin Multi-turn Retrieval-based Chatbots", "topic_distr": {"0": 0.0012729879235848784, "1": 0.0010391288669779897, "2": 0.13604651391506195, "3": 0.0007608724990859628, "4": 0.359744668006897, "5": 0.07839427143335342, "6": 0.24674218893051147, "7": 0.0004955730400979519, "8": 0.0004558386281132698, "9": 0.00042200295138172805, "10": 0.0003928432706743479, "11": 0.0003674529434647411, "12": 0.0003451453521847725, "13": 0.00032539130188524723, "14": 0.00030777606298215687, "15": 0.00029197006369940937, "16": 0.17183542251586914, "17": 0.0002647748333401978, "18": 0.00025299249682575464, "19": 0.00024221405328717083}}, {"key": "li2021few", "year": "2021", "title": "Few-shot Knowledge Graph-to-text Generation With Pretrained Language Models", "topic_distr": {"0": 0.002011597389355302, "1": 0.001642573275603354, "2": 0.0013886309461668134, "3": 0.0012027386110275984, "4": 0.0010607661679387093, "5": 0.0009487763163633645, "6": 0.04485952481627464, "7": 0.0007833707495592535, "8": 0.0007205610745586455, "9": 0.044447701424360275, "10": 0.07161686569452286, "11": 0.0005808465066365898, "12": 0.0005455841310322285, "13": 0.0005143581074662507, "14": 0.0004865130758844316, "15": 0.25944721698760986, "16": 0.34501081705093384, "17": 0.19961273670196533, "18": 0.00039991462836042047, "19": 0.0227188803255558}}, {"key": "li2021grounded", "year": "2021", "title": "Grounded Language-image Pre-training", "topic_distr": {"0": 0.0017566034803166986, "1": 0.0014346386305987835, "2": 0.12987728416919708, "3": 0.0010502338409423828, "4": 0.0009262616513296962, "5": 0.0008284729556180537, "6": 0.0007493607117794454, "7": 0.0006840405403636396, "8": 0.0006291950703598559, "9": 0.0005824916297569871, "10": 0.0005422424292191863, "11": 0.0005071960622444749, "12": 0.00047640487900935113, "13": 0.0004491383151616901, "14": 0.0004248239565640688, "15": 0.0004030069394502789, "16": 0.0003833213122561574, "17": 0.08702828735113144, "18": 0.7709327340126038, "19": 0.00033432856434956193}}, {"key": "li2021personalized", "year": "2021", "title": "Personalized Transformer For Explainable Recommendation", "topic_distr": {"0": 0.09534697234630585, "1": 0.0011191812809556723, "2": 0.000946167332585901, "3": 0.06014680489897728, "4": 0.32255879044532776, "5": 0.06154749542474747, "6": 0.0005847261054441333, "7": 0.09600314497947693, "8": 0.0004909608396701515, "9": 0.0004545181291177869, "10": 0.23232340812683105, "11": 0.0003957650624215603, "12": 0.015814997255802155, "13": 0.08183512091636658, "14": 0.00033149009686894715, "15": 0.0003144662769045681, "16": 0.028967449441552162, "17": 0.00028517565806396306, "18": 0.00027248545666225255, "19": 0.00026087654987350106}}, {"key": "li2021prefix", "year": "2021", "title": "Prefix-tuning: Optimizing Continuous Prompts For Generation", "topic_distr": {"0": 0.07717272639274597, "1": 0.001726861810311675, "2": 0.0823298767209053, "3": 0.001264016143977642, "4": 0.0011148146586492658, "5": 0.0009971170220524073, "6": 0.0009019008139148355, "7": 0.18360164761543274, "8": 0.000757274217903614, "9": 0.0007010637782514095, "10": 0.0006526214419864118, "11": 0.0006104410858824849, "12": 0.0005733820144087076, "13": 0.2428823858499527, "14": 0.000511301273945719, "15": 0.0004850431578233838, "16": 0.0004613503406289965, "17": 0.40243348479270935, "18": 0.00042029059841297567, "19": 0.00040238461224362254}}, {"key": "li2021pretrained", "year": "2021", "title": "Pretrained Language Models For Text Generation: A Survey", "topic_distr": {"0": 0.03777572512626648, "1": 0.0012274833861738443, "2": 0.001037317793816328, "3": 0.0008984717424027622, "4": 0.0007924162200652063, "5": 0.0007087576086632907, "6": 0.0006410770583897829, "7": 0.3376562297344208, "8": 0.0005382755189202726, "9": 0.000498320790939033, "10": 0.00046388767077587545, "11": 0.0004339055740274489, "12": 0.4602073132991791, "13": 0.0003842372098006308, "14": 0.0003634363238234073, "15": 0.0003447718918323517, "16": 0.00032793087302707136, "17": 0.1317228078842163, "18": 0.00029874531901441514, "19": 0.02367887832224369}}, {"key": "li2021scheduled", "year": "2021", "title": "Scheduled Sampling In Vision-language Pretraining With Decoupled Encoder-decoder Network", "topic_distr": {"0": 0.0016629464225843549, "1": 0.0013579619117081165, "2": 0.001148036913946271, "3": 0.18456286191940308, "4": 0.0008769863052293658, "5": 0.0007843995117582381, "6": 0.000709496031049639, "7": 0.20272165536880493, "8": 0.0005957229295745492, "9": 0.0005515040247701108, "10": 0.35135218501091003, "11": 0.00048021410475485027, "12": 0.00045106097240932286, "13": 0.000425244914367795, "14": 0.00040222404641099274, "15": 0.0003815676609519869, "16": 0.0003629292768891901, "17": 0.0003460269363131374, "18": 0.09736768901348114, "19": 0.15345929563045502}}, {"key": "li2021stability", "year": "2021", "title": "The Stability-efficiency Dilemma: Investigating Sequence Length Warmup For Training GPT Models", "topic_distr": {"0": 0.07915972173213959, "1": 0.000743524287827313, "2": 0.27530166506767273, "3": 0.0005442824331112206, "4": 0.0004800347378477454, "5": 0.00042935553938150406, "6": 0.0003883557510562241, "7": 0.0003545036306604743, "8": 0.0003260799858253449, "9": 0.0003018759307451546, "10": 0.13495060801506042, "11": 0.08224286139011383, "12": 0.0002468965540174395, "13": 0.42335888743400574, "14": 0.00022016477305442095, "15": 0.00020885810954496264, "16": 0.0001986560528166592, "17": 0.00018940425070468336, "18": 0.00018097585416398942, "19": 0.0001732655946398154}}, {"key": "li2021structural", "year": "2021", "title": "Structurallm: Structural Pre-training For Form Understanding", "topic_distr": {"0": 0.002353658201172948, "1": 0.0019212615443393588, "2": 0.0016242628917098045, "3": 0.0014068169984966516, "4": 0.0012407570611685514, "5": 0.001109764794819057, "6": 0.0010037916945293546, "7": 0.0009162932983599603, "8": 0.11034004390239716, "9": 0.00078026537084952, "10": 0.4813445508480072, "11": 0.0006794047076255083, "12": 0.000638158933725208, "13": 0.0006016345578245819, "14": 0.0005690647521987557, "15": 0.0005398401408456266, "16": 0.21936993300914764, "17": 0.000489557336550206, "18": 0.17262306809425354, "19": 0.0004478433693293482}}, {"key": "li2021supervision", "year": "2021", "title": "Supervision Exists Everywhere: A Data Efficient Contrastive Language-image Pre-training Paradigm", "topic_distr": {"0": 0.0014177362900227308, "1": 0.02891336940228939, "2": 0.0009784443536773324, "3": 0.0008474525529891253, "4": 0.0007474161102436483, "5": 0.0006685079424642026, "6": 0.0006046711350791156, "7": 0.0005519632250070572, "8": 0.0005077075329609215, "9": 0.0795300304889679, "10": 0.00043754404759965837, "11": 0.0004092646122444421, "12": 0.000384418701287359, "13": 0.09883368015289307, "14": 0.00034279722603969276, "15": 0.00032519272645004094, "16": 0.07727956026792526, "17": 0.19381144642829895, "18": 0.513139009475708, "19": 0.0002697750460356474}}, {"key": "li2021text", "year": "2021", "title": "Text Compression-aided Transformer Encoding", "topic_distr": {"0": 0.0010391157120466232, "1": 0.0008486407459713519, "2": 0.33836373686790466, "3": 0.000621393381152302, "4": 0.0005480440449900925, "5": 0.000490184931550175, "6": 0.0004433763970155269, "7": 0.00040472825639881194, "8": 0.0003722776600625366, "9": 0.0003446444752626121, "10": 0.2681884169578552, "11": 0.0003000941651407629, "12": 0.0002818758657667786, "13": 0.07198071479797363, "14": 0.00025135683245025575, "15": 0.14621202647686005, "16": 0.16868868470191956, "17": 0.0002162382734240964, "18": 0.0002066157612716779, "19": 0.0001978131476789713}}, {"key": "li2021token", "year": "2021", "title": "Terapipe: Token-level Pipeline Parallelism For Training Large-scale Language Models", "topic_distr": {"0": 0.0682206079363823, "1": 0.0016165855340659618, "2": 0.21089880168437958, "3": 0.10211321711540222, "4": 0.001043941592797637, "5": 0.000933728413656354, "6": 0.0008445652783848345, "7": 0.0007709463243372738, "8": 0.0007091328734531999, "9": 0.0006564958021044731, "10": 0.09639480710029602, "11": 0.0005716342129744589, "12": 0.0005369310383684933, "13": 0.5121413469314575, "14": 0.00047879686462692916, "15": 0.0004542080278042704, "16": 0.0004320214211475104, "17": 0.0004119013319723308, "18": 0.00039357191417366266, "19": 0.00037680426612496376}}, {"key": "li2022accelerating", "year": "2022", "title": "Accelerating Attention Through Gradient-based Learned Runtime Pruning", "topic_distr": {"0": 0.0013862422201782465, "1": 0.0011318346951156855, "2": 0.5463882684707642, "3": 0.048874981701374054, "4": 0.022087475284934044, "5": 0.0006537167355418205, "6": 0.0005912923370487988, "7": 0.0005397506174631417, "8": 0.0004964740946888924, "9": 0.0004596221842803061, "10": 0.13720883429050446, "11": 0.00040020933374762535, "12": 0.0003759131650440395, "13": 0.23762191832065582, "14": 0.0003352125931996852, "15": 0.00031799759017303586, "16": 0.0003024644101969898, "17": 0.00028837803984060884, "18": 0.0002755453751888126, "19": 0.00026380608323961496}}, {"key": "li2022benchmark", "year": "2022", "title": "ELEVATER: A Benchmark And Toolkit For Evaluating Language-augmented Visual Models", "topic_distr": {"0": 0.0014349397970363498, "1": 0.0011708057718351483, "2": 0.000989648629911244, "3": 0.11358413100242615, "4": 0.0007559860241599381, "5": 0.0006761731347069144, "6": 0.0006116043077781796, "7": 0.0005582920857705176, "8": 0.0005135289393365383, "9": 0.00047541107051074505, "10": 0.10859213024377823, "11": 0.00041395725565962493, "12": 0.20734134316444397, "13": 0.050712790340185165, "14": 0.00034672775655053556, "15": 0.09318321198225021, "16": 0.02457481436431408, "17": 0.07541389018297195, "18": 0.2799302041530609, "19": 0.03872041031718254}}, {"key": "li2022bootstrapping", "year": "2022", "title": "BLIP: Bootstrapping Language-image Pre-training For Unified Vision-language Understanding And Generation", "topic_distr": {"0": 0.0017561858985573053, "1": 0.06833142042160034, "2": 0.001212680828757584, "3": 0.0010503435041755438, "4": 0.0009263567044399679, "5": 0.0008285579388029873, "6": 0.000749437662307173, "7": 0.0006841107388027012, "8": 0.0006292596226558089, "9": 0.0005825514090247452, "10": 0.0005422980757430196, "11": 0.0005072481581009924, "12": 0.0004764538025483489, "13": 0.09044881165027618, "14": 0.14337241649627686, "15": 0.05586627498269081, "16": 0.0003833606606349349, "17": 0.06914176046848297, "18": 0.4849012792110443, "19": 0.07760924845933914}}, {"key": "li2022clinical", "year": "2022", "title": "Clinical-longformer And Clinical-bigbird: Transformers For Long Clinical Sequences", "topic_distr": {"0": 0.001235711039043963, "1": 0.0010084952227771282, "2": 0.14136619865894318, "3": 0.0007383397314697504, "4": 0.0006511835381388664, "5": 0.0005824352265335619, "6": 0.0005268176319077611, "7": 0.00048089606571011245, "8": 0.02857135236263275, "9": 0.00040950486436486244, "10": 0.5091354846954346, "11": 0.00035657038097269833, "12": 0.000334923475747928, "13": 0.13598434627056122, "14": 0.0002986609179060906, "15": 0.0819568932056427, "16": 0.0956246629357338, "17": 0.0002569332136772573, "18": 0.0002454998029861599, "19": 0.00023504059936385602}}, {"key": "li2022competition", "year": "2022", "title": "Competition-level Code Generation With Alphacode", "topic_distr": {"0": 0.0378270260989666, "1": 0.0008705185609869659, "2": 0.1248069480061531, "3": 0.5202834606170654, "4": 0.03573506325483322, "5": 0.0005027953302487731, "6": 0.1717625856399536, "7": 0.00041514020995236933, "8": 0.00038185479934327304, "9": 0.05679873377084732, "10": 0.0003290837339591235, "11": 0.04835336655378342, "12": 0.00028912731795571744, "13": 0.0002725794038269669, "14": 0.00025782317970879376, "15": 0.00024458253756165504, "16": 0.00023263545881491154, "17": 0.00022180116502568126, "18": 0.00021193112479522824, "19": 0.00020290205429773778}}, {"key": "li2022contrastive", "year": "2022", "title": "Contrastive Decoding: Open-ended Text Generation As Optimization", "topic_distr": {"0": 0.10971027612686157, "1": 0.0168721042573452, "2": 0.0009159610490314662, "3": 0.000793322513345629, "4": 0.0006996767478995025, "5": 0.0006258094217628241, "6": 0.0005660500028170645, "7": 0.5097110867500305, "8": 0.0004752795794047415, "9": 0.000440000876551494, "10": 0.00040959756006486714, "11": 0.0003831243666354567, "12": 0.00035986537113785744, "13": 0.16978779435157776, "14": 0.0003209023270756006, "15": 0.02426016330718994, "16": 0.00028955217567272484, "17": 0.0002760671777650714, "18": 0.0002637823054101318, "19": 0.16283957660198212}}, {"key": "li2022diffusion", "year": "2022", "title": "Diffusion-lm Improves Controllable Text Generation", "topic_distr": {"0": 0.0015990224201232195, "1": 0.0013056888710707426, "2": 0.1725562959909439, "3": 0.0009560289327055216, "4": 0.0008431750466115773, "5": 0.0007541574304923415, "6": 0.07210978865623474, "7": 0.4320214092731476, "8": 0.0005727551761083305, "9": 0.0005302411154843867, "10": 0.0004936023615300655, "11": 0.277848482131958, "12": 0.0004336705314926803, "13": 0.00040884982445277274, "14": 0.00038671650690957904, "15": 0.00036685651866719127, "16": 0.00034893673728220165, "17": 0.0003326860605739057, "18": 0.00031788169872015715, "19": 0.03581368550658226}}, {"key": "li2022effective", "year": "2022", "title": "Mplug: Effective And Efficient Vision-language Learning By Cross-modal Skip-connections", "topic_distr": {"0": 0.0016414885176345706, "1": 0.0013399595627561212, "2": 0.0011327683459967375, "3": 0.000981134595349431, "4": 0.0008653229451738298, "5": 0.0007739666616544127, "6": 0.0007000592886470258, "7": 0.0006390366470441222, "8": 0.04792911559343338, "9": 0.06400352716445923, "10": 0.1457986682653427, "11": 0.00047382700722664595, "12": 0.00044506159611046314, "13": 0.16831538081169128, "14": 0.00039687423850409687, "15": 0.08763176202774048, "16": 0.0003581021155696362, "17": 0.1082019954919815, "18": 0.36805960536003113, "19": 0.00031233267509378493}}, {"key": "li2022explanations", "year": "2022", "title": "Explanations From Large Language Models Make Small Reasoners Better", "topic_distr": {"0": 0.0014183385064825416, "1": 0.0011574822710826993, "2": 0.0009783778805285692, "3": 0.4782041907310486, "4": 0.0007473700097762048, "5": 0.13713254034519196, "6": 0.0006046333000995219, "7": 0.0712113007903099, "8": 0.0005076757515780628, "9": 0.020922504365444183, "10": 0.00043751668999902904, "11": 0.05601400136947632, "12": 0.00038439466152340174, "13": 0.11927817761898041, "14": 0.0003427758056204766, "15": 0.0003251723828725517, "16": 0.00030928876367397606, "17": 0.10947272926568985, "18": 0.00028176233172416687, "19": 0.00026975819491781294}}, {"key": "li2022fine", "year": "2022", "title": "Fine-grained Semantically Aligned Vision-language Pre-training", "topic_distr": {"0": 0.0014351473655551672, "1": 0.054760269820690155, "2": 0.0813433900475502, "3": 0.0008571235230192542, "4": 0.0007559478981420398, "5": 0.0006761388503946364, "6": 0.0006115733413025737, "7": 0.0005582637968473136, "8": 0.00051350292051211, "9": 0.00047538700164295733, "10": 0.10884567350149155, "11": 0.0004139363009016961, "12": 0.09040772169828415, "13": 0.0003665538097266108, "14": 0.00034671020694077015, "15": 0.0003289047454018146, "16": 0.00031283879070542753, "17": 0.00029826926765963435, "18": 0.6564197540283203, "19": 0.00027285449323244393}}, {"key": "li2022library", "year": "2022", "title": "LAVIS: A Library For Language-vision Intelligence", "topic_distr": {"0": 0.0016847065417096019, "1": 0.0013765572803094983, "2": 0.0011635851114988327, "3": 0.001007813261821866, "4": 0.0008888502488844097, "5": 0.022752882912755013, "6": 0.000719092960935086, "7": 0.0006564111681655049, "8": 0.04189925268292427, "9": 0.1117066964507103, "10": 0.044249679893255234, "11": 0.00048670973046682775, "12": 0.5504713654518127, "13": 0.00043099699541926384, "14": 0.00040766471647657454, "15": 0.0003867289051413536, "16": 0.00036783842369914055, "17": 0.026229092851281166, "18": 0.19279320538043976, "19": 0.00032082456164062023}}, {"key": "li2022making", "year": "2022", "title": "Making Large Language Models Better Reasoners With Step-aware Verifier", "topic_distr": {"0": 0.0013558779610320926, "1": 0.001107115764170885, "2": 0.11121690273284912, "3": 0.7559700012207031, "4": 0.0007148734293878078, "5": 0.0006394014926627278, "6": 0.0005783441010862589, "7": 0.0005279311444610357, "8": 0.04164562001824379, "9": 0.0004495573230087757, "10": 0.000418493669712916, "11": 0.06637100875377655, "12": 0.000367681379429996, "13": 0.016892891377210617, "14": 0.00032787208328954875, "15": 0.000311034033074975, "16": 0.00029584101866930723, "17": 0.0002820631198119372, "18": 0.00026951145264320076, "19": 0.00025802923482842743}}, {"key": "li2022personalized", "year": "2022", "title": "Personalized Prompt Learning For Explainable Recommendation", "topic_distr": {"0": 0.07380302250385284, "1": 0.0008491334156133235, "2": 0.30359092354774475, "3": 0.0006215020548552275, "4": 0.2630939483642578, "5": 0.05344494804739952, "6": 0.04998588189482689, "7": 0.00040479807648807764, "8": 0.0003723418922163546, "9": 0.00034470396349206567, "10": 0.00032088550506159663, "11": 0.00030014594085514545, "12": 0.0002819244982674718, "13": 0.0002657888107933104, "14": 0.0002514001971576363, "15": 0.0002384894178248942, "16": 0.00022683996940031648, "17": 0.25119882822036743, "18": 0.0002066514134639874, "19": 0.00019784728647209704}}, {"key": "li2022scaling", "year": "2022", "title": "Scaling Language-image Pre-training Via Masking", "topic_distr": {"0": 0.02184649556875229, "1": 0.09075451642274857, "2": 0.32717666029930115, "3": 0.001065290649421513, "4": 0.0009395423694513738, "5": 0.0008403501706197858, "6": 0.0007601038669236004, "7": 0.0006938472506590188, "8": 0.000638215453363955, "9": 0.0005908424500375986, "10": 0.0005500162369571626, "11": 0.0005144674214534461, "12": 0.04788205400109291, "13": 0.3063569962978363, "14": 0.00043091439874842763, "15": 0.0004087846027687192, "16": 0.00038881675573065877, "17": 0.0003707087889779359, "18": 0.19745229184627533, "19": 0.00033912164508365095}}, {"key": "li2022survey", "year": "2022", "title": "A Survey On Retrieval-augmented Text Generation", "topic_distr": {"0": 0.026643039658665657, "1": 0.0016696567181497812, "2": 0.07663077116012573, "3": 0.0012225399259477854, "4": 0.06893454492092133, "5": 0.0009643970406614244, "6": 0.11854641139507294, "7": 0.28393426537513733, "8": 0.0007324241450987756, "9": 0.000678058248013258, "10": 0.0006312055629678071, "11": 0.0005904093850404024, "12": 0.3425983786582947, "13": 0.0005228263325989246, "14": 0.07356462627649307, "15": 0.00046912638936191797, "16": 0.00044621105189435184, "17": 0.00042543013114482164, "18": 0.0004064986715093255, "19": 0.00038918029167689383}}, {"key": "li2022uni", "year": "2022", "title": "Uni-perceiver V2: A Generalist Model For Large-scale Vision And Vision-language Tasks", "topic_distr": {"0": 0.0014013313921168447, "1": 0.00114450603723526, "2": 0.0009674544562585652, "3": 0.2371339499950409, "4": 0.0007390081300400198, "5": 0.0006609874544665217, "6": 0.0005978686385788023, "7": 0.0742519274353981, "8": 0.0005019958480261266, "9": 0.0004647340683732182, "10": 0.09623288363218307, "11": 0.00040466044447384775, "12": 0.0003800940467044711, "13": 0.000358339719241485, "14": 0.0003389407938811928, "15": 0.00032153434585779905, "16": 0.0003058284055441618, "17": 0.07116258889436722, "18": 0.5123646259307861, "19": 0.00026674012769944966}}, {"key": "li2022vision", "year": "2022", "title": "Vision-language Intelligence: Tasks, Representation Learning, And Large Models", "topic_distr": {"0": 0.0013264023000374436, "1": 0.04961119964718819, "2": 0.1422998160123825, "3": 0.0007932560984045267, "4": 0.0006996191805228591, "5": 0.0006257577915675938, "6": 0.0005660032038576901, "7": 0.0005166659830138087, "8": 0.00047524034744128585, "9": 0.07269351184368134, "10": 0.0004095637414138764, "11": 0.0003830927307717502, "12": 0.4254941940307617, "13": 0.00033924082526937127, "14": 0.000320875842589885, "15": 0.0003043971082661301, "16": 0.05124833807349205, "17": 0.0002760443603619933, "18": 0.2513642907142639, "19": 0.0002525233430787921}}, {"key": "li2023api", "year": "2023", "title": "Api-bank: A Comprehensive Benchmark For Tool-augmented Llms", "topic_distr": {"0": 0.001154277240857482, "1": 0.0009430792997591197, "2": 0.0007971070008352399, "3": 0.6988187432289124, "4": 0.0006089101079851389, "5": 0.037894077599048615, "6": 0.0004926178953610361, "7": 0.0004496774636209011, "8": 0.10724295675754547, "9": 0.00038292078534141183, "10": 0.00035646159085445106, "11": 0.0003334227076265961, "12": 0.14874471724033356, "13": 0.0002952564391307533, "14": 0.0002792725572362542, "15": 0.00026493039331398904, "16": 0.0002519893751014024, "17": 0.00024025373568292707, "18": 0.00022956255997996777, "19": 0.00021978233417030424}}, {"key": "li2023blip", "year": "2023", "title": "BLIP-2: Bootstrapping Language-image Pre-training With Frozen Image Encoders And Large Language Models", "topic_distr": {"0": 0.001889255945570767, "1": 0.001543050049804151, "2": 0.0013043490471318364, "3": 0.0011297593591734767, "4": 0.0009964002529159188, "5": 0.0008912063203752041, "6": 0.0008061037515290082, "7": 0.0007358374423347414, "8": 0.0006768389139324427, "9": 0.0006265990086831152, "10": 0.1007026880979538, "11": 0.04316491261124611, "12": 0.0005124791641719639, "13": 0.298145592212677, "14": 0.000456992449471727, "15": 0.07149192690849304, "16": 0.00041234714444726706, "17": 0.17491942644119263, "18": 0.2992345690727234, "19": 0.00035964458948001266}}, {"key": "li2023comparative", "year": "2023", "title": "A Comparative Study Of Pretrained Language Models For Long Clinical Text", "topic_distr": {"0": 0.0743987113237381, "1": 0.0008780878270044923, "2": 0.0007422376074828207, "3": 0.0006428757915273309, "4": 0.0005669877864420414, "5": 0.0005071288323961198, "6": 0.0004587023286148906, "7": 0.0004187182348687202, "8": 0.02377709187567234, "9": 0.0003565576043911278, "10": 0.5125138759613037, "11": 0.0003104673232883215, "12": 0.00029161927523091435, "13": 0.209509015083313, "14": 0.0002600453153718263, "15": 0.09567884355783463, "16": 0.07804693281650543, "17": 0.00022371283557731658, "18": 0.00021375772485043854, "19": 0.00020465083071030676}}, {"key": "li2023comprehensive", "year": "2023", "title": "Mvbench: A Comprehensive Multi-modal Video Understanding Benchmark", "topic_distr": {"0": 0.15884138643741608, "1": 0.0008561118156649172, "2": 0.0007235342054627836, "3": 0.13255921006202698, "4": 0.04454802721738815, "5": 0.0004943462554365396, "6": 0.0004471403663046658, "7": 0.00040816410910338163, "8": 0.010563421994447708, "9": 0.00034757028333842754, "10": 0.00032355374423787, "11": 0.00030264173983596265, "12": 0.07570283114910126, "13": 0.0002679989265743643, "14": 0.00025349066709168255, "15": 0.06863538920879364, "16": 0.00022872620320413262, "17": 0.00021807398297823966, "18": 0.5040789246559143, "19": 0.00019949243869632483}}, {"key": "li2023dark", "year": "2023", "title": "The Dark Side Of Chatgpt: Legal And Ethical Challenges From Stochastic Parrots And Hallucination", "topic_distr": {"0": 0.3115551769733429, "1": 0.002037066500633955, "2": 0.001721852459013462, "3": 0.0014913203194737434, "4": 0.0013152736937627196, "5": 0.0011764141963794827, "6": 0.00106407655403018, "7": 0.0009713233448565006, "8": 0.0008934438810683787, "9": 0.6717602610588074, "10": 0.0007699729176238179, "11": 0.0007202078704722226, "12": 0.0006764850113540888, "13": 0.0006377670215442777, "14": 0.0006032412056811154, "15": 0.0005722614587284625, "16": 0.0005443082773126662, "17": 0.0005189587827771902, "18": 0.0004958653589710593, "19": 0.00047473961603827775}}, {"key": "li2023empowering", "year": "2023", "title": "Empowering Molecule Discovery For Molecule-caption Translation With Large Language Models: A Chatgpt Perspective", "topic_distr": {"0": 0.0009243700187653303, "1": 0.0007545549306087196, "2": 0.0006377598620019853, "3": 0.3029300272464752, "4": 0.00048716962919570506, "5": 0.00043573734001256526, "6": 0.00039412808837369084, "7": 0.00035977279185317457, "8": 0.00033092667581513524, "9": 0.19920748472213745, "10": 0.0002851937315426767, "11": 0.0002667610242497176, "12": 0.00025056631420738995, "13": 0.06294272094964981, "14": 0.07341990619897842, "15": 0.09992142766714096, "16": 0.09148866683244705, "17": 0.13267013430595398, "18": 0.03211692348122597, "19": 0.00017584093438927084}}, {"key": "li2023evaluating", "year": "2023", "title": "Evaluating Object Hallucination In Large Vision-language Models", "topic_distr": {"0": 0.3316439986228943, "1": 0.0009699429501779377, "2": 0.0008198912255465984, "3": 0.19783921539783478, "4": 0.0006263180403038859, "5": 0.0005601953016594052, "6": 0.0005067014135420322, "7": 0.07780224084854126, "8": 0.0004254480008967221, "9": 0.0003938681329600513, "10": 0.00036665250081568956, "11": 0.0003429549396969378, "12": 0.0003221346123609692, "13": 0.0003036975394934416, "14": 0.00028725669835694134, "15": 0.0002725045196712017, "16": 0.00025919353356584907, "17": 0.0002471223706379533, "18": 0.3857845664024353, "19": 0.00022606570564676076}}, {"key": "li2023few", "year": "2023", "title": "Few-shot In-context Learning For Knowledge Base Question Answering", "topic_distr": {"0": 0.0013869600370526314, "1": 0.0011317107127979398, "2": 0.0009566197404637933, "3": 0.35722190141677856, "4": 0.04740633815526962, "5": 0.0006535896682180464, "6": 0.0005911774351261556, "7": 0.0005396457272581756, "8": 0.1496739238500595, "9": 0.0004595328646246344, "10": 0.0004277799162082374, "11": 0.11868976801633835, "12": 0.06703182309865952, "13": 0.00035432924050837755, "14": 0.00033514745882712305, "15": 0.0003179358027409762, "16": 0.20494168996810913, "17": 0.0002883220149669796, "18": 0.047328025102615356, "19": 0.00026375483139418066}}, {"key": "li2023flexible", "year": "2023", "title": "Flexkbqa: A Flexible Llm-powered Framework For Few-shot Knowledge Base Question Answering", "topic_distr": {"0": 0.024413442239165306, "1": 0.15582172572612762, "2": 0.0006473539979197085, "3": 0.3754538595676422, "4": 0.06393430382013321, "5": 0.00044230037019588053, "6": 0.0004000644257757813, "7": 0.00036519166314974427, "8": 0.1012164056301117, "9": 0.00031097730970941484, "10": 0.00028948928229510784, "11": 0.00027077895356342196, "12": 0.00025434032431803644, "13": 0.10713221877813339, "14": 0.00022680260008201003, "15": 0.000215155043406412, "16": 0.16804549098014832, "17": 0.00019511465507093817, "18": 0.0001864321529865265, "19": 0.00017848944116849452}}, {"key": "li2023graph", "year": "2023", "title": "Graph Transformer For Recommendation", "topic_distr": {"0": 0.07857660204172134, "1": 0.13591451942920685, "2": 0.0011328257387503982, "3": 0.000981162884272635, "4": 0.24907852709293365, "5": 0.0007739808061160147, "6": 0.0007000722689554095, "7": 0.0006390484631992877, "8": 0.0005878103547729552, "9": 0.0005441787652671337, "10": 0.22498929500579834, "11": 0.023118259385228157, "12": 0.00044506980339065194, "13": 0.00041959667578339577, "14": 0.00039688157266937196, "15": 0.05318611115217209, "16": 0.22753608226776123, "17": 0.0003414308885112405, "18": 0.00032623737934045494, "19": 0.00031233843765221536}}, {"key": "li2023graphix", "year": "2023", "title": "Graphix-t5: Mixing Pre-trained Transformers With Graph-aware Layers For Text-to-sql Parsing", "topic_distr": {"0": 0.01592610590159893, "1": 0.000969988526776433, "2": 0.5083349943161011, "3": 0.0007102416711859405, "4": 0.0006264011026360095, "5": 0.04887780919671059, "6": 0.0005067680031061172, "7": 0.00046259412192739546, "8": 0.024714039638638496, "9": 0.00039391990867443383, "10": 0.0833471268415451, "11": 0.0003430000215303153, "12": 0.05845912918448448, "13": 0.06717942655086517, "14": 0.0002872944751288742, "15": 0.00027254034648649395, "16": 0.18787918984889984, "17": 0.000247154850512743, "18": 0.00023615658574271947, "19": 0.0002260954206576571}}, {"key": "li2023guiding", "year": "2023", "title": "Guiding Large Language Models Via Directional Stimulus Prompting", "topic_distr": {"0": 0.0010222652927041054, "1": 0.0008350099669769406, "2": 0.0007056613685563207, "3": 0.40817490220069885, "4": 0.15600843727588654, "5": 0.023549793288111687, "6": 0.00043610474676825106, "7": 0.10975991189479828, "8": 0.00036617202567867935, "9": 0.00033899207483045757, "10": 0.0003155682934448123, "11": 0.057710614055395126, "12": 0.0002772528969217092, "13": 0.0002613845863379538, "14": 0.00024723439128138125, "15": 0.0002345375542063266, "16": 0.00022308113693725318, "17": 0.2391352653503418, "18": 0.00020322711498010904, "19": 0.00019456887093838304}}, {"key": "li2023inference", "year": "2023", "title": "Inference-time Intervention: Eliciting Truthful Answers From A Language Model", "topic_distr": {"0": 0.161323681473732, "1": 0.11879837512969971, "2": 0.24666430056095123, "3": 0.1945933699607849, "4": 0.001060795271769166, "5": 0.0009488025680184364, "6": 0.000858199957292527, "7": 0.01648220233619213, "8": 0.0007205811562016606, "9": 0.0006670943112112582, "10": 0.0006209992570802569, "11": 0.03686845302581787, "12": 0.08598168194293976, "13": 0.13182304799556732, "14": 0.000486526609165594, "15": 0.00046154079609550536, "16": 0.00043899600859731436, "17": 0.00041855109157040715, "18": 0.00039992574602365494, "19": 0.00038288740324787796}}, {"key": "li2023label", "year": "2023", "title": "Label Supervised Llama Finetuning", "topic_distr": {"0": 0.000878250109963119, "1": 0.0007172705372795463, "2": 0.0006063215550966561, "3": 0.3504349887371063, "4": 0.00046315239160321653, "5": 0.0004142556572332978, "6": 0.05445389077067375, "7": 0.018935102969408035, "8": 0.0003146120870951563, "9": 0.032588858157396317, "10": 0.1406068503856659, "11": 0.00025360978906974196, "12": 0.0002382134844083339, "13": 0.08062798529863358, "14": 0.00021242181537672877, "15": 0.00020151279750280082, "16": 0.0204604659229517, "17": 0.23018625378608704, "18": 0.0001746111229294911, "19": 0.06723134219646454}}, {"key": "li2023llama", "year": "2023", "title": "Llama-vid: An Image Is Worth 2 Tokens In Large Language Models", "topic_distr": {"0": 0.0013856278965249658, "1": 0.0011316528543829918, "2": 0.08940694481134415, "3": 0.0008285715593956411, "4": 0.05270490050315857, "5": 0.0006536156870424747, "6": 0.0005912008928135037, "7": 0.0005396671476773918, "8": 0.0004963973187841475, "9": 0.00045955111272633076, "10": 0.12729227542877197, "11": 0.0004001474299002439, "12": 0.00037585501559078693, "13": 0.09668850898742676, "14": 0.0003351607592776418, "15": 0.000317948404699564, "16": 0.0003024176403414458, "17": 0.0002883334527723491, "18": 0.6255374550819397, "19": 0.0002637652796693146}}, {"key": "li2023llava", "year": "2023", "title": "Llava-med: Training A Large Language-and-vision Assistant For Biomedicine In One Day", "topic_distr": {"0": 0.0011044879211112857, "1": 0.04863511770963669, "2": 0.0007619375246576965, "3": 0.12339290231466293, "4": 0.0005820395308546722, "5": 0.0005205906927585602, "6": 0.12481233477592468, "7": 0.00042983322055079043, "8": 0.057291146367788315, "9": 0.06081920117139816, "10": 0.0003407309704925865, "11": 0.0003187087713740766, "12": 0.042126357555389404, "13": 0.06313815712928772, "14": 0.0002669482782948762, "15": 0.18397262692451477, "16": 0.00024086910707410425, "17": 0.00022965135576669127, "18": 0.29080629348754883, "19": 0.00021008335170336068}}, {"key": "li2023masked", "year": "2023", "title": "Masked Vision And Language Pre-training With Unimodal And Multimodal Contrastive Losses For Medical Visual Question Answering", "topic_distr": {"0": 0.001145323272794485, "1": 0.0009343848214484751, "2": 0.000789858924690634, "3": 0.0006841056165285408, "4": 0.0006033519748598337, "5": 0.0005396536435000598, "6": 0.00048812132445164025, "7": 0.0004455728339962661, "8": 0.08120165765285492, "9": 0.0003794255026150495, "10": 0.10667552053928375, "11": 0.0003303792327642441, "12": 0.13150092959403992, "13": 0.06277255713939667, "14": 0.00027672338183037937, "15": 0.0002625121269375086, "16": 0.0002496892411727458, "17": 0.06210384517908096, "18": 0.5290469527244568, "19": 0.019569408148527145}}, {"key": "li2023may", "year": "2023", "title": "Starcoder: May The Source Be With You!", "topic_distr": {"0": 0.09065563231706619, "1": 0.0011706899385899305, "2": 0.14018169045448303, "3": 0.23356640338897705, "4": 0.0007559604127891362, "5": 0.0006761504919268191, "6": 0.20872025191783905, "7": 0.0005582734593190253, "8": 0.0005135118262842298, "9": 0.1087685227394104, "10": 0.00044254621025174856, "11": 0.00041394346044398844, "12": 0.14819973707199097, "13": 0.06353212147951126, "14": 0.00034671620232984424, "15": 0.00032891042064875364, "16": 0.0003128442040178925, "17": 0.0002982744190376252, "18": 0.0002850013552233577, "19": 0.0002728592080529779}}, {"key": "li2023measuring", "year": "2023", "title": "CMMLU: Measuring Massive Multitask Language Understanding In Chinese", "topic_distr": {"0": 0.07597428560256958, "1": 0.0011705834185704589, "2": 0.000989603460766375, "3": 0.46036356687545776, "4": 0.0007559467339888215, "5": 0.0006761386175639927, "6": 0.0006115731666795909, "7": 0.0005582636804319918, "8": 0.0005135028040967882, "9": 0.0004753868852276355, "10": 0.0004425384395290166, "11": 0.00041393618448637426, "12": 0.3825368285179138, "13": 0.00036655369331128895, "14": 0.0003467101196292788, "15": 0.0003289046580903232, "16": 0.00031283870339393616, "17": 0.07260499894618988, "18": 0.0002849963493645191, "19": 0.000272854435024783}}, {"key": "li2023medical", "year": "2023", "title": "Chatdoctor: A Medical Chat Model Fine-tuned On A Large Language Model Meta-ai (llama) Using Medical Domain Knowledge", "topic_distr": {"0": 0.057555876672267914, "1": 0.07164289057254791, "2": 0.0008199955336749554, "3": 0.0007102178642526269, "4": 0.08048148453235626, "5": 0.0005602514138445258, "6": 0.07288771122694016, "7": 0.00046257939538918436, "8": 0.03703128546476364, "9": 0.2041252851486206, "10": 0.0003666890552267432, "11": 0.000342989107593894, "12": 0.2301023006439209, "13": 0.11732763051986694, "14": 0.00028728533652611077, "15": 0.00027253167354501784, "16": 0.12431363761425018, "17": 0.0002471469924785197, "18": 0.0002361490624025464, "19": 0.00022608823201153427}}, {"key": "li2023mimic", "year": "2023", "title": "MIMIC-IT: Multi-modal In-context Instruction Tuning", "topic_distr": {"0": 0.025737592950463295, "1": 0.0010722517035901546, "2": 0.00090627814643085, "3": 0.27385371923446655, "4": 0.0006923075416125357, "5": 0.03641819581389427, "6": 0.08763450384140015, "7": 0.0005112653598189354, "8": 0.0004702727310359478, "9": 0.03879818320274353, "10": 0.0004052826261613518, "11": 0.12038490176200867, "12": 0.08921220153570175, "13": 0.0003356947854626924, "14": 0.0003175217716488987, "15": 0.0003012153028976172, "16": 0.00028650189051404595, "17": 0.00027315891929902136, "18": 0.32213905453681946, "19": 0.0002498837420716882}}, {"key": "li2023multimodal", "year": "2023", "title": "Multimodal Foundation Models: From Specialists To General-purpose Assistants", "topic_distr": {"0": 0.0014683224726468325, "1": 0.0011981341522186995, "2": 0.0010129074798896909, "3": 0.0008773068548180163, "4": 0.0007737477426417172, "5": 0.0006920597516000271, "6": 0.0006259739748202264, "7": 0.0005714091821573675, "8": 0.0005255942814983428, "9": 0.19830721616744995, "10": 0.0004529589496087283, "11": 0.00042368320282548666, "12": 0.34743326902389526, "13": 0.000375184987206012, "14": 0.000354874151526019, "15": 0.0003366494202055037, "16": 0.00032020517392084, "17": 0.03647233173251152, "18": 0.40749889612197876, "19": 0.0002792793675325811}}, {"key": "li2023privacy", "year": "2023", "title": "Privacy In Large Language Models: Attacks, Defenses And Future Directions", "topic_distr": {"0": 0.07581141591072083, "1": 0.12045364826917648, "2": 0.00104990741237998, "3": 0.19200268387794495, "4": 0.0008020325913093984, "5": 0.0007173590129241347, "6": 0.0006488573271781206, "7": 0.000592297816183418, "8": 0.0005448081064969301, "9": 0.3545958697795868, "10": 0.00046951748663559556, "11": 0.00043917150469496846, "12": 0.2495264708995819, "13": 0.0003889004001393914, "14": 0.00036784703843295574, "15": 0.0003489560913294554, "16": 0.00033191070542670786, "17": 0.00031645296257920563, "18": 0.0003023709577973932, "19": 0.00028948881663382053}}, {"key": "li2023revisiting", "year": "2023", "title": "Revisiting Large Language Models As Zero-shot Relation Extractors", "topic_distr": {"0": 0.0010483557125553489, "1": 0.0008560130372643471, "2": 0.0007234736112877727, "3": 0.3539498746395111, "4": 0.0005526569439098239, "5": 0.0004943109815940261, "6": 0.0004471084685064852, "7": 0.0004081350052729249, "8": 0.03282144293189049, "9": 0.025609781965613365, "10": 0.00032353069400414824, "11": 0.0003026201738975942, "12": 0.0002842484973371029, "13": 0.019224779680371284, "14": 0.0002534725936129689, "15": 0.00024045538157224655, "16": 0.00022870990505907685, "17": 0.5618232488632202, "18": 0.00020835493342019618, "19": 0.0001994782214751467}}, {"key": "li2023seed", "year": "2023", "title": "Seed-bench-2: Benchmarking Multimodal Large Language Models", "topic_distr": {"0": 0.06371912360191345, "1": 0.0008559409761801362, "2": 0.0007235013763420284, "3": 0.16432206332683563, "4": 0.0005526784807443619, "5": 0.000494329899083823, "6": 0.051866140216588974, "7": 0.0004081505467183888, "8": 0.00037542555946856737, "9": 0.09129327535629272, "10": 0.00032354300492443144, "11": 0.0003026316990144551, "12": 0.23727552592754364, "13": 0.00026799002080224454, "14": 0.0002534822269808501, "15": 0.0002404645347269252, "16": 0.0002287186071043834, "17": 0.00021806673612445593, "18": 0.38607946038246155, "19": 0.00019948581757489592}}, {"key": "li2023synthetic", "year": "2023", "title": "Synthetic Data Generation With Large Language Models For Text Classification: Potential And Limitations", "topic_distr": {"0": 0.16683295369148254, "1": 0.4356471598148346, "2": 0.0011478582164272666, "3": 0.28859880566596985, "4": 0.0008768399129621685, "5": 0.000784268428105861, "6": 0.0007093774620443583, "7": 0.0006475425907410681, "8": 0.0005956234526820481, "9": 0.0005514119402505457, "10": 0.0005133102531544864, "11": 0.0004801338945981115, "12": 0.0004509856225922704, "13": 0.025838105008006096, "14": 0.00040215684566646814, "15": 0.07456754893064499, "16": 0.0003628686536103487, "17": 0.00034596913610585034, "18": 0.0003305736754555255, "19": 0.0003164899826515466}}, {"key": "li2023textbooks", "year": "2023", "title": "Textbooks Are All You Need II: Phi-1.5 Technical Report", "topic_distr": {"0": 0.08995974808931351, "1": 0.12270797044038773, "2": 0.0009159602923318744, "3": 0.4287082254886627, "4": 0.0006996800075285137, "5": 0.0006258116336539388, "6": 0.0005660519236698747, "7": 0.058646705001592636, "8": 0.0004752812092192471, "9": 0.06857287883758545, "10": 0.00040959895704872906, "11": 0.0003831256472039968, "12": 0.0003598666226025671, "13": 0.22526180744171143, "14": 0.000320903433021158, "15": 0.0003044232726097107, "16": 0.00028955316520296037, "17": 0.000276068109087646, "18": 0.00026378320762887597, "19": 0.0002525450545363128}}, {"key": "li2023theory", "year": "2023", "title": "Theory Of Mind For Multi-agent Collaboration Via Large Language Models", "topic_distr": {"0": 0.3575730323791504, "1": 0.0014548322651535273, "2": 0.0012298942310735583, "3": 0.3483806252479553, "4": 0.0009394915541633964, "5": 0.000840305641759187, "6": 0.0007600632379762828, "7": 0.017855338752269745, "8": 0.0006381813436746597, "9": 0.0005908109014853835, "10": 0.0005499868420884013, "11": 0.23752053081989288, "12": 0.00048320900532417, "13": 0.02889120765030384, "14": 0.00043089137761853635, "15": 0.00040876277489587665, "16": 0.0003887960046995431, "17": 0.00037068899837322533, "18": 0.00035419350024312735, "19": 0.00033910354250110686}}, {"key": "li2024unsupervised", "year": "2024", "title": "Promptkd: Unsupervised Prompt Distillation For Vision-language Models", "topic_distr": {"0": 0.0008206888451240957, "1": 0.0006701845559291542, "2": 0.0005664826603606343, "3": 0.0004906409303657711, "4": 0.044931136071681976, "5": 0.00038704011240042746, "6": 0.0003500810416880995, "7": 0.0186996478587389, "8": 0.0002939428959507495, "9": 0.00027212430723011494, "10": 0.0002533209917601198, "11": 0.011040068231523037, "12": 0.00022256346710491925, "13": 0.25953954458236694, "14": 0.00019846625218633562, "15": 0.00018827393068931997, "16": 0.09111309051513672, "17": 0.2972002923488617, "18": 0.27260616421699524, "19": 0.00015618925681337714}}, {"key": "lialin2023scaling", "year": "2023", "title": "Scaling Down To Scale Up: A Guide To Parameter-efficient Fine-tuning", "topic_distr": {"0": 0.0017092340858653188, "1": 0.0013953640591353178, "2": 0.20439934730529785, "3": 0.0010215362999588251, "4": 0.04810227453708649, "5": 0.0008058315142989159, "6": 0.0007288813358172774, "7": 0.0006653463351540267, "8": 0.0006119997124187648, "9": 0.0005665726494044065, "10": 0.0005274233990348876, "11": 0.0004933348973281682, "12": 0.4622453451156616, "13": 0.2745291292667389, "14": 0.0004132139147259295, "15": 0.00039199311868287623, "16": 0.00037284550489857793, "17": 0.0003554813447408378, "18": 0.00033966259798035026, "19": 0.0003251916787121445}}, {"key": "lian2019learning", "year": "2019", "title": "Learning To Select Knowledge For Response Generation In Dialog Systems", "topic_distr": {"0": 0.052790317684412, "1": 0.001018447452224791, "2": 0.0008609752403572202, "3": 0.0007456987514160573, "4": 0.04700591415166855, "5": 0.0005882423720322549, "6": 0.5616834759712219, "7": 0.00048569057253189385, "8": 0.0004467485414352268, "9": 0.0004135875788051635, "10": 0.00038500939263030887, "11": 0.0003601253847591579, "12": 0.00033826264552772045, "13": 0.0717836245894432, "14": 0.00030163853080011904, "15": 0.0002861477551050484, "16": 0.2597612738609314, "17": 0.00025949484552256763, "18": 0.0002479474351275712, "19": 0.00023738393792882562}}, {"key": "lian2023llm", "year": "2023", "title": "Llm-grounded Diffusion: Enhancing Prompt Understanding Of Text-to-image Diffusion Models With Large Language Models", "topic_distr": {"0": 0.0011043910635635257, "1": 0.01510976068675518, "2": 0.000761976873036474, "3": 0.1993856132030487, "4": 0.034069567918777466, "5": 0.000520611647516489, "6": 0.00047089761937968433, "7": 0.11277130246162415, "8": 0.00039538563578389585, "9": 0.00036603721673600376, "10": 0.00034074464929290116, "11": 0.00031872157705947757, "12": 0.0002993724192492664, "13": 0.00028223812114447355, "14": 0.00026695901760831475, "15": 0.00025324919261038303, "16": 0.0002408787840977311, "17": 0.26322537660598755, "18": 0.3696068227291107, "19": 0.00021009179181419313}}, {"key": "liang2020new", "year": "2020", "title": "XGLUE: A New Benchmark Dataset For Cross-lingual Pre-training, Understanding And Generation", "topic_distr": {"0": 0.0021876501850783825, "1": 0.0017868326976895332, "2": 0.2210320234298706, "3": 0.001308130449615419, "4": 0.0011537183308973908, "5": 0.0010319161228835583, "6": 0.0009333766647614539, "7": 0.0008520162082277238, "8": 0.000783702649641782, "9": 0.0007255305536091328, "10": 0.06959161162376404, "11": 0.0006317451479844749, "12": 0.31758320331573486, "13": 0.0005594304529950023, "14": 0.24106909334659576, "15": 0.13698595762252808, "16": 0.0004774512199219316, "17": 0.00045521536958403885, "18": 0.0004349584924057126, "19": 0.00041642761789262295}}, {"key": "liang2020towards", "year": "2020", "title": "Mixkd: Towards Efficient Distillation Of Large-scale Language Models", "topic_distr": {"0": 0.11419736593961716, "1": 0.05709939822554588, "2": 0.3335847556591034, "3": 0.0006428546621464193, "4": 0.0005669709062203765, "5": 0.0005071128834970295, "6": 0.00045868780580349267, "7": 0.00041870499262586236, "8": 0.0003851337532978505, "9": 0.03626175969839096, "10": 0.00033190957037732005, "11": 0.0003104575152974576, "12": 0.00029161004931665957, "13": 0.2812105417251587, "14": 0.00026003707898780704, "15": 0.0002466827572789043, "16": 0.035562533885240555, "17": 0.1372450888156891, "18": 0.00021375095820985734, "19": 0.00020464435510803014}}, {"key": "liang2021mwp", "year": "2021", "title": "MWP-BERT: Numeracy-augmented Pre-training For Math Word Problem Solving", "topic_distr": {"0": 0.001418305211700499, "1": 0.001157334423623979, "2": 0.23214669525623322, "3": 0.3345629572868347, "4": 0.0007473842124454677, "5": 0.0006684800609946251, "6": 0.0006046457565389574, "7": 0.0005519401165656745, "8": 0.0005076862289570272, "9": 0.0004700020654127002, "10": 0.129611536860466, "11": 0.10792655497789383, "12": 0.0003844026068691164, "13": 0.08251569420099258, "14": 0.018409762531518936, "15": 0.015977319329977036, "16": 0.057078767567873, "17": 0.0002948906330857426, "18": 0.0002817681524902582, "19": 0.014683898538351059}}, {"key": "liang2022holistic", "year": "2022", "title": "Holistic Evaluation Of Language Models", "topic_distr": {"0": 0.12176526337862015, "1": 0.0008634259575046599, "2": 0.0007297311676666141, "3": 0.3354588449001312, "4": 0.10230915248394012, "5": 0.0004985800478607416, "6": 0.02587789297103882, "7": 0.0004116597992833704, "8": 0.0174937192350626, "9": 0.07555902004241943, "10": 0.00032632480724714696, "11": 0.0003052336978726089, "12": 0.26018351316452026, "13": 0.018612615764141083, "14": 0.0002556616673246026, "15": 0.0002425320417387411, "16": 0.00023068512382451445, "17": 0.00021994166309013963, "18": 0.00021015435049775988, "19": 0.03844606503844261}}, {"key": "liang2022visual", "year": "2022", "title": "Visual-language Navigation Pretraining Via Prompt-based Environmental Self-exploration", "topic_distr": {"0": 0.0012223687954246998, "1": 0.000998584320768714, "2": 0.0008440613746643066, "3": 0.0007310523651540279, "4": 0.0006447559571824968, "5": 0.0005766865215264261, "6": 0.0005216178251430392, "7": 0.0205769632011652, "8": 0.0004379724559839815, "9": 0.0004054629534948617, "10": 0.000377446151105687, "11": 0.4241851568222046, "12": 0.0003316177171654999, "13": 0.08628281950950623, "14": 0.000295713049126789, "15": 0.00028052658308297396, "16": 0.09484279155731201, "17": 0.1148911565542221, "18": 0.20226554572582245, "19": 0.049287714064121246}}, {"key": "liang2023can", "year": "2023", "title": "Can Large Language Models Provide Useful Feedback On Research Papers? A Large-scale Empirical Analysis", "topic_distr": {"0": 0.16646772623062134, "1": 0.00082804961130023, "2": 0.0006999628967605531, "3": 0.31651419401168823, "4": 0.20786266028881073, "5": 0.00047824159264564514, "6": 0.0004325735499151051, "7": 0.0003948670346289873, "8": 0.00036320710205473006, "9": 0.18146927654743195, "10": 0.0003130130935460329, "11": 0.00029278238071128726, "12": 0.0890234187245369, "13": 0.033555347472429276, "14": 0.0002452325134072453, "15": 0.00023263848561327904, "16": 0.00022127483680378646, "17": 0.00021096962154842913, "18": 0.00020158156985417008, "19": 0.00019299343694001436}}, {"key": "liang2023encouraging", "year": "2023", "title": "Encouraging Divergent Thinking In Large Language Models Through Multi-agent Debate", "topic_distr": {"0": 0.08432280272245407, "1": 0.0009014052920974791, "2": 0.03204477205872536, "3": 0.6883822679519653, "4": 0.0005820465739816427, "5": 0.0005205973866395652, "6": 0.000470884726382792, "7": 0.0004298386920709163, "8": 0.0003953747800551355, "9": 0.039810776710510254, "10": 0.00034073530696332455, "11": 0.11865049600601196, "12": 0.0002993642119690776, "13": 0.00028223037952557206, "14": 0.03141311556100845, "15": 0.00025324226589873433, "16": 0.00024087217752821743, "17": 0.00022965428070165217, "18": 0.00021943477622698992, "19": 0.0002100860292557627}}, {"key": "liang2023gpt", "year": "2023", "title": "GPT Detectors Are Biased Against Non-native English Writers", "topic_distr": {"0": 0.3325634300708771, "1": 0.28048020601272583, "2": 0.0009358691168017685, "3": 0.0008105673477984965, "4": 0.0007148850127123296, "5": 0.0006394122610799968, "6": 0.020115792751312256, "7": 0.0005279398756101727, "8": 0.00048561033327132463, "9": 0.22106042504310608, "10": 0.0004185006255283952, "11": 0.0003914519911631942, "12": 0.00036768746213056147, "13": 0.0003466432390268892, "14": 0.09097961336374283, "15": 0.0003110392135567963, "16": 0.0002958459372166544, "17": 0.04802751541137695, "18": 0.00026951590552926064, "19": 0.0002580335130915046}}, {"key": "liang2024monitoring", "year": "2024", "title": "Monitoring Ai-modified Content At Scale: A Case Study On The Impact Of Chatgpt On AI Conference Peer Reviews", "topic_distr": {"0": 0.28475356101989746, "1": 0.0011194002581760287, "2": 0.0009461455629207194, "3": 0.0008194849942810833, "4": 0.0007227500318549573, "5": 0.0006464467151090503, "6": 0.0005847165011800826, "7": 0.17128968238830566, "8": 0.0004909528070129454, "9": 0.3208465874195099, "10": 0.00042310479329898953, "11": 0.00039575857226736844, "12": 0.09251823276281357, "13": 0.06931290775537491, "14": 0.0003314846835564822, "15": 0.05368112400174141, "16": 0.0002991007058881223, "17": 0.0002851709723472595, "18": 0.00027248100377619267, "19": 0.0002608723007142544}}, {"key": "liao2019gpt", "year": "2019", "title": "Gpt-based Generation For Classical Chinese Poetry", "topic_distr": {"0": 0.10932352393865585, "1": 0.0015201224014163017, "2": 0.0012851320207118988, "3": 0.12948709726333618, "4": 0.0009816816309466958, "5": 0.0008780391653999686, "6": 0.0007941937656141818, "7": 0.3042353391647339, "8": 0.000666838779579848, "9": 0.0006173411384224892, "10": 0.0005746838869526982, "11": 0.0005375408218242228, "12": 0.0005049073952250183, "13": 0.00047600953257642686, "14": 0.0004502404772210866, "15": 0.30873462557792664, "16": 0.030934525653719902, "17": 0.000387334730476141, "18": 0.1072564348578453, "19": 0.0003543308994267136}}, {"key": "liao2023ai", "year": "2023", "title": "AI Transparency In The Age Of Llms: A Human-centered Research Roadmap", "topic_distr": {"0": 0.1917075663805008, "1": 0.0007599727250635624, "2": 0.000642533355858177, "3": 0.21797646582126617, "4": 0.0004908110131509602, "5": 0.03517045080661774, "6": 0.00039707394898869097, "7": 0.00036246186937205493, "8": 0.00033340012305416167, "9": 0.5499151945114136, "10": 0.0002873253542929888, "11": 0.0002687548694666475, "12": 0.0002524391165934503, "13": 0.00023799101472832263, "14": 0.00022510724375024438, "15": 0.00021354675118345767, "16": 0.0002031156764132902, "17": 0.00019365617481525987, "18": 0.0001850385742727667, "19": 0.00017715521971695125}}, {"key": "liao2023designerly", "year": "2023", "title": "Designerly Understanding: Information Needs For Model Transparency To Support Design Ideation For Ai-powered User Experience", "topic_distr": {"0": 0.17299649119377136, "1": 0.0012889873469248414, "2": 0.001089761033654213, "3": 0.19272251427173615, "4": 0.0008324766531586647, "5": 0.05440591648221016, "6": 0.0006734866183251143, "7": 0.0006147802923806012, "8": 0.000565488007850945, "9": 0.5710037350654602, "10": 0.0004873394500464201, "11": 0.00045584162580780685, "12": 0.00042816807399503887, "13": 0.0004036622995045036, "14": 0.00038180980482138693, "15": 0.00036220179754309356, "16": 0.0003445094043854624, "17": 0.00032846489921212196, "18": 0.00031384837348014116, "19": 0.00030047722975723445}}, {"key": "liao2023gpt", "year": "2023", "title": "GPT-4 Enhanced Multimodal Grounding For Autonomous Driving: Leveraging Cross-modal Attention With Large Language Models", "topic_distr": {"0": 0.04092568904161453, "1": 0.0474608838558197, "2": 0.12513770163059235, "3": 0.0005780858919024467, "4": 0.0005098462570458651, "5": 0.07844202220439911, "6": 0.0004124733677599579, "7": 0.00037651893217116594, "8": 0.0003463301109150052, "9": 0.16276495158672333, "10": 0.029989389702677727, "11": 0.0156512763351202, "12": 0.05124407261610031, "13": 0.08091779053211212, "14": 0.00023383738880511373, "15": 0.00022182856628205627, "16": 0.0002109929482685402, "17": 0.00020116659288760275, "18": 0.36419108510017395, "19": 0.00018402568821329623}}, {"key": "libovick\u00fd2017attention", "year": "2017", "title": "Attention Strategies For Multi-source Sequence-to-sequence Learning", "topic_distr": {"0": 0.002600592328235507, "1": 0.002121665980666876, "2": 0.4455975592136383, "3": 0.0015534752747043967, "4": 0.001370103913359344, "5": 0.001225456246174872, "6": 0.001108435564674437, "7": 0.11523981392383575, "8": 0.0009306895080953836, "9": 0.000861606968101114, "10": 0.0008020713576115668, "11": 0.0007502317312173545, "12": 0.09252515435218811, "13": 0.0006643541273660958, "14": 0.14852043986320496, "15": 0.0005961177521385252, "16": 0.057953834533691406, "17": 0.0005405929987318814, "18": 0.12454330176115036, "19": 0.0004945304244756699}}, {"key": "lieber2024hybrid", "year": "2024", "title": "Jamba: A Hybrid Transformer-mamba Language Model", "topic_distr": {"0": 0.001313213724642992, "1": 0.0231795534491539, "2": 0.2563129961490631, "3": 0.0007849989924579859, "4": 0.022134538739919662, "5": 0.0006192433647811413, "6": 0.0005601108423434198, "7": 0.0005112871876917779, "8": 0.0004702928417827934, "9": 0.0004353842814452946, "10": 0.2571243941783905, "11": 0.06313344091176987, "12": 0.0982820987701416, "13": 0.2505282759666443, "14": 0.00031753533403389156, "15": 0.0003012281667906791, "16": 0.023207319900393486, "17": 0.0002731705899350345, "18": 0.00026101464754901826, "19": 0.0002498944231774658}}, {"key": "liesenfeld2023opening", "year": "2023", "title": "Opening Up Chatgpt: Tracking Openness, Transparency, And Accountability In Instruction-tuned Text Generators", "topic_distr": {"0": 0.05858569219708443, "1": 0.2412111908197403, "2": 0.0009896536357700825, "3": 0.0008571766666136682, "4": 0.06421142816543579, "5": 0.015606689266860485, "6": 0.18220378458499908, "7": 0.0005582969170063734, "8": 0.0005135333631187677, "9": 0.2613905966281891, "10": 0.0004425648075994104, "11": 0.00041396086453460157, "12": 0.1264265477657318, "13": 0.04474420100450516, "14": 0.00034673078334890306, "15": 0.0003289242449682206, "16": 0.0003128573589492589, "17": 0.00029828696278855205, "18": 0.0002850133168976754, "19": 0.00027287067496217787}}, {"key": "lin2019constrained", "year": "2019", "title": "Commongen: A Constrained Text Generation Challenge For Generative Commonsense Reasoning", "topic_distr": {"0": 0.0013272966025397182, "1": 0.0010834649438038468, "2": 0.04706588387489319, "3": 0.1823670119047165, "4": 0.0006996779702603817, "5": 0.0006258100620470941, "6": 0.0005660504684783518, "7": 0.20561204850673676, "8": 0.08491583168506622, "9": 0.0004400012257974595, "10": 0.00040959788020700216, "11": 0.0524553582072258, "12": 0.07176519930362701, "13": 0.0003392691141925752, "14": 0.03600231930613518, "15": 0.0647919625043869, "16": 0.034517448395490646, "17": 0.158549502491951, "18": 0.056213729083538055, "19": 0.0002525443851482123}}, {"key": "lin2019empathetic", "year": "2019", "title": "Caire: An Empathetic Neural Chatbot", "topic_distr": {"0": 0.003461911343038082, "1": 0.002828798955306411, "2": 0.002391308778896928, "3": 0.0020711482502520084, "4": 0.0018266689730808139, "5": 0.13092541694641113, "6": 0.6897364854812622, "7": 0.0013489871053025126, "8": 0.0012408271431922913, "9": 0.07908931374549866, "10": 0.0010693490039557219, "11": 0.07772732526063919, "12": 0.0009395116358064115, "13": 0.000885739631485194, "14": 0.0008377896156162024, "15": 0.0007947645499370992, "16": 0.0007559428340755403, "17": 0.0007207370363175869, "18": 0.0006886646151542664, "19": 0.0006593248690478504}}, {"key": "lin2019personalizing", "year": "2019", "title": "Personalizing Dialogue Agents Via Meta-learning", "topic_distr": {"0": 0.10769771039485931, "1": 0.13877196609973907, "2": 0.001388760982081294, "3": 0.0012027961201965809, "4": 0.20160242915153503, "5": 0.2365579754114151, "6": 0.30575689673423767, "7": 0.0007834064308553934, "8": 0.0007205939036794007, "9": 0.0006671061855740845, "10": 0.0006210102583281696, "11": 0.0005808729911223054, "12": 0.0005456089274957776, "13": 0.0005143815651535988, "14": 0.0004865352238994092, "15": 0.0004615489742718637, "16": 0.0004390037793200463, "17": 0.0004185585130471736, "18": 0.0003999328473582864, "19": 0.0003828941844403744}}, {"key": "lin2020conversational", "year": "2020", "title": "Conversational Question Reformulation Via Sequence-to-sequence Architectures And Pretrained Language Models", "topic_distr": {"0": 0.002150400308892131, "1": 0.0017561216372996569, "2": 0.0014844193356111646, "3": 0.0012856887187808752, "4": 0.0011339237680658698, "5": 0.0010142115643247962, "6": 0.3338514268398285, "7": 0.02467242069542408, "8": 0.05486927926540375, "9": 0.0007130826124921441, "10": 0.15803353488445282, "11": 0.0006209062994457781, "12": 0.0005832118913531303, "13": 0.15521609783172607, "14": 0.000520066823810339, "15": 0.0004933585878461599, "16": 0.000469259568490088, "17": 0.16117995977401733, "18": 0.00042749589192681015, "19": 0.09952513873577118}}, {"key": "lin2020exploring", "year": "2020", "title": "Exploring Versatile Generative Language Model Via Parameter-efficient Transfer Learning", "topic_distr": {"0": 0.0031191809102892876, "1": 0.0025462235789746046, "2": 0.2352788895368576, "3": 0.0018643791554495692, "4": 0.05078980699181557, "5": 0.03331810235977173, "6": 0.001330263796262443, "7": 0.0012143075000494719, "8": 0.0011169458739459515, "9": 0.0010340380249544978, "10": 0.0009625877719372511, "11": 0.0009003735613077879, "12": 0.0008457130752503872, "13": 0.16265538334846497, "14": 0.0007541467202827334, "15": 0.2371228039264679, "16": 0.0006804713048040867, "17": 0.26325300335884094, "18": 0.0006199100171215832, "19": 0.0005934995133429766}}, {"key": "lin2020minimalist", "year": "2020", "title": "Mintl: Minimalist Transfer Learning For Task-oriented Dialogue Systems", "topic_distr": {"0": 0.0014497830998152494, "1": 0.0011843139072880149, "2": 0.2801268696784973, "3": 0.0008670292445458472, "4": 0.1105467677116394, "5": 0.22414983808994293, "6": 0.0937921479344368, "7": 0.05391380563378334, "8": 0.000519438530318439, "9": 0.00048088200856000185, "10": 0.0004476538742892444, "11": 0.000418721028836444, "12": 0.0003933010157197714, "13": 0.10549313575029373, "14": 0.12470116466283798, "15": 0.0003327065787743777, "16": 0.00031645491253584623, "17": 0.0003017169947270304, "18": 0.00028829072834923863, "19": 0.0002760084462352097}}, {"key": "lin2020pre", "year": "2020", "title": "Pre-training Multilingual Neural Machine Translation By Leveraging Alignment Information", "topic_distr": {"0": 0.0011773110600188375, "1": 0.0009609762346372008, "2": 0.2891175150871277, "3": 0.0007035392336547375, "4": 0.0006204915116541088, "5": 0.0005549834459088743, "6": 0.0005019872332923114, "7": 0.0004582300898618996, "8": 0.0004214897926431149, "9": 0.00039020375697873533, "10": 0.0003632413281593472, "11": 0.00033976422855630517, "12": 0.0003191375872120261, "13": 0.0003008720523212105, "14": 0.38479483127593994, "15": 0.0002699692267924547, "16": 0.0731077492237091, "17": 0.08033841848373413, "18": 0.16503529250621796, "19": 0.00022396247368305922}}, {"key": "lin2020variational", "year": "2020", "title": "Variational Transformers For Diverse Response Generation", "topic_distr": {"0": 0.03959605097770691, "1": 0.14451734721660614, "2": 0.0009358025272376835, "3": 0.0008105190936475992, "4": 0.000714845780748874, "5": 0.0006393769290298223, "6": 0.3643227517604828, "7": 0.0005279106553643942, "8": 0.00048558347043581307, "9": 0.0004495399189181626, "10": 0.3092520534992218, "11": 0.00039143033791333437, "12": 0.0003676671185530722, "13": 0.056003864854574203, "14": 0.03981607034802437, "15": 0.0003110220131929964, "16": 0.040048569440841675, "17": 0.00028205220587551594, "18": 0.0002695010043680668, "19": 0.0002580192522145808}}, {"key": "lin2021bilingual", "year": "2021", "title": "Bitod: A Bilingual Multi-domain Dataset For Task-oriented Dialogue Modeling", "topic_distr": {"0": 0.0014675589045509696, "1": 0.0011985168093815446, "2": 0.0010129270376637578, "3": 0.06146937981247902, "4": 0.0007737721898593009, "5": 0.14418455958366394, "6": 0.047917962074279785, "7": 0.0005714271683245897, "8": 0.0005256108706817031, "9": 0.00048659619642421603, "10": 0.0004529732104856521, "11": 0.030139047652482986, "12": 0.13275712728500366, "13": 0.00037519680336117744, "14": 0.49507686495780945, "15": 0.00033666001399978995, "16": 0.06207012012600899, "17": 0.00030530220828950405, "18": 0.01859908737242222, "19": 0.000279288156889379}}, {"key": "lin2021chinese", "year": "2021", "title": "M6: A Chinese Multimodal Pretrainer", "topic_distr": {"0": 0.0019473020220175385, "1": 0.0015914631076157093, "2": 0.001345179625786841, "3": 0.0011650874512270093, "4": 0.0010275619570165873, "5": 0.000919078360311687, "6": 0.0008313140133395791, "7": 0.0007588501321151853, "8": 0.0006980065372772515, "9": 0.0006461953744292259, "10": 0.0006015443941578269, "11": 0.0005626652273349464, "12": 0.05152009055018425, "13": 0.1901664286851883, "14": 0.00047128452570177615, "15": 0.1572696417570114, "16": 0.00042524299351498485, "17": 0.000405438564484939, "18": 0.39860695600509644, "19": 0.1890406757593155}}, {"key": "lin2021end", "year": "2021", "title": "Swinbert: End-to-end Transformers With Sparse Attention For Video Captioning", "topic_distr": {"0": 0.0009240410290658474, "1": 0.0007544108666479588, "2": 0.341328889131546, "3": 0.0005523642175830901, "4": 0.0004871631390415132, "5": 0.00043573154835030437, "6": 0.00039412284968420863, "7": 0.0003597679897211492, "8": 0.0003309222520329058, "9": 0.0003063587937504053, "10": 0.13010983169078827, "11": 0.00026675747358240187, "12": 0.0002505629672668874, "13": 0.00023622224398422986, "14": 0.00022343422460835427, "15": 0.00021195964654907584, "16": 0.0002016061043832451, "17": 0.00019221690308768302, "18": 0.5222577452659607, "19": 0.00017583859153091908}}, {"key": "lin2021few", "year": "2021", "title": "Few-shot Learning With Multilingual Language Models", "topic_distr": {"0": 0.038924071937799454, "1": 0.0010502232471480966, "2": 0.11587820202112198, "3": 0.20762459933757782, "4": 0.0006780163384974003, "5": 0.000606435933150351, "6": 0.0005485263536684215, "7": 0.0005007124855183065, "8": 0.000460566021502018, "9": 0.0004263794398866594, "10": 0.0003969173412770033, "11": 0.000371263682609424, "12": 0.00034872477408498526, "13": 0.07852441817522049, "14": 0.3118044435977936, "15": 0.05202068015933037, "16": 0.0002805883123073727, "17": 0.18905489146709442, "18": 0.0002556162071414292, "19": 0.0002447259903419763}}, {"key": "lin2021measuring", "year": "2021", "title": "Truthfulqa: Measuring How Models Mimic Human Falsehoods", "topic_distr": {"0": 0.20473061501979828, "1": 0.22636453807353973, "2": 0.18712040781974792, "3": 0.11628038436174393, "4": 0.0008326946990564466, "5": 0.0007447805837728083, "6": 0.000673660368192941, "7": 0.0006149387918412685, "8": 0.17963111400604248, "9": 0.0005236483411863446, "10": 0.0004874651203863323, "11": 0.02043073996901512, "12": 0.0004282784939277917, "13": 0.059104856103658676, "14": 0.00038190826307982206, "15": 0.0003622951917350292, "16": 0.00034459822927601635, "17": 0.00032854959135875106, "18": 0.00031392931123264134, "19": 0.00030055473325774074}}, {"key": "lin2021multimodal", "year": "2021", "title": "Multimodal Transformer With Variable-length Memory For Vision-and-language Navigation", "topic_distr": {"0": 0.04551534727215767, "1": 0.0009176296298392117, "2": 0.43732544779777527, "3": 0.0006718391086906195, "4": 0.0005925347795709968, "5": 0.0005299787153489888, "6": 0.00047937012277543545, "7": 0.0004375844437163323, "8": 0.00040249948506243527, "9": 0.00037262303521856666, "10": 0.07978368550539017, "11": 0.2770366668701172, "12": 0.0003047587815672159, "13": 0.00028731621569022536, "14": 0.00027176219737157226, "15": 0.0002578057174105197, "16": 0.0002452127228025347, "17": 0.0002337926853215322, "18": 0.15412023663520813, "19": 0.0002138717973139137}}, {"key": "lin2021scene", "year": "2021", "title": "Scene-intuitive Agent For Remote Embodied Visual Grounding", "topic_distr": {"0": 0.09545841813087463, "1": 0.0009888833155855536, "2": 0.1673239767551422, "3": 0.0007240836275741458, "4": 0.0006386144668795168, "5": 0.0005711928242817521, "6": 0.0005166488117538393, "7": 0.0004716136318165809, "8": 0.000433800247265026, "9": 0.0004016004386357963, "10": 0.00037385051837190986, "11": 0.3356499671936035, "12": 0.016275594010949135, "13": 0.0003096596337854862, "14": 0.0002928960311692208, "15": 0.0002778542402666062, "16": 0.00026428193086758256, "17": 0.00025197380455210805, "18": 0.37854456901550293, "19": 0.00023050374875310808}}, {"key": "lin2021using", "year": "2021", "title": "Using Adversarial Attacks To Reveal The Statistical Bias In Machine Reading Comprehension Models", "topic_distr": {"0": 0.2655024230480194, "1": 0.16769279539585114, "2": 0.21862611174583435, "3": 0.0010214817011728883, "4": 0.0009009053464978933, "5": 0.0008057915838435292, "6": 0.000728845305275172, "7": 0.0814916118979454, "8": 0.15564505755901337, "9": 0.0005665446515195072, "10": 0.10342665016651154, "11": 0.0004933105083182454, "12": 0.00046336225932464004, "13": 0.0004368421796243638, "14": 0.00041319348383694887, "15": 0.00039197373553179204, "16": 0.00037282705307006836, "17": 0.00035546376602724195, "18": 0.0003396458050701767, "19": 0.0003251756133977324}}, {"key": "lin2022retrieval", "year": "2022", "title": "Retrieval Augmented Visual Question Answering With Outside Knowledge", "topic_distr": {"0": 0.00138695421628654, "1": 0.0011317001190036535, "2": 0.0009566518710926175, "3": 0.0008285628282465041, "4": 0.0007307605701498687, "5": 0.0006536106811836362, "6": 0.0005911963526159525, "7": 0.0005396630149334669, "8": 0.35500794649124146, "9": 0.0004595475911628455, "10": 0.00042779362411238253, "11": 0.0004001443739980459, "12": 0.0003758521634154022, "13": 0.118586465716362, "14": 0.0003351581981405616, "15": 0.09217365831136703, "16": 0.1147863045334816, "17": 0.0002883312408812344, "18": 0.16769757866859436, "19": 0.14264215528964996}}, {"key": "lin2022teaching", "year": "2022", "title": "Teaching Models To Express Their Uncertainty In Words", "topic_distr": {"0": 0.0019503189250826836, "1": 0.0015914351679384708, "2": 0.24222740530967712, "3": 0.5011318325996399, "4": 0.001027644844725728, "5": 0.0009191535646095872, "6": 0.0008313818834722042, "7": 0.09242099523544312, "8": 0.13756242394447327, "9": 0.0006462481105700135, "10": 0.000601593463215977, "11": 0.0005627111531794071, "12": 0.0005285497172735631, "13": 0.0004982986720278859, "14": 0.00047132300096563995, "15": 0.0004471179854590446, "16": 0.01541779562830925, "17": 0.0004054716555401683, "18": 0.0003874283574987203, "19": 0.0003709224401973188}}, {"key": "lin2022vision", "year": "2022", "title": "ADAPT: Vision-language Navigation With Modality-aligned Action Prompts", "topic_distr": {"0": 0.0010564386611804366, "1": 0.0008631029049865901, "2": 0.10992616415023804, "3": 0.0006319261738099158, "4": 0.0005573343369178474, "5": 0.0004984942497685552, "6": 0.0004508922284003347, "7": 0.00041158893145620823, "8": 0.0003785882727243006, "9": 0.000350486661773175, "10": 0.00032626863685436547, "11": 0.3316449224948883, "12": 0.0002866540162358433, "13": 0.0002702476631384343, "14": 0.000255617662332952, "15": 0.00024249029229395092, "16": 0.08001118153333664, "17": 0.2063511162996292, "18": 0.2525063753128052, "19": 0.012980122119188309}}, {"key": "lin2023generating", "year": "2023", "title": "Generating With Confidence: Uncertainty Quantification For Black-box Large Language Models", "topic_distr": {"0": 0.10808590799570084, "1": 0.0010951803997159004, "2": 0.0009257858037017286, "3": 0.48344743251800537, "4": 0.0007071889122016728, "5": 0.07253003865480423, "6": 0.041613273322582245, "7": 0.041223831474781036, "8": 0.00048038209206424654, "9": 0.051073458045721054, "10": 0.00041399491601623595, "11": 0.00038723749457858503, "12": 0.1959477961063385, "13": 0.00034291116753593087, "14": 0.000324347463902086, "15": 0.0003076904686167836, "16": 0.00029266075580380857, "17": 0.00027903096633963287, "18": 0.00026661422452889383, "19": 0.0002552554360590875}}, {"key": "lin2023generative", "year": "2023", "title": "Swiftsage: A Generative Agent With Fast And Slow Thinking For Complex Interactive Tasks", "topic_distr": {"0": 0.06010475382208824, "1": 0.0013581124367192388, "2": 0.0011480733519420028, "3": 0.30351632833480835, "4": 0.06688493490219116, "5": 0.0007844149949960411, "6": 0.0007095100008882582, "7": 0.0006476635462604463, "8": 0.0005957346875220537, "9": 0.0005515149096027017, "10": 0.0005134061793796718, "11": 0.4421125650405884, "12": 0.0004510698781814426, "13": 0.028208186849951744, "14": 0.00040223199175670743, "15": 0.03602997586131096, "16": 0.04100664705038071, "17": 0.00034603377571329474, "18": 0.0003306354337837547, "19": 0.014298194088041782}}, {"key": "lin2023how", "year": "2023", "title": "How Can Recommender Systems Benefit From Large Language Models: A Survey", "topic_distr": {"0": 0.14169983565807343, "1": 0.0007326977793127298, "2": 0.0006193963345140219, "3": 0.1522054225206375, "4": 0.189462810754776, "5": 0.00042319949716329575, "6": 0.00038278751890175045, "7": 0.00034942073398269713, "8": 0.021718746051192284, "9": 0.13524487614631653, "10": 0.0002769875864032656, "11": 0.00025908526731655, "12": 0.22997017204761505, "13": 0.05708586424589157, "14": 0.00021700805518776178, "15": 0.0002058635000139475, "16": 0.06860996782779694, "17": 0.00018668857228476554, "18": 0.00017838101484812796, "19": 0.00017078130622394383}}, {"key": "lin2023joint", "year": "2023", "title": "SPHINX: The Joint Mixing Of Weights, Tasks, And Visual Embeddings For Multi-modal Large Language Models", "topic_distr": {"0": 0.0010062115034088492, "1": 0.0670638158917427, "2": 0.0006943480111658573, "3": 0.21782757341861725, "4": 0.0005304007208906114, "5": 0.0004744043108075857, "6": 0.00042910268530249596, "7": 0.00039169873343780637, "8": 0.021281644701957703, "9": 0.00033354925108142197, "10": 0.00031050157849676907, "11": 0.00029043317772448063, "12": 0.09435833245515823, "13": 0.05572587996721268, "14": 0.00024326483253389597, "15": 0.00023077185323927552, "16": 0.00021949937217868865, "17": 0.00020927685545757413, "18": 0.5381878614425659, "19": 0.00019144490943290293}}, {"key": "lin2023llm", "year": "2023", "title": "Llm-eval: Unified Multi-dimensional Automatic Evaluation For Open-domain Conversations With Large Language Models", "topic_distr": {"0": 0.0014850664883852005, "1": 0.04288104921579361, "2": 0.001024867407977581, "3": 0.398685485124588, "4": 0.3665444850921631, "5": 0.000700236763805151, "6": 0.06205621361732483, "7": 0.037287354469299316, "8": 0.0005318043986335397, "9": 0.000492330000270158, "10": 0.00045831079478375614, "11": 0.00042868914897553623, "12": 0.0004026640090160072, "13": 0.0851111114025116, "14": 0.00035906711127609015, "15": 0.0003406270407140255, "16": 0.00032398849725723267, "17": 0.00030889970366843045, "18": 0.00029515381902456284, "19": 0.00028257915982976556}}, {"key": "lin2023pmc", "year": "2023", "title": "PMC-CLIP: Contrastive Language-image Pre-training Using Biomedical Documents", "topic_distr": {"0": 0.0022682552225887775, "1": 0.24297435581684113, "2": 0.08971448242664337, "3": 0.0013558048522099853, "4": 0.0011957657989114523, "5": 0.0010695239761844277, "6": 0.000967393396422267, "7": 0.0008830678416416049, "8": 0.0008122646249830723, "9": 0.0007519724313169718, "10": 0.0007000123732723296, "11": 0.0006547690136358142, "12": 0.1287856101989746, "13": 0.0005798188503831625, "14": 0.0005484300199896097, "15": 0.16778258979320526, "16": 0.000494851847179234, "17": 0.00047180562978610396, "18": 0.3262259364128113, "19": 0.031763315200805664}}, {"key": "lin2023pre", "year": "2023", "title": "VILA: On Pre-training For Visual Language Models", "topic_distr": {"0": 0.0014682096661999822, "1": 0.0011985573219135404, "2": 0.0010129297152161598, "3": 0.4767124056816101, "4": 0.000773761363234371, "5": 0.0006920722080394626, "6": 0.0006259852088987827, "7": 0.025414086878299713, "8": 0.0005256037693470716, "9": 0.00048658958985470235, "10": 0.0004529670695774257, "11": 0.040904004126787186, "12": 0.00039796909550204873, "13": 0.022969938814640045, "14": 0.000354880525264889, "15": 0.0003366554738022387, "16": 0.04346265271306038, "17": 0.00030529804644174874, "18": 0.3816261887550354, "19": 0.00027928437339141965}}, {"key": "lin2023pushing", "year": "2023", "title": "Pushing Large Language Models To The 6G Edge: Vision, Challenges, And Opportunities", "topic_distr": {"0": 0.0012475086841732264, "1": 0.0010185192804783583, "2": 0.0008609977667219937, "3": 0.00074572185985744, "4": 0.0006576923769898713, "5": 0.0005882576224394143, "6": 0.0005320837954059243, "7": 0.00048570320359431207, "8": 0.00044676015386357903, "9": 0.6461194753646851, "10": 0.032025277614593506, "11": 0.00036013475619256496, "12": 0.0003382714348845184, "13": 0.23112377524375916, "14": 0.00030164638883434236, "15": 0.00028615520568564534, "16": 0.0002721774217206985, "17": 0.0002595015976112336, "18": 0.08209297060966492, "19": 0.00023739012249279767}}, {"key": "lin2023retrieval", "year": "2023", "title": "Rella: Retrieval-enhanced Large Language Models For Lifelong Sequential Behavior Comprehension In Recommendation", "topic_distr": {"0": 0.0008915565558709204, "1": 0.10268112272024155, "2": 0.11329476535320282, "3": 0.2639681100845337, "4": 0.3299969434738159, "5": 0.00042017854866571724, "6": 0.00038005507667548954, "7": 0.00034692647750489414, "8": 0.0003191103751305491, "9": 0.00029542366974055767, "10": 0.04096972197294235, "11": 0.0002572358644101769, "12": 0.00024161940382327884, "13": 0.044678933918476105, "14": 0.0002154589892597869, "15": 0.06548503786325455, "16": 0.035025786608457565, "17": 0.00018535593699198216, "18": 0.00017710767860990018, "19": 0.0001695622195256874}}, {"key": "lin2023video", "year": "2023", "title": "Video-llava: Learning United Visual Representation By Alignment Before Projection", "topic_distr": {"0": 0.0012224356178194284, "1": 0.0009987337980419397, "2": 0.000844109570607543, "3": 0.14286287128925323, "4": 0.000644804211333394, "5": 0.0005767298862338066, "6": 0.000521656998898834, "7": 0.0004761852906085551, "8": 0.0004380053433123976, "9": 0.00040549339610151947, "10": 0.0003774744982365519, "11": 0.00035307748476043344, "12": 0.00033164260094054043, "13": 0.0003126613737549633, "14": 0.0002957352844532579, "15": 0.00028054765425622463, "16": 0.00026684379554353654, "17": 0.0002544163435231894, "18": 0.760208785533905, "19": 0.08832783252000809}}, {"key": "lin2024data", "year": "2024", "title": "Data-efficient Fine-tuning For Llm-based Recommendation", "topic_distr": {"0": 0.0008050189935602248, "1": 0.11139474809169769, "2": 0.3425750136375427, "3": 0.19648554921150208, "4": 0.10520580410957336, "5": 0.0003795206139329821, "6": 0.0003432796220295131, "7": 0.00031335666426457465, "8": 0.00028823214233852923, "9": 0.052098408341407776, "10": 0.0002483994176145643, "11": 0.0002323448279639706, "12": 0.00021823948191013187, "13": 0.18837673962116241, "14": 0.00019461043120827526, "15": 0.000184616117621772, "16": 0.00017559820844326168, "17": 0.00016742025036364794, "18": 0.00015997013542801142, "19": 0.00015315480413846672}}, {"key": "lin2024moe", "year": "2024", "title": "Moe-llava: Mixture Of Experts For Large Vision-language Models", "topic_distr": {"0": 0.043348848819732666, "1": 0.0010184526909142733, "2": 0.14923404157161713, "3": 0.0007457112660631537, "4": 0.06347521394491196, "5": 0.0005882502882741392, "6": 0.0005320773343555629, "7": 0.00048569729551672935, "8": 0.0004467547114472836, "9": 0.0004135933122597635, "10": 0.000385014689527452, "11": 0.000360130361514166, "12": 0.146957129240036, "13": 0.38808757066726685, "14": 0.0003016427217517048, "15": 0.00028615171322599053, "16": 0.0002721741038840264, "17": 0.0002594984252937138, "18": 0.20256464183330536, "19": 0.000237387212109752}}, {"key": "ling2022vision", "year": "2022", "title": "Vision-language Pre-training For Multimodal Aspect-based Sentiment Analysis", "topic_distr": {"0": 0.0018631472485139966, "1": 0.15020734071731567, "2": 0.2279193252325058, "3": 0.0011129294289276004, "4": 0.000981554971076548, "5": 0.0008779277559369802, "6": 0.0007940931827761233, "7": 0.0007248737965710461, "8": 0.0006667543202638626, "9": 0.0006172629655338824, "10": 0.0005746111273765564, "11": 0.000537472718860954, "12": 0.0005048434832133353, "13": 0.0004759492294397205, "14": 0.0004501834628172219, "15": 0.0004270640783943236, "16": 0.00040620335494168103, "17": 0.0003872856614179909, "18": 0.5637975931167603, "19": 0.04667353257536888}}, {"key": "liu2016neural", "year": "2016", "title": "Neural Machine Translation With Supervised Attention", "topic_distr": {"0": 0.0021529430523514748, "1": 0.001756096025928855, "2": 0.5186646580696106, "3": 0.026480605825781822, "4": 0.0011341352947056293, "5": 0.03236338496208191, "6": 0.000917533878237009, "7": 0.000837554456666112, "8": 0.0007704003946855664, "9": 0.0007132156752049923, "10": 0.0006639336352236569, "11": 0.0006210221326909959, "12": 0.0005833207396790385, "13": 0.0005499349208548665, "14": 0.3191646635532379, "15": 0.0004934506141580641, "16": 0.09084872156381607, "17": 0.00044748871005140245, "18": 0.00042757566552609205, "19": 0.0004093593161087483}}, {"key": "liu2017phase", "year": "2017", "title": "Phase Conductor On Multi-layered Attentions For Machine Comprehension", "topic_distr": {"0": 0.0017086240695789456, "1": 0.0013950862921774387, "2": 0.6527197957038879, "3": 0.0010214514331892133, "4": 0.0009008808410726488, "5": 0.0008057711529545486, "6": 0.0007288266788236797, "7": 0.0006652964511886239, "8": 0.10475166141986847, "9": 0.0005665301578119397, "10": 0.1267378330230713, "11": 0.0004932978772558272, "12": 0.025582503527402878, "13": 0.00043683103285729885, "14": 0.00041318294825032353, "15": 0.00039196372381411493, "16": 0.07966017723083496, "17": 0.0003554547147359699, "18": 0.0003396371321287006, "19": 0.0003251673188060522}}, {"key": "liu2017table", "year": "2017", "title": "Table-to-text Generation By Structure-aware Seq2seq Learning", "topic_distr": {"0": 0.0013130030129104853, "1": 0.0010720492573454976, "2": 0.25079864263534546, "3": 0.0007849271642044187, "4": 0.0006922747124917805, "5": 0.0006191888242028654, "6": 0.1838369518518448, "7": 0.1327245980501175, "8": 0.0004702512815129012, "9": 0.0004353458061814308, "10": 0.13634057343006134, "11": 0.00037907101796008646, "12": 0.10953561961650848, "13": 0.00033567947684787214, "14": 0.00031750727794133127, "15": 0.00030120156588964164, "16": 0.091411292552948, "17": 0.0002731464628595859, "18": 0.0002609915682114661, "19": 0.0880977138876915}}, {"key": "liu2018context", "year": "2018", "title": "Context-aware Visual Policy Network For Sequence-level Image Captioning", "topic_distr": {"0": 0.03592712804675102, "1": 0.0007715064566582441, "2": 0.31507378816604614, "3": 0.0005649115773849189, "4": 0.11649186164140701, "5": 0.00044562830589711666, "6": 0.00040307457675226033, "7": 0.00036793944309465587, "8": 0.0003384385199751705, "9": 0.0003133171412628144, "10": 0.00029166744207032025, "11": 0.13440260291099548, "12": 0.0002562540175858885, "13": 0.00024158756423275918, "14": 0.00022850908862892538, "15": 0.00021677390031982213, "16": 0.00020618518465198576, "17": 0.0001965827395906672, "18": 0.3930824100971222, "19": 0.00017983242287300527}}, {"key": "liu2018efficient", "year": "2018", "title": "Efficient Contextualized Representation: Language Model Pruning For Sequence Labeling", "topic_distr": {"0": 0.0015598074533045292, "1": 0.03056127391755581, "2": 0.35775992274284363, "3": 0.0009321208344772458, "4": 0.0008220921154133976, "5": 0.0007353004766628146, "6": 0.0006650855066254735, "7": 0.0006071114330552518, "8": 0.0005584339960478246, "9": 0.06386216729879379, "10": 0.15688873827457428, "11": 0.0004501554067246616, "12": 0.0004228270554449409, "13": 0.18045076727867126, "14": 0.0003770470793824643, "15": 0.00035768363159149885, "16": 0.0003402119327802211, "17": 0.0003243676037527621, "18": 0.00030993338441476226, "19": 0.20201492309570312}}, {"key": "liu2018end", "year": "2018", "title": "Seq2rdf: An End-to-end Application For Deriving Triples From Natural Language Text", "topic_distr": {"0": 0.001978265354409814, "1": 0.0016166821587830782, "2": 0.28113675117492676, "3": 0.001183607499115169, "4": 0.0010438928147777915, "5": 0.0009336850489489734, "6": 0.000844525930006057, "7": 0.2573120892047882, "8": 0.000709099811501801, "9": 0.0006564652430824935, "10": 0.08375105261802673, "11": 0.0005716075538657606, "12": 0.0005369060090743005, "13": 0.0005061767296865582, "14": 0.06004700809717178, "15": 0.0004541868984233588, "16": 0.23140175640583038, "17": 0.0004118821525480598, "18": 0.07452760636806488, "19": 0.00037678671651519835}}, {"key": "liu2018reinforcement", "year": "2018", "title": "Reinforcement Learning On Web Interfaces Using Workflow-guided Exploration", "topic_distr": {"0": 0.03098323941230774, "1": 0.027386052533984184, "2": 0.10258231312036514, "3": 0.2481972873210907, "4": 0.0006851372891105711, "5": 0.0006128049571998417, "6": 0.0005542872822843492, "7": 0.0005059712566435337, "8": 0.00046540313633158803, "9": 0.00043085752986371517, "10": 0.0004010859993286431, "11": 0.5211302638053894, "12": 0.000352387287421152, "13": 0.0640411227941513, "14": 0.00031423388281837106, "15": 0.00029809624538756907, "16": 0.0002835351915564388, "17": 0.0002703304053284228, "18": 0.00025830083177424967, "19": 0.0002472962369211018}}, {"key": "liu2019attention", "year": "2019", "title": "Attention-informed Mixed-language Training For Zero-shot Cross-lingual Task-oriented Dialogue Systems", "topic_distr": {"0": 0.001285026897676289, "1": 0.0010500955395400524, "2": 0.3287869691848755, "3": 0.0007687020115554333, "4": 0.10573139041662216, "5": 0.16395916044712067, "6": 0.12300997972488403, "7": 0.0005006739520467818, "8": 0.0004605305439326912, "9": 0.0004263466107659042, "10": 0.0003968867822550237, "11": 0.0003712351026479155, "12": 0.0003486979112494737, "13": 0.00032874051248654723, "14": 0.2712322473526001, "15": 0.00029497529612854123, "16": 0.00028056668816134334, "17": 0.0002675001451279968, "18": 0.00025559653295204043, "19": 0.0002447071310598403}}, {"key": "liu2019knowledge", "year": "2019", "title": "Knowledge Aware Conversation Generation With Explainable Reasoning Over Augmented Graphs", "topic_distr": {"0": 0.0013140143128111959, "1": 0.0010720626451075077, "2": 0.1663513481616974, "3": 0.0007849964895285666, "4": 0.0006923367618583143, "5": 0.0006192433065734804, "6": 0.13394668698310852, "7": 0.12765049934387207, "8": 0.03130153566598892, "9": 0.00043538413592614233, "10": 0.00040529982652515173, "11": 0.03716783970594406, "12": 0.00035608946927823126, "13": 0.0003357090463396162, "14": 0.034622520208358765, "15": 0.0914081409573555, "16": 0.3707522451877594, "17": 0.00027317050262354314, "18": 0.0002610145602375269, "19": 0.0002498943358659744}}, {"key": "liu2019learning", "year": "2019", "title": "Learning To Generate Questions By Learning What Not To Generate", "topic_distr": {"0": 0.0008382205269299448, "1": 0.0006835871026851237, "2": 0.41149455308914185, "3": 0.0005004994454793632, "4": 0.046380769461393356, "5": 0.00039481656858697534, "6": 0.03685403987765312, "7": 0.22177177667617798, "8": 0.18872347474098206, "9": 0.07714592665433884, "10": 0.0002584107278380543, "11": 0.00024170907272491604, "12": 0.00022703524155076593, "13": 0.00021404109429568052, "14": 0.00020245385530870408, "15": 0.00019205674470867962, "16": 0.013376748189330101, "17": 0.00017416782793588936, "18": 0.00016641744878143072, "19": 0.00015932743554003537}}, {"key": "liu2019linguistic", "year": "2019", "title": "Linguistic Knowledge And Transferability Of Contextual Representations", "topic_distr": {"0": 0.059097327291965485, "1": 0.0009432750521227717, "2": 0.3319718837738037, "3": 0.0006904952460899949, "4": 0.0006089871167205274, "5": 0.000544694485142827, "6": 0.0004926807596348226, "7": 0.0004497348563745618, "8": 0.00041367567609995604, "9": 0.0003829696506727487, "10": 0.2562702000141144, "11": 0.00033346525742672384, "12": 0.05986610800027847, "13": 0.0002952940994873643, "14": 0.0002793082094285637, "15": 0.00026496421196497977, "16": 0.03737941011786461, "17": 0.055639367550611496, "18": 0.00022959185298532248, "19": 0.19384653866291046}}, {"key": "liu2019multi", "year": "2019", "title": "MKD: A Multi-task Knowledge Distillation Approach For Pretrained Language Models", "topic_distr": {"0": 0.001340872491709888, "1": 0.001094999024644494, "2": 0.38876378536224365, "3": 0.0008017729269340634, "4": 0.0007071306463330984, "5": 0.0006324760615825653, "6": 0.0005720799090340734, "7": 0.0005222129402682185, "8": 0.0004803425690624863, "9": 0.00044468804844655097, "10": 0.09564816951751709, "11": 0.0003872056258842349, "12": 0.00036369889858178794, "13": 0.34902089834213257, "14": 0.0003243207756895572, "15": 0.00030766514828428626, "16": 0.039890140295028687, "17": 0.0942424014210701, "18": 0.00026659228024072945, "19": 0.024188503623008728}}, {"key": "liu2019robustly", "year": "2019", "title": "Roberta: A Robustly Optimized BERT Pretraining Approach", "topic_distr": {"0": 0.0518709234893322, "1": 0.0014550267951563, "2": 0.4454536437988281, "3": 0.0010652889031916857, "4": 0.0009395410306751728, "5": 0.0008403495885431767, "6": 0.0007601032848469913, "7": 0.0006938466685824096, "8": 0.018032703548669815, "9": 0.0005908419843763113, "10": 0.14571738243103027, "11": 0.0005144670722074807, "12": 0.0004832344420719892, "13": 0.12848888337612152, "14": 0.04332524165511131, "15": 0.00040878428262658417, "16": 0.0003888164646923542, "17": 0.0003707085270434618, "18": 0.0003542121557984501, "19": 0.1582460105419159}}, {"key": "liu2019say", "year": "2019", "title": "Say What I Want: Towards The Dark Side Of Neural Dialogue Models", "topic_distr": {"0": 0.0014857108471915126, "1": 0.04812617972493172, "2": 0.1963416486978531, "3": 0.2426484078168869, "4": 0.0007829744135960937, "5": 0.1566353589296341, "6": 0.04651014506816864, "7": 0.1284758448600769, "8": 0.0005318616167642176, "9": 0.12014076113700867, "10": 0.00045836015488021076, "11": 0.055169861763715744, "12": 0.0004027073737233877, "13": 0.00037965879891999066, "14": 0.0003591057611629367, "15": 0.000340663711540401, "16": 0.00032402336364611983, "17": 0.0003089329693466425, "18": 0.0002951856004074216, "19": 0.00028260957333259284}}, {"key": "liu2019text", "year": "2019", "title": "Text Summarization With Pretrained Encoders", "topic_distr": {"0": 0.0015209844568744302, "1": 0.0012421024730429053, "2": 0.24941596388816833, "3": 0.0009094677516259253, "4": 0.0008021114044822752, "5": 0.0007174298516474664, "6": 0.0006489211227744818, "7": 0.10717396438121796, "8": 0.0005448617157526314, "9": 0.0005044181016273797, "10": 0.5600578188896179, "11": 0.0004392147238831967, "12": 0.019225405529141426, "13": 0.00038893864257261157, "14": 0.0003678832435980439, "15": 0.0003489904338493943, "16": 0.0003319433599244803, "17": 0.00031648410367779434, "18": 0.00030240070191212, "19": 0.05474070459604263}}, {"key": "liu2020adversarial", "year": "2020", "title": "Adversarial Training For Large Neural Language Models", "topic_distr": {"0": 0.0011989077320322394, "1": 0.40044790506362915, "2": 0.13454873859882355, "3": 0.0007169910822995007, "4": 0.0006323544657789171, "5": 0.0005655942368321121, "6": 0.0005115848034620285, "7": 0.0004669910704251379, "8": 0.00042954832315444946, "9": 0.0003976641164626926, "10": 0.15681852400302887, "11": 0.0003462602326180786, "12": 0.08697957545518875, "13": 0.00030662448261864483, "14": 0.07317562401294708, "15": 0.0002751308202277869, "16": 0.03483201935887337, "17": 0.10688330978155136, "18": 0.00023840124777052552, "19": 0.0002282444474985823}}, {"key": "liu2020asking", "year": "2020", "title": "Asking Questions The Human Way: Scalable Question-answer Generation From Text Corpus", "topic_distr": {"0": 0.10286132991313934, "1": 0.0279097780585289, "2": 0.1282244175672531, "3": 0.000564938469324261, "4": 0.0004982526297681034, "5": 0.00044565016287378967, "6": 0.0353684164583683, "7": 0.2605671286582947, "8": 0.26776137948036194, "9": 0.00031333244987763464, "10": 0.00029168170294724405, "11": 0.00027282966766506433, "12": 0.00025626656133681536, "13": 0.0002415993803879246, "14": 0.06763558089733124, "15": 0.10601689666509628, "16": 0.00020619526912923902, "17": 0.0001965923438547179, "18": 0.00018784408166538924, "19": 0.0001798412122298032}}, {"key": "liu2020data", "year": "2020", "title": "Data Boost: Text Data Augmentation Through Reinforcement Learning Guided Conditional Generation", "topic_distr": {"0": 0.0013413262786343694, "1": 0.3689545691013336, "2": 0.1425115317106247, "3": 0.0008018806693144143, "4": 0.02721400558948517, "5": 0.0006325587164610624, "6": 0.0005721547640860081, "7": 0.17967060208320618, "8": 0.00048040543333627284, "9": 0.000444746227003634, "10": 0.016867779195308685, "11": 0.021956289187073708, "12": 0.0003637464833445847, "13": 0.0003429278149269521, "14": 0.00032436323817819357, "15": 0.03627244383096695, "16": 0.0002926749875769019, "17": 0.20043408870697021, "18": 0.0002666271757334471, "19": 0.0002552678342908621}}, {"key": "liu2020exploring", "year": "2020", "title": "Exploring Fine-tuning Techniques For Pre-trained Cross-lingual Models Via Continual Learning", "topic_distr": {"0": 0.002544806571677327, "1": 0.002078004414215684, "2": 0.1321837306022644, "3": 0.001521711703389883, "4": 0.0013420836767181754, "5": 0.0012003954034298658, "6": 0.0010857677552849054, "7": 0.000991123728454113, "8": 0.02321700006723404, "9": 0.0008439868688583374, "10": 0.0966871827840805, "11": 0.0007348892977461219, "12": 0.0006902751047164202, "13": 0.0006507678772322834, "14": 0.03128279745578766, "15": 0.0005839269724674523, "16": 0.22070284187793732, "17": 0.4806683361530304, "18": 0.0005059735267423093, "19": 0.0004844171635340899}}, {"key": "liu2020kg", "year": "2020", "title": "KG-BART: Knowledge Graph-augmented BART For Generative Commonsense Reasoning", "topic_distr": {"0": 0.001199303544126451, "1": 0.0009793714853003621, "2": 0.15229453146457672, "3": 0.0007169988821260631, "4": 0.0006323618581518531, "5": 0.0005656012799590826, "6": 0.0005115911480970681, "7": 0.17522016167640686, "8": 0.042045824229717255, "9": 0.00039766900590620935, "10": 0.00037019074079580605, "11": 0.03431195393204689, "12": 0.0003252432506997138, "13": 0.0003066282661166042, "14": 0.0002900287800002843, "15": 0.03532720357179642, "16": 0.3535388708114624, "17": 0.2004997879266739, "18": 0.00023840418725740165, "19": 0.00022824725601822138}}, {"key": "liu2020mitigating", "year": "2020", "title": "Mitigating Gender Bias For Neural Dialogue Generation With Adversarial Learning", "topic_distr": {"0": 0.19103646278381348, "1": 0.12955224514007568, "2": 0.04864215850830078, "3": 0.0008017977233976126, "4": 0.31057196855545044, "5": 0.08401782065629959, "6": 0.2306969314813614, "7": 0.0005222295876592398, "8": 0.000480357906781137, "9": 0.0004447022220119834, "10": 0.00041397404856979847, "11": 0.000387217995012179, "12": 0.0003637105110101402, "13": 0.00034289387986063957, "14": 0.0003243311366531998, "15": 0.0003076749562751502, "16": 0.00029264602926559746, "17": 0.00027901690918952227, "18": 0.0002666007785592228, "19": 0.00025524257216602564}}, {"key": "liu2020multilingual", "year": "2020", "title": "Multilingual Denoising Pre-training For Neural Machine Translation", "topic_distr": {"0": 0.00159896956756711, "1": 0.0013055934105068445, "2": 0.16741172969341278, "3": 0.0009559665340930223, "4": 0.0008431238238699734, "5": 0.0007541122031398118, "6": 0.0006821008282713592, "7": 0.14464719593524933, "8": 0.0005727208335883915, "9": 0.000530209275893867, "10": 0.0004935727338306606, "11": 0.00046167202526703477, "12": 0.00043364454177208245, "13": 0.00040882531902752817, "14": 0.6772299408912659, "15": 0.000366834516171366, "16": 0.00034891581162810326, "17": 0.00033266612445004284, "18": 0.000317862635711208, "19": 0.0003043204778805375}}, {"key": "liu2020natural", "year": "2020", "title": "Natural Language Inference In Context -- Investigating Contextual Reasoning Over Long Texts", "topic_distr": {"0": 0.13661648333072662, "1": 0.10063868761062622, "2": 0.000967390660662204, "3": 0.4029421806335449, "4": 0.0007389688980765641, "5": 0.0006609536940231919, "6": 0.000597837963141501, "7": 0.09460444748401642, "8": 0.0005019701202400029, "9": 0.00046471026143990457, "10": 0.2583202123641968, "11": 0.0004046396934427321, "12": 0.0003800745471380651, "13": 0.0003583213547244668, "14": 0.00033892341889441013, "15": 0.0003215178439859301, "16": 0.0003058127185795456, "17": 0.00029157043900340796, "18": 0.00027859568945132196, "19": 0.000266726448899135}}, {"key": "liu2020reading", "year": "2020", "title": "Rikinet: Reading Wikipedia Pages For Natural Question Answering", "topic_distr": {"0": 0.00170794571749866, "1": 0.0013949746498838067, "2": 0.4816330671310425, "3": 0.0010214436333626509, "4": 0.0009008717606775463, "5": 0.0008057636441662908, "6": 0.0007288200431503356, "7": 0.000665290339384228, "8": 0.3691219985485077, "9": 0.0005665249773301184, "10": 0.07595553994178772, "11": 0.0004932933370582759, "12": 0.0004633461940102279, "13": 0.0004368270165286958, "14": 0.0004131791356485337, "15": 0.00039196014404296875, "16": 0.06227891519665718, "17": 0.0003554514260031283, "18": 0.00033963401801884174, "19": 0.00032516432111151516}}, {"key": "liu2020survey", "year": "2020", "title": "A Survey On Contextual Embeddings", "topic_distr": {"0": 0.0024945191107690334, "1": 0.0020365773234516382, "2": 0.0017219404689967632, "3": 0.0014914056519046426, "4": 0.0013153634499758482, "5": 0.001176496152766049, "6": 0.0010641509434208274, "7": 0.0009713911567814648, "8": 0.0008935062796808779, "9": 0.0008271837141364813, "10": 0.6734480857849121, "11": 0.0007202581618912518, "12": 0.21378083527088165, "13": 0.09484870731830597, "14": 0.0006032832898199558, "15": 0.0005723013891838491, "16": 0.0005443462869152427, "17": 0.0005189950461499393, "18": 0.0004958999925293028, "19": 0.00047477276530116796}}, {"key": "liu2020text", "year": "2020", "title": "TIME: Text And Image Mutual-translation Adversarial Networks", "topic_distr": {"0": 0.001755762961693108, "1": 0.09511660784482956, "2": 0.34709078073501587, "3": 0.001050237799063325, "4": 0.0009262690437026322, "5": 0.0008284791838377714, "6": 0.0007493665325455368, "7": 0.06617029011249542, "8": 0.0006291999015957117, "9": 0.0005824961117468774, "10": 0.0906469002366066, "11": 0.000507200020365417, "12": 0.00047640857519581914, "13": 0.00044914177851751447, "14": 0.0004248272452969104, "15": 0.04258233681321144, "16": 0.000383324280846864, "17": 0.00036547210766002536, "18": 0.3489305377006531, "19": 0.0003343311545904726}}, {"key": "liu2020very", "year": "2020", "title": "Very Deep Transformers For Neural Machine Translation", "topic_distr": {"0": 0.002653229981660843, "1": 0.0021667727269232273, "2": 0.0018318027723580599, "3": 0.0015865558525547385, "4": 0.001399274100549519, "5": 0.0012515480630099773, "6": 0.0011320357443764806, "7": 0.0010333586251363158, "8": 0.0009505052585154772, "9": 0.0008799518109299242, "10": 0.4721243977546692, "11": 0.000766205252148211, "12": 0.0007196899387054145, "13": 0.0006784991710446775, "14": 0.44316408038139343, "15": 0.0006088099326007068, "16": 0.0005790715222246945, "17": 0.06544158607721329, "18": 0.0005275346920825541, "19": 0.0005050597246736288}}, {"key": "liu2020you", "year": "2020", "title": "You Impress Me: Dialogue Generation Via Mutual Persona Perception", "topic_distr": {"0": 0.11419881880283356, "1": 0.0015915100229904056, "2": 0.13215453922748566, "3": 0.0011651810491457582, "4": 0.11490164697170258, "5": 0.07764695584774017, "6": 0.33185330033302307, "7": 0.0007589061860926449, "8": 0.0006980581092648208, "9": 0.000646243104711175, "10": 0.0006015888066031039, "11": 0.0005627067876048386, "12": 0.22021470963954926, "13": 0.0004982948303222656, "14": 0.0004713193338830024, "15": 0.0004471145221032202, "16": 0.00042527439654804766, "17": 0.00040546851232647896, "18": 0.00038742535980418324, "19": 0.00037091958802193403}}, {"key": "liu2021augmenting", "year": "2021", "title": "Augmenting Sequential Recommendation With Pseudo-prior Items Via Reversely Pre-training Transformer", "topic_distr": {"0": 0.04385118931531906, "1": 0.0012572446139529347, "2": 0.17078709602355957, "3": 0.0009206595132127404, "4": 0.23972539603710175, "5": 0.0007262590224854648, "6": 0.0006569074466824532, "7": 0.06354864686727524, "8": 0.0005515673547051847, "9": 0.0005106260068714619, "10": 0.3384753167629242, "11": 0.00044462017831392586, "12": 0.056530505418777466, "13": 0.00039372534956783056, "14": 0.00037241081008687615, "15": 0.0003532854898367077, "16": 0.0799749493598938, "17": 0.00032037909841164947, "18": 0.0003061223542317748, "19": 0.0002930804039351642}}, {"key": "liu2021controllable", "year": "2021", "title": "Controllable Neural Dialogue Summarization With Personal Named Entity Planning", "topic_distr": {"0": 0.05155535414814949, "1": 0.0011574052041396499, "2": 0.0009783855639398098, "3": 0.0008473981870338321, "4": 0.0007473714067600667, "5": 0.0006684683612547815, "6": 0.1451871246099472, "7": 0.37353140115737915, "8": 0.0005076771485619247, "9": 0.05637049674987793, "10": 0.00043751788325607777, "11": 0.020089052617549896, "12": 0.0003843957092612982, "13": 0.0003623951633926481, "14": 0.00034277670783922076, "15": 0.1215091347694397, "16": 0.00030928957858122885, "17": 0.2244628667831421, "18": 0.00028176308842375875, "19": 0.00026975892251357436}}, {"key": "liu2021decoding", "year": "2021", "title": "Dexperts: Decoding-time Controlled Text Generation With Experts And Anti-experts", "topic_distr": {"0": 0.0018900978611782193, "1": 0.0015432123327627778, "2": 0.001304558478295803, "3": 0.0011299214093014598, "4": 0.0009965422796085477, "5": 0.0008913330384530127, "6": 0.0008062182459980249, "7": 0.4931119978427887, "8": 0.0006769351311959326, "9": 0.0006266880664043128, "10": 0.06090462580323219, "11": 0.0005456794751808047, "12": 0.06642370671033859, "13": 0.211349755525589, "14": 0.00045705740922130644, "15": 0.00043358499533496797, "16": 0.0004124057595618069, "17": 0.022062916308641434, "18": 0.0003757020167540759, "19": 0.13405708968639374}}, {"key": "liu2021generated", "year": "2021", "title": "Generated Knowledge Prompting For Commonsense Reasoning", "topic_distr": {"0": 0.0017090748297050595, "1": 0.0013950170250609517, "2": 0.06904628127813339, "3": 0.33047837018966675, "4": 0.000900949933566153, "5": 0.000805833435151726, "6": 0.0007288832566700876, "7": 0.07608941942453384, "8": 0.18083013594150543, "9": 0.0005665740463882685, "10": 0.0005274247378110886, "11": 0.0004933361196890473, "12": 0.00046338632819242775, "13": 0.0004368648515082896, "14": 0.0004132149333599955, "15": 0.00039199410821311176, "16": 0.30201295018196106, "17": 0.00035548224695958197, "18": 0.0003396634419914335, "19": 0.03201517090201378}}, {"key": "liu2021gpt", "year": "2021", "title": "GPT Understands, Too", "topic_distr": {"0": 0.13024668395519257, "1": 0.0017264971975237131, "2": 0.1712530106306076, "3": 0.0012639010092243552, "4": 0.0011147016193717718, "5": 0.0009970188839361072, "6": 0.0009018118144012988, "7": 0.0008232028922066092, "8": 0.0007571995374746621, "9": 0.0007009946857579052, "10": 0.20179271697998047, "11": 0.0006103808991611004, "12": 0.0005733254947699606, "13": 0.0005405117408372462, "14": 0.0005112508661113679, "15": 0.00048499531112611294, "16": 0.0004613048513419926, "17": 0.48441794514656067, "18": 0.0004202491254545748, "19": 0.00040234494372271}}, {"key": "liu2021mitigating", "year": "2021", "title": "Mitigating Political Bias In Language Models Through Reinforced Calibration", "topic_distr": {"0": 0.32977044582366943, "1": 0.11027418822050095, "2": 0.0013452913844957948, "3": 0.05984027311205864, "4": 0.053566642105579376, "5": 0.0009191625285893679, "6": 0.0008313902653753757, "7": 0.22549723088741302, "8": 0.0006980705657042563, "9": 0.0006462546880356967, "10": 0.031613487750291824, "11": 0.18146313726902008, "12": 0.0005285550723783672, "13": 0.0004983037360943854, "14": 0.00047132777399383485, "15": 0.0004471225256565958, "16": 0.00042528199264779687, "17": 0.00040547578828409314, "18": 0.00038743228651583195, "19": 0.00037092622369527817}}, {"key": "liu2021non", "year": "2021", "title": "Non-invasive Self-attention For Side Information Fusion In Sequential Recommendation", "topic_distr": {"0": 0.0011249864473938942, "1": 0.0009176611783914268, "2": 0.3128392696380615, "3": 0.0006718426011502743, "4": 0.3211064040660858, "5": 0.0005299791228026152, "6": 0.0004793706175405532, "7": 0.0004375849093776196, "8": 0.013114658184349537, "9": 0.0003726234135683626, "10": 0.1496133804321289, "11": 0.00032445642864331603, "12": 0.09058128297328949, "13": 0.00028731650672852993, "14": 0.00027176245930604637, "15": 0.00025780597934499383, "16": 0.10639851540327072, "17": 0.00023379293270409107, "18": 0.0002233892446383834, "19": 0.00021387201559264213}}, {"key": "liu2021omni", "year": "2021", "title": "OPT: Omni-perception Pre-trainer For Cross-modal Understanding And Generation", "topic_distr": {"0": 0.0019516864558681846, "1": 0.0015913124661892653, "2": 0.0013452209532260895, "3": 0.0011651130625978112, "4": 0.0010275852400809526, "5": 0.0009190974524244666, "6": 0.0008313315338455141, "7": 0.0007588661392219365, "8": 0.0006980212056078017, "9": 0.0006462089950218797, "10": 0.33167165517807007, "11": 0.0005626770434901118, "12": 0.0005285177030600607, "13": 0.0004982684622518718, "14": 0.07918570190668106, "15": 0.14574427902698517, "16": 0.00042525192839093506, "17": 0.00040544712101109326, "18": 0.42967283725738525, "19": 0.00037090000114403665}}, {"key": "liu2021p", "year": "2021", "title": "P-tuning V2: Prompt Tuning Can Be Comparable To Fine-tuning Universally Across Scales And Tasks", "topic_distr": {"0": 0.0016000373288989067, "1": 0.0013057553442195058, "2": 0.001103798858821392, "3": 0.0009560317848809063, "4": 0.0008431807509623468, "5": 0.0007541630184277892, "6": 0.0006821469287388027, "7": 0.0006226856494322419, "8": 0.0005727594834752381, "9": 0.0005302450736053288, "10": 0.0791999101638794, "11": 0.00046170319546945393, "12": 0.047156188637018204, "13": 0.16651523113250732, "14": 0.0003867194172926247, "15": 0.00036685928353108466, "16": 0.00034893935662694275, "17": 0.5029516220092773, "18": 0.0003178840852342546, "19": 0.19332414865493774}}, {"key": "liu2021pre", "year": "2021", "title": "Pre-train, Prompt, And Predict: A Systematic Survey Of Prompting Methods In Natural Language Processing", "topic_distr": {"0": 0.0010940921492874622, "1": 0.0008935497608035803, "2": 0.20238567888736725, "3": 0.1932823210954666, "4": 0.0005769176641479135, "5": 0.0005160100408829749, "6": 0.01941489614546299, "7": 0.06014459207653999, "8": 0.0003918908187188208, "9": 0.00036280183121562004, "10": 0.00033773283939808607, "11": 0.0003159044135827571, "12": 0.2360120415687561, "13": 0.0002797434281092137, "14": 0.00026459936634637415, "15": 0.00025101075880229473, "16": 0.00023874967882875353, "17": 0.28281170129776, "18": 0.00021750117593910545, "19": 0.00020823479280807078}}, {"key": "liu2021token", "year": "2021", "title": "A Token-level Reference-free Hallucination Detection Benchmark For Free-form Text Generation", "topic_distr": {"0": 0.2253182977437973, "1": 0.22654986381530762, "2": 0.11550136655569077, "3": 0.0008285950170829892, "4": 0.0007307850755751133, "5": 0.0006536328000947833, "6": 0.0005912163178436458, "7": 0.0005396812339313328, "8": 0.04723132401704788, "9": 0.00045956310350447893, "10": 0.00042780805961228907, "11": 0.00040015787817537785, "12": 0.00037586482358165085, "13": 0.00035435258178040385, "14": 0.0003351694904267788, "15": 0.29680851101875305, "16": 0.0003024255274794996, "17": 0.082052081823349, "18": 0.00027550995582714677, "19": 0.00026377217727713287}}, {"key": "liu2021topic", "year": "2021", "title": "Topic-aware Contrastive Learning For Abstractive Dialogue Summarization", "topic_distr": {"0": 0.001273933332413435, "1": 0.016813674941658974, "2": 0.09278056025505066, "3": 0.0007609996828250587, "4": 0.05388452112674713, "5": 0.050879284739494324, "6": 0.1332843005657196, "7": 0.17462430894374847, "8": 0.0004559156659524888, "9": 0.0004220742848701775, "10": 0.06480179727077484, "11": 0.0003675150219351053, "12": 0.0003452036762610078, "13": 0.00032544627902098, "14": 0.00030782807152718306, "15": 0.18236353993415833, "16": 0.056062571704387665, "17": 0.0930032730102539, "18": 0.07700099050998688, "19": 0.000242254973272793}}, {"key": "liu2021what", "year": "2021", "title": "What Makes Good In-context Examples For GPT-\\(3\\)?", "topic_distr": {"0": 0.0011252937838435173, "1": 0.10647307336330414, "2": 0.22831331193447113, "3": 0.31159427762031555, "4": 0.0005925361183471978, "5": 0.0005299791228026152, "6": 0.0004793706175405532, "7": 0.0004375849093776196, "8": 0.05997408926486969, "9": 0.0003726234135683626, "10": 0.0003468757786322385, "11": 0.00032445642864331603, "12": 0.00030475910170935094, "13": 0.00028731650672852993, "14": 0.00027176245930604637, "15": 0.05979118123650551, "16": 0.03867235407233238, "17": 0.10267075151205063, "18": 0.05442043021321297, "19": 0.033017970621585846}}, {"key": "liu2022few", "year": "2022", "title": "Few-shot Parameter-efficient Fine-tuning Is Better And Cheaper Than In-context Learning", "topic_distr": {"0": 0.0012223728699609637, "1": 0.02533126436173916, "2": 0.4794091284275055, "3": 0.0007310648798011243, "4": 0.0006447676569223404, "5": 0.0005766969989053905, "6": 0.000521627371199429, "7": 0.0004761582240462303, "8": 0.0004379804595373571, "9": 0.00040547034586779773, "10": 0.0003774530196096748, "11": 0.0003530574031174183, "12": 0.0003316237707622349, "13": 0.31404736638069153, "14": 0.0002957184624392539, "15": 0.00028053170535713434, "16": 0.0002668286324478686, "17": 0.1738150715827942, "18": 0.00024308111460413784, "19": 0.00023272493854165077}}, {"key": "liu2022integrating", "year": "2022", "title": "3DALL-E: Integrating Text-to-image AI In 3D Design Workflows", "topic_distr": {"0": 0.12417899072170258, "1": 0.0013578098732978106, "2": 0.0011478880187496543, "3": 0.0009942309698089957, "4": 0.00087687314953655, "5": 0.0007842970080673695, "6": 0.0007094033062458038, "7": 0.07432236522436142, "8": 0.0005956451059319079, "9": 0.49241960048675537, "10": 0.0005133289960213006, "11": 0.000480151386000216, "12": 0.00045100203715264797, "13": 0.0004251893551554531, "14": 0.00040217151399701834, "15": 0.0003815178060904145, "16": 0.00036288186674937606, "17": 0.11976548284292221, "18": 0.17951470613479614, "19": 0.00031650150776840746}}, {"key": "liu2022one", "year": "2022", "title": "Deplot: One-shot Visual Language Reasoning By Plot-to-table Translation", "topic_distr": {"0": 0.0014853019965812564, "1": 0.001212544273585081, "2": 0.0010249163024127483, "3": 0.4661690592765808, "4": 0.0007829235983081162, "5": 0.015815002843737602, "6": 0.0006333972560241818, "7": 0.0005781854270026088, "8": 0.06818338483572006, "9": 0.0004923511296510696, "10": 0.00045833049807697535, "11": 0.00042870757170021534, "12": 0.00040268132579512894, "13": 0.0003796342352870852, "14": 0.05090561509132385, "15": 0.00034064167994074523, "16": 0.000324002408888191, "17": 0.0003089129750151187, "18": 0.3128820061683655, "19": 0.07719239592552185}}, {"key": "liu2022prompting", "year": "2022", "title": "Qaner: Prompting Question Answering Models For Few-shot Named Entity Recognition", "topic_distr": {"0": 0.0015593809075653553, "1": 0.0012735360069200397, "2": 0.09502588212490082, "3": 0.0009321694960817695, "4": 0.0008221316384151578, "5": 0.0007353359251283109, "6": 0.000665117462631315, "7": 0.06109550595283508, "8": 0.1538507044315338, "9": 0.0005170078366063535, "10": 0.00048128346679732203, "11": 0.00045017703087069094, "12": 0.0004228473990224302, "13": 0.1624419391155243, "14": 0.00037706521106883883, "15": 0.0003577008319552988, "16": 0.0003402282891329378, "17": 0.5180452466011047, "18": 0.0003099482855759561, "19": 0.00029674332472495735}}, {"key": "liu2022worker", "year": "2022", "title": "WANLI: Worker And AI Collaboration For Natural Language Inference Dataset Creation", "topic_distr": {"0": 0.0012362266425043344, "1": 0.34460049867630005, "2": 0.3172203004360199, "3": 0.15011493861675262, "4": 0.0006511327810585499, "5": 0.0005823902902193367, "6": 0.0005267768865451217, "7": 0.00048085887101478875, "8": 0.0004423042119015008, "9": 0.08107782155275345, "10": 0.0003811792703345418, "11": 0.00035654279054142535, "12": 0.00033489757333882153, "13": 0.00031573002343066037, "14": 0.00029863780946470797, "15": 0.10037291049957275, "16": 0.00026946276193484664, "17": 0.00025691333576105535, "18": 0.00024548082728870213, "19": 0.00023502240946982056}}, {"key": "liu2023audioldm", "year": "2023", "title": "Audioldm 2: Learning Holistic Audio Generation With Self-supervised Pretraining", "topic_distr": {"0": 0.031329210847616196, "1": 0.0011195852421224117, "2": 0.10433518886566162, "3": 0.0008196194539777935, "4": 0.0007228701142594218, "5": 0.0006465534679591656, "6": 0.08906595408916473, "7": 0.0005338362534530461, "8": 0.0004910339484922588, "9": 0.0004545857955235988, "10": 0.0004231747006997466, "11": 0.025981858372688293, "12": 0.0003717940126080066, "13": 0.00035051474696956575, "14": 0.01960458792746067, "15": 0.1752515733242035, "16": 0.00029915012419223785, "17": 0.20521479845046997, "18": 0.30668434500694275, "19": 0.03629978001117706}}, {"key": "liu2023boosting", "year": "2023", "title": "ONCE: Boosting Content-based Recommendation With Both Open- And Closed-source Large Language Models", "topic_distr": {"0": 0.04429914802312851, "1": 0.03361707180738449, "2": 0.0008524269796907902, "3": 0.24227195978164673, "4": 0.202863410115242, "5": 0.0005824115360155702, "6": 0.000526796153280884, "7": 0.00048087647883221507, "8": 0.0004423204227350652, "9": 0.20598667860031128, "10": 0.12977688014507294, "11": 0.0003565558581613004, "12": 0.05444098636507988, "13": 0.0003157415776513517, "14": 0.0002986487525049597, "15": 0.026896914467215538, "16": 0.04009239003062248, "17": 0.00025692276540212333, "18": 0.00024548982037231326, "19": 0.015396359376609325}}, {"key": "liu2023chain", "year": "2023", "title": "Chain Of Hindsight Aligns Language Models With Feedback", "topic_distr": {"0": 0.1795225292444229, "1": 0.0008706328808329999, "2": 0.12226617336273193, "3": 0.15995380282402039, "4": 0.1794462502002716, "5": 0.010661029256880283, "6": 0.0004547608841676265, "7": 0.14249256253242493, "8": 0.0003818365221377462, "9": 0.00035349384415894747, "10": 0.00032906801789067686, "11": 0.17434318363666534, "12": 0.00028911352274008095, "13": 0.02726399153470993, "14": 0.0002578108396846801, "15": 0.00024457083782181144, "16": 0.00023262434115167707, "17": 0.00022179055667947978, "18": 0.00021192098211031407, "19": 0.00020289234817028046}}, {"key": "liu2023empowering", "year": "2023", "title": "LLM+P: Empowering Large Language Models With Optimal Planning Proficiency", "topic_distr": {"0": 0.12332163751125336, "1": 0.0008630460361018777, "2": 0.0007296266267076135, "3": 0.7101389765739441, "4": 0.000557363498955965, "5": 0.0004985204432159662, "6": 0.00045091594802215695, "7": 0.00041161058470606804, "8": 0.019324373453855515, "9": 0.00035050511360168457, "10": 0.0003262857790105045, "11": 0.10076364874839783, "12": 0.0002866690920200199, "13": 0.017050379887223244, "14": 0.0002556310791987926, "15": 0.023808959871530533, "16": 0.00023065753339324147, "17": 0.00021991535322740674, "18": 0.00021012923389207572, "19": 0.0002011769247474149}}, {"key": "liu2023g", "year": "2023", "title": "G-eval: NLG Evaluation Using GPT-4 With Better Human Alignment", "topic_distr": {"0": 0.32591167092323303, "1": 0.0010720118880271912, "2": 0.06934741139411926, "3": 0.10656784474849701, "4": 0.13519905507564545, "5": 0.020011967048048973, "6": 0.000560058921109885, "7": 0.14066696166992188, "8": 0.0004702492442447692, "9": 0.00043534391443245113, "10": 0.00040526239899918437, "11": 0.0003790693881455809, "12": 0.00035605658194981515, "13": 0.0003356780216563493, "14": 0.04860696941614151, "15": 0.1486039012670517, "16": 0.00028648757142946124, "17": 0.00027314526960253716, "18": 0.00026099043316207826, "19": 0.00024987125652842224}}, {"key": "liu2023git", "year": "2023", "title": "Git-mol: A Multi-modal Large Language Model For Molecular Science With Graph, Image, And Text", "topic_distr": {"0": 0.0019188937731087208, "1": 0.001566960709169507, "2": 0.0013244664296507835, "3": 0.0011471537873148918, "4": 0.001011736341752112, "5": 0.0009049236541613936, "6": 0.11441582441329956, "7": 0.0007471631979569793, "8": 0.0006872565718367696, "9": 0.12566335499286652, "10": 0.1329834759235382, "11": 0.0005539996782317758, "12": 0.0005203670589253306, "13": 0.0004905843525193632, "14": 0.021229790523648262, "15": 0.0004401960177347064, "16": 0.1621527075767517, "17": 0.0003991944540757686, "18": 0.43147680163383484, "19": 0.00036518010892905295}}, {"key": "liu2023improved", "year": "2023", "title": "Improved Baselines With Visual Instruction Tuning", "topic_distr": {"0": 0.002397730015218258, "1": 0.05142022296786308, "2": 0.09091755747795105, "3": 0.3852868378162384, "4": 0.0012647844851016998, "5": 0.0011312570422887802, "6": 0.03216642513871193, "7": 0.0009340386604890227, "8": 0.0008591486257500947, "9": 0.0007953763706609607, "10": 0.0007404171628877521, "11": 0.0006925623747520149, "12": 0.08380886912345886, "13": 0.0006132861017249525, "14": 0.0005800854996778071, "15": 0.0005502949352376163, "16": 0.0005234148120507598, "17": 0.1172451376914978, "18": 0.22761599719524384, "19": 0.00045651651453226805}}, {"key": "liu2023is", "year": "2023", "title": "Is Chatgpt A Good Recommender? A Preliminary Study", "topic_distr": {"0": 0.15323346853256226, "1": 0.000707312545273453, "2": 0.0005978842382319272, "3": 0.0005178401479497552, "4": 0.2554841935634613, "5": 0.031615935266017914, "6": 0.0003694876504596323, "7": 0.00033728021662682295, "8": 0.0003102375194430351, "9": 0.24300305545330048, "10": 0.0002673637354746461, "11": 0.0002500834234524518, "12": 0.10263071954250336, "13": 0.00022145683760754764, "14": 0.00020946815493516624, "15": 0.07277261465787888, "16": 0.00018900443683378398, "17": 0.13694554567337036, "18": 0.00017218320863321424, "19": 0.00016484755906276405}}, {"key": "liu2023jailbreaking", "year": "2023", "title": "Jailbreaking Chatgpt Via Prompt Engineering: An Empirical Study", "topic_distr": {"0": 0.1876598298549652, "1": 0.0012269391445443034, "2": 0.0010372024262323976, "3": 0.19933918118476868, "4": 0.0007923243683762848, "5": 0.0007086759433150291, "6": 0.0006410033674910665, "7": 0.02610553614795208, "8": 0.027801059186458588, "9": 0.1896626502275467, "10": 0.00046383432345464826, "11": 0.0004338556609582156, "12": 0.0802614614367485, "13": 0.0003841930301859975, "14": 0.0003633945307228714, "15": 0.00034473222331143916, "16": 0.00032789315446279943, "17": 0.2818615734577179, "18": 0.0002987109764944762, "19": 0.00028598474455066025}}, {"key": "liu2023large", "year": "2023", "title": "Chatcounselor: A Large Language Models For Mental Health Support", "topic_distr": {"0": 0.0020456432830542326, "1": 0.14843158423900604, "2": 0.0014114287914708257, "3": 0.3666585087776184, "4": 0.0010781825985759497, "5": 0.000964353559538722, "6": 0.06815315783023834, "7": 0.0007962323725223541, "8": 0.03344963118433952, "9": 0.18884381651878357, "10": 0.0006311774486675858, "11": 0.0005903830169700086, "12": 0.15397877991199493, "13": 0.030336247757077217, "14": 0.0004945007967762649, "15": 0.0004691054637078196, "16": 0.00044619114487431943, "17": 0.00042541115544736385, "18": 0.00040648053982295096, "19": 0.0003891629457939416}}, {"key": "liu2023lost", "year": "2023", "title": "Lost In The Middle: How Language Models Use Long Contexts", "topic_distr": {"0": 0.0016869682585820556, "1": 0.0013762805610895157, "2": 0.5289068222045898, "3": 0.0010076755424961448, "4": 0.0008887238800525665, "5": 0.0007948974962346256, "6": 0.000718991388566792, "7": 0.0006563184433616698, "8": 0.1797986626625061, "9": 0.025700096040964127, "10": 0.09607577323913574, "11": 0.0004866409581154585, "12": 0.00045709763071499765, "13": 0.0004309360811021179, "14": 0.0004076071490999311, "15": 0.0003866742772515863, "16": 0.0003677864733617753, "17": 0.020022083073854446, "18": 0.0003350538027007133, "19": 0.13949494063854218}}, {"key": "liu2023pre", "year": "2023", "title": "Pre-train, Prompt And Recommendation: A Comprehensive Survey Of Language Modelling Paradigm Adaptations In Recommender Systems", "topic_distr": {"0": 0.0013886544620618224, "1": 0.0011318270117044449, "2": 0.0009566390654072165, "3": 0.0008285723743028939, "4": 0.21854186058044434, "5": 0.0006536180735565722, "6": 0.0005912029882892966, "7": 0.0005396690685302019, "8": 0.0004963991232216358, "9": 0.00045955274254083633, "10": 0.05134192481637001, "11": 0.00040014885598793626, "12": 0.3016006350517273, "13": 0.11078276485204697, "14": 0.0003351619525346905, "15": 0.0003179495397489518, "16": 0.0003024187171831727, "17": 0.30879175662994385, "18": 0.00027550372760742903, "19": 0.0002637662400957197}}, {"key": "liu2023scaffolding", "year": "2023", "title": "Selenite: Scaffolding Online Sensemaking With Comprehensive Overviews Elicited From Large Language Models", "topic_distr": {"0": 0.1649002581834793, "1": 0.000998498871922493, "2": 0.14489798247814178, "3": 0.138238325715065, "4": 0.1724673956632614, "5": 0.0005767052643932402, "6": 0.0005216347053647041, "7": 0.0004761649470310658, "8": 0.05574440211057663, "9": 0.15135504305362701, "10": 0.00037745837471447885, "11": 0.0003530623798724264, "12": 0.1466001272201538, "13": 0.00031264801509678364, "14": 0.0002957226533908397, "15": 0.00028053566347807646, "16": 0.020873786881566048, "17": 0.00025440548779442906, "18": 0.00024308454885613173, "19": 0.00023272822727449238}}, {"key": "liu2023summary", "year": "2023", "title": "Summary Of Chatgpt-related Research And Perspective Towards The Future Of Large Language Models", "topic_distr": {"0": 0.028907831758260727, "1": 0.0010721824364736676, "2": 0.04062384366989136, "3": 0.05038635805249214, "4": 0.04104316234588623, "5": 0.0006192257860675454, "6": 0.0005600950098596513, "7": 0.0005112727521918714, "8": 0.0004702795413322747, "9": 0.3321707248687744, "10": 0.00040528850513510406, "11": 0.06826835870742798, "12": 0.4329363703727722, "13": 0.00033569964580237865, "14": 0.0003175263700541109, "15": 0.0003012196393683553, "16": 0.0002865060232579708, "17": 0.0002731628774199635, "18": 0.00026100725517608225, "19": 0.0002498873509466648}}, {"key": "liu2023text", "year": "2023", "title": "Text Matching Improves Sequential Recommendation By Reducing Popularity Biases", "topic_distr": {"0": 0.09593295305967331, "1": 0.0012730815215036273, "2": 0.09961099177598953, "3": 0.0009321257239207625, "4": 0.5033999681472778, "5": 0.0007353047258220613, "6": 0.000665089231915772, "7": 0.05241052806377411, "8": 0.000558437139261514, "9": 0.0005169858923181891, "10": 0.24068693816661835, "11": 0.0004501579387579113, "12": 0.0004228294419590384, "13": 0.0003986291994806379, "14": 0.00037704920396208763, "15": 0.0003576856688596308, "16": 0.00034021385363303125, "17": 0.0003243694081902504, "18": 0.00030993513064458966, "19": 0.0002967307227663696}}, {"key": "liu2023trustworthy", "year": "2023", "title": "Trustworthy Llms: A Survey And Guideline For Evaluating Large Language Models' Alignment", "topic_distr": {"0": 0.22392778098583221, "1": 0.0007328008068725467, "2": 0.0006193933659233153, "3": 0.3069736361503601, "4": 0.00047315406845882535, "5": 0.039049647748470306, "6": 0.00038278900319710374, "7": 0.00034942213096655905, "8": 0.0003214059106539935, "9": 0.110642209649086, "10": 0.00027698869234882295, "11": 0.000259086285950616, "12": 0.31460776925086975, "13": 0.00022942917712498456, "14": 0.00021700891375076026, "15": 0.00020586431492120028, "16": 0.00019580850494094193, "17": 0.0001866893144324422, "18": 0.00017838172789197415, "19": 0.00017078199016395956}}, {"key": "liu2023visual", "year": "2023", "title": "Visual Instruction Tuning", "topic_distr": {"0": 0.001600934541784227, "1": 0.13394205272197723, "2": 0.001103786053135991, "3": 0.39657890796661377, "4": 0.0008431666647084057, "5": 0.0007541495724581182, "6": 0.0006821347051300108, "7": 0.0006226744735613465, "8": 0.023907039314508438, "9": 0.0005302355857565999, "10": 0.0004935972392559052, "11": 0.0004616949299816042, "12": 0.00043366604950279, "13": 0.00040884557529352605, "14": 0.00038671251968480647, "15": 0.00036685270606540143, "16": 0.000348933128407225, "17": 0.11832669377326965, "18": 0.317903608083725, "19": 0.00030433558276854455}}, {"key": "liu2024datasets", "year": "2024", "title": "Datasets For Large Language Models: A Comprehensive Survey", "topic_distr": {"0": 0.001085455296561122, "1": 0.0008857293869368732, "2": 0.0007486726972274482, "3": 0.26854386925697327, "4": 0.04605479538440704, "5": 0.0005115223466418684, "6": 0.0004626762820407748, "7": 0.0004223457945045084, "8": 0.00038848264375701547, "9": 0.039864834398031235, "10": 0.00033479565172456205, "11": 0.00031315707019530237, "12": 0.6387108564376831, "13": 0.0002773105807136744, "14": 0.0002622982137836516, "15": 0.0002488277677912265, "16": 0.00023667332425247878, "17": 0.0002256509760627523, "18": 0.00021560961613431573, "19": 0.00020642382150981575}}, {"key": "liu2024linear", "year": "2024", "title": "Linrec: Linear Attention Mechanism For Long-term Sequential Recommender Systems", "topic_distr": {"0": 0.0013554198667407036, "1": 0.0011068523162975907, "2": 0.4961567521095276, "3": 0.0008105093729682267, "4": 0.2285996973514557, "5": 0.0006393680232577026, "6": 0.000578313774894923, "7": 0.00052790337940678, "8": 0.000485576776554808, "9": 0.0004495337198022753, "10": 0.0004184716963209212, "11": 0.0003914249537046999, "12": 0.00036766205448657274, "13": 0.26636824011802673, "14": 0.00032785485382191837, "15": 0.0003110177058260888, "16": 0.0002958255063276738, "17": 0.00028204830596223474, "18": 0.0002694972790777683, "19": 0.00025801570154726505}}, {"key": "liu2024understanding", "year": "2024", "title": "Understanding Llms: A Comprehensive Overview From Training To Inference", "topic_distr": {"0": 0.0016187092987820506, "1": 0.12278393656015396, "2": 0.0011180400615558028, "3": 0.0009683941607363522, "4": 0.0008540831040591002, "5": 0.0007639148971065879, "6": 0.0006909674848429859, "7": 0.0006307373405434191, "8": 0.0005801656516268849, "9": 0.25980639457702637, "10": 0.0004999886732548475, "11": 0.00046767329331487417, "12": 0.2603873014450073, "13": 0.3242635726928711, "14": 0.0003917199501302093, "15": 0.00037160300416871905, "16": 0.022835541516542435, "17": 0.00033699042978696525, "18": 0.0003219945356249809, "19": 0.00030827632872387767}}, {"key": "liventsev2023fully", "year": "2023", "title": "Fully Autonomous Programming With Large Language Models", "topic_distr": {"0": 0.1345333307981491, "1": 0.0009986580116674304, "2": 0.0008441681275144219, "3": 0.7244983315467834, "4": 0.0006448469939641654, "5": 0.000576767954044044, "6": 0.0005216911667957902, "7": 0.032659705728292465, "8": 0.0004380340687930584, "9": 0.00040551996789872646, "10": 0.0003774992364924401, "11": 0.032528359442949295, "12": 0.0003316643415018916, "13": 0.0003126818628516048, "14": 0.0002957546676043421, "15": 0.0002805660478770733, "16": 0.06902211159467697, "17": 0.00025443302001804113, "18": 0.00024311087327077985, "19": 0.00023275343119166791}}, {"key": "li\u00e9vin2022can", "year": "2022", "title": "Can Large Language Models Reason About Medical Questions?", "topic_distr": {"0": 0.0015994868008419871, "1": 0.03639514371752739, "2": 0.1792479008436203, "3": 0.6051671504974365, "4": 0.0008431517635472119, "5": 0.0007541373488493264, "6": 0.0006821235874667764, "7": 0.0006226643454283476, "8": 0.06799217313528061, "9": 0.0005302269710227847, "10": 0.0004935892065986991, "11": 0.0004616874211933464, "12": 0.07043655961751938, "13": 0.0004088389396201819, "14": 0.0003867062332574278, "15": 0.0003668467397801578, "16": 0.0326567143201828, "17": 0.00033267721300944686, "18": 0.00031787322950549424, "19": 0.0003043306351173669}}, {"key": "logan2019wife", "year": "2019", "title": "Barack's Wife Hillary: Using Knowledge-graphs For Fact-aware Language Modeling", "topic_distr": {"0": 0.0015597020974382758, "1": 0.12208442389965057, "2": 0.28290703892707825, "3": 0.0009320850949734449, "4": 0.0008220568997785449, "5": 0.0007352693355642259, "6": 0.0006650572177022696, "7": 0.16894225776195526, "8": 0.0005584102473221719, "9": 0.0005169609794393182, "10": 0.0004812398401554674, "11": 0.00045013625640422106, "12": 0.00042280906927771866, "13": 0.00039860999095253646, "14": 0.00037703104317188263, "15": 0.06392952799797058, "16": 0.35328638553619385, "17": 0.00032435377943329513, "18": 0.00030992020037956536, "19": 0.0002967164327856153}}, {"key": "logan2021cutting", "year": "2021", "title": "Cutting Down On Prompts And Parameters: Simple Few-shot Learning With Language Models", "topic_distr": {"0": 0.04283420369029045, "1": 0.0013764968607574701, "2": 0.09600362181663513, "3": 0.0010076947510242462, "4": 0.000888744427356869, "5": 0.0007949163555167615, "6": 0.0007190085598267615, "7": 0.0006563341594301164, "8": 0.0006037101265974343, "9": 0.0005588983767665923, "10": 0.000520279398187995, "11": 0.0004866525996476412, "12": 0.0004571085737552494, "13": 0.19864247739315033, "14": 0.0004076168988831341, "15": 0.00038668353226967156, "16": 0.0003677952627185732, "17": 0.3997100293636322, "18": 0.00033506183535791934, "19": 0.25324270129203796}}, {"key": "long2020generative", "year": "2020", "title": "Generative Imagination Elevates Machine Translation", "topic_distr": {"0": 0.0014508913736790419, "1": 0.0011840943479910493, "2": 0.27473607659339905, "3": 0.0008670292445458472, "4": 0.0007646849262528121, "5": 0.0006839544512331486, "6": 0.0006186426035128534, "7": 0.0005647168727591634, "8": 0.0005194385885260999, "9": 0.00048088206676766276, "10": 0.0004476539324969053, "11": 0.0004187210579402745, "12": 0.0003933010739274323, "13": 0.0003707908617798239, "14": 0.3674672842025757, "15": 0.03663323447108269, "16": 0.0003164549416396767, "17": 0.00030171702383086085, "18": 0.31150442361831665, "19": 0.00027600847533904016}}, {"key": "long2022vision", "year": "2022", "title": "Vision-and-language Pretrained Models: A Survey", "topic_distr": {"0": 0.09282560646533966, "1": 0.0015201448695734143, "2": 0.001284926082007587, "3": 0.0011129305930808187, "4": 0.0009815633529797196, "5": 0.0008779362542554736, "6": 0.000794100749772042, "7": 0.0007248807232826948, "8": 0.0006667607231065631, "9": 0.0006172688445076346, "10": 0.13553407788276672, "11": 0.0005374778411351144, "12": 0.4261668622493744, "13": 0.0004759537987411022, "14": 0.0004501877701841295, "15": 0.000427068182034418, "16": 0.00040620725485496223, "17": 0.0003872893867082894, "18": 0.2165423482656479, "19": 0.11766640841960907}}, {"key": "longpre2020how", "year": "2020", "title": "How Effective Is Task-agnostic Data Augmentation For Pretrained Transformers?", "topic_distr": {"0": 0.043400853872299194, "1": 0.3050984740257263, "2": 0.20437198877334595, "3": 0.0008671614341437817, "4": 0.0007647981401532888, "5": 0.0006840556743554771, "6": 0.0006187341641634703, "7": 0.000564800517167896, "8": 0.0005195155390538275, "9": 0.0004809532838407904, "10": 0.1917700320482254, "11": 0.0004187830782029778, "12": 0.0003933593106921762, "13": 0.0003708457516040653, "14": 0.00035076981293968856, "15": 0.0003327558806631714, "16": 0.0003165018279105425, "17": 0.00030176169821061194, "18": 0.028331845998764038, "19": 0.22004197537899017}}, {"key": "longpre2023flan", "year": "2023", "title": "The Flan Collection: Designing Data And Methods For Effective Instruction Tuning", "topic_distr": {"0": 0.05055547505617142, "1": 0.0013583427062258124, "2": 0.15650445222854614, "3": 0.1309637576341629, "4": 0.0008769677369855344, "5": 0.0007843823987059295, "6": 0.000709480547811836, "7": 0.0006476366543211043, "8": 0.0005957100074738264, "9": 0.0005514920339919627, "10": 0.0005133848753757775, "11": 0.09988053888082504, "12": 0.13199755549430847, "13": 0.0469498485326767, "14": 0.00040221528615802526, "15": 0.0003815593372564763, "16": 0.0003629213897511363, "17": 0.37531712651252747, "18": 0.00033062169677577913, "19": 0.00031653596670366824}}, {"key": "lopez2020simplifying", "year": "2020", "title": "Simplifying Paragraph-level Question Generation Via Transformer Language Models", "topic_distr": {"0": 0.0013716431567445397, "1": 0.11830385774374008, "2": 0.46973544359207153, "3": 0.0008195016416721046, "4": 0.019504260271787643, "5": 0.0006464600446633995, "6": 0.0005847286083735526, "7": 0.1242474839091301, "8": 0.16569070518016815, "9": 0.0004545200790744275, "10": 0.0004231134953442961, "11": 0.0003957667504437268, "12": 0.00037174028693698347, "13": 0.04683128371834755, "14": 0.00033149152295663953, "15": 0.0003144676156807691, "16": 0.00029910687590017915, "17": 0.00028517688042484224, "18": 0.0002724866208154708, "19": 0.04911673441529274}}, {"key": "lopezlira2023can", "year": "2023", "title": "Can Chatgpt Forecast Stock Price Movements? Return Predictability And Large Language Models", "topic_distr": {"0": 0.21666620671749115, "1": 0.0011444120900705457, "2": 0.0009673612657934427, "3": 0.2672871947288513, "4": 0.0007389594102278352, "5": 0.08004208654165268, "6": 0.0005978300468996167, "7": 0.036557719111442566, "8": 0.0005019634845666587, "9": 0.20289397239685059, "10": 0.00043259383528493345, "11": 0.00040463433833792806, "12": 0.00038006954127922654, "13": 0.09641601890325546, "14": 0.0003389189369045198, "15": 0.06142839044332504, "16": 0.03236476331949234, "17": 0.0002915665681939572, "18": 0.00027859199326485395, "19": 0.00026672292733564973}}, {"key": "louis2023interpretable", "year": "2023", "title": "Interpretable Long-form Legal Question Answering With Retrieval-augmented Large Language Models", "topic_distr": {"0": 0.001188655849546194, "1": 0.0009700400987640023, "2": 0.0008199539151974022, "3": 0.24847108125686646, "4": 0.000626355642452836, "5": 0.0005602285382337868, "6": 0.020214827731251717, "7": 0.0004625606816262007, "8": 0.17580683529376984, "9": 0.2756020128726959, "10": 0.0003666742122732103, "11": 0.00034297522506676614, "12": 0.27273571491241455, "13": 0.0003037154965568334, "14": 0.0002872736949939281, "15": 0.0002725206140894443, "16": 0.00025920887128449976, "17": 0.00024713698076084256, "18": 0.0002361395163461566, "19": 0.00022607907885685563}}, {"key": "lourie2021unicorn", "year": "2021", "title": "UNICORN On RAINBOW: A Universal Commonsense Reasoning Model On A New Multitask Benchmark", "topic_distr": {"0": 0.00118794827722013, "1": 0.0009700370137579739, "2": 0.2784073054790497, "3": 0.14114318788051605, "4": 0.0006263786926865578, "5": 0.0005602493765763938, "6": 0.0005067501333542168, "7": 0.0004625778237823397, "8": 0.00042548892088234425, "9": 0.023346468806266785, "10": 0.0003666878037620336, "11": 0.00034298794344067574, "12": 0.12992778420448303, "13": 0.07262852787971497, "14": 0.00028728434699587524, "15": 0.0002725307422224432, "16": 0.05559646338224411, "17": 0.29247915744781494, "18": 0.00023614826204720885, "19": 0.00022608744620811194}}, {"key": "lowphansirikul2021pretraining", "year": "2021", "title": "Wangchanberta: Pretraining Transformer-based Thai Language Models", "topic_distr": {"0": 0.05336528271436691, "1": 0.051791802048683167, "2": 0.1941978484392166, "3": 0.0009094136185012758, "4": 0.0008020632085390389, "5": 0.0007173867197707295, "6": 0.0006488822400569916, "7": 0.0005923205753788352, "8": 0.000544829061254859, "9": 0.0005043878918513656, "10": 0.30474141240119934, "11": 0.00043918838491663337, "12": 0.00041252587107010186, "13": 0.11001709848642349, "14": 0.0003678611828945577, "15": 0.09414272755384445, "16": 0.0003319234529044479, "17": 0.00031646512798033655, "18": 0.00030238257022574544, "19": 0.184854194521904}}, {"key": "lu2017best", "year": "2017", "title": "Best Of Both Worlds: Transferring Knowledge From Discriminative Learning To A Generative Visual Dialog Model", "topic_distr": {"0": 0.04838581383228302, "1": 0.016795795410871506, "2": 0.13819384574890137, "3": 0.0005483468412421644, "4": 0.17358845472335815, "5": 0.00043256254866719246, "6": 0.20386715233325958, "7": 0.025361334905028343, "8": 0.021565938368439674, "9": 0.00030413075000979006, "10": 0.12362798303365707, "11": 0.000264817412244156, "12": 0.0002487407182343304, "13": 0.00023450427397619933, "14": 0.00022180925589054823, "15": 0.0661870539188385, "16": 0.040305245667696, "17": 0.0872708335518837, "18": 0.052421048283576965, "19": 0.0001745597692206502}}, {"key": "lu2017practical", "year": "2017", "title": "A Practical Approach To Dialogue Response Generation In Closed Domains", "topic_distr": {"0": 0.002012446289882064, "1": 0.0016429758397862315, "2": 0.09001505374908447, "3": 0.001202763058245182, "4": 0.2972199320793152, "5": 0.060099340975284576, "6": 0.2249126136302948, "7": 0.0007833880372345448, "8": 0.09059064835309982, "9": 0.0006670905277132988, "10": 0.07598426938056946, "11": 0.10189289599657059, "12": 0.0005455961800180376, "13": 0.0005143695161677897, "14": 0.00048652381519787014, "15": 0.04978972673416138, "16": 0.0004389934765640646, "17": 0.0004185487050563097, "18": 0.0003999234759248793, "19": 0.0003828852204605937}}, {"key": "lu2018neural", "year": "2018", "title": "A Neural Interlingua For Multilingual Machine Translation", "topic_distr": {"0": 0.002399277873337269, "1": 0.0019584333058446646, "2": 0.14887389540672302, "3": 0.0014340282650664449, "4": 0.001264758873730898, "5": 0.0011312338756397367, "6": 0.0010232104687020183, "7": 0.060903400182724, "8": 0.000859130930621177, "9": 0.0007953599561005831, "10": 0.0007404019124805927, "11": 0.0006925481138750911, "12": 0.09380180388689041, "13": 0.0006132734124548733, "14": 0.681003212928772, "15": 0.0005502835847437382, "16": 0.0005234039854258299, "17": 0.0004990280140191317, "18": 0.00047682152944616973, "19": 0.0004565071139950305}}, {"key": "lu2019multi", "year": "2019", "title": "12-in-1: Multi-task Vision And Language Representation Learning", "topic_distr": {"0": 0.0016199437668547034, "1": 0.08250239491462708, "2": 0.42120805382728577, "3": 0.16722509264945984, "4": 0.0008541324059478939, "5": 0.0007639575633220375, "6": 0.0006910061347298324, "7": 0.0006307726143859327, "8": 0.05383121594786644, "9": 0.0005371315055526793, "10": 0.000500016612932086, "11": 0.0004676994576584548, "12": 0.05074772238731384, "13": 0.05601869896054268, "14": 0.0003917418362107128, "15": 0.0003716237551998347, "16": 0.00035347111406736076, "17": 0.0003370092890691012, "18": 0.14195294678211212, "19": 0.01899539865553379}}, {"key": "lu2019pretraining", "year": "2019", "title": "Vilbert: Pretraining Task-agnostic Visiolinguistic Representations For Vision-and-language Tasks", "topic_distr": {"0": 0.001755826990120113, "1": 0.036154672503471375, "2": 0.3268789052963257, "3": 0.0010503061348572373, "4": 0.0009263239917345345, "5": 0.0008285287185572088, "6": 0.0007494110614061356, "7": 0.0006840865244157612, "8": 0.08064252883195877, "9": 0.0005825307453051209, "10": 0.1479060798883438, "11": 0.0005072301719337702, "12": 0.00047643689322285354, "13": 0.0004491684667300433, "14": 0.00042485250742174685, "15": 0.00040303400601260364, "16": 0.0003833470691461116, "17": 0.00036549384822137654, "18": 0.3617703318595886, "19": 0.03706088289618492}}, {"key": "lu2020countering", "year": "2020", "title": "Countering Language Drift With Seeded Iterated Learning", "topic_distr": {"0": 0.02256726659834385, "1": 0.0013952546287328005, "2": 0.0011794391321018338, "3": 0.0010215308284386992, "4": 0.0009009488858282566, "5": 0.0008058328530751169, "6": 0.1663137972354889, "7": 0.0006653473246842623, "8": 0.0006120006437413394, "9": 0.0005665734643116593, "10": 0.0005274242139421403, "11": 0.35366368293762207, "12": 0.00046338586253114045, "13": 0.11712169647216797, "14": 0.02744722180068493, "15": 0.00039199370075948536, "16": 0.14396534860134125, "17": 0.00035548186860978603, "18": 0.000339663092745468, "19": 0.1596960723400116}}, {"key": "lu2021fantastically", "year": "2021", "title": "Fantastically Ordered Prompts And Where To Find Them: Overcoming Few-shot Prompt Order Sensitivity", "topic_distr": {"0": 0.18234877288341522, "1": 0.17998336255550385, "2": 0.348900705575943, "3": 0.0009942402830347419, "4": 0.0008768760017119348, "5": 0.0007843012572266161, "6": 0.0007094071479514241, "7": 0.0006475696573033929, "8": 0.000595648365560919, "9": 0.0005514349904842675, "10": 0.0005133317317813635, "11": 0.00048015397624112666, "12": 0.00045100448187440634, "13": 0.00042519165435805917, "14": 0.00040217366768047214, "15": 0.05254768207669258, "16": 0.00036288381670601666, "17": 0.13585130870342255, "18": 0.00033058749977499247, "19": 0.09224340319633484}}, {"key": "lu2021less", "year": "2021", "title": "Less Is More: Pre-train A Strong Text Encoder For Dense Retrieval Using A Weak Decoder", "topic_distr": {"0": 0.0015218445332720876, "1": 0.0012419072445482016, "2": 0.13505032658576965, "3": 0.0009093634434975684, "4": 0.018991034477949142, "5": 0.0007173475460149348, "6": 0.0006488468497991562, "7": 0.0005922882701270282, "8": 0.14654047787189484, "9": 0.0005043603596277535, "10": 0.43137073516845703, "11": 0.00043916446156799793, "12": 0.0004125033738091588, "13": 0.00038889411371201277, "14": 0.000367841130355373, "15": 0.1454654186964035, "16": 0.0003319053503219038, "17": 0.0003164478694088757, "18": 0.00030236609745770693, "19": 0.11388696730136871}}, {"key": "lu2021machine", "year": "2021", "title": "Codexglue: A Machine Learning Benchmark Dataset For Code Understanding And Generation", "topic_distr": {"0": 0.002077922224998474, "1": 0.0016974598402157426, "2": 0.0014348947443068027, "3": 0.19874951243400574, "4": 0.0010960819199681282, "5": 0.0009803639259189367, "6": 0.12790626287460327, "7": 0.0008094514487311244, "8": 0.0007445506635122001, "9": 0.0006892847013659775, "10": 0.0285504087805748, "11": 0.0006001846049912274, "12": 0.3794194459915161, "13": 0.00053148262668401, "14": 0.08074359595775604, "15": 0.1722741574048996, "16": 0.00045359882642515004, "17": 0.00043247384019196033, "18": 0.00041322896140627563, "19": 0.0003956238506361842}}, {"key": "lu2021new", "year": "2021", "title": "Iconqa: A New Benchmark For Abstract Diagram Understanding And Visual Language Reasoning", "topic_distr": {"0": 0.07006755471229553, "1": 0.0009342631092295051, "2": 0.0007898192852735519, "3": 0.06205609440803528, "4": 0.01609659753739834, "5": 0.0005396432825364172, "6": 0.0004881118074990809, "7": 0.00044556416105479, "8": 0.1406811624765396, "9": 0.00037941811024211347, "10": 0.08794598281383514, "11": 0.11206289380788803, "12": 0.13293875753879547, "13": 0.0002925556618720293, "14": 0.00027671799762174487, "15": 0.0002625070046633482, "16": 0.00024968438083305955, "17": 0.00023805609089322388, "18": 0.37303686141967773, "19": 0.00021777192887384444}}, {"key": "lu2021pretrained", "year": "2021", "title": "Pretrained Transformers As Universal Computation Engines", "topic_distr": {"0": 0.0017820806242525578, "1": 0.0014549550833180547, "2": 0.2345268875360489, "3": 0.0010652836645022035, "4": 0.0009395316010341048, "5": 0.0008403416723012924, "6": 0.000760096067097038, "7": 0.0006938402075320482, "8": 0.0006382089923135936, "9": 0.0005908364546485245, "10": 0.23965336382389069, "11": 0.0005144622409716249, "12": 0.00048322990187443793, "13": 0.10006248205900192, "14": 0.0004309100331738591, "15": 0.0004087804409209639, "16": 0.0003888128267135471, "17": 0.000370705034583807, "18": 0.08583929389715195, "19": 0.3285559415817261}}, {"key": "lu2022collaborative", "year": "2022", "title": "COTS: Collaborative Two-stream Vision-language Pre-training Model For Cross-modal Retrieval", "topic_distr": {"0": 0.001234845956787467, "1": 0.0010093434248119593, "2": 0.18937017023563385, "3": 0.0007384144701063633, "4": 0.11592550575733185, "5": 0.0005824952968396246, "6": 0.0005268718814477324, "7": 0.0004809456004295498, "8": 0.031107710674405098, "9": 0.00040954703581519425, "10": 0.10794581472873688, "11": 0.00035660711000673473, "12": 0.00033495796378701925, "13": 0.10478717088699341, "14": 0.0002986916806548834, "15": 0.10725151002407074, "16": 0.0002695113653317094, "17": 0.0002569596981629729, "18": 0.3121072053909302, "19": 0.02500571869313717}}, {"key": "lu2022controllable", "year": "2022", "title": "Quark: Controllable Text Generation With Reinforced Unlearning", "topic_distr": {"0": 0.05539270490407944, "1": 0.0013058262411504984, "2": 0.0011037590447813272, "3": 0.000955987605266273, "4": 0.04682144895195961, "5": 0.0007541296654380858, "6": 0.0006821166607551277, "7": 0.43779608607292175, "8": 0.0005727341049350798, "9": 0.0005302216159179807, "10": 0.0004935842007398605, "11": 0.3230935037136078, "12": 0.00043365458259359, "13": 0.0004088347777724266, "14": 0.00038670230424031615, "15": 0.00036684301448985934, "16": 0.00034892390249297023, "17": 0.0003326738369651139, "18": 0.00031786999898031354, "19": 0.12790237367153168}}, {"key": "lu2022dynamic", "year": "2022", "title": "Dynamic Prompt Learning Via Policy Gradient For Semi-structured Mathematical Reasoning", "topic_distr": {"0": 0.000925025437027216, "1": 0.13945703208446503, "2": 0.11555474251508713, "3": 0.4212280809879303, "4": 0.0004872035060543567, "5": 0.0004357672296464443, "6": 0.0003941550967283547, "7": 0.0003597974427975714, "8": 0.03390609100461006, "9": 0.000306383881252259, "10": 0.00028521326021291316, "11": 0.12972860038280487, "12": 0.0002505834854673594, "13": 0.00023624156892765313, "14": 0.00022345251636579633, "15": 0.00021197700698394328, "16": 0.04873751476407051, "17": 0.08662720769643784, "18": 0.020469069480895996, "19": 0.00017585298337507993}}, {"key": "lu2022ernie", "year": "2022", "title": "Ernie-search: Bridging Cross-encoder With Dual-encoder Via Self On-the-fly Distillation For Dense Passage Retrieval", "topic_distr": {"0": 0.001619521644897759, "1": 0.0013225326547399163, "2": 0.1451495736837387, "3": 0.0009684117394499481, "4": 0.0643729493021965, "5": 0.0007639279356226325, "6": 0.0006909791845828295, "7": 0.0006307480507530272, "8": 0.13311006128787994, "9": 0.0005371106090024114, "10": 0.03017507493495941, "11": 0.00046768123866058886, "12": 0.0004392889386508614, "13": 0.2916763126850128, "14": 0.00039172658580355346, "15": 0.0003716092905960977, "16": 0.15630008280277252, "17": 0.17038212716579437, "18": 0.00032199997804127634, "19": 0.0003082815674133599}}, {"key": "lu2022learn", "year": "2022", "title": "Learn To Explain: Multimodal Reasoning Via Thought Chains For Science Question Answering", "topic_distr": {"0": 0.001006011269055307, "1": 0.07723049074411392, "2": 0.000694276939611882, "3": 0.40697988867759705, "4": 0.0005303515936248004, "5": 0.1269388645887375, "6": 0.00042906272574327886, "7": 0.0003916622663382441, "8": 0.19177794456481934, "9": 0.04842197895050049, "10": 0.0003104726492892951, "11": 0.00029040611116215587, "12": 0.00027277597109787166, "13": 0.00025716389063745737, "14": 0.0002432421752018854, "15": 0.00023075036006048322, "16": 0.00021947894128970802, "17": 0.00020925737044308335, "18": 0.14337453246116638, "19": 0.00019142708333674818}}, {"key": "lu2022prompt", "year": "2022", "title": "Prompt Distribution Learning", "topic_distr": {"0": 0.05930529907345772, "1": 0.0013402346521615982, "2": 0.14160647988319397, "3": 0.0009811656782403588, "4": 0.0008653485565446317, "5": 0.0007739904103800654, "6": 0.0007000808836892247, "7": 0.000639056321233511, "8": 0.0005878176307305694, "9": 0.0005441855173557997, "10": 0.000506583193782717, "11": 0.0004738416173495352, "12": 0.00044507530401460826, "13": 0.00041960185626521707, "14": 0.00039688649121671915, "15": 0.0003765041765291244, "16": 0.00035811314592137933, "17": 0.57282555103302, "18": 0.2165418267250061, "19": 0.0003123423084616661}}, {"key": "lu2022retrieval", "year": "2022", "title": "Reacc: A Retrieval-augmented Code Completion Framework", "topic_distr": {"0": 0.03571002185344696, "1": 0.0011843143729493022, "2": 0.1849544644355774, "3": 0.0008670835522934794, "4": 0.0007647320744581521, "5": 0.0006839956040494144, "6": 0.6277025938034058, "7": 0.0005647508078254759, "8": 0.02338813804090023, "9": 0.00048091099597513676, "10": 0.08160369843244553, "11": 0.00041874623275361955, "12": 0.00039332470623776317, "13": 0.00037081315531395376, "14": 0.0003507389919832349, "15": 0.0003327266313135624, "16": 0.03936285898089409, "17": 0.0003017351555172354, "18": 0.0002883081033360213, "19": 0.0002760250645224005}}, {"key": "lu2022unified", "year": "2022", "title": "Unified-io: A Unified Model For Vision, Language, And Multi-modal Tasks", "topic_distr": {"0": 0.0014186151092872024, "1": 0.0011579557321965694, "2": 0.1582721769809723, "3": 0.0008475109934806824, "4": 0.0007474688463844359, "5": 0.0006685553235001862, "6": 0.0006047139759175479, "7": 0.09032396972179413, "8": 0.000507743505295366, "9": 0.020979825407266617, "10": 0.12098702043294907, "11": 0.000409293599659577, "12": 0.08566903322935104, "13": 0.00036244254442863166, "14": 0.00034282152773812413, "15": 0.0003252157475799322, "16": 0.00030933000380173326, "17": 0.00029492389876395464, "18": 0.5155016183853149, "19": 0.00026979416725225747}}, {"key": "lu2023event", "year": "2023", "title": "Event Extraction As Question Generation And Answering", "topic_distr": {"0": 0.001559418044053018, "1": 0.0012730711605399847, "2": 0.4332156777381897, "3": 0.0009321183897554874, "4": 0.0008220894378609955, "5": 0.0007352976826950908, "6": 0.0006650830619037151, "7": 0.0006071091629564762, "8": 0.18446992337703705, "9": 0.0005169810610823333, "10": 0.0004812585248146206, "11": 0.0004501537187024951, "12": 0.00042282548383809626, "13": 0.00039862547419033945, "14": 0.00037704568239860237, "15": 0.11961966753005981, "16": 0.0667327269911766, "17": 0.18611423671245575, "18": 0.000309932220261544, "19": 0.0002967279579024762}}, {"key": "lu2023llama", "year": "2023", "title": "Llama-reviewer: Advancing Code Review Automation With Large Language Models Through Parameter-efficient Fine-tuning", "topic_distr": {"0": 0.0012858386617153883, "1": 0.0010498421033844352, "2": 0.0008875570492818952, "3": 0.43201181292533875, "4": 0.0006780032999813557, "5": 0.000606423884164542, "6": 0.061078742146492004, "7": 0.0005007025902159512, "8": 0.00046055688289925456, "9": 0.00042637099977582693, "10": 0.00039690948324277997, "11": 0.0003712563484441489, "12": 0.23731213808059692, "13": 0.08161406964063644, "14": 0.00031096176826395094, "15": 0.00029499217635020614, "16": 0.04834337905049324, "17": 0.1318700909614563, "18": 0.0002556111430749297, "19": 0.00024472113000229}}, {"key": "lu2023open", "year": "2023", "title": "RTLLM: An Open-source Benchmark For Design RTL Generation With Large Language Model", "topic_distr": {"0": 0.0012726967688649893, "1": 0.0010391698451712728, "2": 0.0008784854435361922, "3": 0.7026097178459167, "4": 0.0006710669258609414, "5": 0.06984033435583115, "6": 0.0005429034936241806, "7": 0.0729154571890831, "8": 0.00045584479812532663, "9": 0.00042200868483632803, "10": 0.00039284859667532146, "11": 0.0003674579202197492, "12": 0.000345150037901476, "13": 0.0003253956965636462, "14": 0.0003077802248299122, "15": 0.0002919740218203515, "16": 0.0002777120389509946, "17": 0.14654876291751862, "18": 0.0002529959019739181, "19": 0.0002422173274680972}}, {"key": "lu2023plug", "year": "2023", "title": "Chameleon: Plug-and-play Compositional Reasoning With Large Language Models", "topic_distr": {"0": 0.0013265706365928054, "1": 0.0010834906715899706, "2": 0.0009158924221992493, "3": 0.6550297737121582, "4": 0.0006996446754783392, "5": 0.0006257796776480973, "6": 0.019631514325737953, "7": 0.0005166837363503873, "8": 0.0004752566746901721, "9": 0.04917000234127045, "10": 0.000409577798563987, "11": 0.15905709564685822, "12": 0.0003598480252549052, "13": 0.00033925246680155396, "14": 0.00032088684383779764, "15": 0.00030440755654126406, "16": 0.08405391126871109, "17": 0.0002760538482107222, "18": 0.02515185810625553, "19": 0.0002525320160202682}}, {"key": "lu2024llava", "year": "2024", "title": "Llava-mr: Large Language-and-vision Assistant For Video Moment Retrieval", "topic_distr": {"0": 0.0017112689092755318, "1": 0.0013951669679954648, "2": 0.001179454498924315, "3": 0.1355733871459961, "4": 0.0009009361965581775, "5": 0.0008058210369199514, "6": 0.0007288720225915313, "7": 0.0006653377786278725, "8": 0.052997466176748276, "9": 0.0005665653734467924, "10": 0.08100082725286484, "11": 0.0004933285526931286, "12": 0.0004633792268577963, "13": 0.11543237417936325, "14": 0.0004132085887249559, "15": 0.04237234592437744, "16": 0.00037284070276655257, "17": 0.0003554767754394561, "18": 0.5622467398643494, "19": 0.0003251874877605587}}, {"key": "lukovnikov2020pretrained", "year": "2020", "title": "Pretrained Transformers For Simple Question Answering Over Knowledge Graphs", "topic_distr": {"0": 0.0024470121134072542, "1": 0.001996582141146064, "2": 0.34025195240974426, "3": 0.001462001702748239, "4": 0.0012894232058897614, "5": 0.0011532912030816078, "6": 0.0010431617265567183, "7": 0.0009522315231151879, "8": 0.13920478522777557, "9": 0.0008108683978207409, "10": 0.3048713505268097, "11": 0.0007060518255457282, "12": 0.0006631884025409818, "13": 0.0006252314196899533, "14": 0.0005913841887377203, "15": 0.0005610133521258831, "16": 0.09903477877378464, "17": 0.0005087584140710533, "18": 0.0004861188936047256, "19": 0.1013408675789833}}, {"key": "lund2023chatgpt", "year": "2023", "title": "Chatgpt And A New Academic Reality: Artificial Intelligence-written Research Papers And The Ethics Of The Large Language Models In Scholarly Publishing", "topic_distr": {"0": 0.13520140945911407, "1": 0.0016166407149285078, "2": 0.0013665176229551435, "3": 0.0011835924815386534, "4": 0.001043882453814149, "5": 0.0009336753864772618, "6": 0.0008445172570645809, "7": 0.000770902493968606, "8": 0.0007090925355441868, "9": 0.6996647119522095, "10": 0.06961020082235336, "11": 0.0005716016748920083, "12": 0.0005369004793465137, "13": 0.000506171490997076, "14": 0.0004787696525454521, "15": 0.00045418221270665526, "16": 0.0004319968575146049, "17": 0.08330488950014114, "18": 0.00039354953332804143, "19": 0.00037678281660191715}}, {"key": "luo2018learning", "year": "2018", "title": "Learning Personalized End-to-end Goal-oriented Dialog", "topic_distr": {"0": 0.11264681071043015, "1": 0.0016695730155333877, "2": 0.0014114018995314837, "3": 0.0012224349193274975, "4": 0.5127273201942444, "5": 0.0009643153753131628, "6": 0.16489723324775696, "7": 0.0007962006493471563, "8": 0.0007323622703552246, "9": 0.00067800102988258, "10": 0.03538696467876434, "11": 0.0005903595010749996, "12": 0.0005545195890590549, "13": 0.0005227821529842913, "14": 0.0004944810643792152, "15": 0.00046908677904866636, "16": 0.16301512718200684, "17": 0.0004253941879142076, "18": 0.000406464358093217, "19": 0.0003891474334523082}}, {"key": "luo2019curiosity", "year": "2019", "title": "Curiosity-driven Reinforcement Learning For Diverse Visual Paragraph Generation", "topic_distr": {"0": 0.030048664659261703, "1": 0.0008280701003968716, "2": 0.26257017254829407, "3": 0.04601380228996277, "4": 0.04581131413578987, "5": 0.00047829074901528656, "6": 0.0004326178750488907, "7": 0.14382952451705933, "8": 0.0003632443258538842, "9": 0.00033628169330768287, "10": 0.0003130451950710267, "11": 0.28520748019218445, "12": 0.00027503614546731114, "13": 0.013769017532467842, "14": 0.0002452576591167599, "15": 0.0002326623216504231, "16": 0.04743832349777222, "17": 0.00021099124569445848, "18": 0.12140318751335144, "19": 0.0001930132129928097}}, {"key": "luo2021automatic", "year": "2021", "title": "Newsclippings: Automatic Generation Of Out-of-context Multimodal Media", "topic_distr": {"0": 0.0931444764137268, "1": 0.07992831617593765, "2": 0.0011181858135387301, "3": 0.0009684849064797163, "4": 0.0008541613933630288, "5": 0.0007639844552613795, "6": 0.0006910301744937897, "7": 0.13433600962162018, "8": 0.0005802182131446898, "9": 0.0562712736427784, "10": 0.0005000340170226991, "11": 0.0004677157266996801, "12": 0.0004393213312141597, "13": 0.00041417719330638647, "14": 0.000391755485907197, "15": 0.09959528595209122, "16": 0.055869877338409424, "17": 0.0003370209888089448, "18": 0.39990517497062683, "19": 0.07342347502708435}}, {"key": "luo2022generative", "year": "2022", "title": "Biogpt: Generative Pre-trained Transformer For Biomedical Text Generation And Mining", "topic_distr": {"0": 0.0014503784477710724, "1": 0.06400395184755325, "2": 0.0010011629201471806, "3": 0.0008671380346640944, "4": 0.0007647762540727854, "5": 0.0006840362912043929, "6": 0.0006187165854498744, "7": 0.000564784393645823, "8": 0.0005195006961002946, "9": 0.09612500667572021, "10": 0.26753467321395874, "11": 0.0004187711456324905, "12": 0.0003933481057174504, "13": 0.0003708351869136095, "14": 0.0003507598303258419, "15": 0.434890478849411, "16": 0.0003164928057231009, "17": 0.12856082618236542, "18": 0.00028832521638832986, "19": 0.0002760414790827781}}, {"key": "luo2023bilingual", "year": "2023", "title": "Taiyi: A Bilingual Fine-tuned Large Language Model For Diverse Biomedical Tasks", "topic_distr": {"0": 0.0164971761405468, "1": 0.0008559197303839028, "2": 0.0007235549855977297, "3": 0.29195383191108704, "4": 0.0005527193425223231, "5": 0.0004943666281178594, "6": 0.02857285365462303, "7": 0.0004081809311173856, "8": 0.049804557114839554, "9": 0.00034758460242301226, "10": 0.0003235671028960496, "11": 0.0003026542253792286, "12": 0.043884433805942535, "13": 0.00026800998602993786, "14": 0.09263055771589279, "15": 0.2764780521392822, "16": 0.00022873564739711583, "17": 0.19526535272598267, "18": 0.00020837837655562907, "19": 0.00019950067508034408}}, {"key": "luo2023chatgpt", "year": "2023", "title": "Chatgpt As A Factual Inconsistency Evaluator For Text Summarization", "topic_distr": {"0": 0.09901236742734909, "1": 0.02470601722598076, "2": 0.14131754636764526, "3": 0.22280894219875336, "4": 0.14374756813049316, "5": 0.000516033498570323, "6": 0.0004667566390708089, "7": 0.16003839671611786, "8": 0.04063204675912857, "9": 0.12490735203027725, "10": 0.0003377482062205672, "11": 0.00031591879087500274, "12": 0.0002967397740576416, "13": 0.00027975617558695376, "14": 0.00026461141533218324, "15": 0.00025102216750383377, "16": 0.039447762072086334, "17": 0.00022764099412597716, "18": 0.00021751107124146074, "19": 0.00020824428065679967}}, {"key": "luo2023cheap", "year": "2023", "title": "Cheap And Quick: Efficient Vision-language Instruction Tuning For Large Language Models", "topic_distr": {"0": 0.0010138091165572405, "1": 0.0008279965841211379, "2": 0.06261693686246872, "3": 0.2697570323944092, "4": 0.0005347080295905471, "5": 0.0121069410815835, "6": 0.0004325868794694543, "7": 0.0003948792291339487, "8": 0.0003632183070294559, "9": 0.07886619865894318, "10": 0.00031302275601774454, "11": 0.00029279140289872885, "12": 0.0002750164130702615, "13": 0.18727678060531616, "14": 0.00024524008040316403, "15": 0.00023264565970748663, "16": 0.00022128164710011333, "17": 0.11192609369754791, "18": 0.2721098065376282, "19": 0.00019299938867334276}}, {"key": "luo2023empirical", "year": "2023", "title": "An Empirical Study Of Catastrophic Forgetting In Large Language Models During Continual Fine-tuning", "topic_distr": {"0": 0.20330345630645752, "1": 0.001039187889546156, "2": 0.057823337614536285, "3": 0.40100884437561035, "4": 0.0006710884626954794, "5": 0.0006002386217005551, "6": 0.0005429208977147937, "7": 0.0004955956828780472, "8": 0.00045585946645587683, "9": 0.00042202224722132087, "10": 0.0003928612277377397, "11": 0.00036746973637491465, "12": 0.00034516112646088004, "13": 0.0003254061739426106, "14": 0.0003077901201322675, "15": 0.000291983422357589, "16": 0.24232523143291473, "17": 0.08878634124994278, "18": 0.00025300405104644597, "19": 0.00024222511274274439}}, {"key": "luo2023generate", "year": "2023", "title": "Chatkbqa: A Generate-then-retrieve Framework For Knowledge Base Question Answering With Fine-tuned Large Language Models", "topic_distr": {"0": 0.0014841720694676042, "1": 0.0012123283231630921, "2": 0.1095563992857933, "3": 0.2616980969905853, "4": 0.0007829013629816473, "5": 0.0007002475904300809, "6": 0.0006333797937259078, "7": 0.0005781694198958576, "8": 0.2483678013086319, "9": 0.0004923375672660768, "10": 0.00045831783791072667, "11": 0.0004286957555450499, "12": 0.00040267020813189447, "13": 0.00037962375790812075, "14": 0.00035907261190004647, "15": 0.034268900752067566, "16": 0.33731022477149963, "17": 0.0003089044475927949, "18": 0.0002951583592221141, "19": 0.0002825834963005036}}, {"key": "luo2023open", "year": "2023", "title": "Biomedgpt: Open Multimodal Generative Pre-trained Transformer For Biomedicine", "topic_distr": {"0": 0.0011147846234962344, "1": 0.000909556751139462, "2": 0.000768710917327553, "3": 0.1849599927663803, "4": 0.01281779259443283, "5": 0.0005252132541500032, "6": 0.00047505972906947136, "7": 0.00043364978046156466, "8": 0.03591258078813553, "9": 0.00036927248584106565, "10": 0.09266114979982376, "11": 0.00032153865322470665, "12": 0.28769752383232117, "13": 0.000284732726868242, "14": 0.000269318581558764, "15": 0.17010121047496796, "16": 0.00024300783115904778, "17": 0.00023169047199189663, "18": 0.20969124138355255, "19": 0.00021194871806073934}}, {"key": "luo2023reasoning", "year": "2023", "title": "Reasoning On Graphs: Faithful And Interpretable Large Language Model Reasoning", "topic_distr": {"0": 0.04297443851828575, "1": 0.0009175868472084403, "2": 0.0007756126578897238, "3": 0.4327363967895508, "4": 0.0005924853612668812, "5": 0.0005299342446960509, "6": 0.0004793299303855747, "7": 0.09912721812725067, "8": 0.012888438068330288, "9": 0.0003725918068084866, "10": 0.00034684635465964675, "11": 0.0774347111582756, "12": 0.00030473325750790536, "13": 0.0002872921177186072, "14": 0.00027173940907232463, "15": 0.0002577841223683208, "16": 0.3290318548679352, "17": 0.0002337730984436348, "18": 0.00022337029804475605, "19": 0.00021385388390626758}}, {"key": "lynch2022interactive", "year": "2022", "title": "Interactive Language: Talking To Robots In Real Time", "topic_distr": {"0": 0.0015036771073937416, "1": 0.08299604803323746, "2": 0.12141916900873184, "3": 0.0008985507301986217, "4": 0.08079123497009277, "5": 0.0007088163401931524, "6": 0.0006411303766071796, "7": 0.0005852443864569068, "8": 0.000538320280611515, "9": 0.0004983622347936034, "10": 0.029209168627858162, "11": 0.43108847737312317, "12": 0.18913039565086365, "13": 0.0003842691658064723, "14": 0.0003634665335994214, "15": 0.00034480055910535157, "16": 0.0003279581433162093, "17": 0.0003126844821963459, "18": 0.05797221511602402, "19": 0.0002860414097085595}}, {"key": "lyu2023faithful", "year": "2023", "title": "Faithful Chain-of-thought Reasoning", "topic_distr": {"0": 0.0015581137267872691, "1": 0.0012728209840133786, "2": 0.0010761091252788901, "3": 0.660515546798706, "4": 0.0008220219169743359, "5": 0.07060697674751282, "6": 0.0006650294526480138, "7": 0.09021864086389542, "8": 0.10569876432418823, "9": 0.0005169393843971193, "10": 0.0004812197294086218, "11": 0.00045011742622591555, "12": 0.0004227914032526314, "13": 0.0003985933435615152, "14": 0.01836915872991085, "15": 0.0003576534800231457, "16": 0.0003401832655072212, "17": 0.00032434024615213275, "18": 0.0003099072491750121, "19": 0.04559510573744774}}, {"key": "lyu2023llm", "year": "2023", "title": "Llm-rec: Personalized Recommendation Via Prompting Large Language Models", "topic_distr": {"0": 0.0012109270319342613, "1": 0.07574556767940521, "2": 0.0008358453051187098, "3": 0.6185796856880188, "4": 0.27233487367630005, "5": 0.0005710826953873038, "6": 0.0005165491602383554, "7": 0.0004715226823464036, "8": 0.0004337166028562933, "9": 0.00040152299334295094, "10": 0.00037377842818386853, "11": 0.00034962029894813895, "12": 0.0003283953119534999, "13": 0.000309599912725389, "14": 0.00029283956973813474, "15": 0.00027780066011473536, "16": 0.02624352090060711, "17": 0.0002519252011552453, "18": 0.00024071465304587036, "19": 0.00023045930720400065}}, {"key": "lyu2023macaw", "year": "2023", "title": "Macaw-llm: Multi-modal Language Modeling With Image, Audio, Video, And Text Integration", "topic_distr": {"0": 0.04693492129445076, "1": 0.001050133490934968, "2": 0.000887595524545759, "3": 0.16436703503131866, "4": 0.0006780277471989393, "5": 0.012130978517234325, "6": 0.0005485343863256276, "7": 0.0005007198196835816, "8": 0.0004605727444868535, "9": 0.04189997911453247, "10": 0.03746606037020683, "11": 0.0003712691250257194, "12": 0.08286424726247787, "13": 0.0003287706640549004, "14": 0.000310972478473559, "15": 0.00029500233358703554, "16": 0.0002805924159474671, "17": 0.00026752467965707183, "18": 0.5875588655471802, "19": 0.02079825848340988}}, {"key": "lyu2023translating", "year": "2023", "title": "Translating Radiology Reports Into Plain Language Using Chatgpt And GPT-4 With Prompt Learning: Promising Results, Limitations, And Potential", "topic_distr": {"0": 0.0013276578392833471, "1": 0.0409248024225235, "2": 0.0009160032495856285, "3": 0.44703471660614014, "4": 0.03279688209295273, "5": 0.0006258411449380219, "6": 0.048994436860084534, "7": 0.0005167346098460257, "8": 0.00047530350275337696, "9": 0.4067919850349426, "10": 0.0004096181655768305, "11": 0.00038314363337121904, "12": 0.000359883502824232, "13": 0.016735607758164406, "14": 0.0003209184797015041, "15": 0.00030443756259046495, "16": 0.00028956675669178367, "17": 0.00027608106029219925, "18": 0.0002637955767568201, "19": 0.0002525568997953087}}, {"key": "lyu2024crud", "year": "2024", "title": "CRUD-RAG: A Comprehensive Chinese Benchmark For Retrieval-augmented Generation Of Large Language Models", "topic_distr": {"0": 0.0009181822533719242, "1": 0.0007489186245948076, "2": 0.000633096438832581, "3": 0.28068825602531433, "4": 0.055169783532619476, "5": 0.00043255218770354986, "6": 0.00039124712930060923, "7": 0.10329223424196243, "8": 0.09513445943593979, "9": 0.10085411369800568, "10": 0.00028310902416706085, "11": 0.00026481106760911644, "12": 0.18528424203395844, "13": 0.00023449864238500595, "14": 0.00022180392988957465, "15": 0.00021041308355052024, "16": 0.17469055950641632, "17": 0.00019081438949797302, "18": 0.00018232323054689914, "19": 0.00017455557826906443}}, {"key": "l\u00e1la2023retrieval", "year": "2023", "title": "Paperqa: Retrieval-augmented Generative Agent For Scientific Research", "topic_distr": {"0": 0.08905959874391556, "1": 0.001028772909194231, "2": 0.06383536756038666, "3": 0.07131438702344894, "4": 0.0006643077940680087, "5": 0.027701236307621002, "6": 0.033480383455753326, "7": 0.0004905888927169144, "8": 0.2249329835176468, "9": 0.2355407178401947, "10": 0.00038889230927452445, "11": 0.14908619225025177, "12": 0.10053347796201706, "13": 0.0003221187216695398, "14": 0.00030468066688627005, "15": 0.0002890336327254772, "16": 0.00027491527725942433, "17": 0.00026211192016489804, "18": 0.00025044806534424424, "19": 0.00023977801902219653}}, {"key": "ma2018generating", "year": "2018", "title": "Livebot: Generating Live Video Comments Based On Visual And Textual Contexts", "topic_distr": {"0": 0.08773616701364517, "1": 0.001395247527398169, "2": 0.1504860520362854, "3": 0.0010214955545961857, "4": 0.0009009168716147542, "5": 0.0008058028179220855, "6": 0.21958065032958984, "7": 0.0006653227028436959, "8": 0.0006119780009612441, "9": 0.06832540035247803, "10": 0.0005274046561680734, "11": 0.0710882619023323, "12": 0.000463368691271171, "13": 0.0004368482332210988, "14": 0.00041319921729154885, "15": 0.00039197917794808745, "16": 0.0003728322626557201, "17": 0.0003554687136784196, "18": 0.3940964639186859, "19": 0.00032518012449145317}}, {"key": "ma2019improving", "year": "2019", "title": "Improving Question Generation With Sentence-level Semantic Matching And Answer Position Inferring", "topic_distr": {"0": 0.0018615818116813898, "1": 0.001520246616564691, "2": 0.37411174178123474, "3": 0.001113079721108079, "4": 0.0009816818637773395, "5": 0.0008780416683293879, "6": 0.0007941960939206183, "7": 0.15621726214885712, "8": 0.3060249388217926, "9": 0.0006173429428599775, "10": 0.0005746855749748647, "11": 0.0005375423934310675, "12": 0.04940744489431381, "13": 0.0004760109295602888, "14": 0.00045024181599728763, "15": 0.0004271194338798523, "16": 0.1028950959444046, "17": 0.0003873358655255288, "18": 0.000370099616702646, "19": 0.00035433194716461003}}, {"key": "ma2019tensorized", "year": "2019", "title": "A Tensorized Transformer For Language Modeling", "topic_distr": {"0": 0.00186178891453892, "1": 0.0015198506880551577, "2": 0.34912997484207153, "3": 0.0011129326885566115, "4": 0.0009815640514716506, "5": 0.0008779366617091, "6": 0.0007941012154333293, "7": 0.0007248811307363212, "8": 0.0006667610723525286, "9": 0.0006172691937536001, "10": 0.2577558755874634, "11": 0.0005374781903810799, "12": 0.0005048486054874957, "13": 0.2676149308681488, "14": 0.1133548766374588, "15": 0.00042706841486506164, "16": 0.0004062074876856059, "17": 0.0003872895904351026, "18": 0.0003700553788803518, "19": 0.00035428963019512594}}, {"key": "ma2019universal", "year": "2019", "title": "Universal Text Representation From BERT: An Empirical Study", "topic_distr": {"0": 0.001434744568541646, "1": 0.0011707993689924479, "2": 0.262984037399292, "3": 0.0008571199141442776, "4": 0.000755943066906184, "5": 0.0006761344848200679, "6": 0.0006115693249739707, "7": 0.000558260187972337, "8": 0.1315820962190628, "9": 0.0004753839166369289, "10": 0.44150981307029724, "11": 0.00041393362334929407, "12": 0.00038880427018739283, "13": 0.00036655142321251333, "14": 0.000346707965945825, "15": 0.08396684378385544, "16": 0.000312836782541126, "17": 0.0002982673468068242, "18": 0.00028499457403086126, "19": 0.07100522518157959}}, {"key": "ma2020character", "year": "2020", "title": "Charbert: Character-aware Pre-trained Language Model", "topic_distr": {"0": 0.001467327936552465, "1": 0.09527485072612762, "2": 0.28557780385017395, "3": 0.0008773005683906376, "4": 0.025989022105932236, "5": 0.0006920552114024758, "6": 0.0006259698420763016, "7": 0.0005714053986594081, "8": 0.048089057207107544, "9": 0.00048657768638804555, "10": 0.4257116913795471, "11": 0.00042368043796159327, "12": 0.0003979593457188457, "13": 0.00037518254248425364, "14": 0.00035487182321958244, "15": 0.000336647208314389, "16": 0.00032020307844504714, "17": 0.08789404481649399, "18": 0.000291705277049914, "19": 0.02424265816807747}}, {"key": "ma2020knowledge", "year": "2020", "title": "Knowledge-driven Data Construction For Zero-shot Evaluation In Commonsense Question Answering", "topic_distr": {"0": 0.1048092171549797, "1": 0.08888442069292068, "2": 0.21890094876289368, "3": 0.000659915036521852, "4": 0.0005820157239213586, "5": 0.0005205701454542577, "6": 0.0004708601045422256, "7": 0.10659521073102951, "8": 0.09610352665185928, "9": 0.0003660080546978861, "10": 0.0003407175245229155, "11": 0.00031869616941548884, "12": 0.15213783085346222, "13": 0.0002822156238835305, "14": 0.0002669377427082509, "15": 0.0002532290236558765, "16": 0.2278485745191574, "17": 0.000229642289923504, "18": 0.00021942330931778997, "19": 0.00021007504255976528}}, {"key": "ma2020xlm", "year": "2020", "title": "XLM-T: Scaling Up Multilingual Machine Translation With Pretrained Cross-lingual Transformer Encoders", "topic_distr": {"0": 0.0018066324992105365, "1": 0.0014759781770408154, "2": 0.11413230001926422, "3": 0.00108065246604383, "4": 0.0009530925308354199, "5": 0.0008524703443981707, "6": 0.000771066639572382, "7": 0.000703854369930923, "8": 0.000647420238237828, "9": 0.0005993639933876693, "10": 0.2242242991924286, "11": 0.0005218874430283904, "12": 0.00049020437290892, "13": 0.0004621479893103242, "14": 0.5669456124305725, "15": 0.0004146803985349834, "16": 0.0003944245690945536, "17": 0.000376055424567312, "18": 0.0003593211295083165, "19": 0.08278855681419373}}, {"key": "ma2021encoder", "year": "2021", "title": "Deltalm: Encoder-decoder Pre-training For Language Generation And Translation By Augmenting Pretrained Multilingual Encoders", "topic_distr": {"0": 0.001578652416355908, "1": 0.0012894198298454285, "2": 0.001089902245439589, "3": 0.0009439400164410472, "4": 0.0008325129165314138, "5": 0.0007446214440278709, "6": 0.0006735164206475019, "7": 0.09022198617458344, "8": 0.014700639061629772, "9": 0.0005235364660620689, "10": 0.41837504506111145, "11": 0.00045586173655465245, "12": 0.00042818699148483574, "13": 0.00040368011104874313, "14": 0.265529602766037, "15": 0.0003622177755460143, "16": 0.07027105987071991, "17": 0.0003284793929196894, "18": 0.00031386222690343857, "19": 0.13093331456184387}}, {"key": "ma2021evaluation", "year": "2021", "title": "Dynaboard: An Evaluation-as-a-service Platform For Holistic Next-generation Benchmarking", "topic_distr": {"0": 0.07447436451911926, "1": 0.06883589178323746, "2": 0.22459843754768372, "3": 0.0011130326893180609, "4": 0.29036393761634827, "5": 0.0008780116331763566, "6": 0.000794168736319989, "7": 0.0007249427726492286, "8": 0.0006668178248219192, "9": 0.10988332331180573, "10": 0.0005746658425778151, "11": 0.000537523883394897, "12": 0.22368358075618744, "13": 0.00047599454410374165, "14": 0.00045022633275948465, "15": 0.00042710473644547164, "16": 0.000406242033932358, "17": 0.0003873225359711796, "18": 0.00037008686922490597, "19": 0.0003543197817634791}}, {"key": "ma2021linear", "year": "2021", "title": "Luna: Linear Unified Nested Attention", "topic_distr": {"0": 0.0013551622396335006, "1": 0.001106778858229518, "2": 0.5328347086906433, "3": 0.0008104714215733111, "4": 0.03913582116365433, "5": 0.0006393394432961941, "6": 0.0005782880471087992, "7": 0.0005278799217194319, "8": 0.00048555515240877867, "9": 0.0004495137254707515, "10": 0.32075342535972595, "11": 0.0003914075205102563, "12": 0.00036764569813385606, "13": 0.06166316568851471, "14": 0.023460812866687775, "15": 0.0003110038524027914, "16": 0.0002958123222924769, "17": 0.0002820357622113079, "18": 0.00026948528829962015, "19": 0.014281687326729298}}, {"key": "ma2021one", "year": "2021", "title": "One Chatbot Per Person: Creating Personalized Chatbots Based On Implicit User Profiles", "topic_distr": {"0": 0.021111709997057915, "1": 0.0008082643034867942, "2": 0.0006833325605839491, "3": 0.0005918394890613854, "4": 0.28916043043136597, "5": 0.14260318875312805, "6": 0.20609377324581146, "7": 0.06905706226825714, "8": 0.00035457208286970854, "9": 0.09991781413555145, "10": 0.07988698780536652, "11": 0.0002858216466847807, "12": 0.0002684697974473238, "13": 0.00025310416822321713, "14": 0.00023940224491525441, "15": 0.015426214784383774, "16": 0.07266687601804733, "17": 0.0002059539401670918, "18": 0.00019678908574860543, "19": 0.00018840513075701892}}, {"key": "ma2021replication", "year": "2021", "title": "A Replication Study Of Dense Passage Retriever", "topic_distr": {"0": 0.0014352878788486123, "1": 0.0011706644436344504, "2": 0.24327987432479858, "3": 0.0008571973303332925, "4": 0.07091232389211655, "5": 0.0006761940894648433, "6": 0.0006116231670603156, "7": 0.1507386863231659, "8": 0.21678107976913452, "9": 0.00047542573884129524, "10": 0.18128067255020142, "11": 0.00041397003224119544, "12": 0.0003888384671881795, "13": 0.0003665836702566594, "14": 0.00034673846676014364, "15": 0.00032893155002966523, "16": 0.0003128642856609076, "17": 0.0002982935693580657, "18": 0.00028501966153271496, "19": 0.1290397346019745}}, {"key": "ma2022can", "year": "2022", "title": "CREPE: Can Vision-language Foundation Models Reason Compositionally?", "topic_distr": {"0": 0.15997859835624695, "1": 0.10163570940494537, "2": 0.13159394264221191, "3": 0.23708689212799072, "4": 0.0006146808154881, "5": 0.0005497857346199453, "6": 0.0004972858005203307, "7": 0.0004539384681265801, "8": 0.0004175422654952854, "9": 0.00038654921809211373, "10": 0.00035983932320959866, "11": 0.0003365821030456573, "12": 0.00031614865292795, "13": 0.0002980541903525591, "14": 0.00028191888122819364, "15": 0.0002674408024176955, "16": 0.011274028569459915, "17": 0.00024253031006082892, "18": 0.2796114683151245, "19": 0.07379702478647232}}, {"key": "ma2022prompt", "year": "2022", "title": "Prompt For Extraction? PAIE: Prompting Argument Interaction For Event Argument Extraction", "topic_distr": {"0": 0.001234967028722167, "1": 0.0010083767119795084, "2": 0.34164872765541077, "3": 0.0007382971816696227, "4": 0.0401616245508194, "5": 0.0005824038526043296, "6": 0.0005267892265692353, "7": 0.0004808701341971755, "8": 0.0004423145728651434, "9": 0.0004094827745575458, "10": 0.000381188205210492, "11": 0.00035655114334076643, "12": 0.0003349054022692144, "13": 0.0341656431555748, "14": 0.0002986447943840176, "15": 0.09210395067930222, "16": 0.00026946907746605575, "17": 0.4843752980232239, "18": 0.0002454865607433021, "19": 0.00023502791009377688}}, {"key": "ma2022understanding", "year": "2022", "title": "Understanding And Mitigating Overfitting In Prompt Tuning For Vision-language Models", "topic_distr": {"0": 0.09731931239366531, "1": 0.05952058732509613, "2": 0.2466767430305481, "3": 0.0005251424154266715, "4": 0.00046315317740663886, "5": 0.00041425632662139833, "6": 0.0003746983711607754, "7": 0.00034203671384602785, "8": 0.000314612640067935, "9": 0.0002912597847171128, "10": 0.0002711342240218073, "11": 0.0002536102256271988, "12": 0.0002382138918619603, "13": 0.00022457994055002928, "14": 0.00021242217917460948, "15": 0.0002015131467487663, "16": 0.042779047042131424, "17": 0.3852928578853607, "18": 0.16411767899990082, "19": 0.00016717231483198702}}, {"key": "ma2023fine", "year": "2023", "title": "Fine-tuning Llama For Multi-stage Text Retrieval", "topic_distr": {"0": 0.0017815773608163, "1": 0.0014551500789821148, "2": 0.0012299875961616635, "3": 0.49496176838874817, "4": 0.0009395756642334163, "5": 0.0008403802057728171, "6": 0.000760131049901247, "7": 0.10749147832393646, "8": 0.17239797115325928, "9": 0.15399989485740662, "10": 0.0005500358529388905, "11": 0.0005144858150742948, "12": 0.00048325207899324596, "13": 0.060301631689071655, "14": 0.0004309298237785697, "15": 0.0004087992128916085, "16": 0.0003888306673616171, "17": 0.0003707220603246242, "18": 0.00035422510700300336, "19": 0.0003391337813809514}}, {"key": "ma2023iterative", "year": "2023", "title": "An Iterative Optimizing Framework For Radiology Report Summarization With Chatgpt", "topic_distr": {"0": 0.0010305173927918077, "1": 0.07381679862737656, "2": 0.07185158133506775, "3": 0.43628206849098206, "4": 0.000543514615856111, "5": 0.0004861335619352758, "6": 0.00043971193372271955, "7": 0.07435975968837738, "8": 0.0003692008031066507, "9": 0.08398931473493576, "10": 0.0003181784995831549, "11": 0.0002976139076054096, "12": 0.07200630009174347, "13": 0.0002635466225910932, "14": 0.00024927937192842364, "15": 0.00023647751368116587, "16": 0.014196014031767845, "17": 0.16886290907859802, "18": 0.00020490809401962906, "19": 0.00019617824000306427}}, {"key": "ma2023language", "year": "2023", "title": "LIV: Language-image Representations And Rewards For Robotic Control", "topic_distr": {"0": 0.022973086684942245, "1": 0.001028939732350409, "2": 0.12542188167572021, "3": 0.0007532372255809605, "4": 0.0006643236265517771, "5": 0.0005941881681792438, "6": 0.0005374482134357095, "7": 0.0004906000103801489, "8": 0.0004512643499765545, "9": 0.00041776822763495147, "10": 0.00038890112773515284, "11": 0.4413434565067291, "12": 0.00034168187994509935, "13": 0.00032212602673098445, "14": 0.0003046875644940883, "15": 0.00028904018108733, "16": 0.00027492150547914207, "17": 0.0002621178573463112, "18": 0.4029005169868469, "19": 0.00023978346143849194}}, {"key": "ma2023llm", "year": "2023", "title": "Llm-pruner: On The Structural Pruning Of Large Language Models", "topic_distr": {"0": 0.0013123027747496963, "1": 0.001072346931323409, "2": 0.0878572091460228, "3": 0.3447933495044708, "4": 0.0006923231412656605, "5": 0.0006192318396642804, "6": 0.0005601004231721163, "7": 0.0005112776416353881, "8": 0.0004702840815298259, "9": 0.0004353761614765972, "10": 0.00040529240504838526, "11": 0.0003790974442381412, "12": 0.00035608295002020895, "13": 0.29868459701538086, "14": 0.00031752942595630884, "15": 0.06699133664369583, "16": 0.08315635472536087, "17": 0.07116705924272537, "18": 0.03996897116303444, "19": 0.0002498897665645927}}, {"key": "ma2023query", "year": "2023", "title": "Query Rewriting For Retrieval-augmented Large Language Models", "topic_distr": {"0": 0.0012727909488603473, "1": 0.001039201277308166, "2": 0.16036216914653778, "3": 0.2670568823814392, "4": 0.041271306574344635, "5": 0.0006002334412187338, "6": 0.0005429162411019206, "7": 0.0004955914337188005, "8": 0.2975132465362549, "9": 0.0004220186092425138, "10": 0.00039285782258957624, "11": 0.00036746656405739486, "12": 0.00034515815787017345, "13": 0.0003254033508710563, "14": 0.0003077874716836959, "15": 0.04954535886645317, "16": 0.0002777185582090169, "17": 0.1773666888475418, "18": 0.0002530018682591617, "19": 0.00024222303181886673}}, {"key": "ma2024era", "year": "2024", "title": "The Era Of 1-bit Llms: All Large Language Models Are In 1.58 Bits", "topic_distr": {"0": 0.002113030292093754, "1": 0.0017259895103052258, "2": 0.20419073104858398, "3": 0.24032701551914215, "4": 0.0011146579636260867, "5": 0.0009969796519726515, "6": 0.0009017765405587852, "7": 0.0008231706451624632, "8": 0.0007571698515675962, "9": 0.15910828113555908, "10": 0.0006525315111503005, "11": 0.000610356975812465, "12": 0.000573303026612848, "13": 0.3356347680091858, "14": 0.0005112307844683528, "15": 0.048235371708869934, "16": 0.000461286777863279, "17": 0.0004398037272039801, "18": 0.00042023268179036677, "19": 0.00040232916944660246}}, {"key": "ma2024exploratory", "year": "2024", "title": "Llmparser: An Exploratory Study On Using Large Language Models For Log Parsing", "topic_distr": {"0": 0.11497022211551666, "1": 0.0008934044162742794, "2": 0.0007552205352112651, "3": 0.4753338098526001, "4": 0.0005768961273133755, "5": 0.0005159906577318907, "6": 0.0004667179600801319, "7": 0.0004260351415723562, "8": 0.00039187620859593153, "9": 0.19148004055023193, "10": 0.0003377202374394983, "11": 0.00031589262653142214, "12": 0.00029671521042473614, "13": 0.07359924167394638, "14": 0.13849712908267975, "15": 0.00025100138736888766, "16": 0.00023874075850471854, "17": 0.00022762212029192597, "18": 0.0002174930414184928, "19": 0.00020822702208533883}}, {"key": "maatouk2023large", "year": "2023", "title": "Large Language Models For Telecom: Forthcoming Impact On The Industry", "topic_distr": {"0": 0.0016885745571926236, "1": 0.0013766915071755648, "2": 0.05312801152467728, "3": 0.12875796854496002, "4": 0.0008889408782124519, "5": 0.0007950928993523121, "6": 0.0007191674085333943, "7": 0.000656479096505791, "8": 0.0006038433639332652, "9": 0.5220766067504883, "10": 0.0005203942419029772, "11": 0.000486760021885857, "12": 0.20576995611190796, "13": 0.08036237955093384, "14": 0.0004077068588230759, "15": 0.00038676889380440116, "16": 0.0003678764624055475, "17": 0.0003507437068037689, "18": 0.0003351357881911099, "19": 0.0003208577400073409}}, {"key": "maaz2023video", "year": "2023", "title": "Video-chatgpt: Towards Detailed Video Understanding Via Large Vision And Language Models", "topic_distr": {"0": 0.0017574295634403825, "1": 0.07426640391349792, "2": 0.0012125432258471847, "3": 0.24291947484016418, "4": 0.0009262689272873104, "5": 0.10775011032819748, "6": 0.11288651823997498, "7": 0.0006840457208454609, "8": 0.0006291997851803899, "9": 0.0005824959953315556, "10": 0.0005422465037554502, "11": 0.04498064145445824, "12": 0.06946590542793274, "13": 0.0004491416912060231, "14": 0.00042482715798541903, "15": 0.0004030099662486464, "16": 0.00038332422263920307, "17": 0.00036547204945236444, "18": 0.33903664350509644, "19": 0.00033433109638281167}}, {"key": "macavaney2020analyzing", "year": "2020", "title": "ABNIRML: Analyzing The Behavior Of Neural IR Models", "topic_distr": {"0": 0.30844929814338684, "1": 0.0009701332892291248, "2": 0.25437209010124207, "3": 0.0007101960363797843, "4": 0.05365995690226555, "5": 0.0005602340679615736, "6": 0.0005067365127615631, "7": 0.06785518676042557, "8": 0.059975896030664444, "9": 0.00039389540324918926, "10": 0.061322737485170364, "11": 0.0003429786884225905, "12": 0.024711087346076965, "13": 0.0003037185815628618, "14": 0.00028727660537697375, "15": 0.00027252337895333767, "16": 0.00025921149062924087, "17": 0.00024713948369026184, "18": 0.00023614190286025405, "19": 0.16456356644630432}}, {"key": "madaan2022language", "year": "2022", "title": "Language Models Of Code Are Few-shot Commonsense Learners", "topic_distr": {"0": 0.0016414700075984001, "1": 0.001340082031674683, "2": 0.0011328179389238358, "3": 0.21624432504177094, "4": 0.000865363806951791, "5": 0.0007740044966340065, "6": 0.20734338462352753, "7": 0.0006390674971044064, "8": 0.0005878278752788901, "9": 0.0005441950052045286, "10": 0.0005065920413471758, "11": 0.00047384988283738494, "12": 0.00044508310384117067, "13": 0.00041960919043049216, "14": 0.00039689341792836785, "15": 0.0003765107539948076, "16": 0.15792667865753174, "17": 0.25308454036712646, "18": 0.0003262471000198275, "19": 0.1549314707517624}}, {"key": "madaan2022memory", "year": "2022", "title": "Memory-assisted Prompt Editing To Improve GPT-3 After Deployment", "topic_distr": {"0": 0.13290467858314514, "1": 0.07438717782497406, "2": 0.001050058868713677, "3": 0.3894326984882355, "4": 0.20129477977752686, "5": 0.0007174316560849547, "6": 0.0006489228107966483, "7": 0.0630054697394371, "8": 0.03858387470245361, "9": 0.0005044194404035807, "10": 0.0004695648967754096, "11": 0.0004392158589325845, "12": 0.0004125516570638865, "13": 0.05557785555720329, "14": 0.000367884204024449, "15": 0.0003489913360681385, "16": 0.00033194420393556356, "17": 0.0003164849185850471, "18": 0.0003024014877155423, "19": 0.038903553038835526}}, {"key": "madaan2022text", "year": "2022", "title": "Text And Patterns: For Effective Chain Of Thought, It Takes Two To Tango", "topic_distr": {"0": 0.15985748171806335, "1": 0.0007716238615103066, "2": 0.11015481501817703, "3": 0.4031715393066406, "4": 0.0004982611862942576, "5": 0.0004456577298697084, "6": 0.00040310120675712824, "7": 0.0003679637738969177, "8": 0.03162294998764992, "9": 0.0003133378631900996, "10": 0.00029168673790991306, "11": 0.0002728343824855983, "12": 0.0002562709560152143, "13": 0.022581329569220543, "14": 0.00022852420806884766, "15": 0.1013152077794075, "16": 0.06515468657016754, "17": 0.1019250676035881, "18": 0.00018784731219056994, "19": 0.00017984431178774685}}, {"key": "madaan2023self", "year": "2023", "title": "Self-refine: Iterative Refinement With Self-feedback", "topic_distr": {"0": 0.0013568020658567548, "1": 0.0011071969056501985, "2": 0.10821431130170822, "3": 0.5850856304168701, "4": 0.07177242636680603, "5": 0.0006393642397597432, "6": 0.0005783104570582509, "7": 0.1843063235282898, "8": 0.00048557392437942326, "9": 0.0004495311004575342, "10": 0.0004184692515991628, "11": 0.043127525597810745, "12": 0.00036765990080311894, "13": 0.00034661724930629134, "14": 0.0003278529329691082, "15": 0.00031101587228477, "16": 0.0002958237600978464, "17": 0.0002820466470438987, "18": 0.00026949570747092366, "19": 0.00025801415904425085}}, {"key": "madotto2018effectively", "year": "2018", "title": "Mem2seq: Effectively Incorporating Knowledge Bases Into End-to-end Task-oriented Dialog Systems", "topic_distr": {"0": 0.0021492643281817436, "1": 0.0017555418889969587, "2": 0.4296445846557617, "3": 0.0012855647364631295, "4": 0.23313501477241516, "5": 0.0010141154052689672, "6": 0.0009172760182991624, "7": 0.0714365765452385, "8": 0.0007701838621869683, "9": 0.0007130152080208063, "10": 0.0006637470214627683, "11": 0.0006208475679159164, "12": 0.0005831567686982453, "13": 0.0005497803213074803, "14": 0.000520017696544528, "15": 0.052264370024204254, "16": 0.20069284737110138, "17": 0.00044736292329616845, "18": 0.0004274554958101362, "19": 0.00040924426866695285}}, {"key": "madotto2020language", "year": "2020", "title": "Language Models As Few-shot Learner For Task-oriented Dialogue Systems", "topic_distr": {"0": 0.0017100452678278089, "1": 0.15239492058753967, "2": 0.20939671993255615, "3": 0.0010215331567451358, "4": 0.0009009467321448028, "5": 0.13703937828540802, "6": 0.0007288797060027719, "7": 0.000665344821754843, "8": 0.0006119983154349029, "9": 0.0005665713106282055, "10": 0.0005274222348816693, "11": 0.10607662051916122, "12": 0.2562835216522217, "13": 0.05501113086938858, "14": 0.0004132129542995244, "15": 0.03944820910692215, "16": 0.0003728446317836642, "17": 0.03616580739617348, "18": 0.0003396618121769279, "19": 0.0003251909220125526}}, {"key": "madotto2021few", "year": "2021", "title": "Few-shot Bot: Prompt-based Learning For Dialogue Systems", "topic_distr": {"0": 0.018529031425714493, "1": 0.05464395135641098, "2": 0.1469355970621109, "3": 0.0005649318918585777, "4": 0.0004982452956028283, "5": 0.1006719172000885, "6": 0.22707432508468628, "7": 0.02298559434711933, "8": 0.03569106012582779, "9": 0.022703371942043304, "10": 0.000291677366476506, "11": 0.09495232254266739, "12": 0.00025626271963119507, "13": 0.04503834247589111, "14": 0.00022851685935165733, "15": 0.00021678127814084291, "16": 0.044295210391283035, "17": 0.129789799451828, "18": 0.00018784127314575016, "19": 0.05444519966840744}}, {"key": "magassouba2019understanding", "year": "2019", "title": "Understanding Natural Language Instructions For Fetching Daily Objects Using Gan-based Multimodal Target-source Classification", "topic_distr": {"0": 0.0022683292627334595, "1": 0.2592759430408478, "2": 0.16989447176456451, "3": 0.0013558295322582126, "4": 0.06654547899961472, "5": 0.0010695427190512419, "6": 0.00096741016022861, "7": 0.04919932410120964, "8": 0.0008122786530293524, "9": 0.0007519854116253555, "10": 0.0007000244804657996, "11": 0.10114262998104095, "12": 0.0006150294793769717, "13": 0.0005798288621008396, "14": 0.0005484395078383386, "15": 0.029340974986553192, "16": 0.0004948604037053883, "17": 0.00047181377885863185, "18": 0.3135342001914978, "19": 0.00043161172652617097}}, {"key": "magee2022structured", "year": "2022", "title": "Structured Like A Language Model: Analysing AI As An Automated Subject", "topic_distr": {"0": 0.3342963755130768, "1": 0.033850155770778656, "2": 0.0008697513840161264, "3": 0.15247417986392975, "4": 0.0006643843371421099, "5": 0.0005942418938502669, "6": 0.053533464670181274, "7": 0.000490644364617765, "8": 0.0004513051244430244, "9": 0.333066463470459, "10": 0.017171960324048996, "11": 0.00036379846278578043, "12": 0.07022994756698608, "13": 0.0003221551305614412, "14": 0.00030471509671770036, "15": 0.00028906631632708013, "16": 0.00027494633104652166, "17": 0.000262141547864303, "18": 0.0002504763542674482, "19": 0.00023980512924026698}}, {"key": "mager2020gpt", "year": "2020", "title": "Gpt-too: A Language-model-first Approach For Amr-to-text Generation", "topic_distr": {"0": 0.0026006035041064024, "1": 0.10179848968982697, "2": 0.20817938446998596, "3": 0.0015534027479588985, "4": 0.0013700376730412245, "5": 0.0012253958266228437, "6": 0.0011083807330578566, "7": 0.2550247609615326, "8": 0.000930643524043262, "9": 0.0008615643600933254, "10": 0.1906914860010147, "11": 0.0007501946529373527, "12": 0.13506600260734558, "13": 0.0006643212400376797, "14": 0.0006283578695729375, "15": 0.0005960882408544421, "16": 0.09539929777383804, "17": 0.0005405662814155221, "18": 0.0005165113252587616, "19": 0.0004945059772580862}}, {"key": "magister2022teaching", "year": "2022", "title": "Teaching Small Language Models To Reason", "topic_distr": {"0": 0.0018074982799589634, "1": 0.0014758494216948748, "2": 0.0012477068230509758, "3": 0.6657010316848755, "4": 0.000953089736867696, "5": 0.0008524691802449524, "6": 0.0007710650679655373, "7": 0.0007038529729470611, "8": 0.0006474189576692879, "9": 0.0005993628292344511, "10": 0.0005579478456638753, "11": 0.0005218864534981549, "12": 0.0004902033833786845, "13": 0.2948414087295532, "14": 0.0004371285031083971, "15": 0.00041467955452390015, "16": 0.00039442378329113126, "17": 0.0003760546969715506, "18": 0.00035932043101638556, "19": 0.026847582310438156}}, {"key": "mahabadi2019end", "year": "2019", "title": "End-to-end Bias Mitigation By Modelling Biases In Corpora", "topic_distr": {"0": 0.2437075674533844, "1": 0.2812143564224243, "2": 0.0009358826791867614, "3": 0.12812362611293793, "4": 0.0007148985168896616, "5": 0.0006394240190275013, "6": 0.0005783643573522568, "7": 0.0005279495380818844, "8": 0.0004856192390434444, "9": 0.00044957303907722235, "10": 0.061094705015420914, "11": 0.000391459179809317, "12": 0.00036769421421922743, "13": 0.0003466495836619288, "14": 0.08713985234498978, "15": 0.00031104491790756583, "16": 0.00029585135052911937, "17": 0.19214791059494019, "18": 0.0002695208531804383, "19": 0.000258038257015869}}, {"key": "mahabadi2021efficient", "year": "2021", "title": "Compacter: Efficient Low-rank Hypercomplex Adapter Layers", "topic_distr": {"0": 0.0015388665487989783, "1": 0.0012572273844853044, "2": 0.3285765051841736, "3": 0.0009205701644532382, "4": 0.0008119063568301499, "5": 0.0007261902210302651, "6": 0.0006568452809005976, "7": 0.0005995894898660481, "8": 0.0005515151424333453, "9": 0.0005105776945129037, "10": 0.1615179181098938, "11": 0.00044457806507125497, "12": 0.0004175883368588984, "13": 0.4173555374145508, "14": 0.0003723755362443626, "15": 0.00035325202043168247, "16": 0.0003359967959113419, "17": 0.0003203487431164831, "18": 0.00030609339592047036, "19": 0.08242656290531158}}, {"key": "mahabadi2021variational", "year": "2021", "title": "Variational Information Bottleneck For Effective Low-resource Fine-tuning", "topic_distr": {"0": 0.07677629590034485, "1": 0.05336502939462662, "2": 0.33413079380989075, "3": 0.05941205471754074, "4": 0.0008653780678287148, "5": 0.0007740164292044938, "6": 0.0007001044577918947, "7": 0.053100232034921646, "8": 0.000587837363127619, "9": 0.0005442037945613265, "10": 0.18767781555652618, "11": 0.00047385753714479506, "12": 0.0004450902924872935, "13": 0.0004196159716229886, "14": 0.00039689982077106833, "15": 0.0003765168657992035, "16": 0.0003581251949071884, "17": 0.22895751893520355, "18": 0.0003262523969169706, "19": 0.000312352814944461}}, {"key": "maharana2022storydall", "year": "2022", "title": "Storydall-e: Adapting Pretrained Text-to-image Transformers For Story Continuation", "topic_distr": {"0": 0.0009455446270294487, "1": 0.06550847738981247, "2": 0.19217927753925323, "3": 0.0005649569793604314, "4": 0.0004982671816833317, "5": 0.0004456628521438688, "6": 0.0004031058051623404, "7": 0.22600030899047852, "8": 0.000338464742526412, "9": 0.0003133414138574153, "10": 0.04966640844941139, "11": 0.024159766733646393, "12": 0.00025627386639826, "13": 0.00024160627799574286, "14": 0.0002285267983097583, "15": 0.00021679069322999567, "16": 0.0002062011626549065, "17": 0.10191722214221954, "18": 0.26847416162490845, "19": 0.067435622215271}}, {"key": "maharjan2024prompt", "year": "2024", "title": "Openmedlm: Prompt Engineering Can Out-perform Fine-tuning In Medical Question-answering With Open-source Large Language Models", "topic_distr": {"0": 0.000990710686892271, "1": 0.0008084019063971937, "2": 0.0006833644001744688, "3": 0.46546459197998047, "4": 0.0005220078746788204, "5": 0.00046689764712937176, "6": 0.00042231290717609227, "7": 0.00038550078170374036, "8": 0.0003545918152667582, "9": 0.06933639943599701, "10": 0.00030558844446204603, "11": 0.00028583756648004055, "12": 0.2956993877887726, "13": 0.10123909264802933, "14": 0.00023941558902151883, "15": 0.00022712029749527574, "16": 0.0002160261938115582, "17": 0.06196751818060875, "18": 0.00019680005789268762, "19": 0.00018841562268789858}}, {"key": "mahowald2023dissociating", "year": "2023", "title": "Dissociating Language And Thought In Large Language Models", "topic_distr": {"0": 0.3487381637096405, "1": 0.0016976314364001155, "2": 0.30549198389053345, "3": 0.28031376004219055, "4": 0.0010961012449115515, "5": 0.000980381271801889, "6": 0.0008867632132023573, "7": 0.0008094659424386919, "8": 0.0007445639930665493, "9": 0.0006892970413900912, "10": 0.0006416677497327328, "11": 0.0006001953734084964, "12": 0.0005637583089992404, "13": 0.0005314921145327389, "14": 0.0005027195438742638, "15": 0.00047690211795270443, "16": 0.05399378761649132, "17": 0.0004324816109146923, "18": 0.0004132363828830421, "19": 0.0003956309228669852}}, {"key": "majumdar2020improving", "year": "2020", "title": "Improving Vision-and-language Navigation With Image-text Pairs From The Web", "topic_distr": {"0": 0.001807855674996972, "1": 0.03214002773165703, "2": 0.20427516102790833, "3": 0.0010807085782289505, "4": 0.0009531414834782481, "5": 0.0008525149314664304, "6": 0.0007711070356890559, "7": 0.0007038912735879421, "8": 0.019279474392533302, "9": 0.021343838423490524, "10": 0.03609193116426468, "11": 0.38281622529029846, "12": 0.0004902301006950438, "13": 0.00046217223280109465, "14": 0.0004371522809378803, "15": 0.0004147021099925041, "16": 0.00039444523281417787, "17": 0.00037607515696436167, "18": 0.19402259588241577, "19": 0.10128673166036606}}, {"key": "majumder2020like", "year": "2020", "title": "Like Hiking? You Probably Enjoy Nature: Persona-grounded Dialog With Commonsense Expansions", "topic_distr": {"0": 0.24615895748138428, "1": 0.10693932324647903, "2": 0.08958376944065094, "3": 0.0009321668185293674, "4": 0.17723853886127472, "5": 0.000735337205696851, "6": 0.14644470810890198, "7": 0.0711110457777977, "8": 0.042983558028936386, "9": 0.000517008826136589, "10": 0.0004812843690160662, "11": 0.00045017790398560464, "12": 0.0004228481848258525, "13": 0.0003986468946095556, "14": 0.02974994294345379, "15": 0.00035770153044722974, "16": 0.031652163714170456, "17": 0.0003243838145863265, "18": 0.053221676498651505, "19": 0.000296743877697736}}, {"key": "maleki2024ai", "year": "2024", "title": "AI Hallucinations: A Misnomer Worth Clarifying", "topic_distr": {"0": 0.20488181710243225, "1": 0.0012573213316500187, "2": 0.001062876544892788, "3": 0.0009205866372212768, "4": 0.08503609150648117, "5": 0.0007262019207701087, "6": 0.000656855758279562, "7": 0.0005995990941300988, "8": 0.0005515239899978042, "9": 0.429859459400177, "10": 0.0004753052198793739, "11": 0.00044458519550971687, "12": 0.10552572458982468, "13": 0.0003936943830922246, "14": 0.0003723815025296062, "15": 0.16598041355609894, "16": 0.0003360021801199764, "17": 0.00032035389449447393, "18": 0.0003060982853639871, "19": 0.0002930573537014425}}, {"key": "malladi2023fine", "year": "2023", "title": "Fine-tuning Language Models With Just Forward Passes", "topic_distr": {"0": 0.08029647171497345, "1": 0.0011574842501431704, "2": 0.03477279096841812, "3": 0.0008474785718135536, "4": 0.0007474384619854391, "5": 0.0006685287225991488, "6": 0.0006046899361535907, "7": 0.02642214298248291, "8": 0.0005077233072370291, "9": 0.0004700364079326391, "10": 0.07735554873943329, "11": 0.00040927735972218215, "12": 0.027021374553442, "13": 0.25344789028167725, "14": 0.0003428079071454704, "15": 0.0003252028545830399, "16": 0.0003093177219852805, "17": 0.34841734170913696, "18": 0.00028178872889839113, "19": 0.14559470117092133}}, {"key": "mallen2022when", "year": "2022", "title": "When Not To Trust Language Models: Investigating Effectiveness Of Parametric And Non-parametric Memories", "topic_distr": {"0": 0.10844571888446808, "1": 0.05061076581478119, "2": 0.16249223053455353, "3": 0.1018131673336029, "4": 0.000707176688592881, "5": 0.0006325169815681875, "6": 0.0005721169291064143, "7": 0.0005222467589192092, "8": 0.0616069994866848, "9": 0.00044471686123870313, "10": 0.0004139876691624522, "11": 0.00038723074248991907, "12": 0.0003637224726844579, "13": 0.11384184658527374, "14": 0.0003243418177589774, "15": 0.0003076850844081491, "16": 0.24419613182544708, "17": 0.00027902607689611614, "18": 0.00026660956791602075, "19": 0.15177176892757416}}, {"key": "malmi2019high", "year": "2019", "title": "Encode, Tag, Realize: High-precision Text Editing", "topic_distr": {"0": 0.0017324935179203749, "1": 0.0014148358022794127, "2": 0.431333988904953, "3": 0.0010356537532061338, "4": 0.0009133954299613833, "5": 0.000816964718978852, "6": 0.0007389515521936119, "7": 0.2720075845718384, "8": 0.0006204550736583769, "9": 0.0005744004156440496, "10": 0.234542578458786, "11": 0.018652934581041336, "12": 0.00046978730824775994, "13": 0.0004428994725458324, "14": 0.032893285155296326, "15": 0.00039740887586958706, "16": 0.0003779967373702675, "17": 0.00036039267433807254, "18": 0.0003443553578108549, "19": 0.00032968452433124185}}, {"key": "manakul2021long", "year": "2021", "title": "Long-span Summarization Via Local Attention And Content Selection", "topic_distr": {"0": 0.0015784630086272955, "1": 0.0012889946810901165, "2": 0.3306084871292114, "3": 0.0009438375127501786, "4": 0.0008324282825924456, "5": 0.0007445439114235342, "6": 0.0006734459311701357, "7": 0.18226391077041626, "8": 0.0005654537817463279, "9": 0.0005234816926531494, "10": 0.33056047558784485, "11": 0.0004558140644803643, "12": 0.00042814220068976283, "13": 0.1465013027191162, "14": 0.00038178672548383474, "15": 0.0003621799114625901, "16": 0.0003444885660428554, "17": 0.00032844505039975047, "18": 0.00031382939778268337, "19": 0.00030045906896702945}}, {"key": "manakul2023zero", "year": "2023", "title": "Selfcheckgpt: Zero-resource Black-box Hallucination Detection For Generative Large Language Models", "topic_distr": {"0": 0.21163274347782135, "1": 0.0008780458592809737, "2": 0.0007422182243317366, "3": 0.3104587495326996, "4": 0.02238667756319046, "5": 0.0005071061896160245, "6": 0.0820775255560875, "7": 0.18450525403022766, "8": 0.053634632378816605, "9": 0.00035654165549203753, "10": 0.000331905233906582, "11": 0.00031045344076119363, "12": 0.00029160623671486974, "13": 0.0002749164414126426, "14": 0.0002600336738396436, "15": 0.06009965389966965, "16": 0.07060987502336502, "17": 0.0002237028384115547, "18": 0.0002137481642421335, "19": 0.00020464167755562812}}, {"key": "mandi2023dialectic", "year": "2023", "title": "Roco: Dialectic Multi-robot Collaboration With Large Language Models", "topic_distr": {"0": 0.001417368883267045, "1": 0.0011573043884709477, "2": 0.0009783373679965734, "3": 0.4945330023765564, "4": 0.07975424826145172, "5": 0.06894063949584961, "6": 0.0006046196795068681, "7": 0.0005519162514247, "8": 0.0005076643428765237, "9": 0.024899976328015327, "10": 0.0004375068238005042, "11": 0.28330767154693604, "12": 0.00038438598858192563, "13": 0.0003623860247898847, "14": 0.0003427680640015751, "15": 0.0003251650487072766, "16": 0.00030928177875466645, "17": 0.000294877914711833, "18": 0.0406210757791996, "19": 0.0002697521122172475}}, {"key": "maneriker2021improving", "year": "2021", "title": "Urltran: Improving Phishing URL Detection Using Transformers", "topic_distr": {"0": 0.0009176344610750675, "1": 0.35301753878593445, "2": 0.36125215888023376, "3": 0.0005483359564095736, "4": 0.024726223200559616, "5": 0.000432553788414225, "6": 0.00039124852628447115, "7": 0.00035714422119781375, "8": 0.00032850884599611163, "9": 0.0003041245217900723, "10": 0.11164458841085434, "11": 0.00026481199893169105, "12": 0.041769903153181076, "13": 0.0002344994863960892, "14": 0.037418901920318604, "15": 0.00021041384025011212, "16": 0.05408971756696701, "17": 0.011734837666153908, "18": 0.00018232388538308442, "19": 0.00017455620400141925}}, {"key": "maniparambil2023enhancing", "year": "2023", "title": "Enhancing CLIP With GPT-4: Harnessing Visual Descriptions As Prompts", "topic_distr": {"0": 0.0012230342254042625, "1": 0.0009988745441660285, "2": 0.0008441467653028667, "3": 0.2425108253955841, "4": 0.0006448185886256397, "5": 0.0005767431575804949, "6": 0.11925648152828217, "7": 0.00047619626275263727, "8": 0.0004380154423415661, "9": 0.0004055027384310961, "10": 0.00037748320028185844, "11": 0.00035308560472913086, "12": 0.00033165025524795055, "13": 0.016966989263892174, "14": 0.0002957420947495848, "15": 0.00028055411530658603, "16": 0.0002668499364517629, "17": 0.24302318692207336, "18": 0.37049707770347595, "19": 0.00023274353588931262}}, {"key": "mansimov2019generalized", "year": "2019", "title": "A Generalized Framework Of Sequence Generation With Application To Undirected Sequence Models", "topic_distr": {"0": 0.0014188550412654877, "1": 0.0011572903022170067, "2": 0.21344149112701416, "3": 0.06605358421802521, "4": 0.0007473822915926576, "5": 0.0006684775580652058, "6": 0.0006046435446478426, "7": 0.2540169060230255, "8": 0.000507684366311878, "9": 0.00047000031918287277, "10": 0.28835615515708923, "11": 0.0004092459275852889, "12": 0.0003844011516775936, "13": 0.0003624003438744694, "14": 0.13235439360141754, "15": 0.000325177883496508, "16": 0.03787553310394287, "17": 0.0002948895562440157, "18": 0.0002817671047523618, "19": 0.00026976276421919465}}, {"key": "manzoor2021towards", "year": "2021", "title": "Towards Retrieval-based Conversational Recommendation", "topic_distr": {"0": 0.0012486205669119954, "1": 0.07579877972602844, "2": 0.1621558517217636, "3": 0.0007457125466316938, "4": 0.286798894405365, "5": 0.0005882505793124437, "6": 0.3629443943500519, "7": 0.00048569749924354255, "8": 0.05636134743690491, "9": 0.04986528679728508, "10": 0.0003850148932542652, "11": 0.0003601305070333183, "12": 0.00033826747676357627, "13": 0.00031890705577097833, "14": 0.00030164283816702664, "15": 0.00028615182964131236, "16": 0.00027217422029934824, "17": 0.00025949854170903563, "18": 0.00024795098579488695, "19": 0.00023738732852507383}}, {"key": "mao2020exploring", "year": "2020", "title": "Dialoguetrm: Exploring The Intra- And Inter-modal Emotional Behaviors In The Conversation", "topic_distr": {"0": 0.0017576707759872079, "1": 0.0014342105714604259, "2": 0.20040276646614075, "3": 0.0010502291843295097, "4": 0.15792904794216156, "5": 0.0008284708601422608, "6": 0.3027130663394928, "7": 0.0006840387941338122, "8": 0.0006291934405453503, "9": 0.12495018541812897, "10": 0.0005422410322353244, "11": 0.0005071947816759348, "12": 0.00047640365664847195, "13": 0.00044913715100847185, "14": 0.0004248228797223419, "15": 0.00040300589171238244, "16": 0.0003833203518297523, "17": 0.00036546835326589644, "18": 0.20373515784740448, "19": 0.0003343277203384787}}, {"key": "mao2020generation", "year": "2020", "title": "Generation-augmented Retrieval For Open-domain Question Answering", "topic_distr": {"0": 0.001640181289985776, "1": 0.0013402450131252408, "2": 0.37936946749687195, "3": 0.000981204560957849, "4": 0.0008653830154798925, "5": 0.0007740204455330968, "6": 0.0007001079502515495, "7": 0.0006390810594893992, "8": 0.33533692359924316, "9": 0.0005442065303213894, "10": 0.0005066028097644448, "11": 0.0004738599236588925, "12": 0.00044509253348223865, "13": 0.04281327873468399, "14": 0.00039690182893536985, "15": 0.06822562962770462, "16": 0.00035812699934467673, "17": 0.05677913501858711, "18": 0.0003262540267314762, "19": 0.10748432576656342}}, {"key": "mao2021dynamic", "year": "2021", "title": "DYLE: Dynamic Latent Extraction For Abstractive Long-input Summarization", "topic_distr": {"0": 0.0015203082002699375, "1": 0.0012419229606166482, "2": 0.4830707907676697, "3": 0.0009093365515582263, "4": 0.0008019994129426777, "5": 0.06479213386774063, "6": 0.07493162900209427, "7": 0.179907888174057, "8": 0.0005447856965474784, "9": 0.0005043477285653353, "10": 0.08012178540229797, "11": 0.0004391534603200853, "12": 0.00041249304194934666, "13": 0.0003888843930326402, "14": 0.0003678319335449487, "15": 0.10880457609891891, "16": 0.00033189705573022366, "17": 0.00031643995316699147, "18": 0.0003023585304617882, "19": 0.00028947691316716373}}, {"key": "mao2021unified", "year": "2021", "title": "Unipelt: A Unified Framework For Parameter-efficient Language Model Tuning", "topic_distr": {"0": 0.0014852065360173583, "1": 0.08182094246149063, "2": 0.4959218502044678, "3": 0.0008877757354639471, "4": 0.0007829790120013058, "5": 0.0007003163336776197, "6": 0.08189556002616882, "7": 0.00057822628878057, "8": 0.0005318648763932288, "9": 0.0004923859960399568, "10": 0.0004583629488479346, "11": 0.0004287379269953817, "12": 0.0004027098184451461, "13": 0.09314638376235962, "14": 0.00035910794395022094, "15": 0.0003406657779123634, "16": 0.0003240253427065909, "17": 0.23886507749557495, "18": 0.00029518737574107945, "19": 0.0002826112904585898}}, {"key": "mao2023survey", "year": "2023", "title": "Gpteval: A Survey On Assessments Of Chatgpt And GPT-4", "topic_distr": {"0": 0.2875191569328308, "1": 0.001786471577361226, "2": 0.0015103282639756799, "3": 0.0013081717770546675, "4": 0.03048529103398323, "5": 0.001031940570101142, "6": 0.0009333989000879228, "7": 0.0008520365809090436, "8": 0.0007837213925085962, "9": 0.2687596380710602, "10": 0.0006754137575626373, "11": 0.0006317602237686515, "12": 0.2623746395111084, "13": 0.0005594438407570124, "14": 0.0005291580455377698, "15": 0.02701513096690178, "16": 0.05156727880239487, "17": 0.00045522625441662967, "18": 0.00043496888247318566, "19": 0.06078685075044632}}, {"key": "marasovi\u01072020natural", "year": "2020", "title": "Natural Language Rationales With Full-stack Visual Reasoning: From Pixels To Semantic Frames To Commonsense Graphs", "topic_distr": {"0": 0.0014340904308483005, "1": 0.0011704410426318645, "2": 0.000989529537037015, "3": 0.0008570688660256565, "4": 0.0007558982470072806, "5": 0.17420007288455963, "6": 0.0006115338183008134, "7": 0.0005582277080975473, "8": 0.08554685115814209, "9": 0.000475356267997995, "10": 0.07937300950288773, "11": 0.13786983489990234, "12": 0.07439514994621277, "13": 0.000366530119208619, "14": 0.00034668779699131846, "15": 0.00032888349960558116, "16": 0.10740816593170166, "17": 0.000298250000923872, "18": 0.3017553389072418, "19": 0.031259048730134964}}, {"key": "marino2020integrating", "year": "2020", "title": "KRISP: Integrating Implicit And Symbolic Knowledge For Open-domain Knowledge-based VQA", "topic_distr": {"0": 0.0011234479025006294, "1": 0.0009177546016871929, "2": 0.11960797756910324, "3": 0.1267864853143692, "4": 0.0005924823344685137, "5": 0.0005299317417666316, "6": 0.00047932768939062953, "7": 0.0004375457647256553, "8": 0.1804598718881607, "9": 0.00037259008968248963, "10": 0.04001863673329353, "11": 0.00032442741212435067, "12": 0.000304731831420213, "13": 0.00028729080804623663, "14": 0.000271738157607615, "15": 0.0002577829291112721, "16": 0.4317609965801239, "17": 0.0002337720216019079, "18": 0.09501934051513672, "19": 0.00021385289437603205}}, {"key": "marjieh2023large", "year": "2023", "title": "Large Language Models Predict Human Sensory Judgments Across Six Modalities", "topic_distr": {"0": 0.3183792531490326, "1": 0.0016428274102509022, "2": 0.0013885882217437029, "3": 0.36458876729011536, "4": 0.0010607263538986444, "5": 0.0009487412753514946, "6": 0.0008581443689763546, "7": 0.0007833418203517795, "8": 0.000720534473657608, "9": 0.0006670511793345213, "10": 0.0006209590355865657, "11": 0.0005808250862173736, "12": 0.0005455639911815524, "13": 0.0005143391317687929, "14": 0.06083817780017853, "15": 0.00046151093556545675, "16": 0.00043896757415495813, "17": 0.00041852399590425193, "18": 0.24416030943393707, "19": 0.0003828626358881593}}, {"key": "martin2019tasty", "year": "2019", "title": "Camembert: A Tasty French Language Model", "topic_distr": {"0": 0.002013053512200713, "1": 0.14428295195102692, "2": 0.47602880001068115, "3": 0.0012027586344629526, "4": 0.0010607809526845813, "5": 0.0009487899951636791, "6": 0.0008581880829297006, "7": 0.0007833816925995052, "8": 0.0007205711444839835, "9": 0.0006670851144008338, "10": 0.12614499032497406, "11": 0.0005808546557091177, "12": 0.02998325601220131, "13": 0.0005143653252162039, "14": 0.07218277454376221, "15": 0.00046153442235663533, "16": 0.0004389899258967489, "17": 0.07642017304897308, "18": 0.00039992021629586816, "19": 0.06430675834417343}}, {"key": "maruf2019selective", "year": "2019", "title": "Selective Attention For Context-aware Neural Machine Translation", "topic_distr": {"0": 0.0013274461962282658, "1": 0.001083775539882481, "2": 0.6340608596801758, "3": 0.0007933175074867904, "4": 0.0006996754091233015, "5": 0.0006258076173253357, "6": 0.0005660482565872371, "7": 0.03588399291038513, "8": 0.11331945657730103, "9": 0.015339290723204613, "10": 0.00040959627949632704, "11": 0.00038312317337840796, "12": 0.0003598642651923001, "13": 0.0003392677754163742, "14": 0.1934221386909485, "15": 0.00030442129354923964, "16": 0.00028955130255781114, "17": 0.0002760663046501577, "18": 0.000263781490502879, "19": 0.0002525433956179768}}, {"key": "mass2019study", "year": "2019", "title": "A Study Of BERT For Non-factoid Question-answering Under Passage Length Constraints", "topic_distr": {"0": 0.10210487991571426, "1": 0.0030865517910569906, "2": 0.35604268312454224, "3": 0.002259732224047184, "4": 0.0019929755944758654, "5": 0.0017825700342655182, "6": 0.001612349646165967, "7": 0.0014718046877533197, "8": 0.1918298900127411, "9": 0.0012533084955066442, "10": 0.27614760398864746, "11": 0.0010913001606240869, "12": 0.053494926542043686, "13": 0.0009663811069913208, "14": 0.0009140655165538192, "15": 0.0008671233081258833, "16": 0.0008247670484706759, "17": 0.0007863560458645225, "18": 0.0007513635791838169, "19": 0.000719352625310421}}, {"key": "maynez2020faithfulness", "year": "2020", "title": "On Faithfulness And Factuality In Abstractive Summarization", "topic_distr": {"0": 0.38504257798194885, "1": 0.1588630974292755, "2": 0.0009461204754188657, "3": 0.0008194633992388844, "4": 0.0007227347232401371, "5": 0.0006464321631938219, "6": 0.0005847031134180725, "7": 0.3089044690132141, "8": 0.036684852093458176, "9": 0.0004545002884697169, "10": 0.07027997076511383, "11": 0.0003957495209760964, "12": 0.0003717241052072495, "13": 0.00035044882679358125, "14": 0.000331477087456733, "15": 0.0003144539368804544, "16": 0.00029909383738413453, "17": 0.0002851644530892372, "18": 0.0002724747755564749, "19": 0.033430472016334534}}, {"key": "mazar\u00e92018training", "year": "2018", "title": "Training Millions Of Personalized Dialogue Agents", "topic_distr": {"0": 0.12363775074481964, "1": 0.5420641899108887, "2": 0.001247721491381526, "3": 0.001080669229850173, "4": 0.0009531062096357346, "5": 0.27683645486831665, "6": 0.0007710772915743291, "7": 0.0007038641488179564, "8": 0.0006474292022176087, "9": 0.000599372258875519, "10": 0.0005579566350206733, "11": 0.0005218946607783437, "12": 0.0004902111832052469, "13": 0.04756266996264458, "14": 0.00043713540071621537, "15": 0.0004146861028857529, "16": 0.000394430011510849, "17": 0.00037606063415296376, "18": 0.0003593261062633246, "19": 0.00034401746233925223}}, {"key": "mccarley2019structured", "year": "2019", "title": "Structured Pruning Of A Bert-based Question Answering Model", "topic_distr": {"0": 0.001223335973918438, "1": 0.0009984559146687388, "2": 0.2839241325855255, "3": 0.0007310977089218795, "4": 0.0006447993218898773, "5": 0.0005767247639596462, "6": 0.0005216523422859609, "7": 0.0004761810414493084, "8": 0.10157791525125504, "9": 0.06973887234926224, "10": 0.1680750995874405, "11": 0.0003530743415467441, "12": 0.0003316396614536643, "13": 0.28886350989341736, "14": 0.00029573263600468636, "15": 0.00028054515132680535, "16": 0.0002668414090294391, "17": 0.0002544140734244138, "18": 0.00024309277068823576, "19": 0.08062287420034409}}, {"key": "mccoy2019berts", "year": "2019", "title": "Berts Of A Feather Do Not Generalize Together: Large Variability In Generalization Across Models With Similar Test Set Performance", "topic_distr": {"0": 0.23881006240844727, "1": 0.0014148757327347994, "2": 0.5544750690460205, "3": 0.07130258530378342, "4": 0.0009135314612649381, "5": 0.0008170869550667703, "6": 0.0007390619139187038, "7": 0.0006746394792571664, "8": 0.0006205477402545512, "9": 0.0005744861555285752, "10": 0.07337269932031631, "11": 0.05314336344599724, "12": 0.00046985744847916067, "13": 0.00044296562555246055, "14": 0.00041898543713614345, "15": 0.0003974682476837188, "16": 0.0003780531696975231, "17": 0.00036044648732058704, "18": 0.00034440678427927196, "19": 0.00032973376801237464}}, {"key": "mccoy2021how", "year": "2021", "title": "How Much Do Language Models Copy From Their Training Data? Evaluating Linguistic Novelty In Text Generation Using RAVEN", "topic_distr": {"0": 0.0015418302500620484, "1": 0.06209922209382057, "2": 0.4888331890106201, "3": 0.11578059196472168, "4": 0.0008119579288177192, "5": 0.0007262359140440822, "6": 0.0006568865501321852, "7": 0.24907034635543823, "8": 0.0150936683639884, "9": 0.000510609766934067, "10": 0.0004753274843096733, "11": 0.00044460600474849343, "12": 0.0004176145885139704, "13": 0.0003937128058169037, "14": 0.0003723989357240498, "15": 0.03759663924574852, "16": 0.024255607277154922, "17": 0.00032036888296715915, "18": 0.00030611263355240226, "19": 0.0002930710616055876}}, {"key": "mccoy2023embers", "year": "2023", "title": "Embers Of Autoregression: Understanding Large Language Models Through The Problem They Are Trained To Solve", "topic_distr": {"0": 0.23620359599590302, "1": 0.0009175332961603999, "2": 0.0007756621344015002, "3": 0.46661096811294556, "4": 0.0005925089935772121, "5": 0.0005299553158693016, "6": 0.00047934899339452386, "7": 0.18972131609916687, "8": 0.0004024817608296871, "9": 0.04151826351881027, "10": 0.0003468601207714528, "11": 0.0003244417894165963, "12": 0.00030474536470137537, "13": 0.0002873035555239767, "14": 0.05981101095676422, "15": 0.0002577943669166416, "16": 0.00024520192528143525, "17": 0.0002337823825655505, "18": 0.00022337917471304536, "19": 0.00021386238222476095}}, {"key": "mcguffie2020radicalization", "year": "2020", "title": "The Radicalization Risks Of GPT-3 And Advanced Neural Language Models", "topic_distr": {"0": 0.1696132868528366, "1": 0.001434924895875156, "2": 0.147609680891037, "3": 0.001050327904522419, "4": 0.000926345819607377, "5": 0.0008285469375550747, "6": 0.0007494278252124786, "7": 0.08560020476579666, "8": 0.0006292514153756201, "9": 0.4040404260158539, "10": 0.0005422909744083881, "11": 0.0005072415224276483, "12": 0.09259679168462753, "13": 0.0004491785366553813, "14": 0.00042486199527047575, "15": 0.00040304299909621477, "16": 0.00038335565477609634, "17": 0.09152725338935852, "18": 0.00034923735074698925, "19": 0.0003343585121911019}}, {"key": "mckenna2023sources", "year": "2023", "title": "Sources Of Hallucination By Large Language Models On Inference Tasks", "topic_distr": {"0": 0.39088594913482666, "1": 0.13352850079536438, "2": 0.04952974244952202, "3": 0.18755070865154266, "4": 0.0007071733707562089, "5": 0.0006325145368464291, "6": 0.0005721147172152996, "7": 0.035253144800662994, "8": 0.03989575803279877, "9": 0.00044471511500887573, "10": 0.00041398603934794664, "11": 0.00038722919998690486, "12": 0.03882526978850365, "13": 0.04757948964834213, "14": 0.0003243405371904373, "15": 0.05738919973373413, "16": 0.00029265449848026037, "17": 0.00027902500005438924, "18": 0.0002666085201781243, "19": 0.015241893008351326}}, {"key": "mees2021benchmark", "year": "2021", "title": "CALVIN: A Benchmark For Language-conditioned Policy Learning For Long-horizon Robot Manipulation Tasks", "topic_distr": {"0": 0.10368634015321732, "1": 0.0012572645209729671, "2": 0.0010629474418237805, "3": 0.0009206380345858634, "4": 0.0008119646809063852, "5": 0.0007262422586791217, "6": 0.0006568923126906157, "7": 0.0005996323889121413, "8": 0.0005515546654351056, "9": 0.0005106142489239573, "10": 0.0004753316461574286, "11": 0.679268479347229, "12": 0.15292811393737793, "13": 0.00039371626917272806, "14": 0.0003724022244568914, "15": 0.00035327731166034937, "16": 0.0003360208647791296, "17": 0.00032037170603871346, "18": 0.054475124925374985, "19": 0.0002930736227426678}}, {"key": "mees2022grounding", "year": "2022", "title": "Grounding Language With Visual Affordances Over Unstructured Data", "topic_distr": {"0": 0.0745677724480629, "1": 0.06791956722736359, "2": 0.0009159729816019535, "3": 0.2021474540233612, "4": 0.019829323515295982, "5": 0.0006258177454583347, "6": 0.0005660575116053224, "7": 0.0005167154595255852, "8": 0.00047528589493595064, "9": 0.00044000669731758535, "10": 0.0004096029733773321, "11": 0.39674583077430725, "12": 0.00035987014416605234, "13": 0.00033927333424799144, "14": 0.0003209065762348473, "15": 0.00030442627030424774, "16": 0.00028955601737834513, "17": 0.0002760708157438785, "18": 0.23269793391227722, "19": 0.00025254752836190164}}, {"key": "mees2022what", "year": "2022", "title": "What Matters In Language Conditioned Robotic Imitation Learning Over Unstructured Data", "topic_distr": {"0": 0.001224271603859961, "1": 0.000998709350824356, "2": 0.0529160313308239, "3": 0.1529073268175125, "4": 0.040029317140579224, "5": 0.0005767616676166654, "6": 0.12688305974006653, "7": 0.0004762115713674575, "8": 0.00043802952859550714, "9": 0.00040551580605097115, "10": 0.11585888266563416, "11": 0.30143094062805176, "12": 0.07818043231964111, "13": 0.0003126786323264241, "14": 0.00029575161170214415, "15": 0.0002805631374940276, "16": 0.00026685852208174765, "17": 0.00025443040067330003, "18": 0.1260315328836441, "19": 0.00023275103012565523}}, {"key": "mehri2020natural", "year": "2020", "title": "Dialoglue: A Natural Language Understanding Benchmark For Task-oriented Dialogue", "topic_distr": {"0": 0.001862031756900251, "1": 0.0015202111098915339, "2": 0.0012850461062043905, "3": 0.0909717008471489, "4": 0.0009816462406888604, "5": 0.22656138241291046, "6": 0.000794167397543788, "7": 0.0007249415502883494, "8": 0.0006668166606687009, "9": 0.0006173206493258476, "10": 0.09163188189268112, "11": 0.0005375230102799833, "12": 0.44119685888290405, "13": 0.0004759937583003193, "14": 0.1382274180650711, "15": 0.0004271040088497102, "16": 0.00040624133544042706, "17": 0.00038732189568690956, "18": 0.0003700862289406359, "19": 0.0003543191705830395}}, {"key": "mehri2020unsupervised", "year": "2020", "title": "Unsupervised Evaluation Of Interactive Dialog With Dialogpt", "topic_distr": {"0": 0.00223051430657506, "1": 0.001819176715798676, "2": 0.29842478036880493, "3": 0.0013315619435161352, "4": 0.470655232667923, "5": 0.001050396473146975, "6": 0.09810133278369904, "7": 0.0008672746480442584, "8": 0.0007977376808412373, "9": 0.0007385237840935588, "10": 0.0006874930113554001, "11": 0.0006430587964132428, "12": 0.0006040195585228503, "13": 0.0005694490973837674, "14": 0.000538621679879725, "15": 0.11912481486797333, "16": 0.00048600169247947633, "17": 0.00046336764353327453, "18": 0.0004427479871083051, "19": 0.0004238852416165173}}, {"key": "mehta2020deep", "year": "2020", "title": "Delight: Deep And Light-weight Transformer", "topic_distr": {"0": 0.0020109170582145452, "1": 0.0016424981877207756, "2": 0.0013886267552152276, "3": 0.09318170696496964, "4": 0.001060735434293747, "5": 0.0009487501811236143, "6": 0.0008581526926718652, "7": 0.0007833493291400373, "8": 0.0007205414003692567, "9": 0.0006670575821772218, "10": 0.5069987177848816, "11": 0.0005808306741528213, "12": 0.0005455692298710346, "13": 0.29531195759773254, "14": 0.09119884669780731, "15": 0.00046151535934768617, "16": 0.00043897179421037436, "17": 0.00041852801223285496, "18": 0.0003999037144239992, "19": 0.0003828663029707968}}, {"key": "mei2023chatgpt", "year": "2023", "title": "Wavcaps: A Chatgpt-assisted Weakly-labelled Audio Captioning Dataset For Audio-language Multimodal Research", "topic_distr": {"0": 0.001103593735024333, "1": 0.23808111250400543, "2": 0.0007619222160428762, "3": 0.0006599306361749768, "4": 0.0005820314399898052, "5": 0.0005205831839703023, "6": 0.00047087183338589966, "7": 0.0004298269341234118, "8": 0.00039536398253403604, "9": 0.11126428097486496, "10": 0.0003407259937375784, "11": 0.00031870411476120353, "12": 0.1286313533782959, "13": 0.047550421208143234, "14": 0.000266944378381595, "15": 0.00025323533918708563, "16": 0.0002408656000625342, "17": 0.00022964800882618874, "18": 0.4676884710788727, "19": 0.0002100802812492475}}, {"key": "meister2020if", "year": "2020", "title": "If Beam Search Is The Answer, What Was The Question?", "topic_distr": {"0": 0.1914355456829071, "1": 0.0011193843092769384, "2": 0.0009461907320655882, "3": 0.2641608715057373, "4": 0.0007227763417176902, "5": 0.0006464700563810766, "6": 0.0005847375141456723, "7": 0.2313292920589447, "8": 0.12376367300748825, "9": 0.0004545270057860762, "10": 0.0004231199563946575, "11": 0.0003957727749366313, "12": 0.00037174593308009207, "13": 0.0003504694323055446, "14": 0.08454260975122452, "15": 0.00031447241781279445, "16": 0.00029911144520156085, "17": 0.0002851812168955803, "18": 0.00027249078266322613, "19": 0.09758153557777405}}, {"key": "meister2021language", "year": "2021", "title": "Language Model Evaluation Beyond Perplexity", "topic_distr": {"0": 0.14573833346366882, "1": 0.0014762307982891798, "2": 0.4678788185119629, "3": 0.0010806967038661242, "4": 0.0009531315881758928, "5": 0.0008525056182406843, "6": 0.0007710984791629016, "7": 0.21451899409294128, "8": 0.030157465487718582, "9": 0.0005993887898512185, "10": 0.0005579720018431544, "11": 0.0005219090380705893, "12": 0.13210561871528625, "13": 0.00046216711052693427, "14": 0.00043714744970202446, "15": 0.0004146975406911224, "16": 0.00039444086723960936, "17": 0.00037607099511660635, "18": 0.0003593360015656799, "19": 0.00034402692108415067}}, {"key": "meng2016interactive", "year": "2016", "title": "Interactive Attention For Neural Machine Translation", "topic_distr": {"0": 0.0013001416809856892, "1": 0.001061026006937027, "2": 0.43006211519241333, "3": 0.0007767805946059525, "4": 0.13666759431362152, "5": 0.0006127638625912368, "6": 0.0005542500875890255, "7": 0.03816277161240578, "8": 0.0004653718788176775, "9": 0.05390828475356102, "10": 0.00040105904918164015, "11": 0.0003751377225853503, "12": 0.0003523635969031602, "13": 0.0003321964177303016, "14": 0.3336106836795807, "15": 0.00029807622195221484, "16": 0.0002835161576513201, "17": 0.0002703122445382178, "18": 0.00025828348589129746, "19": 0.000247279618633911}}, {"key": "meng2020large", "year": "2020", "title": "Openvidial: A Large-scale, Open-domain Dialogue Dataset With Visual Contexts", "topic_distr": {"0": 0.0012857968686148524, "1": 0.001050107995979488, "2": 0.0008876926149241626, "3": 0.0007688092882744968, "4": 0.0006780566181987524, "5": 0.151962012052536, "6": 0.33073729276657104, "7": 0.0005007414729334414, "8": 0.00046059268061071634, "9": 0.00042640414903871715, "10": 0.0003969403333030641, "11": 0.0003712851903401315, "12": 0.00034874497214332223, "13": 0.0003287848667241633, "14": 0.00031098592444323003, "15": 0.00029501511016860604, "16": 0.00028060455224476755, "17": 0.00026753623387776315, "18": 0.5083978176116943, "19": 0.0002447401639074087}}, {"key": "meng2021coco", "year": "2021", "title": "COCO-LM: Correcting And Contrasting Text Sequences For Language Model Pretraining", "topic_distr": {"0": 0.0017561623826622963, "1": 0.0014344695955514908, "2": 0.29969948530197144, "3": 0.0010503098601475358, "4": 0.0009263298125006258, "5": 0.0008285321528092027, "6": 0.0007494144374504685, "7": 0.12748020887374878, "8": 0.0006292401812970638, "9": 0.000582533364649862, "10": 0.2287217527627945, "11": 0.0005072324420325458, "12": 0.00047643904690630734, "13": 0.10291537642478943, "14": 0.000424854428274557, "15": 0.00040303581045009196, "16": 0.058554936200380325, "17": 0.0003654954780358821, "18": 0.0003492311225272715, "19": 0.17214497923851013}}, {"key": "meng2022generating", "year": "2022", "title": "Generating Training Data With Language Models: Towards Zero-shot Language Understanding", "topic_distr": {"0": 0.0012228658888489008, "1": 0.12883232533931732, "2": 0.1469367891550064, "3": 0.11027948558330536, "4": 0.0006447532214224339, "5": 0.0005766840768046677, "6": 0.0005216156132519245, "7": 0.11089932173490524, "8": 0.00043797059333883226, "9": 0.0004054612072650343, "10": 0.19357021152973175, "11": 0.0003530494577717036, "12": 0.00033161629107780755, "13": 0.0003126365481875837, "14": 0.00029571179766207933, "15": 0.00028052538982592523, "16": 0.00026682260795496404, "17": 0.3033563792705536, "18": 0.00024307564308401197, "19": 0.00023271969985216856}}, {"key": "meng2022mass", "year": "2022", "title": "Mass-editing Memory In A Transformer", "topic_distr": {"0": 0.0029683979228138924, "1": 0.0024256508331745863, "2": 0.23042677342891693, "3": 0.21671122312545776, "4": 0.0015659108757972717, "5": 0.0014005916891619563, "6": 0.0012668471317738295, "7": 0.0011564188171178102, "8": 0.0010636986698955297, "9": 0.0009847431210801005, "10": 0.0009166990639641881, "11": 0.0008574507664889097, "12": 0.0008053960627876222, "13": 0.3291429579257965, "14": 0.0007181948749348521, "15": 0.0006813116488046944, "16": 0.2051343023777008, "17": 0.0006178516196087003, "18": 0.0005903575220145285, "19": 0.0005652060499414802}}, {"key": "menick2022teaching", "year": "2022", "title": "Teaching Language Models To Support Answers With Verified Quotes", "topic_distr": {"0": 0.25914913415908813, "1": 0.1397467851638794, "2": 0.0009063243051059544, "3": 0.19290903210639954, "4": 0.000692322792019695, "5": 0.04800548776984215, "6": 0.0005600987351499498, "7": 0.0005112761282362044, "8": 0.26079070568084717, "9": 0.0004353748809080571, "10": 0.0004052911826875061, "11": 0.043194133788347244, "12": 0.0003560819022823125, "13": 0.05064864456653595, "14": 0.0003175284946337342, "15": 0.0003012216475326568, "16": 0.00028650794411078095, "17": 0.00027316471096128225, "18": 0.00026100900140590966, "19": 0.0002498890389688313}}, {"key": "merchant2020what", "year": "2020", "title": "What Happens To BERT Embeddings During Fine-tuning?", "topic_distr": {"0": 0.14192570745944977, "1": 0.0015430885832756758, "2": 0.4343779385089874, "3": 0.0011298991739749908, "4": 0.0009965208591893315, "5": 0.0008913149940781295, "6": 0.0008062019478529692, "7": 0.0007359270821325481, "8": 0.000676921394187957, "9": 0.0006266753771342337, "10": 0.26040560007095337, "11": 0.0005456684157252312, "12": 0.0557752288877964, "13": 0.00048320682253688574, "14": 0.0004570481542032212, "15": 0.0004335762350820005, "16": 0.051603879779577255, "17": 0.0003931912360712886, "18": 0.0003756944206543267, "19": 0.045816753059625626}}, {"key": "merity2018analysis", "year": "2018", "title": "An Analysis Of Neural Language Modeling At Multiple Scales", "topic_distr": {"0": 0.003373170970007777, "1": 0.00275287008844316, "2": 0.6012489199638367, "3": 0.0020154661033302546, "4": 0.001777552766725421, "5": 0.0015898891724646091, "6": 0.0014380683423951268, "7": 0.18008960783481598, "8": 0.0012074632104486227, "9": 0.0011178364511579275, "10": 0.0010405958164483309, "11": 0.0009733398328535259, "12": 0.0009142496855929494, "13": 0.19612358510494232, "14": 0.0008152627851814032, "15": 0.0007733945967629552, "16": 0.0007356167188845575, "17": 0.0007013576105237007, "18": 0.0006701474776491523, "19": 0.0006415966781787574}}, {"key": "merity2019single", "year": "2019", "title": "Single Headed Attention RNN: Stop Thinking With Your Head", "topic_distr": {"0": 0.0019484666408970952, "1": 0.001591094653122127, "2": 0.5832287073135376, "3": 0.0011651269160211086, "4": 0.0010275952517986298, "5": 0.0009191085700877011, "6": 0.0008313413709402084, "7": 0.000758875161409378, "8": 0.0006980295293033123, "9": 0.0006462166784331203, "10": 0.11800264567136765, "11": 0.03911610320210457, "12": 0.040677085518836975, "13": 0.20688220858573914, "14": 0.00047130006714724004, "15": 0.0004470962448976934, "16": 0.00042525699245743454, "17": 0.0004054519522469491, "18": 0.0003874095273204148, "19": 0.0003709044249262661}}, {"key": "merullo2022linearly", "year": "2022", "title": "Linearly Mapping From Image To Text Space", "topic_distr": {"0": 0.0500250980257988, "1": 0.0008147804182954133, "2": 0.15835221111774445, "3": 0.0005965691525489092, "4": 0.0005261491169221699, "5": 0.00047060189535841346, "6": 0.0004256634274497628, "7": 0.00038855927414260805, "8": 0.00035740507883019745, "9": 0.0003308758605271578, "10": 0.00030801290995441377, "11": 0.00028810533694922924, "12": 0.0002706148661673069, "13": 0.00025512647698633373, "14": 0.00024131506506819278, "15": 0.00022892221750225872, "16": 0.00021774008928332478, "17": 0.11497075110673904, "18": 0.4963470995426178, "19": 0.17458437383174896}}, {"key": "meyerson2023language", "year": "2023", "title": "Language Model Crossover: Variation Through Few-shot Prompting", "topic_distr": {"0": 0.001807510037906468, "1": 0.0014760879566892982, "2": 0.22455333173274994, "3": 0.357680082321167, "4": 0.000953189330175519, "5": 0.0008525575394742191, "6": 0.0007711455109529197, "7": 0.18343223631381989, "8": 0.0006474864785559475, "9": 0.09820684045553207, "10": 0.0005580060533247888, "11": 0.000521940877661109, "12": 0.0004902545479126275, "13": 0.0004621952830348164, "14": 0.00043717407970689237, "15": 0.00041472280281595886, "16": 0.0003944649070035666, "17": 0.12563736736774445, "18": 0.00035935788764618337, "19": 0.00034404790494591}}, {"key": "mi2020continual", "year": "2020", "title": "Continual Learning For Natural Language Generation In Task-oriented Dialog Systems", "topic_distr": {"0": 0.036256857216358185, "1": 0.0012272248277440667, "2": 0.0010372811229899526, "3": 0.000898402591701597, "4": 0.31306806206703186, "5": 0.0007087021949701011, "6": 0.070376917719841, "7": 0.0005851500318385661, "8": 0.0005382334347814322, "9": 0.0004982818500138819, "10": 0.00046385140740312636, "11": 0.0004338716680649668, "12": 0.20894183218479156, "13": 0.0003842072037514299, "14": 0.0003634079184848815, "15": 0.06122712418437004, "16": 0.3020932674407959, "17": 0.0003126340452581644, "18": 0.00029872197774238884, "19": 0.00028599530924111605}}, {"key": "mialon2023augmented", "year": "2023", "title": "Augmented Language Models: A Survey", "topic_distr": {"0": 0.0012991302646696568, "1": 0.014364580623805523, "2": 0.0008968745823949575, "3": 0.3578971028327942, "4": 0.0989350751042366, "5": 0.06033369153738022, "6": 0.000554258469492197, "7": 0.0005059449467808008, "8": 0.0004653789510484785, "9": 0.0004308351199142635, "10": 0.0004010651318822056, "11": 0.00037514339783228934, "12": 0.15151122212409973, "13": 0.00033220145269297063, "14": 0.00031421755556948483, "15": 0.0002980807621497661, "16": 0.0002835204650182277, "17": 0.0002703163481783122, "18": 0.0002582874149084091, "19": 0.31027308106422424}}, {"key": "miao2023accelerating", "year": "2023", "title": "Specinfer: Accelerating Generative Large Language Model Serving With Tree-based Speculative Inference And Verification", "topic_distr": {"0": 0.0015794661594554782, "1": 0.0012893159873783588, "2": 0.0010899434564635158, "3": 0.2726976275444031, "4": 0.14840644598007202, "5": 0.0007446829695254564, "6": 0.10113122314214706, "7": 0.08895676583051682, "8": 0.0005655596032738686, "9": 0.0005235796561464667, "10": 0.0730610266327858, "11": 0.00045589933870360255, "12": 0.0004282223235350102, "13": 0.21925023198127747, "14": 0.000381858175387606, "15": 0.08815065026283264, "16": 0.00034455303102731705, "17": 0.0003285065176896751, "18": 0.00031388812931254506, "19": 0.00030051529756747186}}, {"key": "michel2019are", "year": "2019", "title": "Are Sixteen Heads Really Better Than One?", "topic_distr": {"0": 0.12526646256446838, "1": 0.001039378927089274, "2": 0.6742196083068848, "3": 0.0007609421154484153, "4": 0.0006711202440783381, "5": 0.0006002679583616555, "6": 0.0005429473822005093, "7": 0.0004956198390573263, "8": 0.00045588170178234577, "9": 0.0004220428236294538, "10": 0.0498214066028595, "11": 0.00036748763523064554, "12": 0.00034517794847488403, "13": 0.10518243163824081, "14": 0.00030780513770878315, "15": 0.00029199765413068235, "16": 0.0002777345071081072, "17": 0.0002647998626343906, "18": 0.0002530163910705596, "19": 0.0384138859808445}}, {"key": "mihaylova2019scheduled", "year": "2019", "title": "Scheduled Sampling For Transformers", "topic_distr": {"0": 0.021303968504071236, "1": 0.0016425529029220343, "2": 0.6370588541030884, "3": 0.001202691812068224, "4": 0.001060725306160748, "5": 0.0009487409261055291, "6": 0.0008581441361457109, "7": 0.2361966073513031, "8": 0.0007205342990346253, "9": 0.0006670510047115386, "10": 0.07554451376199722, "11": 0.0005808249115943909, "12": 0.0005455638165585697, "13": 0.000514339015353471, "14": 0.0004864949733018875, "15": 0.0004615108191501349, "16": 0.019005607813596725, "17": 0.0004185238794889301, "18": 0.0003998997563030571, "19": 0.00038286251947283745}}, {"key": "miller2017dialog", "year": "2017", "title": "Parlai: A Dialog Research Software Platform", "topic_distr": {"0": 0.002227152930572629, "1": 0.05893392488360405, "2": 0.1366560161113739, "3": 0.0013316479744389653, "4": 0.31768378615379333, "5": 0.0010504665551707149, "6": 0.05074247345328331, "7": 0.00086733273928985, "8": 0.0007977911154739559, "9": 0.14163343608379364, "10": 0.0006875390536151826, "11": 0.0006431018700823188, "12": 0.1771445870399475, "13": 0.0005694872234016657, "14": 0.06424877792596817, "15": 0.0005109946941956878, "16": 0.0004860342596657574, "17": 0.0004633986682165414, "18": 0.04289814829826355, "19": 0.0004239136469550431}}, {"key": "min2019multi", "year": "2019", "title": "Multi-hop Reading Comprehension Through Question Decomposition And Rescoring", "topic_distr": {"0": 0.002113214461132884, "1": 0.031197937205433846, "2": 0.5270048975944519, "3": 0.0012639410560950637, "4": 0.038370683789253235, "5": 0.000997052644379437, "6": 0.0009018424316309392, "7": 0.0416114367544651, "8": 0.22769588232040405, "9": 0.0007010184344835579, "10": 0.0006525792414322495, "11": 0.045249465852975845, "12": 0.0005733449361287057, "13": 0.07894666492938995, "14": 0.0005112681537866592, "15": 0.000485011754790321, "16": 0.0004613204800989479, "17": 0.0004398358578328043, "18": 0.0004202633863314986, "19": 0.00040235856431536376}}, {"key": "min2020syntactic", "year": "2020", "title": "Syntactic Data Augmentation Increases Robustness To Inference Heuristics", "topic_distr": {"0": 0.0015406525926664472, "1": 0.23468808829784393, "2": 0.4142635464668274, "3": 0.02967880666255951, "4": 0.0008120046113617718, "5": 0.000726278405636549, "6": 0.0006569249671883881, "7": 0.07699327915906906, "8": 0.0005515820812433958, "9": 0.0005106396274641156, "10": 0.1051178127527237, "11": 0.00044463202357292175, "12": 0.0004176390066277236, "13": 0.000393735826946795, "14": 0.0003724207344930619, "15": 0.00035329489037394524, "16": 0.06399468332529068, "17": 0.0003203876258339733, "18": 0.00030613053240813315, "19": 0.06785745918750763}}, {"key": "min2021following", "year": "2021", "title": "FILM: Following Instructions In Language With Modular Methods", "topic_distr": {"0": 0.0014018923975527287, "1": 0.001144438167102635, "2": 0.17573776841163635, "3": 0.18644537031650543, "4": 0.0007389370002783835, "5": 0.01907319203019142, "6": 0.0005978119443170726, "7": 0.0005457019433379173, "8": 0.0005019482923671603, "9": 0.0004646900051739067, "10": 0.00043258070945739746, "11": 0.3852587938308716, "12": 0.0003800579870585352, "13": 0.00035830572596751153, "14": 0.00033890866325236857, "15": 0.0003215038450434804, "16": 0.13554419577121735, "17": 0.00029155772062949836, "18": 0.09015568345785141, "19": 0.00026671483647078276}}, {"key": "min2021learning", "year": "2021", "title": "Metaicl: Learning To Learn In Context", "topic_distr": {"0": 0.001355941640213132, "1": 0.09131012111902237, "2": 0.34981995820999146, "3": 0.11287562549114227, "4": 0.0007148919976316392, "5": 0.0006394180236384273, "6": 0.0005783590604551136, "7": 0.0005279447650536895, "8": 0.033967431634664536, "9": 0.00044956893543712795, "10": 0.00041850446723401546, "11": 0.07127503305673599, "12": 0.0003676908672787249, "13": 0.054189443588256836, "14": 0.0003278805234003812, "15": 0.00031104206573218107, "16": 0.0002958486438728869, "17": 0.24657703936100006, "18": 0.0002695184084586799, "19": 0.03372872248291969}}, {"key": "min2021recent", "year": "2021", "title": "Recent Advances In Natural Language Processing Via Large Pre-trained Language Models: A Survey", "topic_distr": {"0": 0.0025973329320549965, "1": 0.06774495542049408, "2": 0.0017934517236426473, "3": 0.26988765597343445, "4": 0.0013700103154405951, "5": 0.0012253739405423403, "6": 0.0011083611752837896, "7": 0.07738011330366135, "8": 0.0009306270512752235, "9": 0.000861549109686166, "10": 0.1529655009508133, "11": 0.0007501813233830035, "12": 0.41737768054008484, "13": 0.0006643094820901752, "14": 0.000628346751909703, "15": 0.0005960777052678168, "16": 0.0005669611855410039, "17": 0.0005405566771514714, "18": 0.0005165021866559982, "19": 0.0004944972461089492}}, {"key": "min2022rethinking", "year": "2022", "title": "Rethinking The Role Of Demonstrations: What Makes In-context Learning Work?", "topic_distr": {"0": 0.12543298304080963, "1": 0.132158100605011, "2": 0.1509275734424591, "3": 0.11417888849973679, "4": 0.0008220734307542443, "5": 0.0007352845859713852, "6": 0.000665071012917906, "7": 0.0006070982199162245, "8": 0.009365229867398739, "9": 0.0005169717478565872, "10": 0.15277110040187836, "11": 0.19721587002277374, "12": 0.0004228178586345166, "13": 0.00039861828554421663, "14": 0.0003770388721022755, "15": 0.0003576758608687669, "16": 0.0003402045404072851, "17": 0.08790287375450134, "18": 0.0003099266323260963, "19": 0.024494580924510956}}, {"key": "min2023fine", "year": "2023", "title": "Factscore: Fine-grained Atomic Evaluation Of Factual Precision In Long Form Text Generation", "topic_distr": {"0": 0.2939874529838562, "1": 0.05627787113189697, "2": 0.0008359226048924029, "3": 0.1276656538248062, "4": 0.000638550438452512, "5": 0.0005711358389817178, "6": 0.000516597181558609, "7": 0.05863737314939499, "8": 0.0004337569116614759, "9": 0.07197505235671997, "10": 0.00037381317815743387, "11": 0.0003496528079267591, "12": 0.000328425841871649, "13": 0.035284001380205154, "14": 0.0002928667818196118, "15": 0.2633260488510132, "16": 0.032005880028009415, "17": 0.000251948629738763, "18": 0.0002407370338914916, "19": 0.0560072585940361}}, {"key": "minervini2018adversarially", "year": "2018", "title": "Adversarially Regularising Neural NLI Models To Integrate Logical Background Knowledge", "topic_distr": {"0": 0.0011555904056876898, "1": 0.267514169216156, "2": 0.2772393822669983, "3": 0.21986930072307587, "4": 0.0006089784437790513, "5": 0.0005446865106932819, "6": 0.0004926735418848693, "7": 0.04558664187788963, "8": 0.0004136695933993906, "9": 0.00038296403363347054, "10": 0.0003565018414519727, "11": 0.00033346033887937665, "12": 0.00031321641290560365, "13": 0.00029528976301662624, "14": 0.033186234533786774, "15": 0.00026496031205169857, "16": 0.15075261890888214, "17": 0.00024028087500482798, "18": 0.0002295884769409895, "19": 0.0002198071451857686}}, {"key": "miotto2022who", "year": "2022", "title": "Who Is GPT-3? An Exploration Of Personality, Values And Demographics", "topic_distr": {"0": 0.48008349537849426, "1": 0.001959429820999503, "2": 0.0016558130737394094, "3": 0.16890929639339447, "4": 0.0012648383853957057, "5": 0.0011313051218166947, "6": 0.0010232750792056322, "7": 0.0009340784163214266, "8": 0.0378052294254303, "9": 0.10629145056009293, "10": 0.0007404487114399672, "11": 0.0006925918278284371, "12": 0.16573700308799744, "13": 0.0006133121787570417, "14": 0.0005801101797260344, "15": 0.0005503183347173035, "16": 0.02859555184841156, "17": 0.0004990595625713468, "18": 0.00047685165191069245, "19": 0.00045653595589101315}}, {"key": "mirchandani2023large", "year": "2023", "title": "Large Language Models As General Pattern Machines", "topic_distr": {"0": 0.0012871351791545749, "1": 0.0010501567739993334, "2": 0.15630033612251282, "3": 0.3360700309276581, "4": 0.0006781277479603887, "5": 0.0006065351190045476, "6": 0.0005486159934662282, "7": 0.07684539258480072, "8": 0.00046064125490374863, "9": 0.08208368718624115, "10": 0.0003969821846112609, "11": 0.23086856305599213, "12": 0.0003487817302811891, "13": 0.09274093806743622, "14": 0.00031101872446015477, "15": 0.0002950462221633643, "16": 0.00028063415084034204, "17": 0.018326979130506516, "18": 0.0002556579711381346, "19": 0.0002447659499011934}}, {"key": "mirowski2022co", "year": "2022", "title": "Co-writing Screenplays And Theatre Scripts With Language Models: An Evaluation By Industry Professionals", "topic_distr": {"0": 0.19326317310333252, "1": 0.0015429453924298286, "2": 0.0013044613879173994, "3": 0.0011298754252493382, "4": 0.000996501767076552, "5": 0.0008912968332879245, "6": 0.10217054188251495, "7": 0.13400329649448395, "8": 0.0006769070751033723, "9": 0.4104931950569153, "10": 0.000583360786549747, "11": 0.0005456568906083703, "12": 0.0005125307943671942, "13": 0.00048319657798856497, "14": 0.0004570384626276791, "15": 0.0004335670673754066, "16": 0.11113425344228745, "17": 0.03864284232258797, "18": 0.000375686475308612, "19": 0.00035968079464510083}}, {"key": "mishra2021cross", "year": "2021", "title": "Cross-task Generalization Via Natural Language Crowdsourcing Instructions", "topic_distr": {"0": 0.12404152750968933, "1": 0.001095302402973175, "2": 0.0777503252029419, "3": 0.11188974976539612, "4": 0.0007072004955261946, "5": 0.0006325375870801508, "6": 0.000572135322727263, "7": 0.0005222635227255523, "8": 0.0004803891060873866, "9": 0.017435094341635704, "10": 0.00041400096961297095, "11": 0.27536338567733765, "12": 0.08984531462192535, "13": 0.00034291617339476943, "14": 0.00032435220782645047, "15": 0.08348695933818817, "16": 0.0002926650340668857, "17": 0.21428200602531433, "18": 0.00026661812444217503, "19": 0.000255259161349386}}, {"key": "mishra2021reframing", "year": "2021", "title": "Reframing Instructional Prompts To Gptk's Language", "topic_distr": {"0": 0.0015219557099044323, "1": 0.0012422559084370732, "2": 0.001049969345331192, "3": 0.41269823908805847, "4": 0.000802046328317374, "5": 0.000717369606718421, "6": 0.0006488669314421713, "7": 0.0005923065473325551, "8": 0.013826470822095871, "9": 0.0005043759592808783, "10": 0.00046952441334724426, "11": 0.1355346441268921, "12": 0.049845028668642044, "13": 0.043355029076337814, "14": 0.00036785248084925115, "15": 0.0003489612718112767, "16": 0.00033191562397405505, "17": 0.24269181489944458, "18": 0.00030237543978728354, "19": 0.09314902126789093}}, {"key": "misra2022enabling", "year": "2022", "title": "Minicons: Enabling Flexible Behavioral And Representational Analyses Of Transformer Language Models", "topic_distr": {"0": 0.046616170555353165, "1": 0.0016167315188795328, "2": 0.001366728451102972, "3": 0.1749543845653534, "4": 0.0010440127225592732, "5": 0.0009337913943454623, "6": 0.0008446220308542252, "7": 0.07447396963834763, "8": 0.000709180545527488, "9": 0.0006565399817191064, "10": 0.46470773220062256, "11": 0.0005716726300306618, "12": 0.10892851650714874, "13": 0.0005062343552708626, "14": 0.0004788290534634143, "15": 0.052411701530218124, "16": 0.00043205046677030623, "17": 0.00041192900971509516, "18": 0.00039359836955554783, "19": 0.0679415836930275}}, {"key": "mitchell2021fast", "year": "2021", "title": "Fast Model Editing At Scale", "topic_distr": {"0": 0.10885671526193619, "1": 0.0008706212975084782, "2": 0.24686811864376068, "3": 0.14386676251888275, "4": 0.020588897168636322, "5": 0.0005028022569604218, "6": 0.00045478882384486496, "7": 0.1501520425081253, "8": 0.00038185997982509434, "9": 0.0003535155556164682, "10": 0.1074814647436142, "11": 0.00030781852547079325, "12": 0.00028913127607665956, "13": 0.21765375137329102, "14": 0.00025782667216844857, "15": 0.00024458588450215757, "16": 0.00023263863113243133, "17": 0.00022180419182404876, "18": 0.00021193400607444346, "19": 0.00020290481916163117}}, {"key": "mitchell2022debate", "year": "2022", "title": "The Debate Over Understanding In Ai's Large Language Models", "topic_distr": {"0": 0.13278478384017944, "1": 0.09953261911869049, "2": 0.0019134187605232, "3": 0.0016572991153225303, "4": 0.0014616632834076881, "5": 0.0013073498848825693, "6": 0.0011825088877230883, "7": 0.00107943220064044, "8": 0.01760351099073887, "9": 0.42583945393562317, "10": 0.0008556714165024459, "11": 0.0008003675029613078, "12": 0.30970656871795654, "13": 0.0007087509147822857, "14": 0.0006703822873532772, "15": 0.0006359544931910932, "16": 0.000604890170507133, "17": 0.0005767192342318594, "18": 0.0005510554765351117, "19": 0.000527578464243561}}, {"key": "mitchell2022memory", "year": "2022", "title": "Memory-based Model Editing At Scale", "topic_distr": {"0": 0.05736728385090828, "1": 0.0011710249818861485, "2": 0.3056713342666626, "3": 0.25049272179603577, "4": 0.0007559936493635178, "5": 0.018351275473833084, "6": 0.0006116105359978974, "7": 0.14446061849594116, "8": 0.0660538375377655, "9": 0.00047541590174660087, "10": 0.00044256544788368046, "11": 0.00041396147571504116, "12": 0.00038883043453097343, "13": 0.0003665760741569102, "14": 0.0003467312781140208, "15": 0.00032892473973333836, "16": 0.15144509077072144, "17": 0.0002982873993460089, "18": 0.00028501375345513225, "19": 0.00027287108241580427}}, {"key": "mitra2023compositional", "year": "2023", "title": "Compositional Chain-of-thought Prompting For Large Multimodal Models", "topic_distr": {"0": 0.0010225350270047784, "1": 0.08784499764442444, "2": 0.0007056790636852384, "3": 0.13421960175037384, "4": 0.0005390611477196217, "5": 0.0004821504116989672, "6": 0.01696995459496975, "7": 0.00039809438749216497, "8": 0.0003661756927613169, "9": 0.00033899545087479055, "10": 0.0003155714366585016, "11": 0.06719231605529785, "12": 0.00027725566178560257, "13": 0.0002613872056826949, "14": 0.00024723686510697007, "15": 0.00023453989706467837, "16": 0.13343876600265503, "17": 0.06145264953374863, "18": 0.3534368574619293, "19": 0.1402561515569687}}, {"key": "mitra2023orca", "year": "2023", "title": "Orca 2: Teaching Small Language Models How To Reason", "topic_distr": {"0": 0.08772815018892288, "1": 0.0008857277571223676, "2": 0.0007486593094654381, "3": 0.4059547483921051, "4": 0.0005718937609344721, "5": 0.011593421921133995, "6": 0.0004626711888704449, "7": 0.0004223411378916353, "8": 0.0003884783654939383, "9": 0.0003596426686272025, "10": 0.00033479195553809404, "11": 0.1435008943080902, "12": 0.0654662549495697, "13": 0.18395701050758362, "14": 0.0002622953325044364, "15": 0.0002488250320311636, "16": 0.00023667070490773767, "17": 0.00022564848768524826, "18": 0.00021560722962021828, "19": 0.0964362695813179}}, {"key": "mitrovi\u01072023chatgpt", "year": "2023", "title": "Chatgpt Or Human? Detect And Explain. Explaining Decisions Of Machine Learning Model For Detecting Short Chatgpt-generated Text", "topic_distr": {"0": 0.22669777274131775, "1": 0.020040780305862427, "2": 0.14773333072662354, "3": 0.08881271630525589, "4": 0.0005435704370029271, "5": 0.06445632874965668, "6": 0.0004397564334794879, "7": 0.21506498754024506, "8": 0.019957881420850754, "9": 0.18441715836524963, "10": 0.00031821068841964006, "11": 0.00029764403006993234, "12": 0.02962995320558548, "13": 0.00026357328169979155, "14": 0.00024930460494942963, "15": 0.00023650145158171654, "16": 0.00022494910808745772, "17": 0.00021447277686093003, "18": 0.0002049288450507447, "19": 0.000196198103367351}}, {"key": "mizrahi2023state", "year": "2023", "title": "State Of What Art? A Call For Multi-prompt LLM Evaluation", "topic_distr": {"0": 0.0015818413812667131, "1": 0.0012893525417894125, "2": 0.0010898439213633537, "3": 0.6777101755142212, "4": 0.0008325159433297813, "5": 0.0007446231902576983, "6": 0.0006735175848007202, "7": 0.0006148085813038051, "8": 0.0005655139684677124, "9": 0.0005235373973846436, "10": 0.0004873618599958718, "11": 0.0004558625805657357, "12": 0.3109959661960602, "13": 0.000403680867748335, "14": 0.0003818273835349828, "15": 0.0003622184449341148, "16": 0.00034452523686923087, "17": 0.000328480004100129, "18": 0.0003138628089800477, "19": 0.0003004910540767014}}, {"key": "mo2017fine", "year": "2017", "title": "Fine Grained Knowledge Transfer For Personalized Task-oriented Dialogue Systems", "topic_distr": {"0": 0.0012859106063842773, "1": 0.0010502480436116457, "2": 0.3104044795036316, "3": 0.0007687895558774471, "4": 0.2999095320701599, "5": 0.10232701897621155, "6": 0.0005485477158799767, "7": 0.027576997876167297, "8": 0.0004605839494615793, "9": 0.0004263960581738502, "10": 0.04482563957571983, "11": 0.000371278147213161, "12": 0.00034873836557380855, "13": 0.00032877863850444555, "14": 0.11826018244028091, "15": 0.05309825390577316, "16": 0.03724076598882675, "17": 0.0002675311698112637, "18": 0.0002556261606514454, "19": 0.00024473550729453564}}, {"key": "mo2024large", "year": "2024", "title": "Large Language Model (LLM) AI Text Generation Detection Based On Transformer Deep Learning Algorithm", "topic_distr": {"0": 0.0011572890216484666, "1": 0.000943260733038187, "2": 0.2970524728298187, "3": 0.08324576914310455, "4": 0.000609075534157455, "5": 0.0005447720177471638, "6": 0.0004927508998662233, "7": 0.03792087361216545, "8": 0.00041373458225280046, "9": 0.1648736447095871, "10": 0.19213837385177612, "11": 0.00033351272577419877, "12": 0.000313265627482906, "13": 0.04175944998860359, "14": 0.0002793479652609676, "15": 0.17698056995868683, "16": 0.00025205741985701025, "17": 0.00024031862267293036, "18": 0.00022962455113884062, "19": 0.00021984167688060552}}, {"key": "moghaddam2023boosting", "year": "2023", "title": "Boosting Theory-of-mind Performance In Large Language Models Via Prompting", "topic_distr": {"0": 0.10895486921072006, "1": 0.018196342512965202, "2": 0.0009357773815281689, "3": 0.6644070148468018, "4": 0.0007148304721340537, "5": 0.000639363017398864, "6": 0.0005783092929050326, "7": 0.0005278993048705161, "8": 0.00048557299305684865, "9": 0.0004495302273426205, "10": 0.00041846843669191003, "11": 0.20123346149921417, "12": 0.000367659202311188, "13": 0.00034661657991819084, "14": 0.0003278522926848382, "15": 0.0003110152902081609, "16": 0.00029582317802123725, "17": 0.0002820461231749505, "18": 0.00026949518360197544, "19": 0.0002580136642791331}}, {"key": "moghe2018towards", "year": "2018", "title": "Towards Exploiting Background Knowledge For Building Conversation Systems", "topic_distr": {"0": 0.001124488189816475, "1": 0.000917766650673002, "2": 0.17420433461666107, "3": 0.0006718359072692692, "4": 0.07864892482757568, "5": 0.0005299769109115005, "6": 0.3280390501022339, "7": 0.09387044608592987, "8": 0.11226514726877213, "9": 0.00037262184196151793, "10": 0.0003468742943368852, "11": 0.0003244550316594541, "12": 0.024146415293216705, "13": 0.00028731528436765075, "14": 0.00027176132425665855, "15": 0.0002578048733994365, "16": 0.1830497682094574, "17": 0.00023379192862194031, "18": 0.00022338829876389354, "19": 0.00021387111337389797}}, {"key": "mohankumar2020towards", "year": "2020", "title": "Towards Transparent And Explainable Attention Models", "topic_distr": {"0": 0.13672523200511932, "1": 0.0007223471766337752, "2": 0.4658583104610443, "3": 0.027248330414295197, "4": 0.017530154436826706, "5": 0.1481507569551468, "6": 0.00037739260005764663, "7": 0.09525968134403229, "8": 0.00031687485170550644, "9": 0.00029335409635677934, "10": 0.10565780103206635, "11": 0.0002554337843321264, "12": 0.00023992675414774567, "13": 0.00022619478113483638, "14": 0.00021394959185272455, "15": 0.00020296212460380048, "16": 0.00019304806482978165, "17": 0.0001840574259404093, "18": 0.0001758669677656144, "19": 0.00016837436123751104}}, {"key": "moiseev2022structured", "year": "2022", "title": "SKILL: Structured Knowledge Infusion For Large Language Models", "topic_distr": {"0": 0.001620501047000289, "1": 0.13426616787910461, "2": 0.14509156346321106, "3": 0.21535445749759674, "4": 0.0008540841517969966, "5": 0.0007639150717295706, "6": 0.0006909676012583077, "7": 0.000630737456958741, "8": 0.0005801657098345459, "9": 0.0005371015868149698, "10": 0.0004999887896701694, "11": 0.000467673409730196, "12": 0.00043928157538175583, "13": 0.06319323927164078, "14": 0.08469502627849579, "15": 0.00037160306237637997, "16": 0.3489762246608734, "17": 0.0003369905170984566, "18": 0.00032199459383264184, "19": 0.0003082763869315386}}, {"key": "mollick2023assigning", "year": "2023", "title": "Assigning AI: Seven Approaches For Students, With Prompts", "topic_distr": {"0": 0.14890910685062408, "1": 0.0013952016597613692, "2": 0.0011793661396950483, "3": 0.19525854289531708, "4": 0.000900903542060405, "5": 0.0008057912345975637, "6": 0.0007288449560292065, "7": 0.0006653130985796452, "8": 0.0006119691533967853, "9": 0.5475147366523743, "10": 0.0005273970891721547, "11": 0.0004933102172799408, "12": 0.0004633620264939964, "13": 0.0004368419467937201, "14": 0.0004131932510063052, "15": 0.00039197353180497885, "16": 0.0003728268784470856, "17": 0.09826651215553284, "18": 0.000339645630447194, "19": 0.00032517543877474964}}, {"key": "mollo2023vector", "year": "2023", "title": "The Vector Grounding Problem", "topic_distr": {"0": 0.15525862574577332, "1": 0.0008281341870315373, "2": 0.10920187085866928, "3": 0.20186346769332886, "4": 0.09134046733379364, "5": 0.07738422602415085, "6": 0.0004326175549067557, "7": 0.00039490722701884806, "8": 0.0003632440639194101, "9": 0.08306021243333817, "10": 0.00031304496224038303, "11": 0.07849959284067154, "12": 0.00027503594174049795, "13": 0.00025929452385753393, "14": 0.0002452574553899467, "15": 0.02926931530237198, "16": 0.0655510351061821, "17": 0.00021099108562339097, "18": 0.10505561530590057, "19": 0.00019301306747365743}}, {"key": "moon2018multimodal", "year": "2018", "title": "Multimodal Named Entity Recognition For Short Social Media Posts", "topic_distr": {"0": 0.09221802651882172, "1": 0.001171165145933628, "2": 0.000989692285656929, "3": 0.0008571965154260397, "4": 0.0007560130907222629, "5": 0.0006761979893781245, "6": 0.11926624923944473, "7": 0.07705911993980408, "8": 0.0005135477404110134, "9": 0.07704256474971771, "10": 0.0004425771767273545, "11": 0.00041397244785912335, "12": 0.00038884070818312466, "13": 0.00036658579483628273, "14": 0.00034674047492444515, "15": 0.0003289334417786449, "16": 0.17044080793857574, "17": 0.00029829531558789313, "18": 0.456150621175766, "19": 0.000272878329269588}}, {"key": "moon2020situated", "year": "2020", "title": "Situated And Interactive Multimodal Conversations", "topic_distr": {"0": 0.0011985601158812642, "1": 0.000979459029622376, "2": 0.0008278502500616014, "3": 0.0007170106400735676, "4": 0.1739327609539032, "5": 0.0005656123976223171, "6": 0.23534201085567474, "7": 0.00046700576785951853, "8": 0.0004295618273317814, "9": 0.000397676631109789, "10": 0.0003701978421304375, "11": 0.09074057638645172, "12": 0.08627504855394363, "13": 0.000306634115986526, "14": 0.0002900343097280711, "15": 0.00027513946406543255, "16": 0.04991127923130989, "17": 0.00024951191153377295, "18": 0.35649585723876953, "19": 0.00022825163614470512}}, {"key": "moon2021multi", "year": "2021", "title": "Multi-modal Understanding And Generation For Medical Images And Text Via Vision-language Pre-training", "topic_distr": {"0": 0.0015395351219922304, "1": 0.0012572580017149448, "2": 0.001062934286892414, "3": 0.0009206075919792056, "4": 0.0008119374979287386, "5": 0.0007262180442921817, "6": 0.0006568703101947904, "7": 0.0005996123654767871, "8": 0.06002982333302498, "9": 0.0005105971358716488, "10": 0.15950225293636322, "11": 0.00044459503260441124, "12": 0.20135556161403656, "13": 0.00039370308513753116, "14": 0.00037238976801745594, "15": 0.11049752682447433, "16": 0.00033600960159674287, "17": 0.12195265293121338, "18": 0.3367368280887604, "19": 0.00029306384385563433}}, {"key": "moor2023med", "year": "2023", "title": "Med-flamingo: A Multimodal Medical Few-shot Learner", "topic_distr": {"0": 0.05468643829226494, "1": 0.06364408135414124, "2": 0.0008609784417785704, "3": 0.0007457314059138298, "4": 0.022997288033366203, "5": 0.0005882663535885513, "6": 0.0005320918862707913, "7": 0.0004857105959672481, "8": 0.02047012560069561, "9": 0.00041360463364981115, "10": 0.0003850252542179078, "11": 0.04453442618250847, "12": 0.32701197266578674, "13": 0.027351489290595055, "14": 0.0003016509872395545, "15": 0.14515787363052368, "16": 0.00027218155446462333, "17": 0.00025950552662834525, "18": 0.2890641689300537, "19": 0.00023739371681585908}}, {"key": "moradi2021evaluating", "year": "2021", "title": "Evaluating The Robustness Of Neural Language Models To Input Perturbations", "topic_distr": {"0": 0.09973917156457901, "1": 0.21338391304016113, "2": 0.1876930296421051, "3": 0.21040338277816772, "4": 0.036638420075178146, "5": 0.0006609581760130823, "6": 0.0005978422123007476, "7": 0.0005457295919768512, "8": 0.0005019736709073186, "9": 0.0004647135210689157, "10": 0.11639171093702316, "11": 0.0004046425165142864, "12": 0.1304130256175995, "13": 0.0003583238576538861, "14": 0.0003389258054085076, "15": 0.0003215201140847057, "16": 0.0003058148722629994, "17": 0.0002915724762715399, "18": 0.00027859763940796256, "19": 0.0002667283115442842}}, {"key": "moradi2021gpt", "year": "2021", "title": "GPT-3 Models Are Poor Few-shot Learners In The Biomedical Domain", "topic_distr": {"0": 0.0013430377002805471, "1": 0.0010952458251267672, "2": 0.0009258000063709915, "3": 0.0008018400403670967, "4": 0.0007071875152178109, "5": 0.0006325269350782037, "6": 0.0005721259512938559, "7": 0.000522255024407059, "8": 0.00048038127715699375, "9": 0.0004447238752618432, "10": 0.10485272854566574, "11": 0.0003872368251904845, "12": 0.0003637282061390579, "13": 0.1558314561843872, "14": 0.11545310169458389, "15": 0.4286530017852783, "16": 0.0002926602610386908, "17": 0.00027903050067834556, "18": 0.0002666137588676065, "19": 0.18609529733657837}}, {"key": "moryossef2019step", "year": "2019", "title": "Step-by-step: Separating Planning From Realization In Neural Data-to-text Generation", "topic_distr": {"0": 0.0361437164247036, "1": 0.0011705491924658418, "2": 0.27145782113075256, "3": 0.03710409998893738, "4": 0.03703811764717102, "5": 0.0006761354161426425, "6": 0.0006115700816735625, "7": 0.5694749355316162, "8": 0.0005135001847520471, "9": 0.0004753844696097076, "10": 0.00044253619853407145, "11": 0.0004139340890105814, "12": 0.0003888047067448497, "13": 0.0003665518306661397, "14": 0.04222451150417328, "15": 0.0003289029991719872, "16": 0.0003128371317870915, "17": 0.00029826766694895923, "18": 0.0002849948941729963, "19": 0.0002728530380409211}}, {"key": "mosbach2020stability", "year": "2020", "title": "On The Stability Of Fine-tuning BERT: Misconceptions, Explanations, And Strong Baselines", "topic_distr": {"0": 0.11904805898666382, "1": 0.05467614158987999, "2": 0.3431747555732727, "3": 0.0008285666699521244, "4": 0.0007307594642043114, "5": 0.040388934314250946, "6": 0.0005911959451623261, "7": 0.0005396626656875014, "8": 0.0004963931860402226, "9": 0.0004595473001245409, "10": 0.2175099104642868, "11": 0.0004001441120635718, "12": 0.00037585190148092806, "13": 0.11010235548019409, "14": 0.0003351579653099179, "15": 0.0003179457562509924, "16": 0.029697401449084282, "17": 0.00028833106625825167, "18": 0.0002755004679784179, "19": 0.07976336032152176}}, {"key": "mosbach2023few", "year": "2023", "title": "Few-shot Fine-tuning Vs. In-context Learning: A Fair Comparison And Evaluation", "topic_distr": {"0": 0.23846697807312012, "1": 0.0014148326590657234, "2": 0.2707546353340149, "3": 0.0986466035246849, "4": 0.0009135632426477969, "5": 0.0008171136723831296, "6": 0.0007390861283056438, "7": 0.01734362542629242, "8": 0.0006205681129358709, "9": 0.0005745050148107111, "10": 0.0005348076811060309, "11": 0.0005002418765798211, "12": 0.0004698728444054723, "13": 0.11266975104808807, "14": 0.00041899914504028857, "15": 0.00039748125709593296, "16": 0.0003780655679292977, "17": 0.25366508960723877, "18": 0.0003444180765654892, "19": 0.0003297445655334741}}, {"key": "moslem2023adaptive", "year": "2023", "title": "Adaptive Machine Translation With Large Language Models", "topic_distr": {"0": 0.001166863483376801, "1": 0.04212391376495361, "2": 0.25034794211387634, "3": 0.22044247388839722, "4": 0.0006147039239294827, "5": 0.0005498072132468224, "6": 0.0004973051254637539, "7": 0.04524962604045868, "8": 0.00041755850543268025, "9": 0.00038656426477245986, "10": 0.00035985332215204835, "11": 0.0003365951997693628, "12": 0.0003161609638482332, "13": 0.00029806577367708087, "14": 0.26782938838005066, "15": 0.0002674511924851686, "16": 0.00025438706506974995, "17": 0.16808772087097168, "18": 0.0002317468315595761, "19": 0.00022187354625202715}}, {"key": "mostafazadeh2016generating", "year": "2016", "title": "Generating Natural Questions About An Image", "topic_distr": {"0": 0.10213741660118103, "1": 0.001083688228391111, "2": 0.0009160227491520345, "3": 0.0007933783927001059, "4": 0.0006997262826189399, "5": 0.0006258526700548828, "6": 0.0005660890601575375, "7": 0.0005167442723177373, "8": 0.2277357280254364, "9": 0.0004400312027428299, "10": 0.00040962579078041017, "11": 0.11369550973176956, "12": 0.1368267834186554, "13": 0.00033929222263395786, "14": 0.00032092444598674774, "15": 0.06015170365571976, "16": 0.00028957214090041816, "17": 0.00027608618256635964, "18": 0.35192325711250305, "19": 0.00025256158551201224}}, {"key": "mostafazadeh2017image", "year": "2017", "title": "Image-grounded Conversations: Multimodal Context For Natural Question And Response Generation", "topic_distr": {"0": 0.12817920744419098, "1": 0.0014552342472597957, "2": 0.027039766311645508, "3": 0.0010654190555214882, "4": 0.0009396531386300921, "5": 0.0008404484833590686, "6": 0.3654599189758301, "7": 0.0006939282175153494, "8": 0.0006382899591699243, "9": 0.09426663815975189, "10": 0.0005500804400071502, "11": 0.0005145274917595088, "12": 0.0912783220410347, "13": 0.00045563053572550416, "14": 0.0004309647192712873, "15": 0.00040883233305066824, "16": 0.0003888621577061713, "17": 0.00037075209547765553, "18": 0.284684419631958, "19": 0.0003391612262930721}}, {"key": "motger2021software", "year": "2021", "title": "Software-based Dialogue Systems: Survey, Taxonomy And Challenges", "topic_distr": {"0": 0.0011771073332056403, "1": 0.0009608648251742125, "2": 0.16152144968509674, "3": 0.0007035784656181931, "4": 0.0006205250974744558, "5": 0.08831965923309326, "6": 0.10644125938415527, "7": 0.0004582546534948051, "8": 0.00042151237721554935, "9": 0.28836336731910706, "10": 0.0003632607695180923, "11": 0.07452882826328278, "12": 0.2743053138256073, "13": 0.00030088817584328353, "14": 0.0002845994313247502, "15": 0.0002699836913961917, "16": 0.0002567958435975015, "17": 0.0002448363520670682, "18": 0.00023394126037601382, "19": 0.00022397447901312262}}, {"key": "motlagh2023impact", "year": "2023", "title": "The Impact Of Artificial Intelligence On The Evolution Of Digital Education: A Comparative Study Of Openai Text Generation Tools Including Chatgpt, Bing Chat, Bard, And Ernie", "topic_distr": {"0": 0.0013433530693873763, "1": 0.039766740053892136, "2": 0.0009258426143787801, "3": 0.0008019107626751065, "4": 0.0007072508451528847, "5": 0.0006325835711322725, "6": 0.0005721772322431207, "7": 0.06849920004606247, "8": 0.00048042426351457834, "9": 0.7806388735771179, "10": 0.0004140312667004764, "11": 0.0003872714878525585, "12": 0.00036376077332533896, "13": 0.00034294126089662313, "14": 0.00032437595655210316, "15": 0.00030771747697144747, "16": 0.10269059985876083, "17": 0.00027905547176487744, "18": 0.00026663762400858104, "19": 0.0002552778460085392}}, {"key": "motlagh2024large", "year": "2024", "title": "Large Language Models In Cybersecurity: State-of-the-art", "topic_distr": {"0": 0.046980537474155426, "1": 0.12456224858760834, "2": 0.001411543576978147, "3": 0.001222593360580504, "4": 0.001078274566680193, "5": 0.0009644368547014892, "6": 0.0008723412756808102, "7": 0.0007963011739775538, "8": 0.0007324547623284161, "9": 0.42994171380996704, "10": 0.0006312319892458618, "11": 0.0005904340650886297, "12": 0.3870619535446167, "13": 0.0005228482186794281, "14": 0.0004945435211993754, "15": 0.0004691460053436458, "16": 0.00044622973655350506, "17": 0.0004254479135852307, "18": 0.0004065156972501427, "19": 0.0003891965898219496}}, {"key": "moudgil2021scene", "year": "2021", "title": "SOAT: A Scene- And Object-aware Transformer For Vision-and-language Navigation", "topic_distr": {"0": 0.14195141196250916, "1": 0.03602854162454605, "2": 0.17975756525993347, "3": 0.0008378148195333779, "4": 0.0007389188394881785, "5": 0.000660908583085984, "6": 0.0005977973924018443, "7": 0.0005456886719912291, "8": 0.0005019360687583685, "9": 0.000464678683783859, "10": 0.07972337305545807, "11": 0.2717069387435913, "12": 0.00038004873204045, "13": 0.00035829702392220497, "14": 0.00033890039776451886, "15": 0.00032149601611308753, "16": 0.00030579196754842997, "17": 0.0002915506192948669, "18": 0.26041844487190247, "19": 0.024069909006357193}}, {"key": "mu2021self", "year": "2021", "title": "SLIP: Self-supervision Meets Language-image Pre-training", "topic_distr": {"0": 0.0015038936398923397, "1": 0.0012271414743736386, "2": 0.4506321847438812, "3": 0.0008984492742456496, "4": 0.0007923907251097262, "5": 0.0007087349658831954, "6": 0.0006410567439161241, "7": 0.0005851772730238736, "8": 0.0005382585222832859, "9": 0.0004983050166629255, "10": 0.0383734256029129, "11": 0.0004338918370194733, "12": 0.0004075508622918278, "13": 0.00038422507350333035, "14": 0.06955745816230774, "15": 0.0003447609778959304, "16": 0.00032792051206342876, "17": 0.1195746436715126, "18": 0.2701169550418854, "19": 0.04245360568165779}}, {"key": "mu2023learning", "year": "2023", "title": "Learning To Compress Prompts With Gist Tokens", "topic_distr": {"0": 0.0018071625381708145, "1": 0.001475964323617518, "2": 0.08642396330833435, "3": 0.0010807333746924996, "4": 0.0009531594114378095, "5": 0.0008525309967808425, "6": 0.0007711215293966234, "7": 0.0007039045449346304, "8": 0.0006474663387052715, "9": 0.0005994066596031189, "10": 0.17425009608268738, "11": 0.03315657377243042, "12": 0.0004902392975054681, "13": 0.34208691120147705, "14": 0.0004371604882180691, "15": 0.0004147099098190665, "16": 0.00039445265429094434, "17": 0.2036529928445816, "18": 0.00035934674087911844, "19": 0.1494421511888504}}, {"key": "mu2023vision", "year": "2023", "title": "Embodiedgpt: Vision-language Pre-training Via Embodied Chain Of Thought", "topic_distr": {"0": 0.0011032820912078023, "1": 0.0009012706577777863, "2": 0.0007618635427206755, "3": 0.3816145062446594, "4": 0.0005819850484840572, "5": 0.0005205428460612893, "6": 0.00047083539539016783, "7": 0.031061729416251183, "8": 0.030540969222784042, "9": 0.02292260341346264, "10": 0.0003406996256671846, "11": 0.29120588302612305, "12": 0.0002993328671436757, "13": 0.0002822008391376585, "14": 0.0002669237437658012, "15": 0.00025321575230918825, "16": 0.00024084695905912668, "17": 0.03639596328139305, "18": 0.2000252902507782, "19": 0.0002100640267599374}}, {"key": "muennighoff2022crosslingual", "year": "2022", "title": "Crosslingual Generalization Through Multitask Finetuning", "topic_distr": {"0": 0.0015800913097336888, "1": 0.001289307838305831, "2": 0.0010898157488554716, "3": 0.2624431550502777, "4": 0.0008324799127876759, "5": 0.0007445923984050751, "6": 0.0006734900525771081, "7": 0.0006147833773866296, "8": 0.0005654908018186688, "9": 0.0005235159769654274, "10": 0.00048734189476817846, "11": 0.00045584392501041293, "12": 0.00042817022767849267, "13": 0.0004036643367726356, "14": 0.22351637482643127, "15": 0.0003622036019805819, "16": 0.00034451112151145935, "17": 0.28979143500328064, "18": 0.0003138499450869858, "19": 0.21353989839553833}}, {"key": "muennighoff2022gpt", "year": "2022", "title": "SGPT: GPT Sentence Embeddings For Semantic Search", "topic_distr": {"0": 0.001833329675719142, "1": 0.0014977294486016035, "2": 0.1570611149072647, "3": 0.17330597341060638, "4": 0.0009671300067566335, "5": 0.0008650266099721193, "6": 0.0007824238855391741, "7": 0.0007142216782085598, "8": 0.045016683638095856, "9": 0.0006081922329030931, "10": 0.3621980845928192, "11": 0.0005295745213516057, "12": 0.04259902238845825, "13": 0.20966166257858276, "14": 0.00044356798753142357, "15": 0.00042078833212144673, "16": 0.00040023415931500494, "17": 0.00038159446557983756, "18": 0.000364613690180704, "19": 0.0003490797826088965}}, {"key": "mukherjee2023progressive", "year": "2023", "title": "Orca: Progressive Learning From Complex Explanation Traces Of GPT-4", "topic_distr": {"0": 0.0010484589729458094, "1": 0.0008560415008105338, "2": 0.000723499630112201, "3": 0.24772080779075623, "4": 0.0005526752211153507, "5": 0.06513915210962296, "6": 0.00044712284579873085, "7": 0.07894185185432434, "8": 0.0003754233184736222, "9": 0.1306009739637375, "10": 0.0003235410840716213, "11": 0.18861746788024902, "12": 0.1692485362291336, "13": 0.11405589431524277, "14": 0.00025348071358166635, "15": 0.00024046310863923281, "16": 0.00022871725377626717, "17": 0.00021806542645208538, "18": 0.00020836162730120122, "19": 0.0001994846243178472}}, {"key": "muller2020when", "year": "2020", "title": "When Being Unseen From Mbert Is Just The Beginning: Handling New Languages With Multilingual Language Models", "topic_distr": {"0": 0.0017582268919795752, "1": 0.08323588222265244, "2": 0.0012127556838095188, "3": 0.22259695827960968, "4": 0.0009263927931897342, "5": 0.0008285900112241507, "6": 0.0007494666497223079, "7": 0.0006841373397037387, "8": 0.0006292840698733926, "9": 0.0005825739935971797, "10": 0.08958703279495239, "11": 0.0005072678322903812, "12": 0.00047647228348068893, "13": 0.00044920184882357717, "14": 0.5171369910240173, "15": 0.00040306392475031316, "16": 0.00038337556179612875, "17": 0.00036552100209519267, "18": 0.0003492554824333638, "19": 0.07713750004768372}}, {"key": "murahari2019large", "year": "2019", "title": "Large-scale Pretraining For Visual Dialog: A Simple State-of-the-art Baseline", "topic_distr": {"0": 0.0017569327028468251, "1": 0.0014346494572237134, "2": 0.2810446619987488, "3": 0.0010502557270228863, "4": 0.09079509228467941, "5": 0.000828493561130017, "6": 0.09131761640310287, "7": 0.0006840575370006263, "8": 0.10174538195133209, "9": 0.0005825060652568936, "10": 0.029193492606282234, "11": 0.0005072086933068931, "12": 0.000476416724268347, "13": 0.00044914946192875504, "14": 0.0004248345212545246, "15": 0.000403016951167956, "16": 0.00038333082920871675, "17": 0.00036547836498357356, "18": 0.15824124217033386, "19": 0.23831616342067719}}, {"key": "mysore2023large", "year": "2023", "title": "Large Language Model Augmented Narrative Driven Recommendations", "topic_distr": {"0": 0.051973871886730194, "1": 0.228844553232193, "2": 0.000967388681601733, "3": 0.0008378774509765208, "4": 0.22538723051548004, "5": 0.0006609548581764102, "6": 0.0005978391272947192, "7": 0.0005457267398014665, "8": 0.15475554764270782, "9": 0.26030540466308594, "10": 0.0004326003254391253, "11": 0.0004046404210384935, "12": 0.00038007524562999606, "13": 0.00035832199500873685, "14": 0.0003389240300748497, "15": 0.0003215184260625392, "16": 0.0003058132715523243, "17": 0.07203637808561325, "18": 0.0002785961842164397, "19": 0.0002667269145604223}}, {"key": "m\u00f6kander2023auditing", "year": "2023", "title": "Auditing Large Language Models: A Three-layered Approach", "topic_distr": {"0": 0.09220238029956818, "1": 0.000934358686208725, "2": 0.1276019960641861, "3": 0.17211195826530457, "4": 0.0006033663521520793, "5": 0.0005396659835241735, "6": 0.00048813241301104426, "7": 0.00044558296212926507, "8": 0.0004098567005712539, "9": 0.5703372359275818, "10": 0.0003532158734742552, "11": 0.0003303867415525019, "12": 0.00031032940023578703, "13": 0.00029256800189614296, "14": 0.000276729668257758, "15": 0.0002625180932227522, "16": 0.0002496949164196849, "17": 0.03180479258298874, "18": 0.00022747230832464993, "19": 0.00021778112568426877}}, {"key": "m\u00fcndler2023self", "year": "2023", "title": "Self-contradictory Hallucinations Of Large Language Models: Evaluation, Detection And Mitigation", "topic_distr": {"0": 0.0012735601048916578, "1": 0.12174198776483536, "2": 0.0008785847458057106, "3": 0.2827017903327942, "4": 0.0006711339810863137, "5": 0.0006002795998938382, "6": 0.0005429579759947956, "7": 0.19905120134353638, "8": 0.06921930611133575, "9": 0.08865490555763245, "10": 0.00039288803236559033, "11": 0.0003674947947729379, "12": 0.00034518467145971954, "13": 0.00032542835106141865, "14": 0.00030781113309785724, "15": 0.13808804750442505, "16": 0.027032719925045967, "17": 0.00026480501401238143, "18": 0.0002530213096179068, "19": 0.06728687137365341}}, {"key": "nagoudi2021text", "year": "2021", "title": "Arat5: Text-to-text Transformers For Arabic Language Generation", "topic_distr": {"0": 0.0016422534827142954, "1": 0.0013402866898104548, "2": 0.28654277324676514, "3": 0.21660484373569489, "4": 0.0008653296972624958, "5": 0.0007739731809124351, "6": 0.0007000652840360999, "7": 0.0006390421185642481, "8": 0.01704307831823826, "9": 0.0005441733519546688, "10": 0.11749576032161713, "11": 0.00047383105265907943, "12": 0.0004450653796084225, "13": 0.00041959251393564045, "14": 0.11245228350162506, "15": 0.2406795769929886, "16": 0.0003581051714718342, "17": 0.0003414275124669075, "18": 0.00032623414881527424, "19": 0.0003123353235423565}}, {"key": "nakamura2018another", "year": "2018", "title": "Another Diversity-promoting Objective Function For Neural Dialogue Generation", "topic_distr": {"0": 0.0016005384968593717, "1": 0.0013062438229098916, "2": 0.14463892579078674, "3": 0.0009561622282490134, "4": 0.0008432919275946915, "5": 0.040720369666814804, "6": 0.42594993114471436, "7": 0.07055187970399857, "8": 0.0005728347459807992, "9": 0.0005303147481754422, "10": 0.15556789934635162, "11": 0.0004617638769559562, "12": 0.0004337308055255562, "13": 0.15380841493606567, "14": 0.0003867702616844326, "15": 0.000366907479474321, "16": 0.00034898522426374257, "17": 0.000332732277456671, "18": 0.00031792584923096, "19": 0.0003043810138478875}}, {"key": "nakano2021browser", "year": "2021", "title": "Webgpt: Browser-assisted Question-answering With Human Feedback", "topic_distr": {"0": 0.29515203833580017, "1": 0.0017558434046804905, "2": 0.0014844316756352782, "3": 0.0012856811517849565, "4": 0.19192738831043243, "5": 0.0010142034152522683, "6": 0.0009173555299639702, "7": 0.000837391649838537, "8": 0.2603608965873718, "9": 0.0007130770245566964, "10": 0.0006638045888394117, "11": 0.23998799920082092, "12": 0.0005832073511555791, "13": 0.0005498279933817685, "14": 0.000520062749274075, "15": 0.0004933546879328787, "16": 0.00046925590140745044, "17": 0.00044740171870216727, "18": 0.0004274925449863076, "19": 0.0004092797462362796}}, {"key": "nam2023using", "year": "2023", "title": "Using An LLM To Help With Code Understanding", "topic_distr": {"0": 0.0012121822219341993, "1": 0.04920613765716553, "2": 0.0008359000785276294, "3": 0.19467425346374512, "4": 0.0006385436281561852, "5": 0.08163270354270935, "6": 0.15942056477069855, "7": 0.00047156159416772425, "8": 0.0004337524005677551, "9": 0.4420751631259918, "10": 0.00037380927824415267, "11": 0.022180676460266113, "12": 0.00032842240761965513, "13": 0.00030962546588853, "14": 0.00029286372591741383, "15": 0.0002778235648293048, "16": 0.0002642527688294649, "17": 0.025230886414647102, "18": 0.00024073451641015708, "19": 0.0199001245200634}}, {"key": "nangia2019human", "year": "2019", "title": "Human Vs. Muppet: A Conservative Estimate Of Human Performance On The GLUE Benchmark", "topic_distr": {"0": 0.1156943067908287, "1": 0.15348488092422485, "2": 0.48250433802604675, "3": 0.0008670971728861332, "4": 0.0007647427846677601, "5": 0.0006840057903900743, "6": 0.0006186889368109405, "7": 0.0005647591897286475, "8": 0.000519477529451251, "9": 0.00048091812641359866, "10": 0.05666184425354004, "11": 0.0004187524609733373, "12": 0.1844993233680725, "13": 0.0003708186559379101, "14": 0.0003507441724650562, "15": 0.0003327315498609096, "16": 0.00031647866126149893, "17": 0.00030173963750712574, "18": 0.000288312352495268, "19": 0.0002760291681624949}}, {"key": "naous2023having", "year": "2023", "title": "Having Beer After Prayer? Measuring Cultural Bias In Large Language Models", "topic_distr": {"0": 0.3082793951034546, "1": 0.0012271711602807045, "2": 0.001037328620441258, "3": 0.10062365233898163, "4": 0.0007923979428596795, "5": 0.0007087417179718614, "6": 0.0006410629139281809, "7": 0.07480120658874512, "8": 0.0005382635863497853, "9": 0.0004983097314834595, "10": 0.00046387736801989377, "11": 0.0004338959406595677, "12": 0.19511198997497559, "13": 0.00038422871148213744, "14": 0.09005382657051086, "15": 0.00034476423752494156, "16": 0.00032792362617328763, "17": 0.09072181582450867, "18": 0.00029873871244490147, "19": 0.13271139562129974}}, {"key": "narang2020training", "year": "2020", "title": "WT5?! Training Text-to-text Models To Explain Their Predictions", "topic_distr": {"0": 0.0016856711590662599, "1": 0.05225992575287819, "2": 0.4176885485649109, "3": 0.0010076509788632393, "4": 0.0008887029252946377, "5": 0.199351966381073, "6": 0.08468001335859299, "7": 0.10968416929244995, "8": 0.0006036817794665694, "9": 0.0005588721251115203, "10": 0.0005202550091780722, "11": 0.0004866297822445631, "12": 0.1279844343662262, "13": 0.0004309261857997626, "14": 0.0004075977485626936, "15": 0.000386665400583297, "16": 0.00036777800414711237, "17": 0.00035064987605437636, "18": 0.0003350461192894727, "19": 0.00032077188370749354}}, {"key": "narasimhan2017grounding", "year": "2017", "title": "Grounding Language For Transfer In Deep Reinforcement Learning", "topic_distr": {"0": 0.0013558289501816034, "1": 0.0011070052860304713, "2": 0.12761427462100983, "3": 0.05848320946097374, "4": 0.0007148548611439764, "5": 0.0006393842049874365, "6": 0.0005783283850178123, "7": 0.0005279167671687901, "8": 0.00048558905837126076, "9": 0.0004495450993999839, "10": 0.00041848229011520743, "11": 0.49281397461891174, "12": 0.0003676713677123189, "13": 0.0003466280468273908, "14": 0.08646740019321442, "15": 0.00031102559296414256, "16": 0.13117656111717224, "17": 0.00028205543640069664, "18": 0.09560228139162064, "19": 0.00025802222080528736}}, {"key": "narayan2021planning", "year": "2021", "title": "Planning With Learned Entity Prompts For Abstractive Summarization", "topic_distr": {"0": 0.07836807519197464, "1": 0.0012123078340664506, "2": 0.0010249941842630506, "3": 0.11268681287765503, "4": 0.0007829598034732044, "5": 0.0007002999191172421, "6": 0.0006334271747618914, "7": 0.348165363073349, "8": 0.0005318523617461324, "9": 0.000492374412715435, "10": 0.15646038949489594, "11": 0.0004287278279662132, "12": 0.0004027003305964172, "13": 0.0003796521632466465, "14": 0.0003590995038393885, "15": 0.0003406577743589878, "16": 0.0847400650382042, "17": 0.17134197056293488, "18": 0.00029518044902943075, "19": 0.04065310209989548}}, {"key": "narayanan2021efficient", "year": "2021", "title": "Efficient Large-scale Language Model Training On GPU Clusters Using Megatron-lm", "topic_distr": {"0": 0.08380774408578873, "1": 0.0010394788114354014, "2": 0.2551150321960449, "3": 0.0007609745371155441, "4": 0.000671146553941071, "5": 0.0006002909503877163, "6": 0.0005429682205431163, "7": 0.0004956388147547841, "8": 0.0004558991640806198, "9": 0.04335112124681473, "10": 0.00039289542473852634, "11": 0.0003675017214845866, "12": 0.07214148342609406, "13": 0.538620114326477, "14": 0.0003078169247601181, "15": 0.00029200883000157773, "16": 0.0002777451300062239, "17": 0.00026480999076738954, "18": 0.0002530260826461017, "19": 0.00024224621301982552}}, {"key": "naseem2019rewarding", "year": "2019", "title": "Rewarding Smatch: Transition-based AMR Parsing With Reinforcement Learning", "topic_distr": {"0": 0.002971033565700054, "1": 0.0024247090332210064, "2": 0.6134958267211914, "3": 0.0017753823194652796, "4": 0.0015658196061849594, "5": 0.001400509849190712, "6": 0.0012667728587985039, "7": 0.001156351063400507, "8": 0.0010636362712830305, "9": 0.0009846854954957962, "10": 0.000916645338293165, "11": 0.18028311431407928, "12": 0.0008053488563746214, "13": 0.0007592554902657866, "14": 0.0007181527907960117, "15": 0.0006812717183493078, "16": 0.15131241083145142, "17": 0.0006178154144436121, "18": 0.000590322888456285, "19": 0.03521100431680679}}, {"key": "nasr2023scalable", "year": "2023", "title": "Scalable Extraction Of Training Data From (production) Language Models", "topic_distr": {"0": 0.0019214284839108586, "1": 0.6050066947937012, "2": 0.001324607990682125, "3": 0.0011472728801891208, "4": 0.0010118393693119287, "5": 0.0009050153894349933, "6": 0.0008185940678231418, "7": 0.0007472389843314886, "8": 0.0006873263046145439, "9": 0.13374854624271393, "10": 0.0005923401331529021, "11": 0.0005540558486245573, "12": 0.0005204198532737792, "13": 0.04989339038729668, "14": 0.00046407338231801987, "15": 0.060642458498477936, "16": 0.1388687789440155, "17": 0.0003992349375039339, "18": 0.0003814691735897213, "19": 0.00036521715810522437}}, {"key": "nayak2022learning", "year": "2022", "title": "Learning To Compose Soft Prompts For Compositional Zero-shot Learning", "topic_distr": {"0": 0.0013415367575362325, "1": 0.0010951359290629625, "2": 0.14225681126117706, "3": 0.0008018360240384936, "4": 0.0007071857107803226, "5": 0.0006325257127173245, "6": 0.0005721249035559595, "7": 0.150880366563797, "8": 0.0004803803749382496, "9": 0.00044472303125075996, "10": 0.0004139934026170522, "11": 0.07747866958379745, "12": 0.0003637275076471269, "13": 0.00034290991607122123, "14": 0.00032434629974886775, "15": 0.01427991222590208, "16": 0.014593709260225296, "17": 0.3589121997356415, "18": 0.23382267355918884, "19": 0.00025525453384034336}}, {"key": "nazi2023large", "year": "2023", "title": "Large Language Models In Healthcare And Medical Domain: A Review", "topic_distr": {"0": 0.0009742893744260073, "1": 0.0007957073976285756, "2": 0.0006726410938426852, "3": 0.17076760530471802, "4": 0.0005138367996551096, "5": 0.0004595889477059245, "6": 0.0004157019720878452, "7": 0.0003794661315623671, "8": 0.015349139459431171, "9": 0.19905626773834229, "10": 0.0003008047351613641, "11": 0.010233249515295029, "12": 0.45787909626960754, "13": 0.03419946879148483, "14": 0.00023566775780636817, "15": 0.027158576995134354, "16": 0.00021264450333546847, "17": 0.08001706004142761, "18": 0.00019371933012735099, "19": 0.0001854661531979218}}, {"key": "neelakantan2019neural", "year": "2019", "title": "Neural Assistant: Joint Action Prediction, Response Generation, And Latent Knowledge Reasoning", "topic_distr": {"0": 0.0008324335212819278, "1": 0.0006789754261262715, "2": 0.23547181487083435, "3": 0.04559740051627159, "4": 0.05938774347305298, "5": 0.00039217458106577396, "6": 0.3357095718383789, "7": 0.0560712106525898, "8": 0.00029784225625917315, "9": 0.00027573422994464636, "10": 0.00025668146554380655, "11": 0.13088731467723846, "12": 0.00022551593428943306, "13": 0.00021260874927975237, "14": 0.0002010990574490279, "15": 0.00019077151955571026, "16": 0.13281454145908356, "17": 0.00017300230683758855, "18": 0.0001653037907090038, "19": 0.00015826123126316816}}, {"key": "nema2019ask", "year": "2019", "title": "Let's Ask Again: Refine Network For Automatic Question Generation", "topic_distr": {"0": 0.0010487373219802976, "1": 0.0008558121044188738, "2": 0.3501882255077362, "3": 0.11056678742170334, "4": 0.0005526746972464025, "5": 0.0004943259991705418, "6": 0.0004471220599953085, "7": 0.2684655487537384, "8": 0.2645062208175659, "9": 0.00034755602246150374, "10": 0.00032354050199501216, "11": 0.0003026293416041881, "12": 0.00028425714117474854, "13": 0.0002679879544302821, "14": 0.0002534802770242095, "15": 0.00024046267208177596, "16": 0.00022871683177072555, "17": 0.0002180650335503742, "18": 0.0002083612489514053, "19": 0.0001994842750718817}}, {"key": "nepal2024contextual", "year": "2024", "title": "Contextual AI Journaling: Integrating LLM And Time Series Behavioral Sensing Technology To Promote Self-reflection And Well-being Using The Mindscape App", "topic_distr": {"0": 0.0018091293750330806, "1": 0.0014759026234969497, "2": 0.18125484883785248, "3": 0.0010806958889588714, "4": 0.0009531251853331923, "5": 0.0008524995646439493, "6": 0.0007710930658504367, "7": 0.0007038785261102021, "8": 0.000647442415356636, "9": 0.7410987019538879, "10": 0.0005579681019298732, "11": 0.0005219053709879518, "12": 0.000490221194922924, "13": 0.0004621638508979231, "14": 0.00043714436469599605, "15": 0.0004146946012042463, "16": 0.00039443810237571597, "17": 0.06537079811096191, "18": 0.00035933346953243017, "19": 0.00034402450546622276}}, {"key": "nguyen2018vision", "year": "2018", "title": "Vision-based Navigation With Language-based Assistance Via Imitation Learning With Indirect Intervention", "topic_distr": {"0": 0.12856993079185486, "1": 0.0014762572245672345, "2": 0.0012477635173127055, "3": 0.0010807323269546032, "4": 0.15540923178195953, "5": 0.0008525289595127106, "6": 0.0007711196085438132, "7": 0.0007039027404971421, "8": 0.0006474647088907659, "9": 0.0005994051462039351, "10": 0.0005579872522503138, "11": 0.49610352516174316, "12": 0.000490238016936928, "13": 0.0004621797415893525, "14": 0.0004371593822725117, "15": 0.0004147088620811701, "16": 0.0003944516647607088, "17": 0.0003760812687687576, "18": 0.20906133949756622, "19": 0.0003440363216213882}}, {"key": "nguyen2019efficient", "year": "2019", "title": "Efficient Attention Mechanism For Visual Dialog That Can Handle All The Interactions Between Multiple Inputs", "topic_distr": {"0": 0.0011048270389437675, "1": 0.0009012754308059812, "2": 0.3917616009712219, "3": 0.0006599217304028571, "4": 0.1613207310438156, "5": 0.0005205782363191247, "6": 0.0004708673804998398, "7": 0.0004298228886909783, "8": 0.008318331092596054, "9": 0.012034815736114979, "10": 0.19652797281742096, "11": 0.0003187011170666665, "12": 0.0002993531816173345, "13": 0.061614371836185455, "14": 0.00026694187545217574, "15": 0.0002532329526729882, "16": 0.00024086331541184336, "17": 0.00022964584059081972, "18": 0.15104356408119202, "19": 0.011682569980621338}}, {"key": "nguyen2019transformers", "year": "2019", "title": "Transformers Without Tears: Improving The Normalization Of Self-attention", "topic_distr": {"0": 0.0018610887927934527, "1": 0.0015200069174170494, "2": 0.5251416563987732, "3": 0.0011129117337986827, "4": 0.0009815436787903309, "5": 0.0008779186173342168, "6": 0.0007940848008729517, "7": 0.0007248661713674664, "8": 0.000666747335344553, "9": 0.000617256504483521, "10": 0.09218466281890869, "11": 0.0005374670727178454, "12": 0.0005048381863161922, "13": 0.14180022478103638, "14": 0.22872987389564514, "15": 0.0004270596255082637, "16": 0.00040619910578243434, "17": 0.00038728161598555744, "18": 0.0003700477536767721, "19": 0.0003542823251336813}}, {"key": "nguyen2019visual", "year": "2019", "title": "Help, Anna! Visual Navigation With Natural Multimodal Assistance Via Retrospective Curiosity-encouraging Imitation Learning", "topic_distr": {"0": 0.04360608756542206, "1": 0.0010502130025997758, "2": 0.0572175569832325, "3": 0.0007688569603487849, "4": 0.0006781007396057248, "5": 0.02161579765379429, "6": 0.05015203356742859, "7": 0.0005007741274312139, "8": 0.00046062268665991724, "9": 0.04882923513650894, "10": 0.0003969661775045097, "11": 0.5792695879936218, "12": 0.0003487676731310785, "13": 0.00032880628714337945, "14": 0.0003110061807092279, "15": 0.0002950343186967075, "16": 0.0002806228294502944, "17": 0.00026755366707220674, "18": 0.17181995511054993, "19": 0.02180243283510208}}, {"key": "nguyen2020pre", "year": "2020", "title": "Phobert: Pre-trained Language Models For Vietnamese", "topic_distr": {"0": 0.0034626072738319635, "1": 0.0028286243323236704, "2": 0.0023913243785500526, "3": 0.002071179449558258, "4": 0.001826694468036294, "5": 0.0016338436398655176, "6": 0.0014778256881982088, "7": 0.0013490067794919014, "8": 0.0012408450711518526, "9": 0.001148740528151393, "10": 0.3216855525970459, "11": 0.0010002490598708391, "12": 0.36552584171295166, "13": 0.0008857524953782558, "14": 0.18752296268939972, "15": 0.0007947760750539601, "16": 0.000755953777115792, "17": 0.0007207475136965513, "18": 0.0006886746268719435, "19": 0.10098876804113388}}, {"key": "nguyen2022generative", "year": "2022", "title": "Generative Spoken Dialogue Language Modeling", "topic_distr": {"0": 0.0031960916239768267, "1": 0.11659742891788483, "2": 0.00220751971937716, "3": 0.0019119714852422476, "4": 0.0016862836200743914, "5": 0.0015082585159689188, "6": 0.4019193947315216, "7": 0.0012453146046027541, "8": 0.0011454668128862977, "9": 0.0010604419512674212, "10": 0.24972480535507202, "11": 0.0009233643650077283, "12": 0.0008673081756569445, "13": 0.08335473388433456, "14": 0.0007734036771580577, "15": 0.04308256134390831, "16": 0.0006978469900786877, "17": 0.000665346859022975, "18": 0.08682378381490707, "19": 0.0006086543435230851}}, {"key": "nguyen2023multimodal", "year": "2023", "title": "Openvivqa: Task, Dataset, And Multimodal Fusion Models For Visual Question Answering In Vietnamese", "topic_distr": {"0": 0.0010234861401841044, "1": 0.0008349170675501227, "2": 0.10939513146877289, "3": 0.0006112735718488693, "4": 0.000539120112080127, "5": 0.00048220233293250203, "6": 0.045679666101932526, "7": 0.00039813731564208865, "8": 0.2751900851726532, "9": 0.06098482757806778, "10": 0.000315605488140136, "11": 0.0002952071954496205, "12": 0.15904799103736877, "13": 0.00026141537819057703, "14": 0.00024726352421566844, "15": 0.00023456518829334527, "16": 0.014736027456820011, "17": 0.00021271687000989914, "18": 0.329315721988678, "19": 0.00019459180475678295}}, {"key": "ni2020learning", "year": "2020", "title": "M3P: Learning Universal Representations Via Multitask Multilingual Multimodal Pre-training", "topic_distr": {"0": 0.0020108057651668787, "1": 0.0016425246139988303, "2": 0.06100628152489662, "3": 0.0012027244083583355, "4": 0.0010607523145154119, "5": 0.0009487646166235209, "6": 0.0008581654983572662, "7": 0.0007833610870875418, "8": 0.0007205521687865257, "9": 0.000667067535687238, "10": 0.0006209742859937251, "11": 0.0005808393470942974, "12": 0.0005455773789435625, "13": 0.0005143517628312111, "14": 0.20467451214790344, "15": 0.0004615222569555044, "16": 0.0004389783716760576, "17": 0.00041853426955640316, "18": 0.720460832118988, "19": 0.0003828720364253968}}, {"key": "ni2021sentence", "year": "2021", "title": "Sentence-t5: Scalable Sentence Encoders From Pre-trained Text-to-text Models", "topic_distr": {"0": 0.0017094395589083433, "1": 0.0013954277383163571, "2": 0.22829477488994598, "3": 0.17226259410381317, "4": 0.0009010033099912107, "5": 0.0008058815146796405, "6": 0.0007289265049621463, "7": 0.0006653875461779535, "8": 0.0006120376056060195, "9": 0.0005666076904162765, "10": 0.45904797315597534, "11": 0.0004933653981424868, "12": 0.0004634138604160398, "13": 0.06268639862537384, "14": 0.06758150458335876, "15": 0.0003920173621736467, "16": 0.0003728685842361301, "17": 0.0003555033472366631, "18": 0.00033968361094594, "19": 0.00032521181856282055}}, {"key": "ni2022expanding", "year": "2022", "title": "Expanding Language-image Pretrained Models For General Video Recognition", "topic_distr": {"0": 0.0010657861130312085, "1": 0.0008705373620614409, "2": 0.18323121964931488, "3": 0.0006373638170771301, "4": 0.0005621276795864105, "5": 0.0005027810693718493, "6": 0.0004547697026282549, "7": 0.0004151283937972039, "8": 0.0003818439145106822, "9": 0.0003535006835591048, "10": 0.0003290743916295469, "11": 0.00030780557426624, "12": 0.00028911911067552865, "13": 0.09966398030519485, "14": 0.00025781584554351866, "15": 0.0002445755817461759, "16": 0.03187713772058487, "17": 0.26769328117370605, "18": 0.31985777616500854, "19": 0.09100441634654999}}, {"key": "ni2025measurement", "year": "2025", "title": "Measurement Of Llm's Philosophies Of Human Nature", "topic_distr": {"0": 0.3881634771823883, "1": 0.05590791627764702, "2": 0.0007421678747050464, "3": 0.2558693587779999, "4": 0.05734168365597725, "5": 0.0005070905899628997, "6": 0.0004586677241604775, "7": 0.00041868662810884416, "8": 0.0003851168730761856, "9": 0.20798839628696442, "10": 0.0003318950184620917, "11": 0.0003104439238086343, "12": 0.00029159727273508906, "13": 0.0002749079721979797, "14": 0.00026002569939009845, "15": 0.00024667195975780487, "16": 0.0002346228138776496, "17": 0.029848866164684296, "18": 0.0002137416013283655, "19": 0.00020463539112824947}}, {"key": "nicholas2023lost", "year": "2023", "title": "Lost In Translation: Large Language Models In Non-english Content Analysis", "topic_distr": {"0": 0.051974449306726456, "1": 0.0010393591364845634, "2": 0.0008785751415416598, "3": 0.15777382254600525, "4": 0.0479452945291996, "5": 0.05818625167012215, "6": 0.0005429611774161458, "7": 0.0004956324119120836, "8": 0.0004558932560030371, "9": 0.3418818414211273, "10": 0.00039289036067202687, "11": 0.00036749697756022215, "12": 0.09422150999307632, "13": 0.026504890993237495, "14": 0.21600930392742157, "15": 0.0002920050756074488, "16": 0.00027774155023507774, "17": 0.0002648065856192261, "18": 0.0002530227939132601, "19": 0.0002422430698061362}}, {"key": "nichols2020collaborative", "year": "2020", "title": "Collaborative Storytelling With Large-scale Neural Language Models", "topic_distr": {"0": 0.08798514306545258, "1": 0.0013058010954409838, "2": 0.001103789429180324, "3": 0.1469147950410843, "4": 0.10707226395606995, "5": 0.0007541535305790603, "6": 0.17721790075302124, "7": 0.2284647524356842, "8": 0.000572752149309963, "9": 0.1223793476819992, "10": 0.0004935997421853244, "11": 0.0826697051525116, "12": 0.0004336682613939047, "13": 0.00040884767076931894, "14": 0.00038671446964144707, "15": 0.00036685456871055067, "16": 0.0003489349037408829, "17": 0.04049878939986229, "18": 0.00031788001069799066, "19": 0.00030433712527155876}}, {"key": "nie2018operations", "year": "2018", "title": "Operations Guided Neural Networks For High Fidelity Data-to-text Generation", "topic_distr": {"0": 0.0016625863499939442, "1": 0.12367919832468033, "2": 0.3574734628200531, "3": 0.027661414816975594, "4": 0.0008768840343691409, "5": 0.0007843074854463339, "6": 0.034537315368652344, "7": 0.2671864926815033, "8": 0.000595653080381453, "9": 0.000551439356058836, "10": 0.0005133358063176274, "11": 0.0004801577888429165, "12": 0.0004510080616455525, "13": 0.0968148410320282, "14": 0.0004021768691018224, "15": 0.00038152289926074445, "16": 0.0849551111459732, "17": 0.0003459863655734807, "18": 0.00033059011911973357, "19": 0.0003165057278238237}}, {"key": "nie2020contextualized", "year": "2020", "title": "Coregen: Contextualized Code Representation Learning For Commit Message Generation", "topic_distr": {"0": 0.001154372119344771, "1": 0.0009432078804820776, "2": 0.0007973259780555964, "3": 0.0006905770278535783, "4": 0.0006090565002523363, "5": 0.0005447553703561425, "6": 0.370689332485199, "7": 0.0004497850895859301, "8": 0.00041372189298272133, "9": 0.0003830124333035201, "10": 0.2934739887714386, "11": 0.08207882940769196, "12": 0.09205885976552963, "13": 0.00029532710323110223, "14": 0.00027933940873481333, "15": 0.05949786305427551, "16": 0.0002520497073419392, "17": 0.00024031124485190958, "18": 0.00022961750801187009, "19": 0.0949186310172081}}, {"key": "nievas2023distilling", "year": "2023", "title": "Distilling Large Language Models For Matching Patients To Clinical Trials", "topic_distr": {"0": 0.001031312276609242, "1": 0.06213775649666786, "2": 0.0007115850457921624, "3": 0.2815532088279724, "4": 0.057146571576595306, "5": 0.00048618976143188775, "6": 0.011897067539393902, "7": 0.01913367584347725, "8": 0.0003692434693221003, "9": 0.2766750454902649, "10": 0.00031821528682485223, "11": 0.0002976483083330095, "12": 0.20027293264865875, "13": 0.08664316684007645, "14": 0.0002493081847205758, "15": 0.00023650485672987998, "16": 0.00022495233861263841, "17": 0.00021447586186695844, "18": 0.00020493178453762084, "19": 0.00019620091188699007}}, {"key": "nijkamp2022open", "year": "2022", "title": "Codegen: An Open Large Language Model For Code With Multi-turn Program Synthesis", "topic_distr": {"0": 0.0013122789096087217, "1": 0.11745747178792953, "2": 0.0009062422323040664, "3": 0.4864371716976166, "4": 0.000692271685693413, "5": 0.0006191859720274806, "6": 0.2545997202396393, "7": 0.0005112398648634553, "8": 0.00047024927334859967, "9": 0.0004353439435362816, "10": 0.0004052624281030148, "11": 0.00037906941724941134, "12": 0.09975577145814896, "13": 0.03432949632406235, "14": 0.00031750593916513026, "15": 0.00030120028532110155, "16": 0.0002864876005332917, "17": 0.0002731452987063676, "18": 0.0002609904622659087, "19": 0.0002498712856322527}}, {"key": "nijkamp2023lessons", "year": "2023", "title": "Codegen2: Lessons For Training Llms On Programming And Natural Languages", "topic_distr": {"0": 0.0012115163262933493, "1": 0.07890813052654266, "2": 0.2647097408771515, "3": 0.372420072555542, "4": 0.0006385129527188838, "5": 0.0005711025441996753, "6": 0.0005165670881979167, "7": 0.00047153898049145937, "8": 0.00043373159132897854, "9": 0.0004015368758700788, "10": 0.11513129621744156, "11": 0.0003496323770377785, "12": 0.00032840666244737804, "13": 0.16235020756721497, "14": 0.0002928496978711337, "15": 0.0002778102643787861, "16": 0.00026424010866321623, "17": 0.0002519339323043823, "18": 0.000240722976741381, "19": 0.00023046726710163057}}, {"key": "niklaus2023multi", "year": "2023", "title": "LEXTREME: A Multi-lingual And Multi-task Benchmark For The Legal Domain", "topic_distr": {"0": 0.0561269149184227, "1": 0.0012123695341870189, "2": 0.23567673563957214, "3": 0.1549205332994461, "4": 0.0007829649839550257, "5": 0.0007003046339377761, "6": 0.0006334315403364599, "7": 0.0005782166263088584, "8": 0.000531855970621109, "9": 0.12920966744422913, "10": 0.000458355265436694, "11": 0.00042873076745308936, "12": 0.3418494760990143, "13": 0.00037965475348755717, "14": 0.074959397315979, "15": 0.00034066010266542435, "16": 0.00032401992939412594, "17": 0.0003089296806138009, "18": 0.00029518245719373226, "19": 0.0002826065756380558}}, {"key": "nishida2018retrieve", "year": "2018", "title": "Retrieve-and-read: Multi-task Learning Of Information Retrieval And Reading Comprehension", "topic_distr": {"0": 0.0012118180748075247, "1": 0.0009888331405818462, "2": 0.5209078192710876, "3": 0.0007239688420668244, "4": 0.0006385112646967173, "5": 0.0005711009725928307, "6": 0.03962232545018196, "7": 0.0004715377581305802, "8": 0.29574984312057495, "9": 0.00040153582813218236, "10": 0.00037379038985818624, "11": 0.00034963147481903434, "12": 0.0003284058184362948, "13": 0.00030960983713157475, "14": 0.0002928489411715418, "15": 0.08053135871887207, "16": 0.03310178592801094, "17": 0.0002519332629162818, "18": 0.0002407223655609414, "19": 0.022932592779397964}}, {"key": "niszczota2023gpt", "year": "2023", "title": "GPT Has Become Financially Literate: Insights From Financial Literacy Tests Of GPT And A Preliminary Test Of How People Use It As A Source Of Advice", "topic_distr": {"0": 0.46951285004615784, "1": 0.002262813737615943, "2": 0.0019130731234326959, "3": 0.0016569587169215083, "4": 0.0014613643288612366, "5": 0.0013070824788883328, "6": 0.0011822670930996537, "7": 0.0010792114771902561, "8": 0.000992681598290801, "9": 0.20769834518432617, "10": 0.0008554963860660791, "11": 0.0008002037648111582, "12": 0.16527405381202698, "13": 0.0007086059194989502, "14": 0.14039941132068634, "15": 0.0006358243990689516, "16": 0.000604766421020031, "17": 0.0005766012473031878, "18": 0.0005509427865035832, "19": 0.0005274704890325665}}, {"key": "niu2018adversarial", "year": "2018", "title": "Adversarial Over-sensitivity And Over-stability Strategies For Dialogue Models", "topic_distr": {"0": 0.0014855992048978806, "1": 0.35987815260887146, "2": 0.3100411593914032, "3": 0.0008877437212504447, "4": 0.0007829493843019009, "5": 0.0499054417014122, "6": 0.0006334183271974325, "7": 0.10987325757741928, "8": 0.0005318449111655354, "9": 0.0004923674860037863, "10": 0.0004583457484841347, "11": 0.00042872183257713914, "12": 0.00040269471355713904, "13": 0.09149550646543503, "14": 0.0003590944688767195, "15": 0.05082106217741966, "16": 0.00032401317730546, "17": 0.00030892324866726995, "18": 0.0002951763162855059, "19": 0.020594533532857895}}, {"key": "niu2018polite", "year": "2018", "title": "Polite Dialogue Generation Without Parallel Data", "topic_distr": {"0": 0.0014846487902104855, "1": 0.001212702365592122, "2": 0.21110902726650238, "3": 0.0008876854553818703, "4": 0.0007829044479876757, "5": 0.09188270568847656, "6": 0.29507455229759216, "7": 0.23833569884300232, "8": 0.0005318145849741995, "9": 0.000492339429911226, "10": 0.00045831958414055407, "11": 0.09312473982572556, "12": 0.0004026717215310782, "13": 0.027190398424863815, "14": 0.03547852113842964, "15": 0.0003406335599720478, "16": 0.00032399469637311995, "17": 0.0003089056408498436, "18": 0.00029515946516767144, "19": 0.0002825845731422305}}, {"key": "niu2018recursive", "year": "2018", "title": "Recursive Visual Attention In Visual Dialog", "topic_distr": {"0": 0.0014005106640979648, "1": 0.0011443692492321134, "2": 0.13253644108772278, "3": 0.0008378667407669127, "4": 0.23498335480690002, "5": 0.027397504076361656, "6": 0.0005978288827463984, "7": 0.0005457174265757203, "8": 0.10774338245391846, "9": 0.0004647031892091036, "10": 0.0004325929912738502, "11": 0.08462566882371902, "12": 0.00038006878457963467, "13": 0.0003583159123081714, "14": 0.0003389182675164193, "15": 0.0003215129836462438, "16": 0.000305808091070503, "17": 0.00029156601522117853, "18": 0.4050271511077881, "19": 0.0002667224034667015}}, {"key": "niven2019probing", "year": "2019", "title": "Probing Neural Network Comprehension Of Natural Language Arguments", "topic_distr": {"0": 0.05053238198161125, "1": 0.2205360382795334, "2": 0.3977839946746826, "3": 0.03534570708870888, "4": 0.001289553358219564, "5": 0.0011534113436937332, "6": 0.001043270225636661, "7": 0.0009523305925540626, "8": 0.0008759739575907588, "9": 0.0008109527407214046, "10": 0.08554735034704208, "11": 0.0007061253418214619, "12": 0.13894321024417877, "13": 0.0006252964958548546, "14": 0.0005914457142353058, "15": 0.0005610717344097793, "16": 0.0005336651811376214, "17": 0.0005088113248348236, "18": 0.0004861694760620594, "19": 0.061173200607299805}}, {"key": "nllb2022no", "year": "2022", "title": "No Language Left Behind: Scaling Human-centered Machine Translation", "topic_distr": {"0": 0.10828620940446854, "1": 0.00097017886582762, "2": 0.15025554597377777, "3": 0.000710268272086978, "4": 0.07715565711259842, "5": 0.0005602917517535388, "6": 0.0005067886668257415, "7": 0.01296262163668871, "8": 0.00042552128434181213, "9": 0.1545051485300064, "10": 0.0003667156561277807, "11": 0.00034301402047276497, "12": 0.13642001152038574, "13": 0.07122333347797394, "14": 0.2678627073764801, "15": 0.00027255143504589796, "16": 0.0002592381788417697, "17": 0.0002471649495419115, "18": 0.00023616621911060065, "19": 0.016430828720331192}}, {"key": "noever2020chess", "year": "2020", "title": "The Chess Transformer: Mastering Play Using Generative Language Models", "topic_distr": {"0": 0.12824992835521698, "1": 0.14020028710365295, "2": 0.0011328143300488591, "3": 0.000981172895990312, "4": 0.0008653533877804875, "5": 0.0007739951252005994, "6": 0.0477779246866703, "7": 0.0006390600465238094, "8": 0.0005878210649825633, "9": 0.000544188660569489, "10": 0.2523276209831238, "11": 0.3114233911037445, "12": 0.0004450778942555189, "13": 0.04521897807717323, "14": 0.00039688879041932523, "15": 0.06709740310907364, "16": 0.0003581152413971722, "17": 0.0003414371167309582, "18": 0.0003262433165218681, "19": 0.0003123441128991544}}, {"key": "nogueira2019passage", "year": "2019", "title": "Passage Re-ranking With BERT", "topic_distr": {"0": 0.0733962208032608, "1": 0.0021669110283255577, "2": 0.001831739442422986, "3": 0.001586517202667892, "4": 0.0013992368476465344, "5": 0.001251514651812613, "6": 0.10571956634521484, "7": 0.0010333308018743992, "8": 0.11850253492593765, "9": 0.0008799281204119325, "10": 0.5599027276039124, "11": 0.0007661845884285867, "12": 0.0007196705555543303, "13": 0.0006784808938391507, "14": 0.0006417509284801781, "15": 0.0006087935180403292, "16": 0.0005790559225715697, "17": 0.0005520881386473775, "18": 0.0005275204312056303, "19": 0.12725619971752167}}, {"key": "nogueira2020document", "year": "2020", "title": "Document Ranking With A Pretrained Sequence-to-sequence Model", "topic_distr": {"0": 0.0016434829449281096, "1": 0.04004435986280441, "2": 0.4596289098262787, "3": 0.000981221441179514, "4": 0.1683279126882553, "5": 0.0007740354631096125, "6": 0.09729868173599243, "7": 0.0006390935159288347, "8": 0.06276144832372665, "9": 0.0005442171241156757, "10": 0.09274701774120331, "11": 0.0004738691495731473, "12": 0.0004451011773198843, "13": 0.0004196262452751398, "14": 0.0003969095414504409, "15": 0.0003765260917134583, "16": 0.015227767638862133, "17": 0.0003414549573790282, "18": 0.00032626037136651576, "19": 0.0566021203994751}}, {"key": "nogueira2021investigating", "year": "2021", "title": "Investigating The Limitations Of Transformers With Simple Arithmetic Tasks", "topic_distr": {"0": 0.2213883250951767, "1": 0.0010835897410288453, "2": 0.319906085729599, "3": 0.17450356483459473, "4": 0.0006996467127464712, "5": 0.0006257828790694475, "6": 0.0005660258466377854, "7": 0.0005166865885257721, "8": 0.00047525932313874364, "9": 0.00043998213368467987, "10": 0.25895488262176514, "11": 0.00038310801028274, "12": 0.0003598500625230372, "13": 0.0003392543876543641, "14": 0.00032088864827528596, "15": 0.000304409273667261, "16": 0.0002895398356486112, "17": 0.0002760553907137364, "18": 0.0002637710713315755, "19": 0.018303297460079193}}, {"key": "nooralahzadeh2021progressive", "year": "2021", "title": "Progressive Transformer-based Generation Of Radiology Reports", "topic_distr": {"0": 0.0036651529371738434, "1": 0.0029948800802230835, "2": 0.002532069105654955, "3": 0.0021930744405835867, "4": 0.0019342012237757444, "5": 0.0017299996688961983, "6": 0.00156479945871979, "7": 0.2946183383464813, "8": 0.0013138720532879233, "9": 0.001216346863657236, "10": 0.1393396556377411, "11": 0.18163129687309265, "12": 0.0009948187507689, "13": 0.0009378812974318862, "14": 0.0008871085592545569, "15": 0.2168244570493698, "16": 0.0008004436385817826, "17": 0.0007631654152646661, "18": 0.14336036145687103, "19": 0.000698138028383255}}, {"key": "nori2023can", "year": "2023", "title": "Can Generalist Foundation Models Outcompete Special-purpose Tuning? Case Study In Medicine", "topic_distr": {"0": 0.04226822406053543, "1": 0.03267386555671692, "2": 0.15689195692539215, "3": 0.30900833010673523, "4": 0.00048361526569351554, "5": 0.00043255824130028486, "6": 0.0003912526008207351, "7": 0.0003571479464881122, "8": 0.0003285122802481055, "9": 0.00030412772321142256, "10": 0.00028311298228800297, "11": 0.00026481476379558444, "12": 0.202396959066391, "13": 0.0874464362859726, "14": 0.00022180704399943352, "15": 0.0002104160375893116, "16": 0.00020013788889627904, "17": 0.165479838848114, "18": 0.00018232579168397933, "19": 0.0001745580229908228}}, {"key": "nori2023capabilities", "year": "2023", "title": "Capabilities Of GPT-4 On Medical Challenge Problems", "topic_distr": {"0": 0.18113839626312256, "1": 0.0007894720183685422, "2": 0.0006673774914816022, "3": 0.2992003560066223, "4": 0.000509795849211514, "5": 0.0561673603951931, "6": 0.00041243297164328396, "7": 0.04401414468884468, "8": 0.01567278802394867, "9": 0.08105286210775375, "10": 0.00029843926313333213, "11": 0.0002791504666674882, "12": 0.21436583995819092, "13": 0.09194054454565048, "14": 0.00023381451319437474, "15": 0.00022180686937645078, "16": 0.00021097229910083115, "17": 0.00020114690414629877, "18": 0.012439264915883541, "19": 0.00018400768749415874}}, {"key": "novelli2024generative", "year": "2024", "title": "Generative AI In EU Law: Liability, Privacy, Intellectual Property, And Cybersecurity", "topic_distr": {"0": 0.0895911306142807, "1": 0.032414890825748444, "2": 0.0010629006428644061, "3": 0.0009206143440678716, "4": 0.02391028217971325, "5": 0.000726223224774003, "6": 0.0006568750832229853, "7": 0.0005996166728436947, "8": 0.0005515401717275381, "9": 0.5955285429954529, "10": 0.00047531918971799314, "11": 0.00044459826312959194, "12": 0.1734652817249298, "13": 0.0003937059373129159, "14": 0.00037239244556985795, "15": 0.049351613968610764, "16": 0.00033601204631850123, "17": 0.00032036329503171146, "18": 0.028585080057382584, "19": 0.0002930659684352577}}, {"key": "nunes2023evaluating", "year": "2023", "title": "Evaluating GPT-3.5 And GPT-4 Models On Brazilian University Admission Exams", "topic_distr": {"0": 0.14158856868743896, "1": 0.0013402816839516163, "2": 0.0011328260879963636, "3": 0.33800527453422546, "4": 0.00086533825378865, "5": 0.05255776271224022, "6": 0.0007000725599937141, "7": 0.0006390486960299313, "8": 0.10001952201128006, "9": 0.0005441789980977774, "10": 0.000506577140185982, "11": 0.00047383594210259616, "12": 0.26814329624176025, "13": 0.0004195968504063785, "14": 0.0003968817472923547, "15": 0.00037649969453923404, "16": 0.0003581088676583022, "17": 0.04589157924056053, "18": 0.0003262375248596072, "19": 0.04571453481912613}}, {"key": "nye2021show", "year": "2021", "title": "Show Your Work: Scratchpads For Intermediate Computation With Language Models", "topic_distr": {"0": 0.0019190114689990878, "1": 0.07081454992294312, "2": 0.291445255279541, "3": 0.455351859331131, "4": 0.001011948217637837, "5": 0.0009051135857589543, "6": 0.0008186828927136958, "7": 0.000747320125810802, "8": 0.000687400926835835, "9": 0.0006363770226016641, "10": 0.0005924044526182115, "11": 0.0005541160353459418, "12": 0.0005204763729125261, "13": 0.17152629792690277, "14": 0.00046412379015237093, "15": 0.0004402885097078979, "16": 0.0004187817976344377, "17": 0.00039927830221131444, "18": 0.0003815106174442917, "19": 0.00036525679752230644}}, {"key": "oh2022why", "year": "2022", "title": "Why Does Surprisal From Larger Transformer-based Language Models Provide A Poorer Fit To Human Reading Times?", "topic_distr": {"0": 0.2787112891674042, "1": 0.03211243078112602, "2": 0.42082148790359497, "3": 0.0010357099818065763, "4": 0.0009134523570537567, "5": 0.0008170154178515077, "6": 0.0007389974198304117, "7": 0.000674580573104322, "8": 0.06597498804330826, "9": 0.0005744359805248678, "10": 0.08788181096315384, "11": 0.0005001818062737584, "12": 0.00046981641207821667, "13": 0.10654491931200027, "14": 0.0004189488245174289, "15": 0.0003974335268139839, "16": 0.0003780201659537852, "17": 0.0003604150260798633, "18": 0.00034437672002241015, "19": 0.0003297049552202225}}, {"key": "oh2023black", "year": "2023", "title": "Blackvip: Black-box Visual Prompting For Robust Transfer Learning", "topic_distr": {"0": 0.001401677611283958, "1": 0.06546586006879807, "2": 0.04360193759202957, "3": 0.18093736469745636, "4": 0.0007389947422780097, "5": 0.00066097651142627, "6": 0.0005978587432764471, "7": 0.0005457446677610278, "8": 0.0005019875825382769, "9": 0.0004647263849619776, "10": 0.0004326145863160491, "11": 0.00040465372148901224, "12": 0.00038008776027709246, "13": 0.30603936314582825, "14": 0.0003389352059457451, "15": 0.00032152901985682547, "16": 0.0321924090385437, "17": 0.30447837710380554, "18": 0.06022810935974121, "19": 0.00026673570391722023}}, {"key": "ohsugi2019simple", "year": "2019", "title": "A Simple But Effective Method To Incorporate Multi-turn Context With BERT For Conversational Machine Comprehension", "topic_distr": {"0": 0.0014854550827294588, "1": 0.0012125155190005898, "2": 0.4628540277481079, "3": 0.0008878400549292564, "4": 0.0007830347749404609, "5": 0.02346978709101677, "6": 0.1109088733792305, "7": 0.000578267325181514, "8": 0.1561160385608673, "9": 0.0004924209206365049, "10": 0.20374687016010284, "11": 0.000428768340498209, "12": 0.0004027383984066546, "13": 0.0003796880482695997, "14": 0.0003591334098018706, "15": 0.00034068996319547296, "16": 0.034667063504457474, "17": 0.0003089567762799561, "18": 0.0002952083304990083, "19": 0.0002826313429977745}}, {"key": "olga2023generative", "year": "2023", "title": "Generative AI: Implications And Applications For Education", "topic_distr": {"0": 0.0020453680772334337, "1": 0.0016702626598998904, "2": 0.0014113002689555287, "3": 0.09861443191766739, "4": 0.0010781054152175784, "5": 0.0009642866207286716, "6": 0.0008722054772078991, "7": 0.0007961772498674691, "8": 0.0007323407335206866, "9": 0.7093109488487244, "10": 0.0006311337347142398, "11": 0.0005903421551920474, "12": 0.0005545032909139991, "13": 0.0005227667861618102, "14": 0.0004944665706716478, "15": 0.10537148267030716, "16": 0.03935529664158821, "17": 0.00042538170237094164, "18": 0.034170057624578476, "19": 0.0003891359956469387}}, {"key": "olsson2022learning", "year": "2022", "title": "In-context Learning And Induction Heads", "topic_distr": {"0": 0.19101883471012115, "1": 0.0016426552319899201, "2": 0.40255552530288696, "3": 0.0012027440825477242, "4": 0.001060771057382226, "5": 0.036959920078516006, "6": 0.0008581810398027301, "7": 0.0007833752315491438, "8": 0.0007205652073025703, "9": 0.0006670795846730471, "10": 0.09284947067499161, "11": 0.06819254159927368, "12": 0.0005455872160382569, "13": 0.19835439324378967, "14": 0.000486515840748325, "15": 0.0004615306097548455, "16": 0.00043898631702177227, "17": 0.0004185418365523219, "18": 0.00039991692756302655, "19": 0.0003828789631370455}}, {"key": "omar2023chatgpt", "year": "2023", "title": "Chatgpt Versus Traditional Question Answering For Knowledge Graphs: Current Status And Future Directions Towards Knowledge Graph Chatbots", "topic_distr": {"0": 0.0012606235686689615, "1": 0.1154395118355751, "2": 0.0008696757722645998, "3": 0.04234394058585167, "4": 0.07342813163995743, "5": 0.0005941983545199037, "6": 0.06345907598733902, "7": 0.0004906083340756595, "8": 0.07583872973918915, "9": 0.2389935702085495, "10": 0.0003889077343046665, "11": 0.00036377174546942115, "12": 0.2784624993801117, "13": 0.0003221314982511103, "14": 0.00030469271587207913, "15": 0.00028904509963467717, "16": 0.10639849305152893, "17": 0.0002621223102323711, "18": 0.00025045798975043, "19": 0.00023978752142284065}}, {"key": "omar2023universal", "year": "2023", "title": "A Universal Question-answering Platform For Knowledge Graphs", "topic_distr": {"0": 0.0010940056527033448, "1": 0.0008934479556046426, "2": 0.2165195643901825, "3": 0.0897417813539505, "4": 0.05408662185072899, "5": 0.0005160326254554093, "6": 0.0004667557659558952, "7": 0.0004260696587152779, "8": 0.18066786229610443, "9": 0.0003628176636993885, "10": 0.0003377475659362972, "11": 0.06727844476699829, "12": 0.10490868985652924, "13": 0.00027975565171800554, "14": 0.0002646109205670655, "15": 0.1441677063703537, "16": 0.1373346596956253, "17": 0.0002276405575685203, "18": 0.00021751066378783435, "19": 0.0002082438877550885}}, {"key": "omiye2023large", "year": "2023", "title": "Large Language Models In Medicine: The Potentials And Pitfalls", "topic_distr": {"0": 0.0023110639303922653, "1": 0.0018857393879443407, "2": 0.001594308065250516, "3": 0.0013808963121846318, "4": 0.001217895420268178, "5": 0.0010893174912780523, "6": 0.0009852969087660313, "7": 0.0008994106901809573, "8": 0.06412467360496521, "9": 0.4915589392185211, "10": 0.0007129674195311964, "11": 0.0006668867426924407, "12": 0.40433844923973083, "13": 0.02426241710782051, "14": 0.0005585798062384129, "15": 0.0005298936739563942, "16": 0.0005040100659243762, "17": 0.0004805373027920723, "18": 0.0004591536126099527, "19": 0.00043959193862974644}}, {"key": "openai2023gpt", "year": "2023", "title": "GPT-4 Technical Report", "topic_distr": {"0": 0.1651984006166458, "1": 0.0014760579215362668, "2": 0.0012477237032726407, "3": 0.0010806870413944125, "4": 0.000953121401835233, "5": 0.0008524958975613117, "6": 0.0007710898062214255, "7": 0.1577882170677185, "8": 0.000647439737804234, "9": 0.08966318517923355, "10": 0.06388769298791885, "11": 0.000521903159096837, "12": 0.2556818723678589, "13": 0.16473804414272308, "14": 0.0004371425020508468, "15": 0.0004146928549744189, "16": 0.00039443644345737994, "17": 0.00037606674595735967, "18": 0.093525730073452, "19": 0.0003440230502746999}}, {"key": "oppenlaender2022taxonomy", "year": "2022", "title": "A Taxonomy Of Prompt Modifiers For Text-to-image Generation", "topic_distr": {"0": 0.0014341181376948953, "1": 0.017112823203206062, "2": 0.06456264108419418, "3": 0.0008572504739277065, "4": 0.0007560586091130972, "5": 0.0006762383854947984, "6": 0.0006116634467616677, "7": 0.1173747181892395, "8": 0.0005135785904712975, "9": 0.6027634739875793, "10": 0.0004426037485245615, "11": 0.00041399727342650294, "12": 0.00038886404945515096, "13": 0.000366607797332108, "14": 0.0003467612841632217, "15": 0.00032895320327952504, "16": 0.00031288486206904054, "17": 0.1535361111164093, "18": 0.03692775219678879, "19": 0.0002728946856223047}}, {"key": "orenstrakh2023detecting", "year": "2023", "title": "Detecting Llm-generated Text In Computing Education: A Comparative Study For Chatgpt Cases", "topic_distr": {"0": 0.12804776430130005, "1": 0.4130702018737793, "2": 0.0007486651302315295, "3": 0.20823551714420319, "4": 0.0005719013861380517, "5": 0.0005115236272104084, "6": 0.0004626773879863322, "7": 0.0004223467840347439, "8": 0.0003884835750795901, "9": 0.24492599070072174, "10": 0.0003347964375279844, "11": 0.0003131577977910638, "12": 0.00029414641903713346, "13": 0.0002773112209979445, "14": 0.0002622988249640912, "15": 0.00024882834986783564, "16": 0.00023667387722525746, "17": 0.00022565151448361576, "18": 0.00021561012545134872, "19": 0.00020642431627493352}}, {"key": "ott2018scaling", "year": "2018", "title": "Scaling Neural Machine Translation", "topic_distr": {"0": 0.0019781801383942366, "1": 0.05100071430206299, "2": 0.2922699451446533, "3": 0.001183573273010552, "4": 0.001043865573592484, "5": 0.0009336603689007461, "6": 0.0008445035200566053, "7": 0.0007708900375291705, "8": 0.0007090810686349869, "9": 0.0006564478971995413, "10": 0.0006110884132795036, "11": 0.0005715924198739231, "12": 0.0005368918064050376, "13": 0.2586710453033447, "14": 0.36446353793144226, "15": 0.00045417487854138017, "16": 0.0004319898725952953, "17": 0.022098543122410774, "18": 0.0003935431595891714, "19": 0.0003767767339013517}}, {"key": "ott2019extensible", "year": "2019", "title": "Fairseq: A Fast, Extensible Toolkit For Sequence Modeling", "topic_distr": {"0": 0.0032839837949723005, "1": 0.0026806723326444626, "2": 0.18806399405002594, "3": 0.0019624338019639254, "4": 0.0017307867528870702, "5": 0.0015480603324249387, "6": 0.0014002332463860512, "7": 0.1200205385684967, "8": 0.0011756952153518796, "9": 0.14868463575839996, "10": 0.31222066283226013, "11": 0.0009477315470576286, "12": 0.000890196010004729, "13": 0.0008392464951612055, "14": 0.13788163661956787, "15": 0.0007530467701144516, "16": 0.0007162628462538123, "17": 0.0006829050835222006, "18": 0.07389260083436966, "19": 0.0006247164565138519}}, {"key": "ott2023central", "year": "2023", "title": "Thoughtsource: A Central Hub For Large Language Model Reasoning Data", "topic_distr": {"0": 0.17400190234184265, "1": 0.03299109265208244, "2": 0.0011181606678292155, "3": 0.5398984551429749, "4": 0.0008541151182726026, "5": 0.0007639425457455218, "6": 0.0006909922230988741, "7": 0.0006307599251158535, "8": 0.03492271155118942, "9": 0.11919381469488144, "10": 0.0005000066012144089, "11": 0.0004676900280173868, "12": 0.06459866464138031, "13": 0.0004141544341109693, "14": 0.00039173397817648947, "15": 0.0003716162755154073, "16": 0.027222895994782448, "17": 0.0003370025078766048, "18": 0.00032200603163801134, "19": 0.00030828735907562077}}, {"key": "ouyang2022training", "year": "2022", "title": "Training Language Models To Follow Instructions With Human Feedback", "topic_distr": {"0": 0.10517391562461853, "1": 0.10313404351472855, "2": 0.000827837036922574, "3": 0.28640565276145935, "4": 0.24941782653331757, "5": 0.0005656112916767597, "6": 0.0005116001702845097, "7": 0.07265523076057434, "8": 0.0004295612161513418, "9": 0.0003976760490331799, "10": 0.0003701972891576588, "11": 0.04105844348669052, "12": 0.0003252489841543138, "13": 0.00030663367942906916, "14": 0.0002900339022744447, "15": 0.0002751390857156366, "16": 0.0002616994024720043, "17": 0.13712701201438904, "18": 0.00023840839276090264, "19": 0.00022825130145065486}}, {"key": "ovadia2023fine", "year": "2023", "title": "Fine-tuning Or Retrieval? Comparing Knowledge Injection In Llms", "topic_distr": {"0": 0.0014181750593706965, "1": 0.06115773320198059, "2": 0.2621738910675049, "3": 0.24475808441638947, "4": 0.0007473556324839592, "5": 0.0006684535183012486, "6": 0.0006046218913979828, "7": 0.000551918288692832, "8": 0.07266291975975037, "9": 0.0004699834971688688, "10": 0.00043750842451117933, "11": 0.00040923128835856915, "12": 0.00038438738556578755, "13": 0.0003623873635660857, "14": 0.00034276931546628475, "15": 0.04069391265511513, "16": 0.3113102316856384, "17": 0.0002948789915535599, "18": 0.0002817570057231933, "19": 0.000269753101747483}}, {"key": "owoicho2023exploiting", "year": "2023", "title": "Exploiting Simulated User Feedback For Conversational Search: Ranking, Rewriting, And Beyond", "topic_distr": {"0": 0.060647547245025635, "1": 0.0009345185826532543, "2": 0.0775575041770935, "3": 0.04687514156103134, "4": 0.3707185387611389, "5": 0.0005396789056248963, "6": 0.09089360386133194, "7": 0.0004455936432350427, "8": 0.09304635226726532, "9": 0.08298095315694809, "10": 0.0003532243426889181, "11": 0.00033039465779438615, "12": 0.1729121059179306, "13": 0.00029257501591928303, "14": 0.00027673630393110216, "15": 0.00026252437965013087, "16": 0.000249700911808759, "17": 0.00023807183606550097, "18": 0.00022747775074094534, "19": 0.00021778633526992053}}, {"key": "packer2023towards", "year": "2023", "title": "Memgpt: Towards Llms As Operating Systems", "topic_distr": {"0": 0.05338837578892708, "1": 0.0829128697514534, "2": 0.0009258572245016694, "3": 0.1118738204240799, "4": 0.16135035455226898, "5": 0.0006325747235678136, "6": 0.11292625218629837, "7": 0.0005222944309934974, "8": 0.0567612461745739, "9": 0.18460723757743835, "10": 0.00041402544593438506, "11": 0.11815417557954788, "12": 0.0003637556510511786, "13": 0.0003429364587645978, "14": 0.031351976096630096, "15": 0.00030771316960453987, "16": 0.08236357569694519, "17": 0.0002790515427477658, "18": 0.0002666338987182826, "19": 0.000255274266237393}}, {"key": "paiss2023teaching", "year": "2023", "title": "Teaching CLIP To Count To Ten", "topic_distr": {"0": 0.03632510453462601, "1": 0.0009520246530883014, "2": 0.0008046959992498159, "3": 0.2639949321746826, "4": 0.0006146972300484776, "5": 0.0005498013342730701, "6": 0.0004973000031895936, "7": 0.00045395141933113337, "8": 0.0004175541689619422, "9": 0.00038656024844385684, "10": 0.0003598495968617499, "11": 0.000336591707309708, "12": 0.0003161576751153916, "13": 0.00029806268867105246, "14": 0.0002819269138853997, "15": 0.05267813429236412, "16": 0.017322706058621407, "17": 0.00024253723677247763, "18": 0.6229455471038818, "19": 0.00022187124704942107}}, {"key": "pal2023med", "year": "2023", "title": "Med-halt: Medical Domain Hallucination Test For Large Language Models", "topic_distr": {"0": 0.30642545223236084, "1": 0.0011069482425227761, "2": 0.0009357334929518402, "3": 0.14457643032073975, "4": 0.0007148032309487462, "5": 0.000639338803011924, "6": 0.0005782873486168683, "7": 0.0005278792814351618, "8": 0.05751974135637283, "9": 0.0004495132016018033, "10": 0.0004184525751043111, "11": 0.000391407054848969, "12": 0.45616671442985535, "13": 0.0003466034249868244, "14": 0.00032783986534923315, "15": 0.0003110035031568259, "16": 0.0002958119730465114, "17": 0.0002820354129653424, "18": 0.027727995067834854, "19": 0.0002580038853920996}}, {"key": "palagin2023ontochatgpt", "year": "2023", "title": "Ontochatgpt Information System: Ontology-driven Structured Prompts For Chatgpt Meta-learning", "topic_distr": {"0": 0.0011876305798068643, "1": 0.0009700359078124166, "2": 0.0008200121810659766, "3": 0.0007102492963895202, "4": 0.1042904183268547, "5": 0.0005602744640782475, "6": 0.054989591240882874, "7": 0.00046259837108664215, "8": 0.01361554954200983, "9": 0.4160354435443878, "10": 0.0003667040728032589, "11": 0.0003430031647440046, "12": 0.0954350009560585, "13": 0.0147768035531044, "14": 0.0002872970944736153, "15": 0.00027254282031208277, "16": 0.15071918070316315, "17": 0.1436954289674759, "18": 0.0002361587539780885, "19": 0.00022609748702961951}}, {"key": "pampari2018large", "year": "2018", "title": "Emrqa: A Large Corpus For Question Answering On Electronic Medical Records", "topic_distr": {"0": 0.00226838537491858, "1": 0.10708893835544586, "2": 0.07256533950567245, "3": 0.0013558940263465047, "4": 0.0011958384420722723, "5": 0.0010695896344259381, "6": 0.0009674528264440596, "7": 0.0008831220329739153, "8": 0.4163696765899658, "9": 0.08130867779254913, "10": 0.0007000553305260837, "11": 0.053565241396427155, "12": 0.18386662006378174, "13": 0.07387717813253403, "14": 0.0005484636640176177, "15": 0.0005202970933169127, "16": 0.0004948822315782309, "17": 0.00047183455899357796, "18": 0.0004508381534833461, "19": 0.0004316307313274592}}, {"key": "pan2019frustratingly", "year": "2019", "title": "Frustratingly Easy Natural Question Answering", "topic_distr": {"0": 0.0017326868837699294, "1": 0.2980287969112396, "2": 0.4321521818637848, "3": 0.001035679248161614, "4": 0.0009134261053986847, "5": 0.000816991669125855, "6": 0.026975877583026886, "7": 0.0006745608407072723, "8": 0.15479207038879395, "9": 0.0005744192167185247, "10": 0.07866159826517105, "11": 0.0005001671379432082, "12": 0.0004698026750702411, "13": 0.00044291396625339985, "14": 0.0004189365718048066, "15": 0.0003974219143856317, "16": 0.0003780091064982116, "17": 0.0003604044613894075, "18": 0.0003443666500970721, "19": 0.0003296953218523413}}, {"key": "pan2019reinforced", "year": "2019", "title": "Reinforced Dynamic Reasoning For Conversational Question Generation", "topic_distr": {"0": 0.0012755804928019643, "1": 0.0010394644923508167, "2": 0.24506354331970215, "3": 0.0007610566099174321, "4": 0.14111869037151337, "5": 0.0006003529415465891, "6": 0.18382833898067474, "7": 0.000495689979288727, "8": 0.24486230313777924, "9": 0.000422102544689551, "10": 0.0003929359663743526, "11": 0.08075344562530518, "12": 0.0003452268138062209, "13": 0.0003254680777899921, "14": 0.0003078486770391464, "15": 0.0002920389815699309, "16": 0.09735580533742905, "17": 0.0002648373192641884, "18": 0.0002530521887820214, "19": 0.00024227119865827262}}, {"key": "pan2019transferring", "year": "2019", "title": "Macnet: Transferring Knowledge From Machine Comprehension To Sequence-to-sequence Models", "topic_distr": {"0": 0.0017571344505995512, "1": 0.0014343492221087217, "2": 0.32805415987968445, "3": 0.0010501939104869962, "4": 0.0009262274252250791, "5": 0.0008284420473501086, "6": 0.0007493327721022069, "7": 0.05448881909251213, "8": 0.0006291716126725078, "9": 0.0005824698600918055, "10": 0.11473341286182404, "11": 0.000507177144754678, "12": 0.14850138127803802, "13": 0.00044912155135534704, "14": 0.15296562016010284, "15": 0.09966831654310226, "16": 0.09162572771310806, "17": 0.0003654556639958173, "18": 0.0003491930547170341, "19": 0.00033431610791012645}}, {"key": "pan2020auto", "year": "2020", "title": "Auto-captions On GIF: A Large-scale Video-sentence Dataset For Vision-language Pre-training", "topic_distr": {"0": 0.0021136696450412273, "1": 0.0017263885820284486, "2": 0.0014594041276723146, "3": 0.0012639897176995873, "4": 0.0011147871846333146, "5": 0.0009970942046493292, "6": 0.0009018800337798893, "7": 0.0008232650579884648, "8": 0.06677202135324478, "9": 0.0007010475965216756, "10": 0.03571391850709915, "11": 0.0006104269996285439, "12": 0.1956346333026886, "13": 0.023061104118824005, "14": 0.0005112894577905536, "15": 0.00048503195284865797, "16": 0.06644804030656815, "17": 0.00043985419324599206, "18": 0.5678299069404602, "19": 0.03139220550656319}}, {"key": "pan2021contrastive", "year": "2021", "title": "Contrastive Learning For Many-to-many Multilingual Neural Machine Translation", "topic_distr": {"0": 0.001326328725554049, "1": 0.042121898382902145, "2": 0.19865703582763672, "3": 0.000793278799392283, "4": 0.0006996408919803798, "5": 0.0006257763016037643, "6": 0.0005660199676640332, "7": 0.0005166812334209681, "8": 0.00047525440459139645, "9": 0.0004399775352794677, "10": 0.20618723332881927, "11": 0.0003831040521617979, "12": 0.0003598463081289083, "13": 0.0003392508369870484, "14": 0.5451223850250244, "15": 0.0003044061013497412, "16": 0.00028953683795407414, "17": 0.00027605253853835166, "18": 0.0002637683355715126, "19": 0.000252530793659389}}, {"key": "pan2021improved", "year": "2021", "title": "Improved Text Classification Via Contrastive Adversarial Training", "topic_distr": {"0": 0.0016188235022127628, "1": 0.32986822724342346, "2": 0.18567927181720734, "3": 0.11077558249235153, "4": 0.0008540430571883917, "5": 0.0007638786337338388, "6": 0.0006909347139298916, "7": 0.0006307074218057096, "8": 0.000580138061195612, "9": 0.0005370759754441679, "10": 0.36459630727767944, "11": 0.00046765111619606614, "12": 0.00043926064972765744, "13": 0.00041411997517570853, "14": 0.0003917013527825475, "15": 0.00037158536724746227, "16": 0.00035343458876013756, "17": 0.0003369744517840445, "18": 0.0003219792270101607, "19": 0.0003082617186009884}}, {"key": "pan2023automatically", "year": "2023", "title": "Automatically Correcting Large Language Models: Surveying The Landscape Of Diverse Self-correction Strategies", "topic_distr": {"0": 0.13587753474712372, "1": 0.0013400360476225615, "2": 0.0011327872052788734, "3": 0.4562048316001892, "4": 0.000865340291056782, "5": 0.0007739813299849629, "6": 0.0007000726764090359, "7": 0.0006390488124452531, "8": 0.0005878107040189207, "9": 0.15313395857810974, "10": 0.0005065772566013038, "11": 0.00047383602941408753, "12": 0.24523311853408813, "13": 0.0004195969377178699, "14": 0.0003968818055000156, "15": 0.00037649975274689496, "16": 0.00035810895496979356, "17": 0.00034143112134188414, "18": 0.00032623758306726813, "19": 0.0003123386122751981}}, {"key": "pan2023logic", "year": "2023", "title": "Logic-lm: Empowering Large Language Models With Symbolic Solvers For Faithful Logical Reasoning", "topic_distr": {"0": 0.0014848352875560522, "1": 0.0012125660432502627, "2": 0.0010250236373394728, "3": 0.8531808257102966, "4": 0.0007829999085515738, "5": 0.0007003343780525029, "6": 0.0006334583158604801, "7": 0.02952144481241703, "8": 0.0005318784969858825, "9": 0.0004923985688947141, "10": 0.00045837467769160867, "11": 0.1072828620672226, "12": 0.00040272012120112777, "13": 0.0003796708188019693, "14": 0.00035911714076064527, "15": 0.00034067450906150043, "16": 0.00032403363729827106, "17": 0.00030894274823367596, "18": 0.0002951949427369982, "19": 0.0002826185373123735}}, {"key": "pan2023preliminary", "year": "2023", "title": "A Preliminary Evaluation Of Chatgpt For Zero-shot Dialogue Understanding", "topic_distr": {"0": 0.0016658286331221461, "1": 0.001358170760795474, "2": 0.0011478643864393234, "3": 0.21669717133045197, "4": 0.0008768408442847431, "5": 0.26801368594169617, "6": 0.06557829678058624, "7": 0.0006475423579104245, "8": 0.0005956232780590653, "9": 0.20963257551193237, "10": 0.0005133101367391646, "11": 0.0004801337490789592, "12": 0.23022818565368652, "13": 0.0004251737555023283, "14": 0.0004021567292511463, "15": 0.0003815037780441344, "16": 0.0003628685371950269, "17": 0.00034596904879435897, "18": 0.00033057358814403415, "19": 0.00031648989534005523}}, {"key": "pan2023unifying", "year": "2023", "title": "Unifying Large Language Models And Knowledge Graphs: A Roadmap", "topic_distr": {"0": 0.0010312605882063508, "1": 0.0008419252699241042, "2": 0.0007116011693142354, "3": 0.3015618324279785, "4": 0.0005435795173980296, "5": 0.012748070061206818, "6": 0.0004397642333060503, "7": 0.0004014309379272163, "8": 0.029273994266986847, "9": 0.12430112808942795, "10": 0.05145592987537384, "11": 0.000297649297863245, "12": 0.12788845598697662, "13": 0.0002635779674164951, "14": 0.00024930902873165905, "15": 0.01899903081357479, "16": 0.32837584614753723, "17": 0.00021447657491080463, "18": 0.00020493246847763658, "19": 0.00019620158127509058}}, {"key": "pan2024assessing", "year": "2024", "title": "Assessing AI Detectors In Identifying Ai-generated Code: Implications For Education", "topic_distr": {"0": 0.06766772270202637, "1": 0.14679446816444397, "2": 0.0010372750693932176, "3": 0.3648092746734619, "4": 0.0007923776283860207, "5": 0.0007087232079356909, "6": 0.20731830596923828, "7": 0.000585167552344501, "8": 0.014690452255308628, "9": 0.1919732391834259, "10": 0.00046386526082642376, "11": 0.00043388461926952004, "12": 0.0004075440810993314, "13": 0.00038421867066062987, "14": 0.0003634187742136419, "15": 0.00034475524444133043, "16": 0.0003279150405433029, "17": 0.000312643387587741, "18": 0.00029873091261833906, "19": 0.00028600383666343987}}, {"key": "pandya2023automating", "year": "2023", "title": "Automating Customer Service Using Langchain: Building Custom Open-source GPT Chatbot For Organizations", "topic_distr": {"0": 0.046803250908851624, "1": 0.0009795832447707653, "2": 0.000827926502097398, "3": 0.0007170947501435876, "4": 0.0006324475398287177, "5": 0.0005656771827489138, "6": 0.0005116591928526759, "7": 0.00046705896966159344, "8": 0.06609266996383667, "9": 0.611559271812439, "10": 0.0003702400135807693, "11": 0.00034631058224476874, "12": 0.000325286528095603, "13": 0.08661104738712311, "14": 0.00029006737167946994, "15": 0.0002751708379946649, "16": 0.09604872018098831, "17": 0.0002495403459761292, "18": 0.08609864860773087, "19": 0.0002282776404172182}}, {"key": "pang2020text", "year": "2020", "title": "Text Generation By Learning From Demonstrations", "topic_distr": {"0": 0.13304764032363892, "1": 0.0010291044600307941, "2": 0.0008697363664396107, "3": 0.019385220482945442, "4": 0.21735268831253052, "5": 0.0005942479474470019, "6": 0.0005375022883526981, "7": 0.25834307074546814, "8": 0.000451309751952067, "9": 0.000417810253566131, "10": 0.0003889402432832867, "11": 0.2616342306137085, "12": 0.00034171625156886876, "13": 0.07285741716623306, "14": 0.03143296763300896, "15": 0.00028906925581395626, "16": 0.00027494915411807597, "17": 0.000262144225416705, "18": 0.00025047894450835884, "19": 0.00023980757396202534}}, {"key": "pang2021question", "year": "2021", "title": "Quality: Question Answering With Long Input Texts, Yes!", "topic_distr": {"0": 0.0021145606879144907, "1": 0.14154011011123657, "2": 0.37764957547187805, "3": 0.05592856928706169, "4": 0.0011149263009428978, "5": 0.0009972197003662586, "6": 0.0009019937133416533, "7": 0.14772488176822662, "8": 0.22119784355163574, "9": 0.0007011359557509422, "10": 0.045684076845645905, "11": 0.0006105039501562715, "12": 0.0005734410951845348, "13": 0.0005406207055784762, "14": 0.0005113538936711848, "15": 0.00048509309999644756, "16": 0.0004613978380803019, "17": 0.00043990963604301214, "18": 0.00042033387580886483, "19": 0.00040242605609819293}}, {"key": "pangakis2023automated", "year": "2023", "title": "Automated Annotation With Generative AI Requires Validation", "topic_distr": {"0": 0.04747844487428665, "1": 0.27334120869636536, "2": 0.0010011254344135523, "3": 0.3341115713119507, "4": 0.0007647546008229256, "5": 0.0006840169662609696, "6": 0.0006186991231516004, "7": 0.0005647684447467327, "8": 0.0005194860277697444, "9": 0.278683602809906, "10": 0.0004476947942748666, "11": 0.0004187593003734946, "12": 0.00039333695895038545, "13": 0.0003708247095346451, "14": 0.00035074990591965616, "15": 0.000332736992277205, "16": 0.0003164838417433202, "17": 0.059037357568740845, "18": 0.000288317067315802, "19": 0.0002760336792562157}}, {"key": "papangelis2020plato", "year": "2020", "title": "Plato Dialogue System: A Flexible Conversational AI Research Platform", "topic_distr": {"0": 0.001979017863050103, "1": 0.001616475055925548, "2": 0.0013665960868820548, "3": 0.0011836146004498005, "4": 0.11974117904901505, "5": 0.0009336944785900414, "6": 0.3851970136165619, "7": 0.0007709180354140699, "8": 0.0007091067964211106, "9": 0.27822285890579224, "10": 0.0006111106486059725, "11": 0.20407816767692566, "12": 0.0005369113059714437, "13": 0.0005061817355453968, "14": 0.00047877931501716375, "15": 0.00045419138041324914, "16": 0.0004320055595599115, "17": 0.0004118861979804933, "18": 0.0003935574786737561, "19": 0.0003767904418054968}}, {"key": "paperno2016lambada", "year": "2016", "title": "The LAMBADA Dataset: Word Prediction Requiring A Broad Discourse Context", "topic_distr": {"0": 0.001735810423269868, "1": 0.17341116070747375, "2": 0.5661547780036926, "3": 0.001035781460814178, "4": 0.000913514755666256, "5": 0.0008170721121132374, "6": 0.0007390486425720155, "7": 0.0006746273138560355, "8": 0.05351655185222626, "9": 0.0005744758527725935, "10": 0.0005347804981283844, "11": 0.0005002164398320019, "12": 0.17762082815170288, "13": 0.00044295762199908495, "14": 0.019518349319696426, "15": 0.00039746108814142644, "16": 0.00037804635940119624, "17": 0.0003604399971663952, "18": 0.0003444005851633847, "19": 0.00032972783083096147}}, {"key": "paranjape2020neural", "year": "2020", "title": "Neural Generation Meets Real People: Towards Emotionally Engaging Mixed-initiative Conversations", "topic_distr": {"0": 0.0020137287210673094, "1": 0.0016426661750301719, "2": 0.06567731499671936, "3": 0.0012027585180476308, "4": 0.2912062108516693, "5": 0.0009487937204539776, "6": 0.20076914131641388, "7": 0.0007833848940208554, "8": 0.0007205740548670292, "9": 0.11693289875984192, "10": 0.000620993145275861, "11": 0.17040002346038818, "12": 0.12404527515172958, "13": 0.0005143674206919968, "14": 0.0004865218361373991, "15": 0.00046153628500178456, "16": 0.020372427999973297, "17": 0.00041854698793031275, "18": 0.00039992184611037374, "19": 0.00038288364885374904}}, {"key": "paranjape2021posterior", "year": "2021", "title": "Hindsight: Posterior-guided Training Of Retrievers For Improved Open-ended Generation", "topic_distr": {"0": 0.06406741589307785, "1": 0.0009608201798982918, "2": 0.0008122001891024411, "3": 0.0007034544833004475, "4": 0.0006204222445376217, "5": 0.0005549194756895304, "6": 0.28490135073661804, "7": 0.21110358834266663, "8": 0.26701638102531433, "9": 0.00039015873335301876, "10": 0.00036319944774731994, "11": 0.0003397250548005104, "12": 0.0003191007999703288, "13": 0.0003008373605553061, "14": 0.0002845513809006661, "15": 0.00026993811479769647, "16": 0.000256752478890121, "17": 0.00024479502462781966, "18": 0.0002339017519261688, "19": 0.16625650227069855}}, {"key": "paranjape2023automatic", "year": "2023", "title": "ART: Automatic Multi-step Reasoning And Tool-use For Large Language Models", "topic_distr": {"0": 0.014305315911769867, "1": 0.0008779302588663995, "2": 0.0007422567578032613, "3": 0.7733103036880493, "4": 0.0005670015816576779, "5": 0.0005071412888355553, "6": 0.00045871359179727733, "7": 0.059479970484972, "8": 0.00038515537744387984, "9": 0.00035656633554026484, "10": 0.015777187421917915, "11": 0.1129382848739624, "12": 0.0002916264347732067, "13": 0.0002749354753177613, "14": 0.0002600516891106963, "15": 0.0002466966107022017, "16": 0.00023464627156499773, "17": 0.018567774444818497, "18": 0.00021376296353992075, "19": 0.00020465585112106055}}, {"key": "parcalabescu2020seeing", "year": "2020", "title": "Seeing Past Words: Testing The Cross-modal Capabilities Of Pretrained V&L Models On Counting Tasks", "topic_distr": {"0": 0.24716734886169434, "1": 0.0012270703446120024, "2": 0.0010373230325058103, "3": 0.2176448255777359, "4": 0.0007923836237750947, "5": 0.050054777413606644, "6": 0.0006410505156964064, "7": 0.000585171568673104, "8": 0.0005382532253861427, "9": 0.0004983001854270697, "10": 0.000463868462247774, "11": 0.0004338876169640571, "12": 0.0004075468750670552, "13": 0.00038422131910920143, "14": 0.0003634213062468916, "15": 0.0003447576309554279, "16": 0.09459520131349564, "17": 0.0003126455412711948, "18": 0.24805250763893127, "19": 0.13445544242858887}}, {"key": "pardos2023learning", "year": "2023", "title": "Learning Gain Differences Between Chatgpt And Human Tutor Generated Algebra Hints", "topic_distr": {"0": 0.1558426469564438, "1": 0.2540700435638428, "2": 0.0008278435561805964, "3": 0.11494667828083038, "4": 0.0006323804263956845, "5": 0.000565617170650512, "6": 0.0005116055253893137, "7": 0.00046700998791493475, "8": 0.0004295657272450626, "9": 0.4688152074813843, "10": 0.00037020118907094, "11": 0.00034627426066435874, "12": 0.0003252524184063077, "13": 0.00030663690995424986, "14": 0.0002900369290728122, "15": 0.00027514196699485183, "16": 0.00026170213823206723, "17": 0.0002495141525287181, "18": 0.00023841089569032192, "19": 0.00022825368796475232}}, {"key": "parelli2023clip", "year": "2023", "title": "Clip-guided Vision-language Pre-training For Question Answering In 3D Scenes", "topic_distr": {"0": 0.05839131399989128, "1": 0.0015202267095446587, "2": 0.111223004758358, "3": 0.0011129945050925016, "4": 0.0009816117817535996, "5": 0.0008779799682088196, "6": 0.0007941396906971931, "7": 0.0007249162881635129, "8": 0.057058703154325485, "9": 0.0006172991706989706, "10": 0.0005746448296122253, "11": 0.0005375042674131691, "12": 0.036334648728370667, "13": 0.000475977169116959, "14": 0.00045020985999144614, "15": 0.00042708913679234684, "16": 0.07238218188285828, "17": 0.00038730839150957763, "18": 0.654774010181427, "19": 0.00035430683055892587}}, {"key": "parikh2020controlled", "year": "2020", "title": "Totto: A Controlled Table-to-text Generation Dataset", "topic_distr": {"0": 0.026888100430369377, "1": 0.19580619037151337, "2": 0.1014954075217247, "3": 0.0011130520142614841, "4": 0.0009816681267693639, "5": 0.0008780282223597169, "6": 0.15402422845363617, "7": 0.3074009120464325, "8": 0.0006668305140919983, "9": 0.0006173334550112486, "10": 0.0005746767856180668, "11": 0.0005375341279432178, "12": 0.1319677084684372, "13": 0.00047600362449884415, "14": 0.00045023488928563893, "15": 0.00042711288551799953, "16": 0.0004062497755512595, "17": 0.00038732989924028516, "18": 0.0003700939123518765, "19": 0.07453130185604095}}, {"key": "parisi2022tool", "year": "2022", "title": "TALM: Tool Augmented Language Models", "topic_distr": {"0": 0.001450891955755651, "1": 0.0011846821289509535, "2": 0.21640853583812714, "3": 0.527059018611908, "4": 0.0007647439488209784, "5": 0.0006840068381279707, "6": 0.0006186898681335151, "7": 0.0005647600628435612, "8": 0.03575599566102028, "9": 0.0004809188540093601, "10": 0.00044768815860152245, "11": 0.0004187530721537769, "12": 0.0003933311381842941, "13": 0.00037081920891068876, "14": 0.0003507446963340044, "15": 0.00033273204462602735, "16": 0.0003164791560266167, "17": 0.00030174010316841304, "18": 0.00028831278905272484, "19": 0.21180717647075653}}, {"key": "parisotto2019stabilizing", "year": "2019", "title": "Stabilizing Transformers For Reinforcement Learning", "topic_distr": {"0": 0.0010482351062819362, "1": 0.000855961930938065, "2": 0.22135208547115326, "3": 0.0006266461568884552, "4": 0.0005526738823391497, "5": 0.0004943260573782027, "6": 0.000447122089099139, "7": 0.0004081474326085299, "8": 0.00037542267818935215, "9": 0.00034755608066916466, "10": 0.1858130544424057, "11": 0.23913681507110596, "12": 0.000284257170278579, "13": 0.1557719111442566, "14": 0.06302567571401596, "15": 0.00024046270118560642, "16": 0.05293288454413414, "17": 0.07587895542383194, "18": 0.00020836127805523574, "19": 0.00019948428962379694}}, {"key": "park2018multimodal", "year": "2018", "title": "Multimodal Explanations: Justifying Decisions And Pointing To The Evidence", "topic_distr": {"0": 0.0015225076349452138, "1": 0.001242154510691762, "2": 0.23105186223983765, "3": 0.0009094396373257041, "4": 0.0008020913228392601, "5": 0.15552937984466553, "6": 0.0006489030201919377, "7": 0.000592339551076293, "8": 0.09079156816005707, "9": 0.029790863394737244, "10": 0.0004695505485869944, "11": 0.06712422519922256, "12": 0.00041253905510529876, "13": 0.0003889277868438512, "14": 0.0003678729699458927, "15": 0.06282931566238403, "16": 0.0003319340758025646, "17": 0.0003164752561133355, "18": 0.3545885682106018, "19": 0.00028950918931514025}}, {"key": "park2022lut", "year": "2022", "title": "LUT-GEMM: Quantized Matrix Multiplication Based On Luts For Efficient Inference In Large-scale Generative Language Models", "topic_distr": {"0": 0.001247367006726563, "1": 0.0010185736464336514, "2": 0.2618447542190552, "3": 0.0007457170868292451, "4": 0.0006576926098205149, "5": 0.0005882573896087706, "6": 0.0005320838536135852, "7": 0.000485703261801973, "8": 0.0004467601829674095, "9": 0.00041359837632626295, "10": 0.00038501943345181644, "11": 0.0003601347852963954, "12": 0.00033827146398834884, "13": 0.6371701955795288, "14": 0.0003016464179381728, "15": 0.0924471840262413, "16": 0.00027217745082452893, "17": 0.0002595015976112336, "18": 0.0002479538961779326, "19": 0.0002373901370447129}}, {"key": "parker2023large", "year": "2023", "title": "A Large Language Model Approach To Educational Survey Feedback Analysis", "topic_distr": {"0": 0.0657203271985054, "1": 0.07931029051542282, "2": 0.0005778621416538954, "3": 0.269452840089798, "4": 0.0004414179129526019, "5": 0.0003948153753299266, "6": 0.00035711374948732555, "7": 0.00032598490361124277, "8": 0.0002998478594236076, "9": 0.33993250131607056, "10": 0.030597155913710594, "11": 0.00024170827236957848, "12": 0.10864295810461044, "13": 0.00021404039580374956, "14": 0.0002024532004725188, "15": 0.017213251441717148, "16": 0.00018267479026690125, "17": 0.08556701987981796, "18": 0.00016641689580865204, "19": 0.00015932691167108715}}, {"key": "parthasarathi2018extending", "year": "2018", "title": "Extending Neural Generative Conversational Model Using External Knowledge Sources", "topic_distr": {"0": 0.0018897332483902574, "1": 0.0015434283996000886, "2": 0.1376642882823944, "3": 0.001130028162151575, "4": 0.000996636226773262, "5": 0.0008914183126762509, "6": 0.2621932625770569, "7": 0.03478631377220154, "8": 0.0006769995088689029, "9": 0.02575431391596794, "10": 0.0005834404728375375, "11": 0.06854303181171417, "12": 0.02176692523062229, "13": 0.00048326258547604084, "14": 0.0004571008903440088, "15": 0.13209447264671326, "16": 0.3074166476726532, "17": 0.00039323660894297063, "18": 0.0003757377853617072, "19": 0.0003597299219109118}}, {"key": "parthasarathy2024ultimate", "year": "2024", "title": "The Ultimate Guide To Fine-tuning Llms From Basics To Breakthroughs: An Exhaustive Review Of Technologies, Research, Best Practices, Applied Research Challenges And Opportunities", "topic_distr": {"0": 0.0010483276564627886, "1": 0.022252291440963745, "2": 0.0751626119017601, "3": 0.0006266591371968389, "4": 0.0843232125043869, "5": 0.000494335894472897, "6": 0.0004471310239750892, "7": 0.00040815555257722735, "8": 0.00037543018697761, "9": 0.32501137256622314, "10": 0.000323546992149204, "11": 0.01946665160357952, "12": 0.19403564929962158, "13": 0.22825852036476135, "14": 0.00025348537019453943, "15": 0.00024046750331763178, "16": 0.0002287214301759377, "17": 0.00021806941367685795, "18": 0.046625830233097076, "19": 0.0001994882768485695}}, {"key": "parvez2021retrieval", "year": "2021", "title": "Retrieval Augmented Code Generation And Summarization", "topic_distr": {"0": 0.0014874028274789453, "1": 0.001212647301144898, "2": 0.0010250365594401956, "3": 0.16107958555221558, "4": 0.0007830163813196123, "5": 0.0007003488135524094, "6": 0.35054928064346313, "7": 0.16039104759693146, "8": 0.11524108797311783, "9": 0.0004924085806123912, "10": 0.00045838396181352437, "11": 0.00042875760118477046, "12": 0.0004027282993774861, "13": 0.0003796785313170403, "14": 0.00035912441671825945, "15": 0.1810772866010666, "16": 0.0003240402147639543, "17": 0.00030894900555722415, "18": 0.0002952009381260723, "19": 0.023003965616226196}}, {"key": "pascual2021plug", "year": "2021", "title": "A Plug-and-play Method For Controlled Text Generation", "topic_distr": {"0": 0.12618787586688995, "1": 0.0009608693071641028, "2": 0.2601344883441925, "3": 0.0007035011076368392, "4": 0.015937291085720062, "5": 0.000554952013771981, "6": 0.0005019585369154811, "7": 0.5243720412254333, "8": 0.0004214656655676663, "9": 0.00039018140523694456, "10": 0.00036322054802440107, "11": 0.00033974478719756007, "12": 0.00031911933911032975, "13": 0.0003008548519574106, "14": 0.00028456791187636554, "15": 0.0002699537726584822, "16": 0.0002567674091551453, "17": 0.06724333763122559, "18": 0.0002339153434149921, "19": 0.00022394965344574302}}, {"key": "pashevich2021episodic", "year": "2021", "title": "Episodic Transformer For Vision-and-language Navigation", "topic_distr": {"0": 0.001520467922091484, "1": 0.05905207619071007, "2": 0.15195408463478088, "3": 0.0009093691478483379, "4": 0.0008020259556360543, "5": 0.0007173526682890952, "6": 0.0006488515646196902, "7": 0.0005922925774939358, "8": 0.0005448033334687352, "9": 0.000504364026710391, "10": 0.1623866707086563, "11": 0.45479094982147217, "12": 0.0004125063423998654, "13": 0.00038889693678356707, "14": 0.00036784380790777504, "15": 0.00034895300632342696, "16": 0.00033190776593983173, "17": 0.0003164501686114818, "18": 0.14953680336475372, "19": 0.01387331448495388}}, {"key": "patil2023large", "year": "2023", "title": "Gorilla: Large Language Model Connected With Massive Apis", "topic_distr": {"0": 0.0872327983379364, "1": 0.0009794983780011535, "2": 0.0008279462927021086, "3": 0.6752690672874451, "4": 0.0006324577261693776, "5": 0.0005656863795593381, "6": 0.0005116679240018129, "7": 0.0004670669441111386, "8": 0.06300325691699982, "9": 0.1525437980890274, "10": 0.0003702463291119784, "11": 0.00034631649032235146, "12": 0.0003252920869272202, "13": 0.00030667430837638676, "14": 0.0002900723193306476, "15": 0.00027517552371136844, "16": 0.00026173406513407826, "17": 0.00024954459513537586, "18": 0.0002384399704169482, "19": 0.015303263440728188}}, {"key": "paul2023reasoning", "year": "2023", "title": "REFINER: Reasoning Feedback On Intermediate Representations", "topic_distr": {"0": 0.0015038637211546302, "1": 0.0012270626612007618, "2": 0.0010373223340138793, "3": 0.6221464276313782, "4": 0.0007923846715129912, "5": 0.0007087290869094431, "6": 0.0006410512141883373, "7": 0.0005851721507497132, "8": 0.0005382538074627519, "9": 0.000498300651088357, "10": 0.07227198779582977, "11": 0.10683966428041458, "12": 0.0004075472825206816, "13": 0.00038422169745899737, "14": 0.0003634216554928571, "15": 0.00034475798020139337, "16": 0.00032791763078421354, "17": 0.00031264586141332984, "18": 0.00029873327002860606, "19": 0.18877053260803223}}, {"key": "paxton2019interpretable", "year": "2019", "title": "Prospection: Interpretable Plans From Language By Predicting The Future", "topic_distr": {"0": 0.099574014544487, "1": 0.0016695453086867929, "2": 0.18977774679660797, "3": 0.0012225329410284758, "4": 0.0010782239260151982, "5": 0.000964391918387264, "6": 0.0008723001810722053, "7": 0.0007962636882439256, "8": 0.0007324203033931553, "9": 0.0006780546973459423, "10": 0.000631202245131135, "11": 0.698294997215271, "12": 0.0005545634776353836, "13": 0.0005228235968388617, "14": 0.00049452023813501, "15": 0.00046912391553632915, "16": 0.0004462087235879153, "17": 0.0004254278901498765, "18": 0.00040649654692970216, "19": 0.00038917825440876186}}, {"key": "pearce2020deriving", "year": "2020", "title": "DAVE: Deriving Automatically Verilog From English", "topic_distr": {"0": 0.0021149434614926577, "1": 0.0017261203611269593, "2": 0.0014592597726732492, "3": 0.4858901798725128, "4": 0.0011147194309160113, "5": 0.0009970328537747264, "6": 0.1520179808139801, "7": 0.0008232143591158092, "8": 0.0007572101312689483, "9": 0.0007010044646449387, "10": 0.0006525662029162049, "11": 0.0006103893974795938, "12": 0.1876617819070816, "13": 0.0005405193078331649, "14": 0.16072431206703186, "15": 0.00048500209231860936, "16": 0.00046131128328852355, "17": 0.00043982709757983685, "18": 0.0004202550044283271, "19": 0.00040235056076198816}}, {"key": "pearce2021comparative", "year": "2021", "title": "A Comparative Study Of Transformer-based Language Models On Extractive Question Answering", "topic_distr": {"0": 0.001622682437300682, "1": 0.0013230381300672889, "2": 0.4237820506095886, "3": 0.0009685840923339128, "4": 0.0008542469004169106, "5": 0.0007640607072971761, "6": 0.0006910993251949549, "7": 0.018741564825177193, "8": 0.20893515646457672, "9": 0.0005372040322981775, "10": 0.10229317098855972, "11": 0.00046776258386671543, "12": 0.23652072250843048, "13": 0.0004142186953686178, "14": 0.00039179474697448313, "15": 0.0003716739302035421, "16": 0.0003535188443493098, "17": 0.0003370547783561051, "18": 0.00032205600291490555, "19": 0.0003083351766690612}}, {"key": "peer2021greedy", "year": "2021", "title": "Greedy-layer Pruning: Speeding Up Transformer Models For Natural Language Processing", "topic_distr": {"0": 0.0012466851621866226, "1": 0.0010184062412008643, "2": 0.3063388168811798, "3": 0.000745717145036906, "4": 0.0006576897576451302, "5": 0.0005882553523406386, "6": 0.0005320817581377923, "7": 0.0004857013118453324, "8": 0.00044675840763375163, "9": 0.0004135967465117574, "10": 0.0788392648100853, "11": 0.0003601333301048726, "12": 0.00033827012521214783, "13": 0.447212815284729, "14": 0.0003016452246811241, "15": 0.000286154099740088, "16": 0.07752852141857147, "17": 0.08217418938875198, "18": 0.00024795293575152755, "19": 0.00023738919117022306}}, {"key": "pei2019modular", "year": "2019", "title": "A Modular Task-oriented Dialogue System Using A Neural Mixture-of-experts", "topic_distr": {"0": 0.0012874198146164417, "1": 0.0010500469943508506, "2": 0.2371528595685959, "3": 0.0007688110927119851, "4": 0.18302194774150848, "5": 0.0448140986263752, "6": 0.25966712832450867, "7": 0.0005007431609556079, "8": 0.0004605941940099001, "9": 0.0004264055460225791, "10": 0.00039694164297543466, "11": 0.07461303472518921, "12": 0.00034874610719271004, "13": 0.164730966091156, "14": 0.0003109869721811265, "15": 0.02940075471997261, "16": 0.00028060548356734216, "17": 0.0002675371360965073, "18": 0.0002556318650022149, "19": 0.0002447409788146615}}, {"key": "penedo2023refinedweb", "year": "2023", "title": "The Refinedweb Dataset For Falcon LLM: Outperforming Curated Corpora With Web Data, And Web Data Only", "topic_distr": {"0": 0.1772240847349167, "1": 0.13668718934059143, "2": 0.15263527631759644, "3": 0.07501422613859177, "4": 0.0008888362208381295, "5": 0.0007949982536956668, "6": 0.03739099204540253, "7": 0.0006564015056937933, "8": 0.0006037720595486462, "9": 0.000558955711312592, "10": 0.0005203328328207135, "11": 0.00048670254182070494, "12": 0.00045715548912994564, "13": 0.2331697642803192, "14": 0.00040765872108750045, "15": 0.0003867232007905841, "16": 0.0003678330103866756, "17": 0.00035070229205302894, "18": 0.00033509620698168874, "19": 0.18106327950954437}}, {"key": "peng2018dynamic", "year": "2018", "title": "Dynamic Fusion With Intra- And Inter- Modality Attention Flow For Visual Question Answering", "topic_distr": {"0": 0.0016880305483937263, "1": 0.0013762455200776458, "2": 0.1989656537771225, "3": 0.0010076540056616068, "4": 0.000888708105776459, "5": 0.0007948812562972307, "6": 0.0007189768948592246, "7": 0.0006563051720149815, "8": 0.1388239860534668, "9": 0.000558873696718365, "10": 0.000520256464369595, "11": 0.0004866311210207641, "12": 0.00045708840480074286, "13": 0.00043092737905681133, "14": 0.0004075988836120814, "15": 0.0003866664774250239, "16": 0.0949539840221405, "17": 0.00035065083648078144, "18": 0.5562061071395874, "19": 0.00032077275682240725}}, {"key": "peng2020building", "year": "2020", "title": "SOLOIST: Building Task Bots At Scale With Transfer Learning And Machine Teaching", "topic_distr": {"0": 0.03143977373838425, "1": 0.001305834506638348, "2": 0.0011039141099900007, "3": 0.0009561155457049608, "4": 0.23458793759346008, "5": 0.0007542249513790011, "6": 0.18827497959136963, "7": 0.0006227366393432021, "8": 0.0005728063988499343, "9": 0.0005302884965203702, "10": 0.0004936464829370379, "11": 0.05725201591849327, "12": 0.00043370932689867914, "13": 0.23319873213768005, "14": 0.18459659814834595, "15": 0.000366889318684116, "16": 0.06255476921796799, "17": 0.0003327158046886325, "18": 0.0003179101040586829, "19": 0.00030436593806371093}}, {"key": "peng2020few", "year": "2020", "title": "Few-shot Natural Language Generation For Task-oriented Dialog", "topic_distr": {"0": 0.0015606821980327368, "1": 0.05185726657509804, "2": 0.0010762505698949099, "3": 0.0009321582037955523, "4": 0.29185977578163147, "5": 0.0007353301625698805, "6": 0.12111397832632065, "7": 0.024925673380494118, "8": 0.0005584564642049372, "9": 0.0005170037620700896, "10": 0.0004812796541955322, "11": 0.0993897020816803, "12": 0.21604213118553162, "13": 0.00039864296559244394, "14": 0.0003770622133743018, "15": 0.18690334260463715, "16": 0.00034022561158053577, "17": 0.00032438061316497624, "18": 0.00030994584085419774, "19": 0.00029674096731469035}}, {"key": "peng2022large", "year": "2022", "title": "GODEL: Large-scale Pre-training For Goal-directed Dialog", "topic_distr": {"0": 0.0016225308645516634, "1": 0.0013231340562924743, "2": 0.0011182102607563138, "3": 0.1901501715183258, "4": 0.22991374135017395, "5": 0.0007640066323801875, "6": 0.32306110858917236, "7": 0.0006308129522949457, "8": 0.03790749981999397, "9": 0.0005371659062802792, "10": 0.0005000486271455884, "11": 0.00046772940549999475, "12": 0.00043933416600339115, "13": 0.00041418930049985647, "14": 0.0003917669237125665, "15": 0.0003716475621331483, "16": 0.15528571605682373, "17": 0.00033703085500746965, "18": 0.00032203312730416656, "19": 0.0544421412050724}}, {"key": "peng2022sgva", "year": "2022", "title": "Sgva-clip: Semantic-guided Visual Adapting Of Vision-language Models For Few-shot Image Classification", "topic_distr": {"0": 0.001177153899334371, "1": 0.0009608897380530834, "2": 0.0702502653002739, "3": 0.0007034840527921915, "4": 0.0006204448291100562, "5": 0.0005549416528083384, "6": 0.0005019493401050568, "7": 0.00045819548540748656, "8": 0.00042145795305259526, "9": 0.00039017427479848266, "10": 0.0003632138832472265, "11": 0.00033973855897784233, "12": 0.05483560264110565, "13": 0.09380833804607391, "14": 0.0002845627022907138, "15": 0.000269948854111135, "16": 0.15182410180568695, "17": 0.24330304563045502, "18": 0.37870854139328003, "19": 0.00022394556435756385}}, {"key": "peng2023check", "year": "2023", "title": "Check Your Facts And Try Again: Improving Large Language Models With External Knowledge And Automated Feedback", "topic_distr": {"0": 0.04332808032631874, "1": 0.0011841101804748178, "2": 0.001001024735160172, "3": 0.29008790850639343, "4": 0.14126022160053253, "5": 0.0006839525885879993, "6": 0.13995078206062317, "7": 0.09597238898277283, "8": 0.07483639568090439, "9": 0.057570140808820724, "10": 0.0004476526810321957, "11": 0.0004187198937870562, "12": 0.00039329996798187494, "13": 0.0003707898431457579, "14": 0.0003507169312797487, "15": 0.00033270567655563354, "16": 0.1184053048491478, "17": 0.0328415185213089, "18": 0.0002882899425458163, "19": 0.0002760077186394483}}, {"key": "peng2023instruction", "year": "2023", "title": "Instruction Tuning With GPT-4", "topic_distr": {"0": 0.0020789667032659054, "1": 0.19932176172733307, "2": 0.0014348793774843216, "3": 0.47718545794487, "4": 0.0010960762156173587, "5": 0.0009803588036447763, "6": 0.0008867427823133767, "7": 0.0008094473159871995, "8": 0.0007445468800142407, "9": 0.0006892811506986618, "10": 0.0006416530231945217, "11": 0.08822956681251526, "12": 0.0005637453286908567, "13": 0.0005314798909239471, "14": 0.000502707960549742, "15": 0.10356903076171875, "16": 0.00045359652722254395, "17": 0.06499636173248291, "18": 0.00041322686593048275, "19": 0.0548710972070694}}, {"key": "peng2023kosmos", "year": "2023", "title": "Kosmos-2: Grounding Multimodal Large Language Models To The World", "topic_distr": {"0": 0.001222641090862453, "1": 0.037052419036626816, "2": 0.09160621464252472, "3": 0.0007311045192182064, "4": 0.0006448021158576012, "5": 0.000576728314626962, "6": 0.000521655660122633, "7": 0.00047618403914384544, "8": 0.0004380042082630098, "9": 0.06351637095212936, "10": 0.00037747350870631635, "11": 0.1073438748717308, "12": 0.0003316417569294572, "13": 0.0003126605588477105, "14": 0.0002957344986498356, "15": 0.07972464710474014, "16": 0.0002668430970516056, "17": 0.0002544156741350889, "18": 0.5595512390136719, "19": 0.05475538596510887}}, {"key": "peng2023model", "year": "2023", "title": "Model Tuning Or Prompt Tuning? A Study Of Large Language Models For Clinical Concept And Relation Extraction", "topic_distr": {"0": 0.04570164158940315, "1": 0.0007835537544451654, "2": 0.0006622695946134627, "3": 0.28864607214927673, "4": 0.0005059028044342995, "5": 0.0004524926480371505, "6": 0.0004092834424227476, "7": 0.0003736071230378002, "8": 0.0003436517727095634, "9": 0.00031814342946745455, "10": 0.00029616025858558714, "11": 0.00027701875660568476, "12": 0.0002602013119030744, "13": 0.11552862823009491, "14": 0.02755573019385338, "15": 0.00022011305554769933, "16": 0.0002093612274620682, "17": 0.5170828700065613, "18": 0.00019072827126365155, "19": 0.00018260252545587718}}, {"key": "peng2023prompting", "year": "2023", "title": "Prompting The Hidden Talent Of Web-scale Speech Models For Zero-shot Task Generalization", "topic_distr": {"0": 0.10781461745500565, "1": 0.07583113014698029, "2": 0.0012300466187298298, "3": 0.16168466210365295, "4": 0.0009396038949489594, "5": 0.0008404058171436191, "6": 0.03693360835313797, "7": 0.02378256805241108, "8": 0.0006382577703334391, "9": 0.0005908816237933934, "10": 0.08631990104913712, "11": 0.0005145015311427414, "12": 0.0004832668346352875, "13": 0.0004556075145956129, "14": 0.06250142306089401, "15": 0.0004088116984348744, "16": 0.00038884254172444344, "17": 0.43794846534729004, "18": 0.0003542359045241028, "19": 0.00033914411324076355}}, {"key": "peng2023reinventing", "year": "2023", "title": "RWKV: Reinventing Rnns For The Transformer Era", "topic_distr": {"0": 0.0013134811306372285, "1": 0.030400609597563744, "2": 0.331521600484848, "3": 0.000785012380219996, "4": 0.0006923477631062269, "5": 0.0006192541914060712, "6": 0.0005601207376457751, "7": 0.0005112962098792195, "8": 0.0004703011072706431, "9": 0.00043539193575270474, "10": 0.220180943608284, "11": 0.00037911118124611676, "12": 0.0003560958430171013, "13": 0.3960687220096588, "14": 0.00031754092196933925, "15": 0.014317601919174194, "16": 0.00028651917818933725, "17": 0.00027317542117089033, "18": 0.00026101921685039997, "19": 0.00024989881785586476}}, {"key": "peng2023study", "year": "2023", "title": "A Study Of Generative Large Language Model For Medical Research And Healthcare", "topic_distr": {"0": 0.05810558423399925, "1": 0.13104167580604553, "2": 0.0011794317979365587, "3": 0.0938987210392952, "4": 0.0009009468485601246, "5": 0.0008058303501456976, "6": 0.0007288805791176856, "7": 0.04262535646557808, "8": 0.000611998955719173, "9": 0.11861366033554077, "10": 0.0005274227587506175, "11": 0.0004933342570438981, "12": 0.2498936653137207, "13": 0.2066618949174881, "14": 0.0004132133908569813, "15": 0.09210515022277832, "16": 0.0003728450392372906, "17": 0.00035548090818338096, "18": 0.0003396621614228934, "19": 0.0003251912712585181}}, {"key": "penha2020what", "year": "2020", "title": "What Does BERT Know About Books, Movies And Music? Probing BERT For Conversational Recommendation", "topic_distr": {"0": 0.14024324715137482, "1": 0.014533303678035736, "2": 0.18567946553230286, "3": 0.0005214871489442885, "4": 0.17352908849716187, "5": 0.0004113720206078142, "6": 0.0382821150124073, "7": 0.0003396552347112447, "8": 0.00031242211116477847, "9": 0.00028923185891471803, "10": 0.17463929951190948, "11": 0.00025184443802572787, "12": 0.0002365552936680615, "13": 0.00022301627905108035, "14": 0.00021094316616654396, "15": 0.00020011008018627763, "16": 0.15161167085170746, "17": 0.0607731007039547, "18": 0.00017339567421004176, "19": 0.05753863602876663}}, {"key": "penha2021evaluating", "year": "2021", "title": "Evaluating The Robustness Of Retrieval Pipelines With Query Variation Generators", "topic_distr": {"0": 0.03011799231171608, "1": 0.049105674028396606, "2": 0.2792176306247711, "3": 0.2000579535961151, "4": 0.061200521886348724, "5": 0.0005160405416972935, "6": 0.0004667630128096789, "7": 0.0004260762652847916, "8": 0.26553136110305786, "9": 0.0003628233098424971, "10": 0.04870009422302246, "11": 0.00031592309824191034, "12": 0.062293581664562225, "13": 0.0002797599881887436, "14": 0.0002646150242071599, "15": 0.00025102560175582767, "16": 0.00023876379418652505, "17": 0.0002276440936839208, "18": 0.00021751403983216733, "19": 0.0002082471182802692}}, {"key": "pereira2022multi", "year": "2022", "title": "Visconde: Multi-document QA With GPT-3 And Neural Reranking", "topic_distr": {"0": 0.001522325910627842, "1": 0.0012419931590557098, "2": 0.0010499521158635616, "3": 0.38348066806793213, "4": 0.0008020327077247202, "5": 0.05679084733128548, "6": 0.000648856395855546, "7": 0.0005922970012761652, "8": 0.4383199214935303, "9": 0.0005043678102083504, "10": 0.00046951681724749506, "11": 0.00043917089351452887, "12": 0.0004125094274058938, "13": 0.00038889984716661274, "14": 0.000367846543667838, "15": 0.11172858625650406, "16": 0.00033191023976542056, "17": 0.0003164525260217488, "18": 0.00030237052123993635, "19": 0.00028948840918019414}}, {"key": "perez2021true", "year": "2021", "title": "True Few-shot Learning With Language Models", "topic_distr": {"0": 0.001418050960637629, "1": 0.30013537406921387, "2": 0.0009783640271052718, "3": 0.25700902938842773, "4": 0.0007473541190847754, "5": 0.0006684529362246394, "6": 0.0006046214257366955, "7": 0.0005519178812392056, "8": 0.0005076657980680466, "9": 0.00046998311881907284, "10": 0.00043750807526521385, "11": 0.0004092309682164341, "12": 0.000384387094527483, "13": 0.00036238707252778113, "14": 0.00034276905353181064, "15": 0.0003251659800298512, "16": 0.00030928265186958015, "17": 0.3185371458530426, "18": 0.0002817568019963801, "19": 0.11551954597234726}}, {"key": "perez2022ignore", "year": "2022", "title": "Ignore Previous Prompt: Attack Techniques For Language Models", "topic_distr": {"0": 0.0021911244839429855, "1": 0.2784269452095032, "2": 0.0015105076599866152, "3": 0.1945783495903015, "4": 0.001153860124759376, "5": 0.0010320423170924187, "6": 0.0009334906935691833, "7": 0.000852120341733098, "8": 0.0007837984012439847, "9": 0.23098063468933105, "10": 0.03926137834787369, "11": 0.03071909211575985, "12": 0.0005934652290306985, "13": 0.0005594987887889147, "14": 0.0005292100249789655, "15": 0.0005020322278141975, "16": 0.0004775095439981669, "17": 0.1373785138130188, "18": 0.07711996883153915, "19": 0.0004164784913882613}}, {"key": "perez2022red", "year": "2022", "title": "Red Teaming Language Models With Language Models", "topic_distr": {"0": 0.40862807631492615, "1": 0.06555420905351639, "2": 0.0007756286067888141, "3": 0.0006718063959851861, "4": 0.05123143643140793, "5": 0.000529950950294733, "6": 0.0004793450643774122, "7": 0.148553267121315, "8": 0.0004024784138891846, "9": 0.07061436772346497, "10": 0.00034685723949223757, "11": 0.017677491530776024, "12": 0.00030474283266812563, "13": 0.00028730116900987923, "14": 0.0002717479655984789, "15": 0.0227919053286314, "16": 0.0002451998880133033, "17": 0.12051603198051453, "18": 0.00022337731206789613, "19": 0.08989480882883072}}, {"key": "peters2018dissecting", "year": "2018", "title": "Dissecting Contextual Word Embeddings: Architecture And Representation", "topic_distr": {"0": 0.06805729866027832, "1": 0.06724508851766586, "2": 0.27962949872016907, "3": 0.0008378920028917491, "4": 0.0007389861857518554, "5": 0.0006609683623537421, "6": 0.0005978514673188329, "7": 0.0005457380320876837, "8": 0.01001584343612194, "9": 0.000464720738818869, "10": 0.5682598352432251, "11": 0.00040464880294166505, "12": 0.00038008313276804984, "13": 0.0003583294164855033, "14": 0.00033893107320182025, "15": 0.0003215250908397138, "16": 0.00030581961618736386, "17": 0.0002915769873652607, "18": 0.00027860194677487016, "19": 0.00026673247339203954}}, {"key": "peters2023large", "year": "2023", "title": "Large Language Models Can Infer Psychological Dispositions Of Social Media Users", "topic_distr": {"0": 0.470132976770401, "1": 0.04809131845831871, "2": 0.000748629099689424, "3": 0.1530081182718277, "4": 0.0998239740729332, "5": 0.0005114945815876126, "6": 0.0004626511363312602, "7": 0.000422322831582278, "8": 0.00038846154347993433, "9": 0.2237953245639801, "10": 0.0003347774618305266, "11": 0.0003131400444544852, "12": 0.00029412974254228175, "13": 0.00027729550492949784, "14": 0.0002622839529067278, "15": 0.0002488142345100641, "16": 0.0002366604603594169, "17": 0.0002256387087982148, "18": 0.00021559788729064167, "19": 0.00020641260198317468}}, {"key": "petroni2019language", "year": "2019", "title": "Language Models As Knowledge Bases?", "topic_distr": {"0": 0.09328256547451019, "1": 0.0009259902290068567, "2": 0.18475215137004852, "3": 0.0006779158138670027, "4": 0.0005978926201350987, "5": 0.0005347707192413509, "6": 0.0004837046144530177, "7": 0.0004415411385707557, "8": 0.10137080401182175, "9": 0.0003759923274628818, "10": 0.0676669254899025, "11": 0.0003273898328188807, "12": 0.0003075144486501813, "13": 0.00028991414001211524, "14": 0.0002742194919846952, "15": 0.00026013681781478226, "16": 0.1772046834230423, "17": 0.0601164847612381, "18": 0.00022540891950484365, "19": 0.3098839819431305}}, {"key": "petroni2020how", "year": "2020", "title": "How Context Affects Language Models' Factual Predictions", "topic_distr": {"0": 0.0012873271480202675, "1": 0.0010499381460249424, "2": 0.49202120304107666, "3": 0.0007687645847909153, "4": 0.0006780159892514348, "5": 0.0006064349436201155, "6": 0.0005485254805535078, "7": 0.0005007116706110537, "8": 0.18418361246585846, "9": 0.0004263787413947284, "10": 0.06417454034090042, "11": 0.0003712630714289844, "12": 0.0003487241920083761, "13": 0.00032876530895009637, "14": 0.07402805238962173, "15": 0.0002949975314550102, "16": 0.17761491239070892, "17": 0.0002675203140825033, "18": 0.00025561577058397233, "19": 0.0002447255828883499}}, {"key": "petrov2022systematic", "year": "2022", "title": "A Systematic Review And Replicability Study Of Bert4rec For Sequential Recommendation", "topic_distr": {"0": 0.06295852363109589, "1": 0.0008558845147490501, "2": 0.3215622901916504, "3": 0.0006266699056141078, "4": 0.15929274260997772, "5": 0.0004943461972288787, "6": 0.0430908203125, "7": 0.0004081640799995512, "8": 0.0003754379868041724, "9": 0.0003475702542345971, "10": 0.17638063430786133, "11": 0.00030264173983596265, "12": 0.11473073065280914, "13": 0.11722493916749954, "14": 0.0002534906379878521, "15": 0.00024047250917647034, "16": 0.0002287261886522174, "17": 0.00021807396842632443, "18": 0.0002083697763737291, "19": 0.00019949243869632483}}, {"key": "petrov2023language", "year": "2023", "title": "Language Model Tokenizers Introduce Unfairness Between Languages", "topic_distr": {"0": 0.3328790068626404, "1": 0.0015913688112050295, "2": 0.0013452640268951654, "3": 0.0011651533422991633, "4": 0.0010276146931573749, "5": 0.0009191256831400096, "6": 0.0008313569123856723, "7": 0.0007588893640786409, "8": 0.0006980425678193569, "9": 0.09245423227548599, "10": 0.16391021013259888, "11": 0.0005626942729577422, "12": 0.0005285338265821338, "13": 0.1037551537156105, "14": 0.1328420639038086, "15": 0.000447104568593204, "16": 0.0004252649378031492, "17": 0.00040545951924286783, "18": 0.00038741674507036805, "19": 0.1630660742521286}}, {"key": "pfeiffer2020framework", "year": "2020", "title": "Adapterhub: A Framework For Adapting Transformers", "topic_distr": {"0": 0.0015399028779938817, "1": 0.0012574177235364914, "2": 0.0010629832977429032, "3": 0.0009206670802086592, "4": 0.0008119879639707506, "5": 0.0007262625149451196, "6": 0.0006569105316884816, "7": 0.0005996490945108235, "8": 0.0005515699740499258, "9": 0.12221614271402359, "10": 0.31065380573272705, "11": 0.00044462227378971875, "12": 0.06351533532142639, "13": 0.324863076210022, "14": 0.10796191543340683, "15": 0.00035328714875504375, "16": 0.06094490736722946, "17": 0.00032038058270700276, "18": 0.00030612380942329764, "19": 0.0002930817718151957}}, {"key": "pfeiffer2020mad", "year": "2020", "title": "MAD-X: An Adapter-based Framework For Multi-task Cross-lingual Transfer", "topic_distr": {"0": 0.0019177044741809368, "1": 0.0015668661799281836, "2": 0.0013245417503640056, "3": 0.0011472086189314723, "4": 0.0010117883794009686, "5": 0.0009049696964211762, "6": 0.0008185525075532496, "7": 0.0007472010911442339, "8": 0.047162748873233795, "9": 0.0006362756248563528, "10": 0.24483558535575867, "11": 0.000554027734324336, "12": 0.0005203934852033854, "13": 0.09144251048564911, "14": 0.3055163025856018, "15": 0.0004402183694764972, "16": 0.07034607231616974, "17": 0.22836041450500488, "18": 0.0003814498195424676, "19": 0.00036519861896522343}}, {"key": "phan2021multi", "year": "2021", "title": "Cotext: Multi-task Learning With Code-text Transformer", "topic_distr": {"0": 0.001708488678559661, "1": 0.08178756386041641, "2": 0.0011793787125498056, "3": 0.0010215077782049775, "4": 0.0009009240311570466, "5": 0.0008058099774643779, "6": 0.44868502020835876, "7": 0.0006653285818174481, "8": 0.0006119834142737091, "9": 0.000566557515412569, "10": 0.11543632298707962, "11": 0.0004933217423968017, "12": 0.00046337282401509583, "13": 0.05210942402482033, "14": 0.0004132028843741864, "15": 0.00039198267040774226, "16": 0.0003728355513885617, "17": 0.16168184578418732, "18": 0.13037988543510437, "19": 0.0003251830057706684}}, {"key": "phan2021text", "year": "2021", "title": "Scifive: A Text-to-text Transformer Model For Biomedical Literature", "topic_distr": {"0": 0.0026521619874984026, "1": 0.0021666991524398327, "2": 0.0018317538779228926, "3": 0.0015865596942603588, "4": 0.001399268745444715, "5": 0.001251543522812426, "6": 0.0011320313205942512, "7": 0.0010333546670153737, "8": 0.0009505015914328396, "9": 0.06563938409090042, "10": 0.2628856599330902, "11": 0.0007662022835575044, "12": 0.19044539332389832, "13": 0.0006784965516999364, "14": 0.000641765771433711, "15": 0.3041779398918152, "16": 0.1591765582561493, "17": 0.0005521008861251175, "18": 0.0005275326548144221, "19": 0.0005050578038208187}}, {"key": "phan2022pretrained", "year": "2022", "title": "Vit5: Pretrained Text-to-text Transformer For Vietnamese Language Generation", "topic_distr": {"0": 0.001541443751193583, "1": 0.0012574244756251574, "2": 0.0010628750314936042, "3": 0.000920588499866426, "4": 0.0008119188132695854, "5": 0.000726201687939465, "6": 0.0006568555836565793, "7": 0.17573615908622742, "8": 0.0005515238153748214, "9": 0.0005105857271701097, "10": 0.24110496044158936, "11": 0.00044458507909439504, "12": 0.0004175949143245816, "13": 0.00039369426667690277, "14": 0.09272103011608124, "15": 0.0003532575792632997, "16": 0.00033600209280848503, "17": 0.2938626706600189, "18": 0.0003060981980524957, "19": 0.18628451228141785}}, {"key": "phang2018sentence", "year": "2018", "title": "Sentence Encoders On Stilts: Supplementary Training On Intermediate Labeled-data Tasks", "topic_distr": {"0": 0.001888171536847949, "1": 0.13043707609176636, "2": 0.5811922550201416, "3": 0.001129733631387353, "4": 0.0009963824413716793, "5": 0.0008911897893995047, "6": 0.0008060886757448316, "7": 0.0007358237053267658, "8": 0.0006768263410776854, "9": 0.0006265873089432716, "10": 0.20604681968688965, "11": 0.000545591814443469, "12": 0.000512469676323235, "13": 0.00048313895240426064, "14": 0.00045698395115323365, "15": 0.00043351532076485455, "16": 0.00041233949013985693, "17": 0.00039313602610491216, "18": 0.0003756416554097086, "19": 0.07096020877361298}}, {"key": "phung2023automating", "year": "2023", "title": "Automating Human Tutor-style Programming Feedback: Leveraging GPT-4 Tutor Model For Hint Generation And GPT-3.5 Student Model For Hint Validation", "topic_distr": {"0": 0.0011347428662702441, "1": 0.0009260890074074268, "2": 0.000782738730777055, "3": 0.48601120710372925, "4": 0.0005979220732115209, "5": 0.0005347965052351356, "6": 0.10261864215135574, "7": 0.10780717432498932, "8": 0.00040615853504277766, "9": 0.20506244897842407, "10": 0.00035002880031242967, "11": 0.00032740566530264914, "12": 0.020443854853510857, "13": 0.00028992813895456493, "14": 0.000274232734227553, "15": 0.07150803506374359, "16": 0.00024744190159253776, "17": 0.00023591805074829608, "18": 0.00022541980433743447, "19": 0.0002158160787075758}}, {"key": "phung2023generative", "year": "2023", "title": "Generative AI For Programming Education: Benchmarking Chatgpt, GPT-4, And Human Tutors", "topic_distr": {"0": 0.0012740092352032661, "1": 0.001039384864270687, "2": 0.0008784750243648887, "3": 0.5157485604286194, "4": 0.0006710612215101719, "5": 0.0006002144073136151, "6": 0.11066018044948578, "7": 0.000495575659442693, "8": 0.0004558410437311977, "9": 0.27895861864089966, "10": 0.0003928453370463103, "11": 0.0003674548934213817, "12": 0.08649493008852005, "13": 0.0003253930190112442, "14": 0.00030777769279666245, "15": 0.00029197163530625403, "16": 0.00027770973974838853, "17": 0.0002647762303240597, "18": 0.00025299383560195565, "19": 0.00024221533385571092}}, {"key": "phung2023grounded", "year": "2023", "title": "Grounded Text-to-image Synthesis With Attention Refocusing", "topic_distr": {"0": 0.0018627564422786236, "1": 0.0015203711809590459, "2": 0.23727937042713165, "3": 0.26182302832603455, "4": 0.0009816312231123447, "5": 0.0008779967902228236, "6": 0.0007941554649733007, "7": 0.08702153712511063, "8": 0.0006668066489510238, "9": 0.0006173113943077624, "10": 0.0005746561801061034, "11": 0.0005375149194151163, "12": 0.0005048830644227564, "13": 0.00047598659875802696, "14": 0.00045021879486739635, "15": 0.00042709760600700974, "16": 0.0004062352527398616, "17": 0.0935116559267044, "18": 0.30931249260902405, "19": 0.00035431384458206594}}, {"key": "phute2023llm", "year": "2023", "title": "LLM Self Defense: By Self Examination, Llms Know They Are Being Tricked", "topic_distr": {"0": 0.18487489223480225, "1": 0.14047956466674805, "2": 0.001037196139805019, "3": 0.36003997921943665, "4": 0.0007923209923319519, "5": 0.0007086725672706962, "6": 0.04466237127780914, "7": 0.12193138152360916, "8": 0.0005382110830396414, "9": 0.0004982611280865967, "10": 0.000463832140667364, "11": 0.037606380879879, "12": 0.0004075149481650442, "13": 0.00038419122574850917, "14": 0.0003633928135968745, "15": 0.00034473062260076404, "16": 0.0003278916410636157, "17": 0.10395447909832001, "18": 0.0002987095795106143, "19": 0.00028598340577445924}}, {"key": "pillutla2021measuring", "year": "2021", "title": "MAUVE: Measuring The Gap Between Neural Text And Human Text Using Divergence Frontiers", "topic_distr": {"0": 0.18505142629146576, "1": 0.0016696449602022767, "2": 0.1947854906320572, "3": 0.07030777633190155, "4": 0.0010782078607007861, "5": 0.0009643763187341392, "6": 0.0008722866186872125, "7": 0.3842453956604004, "8": 0.0007324088364839554, "9": 0.000678044103551656, "10": 0.0006311924080364406, "11": 0.0005903970450162888, "12": 0.09811175614595413, "13": 0.05765070021152496, "14": 0.0004945124965161085, "15": 0.00046911658137105405, "16": 0.0004462017386686057, "17": 0.0004254212253727019, "18": 0.00040649017319083214, "19": 0.0003891721717081964}}, {"key": "pino2019harnessing", "year": "2019", "title": "Harnessing Indirect Training Data For End-to-end Automatic Speech Translation: Tricks Of The Trade", "topic_distr": {"0": 0.0016672149067744613, "1": 0.21386253833770752, "2": 0.2893657386302948, "3": 0.10528170317411423, "4": 0.045242924243211746, "5": 0.0007844386273063719, "6": 0.053679730743169785, "7": 0.0006476830458268523, "8": 0.000595752673689276, "9": 0.0005515315569937229, "10": 0.0005134216626174748, "11": 0.00048023805720731616, "12": 0.00045108344056643546, "13": 0.00042526613106019795, "14": 0.2398681789636612, "15": 0.00038158666575327516, "16": 0.00036294737947173417, "17": 0.00034604419488459826, "18": 0.0003306453872937709, "19": 0.045161303132772446}}, {"key": "pires2023portuguese", "year": "2023", "title": "Sabi\\'a: Portuguese Large Language Models", "topic_distr": {"0": 0.1637788861989975, "1": 0.001273228321224451, "2": 0.3073834180831909, "3": 0.22316546738147736, "4": 0.0008221646421588957, "5": 0.0007353650871664286, "6": 0.0006651439471170306, "7": 0.0006071647512726486, "8": 0.0005584830651059747, "9": 0.000517028383910656, "10": 0.0004813025880139321, "11": 0.00045019492972642183, "12": 0.0004228642210364342, "13": 0.0003986619703937322, "14": 0.10781969875097275, "15": 0.05464018136262894, "16": 0.052545592188835144, "17": 0.0003243960964027792, "18": 0.00030996062560006976, "19": 0.08310079574584961}}, {"key": "platanios2019competence", "year": "2019", "title": "Competence-based Curriculum Learning For Neural Machine Translation", "topic_distr": {"0": 0.0011655259877443314, "1": 0.0009520092862658203, "2": 0.45283201336860657, "3": 0.046766262501478195, "4": 0.0006146531086415052, "5": 0.000549761054571718, "6": 0.0004972635069862008, "7": 0.0004539180954452604, "8": 0.00041752352262847126, "9": 0.000386531901312992, "10": 0.03592954948544502, "11": 0.0003365670272614807, "12": 0.0003161344793625176, "13": 0.24967825412750244, "14": 0.12130661308765411, "15": 0.05787094682455063, "16": 0.0002543657610658556, "17": 0.029218509793281555, "18": 0.00023172743385657668, "19": 0.00022185496345628053}}, {"key": "plepi2021context", "year": "2021", "title": "Context Transformer With Stacked Pointer Networks For Conversational Question Answering Over Knowledge Graphs", "topic_distr": {"0": 0.0013552266173064709, "1": 0.001106925425119698, "2": 0.4135381877422333, "3": 0.0008105292217805982, "4": 0.04732704907655716, "5": 0.0006393799558281898, "6": 0.04605184122920036, "7": 0.0005279132165014744, "8": 0.21090924739837646, "9": 0.0004495420726016164, "10": 0.0004184794961474836, "11": 0.06507508456707001, "12": 0.0003676688938867301, "13": 0.00034662571852095425, "14": 0.0003278609365224838, "15": 0.0003110234974883497, "16": 0.20962786674499512, "17": 0.00028205354465171695, "18": 0.00026950231404043734, "19": 0.00025802047457545996}}, {"key": "poesia2022reliable", "year": "2022", "title": "Synchromesh: Reliable Code Generation From Pre-trained Language Models", "topic_distr": {"0": 0.04714556410908699, "1": 0.053714293986558914, "2": 0.0007972525199875236, "3": 0.46393078565597534, "4": 0.0006090100505389273, "5": 0.0005447139265015721, "6": 0.19392117857933044, "7": 0.1513575315475464, "8": 0.00041368999518454075, "9": 0.00038298292201943696, "10": 0.00035651944926939905, "11": 0.0003334767825435847, "12": 0.00031323186703957617, "13": 0.00029530434403568506, "14": 0.00027931787190027535, "15": 0.00026497337967157364, "16": 0.0846504271030426, "17": 0.00024029272026382387, "18": 0.0002295998128829524, "19": 0.00021981798636261374}}, {"key": "poldrack2023ai", "year": "2023", "title": "Ai-assisted Coding: Experiments With GPT-4", "topic_distr": {"0": 0.0017098403768613935, "1": 0.0013951751170679927, "2": 0.001179296406917274, "3": 0.5510807037353516, "4": 0.0009008572087623179, "5": 0.0008057497325353324, "6": 0.17886769771575928, "7": 0.05157254636287689, "8": 0.0006119376630522311, "9": 0.20775718986988068, "10": 0.000527369964402169, "11": 0.0004932848387397826, "12": 0.0004633381904568523, "13": 0.00043681947863660753, "14": 0.0004131720052100718, "15": 0.00039195336285047233, "16": 0.00037280769902281463, "17": 0.0003554453141987324, "18": 0.00033962816814891994, "19": 0.000325158704072237}}, {"key": "poli2023hyena", "year": "2023", "title": "Hyena Hierarchy: Towards Larger Convolutional Language Models", "topic_distr": {"0": 0.001355504966340959, "1": 0.00110724288970232, "2": 0.43480831384658813, "3": 0.07941625267267227, "4": 0.000714882044121623, "5": 0.000639408768620342, "6": 0.0005783505621366203, "7": 0.000527937023434788, "8": 0.00048560771392658353, "9": 0.0004495623579714447, "10": 0.3082473874092102, "11": 0.04153614491224289, "12": 0.0003676854830700904, "13": 0.12802134454250336, "14": 0.0003278757503721863, "15": 0.0003110375255346298, "16": 0.0002958443365059793, "17": 0.000282066292129457, "18": 0.0002695144503377378, "19": 0.00025803211610764265}}, {"key": "popel2018training", "year": "2018", "title": "Training Tips For The Transformer Model", "topic_distr": {"0": 0.0019834041595458984, "1": 0.13867197930812836, "2": 0.2693204879760742, "3": 0.001183781074360013, "4": 0.05613010749220848, "5": 0.0009338179952464998, "6": 0.0008446461288258433, "7": 0.0007710201316513121, "8": 0.000709200685378164, "9": 0.057365261018276215, "10": 0.11801624298095703, "11": 0.0005716888699680567, "12": 0.0005369824357330799, "13": 0.26030227541923523, "14": 0.09059038013219833, "15": 0.00045425150892697275, "16": 0.00043206277769058943, "17": 0.0004119407385587692, "18": 0.0003936095745302737, "19": 0.00037684032577089965}}, {"key": "poth2021what", "year": "2021", "title": "What To Pre-train On? Efficient Intermediate Task Selection", "topic_distr": {"0": 0.02432989329099655, "1": 0.0012574291322380304, "2": 0.3998574912548065, "3": 0.0009206457179971039, "4": 0.0008119682315737009, "5": 0.0007262451690621674, "6": 0.0006568948738276958, "7": 0.0005996347754262388, "8": 0.04109182208776474, "9": 0.0005106162279844284, "10": 0.12466549873352051, "11": 0.0004446116799954325, "12": 0.0004176198854111135, "13": 0.1259314864873886, "14": 0.13714630901813507, "15": 0.0003532787086442113, "16": 0.0003360221744515002, "17": 0.13934336602687836, "18": 0.000306116504361853, "19": 0.00029307478689588606}}, {"key": "pourreza2023din", "year": "2023", "title": "DIN-SQL: Decomposed In-context Learning Of Text-to-sql With Self-correction", "topic_distr": {"0": 0.0016203118721023202, "1": 0.0013225370785221457, "2": 0.2824752926826477, "3": 0.6861184239387512, "4": 0.0008540521957911551, "5": 0.0007638862007297575, "6": 0.0006909415824338794, "7": 0.021132420748472214, "8": 0.0005801438819617033, "9": 0.0005370813887566328, "10": 0.0004999699303880334, "11": 0.0004676558019127697, "12": 0.0004392650444060564, "13": 0.0004141241079196334, "14": 0.00039170528179965913, "15": 0.0003715890634339303, "16": 0.0003534381394274533, "17": 0.0003369778278283775, "18": 0.0003219824575353414, "19": 0.0003082648036070168}}, {"key": "prabhumoye2021focused", "year": "2021", "title": "Focused Attention Improves Document-grounded Generation", "topic_distr": {"0": 0.001642659422941506, "1": 0.001340094138868153, "2": 0.22117950022220612, "3": 0.0009811612544581294, "4": 0.0008653419790789485, "5": 0.0007739847060292959, "6": 0.16521403193473816, "7": 0.2762647271156311, "8": 0.1463453471660614, "9": 0.0005441813264042139, "10": 0.0005065793520770967, "11": 0.00047383797937072814, "12": 0.18133744597434998, "13": 0.0004195986548438668, "14": 0.0003968834353145212, "15": 0.0003765013243537396, "16": 0.00035811043926514685, "17": 0.00034143251832574606, "18": 0.00032623892184346914, "19": 0.00031233992194756866}}, {"key": "pradeep2020scientific", "year": "2020", "title": "Scientific Claim Verification With VERT5ERINI", "topic_distr": {"0": 0.0020127235911786556, "1": 0.001642698422074318, "2": 0.0013887920649722219, "3": 0.0012028688797727227, "4": 0.0010608751326799393, "5": 0.20707961916923523, "6": 0.0008582654409110546, "7": 0.0007834522984921932, "8": 0.14885397255420685, "9": 0.07169323414564133, "10": 0.16134339570999146, "11": 0.1223800927400589, "12": 0.028672918677330017, "13": 0.000514411658514291, "14": 0.00048656368744559586, "15": 0.059153713285923004, "16": 0.1615295112133026, "17": 0.00041858298936858773, "18": 0.0003999562468379736, "19": 0.028524350374937057}}, {"key": "pramanick2023egocentric", "year": "2023", "title": "Egovlpv2: Egocentric Video-language Pre-training With Fusion In The Backbone", "topic_distr": {"0": 0.0015809708274900913, "1": 0.001289057545363903, "2": 0.2204827517271042, "3": 0.0009439153946004808, "4": 0.019925447180867195, "5": 0.000744604563806206, "6": 0.0006735009956173599, "7": 0.034232694655656815, "8": 0.0005654999404214323, "9": 0.0005235244170762599, "10": 0.1276896446943283, "11": 0.00045585125917568803, "12": 0.00042817715439014137, "13": 0.11270704865455627, "14": 0.0003818178956862539, "15": 0.0003622094518505037, "16": 0.14615359902381897, "17": 0.0003284718550276011, "18": 0.3302307724952698, "19": 0.0003004836034961045}}, {"key": "prasad2022gradient", "year": "2022", "title": "Grips: Gradient-free, Edit-based Instruction Search For Prompting Large Language Models", "topic_distr": {"0": 0.0012861036229878664, "1": 0.0010501369833946228, "2": 0.0008875874918885529, "3": 0.5820006132125854, "4": 0.0006780143594369292, "5": 0.0006064340705052018, "6": 0.0005485247238539159, "7": 0.017249181866645813, "8": 0.0004605646536219865, "9": 0.0004263781593181193, "10": 0.00039691614801995456, "11": 0.00037126257666386664, "12": 0.0003487237263470888, "13": 0.06676854938268661, "14": 0.00031096700695343316, "15": 0.00029499715310521424, "16": 0.00028058746829628944, "17": 0.3255341649055481, "18": 0.0002556154504418373, "19": 0.00024472526274621487}}, {"key": "prasanna2020when", "year": "2020", "title": "When BERT Plays The Lottery, All Tickets Are Winning", "topic_distr": {"0": 0.0022699201945215464, "1": 0.0018515929114073515, "2": 0.6319491863250732, "3": 0.0013557872734963894, "4": 0.001195749151520431, "5": 0.0010695102391764522, "6": 0.0009673810563981533, "7": 0.0008830566075630486, "8": 0.0008122542640194297, "9": 0.0007519628270529211, "10": 0.14697490632534027, "11": 0.0006547606899403036, "12": 0.0006150110275484622, "13": 0.1819058209657669, "14": 0.0005484230350703001, "15": 0.000520258501637727, "16": 0.024320228025317192, "17": 0.0004717996052931994, "18": 0.0004508047422859818, "19": 0.00043159874621778727}}, {"key": "prather2023robots", "year": "2023", "title": "The Robots Are Here: Navigating The Generative AI Revolution In Computing Education", "topic_distr": {"0": 0.15577061474323273, "1": 0.0007834183052182198, "2": 0.0006623112130910158, "3": 0.027057915925979614, "4": 0.0005059355171397328, "5": 0.0004525218391790986, "6": 0.03169013187289238, "7": 0.000373631133697927, "8": 0.0003436738916207105, "9": 0.5861140489578247, "10": 0.00029617929249070585, "11": 0.0002770365681499243, "12": 0.1803479641675949, "13": 0.0002453247143421322, "14": 0.00023204393801279366, "15": 0.00022012721456121653, "16": 0.00020937470253556967, "17": 0.014044451527297497, "18": 0.00019074053852818906, "19": 0.00018261426885146648}}, {"key": "prato2019fully", "year": "2019", "title": "Fully Quantized Transformer For Machine Translation", "topic_distr": {"0": 0.002398513723164797, "1": 0.0019584239926189184, "2": 0.30759865045547485, "3": 0.001434065168723464, "4": 0.0012647927505895495, "5": 0.0011312623973935843, "6": 0.056345365941524506, "7": 0.000934043200686574, "8": 0.0008591528167016804, "9": 0.000795380212366581, "10": 0.0007404207717627287, "11": 0.0006925657507963479, "12": 0.0006505210185423493, "13": 0.396564245223999, "14": 0.22412647306919098, "15": 0.0005502976127900183, "16": 0.0005234173149801791, "17": 0.0004990407614968717, "18": 0.0004768336657434702, "19": 0.00045651872642338276}}, {"key": "press2019improving", "year": "2019", "title": "Improving Transformer Models By Reordering Their Sublayers", "topic_distr": {"0": 0.00198176596313715, "1": 0.0016167539870366454, "2": 0.6456784009933472, "3": 0.0011836406774818897, "4": 0.0010439101606607437, "5": 0.0009337003575637937, "6": 0.0008445401326753199, "7": 0.0007709232741035521, "8": 0.0007091115694493055, "9": 0.0006564761279150844, "10": 0.1432788223028183, "11": 0.0005716170417144895, "12": 0.0005369149148464203, "13": 0.13737861812114716, "14": 0.06074634566903114, "15": 0.00045419440721161664, "16": 0.00043200846994295716, "17": 0.00041188899194821715, "18": 0.00039356009801849723, "19": 0.00037679297383874655}}, {"key": "press2022measuring", "year": "2022", "title": "Measuring And Narrowing The Compositionality Gap In Language Models", "topic_distr": {"0": 0.0751877874135971, "1": 0.0010608150623738766, "2": 0.0008968236506916583, "3": 0.5863333344459534, "4": 0.0006850676145404577, "5": 0.0006127427332103252, "6": 0.000554230937268585, "7": 0.0005059198592789471, "8": 0.20865002274513245, "9": 0.00043081375770270824, "10": 0.00040104525396600366, "11": 0.030829092487692833, "12": 0.0003523514897096902, "13": 0.0231865756213665, "14": 0.00031420195591636, "15": 0.00029806597740389407, "16": 0.04999387636780739, "17": 0.00027030293131247163, "18": 0.0002582745801191777, "19": 0.019178617745637894}}, {"key": "pruksachatkun2020intermediate", "year": "2020", "title": "Intermediate-task Transfer Learning With Pretrained Models For Natural Language Understanding: When And Why Does It Work?", "topic_distr": {"0": 0.034892842173576355, "1": 0.0011708085658028722, "2": 0.13715417683124542, "3": 0.3761667311191559, "4": 0.0007559251971542835, "5": 0.0006761195254512131, "6": 0.000611555646173656, "7": 0.0005582477315329015, "8": 0.000513488135766238, "9": 0.0004753732937388122, "10": 0.07720779627561569, "11": 0.0004139243683312088, "12": 0.00038879556814208627, "13": 0.00036654321593232453, "14": 0.13546642661094666, "15": 0.0003288952575530857, "16": 0.03681948035955429, "17": 0.0002982606820296496, "18": 0.00028498820029199123, "19": 0.1954496204853058}}, {"key": "pruthi2019learning", "year": "2019", "title": "Learning To Deceive With Attention-based Explanations", "topic_distr": {"0": 0.11417397856712341, "1": 0.001212461618706584, "2": 0.6429200768470764, "3": 0.0008878021617420018, "4": 0.04623491317033768, "5": 0.07996519654989243, "6": 0.0006334619829431176, "7": 0.000578244449570775, "8": 0.00053188152378425, "9": 0.06899068504571915, "10": 0.0004583772970363498, "11": 0.00042875134386122227, "12": 0.0004027224495075643, "13": 0.040670815855264664, "14": 0.0003591192071326077, "15": 0.00034067645901814103, "16": 0.0003240354999434203, "17": 0.0003089445235673338, "18": 0.0002951966307591647, "19": 0.00028262013802304864}}, {"key": "pryzant2023automatic", "year": "2023", "title": "Automatic Prompt Optimization With \"gradient Descent\" And Beam Search", "topic_distr": {"0": 0.0012855983804911375, "1": 0.1219710260629654, "2": 0.0008875370840542018, "3": 0.3249601423740387, "4": 0.0006779918330721557, "5": 0.0006064138142392039, "6": 0.0005485063302330673, "7": 0.05232391506433487, "8": 0.000460549199488014, "9": 0.0004263638984411955, "10": 0.00039690284756943583, "11": 0.10792696475982666, "12": 0.00034871205571107566, "13": 0.0710396096110344, "14": 0.00031095658778212965, "15": 0.00029498725780285895, "16": 0.0002805780677590519, "17": 0.3147529363632202, "18": 0.0002556068648118526, "19": 0.00024471705546602607}}, {"key": "pu2023summarization", "year": "2023", "title": "Summarization Is (almost) Dead", "topic_distr": {"0": 0.30260035395622253, "1": 0.0013401524629443884, "2": 0.0011327943066135049, "3": 0.2161397635936737, "4": 0.055507443845272064, "5": 0.0007739813881926239, "6": 0.0007000726764090359, "7": 0.2861829996109009, "8": 0.0005878107622265816, "9": 0.04283089563250542, "10": 0.0005065773148089647, "11": 0.00047383608762174845, "12": 0.08869221806526184, "13": 0.00041959696682170033, "14": 0.00039688186370767653, "15": 0.00037649981095455587, "16": 0.000358108984073624, "17": 0.0003414311504457146, "18": 0.0003262376121710986, "19": 0.000312338670482859}}, {"key": "pudipeddi2020training", "year": "2020", "title": "Training Large Neural Networks With Constant Memory Using A New Execution Algorithm", "topic_distr": {"0": 0.001057094894349575, "1": 0.0008632660610601306, "2": 0.4026068449020386, "3": 0.0006319978856481612, "4": 0.0005573933594860137, "5": 0.0004985473351553082, "6": 0.0004509402497205883, "7": 0.00041163276182487607, "8": 0.0003786285815294832, "9": 0.04310460016131401, "10": 0.13267560303211212, "11": 0.00030521367443725467, "12": 0.00028668457525782287, "13": 0.3017522096633911, "14": 0.09742806106805801, "15": 0.00024251612194348127, "16": 0.016117554157972336, "17": 0.0002199272275902331, "18": 0.0002101405552821234, "19": 0.00020118778047617525}}, {"key": "puduppully2019data", "year": "2019", "title": "Data-to-text Generation With Entity Modeling", "topic_distr": {"0": 0.0017814674647524953, "1": 0.001455335645005107, "2": 0.42646756768226624, "3": 0.0010652452474460006, "4": 0.0009395053493790329, "5": 0.0008403185056522489, "6": 0.07534897327423096, "7": 0.32347628474235535, "8": 0.0006381912971846759, "9": 0.0005908200982958078, "10": 0.0005499953986145556, "11": 0.000514447980094701, "12": 0.0004832165432162583, "13": 0.00045556010445579886, "14": 0.00043089810060337186, "15": 0.0004087691195309162, "16": 0.16348940134048462, "17": 0.0003706947900354862, "18": 0.0003541990299709141, "19": 0.0003391088102944195}}, {"key": "puri2020training", "year": "2020", "title": "Training Question Answering Models From Synthetic Data", "topic_distr": {"0": 0.0012020639842376113, "1": 0.3041931092739105, "2": 0.2925992012023926, "3": 0.000717076298315078, "4": 0.0006324299029074609, "5": 0.026343826204538345, "6": 0.0005116460961289704, "7": 0.019905896857380867, "8": 0.22072762250900269, "9": 0.00039771173032931983, "10": 0.0003702305257320404, "11": 0.00034630170557647943, "12": 0.0003252781752962619, "13": 0.06996385008096695, "14": 0.000290059921098873, "15": 0.0002751637657638639, "16": 0.0002617228892631829, "17": 0.0002495339431334287, "18": 0.00023842979862820357, "19": 0.060448840260505676}}, {"key": "p\u00e9rez2021pre", "year": "2021", "title": "Robertuito: A Pre-trained Language Model For Social Media Text In Spanish", "topic_distr": {"0": 0.0019834954291582108, "1": 0.001616753521375358, "2": 0.0013665552251040936, "3": 0.0011836125049740076, "4": 0.001043898519128561, "5": 0.0009336902876384556, "6": 0.0008445308194495738, "7": 0.0007709148922003806, "8": 0.000709103886038065, "9": 0.0006564690265804529, "10": 0.26922354102134705, "11": 0.0005716108717024326, "12": 0.20251747965812683, "13": 0.0005061796400696039, "14": 0.24388836324214935, "15": 0.2705695927143097, "16": 0.00043200378422625363, "17": 0.0004118845099583268, "18": 0.00039355584885925055, "19": 0.00037678887019865215}}, {"key": "qi2019answering", "year": "2019", "title": "Answering Complex Open-domain Questions Through Iterative Query Generation", "topic_distr": {"0": 0.001401421264745295, "1": 0.0011443725088611245, "2": 0.1780620664358139, "3": 0.0008379031205549836, "4": 0.0007389909587800503, "5": 0.07896740734577179, "6": 0.058621034026145935, "7": 0.0005457416991703212, "8": 0.5992978811264038, "9": 0.00046472385292872787, "10": 0.02671094797551632, "11": 0.00040465150959789753, "12": 0.00038008566480129957, "13": 0.027124952524900436, "14": 0.0003389333433005959, "15": 0.0003215272445231676, "16": 0.0003058216825593263, "17": 0.0002915789373219013, "18": 0.0002786038094200194, "19": 0.023761402815580368}}, {"key": "qi2020bridging", "year": "2020", "title": "BANG: Bridging Autoregressive And Non-autoregressive Generation With Large Scale Pretraining", "topic_distr": {"0": 0.0018074961844831705, "1": 0.001475892961025238, "2": 0.4510646462440491, "3": 0.0010807063663378358, "4": 0.0009531311807222664, "5": 0.02963992767035961, "6": 0.0007710985955782235, "7": 0.23647932708263397, "8": 0.018298301845788956, "9": 0.0005993888480588794, "10": 0.0005579720600508153, "11": 0.0005219090962782502, "12": 0.0004902246873825788, "13": 0.0004621671687345952, "14": 0.0004371475079096854, "15": 0.00041469756979495287, "16": 0.0003944409254472703, "17": 0.10102012008428574, "18": 0.00035933603066951036, "19": 0.153172105550766}}, {"key": "qi2020cross", "year": "2020", "title": "Imagebert: Cross-modal Pre-training With Large-scale Weak-supervised Image-text Data", "topic_distr": {"0": 0.002266578609123826, "1": 0.10731548070907593, "2": 0.0015652385773137212, "3": 0.0013556942576542497, "4": 0.0011956690577790141, "5": 0.0010694378288462758, "6": 0.0009673154563643038, "7": 0.0008829967118799686, "8": 0.0008121991413645446, "9": 0.0007519117789343, "10": 0.3730365037918091, "11": 0.0006547162192873657, "12": 0.0006149692926555872, "13": 0.000579772109631449, "14": 0.0005483858403749764, "15": 0.0005202232277952135, "16": 0.0004948119749315083, "17": 0.000471767591079697, "18": 0.5044647455215454, "19": 0.0004315694677643478}}, {"key": "qi2020predicting", "year": "2020", "title": "Prophetnet: Predicting Future N-gram For Sequence-to-sequence Pre-training", "topic_distr": {"0": 0.001888982835225761, "1": 0.0015430115163326263, "2": 0.5601963996887207, "3": 0.0011298154713585973, "4": 0.0009964548517018557, "5": 0.0008912549237720668, "6": 0.0008061474654823542, "7": 0.07406359910964966, "8": 0.059055112302303314, "9": 0.0006266330019570887, "10": 0.1743929535150528, "11": 0.000545631512068212, "12": 0.09926973283290863, "13": 0.0004831741389352828, "14": 0.00045701724593527615, "15": 0.0004335468984209001, "16": 0.022092022001743317, "17": 0.0003931646642740816, "18": 0.00037566901301033795, "19": 0.00035966408904641867}}, {"key": "qi2022fine", "year": "2022", "title": "FUM: Fine-grained And Fast User Modeling For News Recommendation", "topic_distr": {"0": 0.042784009128808975, "1": 0.0011706202058121562, "2": 0.000989685533568263, "3": 0.0008571901707910001, "4": 0.46825677156448364, "5": 0.0006761950789950788, "6": 0.0006116241565905511, "7": 0.0005583102465607226, "8": 0.0005135456449352205, "9": 0.0004754265246447176, "10": 0.26109129190444946, "11": 0.0004139707307331264, "12": 0.00038883910747244954, "13": 0.000366584281437099, "14": 0.00034673904883675277, "15": 0.1629612296819687, "16": 0.0566818006336689, "17": 0.0002982940641231835, "18": 0.00028502012719400227, "19": 0.0002728771942202002}}, {"key": "qi2022integrating", "year": "2022", "title": "RASAT: Integrating Relational Structures Into Pretrained Seq2seq Model For Text-to-sql", "topic_distr": {"0": 0.001979038119316101, "1": 0.0016163756372407079, "2": 0.0013665343867614865, "3": 0.13657695055007935, "4": 0.0010438866447657347, "5": 0.0009336796356365085, "6": 0.0008445211569778621, "7": 0.0007709060446359217, "8": 0.02319510653614998, "9": 0.0006564615177921951, "10": 0.22466109693050385, "11": 0.0005716042942367494, "12": 0.000536902982275933, "13": 0.0005061738193035126, "14": 0.0004787718353327364, "15": 0.00045418430818244815, "16": 0.4718664884567261, "17": 0.0004118797951377928, "18": 0.00039355133776552975, "19": 0.13113588094711304}}, {"key": "qi2023fine", "year": "2023", "title": "Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!", "topic_distr": {"0": 0.3606763184070587, "1": 0.17720486223697662, "2": 0.0007972323219291866, "3": 0.23538640141487122, "4": 0.0006089969538152218, "5": 0.0005447028670459986, "6": 0.0004926883848384023, "7": 0.0004497417830862105, "8": 0.00041368204983882606, "9": 0.051530271768569946, "10": 0.00035651258076541126, "11": 0.0003334703797008842, "12": 0.10497583448886871, "13": 0.03923933953046799, "14": 0.0002793125167954713, "15": 0.0002649682865012437, "16": 0.0002520254347473383, "17": 0.025744212791323662, "18": 0.00022959538910072297, "19": 0.0002198137663071975}}, {"key": "qi2023visual", "year": "2023", "title": "Visual Adversarial Examples Jailbreak Aligned Large Language Models", "topic_distr": {"0": 0.15193073451519012, "1": 0.3355488181114197, "2": 0.0007687154575251043, "3": 0.06641197949647903, "4": 0.0005872180336154997, "5": 0.000525223440490663, "6": 0.0004750690422952175, "7": 0.0004336583078838885, "8": 0.00039888813626021147, "9": 0.15065154433250427, "10": 0.00034376312396489084, "11": 0.00032154496875591576, "12": 0.0003020243893843144, "13": 0.0002847383148036897, "14": 0.00026932384935207665, "15": 0.016193807125091553, "16": 0.0002430126041872427, "17": 0.0002316950267413631, "18": 0.27386629581451416, "19": 0.00021195287990849465}}, {"key": "qi2024multimodal", "year": "2024", "title": "SNIFFER: Multimodal Large Language Model For Explainable Out-of-context Misinformation Detection", "topic_distr": {"0": 0.03132332116365433, "1": 0.08052946627140045, "2": 0.0008696903241798282, "3": 0.19533872604370117, "4": 0.0006643598899245262, "5": 0.0915018692612648, "6": 0.000537476793397218, "7": 0.04636622965335846, "8": 0.0004512883024290204, "9": 0.0004177904047537595, "10": 0.0003889217914547771, "11": 0.0003637849004007876, "12": 0.0003417000116314739, "13": 0.000322143139783293, "14": 0.00030470374622382224, "15": 0.11050599813461304, "16": 0.1493721753358841, "17": 0.00026213176897726953, "18": 0.28989845514297485, "19": 0.00023979619436431676}}, {"key": "qian2019domain", "year": "2019", "title": "Domain Adaptive Dialog Generation Via Meta Learning", "topic_distr": {"0": 0.01974247582256794, "1": 0.08578680455684662, "2": 0.16399580240249634, "3": 0.0008984367595985532, "4": 0.3805200457572937, "5": 0.0007087303092703223, "6": 0.0006410524365492165, "7": 0.0005851732566952705, "8": 0.0005382548552006483, "9": 0.0004983016406185925, "10": 0.00046386983012780547, "11": 0.0004338888975325972, "12": 0.00040754806832410395, "13": 0.042614154517650604, "14": 0.00036342235398478806, "15": 0.08727498352527618, "16": 0.0003279182710684836, "17": 0.21361438930034637, "18": 0.0002987338521052152, "19": 0.0002860066597349942}}, {"key": "qian2020large", "year": "2020", "title": "Pchatbot: A Large-scale Dataset For Personalized Chatbot", "topic_distr": {"0": 0.10791277885437012, "1": 0.07066535949707031, "2": 0.0697193294763565, "3": 0.0008772774017415941, "4": 0.06952959299087524, "5": 0.5274085998535156, "6": 0.026439936831593513, "7": 0.0005713911959901452, "8": 0.0005255778087303042, "9": 0.00048656557919457555, "10": 0.00045294471783563495, "11": 0.00042366990237496793, "12": 0.12272390723228455, "13": 0.00037517320015467703, "14": 0.00035486300475895405, "15": 0.00033663882641121745, "16": 0.000320195103995502, "17": 0.00030528297065757215, "18": 0.0002916980301961303, "19": 0.0002792706072796136}}, {"key": "qian2022controllable", "year": "2022", "title": "Controllable Natural Language Generation With Contrastive Prefixes", "topic_distr": {"0": 0.0018076817505061626, "1": 0.0014759298646822572, "2": 0.3864293694496155, "3": 0.0010806897189468145, "4": 0.0009531228570267558, "5": 0.0008524971199221909, "6": 0.000771090853959322, "7": 0.4354710280895233, "8": 0.0006474406109191477, "9": 0.0005993827944621444, "10": 0.0005579664721153677, "11": 0.000521903857588768, "12": 0.0004902197979390621, "13": 0.0004621625121217221, "14": 0.00043714308412745595, "15": 0.09994117170572281, "16": 0.00039443696732632816, "17": 0.00037606724072247744, "18": 0.00035933242179453373, "19": 0.0663713738322258}}, {"key": "qian2023communicative", "year": "2023", "title": "Chatdev: Communicative Agents For Software Development", "topic_distr": {"0": 0.001418275642208755, "1": 0.0011576078832149506, "2": 0.00097835180349648, "3": 0.3982165455818176, "4": 0.0007473673904314637, "5": 0.01972091570496559, "6": 0.0006046313210390508, "7": 0.0005519269034266472, "8": 0.0005076741217635572, "9": 0.33029255270957947, "10": 0.00043751526391133666, "11": 0.17883552610874176, "12": 0.0003843934100586921, "13": 0.0003623930097091943, "14": 0.0003427746705710888, "15": 0.0003251713060308248, "16": 0.0642700046300888, "17": 0.00029488358995877206, "18": 0.00028176140040159225, "19": 0.0002697572926990688}}, {"key": "qiao2019understanding", "year": "2019", "title": "Understanding The Behaviors Of BERT In Ranking", "topic_distr": {"0": 0.0019816674757748842, "1": 0.0016164095140993595, "2": 0.2342311441898346, "3": 0.0011836274061352015, "4": 0.20645032823085785, "5": 0.0009337027440778911, "6": 0.000844542111735791, "7": 0.0007709251949563622, "8": 0.12581674754619598, "9": 0.0006564778159372509, "10": 0.42135244607925415, "11": 0.0005716184969060123, "12": 0.0005369163118302822, "13": 0.0005061863921582699, "14": 0.0004787837387993932, "15": 0.0004541955713648349, "16": 0.0004320095758885145, "17": 0.0004118900396861136, "18": 0.0003935611166525632, "19": 0.00037679390516132116}}, {"key": "qiao2022history", "year": "2022", "title": "HOP: History-and-order Aware Pre-training For Vision-and-language Navigation", "topic_distr": {"0": 0.001372980303131044, "1": 0.001119104796089232, "2": 0.19407051801681519, "3": 0.0008194869151338935, "4": 0.0007227541645988822, "5": 0.0006464489852078259, "6": 0.0005847185966558754, "7": 0.0005337499314919114, "8": 0.0004909545532427728, "9": 0.00045451230835169554, "10": 0.07762542366981506, "11": 0.48587918281555176, "12": 0.00037173391319811344, "13": 0.0003504580818116665, "14": 0.00033148584770970047, "15": 0.0003144622314721346, "16": 0.12794244289398193, "17": 0.0002851719909813255, "18": 0.0526883564889431, "19": 0.0533960722386837}}, {"key": "qiao2022reasoning", "year": "2022", "title": "Reasoning With Language Model Prompting: A Survey", "topic_distr": {"0": 0.0024937919806689024, "1": 0.0020364965312182903, "2": 0.0017216659616678953, "3": 0.25614622235298157, "4": 0.001315210247412324, "5": 0.0011763591319322586, "6": 0.001064026728272438, "7": 0.0009712778264656663, "8": 0.0008934020297601819, "9": 0.0008270872058346868, "10": 0.0007699368870817125, "11": 0.07350840419530869, "12": 0.6532291769981384, "13": 0.0006377371610142291, "14": 0.0006032129167579114, "15": 0.0005722346249967813, "16": 0.0005442827823571861, "17": 0.0005189344519749284, "18": 0.0004958421341143548, "19": 0.0004747173807118088}}, {"key": "qiao2023march", "year": "2023", "title": "March In Chat: Interactive Prompting For Remote Embodied Referring Expression", "topic_distr": {"0": 0.00140465353615582, "1": 0.0011444630799815059, "2": 0.07155820727348328, "3": 0.20997528731822968, "4": 0.0007390414248220623, "5": 0.000661016849335283, "6": 0.0005978952976875007, "7": 0.0005457780207507312, "8": 0.0005020182579755783, "9": 0.0004647547903005034, "10": 0.0004326410125941038, "11": 0.4375745356082916, "12": 0.08339085429906845, "13": 0.00035835569724440575, "14": 0.0003389559278730303, "15": 0.09034823626279831, "16": 0.000305842055240646, "17": 0.05784372240304947, "18": 0.041546985507011414, "19": 0.00026675203116610646}}, {"key": "qin2019conversing", "year": "2019", "title": "Conversing By Reading: Contentful Neural Conversation With On-demand Machine Reading", "topic_distr": {"0": 0.0014500011457130313, "1": 0.001184121472761035, "2": 0.07574761658906937, "3": 0.000867023947648704, "4": 0.0007646824233233929, "5": 0.0006839518900960684, "6": 0.37913352251052856, "7": 0.14520253241062164, "8": 0.13080184161663055, "9": 0.00048088026233017445, "10": 0.00044765224447473884, "11": 0.05395540967583656, "12": 0.02331843227148056, "13": 0.000370789464795962, "14": 0.033776089549064636, "15": 0.0003327053564134985, "16": 0.15061672031879425, "17": 0.00030171588878147304, "18": 0.0002882896806113422, "19": 0.0002760074276011437}}, {"key": "qin2019counterfactual", "year": "2019", "title": "Counterfactual Story Reasoning And Generation", "topic_distr": {"0": 0.09933461248874664, "1": 0.0011843323009088635, "2": 0.0010011284612119198, "3": 0.23004554212093353, "4": 0.0007647487218491733, "5": 0.0006840106216259301, "6": 0.0006186931859701872, "7": 0.359805166721344, "8": 0.0005194810219109058, "9": 0.05444885790348053, "10": 0.00044769051601178944, "11": 0.0004187552840448916, "12": 0.0973450168967247, "13": 0.00037082115886732936, "14": 0.00035074655897915363, "15": 0.00033273379085585475, "16": 0.0003164808149449527, "17": 0.1514468491077423, "18": 0.0002883143024519086, "19": 0.00027603103080764413}}, {"key": "qin2019entity", "year": "2019", "title": "Entity-consistent End-to-end Task-oriented Dialogue System With KB Retriever", "topic_distr": {"0": 0.0013123973039910197, "1": 0.0010722953593358397, "2": 0.3842146396636963, "3": 0.0007849197136238217, "4": 0.09910135716199875, "5": 0.0807635560631752, "6": 0.11605057865381241, "7": 0.08748795092105865, "8": 0.15179240703582764, "9": 0.0004353407712187618, "10": 0.00040525945951230824, "11": 0.0003790666232816875, "12": 0.00035605402081273496, "13": 0.0003356756060384214, "14": 0.0003175036108586937, "15": 0.00030119807342998683, "16": 0.07410577684640884, "17": 0.00027314331964589655, "18": 0.00026098857051692903, "19": 0.0002498694520909339}}, {"key": "qin2020cosda", "year": "2020", "title": "Cosda-ml: Multi-lingual Code-switching Data Augmentation For Zero-shot Cross-lingual NLP", "topic_distr": {"0": 0.0020789392292499542, "1": 0.1435544192790985, "2": 0.348008930683136, "3": 0.001242749858647585, "4": 0.0010960542131215334, "5": 0.000980338198132813, "6": 0.0008867243304848671, "7": 0.0008094303775578737, "8": 0.0007445312803611159, "9": 0.0006892667734064162, "10": 0.10677861422300339, "11": 0.0006001690053381026, "12": 0.0005637335125356913, "13": 0.0005314687732607126, "14": 0.16626200079917908, "15": 0.0004768811631947756, "16": 0.00045358703937381506, "17": 0.00043246260611340404, "18": 0.157643660902977, "19": 0.06616606563329697}}, {"key": "qin2021learning", "year": "2021", "title": "Learning How To Ask: Querying Lms With Mixtures Of Soft Prompts", "topic_distr": {"0": 0.0016423604683950543, "1": 0.0013404639903455973, "2": 0.32564955949783325, "3": 0.0009813165524974465, "4": 0.0008654827834106982, "5": 0.0007741110166534781, "6": 0.0007001899066381156, "7": 0.000639155856333673, "8": 0.0005879091913811862, "9": 0.016986045986413956, "10": 0.0005066621233709157, "11": 0.05036081746220589, "12": 0.0004451446293387562, "13": 0.016215575858950615, "14": 0.027789073064923286, "15": 0.0003765628207474947, "16": 0.09861582517623901, "17": 0.3836362063884735, "18": 0.0003262922400608659, "19": 0.0715612918138504}}, {"key": "qin2021unified", "year": "2021", "title": "LFPT5: A Unified Framework For Lifelong Few-shot Language Learning Based On Prompt Tuning Of T5", "topic_distr": {"0": 0.0011656148126348853, "1": 0.04991699755191803, "2": 0.331012099981308, "3": 0.0006968994275666773, "4": 0.04709411412477493, "5": 0.0005497479578480124, "6": 0.0004972516908310354, "7": 0.0004539073270279914, "8": 0.00041751362732611597, "9": 0.00038652270450256765, "10": 0.00035981464316137135, "11": 0.09453145414590836, "12": 0.00031612697057425976, "13": 0.00029803375946357846, "14": 0.0002818995271809399, "15": 0.03908546641469002, "16": 0.055315595120191574, "17": 0.37716734409332275, "18": 0.00023172193323262036, "19": 0.00022184969566296786}}, {"key": "qin2023facilitating", "year": "2023", "title": "Toolllm: Facilitating Large Language Models To Master 16000+ Real-world Apis", "topic_distr": {"0": 0.0008481860277242959, "1": 0.0006930095260031521, "2": 0.0005856846109963953, "3": 0.7258859276771545, "4": 0.00044740457087755203, "5": 0.0004001698980573565, "6": 0.06708433479070663, "7": 0.0003304060082882643, "8": 0.01043560542166233, "9": 0.050691377371549606, "10": 0.00026191453798674047, "11": 0.11457502096891403, "12": 0.026452256366610527, "13": 0.00021694328461308032, "14": 0.0002051989285973832, "15": 0.00019466085359454155, "16": 0.00018515228293836117, "17": 0.00017652937094680965, "18": 0.00016867389786057174, "19": 0.0001614877546671778}}, {"key": "qin2023is", "year": "2023", "title": "Is Chatgpt A General-purpose Natural Language Processing Task Solver?", "topic_distr": {"0": 0.0013285994064062834, "1": 0.0010835436405614018, "2": 0.0009158816537819803, "3": 0.4939085841178894, "4": 0.0006996191223151982, "5": 0.0006257573841139674, "6": 0.033524040132761, "7": 0.0005166655755601823, "8": 0.0004752399690914899, "9": 0.12031052261590958, "10": 0.10761712491512299, "11": 0.0003830924106296152, "12": 0.23656496405601501, "13": 0.00033924056333489716, "14": 0.0003208755806554109, "15": 0.00030439687543548644, "16": 0.0002895280485972762, "17": 0.0002760441566351801, "18": 0.0002637603029143065, "19": 0.0002525231393519789}}, {"key": "qin2023large", "year": "2023", "title": "Large Language Models Are Effective Text Rankers With Pairwise Ranking Prompting", "topic_distr": {"0": 0.0011544742155820131, "1": 0.00094311946304515, "2": 0.18016266822814941, "3": 0.2808801829814911, "4": 0.14811937510967255, "5": 0.0005446464638225734, "6": 0.0004926373367197812, "7": 0.00044969524606131017, "8": 0.04069484397768974, "9": 0.04317893087863922, "10": 0.0003564756771083921, "11": 0.00033343586255796254, "12": 0.00031319342087954283, "13": 0.12926115095615387, "14": 0.0002792835875879973, "15": 0.00026494087069295347, "16": 0.0002519993286114186, "17": 0.17186956107616425, "18": 0.00022957162582315505, "19": 0.00021979100711178035}}, {"key": "qiu2019blockwise", "year": "2019", "title": "Blockwise Self-attention For Long Document Understanding", "topic_distr": {"0": 0.0020109054166823626, "1": 0.0016425754874944687, "2": 0.23133203387260437, "3": 0.03605836257338524, "4": 0.0010607920121401548, "5": 0.0009488002979196608, "6": 0.0008581978618167341, "7": 0.0007833906565792859, "8": 0.07133718580007553, "9": 0.0006670927396044135, "10": 0.4219439625740051, "11": 0.0005808612913824618, "12": 0.0005455979844555259, "13": 0.22764180600643158, "14": 0.0004865254450123757, "15": 0.000461539690149948, "16": 0.0004389949608594179, "17": 0.00041855007293634117, "18": 0.00039992478559724987, "19": 0.0003828865010291338}}, {"key": "qiu2021vt", "year": "2021", "title": "VT-CLIP: Enhancing Vision-language Models With Visual-guided Texts", "topic_distr": {"0": 0.001808923319913447, "1": 0.001475890981964767, "2": 0.0012477792333811522, "3": 0.0010807171929627657, "4": 0.000953149632550776, "5": 0.0008525217417627573, "6": 0.00077111303107813, "7": 0.0007038968033157289, "8": 0.000647459295578301, "9": 0.0005994001403450966, "10": 0.07564874738454819, "11": 0.0005219189333729446, "12": 0.0004902339424006641, "13": 0.0004621758416760713, "14": 0.00043715571518987417, "15": 0.0004147053696215153, "16": 0.16304422914981842, "17": 0.15668955445289612, "18": 0.5918064117431641, "19": 0.000344033440342173}}, {"key": "qu2019attentive", "year": "2019", "title": "Attentive History Selection For Conversational Question Answering", "topic_distr": {"0": 0.0010311375372111797, "1": 0.0008417083881795406, "2": 0.24247314035892487, "3": 0.0006162568461149931, "4": 0.2135273814201355, "5": 0.00048613245598971844, "6": 0.20345821976661682, "7": 0.0004013822181150317, "8": 0.12850727140903473, "9": 0.0003417952102608979, "10": 0.1657787263393402, "11": 0.00029761320911347866, "12": 0.04064948111772537, "13": 0.00026354598230682313, "14": 0.00024927876074798405, "15": 0.00023647694615647197, "16": 0.00022492579591926187, "17": 0.0002144505560863763, "18": 0.00020490761380642653, "19": 0.00019617777434177697}}, {"key": "qu2020contrast", "year": "2020", "title": "Coda: Contrast-enhanced And Diversity-promoting Data Augmentation For Natural Language Understanding", "topic_distr": {"0": 0.0011442371178418398, "1": 0.24809999763965607, "2": 0.16835808753967285, "3": 0.09468957036733627, "4": 0.0006034197867847979, "5": 0.0005397141794674098, "6": 0.0004881760396528989, "7": 0.0004456227761693299, "8": 0.00040989331318996847, "9": 0.00037946802331134677, "10": 0.232069730758667, "11": 0.00033041625283658504, "12": 0.0003103571361862123, "13": 0.07403203845024109, "14": 0.00027675440651364625, "15": 0.00026254155091010034, "16": 0.05390142649412155, "17": 0.12321324646472931, "18": 0.00022749262279830873, "19": 0.0002178005815949291}}, {"key": "qu2020open", "year": "2020", "title": "Open-retrieval Conversational Question Answering", "topic_distr": {"0": 0.0013141996460035443, "1": 0.0010720096761360765, "2": 0.11357138305902481, "3": 0.000784939038567245, "4": 0.16583701968193054, "5": 0.000619195809122175, "6": 0.18169476091861725, "7": 0.0005112478393130004, "8": 0.33068230748176575, "9": 0.000435350724728778, "10": 0.036322012543678284, "11": 0.00037907532532699406, "12": 0.14903181791305542, "13": 0.00033568328944966197, "14": 0.0003175108868163079, "15": 0.0003012049710378051, "16": 0.01600625179708004, "17": 0.0002731495478656143, "18": 0.00026099453680217266, "19": 0.0002498751855455339}}, {"key": "qu2021asking", "year": "2021", "title": "Asking Questions Like Educational Experts: Automatically Generating Question-answer Pairs On Real-world Examination Data", "topic_distr": {"0": 0.1628750115633011, "1": 0.04247583821415901, "2": 0.0009674201137386262, "3": 0.0008378973579965532, "4": 0.000738991133403033, "5": 0.0006609730189666152, "6": 0.0005978556000627577, "7": 0.09464602917432785, "8": 0.16046972572803497, "9": 0.05150070786476135, "10": 0.0004326123162172735, "11": 0.01987769827246666, "12": 0.00038008575211279094, "13": 0.0003583319194149226, "14": 0.12124484777450562, "15": 0.340793251991272, "16": 0.0003058217407669872, "17": 0.0002915790246333927, "18": 0.00027860389673151076, "19": 0.0002667343069333583}}, {"key": "qu2022simple", "year": "2022", "title": "Siri: A Simple Selective Retraining Mechanism For Transformer-based Visual Grounding", "topic_distr": {"0": 0.0016206208383664489, "1": 0.07635913789272308, "2": 0.4978610873222351, "3": 0.0009684414253570139, "4": 0.000854123558383435, "5": 0.0007639504037797451, "6": 0.0006909996154718101, "7": 0.0006307667354121804, "8": 0.0005801926599815488, "9": 0.0005371264996938407, "10": 0.0005000119563192129, "11": 0.00046769509208388627, "12": 0.013809681870043278, "13": 0.10845384001731873, "14": 0.0003917381982319057, "15": 0.00037162029184401035, "16": 0.00035346782533451915, "17": 0.0003370061458554119, "18": 0.29414018988609314, "19": 0.0003082907060161233}}, {"key": "qu2023layoutllm", "year": "2023", "title": "Layoutllm-t2i: Eliciting Layout Guidance From LLM For Text-to-image Generation", "topic_distr": {"0": 0.0012862638104707003, "1": 0.0010500362841412425, "2": 0.0008875612984411418, "3": 0.1619468629360199, "4": 0.019596528261899948, "5": 0.0006064253393560648, "6": 0.0005485167494043708, "7": 0.21727873384952545, "8": 0.000460557930637151, "9": 0.000426371960202232, "10": 0.00039691038546152413, "11": 0.00037125719245523214, "12": 0.05213063582777977, "13": 0.00032876007026061416, "14": 0.0003109624667558819, "15": 0.08468897640705109, "16": 0.0002805833937600255, "17": 0.20974306762218475, "18": 0.24741622805595398, "19": 0.0002447216829750687}}, {"key": "rabe2020mathematical", "year": "2020", "title": "Mathematical Reasoning Via Self-supervised Skip-tree Training", "topic_distr": {"0": 0.14073868095874786, "1": 0.0019969556014984846, "2": 0.0016880962066352367, "3": 0.6030485033988953, "4": 0.0012895000400021672, "5": 0.001153362449258566, "6": 0.0010432259878143668, "7": 0.0009522901964373887, "8": 0.0008759367628954351, "9": 0.0008109183982014656, "10": 0.0007548852590844035, "11": 0.0007060953648760915, "12": 0.000663229264318943, "13": 0.000625269953161478, "14": 0.0005914206267334521, "15": 0.0005610479274764657, "16": 0.0005336425383575261, "17": 0.0005087897297926247, "18": 0.0004861488414462656, "19": 0.24097204208374023}}, {"key": "radiyadixit2020how", "year": "2020", "title": "How Fine Can Fine-tuning Be? Learning Efficient Language Models", "topic_distr": {"0": 0.09320861101150513, "1": 0.03602681681513786, "2": 0.2924743592739105, "3": 0.0008877781219780445, "4": 0.0007829820970073342, "5": 0.0007003191858530045, "6": 0.0006334445788525045, "7": 0.0005782286170870066, "8": 0.016110055148601532, "9": 0.0004923879751004279, "10": 0.22735589742660522, "11": 0.00042873964412137866, "12": 0.0004027114191558212, "13": 0.2871692180633545, "14": 0.0003591093700379133, "15": 0.0411786213517189, "16": 0.00032402665237896144, "17": 0.00030893608345650136, "18": 0.0002951885689981282, "19": 0.0002826124255079776}}, {"key": "rae2019compressive", "year": "2019", "title": "Compressive Transformers For Long-range Sequence Modelling", "topic_distr": {"0": 0.14383462071418762, "1": 0.04660420119762421, "2": 0.0020500177051872015, "3": 0.0017755543813109398, "4": 0.0015659668715670705, "5": 0.0014006407000124454, "6": 0.0012668913695961237, "7": 0.0011564592132344842, "8": 0.0010637358063831925, "9": 0.0009847775800153613, "10": 0.42959362268447876, "11": 0.15640664100646973, "12": 0.0008054242352955043, "13": 0.000759326561819762, "14": 0.0007182200206443667, "15": 0.000681335455738008, "16": 0.2075590342283249, "17": 0.0006178732146508992, "18": 0.0005903781275264919, "19": 0.0005652258405461907}}, {"key": "rae2021scaling", "year": "2021", "title": "Scaling Language Models: Methods, Analysis & Insights From Training Gopher", "topic_distr": {"0": 0.2400495558977127, "1": 0.04154173284769058, "2": 0.07102760672569275, "3": 0.19291241466999054, "4": 0.0008887727744877338, "5": 0.0007949407445266843, "6": 0.0007190305041149259, "7": 0.0006563541828654706, "8": 0.0006037285784259439, "9": 0.05818408727645874, "10": 0.0005202952888794243, "11": 0.00048666747170500457, "12": 0.16839934885501862, "13": 0.22104676067829132, "14": 0.00040762932621873915, "15": 0.000386695348424837, "16": 0.0003678064967971295, "17": 0.0003506770299281925, "18": 0.00033507205080240965, "19": 0.00032079670927487314}}, {"key": "rafailov2023direct", "year": "2023", "title": "Direct Preference Optimization: Your Language Model Is Secretly A Reward Model", "topic_distr": {"0": 0.00100648810621351, "1": 0.000821402354631573, "2": 0.0006943627959117293, "3": 0.000601409119553864, "4": 0.1293766051530838, "5": 0.012630283832550049, "6": 0.00042911505443044007, "7": 0.1470859795808792, "8": 0.0003603031509555876, "9": 0.0003335587971378118, "10": 0.0003105104551650584, "11": 0.3986426889896393, "12": 0.00027280914946459234, "13": 0.15639977157115936, "14": 0.00024327178834937513, "15": 0.0002307784598087892, "16": 0.0002195056586060673, "17": 0.06027289479970932, "18": 0.00019996985793113708, "19": 0.08986828476190567}}, {"key": "raffel2019exploring", "year": "2019", "title": "Exploring The Limits Of Transfer Learning With A Unified Text-to-text Transformer", "topic_distr": {"0": 0.0016193019691854715, "1": 0.060814160853624344, "2": 0.09949083626270294, "3": 0.0009684868273325264, "4": 0.0008541634888388216, "5": 0.0007639858522452414, "6": 0.0006910316296853125, "7": 0.0006307958974502981, "8": 0.03629621863365173, "9": 0.10420304536819458, "10": 0.12149343639612198, "11": 0.0004677167453337461, "12": 0.125934436917305, "13": 0.00041417809552513063, "14": 0.1814914345741272, "15": 0.0003716374922078103, "16": 0.00035348418168723583, "17": 0.26251134276390076, "18": 0.00032202442525886, "19": 0.0003083049668930471}}, {"key": "rafiepour2023cnn", "year": "2023", "title": "CTRAN: Cnn-transformer-based Network For Natural Language Understanding", "topic_distr": {"0": 0.0020787136163562536, "1": 0.0016982225934043527, "2": 0.18935179710388184, "3": 0.0012429263442754745, "4": 0.001096212537959218, "5": 0.0009804803412407637, "6": 0.0008868526783771813, "7": 0.0008095476659946144, "8": 0.0007446391391567886, "9": 0.0006893665995448828, "10": 0.7044387459754944, "11": 0.0006002559093758464, "12": 0.0005638151778839529, "13": 0.0005315457819961011, "14": 0.0005027702427469194, "15": 0.00047695025568827987, "16": 0.02309507317841053, "17": 0.0004325252375565469, "18": 0.0693838819861412, "19": 0.00039567085332237184}}, {"key": "raghu2018disentangling", "year": "2018", "title": "Disentangling Language And Knowledge In Task-oriented Dialogs", "topic_distr": {"0": 0.11799505352973938, "1": 0.06296990811824799, "2": 0.35331425070762634, "3": 0.0013082410441711545, "4": 0.1643851101398468, "5": 0.10277004539966583, "6": 0.0009334561764262617, "7": 0.0008520886767655611, "8": 0.000783769297413528, "9": 0.0007255921955220401, "10": 0.000675455026794225, "11": 0.000631798873655498, "12": 0.0005934431683272123, "13": 0.0005594780086539686, "14": 0.0005291904089972377, "15": 0.0005020135431550443, "16": 0.18916437029838562, "17": 0.00045525404857471585, "18": 0.00043499545427039266, "19": 0.00041646300815045834}}, {"key": "rahimi2021explaining", "year": "2021", "title": "Explaining Documents' Relevance To Search Queries", "topic_distr": {"0": 0.0010852160630747676, "1": 0.0008858958026394248, "2": 0.2913592457771301, "3": 0.022755278274416924, "4": 0.08306246995925903, "5": 0.15403646230697632, "6": 0.13473659753799438, "7": 0.06540873646736145, "8": 0.15223076939582825, "9": 0.0003596592869143933, "10": 0.09179950505495071, "11": 0.000313168071443215, "12": 0.00029415605240501463, "13": 0.00027732033049687743, "14": 0.0002623074396979064, "15": 0.0002488364989403635, "16": 0.0002366816479479894, "17": 0.00022565890685655177, "18": 0.0002156171976821497, "19": 0.0002064310829155147}}, {"key": "rahman2020improved", "year": "2020", "title": "An Improved Attention For Visual Question Answering", "topic_distr": {"0": 0.001114081242121756, "1": 0.0009093033149838448, "2": 0.4465329051017761, "3": 0.000665802916046232, "4": 0.0005872118636034429, "5": 0.0005252176197245717, "6": 0.00047506351256743073, "7": 0.000433653243817389, "8": 0.16418857872486115, "9": 0.00036927545443177223, "10": 0.00034375913674011827, "11": 0.00032154121436178684, "12": 0.00030202086782082915, "13": 0.00028473499696701765, "14": 0.0002693207061383873, "15": 0.00025548963458277285, "16": 0.00024300976656377316, "17": 0.00023169232008513063, "18": 0.3817353844642639, "19": 0.00021195040608290583}}, {"key": "rajani2019explain", "year": "2019", "title": "Explain Yourself! Leveraging Language Models For Commonsense Reasoning", "topic_distr": {"0": 0.0018902355805039406, "1": 0.0015433826483786106, "2": 0.0013043524231761694, "3": 0.31366029381752014, "4": 0.0009963898919522762, "5": 0.21141894161701202, "6": 0.0008060952532105148, "7": 0.0007358297007158399, "8": 0.1203434094786644, "9": 0.000626592431217432, "10": 0.0005832959432154894, "11": 0.34266427159309387, "12": 0.0005124738090671599, "13": 0.00048314285231754184, "14": 0.00045698764733970165, "15": 0.0004335188423283398, "16": 0.000412342807976529, "17": 0.00039313919842243195, "18": 0.0003756446822080761, "19": 0.0003596408059820533}}, {"key": "rajbhandari2019memory", "year": "2019", "title": "Zero: Memory Optimizations Toward Training Trillion Parameter Models", "topic_distr": {"0": 0.056549668312072754, "1": 0.1896631121635437, "2": 0.05854266136884689, "3": 0.018151922151446342, "4": 0.0005770027637481689, "5": 0.0005160860600881279, "6": 0.00046680422383360565, "7": 0.00042611389653757215, "8": 0.0003919486189261079, "9": 0.1351574957370758, "10": 0.00033778263605199754, "11": 0.00031595100881531835, "12": 0.00029677004204131663, "13": 0.5371987223625183, "14": 0.00026463839458301663, "15": 0.0002510477788746357, "16": 0.00023878487991169095, "17": 0.0002276642044307664, "18": 0.00021753324836026877, "19": 0.00020826551190111786}}, {"key": "rajbhandari2022deepspeed", "year": "2022", "title": "Deepspeed-moe: Advancing Mixture-of-experts Inference And Training To Power Next-generation AI Scale", "topic_distr": {"0": 0.001143735833466053, "1": 0.0009344722493551672, "2": 0.1026255413889885, "3": 0.0006842133007012308, "4": 0.0006034457474015653, "5": 0.0005397372879087925, "6": 0.00048819687799550593, "7": 0.0004456418100744486, "8": 0.00040991080459207296, "9": 0.1285947561264038, "10": 0.03805015981197357, "11": 0.00033043036819435656, "12": 0.11328604072332382, "13": 0.6103912591934204, "14": 0.0002767662226688117, "15": 0.0002625527558848262, "16": 0.00024972789105959237, "17": 0.00023809756385162473, "18": 0.00022750234347768128, "19": 0.00021780988026876003}}, {"key": "rajput2023recommender", "year": "2023", "title": "Recommender Systems With Generative Retrieval", "topic_distr": {"0": 0.0014186009066179395, "1": 0.0011574876261875033, "2": 0.2526751458644867, "3": 0.07345952838659286, "4": 0.3228454887866974, "5": 0.0006685007829219103, "6": 0.0006046646740287542, "7": 0.0005519573460333049, "8": 0.1485622674226761, "9": 0.0004700167628470808, "10": 0.0004375393909867853, "11": 0.0004092602466698736, "12": 0.0003844145976472646, "13": 0.0003624130040407181, "14": 0.0003427935589570552, "15": 0.06918533891439438, "16": 0.1256180852651596, "17": 0.0002948998589999974, "18": 0.00028177694184705615, "19": 0.00026977219386026263}}, {"key": "ram2018conversational", "year": "2018", "title": "Conversational AI: The Science Behind The Alexa Prize", "topic_distr": {"0": 0.039386361837387085, "1": 0.07789132744073868, "2": 0.0007552577881142497, "3": 0.000654151663184166, "4": 0.2194034308195114, "5": 0.0005160257569514215, "6": 0.18620601296424866, "7": 0.0004260636924300343, "8": 0.0003919024602510035, "9": 0.18135054409503937, "10": 0.0003377428511157632, "11": 0.10159745812416077, "12": 0.17492590844631195, "13": 0.0002797517227008939, "14": 0.00026460722438059747, "15": 0.014721311628818512, "16": 0.00023875675105955452, "17": 0.0002276373706990853, "18": 0.00021750762243755162, "19": 0.00020824097737204283}}, {"key": "ram2021few", "year": "2021", "title": "Few-shot Question Answering By Pretraining Span Selection", "topic_distr": {"0": 0.0015421994030475616, "1": 0.041535764932632446, "2": 0.4716774821281433, "3": 0.02300274558365345, "4": 0.0008121374412439764, "5": 0.0007263972074724734, "6": 0.0006570324185304344, "7": 0.01768249273300171, "8": 0.2428988218307495, "9": 0.0005107231554575264, "10": 0.10206054896116257, "11": 0.00044470475404523313, "12": 0.000417707342421636, "13": 0.0003938002628274262, "14": 0.00037248164881020784, "15": 0.0003533526905812323, "16": 0.00033609254751354456, "17": 0.00032044004183262587, "18": 0.0003061806201003492, "19": 0.09394889324903488}}, {"key": "ram2023retrieval", "year": "2023", "title": "In-context Retrieval-augmented Language Models", "topic_distr": {"0": 0.019655324518680573, "1": 0.10363440960645676, "2": 0.2594406008720398, "3": 0.0860908254981041, "4": 0.01562036108225584, "5": 0.0006394261727109551, "6": 0.000578366219997406, "7": 0.07044325023889542, "8": 0.11465224623680115, "9": 0.0004495744942687452, "10": 0.00041850964771583676, "11": 0.00039146043127402663, "12": 0.00036769540747627616, "13": 0.031122785061597824, "14": 0.0003278845688328147, "15": 0.00031104590743780136, "16": 0.00029585231095552444, "17": 0.0002820738882292062, "18": 0.06731964647769928, "19": 0.22795867919921875}}, {"key": "ramamurthy2022is", "year": "2022", "title": "Is Reinforcement Learning (not) For Natural Language Processing: Benchmarks, Baselines, And Building Blocks For Natural Language Policy Optimization", "topic_distr": {"0": 0.04388514906167984, "1": 0.0007024259539321065, "2": 0.0005938115646131337, "3": 0.0005143122398294508, "4": 0.12771302461624146, "5": 0.00040571330464445055, "6": 0.0003669711295515299, "7": 0.13155674934387207, "8": 0.01709713041782379, "9": 0.00028525327797979116, "10": 0.058680832386016846, "11": 0.3533862233161926, "12": 0.1274459958076477, "13": 0.0719105452299118, "14": 0.00020804149971809238, "15": 0.00019735743990167975, "16": 0.0001877171453088522, "17": 0.00017897479119710624, "18": 0.0001710104988887906, "19": 0.0645127221941948}}, {"key": "ramos2022lightweight", "year": "2022", "title": "Smallcap: Lightweight Image Captioning Prompted With Retrieval Augmentation", "topic_distr": {"0": 0.001484844135120511, "1": 0.09090513736009598, "2": 0.06513456255197525, "3": 0.0008877444779500365, "4": 0.0007829525275155902, "5": 0.0007002935162745416, "6": 0.0006334214704111218, "7": 0.0005782074294984341, "8": 0.0005318475305102766, "9": 0.0004923699307255447, "10": 0.00045834798947907984, "11": 0.000428723928052932, "12": 0.09263045340776443, "13": 0.1498013287782669, "14": 0.00035909624421037734, "15": 0.0003406546893529594, "16": 0.0003240147780161351, "17": 0.17068850994110107, "18": 0.34671998023986816, "19": 0.07611747086048126}}, {"key": "ramos2023retrieval", "year": "2023", "title": "Retrieval-augmented Image Captioning", "topic_distr": {"0": 0.0014174246462062001, "1": 0.0011573691153898835, "2": 0.2007942795753479, "3": 0.000847357208840549, "4": 0.0007473360165022314, "5": 0.0006684368127025664, "6": 0.0006046066991984844, "7": 0.03247237205505371, "8": 0.035708848387002945, "9": 0.0004699717101175338, "10": 0.07407502084970474, "11": 0.0004092210147064179, "12": 0.0003843777521979064, "13": 0.0003623782831709832, "14": 0.0003427607298363, "15": 0.016888679936528206, "16": 0.0003092751430813223, "17": 0.0002948715991806239, "18": 0.5085604786872864, "19": 0.12348493933677673}}, {"key": "ramos2024review", "year": "2024", "title": "A Review Of Large Language Models And Autonomous Agents In Chemistry", "topic_distr": {"0": 0.0011546548921614885, "1": 0.053421203047037125, "2": 0.0007971700397320092, "3": 0.1752123236656189, "4": 0.0006089551607146859, "5": 0.06146353483200073, "6": 0.0004926541587337852, "7": 0.0004497105546761304, "8": 0.0004136533534619957, "9": 0.2694588899612427, "10": 0.00035648784250952303, "11": 0.1665610671043396, "12": 0.2544352114200592, "13": 0.013688569888472557, "14": 0.0002792931336443871, "15": 0.00026494989288039505, "16": 0.0002520079433452338, "17": 0.00024027143081184477, "18": 0.00022957946930546314, "19": 0.00021979851590003818}}, {"key": "ran2019option", "year": "2019", "title": "Option Comparison Network For Multiple-choice Reading Comprehension", "topic_distr": {"0": 0.0015421275747939944, "1": 0.0012574243592098355, "2": 0.6151269674301147, "3": 0.0009206373943015933, "4": 0.0008119597914628685, "5": 0.000726238067727536, "6": 0.0006568885291926563, "7": 0.0005996289546601474, "8": 0.19690510630607605, "9": 0.0005106112803332508, "10": 0.0004753289103973657, "11": 0.00044460734352469444, "12": 0.029033370316028595, "13": 0.04390450194478035, "14": 0.0003724000707734376, "15": 0.10545664280653, "16": 0.000336018914822489, "17": 0.0003203698433935642, "18": 0.0003061135357711464, "19": 0.0002930719347205013}}, {"key": "ranasinghe2020transquest", "year": "2020", "title": "Transquest At WMT2020: Sentence-level Direct Assessment", "topic_distr": {"0": 0.14654885232448578, "1": 0.04177391529083252, "2": 0.32106247544288635, "3": 0.14177916944026947, "4": 0.0015294898767024279, "5": 0.0013680143747478724, "6": 0.0012373806675896049, "7": 0.0011295208241790533, "8": 0.0010389572707936168, "9": 0.0009618382900953293, "10": 0.16871152818202972, "11": 0.000837506668176502, "12": 0.0007866628002375364, "13": 0.0007416388834826648, "14": 0.16746243834495544, "15": 0.0006654644967056811, "16": 0.0006329587195068598, "17": 0.0006034805555827916, "18": 0.0005766259273514152, "19": 0.0005520595004782081}}, {"key": "rao2021language", "year": "2021", "title": "Denseclip: Language-guided Dense Prediction With Context-aware Prompting", "topic_distr": {"0": 0.0012854061787948012, "1": 0.0010499842464923859, "2": 0.12207567691802979, "3": 0.0007687704055570066, "4": 0.028185227885842323, "5": 0.0006064411136321723, "6": 0.0005485310102812946, "7": 0.0005007167346775532, "8": 0.0004605698923114687, "9": 0.000426383048761636, "10": 0.0003969206882175058, "11": 0.0003712668258231133, "12": 0.0003487277135718614, "13": 0.000328768597682938, "14": 0.0003109705285169184, "15": 0.00029500050004571676, "16": 0.16254815459251404, "17": 0.2869437634944916, "18": 0.3079385757446289, "19": 0.08461015671491623}}, {"key": "rao2023can", "year": "2023", "title": "Can Chatgpt Assess Human Personalities? A General Evaluation Framework", "topic_distr": {"0": 0.3741239309310913, "1": 0.04837390407919884, "2": 0.0006779305986128747, "3": 0.31244003772735596, "4": 0.0005178691353648901, "5": 0.00046319502871483564, "6": 0.07160311192274094, "7": 0.0003824436862487346, "8": 0.04261155426502228, "9": 0.1001034677028656, "10": 0.0003031650558114052, "11": 0.00028357081464491785, "12": 0.0002663556078914553, "13": 0.0002511109923943877, "14": 0.00023751697153784335, "15": 0.00022531917784363031, "16": 0.00021431305503938347, "17": 0.04653903841972351, "18": 0.0001952393795363605, "19": 0.0001869214465841651}}, {"key": "rao2023cat", "year": "2023", "title": "CAT-LM: Training Language Models On Aligned Code And Tests", "topic_distr": {"0": 0.14994579553604126, "1": 0.15669915080070496, "2": 0.0006150032859295607, "3": 0.19235585629940033, "4": 0.00046978986938484013, "5": 0.000420192169258371, "6": 0.2900046706199646, "7": 0.13634948432445526, "8": 0.0003191206487827003, "9": 0.000295433186693117, "10": 0.00027501926524564624, "11": 0.00025724415900185704, "12": 0.00024162720364984125, "13": 0.05296846851706505, "14": 0.00021546594507526606, "15": 0.00020440058142412454, "16": 0.00019441626500338316, "17": 0.00018536191782914102, "18": 0.00017711339751258492, "19": 0.017806369811296463}}, {"key": "rasheed2023pixel", "year": "2023", "title": "Glamm: Pixel Grounding Large Multimodal Model", "topic_distr": {"0": 0.0010140390368178487, "1": 0.000828042917419225, "2": 0.0006999465986154974, "3": 0.0006062422762624919, "4": 0.05078383535146713, "5": 0.00047823137720115483, "6": 0.1533387154340744, "7": 0.0003948585654143244, "8": 0.00036319930222816765, "9": 0.00033624001662246883, "10": 0.00031300639966502786, "11": 0.0002927760942839086, "12": 0.00027500203577801585, "13": 0.00025926256785169244, "14": 0.0002452272456139326, "15": 0.08910980075597763, "16": 0.00022127007832750678, "17": 0.05176498368382454, "18": 0.6484823226928711, "19": 0.00019298928964417428}}, {"key": "rashkin2018towards", "year": "2018", "title": "Towards Empathetic Open-domain Conversation Models: A New Benchmark And Dataset", "topic_distr": {"0": 0.002013483317568898, "1": 0.0016430624527856708, "2": 0.001388575998134911, "3": 0.00120267691090703, "4": 0.14153382182121277, "5": 0.16550669074058533, "6": 0.3386550843715668, "7": 0.0007833302370272577, "8": 0.0007205238216556609, "9": 0.05068986862897873, "10": 0.0006209498387761414, "11": 0.11339030414819717, "12": 0.17874906957149506, "13": 0.0005143315065652132, "14": 0.0004864879010710865, "15": 0.00046150406706146896, "16": 0.0004389610840007663, "17": 0.00041851779678836465, "18": 0.00039989393553696573, "19": 0.00038285693153738976}}, {"key": "rashkin2020outline", "year": "2020", "title": "Plotmachines: Outline-conditioned Generation With Dynamic Plot State Tracking", "topic_distr": {"0": 0.0013558928621932864, "1": 0.1468394696712494, "2": 0.2676418423652649, "3": 0.0008105739834718406, "4": 0.0007148931035771966, "5": 0.0820058286190033, "6": 0.0005783602828159928, "7": 0.47930508852005005, "8": 0.0004856158047914505, "9": 0.00044956986675970256, "10": 0.00041850534034892917, "11": 0.0003914564149454236, "12": 0.01691187545657158, "13": 0.0003466471389401704, "14": 0.0003278811927884817, "15": 0.0003110427060164511, "16": 0.0002958492550533265, "17": 0.00028207097784616053, "18": 0.0002695189614314586, "19": 0.00025803642347455025}}, {"key": "rashkin2021increasing", "year": "2021", "title": "Increasing Faithfulness In Knowledge-grounded Dialogue With Controllable Features", "topic_distr": {"0": 0.19816100597381592, "1": 0.0011443468974903226, "2": 0.0009673307649791241, "3": 0.000837817438878119, "4": 0.0007389214588329196, "5": 0.03790351003408432, "6": 0.38974088430404663, "7": 0.3661610186100006, "8": 0.0005019373493269086, "9": 0.0004646799061447382, "10": 0.0004325712798163295, "11": 0.0004046132380608469, "12": 0.0003800497215706855, "13": 0.00035829792614094913, "14": 0.00033890127087943256, "15": 0.0003214968601241708, "16": 0.0003057927533518523, "17": 0.0002915513759944588, "18": 0.00027857747045345604, "19": 0.0002667090157046914}}, {"key": "rastogi2019towards", "year": "2019", "title": "Towards Scalable Multi-domain Conversational Agents: The Schema-guided Dialogue Dataset", "topic_distr": {"0": 0.000966887513641268, "1": 0.000789751997217536, "2": 0.15262117981910706, "3": 0.06728550791740417, "4": 0.12022700905799866, "5": 0.2827090620994568, "6": 0.1649325042963028, "7": 0.00037653601611964405, "8": 0.0003463458560872823, "9": 0.0677105262875557, "10": 0.0002984820166602731, "11": 0.00027919045533053577, "12": 0.11781430244445801, "13": 0.0002472320629749447, "14": 0.00023384801170323044, "15": 0.00022183865075930953, "16": 0.022362342104315758, "17": 0.00020117573149036616, "18": 0.00019222349510528147, "19": 0.00018403405556455255}}, {"key": "rastogi2020schema", "year": "2020", "title": "Schema-guided Dialogue State Tracking Task At DSTC8", "topic_distr": {"0": 0.001686653820797801, "1": 0.026469185948371887, "2": 0.19949454069137573, "3": 0.07799948006868362, "4": 0.0008888264419510961, "5": 0.25926473736763, "6": 0.0800955519080162, "7": 0.0006563932984136045, "8": 0.0006037645507603884, "9": 0.07113143801689148, "10": 0.04281728342175484, "11": 0.0004866964591201395, "12": 0.23580563068389893, "13": 0.0004309852374717593, "14": 0.0004076536279171705, "15": 0.0003867183986585587, "16": 0.00036782841198146343, "17": 0.00035069792647846043, "18": 0.00033509201603010297, "19": 0.0003208158304914832}}, {"key": "rastogi2023supporting", "year": "2023", "title": "Supporting Human-ai Collaboration In Auditing Llms With Llms", "topic_distr": {"0": 0.29046764969825745, "1": 0.062426671385765076, "2": 0.0008876541396602988, "3": 0.23502963781356812, "4": 0.0006780675030313432, "5": 0.0006064799381420016, "6": 0.0005485662841238081, "7": 0.0005007489235140383, "8": 0.0004605994909070432, "9": 0.35091593861579895, "10": 0.00039694621227681637, "11": 0.00037129069096408784, "12": 0.00034875012352131307, "13": 0.00032878975616768, "14": 0.0003109905228484422, "15": 0.05467268452048302, "16": 0.00028060871409252286, "17": 0.00026754019199870527, "18": 0.0002556347753852606, "19": 0.00024474377278238535}}, {"key": "ratner2022parallel", "year": "2022", "title": "Parallel Context Windows For Large Language Models", "topic_distr": {"0": 0.0012986051151528955, "1": 0.0010608858428895473, "2": 0.38465365767478943, "3": 0.2531030476093292, "4": 0.0006850272766314447, "5": 0.0006127062370069325, "6": 0.0005541979917325079, "7": 0.040681544691324234, "8": 0.06393256038427353, "9": 0.00043078811722807586, "10": 0.13130968809127808, "11": 0.00037510247784666717, "12": 0.0003523305058479309, "13": 0.11927833408117294, "14": 0.0003141832712572068, "15": 0.00029804822406731546, "16": 0.0002834895276464522, "17": 0.0002702868659980595, "18": 0.00025825921329669654, "19": 0.00024725639377720654}}, {"key": "raunak2019compositionality", "year": "2019", "title": "On Compositionality In Neural Machine Translation", "topic_distr": {"0": 0.27606838941574097, "1": 0.002078679855912924, "2": 0.19730767607688904, "3": 0.0015218391781672835, "4": 0.0013421972980722785, "5": 0.0012004972668364644, "6": 0.0010858597233891487, "7": 0.03343501314520836, "8": 0.0009117338922806084, "9": 0.0008440583478659391, "10": 0.12878160178661346, "11": 0.0007349515217356384, "12": 0.0006903336034156382, "13": 0.0006508229998871684, "14": 0.35068681836128235, "15": 0.0005839764489792287, "16": 0.0005554510280489922, "17": 0.0005295826122164726, "18": 0.0005060164257884026, "19": 0.0004844581999350339}}, {"key": "ravi2022vlc", "year": "2022", "title": "VLC-BERT: Visual Question Answering With Contextualized Commonsense Knowledge", "topic_distr": {"0": 0.0015797297237440944, "1": 0.001289094565436244, "2": 0.0010898465989157557, "3": 0.10348524153232574, "4": 0.0008324995287694037, "5": 0.016552025452256203, "6": 0.0006735046044923365, "7": 0.0006147966487333179, "8": 0.16496191918849945, "9": 0.0005235273274593055, "10": 0.06568354368209839, "11": 0.0004558537621051073, "12": 0.00042817951180040836, "13": 0.0004036730679217726, "14": 0.0003818199911620468, "15": 0.0003622114600148052, "16": 0.27808794379234314, "17": 0.00032847365946508944, "18": 0.22359076142311096, "19": 0.13867534697055817}}, {"key": "rawte2023troubling", "year": "2023", "title": "The Troubling Emergence Of Hallucination In Large Language Models -- An Extensive Definition, Quantification, And Prescriptive Remediations", "topic_distr": {"0": 0.3852285146713257, "1": 0.07135172933340073, "2": 0.000748679565731436, "3": 0.3270709216594696, "4": 0.0005719127366319299, "5": 0.0005115334060974419, "6": 0.0004626863228622824, "7": 0.00042235496221110225, "8": 0.0003884910838678479, "9": 0.00035965442657470703, "10": 0.00033480292768217623, "11": 0.0003131638513877988, "12": 0.17043699324131012, "13": 0.0002773165761027485, "14": 0.00026230388903059065, "15": 0.04037458822131157, "16": 0.00023667844652663916, "17": 0.00022565586550626904, "18": 0.00021561428729910403, "19": 0.0002064283034997061}}, {"key": "razeghi2022impact", "year": "2022", "title": "Impact Of Pretraining Term Frequencies On Few-shot Reasoning", "topic_distr": {"0": 0.24160340428352356, "1": 0.08953380584716797, "2": 0.19575221836566925, "3": 0.2729688286781311, "4": 0.0007473472505807877, "5": 0.0006684468826279044, "6": 0.0006046158378012478, "7": 0.0005519127589650452, "8": 0.0005076611414551735, "9": 0.00046997881145216525, "10": 0.0004375040589366108, "11": 0.0004092272138223052, "12": 0.0003843835729639977, "13": 0.0003623837255872786, "14": 0.0003427659103181213, "15": 0.00032516298233531415, "16": 0.00030927982879802585, "17": 0.00029487605206668377, "18": 0.00028175421175546944, "19": 0.1934444159269333}}, {"key": "razumovskaia2021crossing", "year": "2021", "title": "Crossing The Conversational Chasm: A Primer On Natural Language Processing For Multilingual Task-oriented Dialogue Systems", "topic_distr": {"0": 0.13755764067173004, "1": 0.08598983287811279, "2": 0.0006833575898781419, "3": 0.0005918702227063477, "4": 0.13949961960315704, "5": 0.04824168235063553, "6": 0.00042230935650877655, "7": 0.00038549755117855966, "8": 0.0003545888466760516, "9": 0.05830429866909981, "10": 0.0003055858542211354, "11": 0.05088581144809723, "12": 0.1965533345937729, "13": 0.0002531161590013653, "14": 0.19931268692016602, "15": 0.07985157519578934, "16": 0.00021602437482215464, "17": 0.0002059636899502948, "18": 0.00019679839897435158, "19": 0.00018841403652913868}}, {"key": "rebedea2023nemo", "year": "2023", "title": "Nemo Guardrails: A Toolkit For Controllable And Safe LLM Applications With Programmable Rails", "topic_distr": {"0": 0.12503622472286224, "1": 0.001669737626798451, "2": 0.14917853474617004, "3": 0.21264566481113434, "4": 0.001078197848983109, "5": 0.08252246677875519, "6": 0.00087227817857638, "7": 0.1919400542974472, "8": 0.0007324017351493239, "9": 0.2293945848941803, "10": 0.0006311862962320447, "11": 0.0005903912824578583, "12": 0.0005545494495891035, "13": 0.0005228103254921734, "14": 0.0004945077234879136, "15": 0.0004691120411735028, "16": 0.00044619740219786763, "17": 0.0004254171217326075, "18": 0.0004064862441737205, "19": 0.000389168388210237}}, {"key": "reddy2018conversational", "year": "2018", "title": "Coqa: A Conversational Question Answering Challenge", "topic_distr": {"0": 0.038809023797512054, "1": 0.001257385010831058, "2": 0.20850203931331635, "3": 0.000920670572668314, "4": 0.0008119913400150836, "5": 0.0007262651924975216, "6": 0.18011076748371124, "7": 0.0005996512481942773, "8": 0.40665948390960693, "9": 0.0005106303142383695, "10": 0.0004753466055262834, "11": 0.0004446239036042243, "12": 0.10866712033748627, "13": 0.0003937286383006722, "14": 0.000372413924196735, "15": 0.049483269453048706, "16": 0.0003360314294695854, "17": 0.0003203817759640515, "18": 0.00030612494447268546, "19": 0.0002930828486569226}}, {"key": "rei2020neural", "year": "2020", "title": "COMET: A Neural Framework For MT Evaluation", "topic_distr": {"0": 0.1237606629729271, "1": 0.034657806158065796, "2": 0.2710523307323456, "3": 0.0012027084594592452, "4": 0.0010607406729832292, "5": 0.0009487528004683554, "6": 0.0008581549627706409, "7": 0.2498752772808075, "8": 0.0007205433212220669, "9": 0.0006670593284070492, "10": 0.0006209666607901454, "11": 0.000580832187552005, "12": 0.0005455706268548965, "13": 0.0005143454181961715, "14": 0.2858762741088867, "15": 0.00046151658170856535, "16": 0.0004389729583635926, "17": 0.0004185291181784123, "18": 0.00039990476216189563, "19": 0.025339074432849884}}, {"key": "reif2021recipe", "year": "2021", "title": "A Recipe For Arbitrary Text Style Transfer With Large Language Models", "topic_distr": {"0": 0.002653727540746331, "1": 0.0021669536363333464, "2": 0.0018317664507776499, "3": 0.0015865727327764034, "4": 0.0013992806198075414, "5": 0.001251552952453494, "6": 0.0011320402845740318, "7": 0.36134859919548035, "8": 0.0009505090420134366, "9": 0.0008799553033895791, "10": 0.0008191518718376756, "11": 0.11187062412500381, "12": 0.0007196927908807993, "13": 0.0006785018485970795, "14": 0.0006417707772925496, "15": 0.0006088123773224652, "16": 0.0005790737923234701, "17": 0.36684727668762207, "18": 0.000527536787558347, "19": 0.14150656759738922}}, {"key": "ren2021joint", "year": "2021", "title": "Rocketqav2: A Joint Training Method For Dense Passage Retrieval And Passage Re-ranking", "topic_distr": {"0": 0.0014870644081383944, "1": 0.033912528306245804, "2": 0.32404282689094543, "3": 0.0008877521031536162, "4": 0.06209598854184151, "5": 0.0007002991624176502, "6": 0.15132561326026917, "7": 0.0005782120861113071, "8": 0.20752890408039093, "9": 0.0004923738306388259, "10": 0.0004583516565617174, "11": 0.0004287273623049259, "12": 0.00040269989403896034, "13": 0.21374820172786713, "14": 0.0003590990963857621, "15": 0.00034065739600919187, "16": 0.00032401736825704575, "17": 0.0003089272358920425, "18": 0.0002951801288872957, "19": 0.00028260433464311063}}, {"key": "ren2021learning", "year": "2021", "title": "Learning To Ask Appropriate Questions In Conversational Recommendation", "topic_distr": {"0": 0.0009986747754737735, "1": 0.04465818777680397, "2": 0.03744818642735481, "3": 0.0005966408643871546, "4": 0.3604472875595093, "5": 0.0004706585896201432, "6": 0.258334755897522, "7": 0.00038860595668666065, "8": 0.10027974843978882, "9": 0.0003309156163595617, "10": 0.0003080499009229243, "11": 0.08061758428812027, "12": 0.00027064737514592707, "13": 0.00025515712331980467, "14": 0.0002413440524833277, "15": 0.00022894972062204033, "16": 0.11352863162755966, "17": 0.00020762445637956262, "18": 0.00019838525622617453, "19": 0.00018993330013472587}}, {"key": "ren2023representation", "year": "2023", "title": "Representation Learning With Large Language Models For Recommendation", "topic_distr": {"0": 0.05689051002264023, "1": 0.07272712886333466, "2": 0.0006106420769356191, "3": 0.0005288845277391374, "4": 0.2981709837913513, "5": 0.00041720664012245834, "6": 0.0003773669304791838, "7": 0.00034447264624759555, "8": 0.000316853285767138, "9": 0.10430426895618439, "10": 0.00027306523406878114, "11": 0.0002554164093453437, "12": 0.0002399104123469442, "13": 0.04077405110001564, "14": 0.00021393502538558096, "15": 0.00020294830028433353, "16": 0.2097318321466446, "17": 0.030943777412176132, "18": 0.18250837922096252, "19": 0.00016836289432831109}}, {"key": "ren2023robots", "year": "2023", "title": "Robots That Ask For Help: Uncertainty Alignment For Large Language Model Planners", "topic_distr": {"0": 0.2213728129863739, "1": 0.0011445872951298952, "2": 0.09523294121026993, "3": 0.40311840176582336, "4": 0.0007390033570118248, "5": 0.0006609828560613096, "6": 0.0005978645640425384, "7": 0.0005457500228658319, "8": 0.0005019924719817936, "9": 0.00046473092515952885, "10": 0.0004326188063714653, "11": 0.12479306757450104, "12": 0.00038009145646356046, "13": 0.056385889649391174, "14": 0.0003389384946785867, "15": 0.0003215321630705148, "16": 0.00030582633917219937, "17": 0.05639148876070976, "18": 0.036004725843667984, "19": 0.00026673832326196134}}, {"key": "ren2023time", "year": "2023", "title": "Timechat: A Time-sensitive Multimodal Large Language Model For Long Video Understanding", "topic_distr": {"0": 0.001663143397308886, "1": 0.0013582358369603753, "2": 0.0011479518143460155, "3": 0.0009942619362846017, "4": 0.04767840728163719, "5": 0.0007843155763112009, "6": 0.0007094200700521469, "7": 0.0006475814152508974, "8": 0.000595659192185849, "9": 0.0005514450022019446, "10": 0.10516685992479324, "11": 0.0004801627073902637, "12": 0.00045101268915459514, "13": 0.00042519939597696066, "14": 0.00040218100184574723, "15": 0.00038152679917402565, "16": 0.0003628904523793608, "17": 0.00034598991624079645, "18": 0.8355372548103333, "19": 0.00031650898745283484}}, {"key": "renze2024effect", "year": "2024", "title": "The Effect Of Sampling Temperature On Problem Solving In Large Language Models", "topic_distr": {"0": 0.07623499631881714, "1": 0.06560244411230087, "2": 0.0013886925298720598, "3": 0.7484605312347412, "4": 0.0010608062148094177, "5": 0.0009488132200203836, "6": 0.0008582096197642386, "7": 0.000783401308581233, "8": 0.0007205891888588667, "9": 0.000667101819999516, "10": 0.0006210061837919056, "11": 0.000580869207624346, "12": 0.0989697277545929, "13": 0.0005143781891092658, "14": 0.0004865320515818894, "15": 0.00046154597657732666, "16": 0.00043900092714466155, "17": 0.0004185557772871107, "18": 0.0003999302280135453, "19": 0.00038289171061478555}}, {"key": "reynolds2021prompt", "year": "2021", "title": "Prompt Programming For Large Language Models: Beyond The Few-shot Paradigm", "topic_distr": {"0": 0.18301430344581604, "1": 0.0012272067833691835, "2": 0.0010374068515375257, "3": 0.2379920929670334, "4": 0.0007924470701254904, "5": 0.015490524470806122, "6": 0.06425045430660248, "7": 0.03752830624580383, "8": 0.0005382964736782014, "9": 0.19170084595680237, "10": 0.0004639057151507586, "11": 0.0004339224542491138, "12": 0.0004075795877724886, "13": 0.00038425216916948557, "14": 0.00036345046828500926, "15": 0.00034478530869819224, "16": 0.0003279436205048114, "17": 0.2631174921989441, "18": 0.00029875696054659784, "19": 0.0002860287786461413}}, {"key": "reza2023rapid", "year": "2023", "title": "Abscribe: Rapid Exploration & Organization Of Multiple Writing Variations In Human-ai Co-writing Tasks Using Large Language Models", "topic_distr": {"0": 0.0015391743509098887, "1": 0.0012573275016620755, "2": 0.0010629835305735469, "3": 0.3968367576599121, "4": 0.0008120128768496215, "5": 0.0007262849831022322, "6": 0.0006569307879544795, "7": 0.0005996675463393331, "8": 0.0005515869706869125, "9": 0.35656577348709106, "10": 0.0004753594985231757, "11": 0.0004446359525900334, "12": 0.0004176427028141916, "13": 0.0580768957734108, "14": 0.0003724240232259035, "15": 0.12795411050319672, "16": 0.028630083426833153, "17": 0.00032039047800935805, "18": 0.02240685001015663, "19": 0.00029309079400263727}}, {"key": "ribeiro2020investigating", "year": "2020", "title": "Investigating Pretrained Language Models For Graph-to-text Generation", "topic_distr": {"0": 0.06627512723207474, "1": 0.0012576163280755281, "2": 0.22841598093509674, "3": 0.0009205852984450758, "4": 0.0008119174744933844, "5": 0.0007262005819939077, "6": 0.0006568545359186828, "7": 0.1401158720254898, "8": 0.0005515229422599077, "9": 0.0438443087041378, "10": 0.0004753043467644602, "11": 0.0004445843514986336, "12": 0.0004175942449364811, "13": 0.0003936936263926327, "14": 0.029188718646764755, "15": 0.000353257026290521, "16": 0.1408504992723465, "17": 0.190181165933609, "18": 0.00030609770328737795, "19": 0.15381307899951935}}, {"key": "ribeiro2021structural", "year": "2021", "title": "Structural Adapters In Pretrained Language Models For Amr-to-text Generation", "topic_distr": {"0": 0.0016846373910084367, "1": 0.0013764756731688976, "2": 0.0011633915128186345, "3": 0.001007637707516551, "4": 0.0008886977448128164, "5": 0.0007948733400553465, "6": 0.0007189694442786276, "7": 0.0006562984199263155, "8": 0.0006036772392690182, "9": 0.0005588679341599345, "10": 0.24347467720508575, "11": 0.00048662611516192555, "12": 0.0004570836899802089, "13": 0.12396935373544693, "14": 0.00040759469266049564, "15": 0.1392543464899063, "16": 0.3629474639892578, "17": 0.0003506472276058048, "18": 0.00033504358725622296, "19": 0.11886369436979294}}, {"key": "richardson2019probing", "year": "2019", "title": "Probing Natural Language Inference Models Through Semantic Fragments", "topic_distr": {"0": 0.17802928388118744, "1": 0.0010721595026552677, "2": 0.08540689200162888, "3": 0.38497257232666016, "4": 0.0006923067849129438, "5": 0.0006192172295413911, "6": 0.0005600872100330889, "7": 0.000511265592649579, "8": 0.00047027296386659145, "9": 0.00043536588782444596, "10": 0.12835285067558289, "11": 0.04759532958269119, "12": 0.00035607453901320696, "13": 0.0003356949600856751, "14": 0.000317521917168051, "15": 0.0003012154484167695, "16": 0.09082698076963425, "17": 0.00027315906481817365, "18": 0.00026100361719727516, "19": 0.07861071079969406}}, {"key": "roberts2020how", "year": "2020", "title": "How Much Knowledge Can You Pack Into The Parameters Of A Language Model?", "topic_distr": {"0": 0.002449861727654934, "1": 0.00199724268168211, "2": 0.23590992391109467, "3": 0.0014621509471908212, "4": 0.0012895597610622644, "5": 0.001153415534645319, "6": 0.1715553253889084, "7": 0.051607728004455566, "8": 0.24297469854354858, "9": 0.0008109557093121111, "10": 0.0007549200090579689, "11": 0.0007061278447508812, "12": 0.037417467683553696, "13": 0.09076453745365143, "14": 0.0005914478679187596, "15": 0.0005610737716779113, "16": 0.1565331220626831, "17": 0.0005088131874799728, "18": 0.0004861712222918868, "19": 0.00046545849181711674}}, {"key": "roberts2022scaling", "year": "2022", "title": "Scaling Up Models And Data With \\(\\texttt{t5x}\\) And \\(\\texttt{seqio}\\)", "topic_distr": {"0": 0.0017569088377058506, "1": 0.11438541859388351, "2": 0.1571599543094635, "3": 0.0010503369849175215, "4": 0.0009263491374440491, "5": 0.0008285505464300513, "6": 0.0007494306191802025, "7": 0.0006841043941676617, "8": 0.0006292537436820567, "9": 0.13260608911514282, "10": 0.07904210686683655, "11": 0.0005072433850727975, "12": 0.2127271294593811, "13": 0.2946867048740387, "14": 0.00042486359598115087, "15": 0.000403044541599229, "16": 0.0003833570808637887, "17": 0.00036550339427776635, "18": 0.0003492386604193598, "19": 0.00033435976365581155}}, {"key": "robey2023defending", "year": "2023", "title": "Smoothllm: Defending Large Language Models Against Jailbreaking Attacks", "topic_distr": {"0": 0.00191995850764215, "1": 0.3334147334098816, "2": 0.0013246494345366955, "3": 0.6539077758789062, "4": 0.0010118605569005013, "5": 0.000905033724848181, "6": 0.0008186104823835194, "7": 0.0007472539437003434, "8": 0.0006873400998301804, "9": 0.0006363206775858998, "10": 0.0005923520075157285, "11": 0.0005540669662877917, "12": 0.0005204303306527436, "13": 0.0004906439571641386, "14": 0.000464082695543766, "15": 0.0004402495105750859, "16": 0.0004187447193544358, "17": 0.00039924297016113997, "18": 0.00038147682789713144, "19": 0.00036522449227049947}}, {"key": "robinson2022leveraging", "year": "2022", "title": "Leveraging Large Language Models For Multiple Choice Question Answering", "topic_distr": {"0": 0.0011775168823078275, "1": 0.000960938457865268, "2": 0.21463528275489807, "3": 0.4630289077758789, "4": 0.0006204601959325373, "5": 0.0005549557390622795, "6": 0.0005019621457904577, "7": 0.0004582071560434997, "8": 0.20672599971294403, "9": 0.00039018422830849886, "10": 0.0003632231382653117, "11": 0.00033974723191931844, "12": 0.00031912163831293583, "13": 0.024693621322512627, "14": 0.0002845699491444975, "15": 0.0002699557226151228, "16": 0.00025676924269646406, "17": 0.0002448110026307404, "18": 0.00023391701688524336, "19": 0.08393987268209457}}, {"key": "robinson2023chatgpt", "year": "2023", "title": "Chatgpt MT: Competitive For High- (but Not Low-) Resource Languages", "topic_distr": {"0": 0.20024289190769196, "1": 0.0012732159812003374, "2": 0.2666398286819458, "3": 0.33455196022987366, "4": 0.0008220841991715133, "5": 0.0007352934335358441, "6": 0.0006650791619904339, "7": 0.0006071056704968214, "8": 0.0005584286991506815, "9": 0.0776280090212822, "10": 0.00048125573084689677, "11": 0.000450151099357754, "12": 0.0004228230391163379, "13": 0.018989864736795425, "14": 0.09430309385061264, "15": 0.0003576802264433354, "16": 0.0003402087022550404, "17": 0.0003243644896429032, "18": 0.00030993041582405567, "19": 0.0002967262116726488}}, {"key": "roest2023next", "year": "2023", "title": "Next-step Hint Generation For Introductory Programming Using Large Language Models", "topic_distr": {"0": 0.0015812566271051764, "1": 0.0012892144732177258, "2": 0.0010898351902142167, "3": 0.41443127393722534, "4": 0.000832515477668494, "5": 0.0007446226081810892, "6": 0.1270536184310913, "7": 0.0006148082902655005, "8": 0.04729591682553291, "9": 0.40126046538352966, "10": 0.00048736168537288904, "11": 0.00045586240594275296, "12": 0.00042818760266527534, "13": 0.00040368069312535226, "14": 0.0003818272380158305, "15": 0.00036221829941496253, "16": 0.0003445250913500786, "17": 0.0003284798876848072, "18": 0.0003138626925647259, "19": 0.0003004909376613796}}, {"key": "rohde2021hierarchical", "year": "2021", "title": "Hierarchical Learning For Generation With Long Source Sequences", "topic_distr": {"0": 0.0018904381431639194, "1": 0.0015428614569827914, "2": 0.2324153184890747, "3": 0.0011297621531412005, "4": 0.0009964057244360447, "5": 0.000891211733687669, "6": 0.14111636579036713, "7": 0.000735841749701649, "8": 0.0006768429302610457, "9": 0.0006266026757657528, "10": 0.43432703614234924, "11": 0.0005456051439978182, "12": 0.0005124821909703314, "13": 0.00048315076855942607, "14": 0.18013577163219452, "15": 0.00043352594366297126, "16": 0.0004123495891690254, "17": 0.00039314565947279334, "18": 0.00037565085222013295, "19": 0.000359646714059636}}, {"key": "roller2020open", "year": "2020", "title": "Open-domain Conversational Agents: Current Progress, Open Problems, And Future Directions", "topic_distr": {"0": 0.29464372992515564, "1": 0.00195876881480217, "2": 0.0016558700008317828, "3": 0.001434225938282907, "4": 0.06464086472988129, "5": 0.001131383702158928, "6": 0.15171073377132416, "7": 0.0009341432014480233, "8": 0.0008592447848059237, "9": 0.0007954653701744974, "10": 0.0007405000505968928, "11": 0.20046669244766235, "12": 0.24682557582855225, "13": 0.0006133547285571694, "14": 0.0005801504012197256, "15": 0.0005503565189428627, "16": 0.029026411473751068, "17": 0.0004990941961295903, "18": 0.0004768847138620913, "19": 0.00045656762085855007}}, {"key": "roller2020recipes", "year": "2020", "title": "Recipes For Building An Open-domain Chatbot", "topic_distr": {"0": 0.20107845962047577, "1": 0.001340407063253224, "2": 0.22991536557674408, "3": 0.0009811418130993843, "4": 0.0008653238182887435, "5": 0.0007739686407148838, "6": 0.24359408020973206, "7": 0.0006390381022356451, "8": 0.0005878008669242263, "9": 0.1410222351551056, "10": 0.0005065687582828104, "11": 0.00047382808406837285, "12": 0.00044506261474452913, "13": 0.1756652295589447, "14": 0.0003968751698266715, "15": 0.0003764934663195163, "16": 0.00035810295958071947, "17": 0.00034142538788728416, "18": 0.00032623211154714227, "19": 0.00031233340268954635}}, {"key": "ross2020explaining", "year": "2020", "title": "Explaining NLP Models Via Minimal Contrastive Editing (mice)", "topic_distr": {"0": 0.3434525728225708, "1": 0.001212446135468781, "2": 0.0010249379556626081, "3": 0.0008877305663190782, "4": 0.0007829423993825912, "5": 0.17063355445861816, "6": 0.0006334130303002894, "7": 0.2621345520019531, "8": 0.0005318405455909669, "9": 0.0004923634114675224, "10": 0.00045834193588234484, "11": 0.0004287182819098234, "12": 0.1034931018948555, "13": 0.00037964372313581407, "14": 0.0003590915002860129, "15": 0.0003406501782592386, "16": 0.00032401049975305796, "17": 0.11185236275196075, "18": 0.0002951738715637475, "19": 0.00028259833925403655}}, {"key": "rosset2020knowledge", "year": "2020", "title": "Knowledge-aware Language Model Pretraining", "topic_distr": {"0": 0.06972420960664749, "1": 0.0013230834156274796, "2": 0.18813608586788177, "3": 0.08122025430202484, "4": 0.0008542026625946164, "5": 0.0007640214753337204, "6": 0.0006910639349371195, "7": 0.0006308253505267203, "8": 0.0005802465602755547, "9": 0.026094725355505943, "10": 0.19741936028003693, "11": 0.0004677385732065886, "12": 0.00043934278073720634, "13": 0.0004141974204685539, "14": 0.00039177460712380707, "15": 0.0003716548380907625, "16": 0.25954967737197876, "17": 0.00033703746157698333, "18": 0.00032203944283537567, "19": 0.17026843130588531}}, {"key": "roth2023waffling", "year": "2023", "title": "Waffling Around For Performance: Visual Classification With Random Words And Broad Concepts", "topic_distr": {"0": 0.0015608579851686954, "1": 0.001273046713322401, "2": 0.2780654728412628, "3": 0.2508547306060791, "4": 0.0008220936870202422, "5": 0.0007353016408160329, "6": 0.0006650865543633699, "7": 0.0006071123643778265, "8": 0.0005584348691627383, "9": 0.0005169837386347353, "10": 0.00048126105684787035, "11": 0.0004501560761127621, "12": 0.00042282769572921097, "13": 0.00039862756966613233, "14": 0.0003770476614590734, "15": 0.00035768418456427753, "16": 0.06597581505775452, "17": 0.21683022379875183, "18": 0.17875055968761444, "19": 0.0002967295004054904}}, {"key": "rothe2017question", "year": "2017", "title": "Question Asking As Program Generation", "topic_distr": {"0": 0.20683276653289795, "1": 0.0014343601651489735, "2": 0.09538494795560837, "3": 0.13589148223400116, "4": 0.000926291337236762, "5": 0.0008284993236884475, "6": 0.0007493845769204199, "7": 0.09938056766986847, "8": 0.18851004540920258, "9": 0.0005825101397931576, "10": 0.0005422596586868167, "11": 0.26575103402137756, "12": 0.0004764200421050191, "13": 0.00044915260514244437, "14": 0.0004248374898452312, "15": 0.00040301974513567984, "16": 0.00038333350676111877, "17": 0.00036548092612065375, "18": 0.00034921718179248273, "19": 0.0003343392163515091}}, {"key": "rothe2019leveraging", "year": "2019", "title": "Leveraging Pre-trained Checkpoints For Sequence Generation Tasks", "topic_distr": {"0": 0.0020109352190047503, "1": 0.07098639011383057, "2": 0.001388665521517396, "3": 0.0012027573538944125, "4": 0.0010607769945636392, "5": 0.0009487866773270071, "6": 0.0008581855800002813, "7": 0.0007833793642930686, "8": 0.0007205690490081906, "9": 0.0452643483877182, "10": 0.4847038686275482, "11": 0.0005808529094792902, "12": 0.0005455901264213026, "13": 0.06815266609191895, "14": 0.1333390474319458, "15": 0.1858128309249878, "16": 0.00043898861622437835, "17": 0.0004185440484434366, "18": 0.0003999190521426499, "19": 0.000382880971301347}}, {"key": "rothe2021simple", "year": "2021", "title": "A Simple Recipe For Multilingual Grammatical Error Correction", "topic_distr": {"0": 0.0017326370580121875, "1": 0.03238597884774208, "2": 0.40693020820617676, "3": 0.26233094930648804, "4": 0.000913521449547261, "5": 0.0008170778746716678, "6": 0.0007390537648461759, "7": 0.0414455272257328, "8": 0.0006205409299582243, "9": 0.0005744798691011965, "10": 0.0005347842816263437, "11": 0.0005002199322916567, "12": 0.00046985226799733937, "13": 0.038518618792295456, "14": 0.1845444291830063, "15": 0.00039746385300531983, "16": 0.0003780490078497678, "17": 0.0003604425291996449, "18": 0.02547641098499298, "19": 0.00032973013003356755}}, {"key": "rotstein2023leveraging", "year": "2023", "title": "Fusecap: Leveraging Large Language Models For Enriched Fused Image Captions", "topic_distr": {"0": 0.0659392848610878, "1": 0.02801242098212242, "2": 0.0008046854054555297, "3": 0.0006969529204070568, "4": 0.0006146811065264046, "5": 0.0005497865495271981, "6": 0.0004972866154275835, "7": 0.07403462380170822, "8": 0.00041754290577955544, "9": 0.14787150919437408, "10": 0.0003598399052862078, "11": 0.0003365826269146055, "12": 0.06652946025133133, "13": 0.0002980546560138464, "14": 0.0002819193177856505, "15": 0.0002674412098713219, "16": 0.00025437757722102106, "17": 0.0002425307029625401, "18": 0.6117691397666931, "19": 0.0002218652662122622}}, {"key": "roy2023generating", "year": "2023", "title": "Generating Phishing Attacks Using Chatgpt", "topic_distr": {"0": 0.0020809657871723175, "1": 0.19880123436450958, "2": 0.00143491814378649, "3": 0.07442747801542282, "4": 0.0010961166117340326, "5": 0.0009803954744711518, "6": 0.17611034214496613, "7": 0.0008094775257632136, "8": 0.0007445746450684965, "9": 0.3399208188056946, "10": 0.0006416769465431571, "11": 0.08297646045684814, "12": 0.0005637663416564465, "13": 0.0005314997397363186, "14": 0.0005027267034165561, "15": 0.00047690895735286176, "16": 0.0004536134656518698, "17": 0.11663815379142761, "18": 0.0004132422909606248, "19": 0.00039563659811392426}}, {"key": "rozi\u00e8re2023code", "year": "2023", "title": "Code Llama: Open Foundation Models For Code", "topic_distr": {"0": 0.0013412213884294033, "1": 0.001095071085728705, "2": 0.0009256855701096356, "3": 0.0008017691434361041, "4": 0.0007071243016980588, "5": 0.0006324697169475257, "6": 0.27064672112464905, "7": 0.0005222077015787363, "8": 0.00048033776693046093, "9": 0.0004446835955604911, "10": 0.2171393185853958, "11": 0.00038720175507478416, "12": 0.5028078556060791, "13": 0.00034287950256839395, "14": 0.0003243175451643765, "15": 0.00030766206327825785, "16": 0.0002926337474491447, "17": 0.00027900520944967866, "18": 0.00026658960268832743, "19": 0.000255231891060248}}, {"key": "ruan2020fine", "year": "2020", "title": "Fine-tuning BERT For Schema-guided Zero-shot Dialogue State Tracking", "topic_distr": {"0": 0.0011893559712916613, "1": 0.000969984452240169, "2": 0.0008199808653444052, "3": 0.07957565039396286, "4": 0.10975582897663116, "5": 0.2480221539735794, "6": 0.23107492923736572, "7": 0.0004625760193448514, "8": 0.0004254872619640082, "9": 0.06788462400436401, "10": 0.12291409820318222, "11": 0.0003429866046644747, "12": 0.0003221643273718655, "13": 0.0003037255664821714, "14": 0.0002872832119464874, "15": 0.0002725296653807163, "16": 0.0002592174569144845, "17": 0.1346551924943924, "18": 0.00023614733072463423, "19": 0.00022608657309319824}}, {"key": "rubenstein2023large", "year": "2023", "title": "Audiopalm: A Large Language Model That Can Speak And Listen", "topic_distr": {"0": 0.001559281605295837, "1": 0.2794555425643921, "2": 0.001076164306141436, "3": 0.0009321041288785636, "4": 0.000822074303869158, "5": 0.0007352847023867071, "6": 0.1253855675458908, "7": 0.0006070983945392072, "8": 0.0005584220634773374, "9": 0.000516971864271909, "10": 0.0004812499973922968, "11": 0.00045014574425294995, "12": 0.0004228179750498384, "13": 0.0975179597735405, "14": 0.060150064527988434, "15": 0.00035767597728408873, "16": 0.053589824587106705, "17": 0.09734027832746506, "18": 0.2551807165145874, "19": 0.022860759869217873}}, {"key": "rubin2021learning", "year": "2021", "title": "Learning To Retrieve Prompts For In-context Learning", "topic_distr": {"0": 0.0014506197767332196, "1": 0.258454293012619, "2": 0.14388206601142883, "3": 0.0008670481038279831, "4": 0.0007647002348676324, "5": 0.0006839675479568541, "6": 0.02119549736380577, "7": 0.09705686569213867, "8": 0.06339903175830841, "9": 0.00048089123447425663, "10": 0.00044766245991922915, "11": 0.0004187290323898196, "12": 0.0003933085536118597, "13": 0.0003707979340106249, "14": 0.0003507245855871588, "15": 0.00033271295251324773, "16": 0.0003164609952364117, "17": 0.31404203176498413, "18": 0.0002882962580770254, "19": 0.09480424225330353}}, {"key": "ruder2021xtreme", "year": "2021", "title": "XTREME-R: Towards More Challenging And Nuanced Multilingual Evaluation", "topic_distr": {"0": 0.022231362760066986, "1": 0.0014551253989338875, "2": 0.21799229085445404, "3": 0.062799371778965, "4": 0.0009396193199791014, "5": 0.0008404191466979682, "6": 0.0007601662073284388, "7": 0.0006939041195437312, "8": 0.022478973492980003, "9": 0.0005908908788114786, "10": 0.0005500612896867096, "11": 0.04792330786585808, "12": 0.4518548548221588, "13": 0.00045561467413790524, "14": 0.16657225787639618, "15": 0.0004088181012775749, "16": 0.00038884865352883935, "17": 0.0003707392024807632, "18": 0.00035424146335572004, "19": 0.00033914943924173713}}, {"key": "ruis2022goldilocks", "year": "2022", "title": "The Goldilocks Of Pragmatic Understanding: Fine-tuning Strategy Matters For Implicature Resolution By Llms", "topic_distr": {"0": 0.34236106276512146, "1": 0.0011844390537589788, "2": 0.001001176773570478, "3": 0.3541658818721771, "4": 0.0007647710735909641, "5": 0.02751125395298004, "6": 0.09121526777744293, "7": 0.00056478037731722, "8": 0.0005194969708099961, "9": 0.04056590050458908, "10": 0.000447704253019765, "11": 0.03522632643580437, "12": 0.08433827012777328, "13": 0.00037083253846503794, "14": 0.0003507573273964226, "15": 0.00033274400630034506, "16": 0.018213247880339622, "17": 0.00030175092979334295, "18": 0.00028832315001636744, "19": 0.00027603950002230704}}, {"key": "rust2020how", "year": "2020", "title": "How Good Is Your Tokenizer? On The Monolingual Performance Of Multilingual Language Models", "topic_distr": {"0": 0.09186568856239319, "1": 0.001119509106501937, "2": 0.0009462364250794053, "3": 0.16051149368286133, "4": 0.0007228044560179114, "5": 0.0006464957259595394, "6": 0.0005847607972100377, "7": 0.02635294571518898, "8": 0.0004909900017082691, "9": 0.0004545451665762812, "10": 0.05228162184357643, "11": 0.00039578857831656933, "12": 0.060498036444187164, "13": 0.00035048340214416385, "14": 0.3403247594833374, "15": 0.0003144849615637213, "16": 0.0002991233777720481, "17": 0.0002851925964932889, "18": 0.02836991287767887, "19": 0.23318517208099365}}, {"key": "r\u00f6nnqvist2019is", "year": "2019", "title": "Is Multilingual BERT Fluent In Language Generation?", "topic_distr": {"0": 0.15832257270812988, "1": 0.0015670263674110174, "2": 0.001324645709246397, "3": 0.20132982730865479, "4": 0.0010118656791746616, "5": 0.0009050397202372551, "6": 0.000818616128526628, "7": 0.16501681506633759, "8": 0.0006873448728583753, "9": 0.0006363251013681293, "10": 0.18477417528629303, "11": 0.000554070807993412, "12": 0.0005204339395277202, "13": 0.0004906473914161325, "14": 0.21578052639961243, "15": 0.00044025256647728384, "16": 0.0004187476297374815, "17": 0.00039924573502503335, "18": 0.000381479476345703, "19": 0.06462036818265915}}, {"key": "r\u00fcckl\u00e92020efficiency", "year": "2020", "title": "Adapterdrop: On The Efficiency Of Adapters In Transformers", "topic_distr": {"0": 0.002268166746944189, "1": 0.0018519206205382943, "2": 0.1435176432132721, "3": 0.0733184888958931, "4": 0.0011960134143009782, "5": 0.0010697462130337954, "6": 0.0009675946785137057, "7": 0.0008832514868117869, "8": 0.0008124335436150432, "9": 0.0007521287770941854, "10": 0.16705439984798431, "11": 0.0006549051613546908, "12": 0.03448234871029854, "13": 0.5507734417915344, "14": 0.0005485441070050001, "15": 0.0005203733453527093, "16": 0.000494954758323729, "17": 0.01795106939971447, "18": 0.00045090424828231335, "19": 0.0004316940321587026}}, {"key": "saab2024capabilities", "year": "2024", "title": "Capabilities Of Gemini Models In Medicine", "topic_distr": {"0": 0.0008855622727423906, "1": 0.03592270240187645, "2": 0.000610650866292417, "3": 0.2008805125951767, "4": 0.00046646114788018167, "5": 0.008894022554159164, "6": 0.00037737464299425483, "7": 0.010548795573413372, "8": 0.05389224365353584, "9": 0.141681969165802, "10": 0.0002730707929003984, "11": 0.04695404693484306, "12": 0.2711990773677826, "13": 0.00022618399816565216, "14": 0.0002139394055120647, "15": 0.0002029524475801736, "16": 0.00019303886801935732, "17": 0.00018404866568744183, "18": 0.22622492909431458, "19": 0.0001683663431322202}}, {"key": "sachan2021end", "year": "2021", "title": "End-to-end Training Of Multi-document Reader And Retriever For Open-domain Question Answering", "topic_distr": {"0": 0.0011759100016206503, "1": 0.0009607286774553359, "2": 0.4869256615638733, "3": 0.0007034518639557064, "4": 0.0006204171804711223, "5": 0.0005549176130443811, "6": 0.03537464141845703, "7": 0.0004581756074912846, "8": 0.41436389088630676, "9": 0.00039015733636915684, "10": 0.0003631981380749494, "11": 0.0003397238324396312, "12": 0.00031909963581711054, "13": 0.05593614652752876, "14": 0.0002845503331627697, "15": 0.00026993712526746094, "16": 0.00025675154756754637, "17": 0.0002447941224090755, "18": 0.00023390090791508555, "19": 0.0002239358436781913}}, {"key": "sachan2022improving", "year": "2022", "title": "Improving Passage Retrieval With Zero-shot Question Generation", "topic_distr": {"0": 0.0015204075025394559, "1": 0.0012420492712408304, "2": 0.5697081685066223, "3": 0.000909357622731477, "4": 0.0008020163513720036, "5": 0.0007173454505391419, "6": 0.0006488444050773978, "7": 0.08156424015760422, "8": 0.31507813930511475, "9": 0.0005043584387749434, "10": 0.0004695081152021885, "11": 0.00043916277354583144, "12": 0.00041250180220231414, "13": 0.0003888926294166595, "14": 0.0003678397333715111, "15": 0.0003489491355139762, "16": 0.0003319040988571942, "17": 0.02395441383123398, "18": 0.00030236493330448866, "19": 0.0002894830540753901}}, {"key": "sadasivan2023can", "year": "2023", "title": "Can Ai-generated Text Be Reliably Detected?", "topic_distr": {"0": 0.18595822155475616, "1": 0.2710092067718506, "2": 0.0006779103423468769, "3": 0.090950146317482, "4": 0.0005178511491976678, "5": 0.0004631797783076763, "6": 0.0004189500177744776, "7": 0.0731607973575592, "8": 0.009717714041471481, "9": 0.1975225806236267, "10": 0.0003031550149898976, "11": 0.0002835614432115108, "12": 0.00026634681853465736, "13": 0.00025110269780270755, "14": 0.00023750911350362003, "15": 0.16746097803115845, "16": 0.00021430596825666726, "17": 0.00020432531891856343, "18": 0.00019523293303791434, "19": 0.00018691527657210827}}, {"key": "saha2018complex", "year": "2018", "title": "Complex Sequential Question Answering: Towards Learning To Converse Over Linked Question Answer Pairs With A Knowledge Graph", "topic_distr": {"0": 0.0009457594132982194, "1": 0.000771676714066416, "2": 0.20614022016525269, "3": 0.1408006101846695, "4": 0.1009376123547554, "5": 0.00044566913857124746, "6": 0.025240594521164894, "7": 0.0003679731162264943, "8": 0.288063645362854, "9": 0.00031334583763964474, "10": 0.00029169415938667953, "11": 0.10285450518131256, "12": 0.03820381686091423, "13": 0.00024160969769582152, "14": 0.00022853001428302377, "15": 0.00021679374913219362, "16": 0.09337164461612701, "17": 0.00019660074030980468, "18": 0.00018785209977068007, "19": 0.00017984888108912855}}, {"key": "saharia2020non", "year": "2020", "title": "Non-autoregressive Machine Translation With Latent Alignments", "topic_distr": {"0": 0.001806391403079033, "1": 0.0014757789904251695, "2": 0.15855228900909424, "3": 0.0010806592181324959, "4": 0.0009530960815027356, "5": 0.0008524744189344347, "6": 0.07495147734880447, "7": 0.1646638959646225, "8": 0.000647422973997891, "9": 0.0005993664963170886, "10": 0.12722039222717285, "11": 0.0005218896549195051, "12": 0.000490206410177052, "13": 0.0004621499392669648, "14": 0.4638340473175049, "15": 0.00041468211566098034, "16": 0.0003944262280128896, "17": 0.0003760570252779871, "18": 0.00035932264290750027, "19": 0.00034401414450258017}}, {"key": "sahoo2024systematic", "year": "2024", "title": "A Systematic Survey Of Prompt Engineering In Large Language Models: Techniques And Applications", "topic_distr": {"0": 0.00100665632635355, "1": 0.0008213460678234696, "2": 0.0006943793268874288, "3": 0.1487201601266861, "4": 0.0005304242367856205, "5": 0.00047442506183870137, "6": 0.00042912145727314055, "7": 0.0003917158755939454, "8": 0.00036030859337188303, "9": 0.11386798322200775, "10": 0.00031051516998559237, "11": 0.00029044586699455976, "12": 0.3577786087989807, "13": 0.00025719907716847956, "14": 0.0002432754699839279, "15": 0.000230781952268444, "16": 0.09940560162067413, "17": 0.2628602087497711, "18": 0.00019997288472950459, "19": 0.011126859113574028}}, {"key": "sahu2022data", "year": "2022", "title": "Data Augmentation For Intent Classification With Off-the-shelf Large Language Models", "topic_distr": {"0": 0.0014024401316419244, "1": 0.5356436371803284, "2": 0.1486537754535675, "3": 0.0008379545179195702, "4": 0.0007390400860458612, "5": 0.0006610161508433521, "6": 0.1176535114645958, "7": 0.0005457775550894439, "8": 0.000502017792314291, "9": 0.0004647543537430465, "10": 0.0004326406051404774, "11": 0.00040467808139510453, "12": 0.00038011063588783145, "13": 0.03711264207959175, "14": 0.0003389556077308953, "15": 0.0003215483739040792, "16": 0.00030584176420234144, "17": 0.1349644511938095, "18": 0.0002786221157293767, "19": 0.018356535583734512}}, {"key": "sajjad2020effect", "year": "2020", "title": "On The Effect Of Dropping Layers Of Pre-trained Transformer Models", "topic_distr": {"0": 0.001402745838277042, "1": 0.0011448668083176017, "2": 0.4586728513240814, "3": 0.0008379530627280474, "4": 0.0007390399696305394, "5": 0.0006610171403735876, "6": 0.0005978955887258053, "7": 0.0005457783117890358, "8": 0.000502018490806222, "9": 0.0004647550522349775, "10": 0.23156459629535675, "11": 0.016535261645913124, "12": 0.00038011118886061013, "13": 0.267636775970459, "14": 0.016850002110004425, "15": 0.0003215488395653665, "16": 0.0003058422007597983, "17": 0.0002915985241997987, "18": 0.00027862252318300307, "19": 0.0002667521475814283}}, {"key": "sakaguchi2019adversarial", "year": "2019", "title": "Winogrande: An Adversarial Winograd Schema Challenge At Scale", "topic_distr": {"0": 0.17612224817276, "1": 0.12234558165073395, "2": 0.3648093044757843, "3": 0.147052600979805, "4": 0.0005872176261618733, "5": 0.0005252224509604275, "6": 0.0004750678490381688, "7": 0.00043365720193833113, "8": 0.07438360154628754, "9": 0.00036927880137227476, "10": 0.0003437622799538076, "11": 0.00032154415384866297, "12": 0.0807846188545227, "13": 0.0002847375872079283, "14": 0.02999800816178322, "15": 0.0002554919628892094, "16": 0.0002430119930068031, "17": 0.00023169444466475397, "18": 0.00022138415079098195, "19": 0.0002119523414876312}}, {"key": "salaberria2021image", "year": "2021", "title": "Image Captioning For Effective Use Of Language Models In Knowledge-based Visual Question Answering", "topic_distr": {"0": 0.001199426711536944, "1": 0.0009792621713131666, "2": 0.17346444725990295, "3": 0.0007170046446844935, "4": 0.0006323665147647262, "5": 0.0005656044813804328, "6": 0.0005115940002724528, "7": 0.0004669994523283094, "8": 0.15062806010246277, "9": 0.0003976712469011545, "10": 0.00037019283627159894, "11": 0.00034626646083779633, "12": 0.0003252450842410326, "13": 0.12367170304059982, "14": 0.0002900304098147899, "15": 0.00027513576787896454, "16": 0.1581565886735916, "17": 0.00024950853548943996, "18": 0.2466292679309845, "19": 0.1401236206293106}}, {"key": "salazar2019masked", "year": "2019", "title": "Masked Language Model Scoring", "topic_distr": {"0": 0.063050776720047, "1": 0.0014147752663120627, "2": 0.17850662767887115, "3": 0.1690039038658142, "4": 0.0009135064901784062, "5": 0.0008170641376636922, "6": 0.0007390413666144013, "7": 0.0006746207363903522, "8": 0.0006205305107869208, "9": 0.0005744702066294849, "10": 0.21149560809135437, "11": 0.0005002116085961461, "12": 0.00046984440996311605, "13": 0.00044295331463217735, "14": 0.19272300601005554, "15": 0.00039745718822814524, "16": 0.0003780426923185587, "17": 0.0003604364756029099, "18": 0.00034439723822288215, "19": 0.17657268047332764}}, {"key": "salemi2023when", "year": "2023", "title": "Lamp: When Large Language Models Meet Personalization", "topic_distr": {"0": 0.0018623534124344587, "1": 0.10840889066457748, "2": 0.001284899073652923, "3": 0.0011128972982987761, "4": 0.40511104464530945, "5": 0.0008779031923040748, "6": 0.0007940709474496543, "7": 0.0007248534820973873, "8": 0.08721685409545898, "9": 0.0006172456778585911, "10": 0.0005745950038544834, "11": 0.0005374576430767775, "12": 0.21523183584213257, "13": 0.00047593589988537133, "14": 0.0004501708608586341, "15": 0.17320123314857483, "16": 0.00040619197534397244, "17": 0.00038727480568923056, "18": 0.00037004126352258027, "19": 0.000354276126017794}}, {"key": "salemi2024optimization", "year": "2024", "title": "Optimization Methods For Personalizing Large Language Models Through Retrieval Augmentation", "topic_distr": {"0": 0.0015218656044453382, "1": 0.05303896963596344, "2": 0.0010499900672584772, "3": 0.180125892162323, "4": 0.2118825763463974, "5": 0.000717385730240494, "6": 0.0006488814833573997, "7": 0.0005923198768869042, "8": 0.10834294557571411, "9": 0.0005043872515670955, "10": 0.0004695349489338696, "11": 0.00043918786104768515, "12": 0.00041252534720115364, "13": 0.18646928668022156, "14": 0.00036786074633710086, "15": 0.1774546504020691, "16": 0.0003319230454508215, "17": 0.07503790408372879, "18": 0.00030238222097977996, "19": 0.0002894995850510895}}, {"key": "salewski2023impersonation", "year": "2023", "title": "In-context Impersonation Reveals Large Language Models' Strengths And Biases", "topic_distr": {"0": 0.3342650830745697, "1": 0.001131582772359252, "2": 0.0009566734079271555, "3": 0.5291664600372314, "4": 0.000730786588974297, "5": 0.0006536347209475935, "6": 0.04313037171959877, "7": 0.03468262776732445, "8": 0.000496411754284054, "9": 0.00045956444228067994, "10": 0.0004278093110769987, "11": 0.0004001590423285961, "12": 0.0003758659295272082, "13": 0.00035435360041446984, "14": 0.00033517045085318387, "15": 0.00031795763061381876, "16": 0.0003024264005944133, "17": 0.0002883418055716902, "18": 0.05126095190644264, "19": 0.00026377293397672474}}, {"key": "sallou2023breaking", "year": "2023", "title": "Breaking The Silence: The Threats Of Using Llms In Software Engineering", "topic_distr": {"0": 0.0017331913113594055, "1": 0.14911708235740662, "2": 0.0011957415845245123, "3": 0.1952877640724182, "4": 0.0009134339634329081, "5": 0.0008169991197064519, "6": 0.12371942400932312, "7": 0.037458378821611404, "8": 0.0006204812088981271, "9": 0.46753475069999695, "10": 0.0005347327678464353, "11": 0.0005001717945560813, "12": 0.00046980706974864006, "13": 0.0004429180989973247, "14": 0.00041894050082191825, "15": 0.0003974256105720997, "16": 0.0003780126280616969, "17": 0.0003604078374337405, "18": 0.00034436985151842237, "19": 0.017755921930074692}}, {"key": "sammani2022nlx", "year": "2022", "title": "NLX-GPT: A Model For Natural Language Explanations In Vision And Vision-language Tasks", "topic_distr": {"0": 0.07212869077920914, "1": 0.019287744536995888, "2": 0.0008358970517292619, "3": 0.194086492061615, "4": 0.0006385261658579111, "5": 0.21867996454238892, "6": 0.0005165780312381685, "7": 0.09061538428068161, "8": 0.03439832106232643, "9": 0.0004015454032924026, "10": 0.000373799295630306, "11": 0.0003496398276183754, "12": 0.06371524184942245, "13": 0.1314023733139038, "14": 0.0002928559260908514, "15": 0.0002778161724563688, "16": 0.0002642457257024944, "17": 0.00025193928740918636, "18": 0.17125242948532104, "19": 0.00023047217109706253}}, {"key": "samsi2023from", "year": "2023", "title": "From Words To Watts: Benchmarking The Energy Costs Of Large Language Model Inference", "topic_distr": {"0": 0.001049005426466465, "1": 0.0008558595436625183, "2": 0.0007234973600134254, "3": 0.24240978062152863, "4": 0.0005526633467525244, "5": 0.0004943167441524565, "6": 0.0004471136489883065, "7": 0.00040813969098962843, "8": 0.0003754155768547207, "9": 0.18055415153503418, "10": 0.0003235344192944467, "11": 0.000302623666357249, "12": 0.11150171607732773, "13": 0.42087268829345703, "14": 0.0002534755039960146, "15": 0.03802142292261124, "16": 0.00022871253895573318, "17": 0.00021806094446219504, "18": 0.00020835733448620886, "19": 0.0001994805206777528}}, {"key": "sandoval2022lost", "year": "2022", "title": "Lost At C: A User Study On The Security Implications Of Large Language Model Code Assistants", "topic_distr": {"0": 0.20482738316059113, "1": 0.19382822513580322, "2": 0.0013044066727161407, "3": 0.21006421744823456, "4": 0.0009964359924197197, "5": 0.0008912374614737928, "6": 0.10988390445709229, "7": 0.0007358629372902215, "8": 0.0006768623716197908, "9": 0.2722354531288147, "10": 0.0005833223112858832, "11": 0.0005456208600662649, "12": 0.0005124969757162035, "13": 0.0004831646801903844, "14": 0.00045700831105932593, "15": 0.0004335384292062372, "16": 0.00041236146353185177, "17": 0.000393156980862841, "18": 0.00037566167884506285, "19": 0.00035965704591944814}}, {"key": "sanh2019distilled", "year": "2019", "title": "Distilbert, A Distilled Version Of BERT: Smaller, Faster, Cheaper And Lighter", "topic_distr": {"0": 0.06663105636835098, "1": 0.0013404731871560216, "2": 0.08811745792627335, "3": 0.0009813738288357854, "4": 0.000865525275003165, "5": 0.0007741486770100892, "6": 0.0007002240163274109, "7": 0.0006391869974322617, "8": 0.0005879378295503557, "9": 0.0005442967521958053, "10": 0.2621293067932129, "11": 0.00047393847489729524, "12": 0.00044516631169244647, "13": 0.4695015251636505, "14": 0.054735224694013596, "15": 0.00037658115616068244, "16": 0.05017632246017456, "17": 0.0003415049286559224, "18": 0.00032630813075229526, "19": 0.0003124061622656882}}, {"key": "sanh2021multitask", "year": "2021", "title": "Multitask Prompted Training Enables Zero-shot Task Generalization", "topic_distr": {"0": 0.001620766008272767, "1": 0.001322808675467968, "2": 0.2422652691602707, "3": 0.12470567226409912, "4": 0.0008541887509636581, "5": 0.0007640072144567966, "6": 0.0006910505471751094, "7": 0.0006308131851255894, "8": 0.0312785878777504, "9": 0.0005371660809032619, "10": 0.0005000488017685711, "11": 0.0004677295219153166, "12": 0.000439334282418713, "13": 0.0893707275390625, "14": 0.0003917670401278883, "15": 0.00037164767854847014, "16": 0.0003534938732627779, "17": 0.31859347224235535, "18": 0.0003220332437194884, "19": 0.1845194399356842}}, {"key": "sankar2019do", "year": "2019", "title": "Do Neural Dialog Systems Use The Conversation History Effectively? An Empirical Study", "topic_distr": {"0": 0.15414825081825256, "1": 0.0012419428676366806, "2": 0.2776392996311188, "3": 0.0009093960397876799, "4": 0.20246320962905884, "5": 0.0007173732155933976, "6": 0.12520715594291687, "7": 0.0005923095159232616, "8": 0.0005448188749141991, "9": 0.10194609314203262, "10": 0.0004695267416536808, "11": 0.03513559699058533, "12": 0.09663902968168259, "13": 0.00038890805444680154, "14": 0.0003678543143905699, "15": 0.0003489629889372736, "16": 0.00033191725378856063, "17": 0.0003164591907989234, "18": 0.00030237692408263683, "19": 0.00028949452098459005}}, {"key": "sanner2023large", "year": "2023", "title": "Large Language Models Are Competitive Near Cold-start Recommenders For Language- And Item-based Preferences", "topic_distr": {"0": 0.13791251182556152, "1": 0.0011073460336774588, "2": 0.0009357971721328795, "3": 0.26017382740974426, "4": 0.4407375752925873, "5": 0.06989308446645737, "6": 0.0005783159285783768, "7": 0.0005279053584672511, "8": 0.0004855786100961268, "9": 0.0004495354078244418, "10": 0.00041847326792776585, "11": 0.0003914264088962227, "12": 0.00036766345147043467, "13": 0.0003466205671429634, "14": 0.00032785607618279755, "15": 0.00031101886997930706, "16": 0.0002958265831694007, "17": 0.0002820493537001312, "18": 0.08419955521821976, "19": 0.0002580166619736701}}, {"key": "santhanam2019survey", "year": "2019", "title": "A Survey Of Natural Language Generation Techniques With A Focus On Dialogue Systems - Past, Present And Future Directions", "topic_distr": {"0": 0.11002150923013687, "1": 0.0007489066920243204, "2": 0.12918853759765625, "3": 0.0005483059212565422, "4": 0.00048358362982980907, "5": 0.08629612624645233, "6": 0.19938340783119202, "7": 0.0003571240231394768, "8": 0.00032849027775228024, "9": 0.13908354938030243, "10": 0.00028309403569437563, "11": 0.0002647970395628363, "12": 0.29442402720451355, "13": 0.00023448621504940093, "14": 0.00022179217194207013, "15": 0.037384431809186935, "16": 0.00020012447203043848, "17": 0.0001908042759168893, "18": 0.00018231358262710273, "19": 0.00017454632325097919}}, {"key": "santhanam2021effective", "year": "2021", "title": "Colbertv2: Effective And Efficient Retrieval Via Lightweight Late Interaction", "topic_distr": {"0": 0.0019182618707418442, "1": 0.001566908322274685, "2": 0.2821662127971649, "3": 0.0011471895268186927, "4": 0.11363766342401505, "5": 0.0009049579966813326, "6": 0.03113260306417942, "7": 0.000747191603295505, "8": 0.12540081143379211, "9": 0.0006362675921991467, "10": 0.26757538318634033, "11": 0.0005540207494050264, "12": 0.0005203868495300412, "13": 0.16962336003780365, "14": 0.0004640439583454281, "15": 0.0004402127815410495, "16": 0.0004187097947578877, "17": 0.000399209646275267, "18": 0.0003814449883066118, "19": 0.0003651939914561808}}, {"key": "santhanam2021rome", "year": "2021", "title": "Rome Was Built In 1776: A Case Study On Factual Correctness In Knowledge-grounded Response Generation", "topic_distr": {"0": 0.23381437361240387, "1": 0.15500439703464508, "2": 0.0008046046132221818, "3": 0.0006968866800889373, "4": 0.0006146261584945023, "5": 0.0005497378879226744, "6": 0.42736002802848816, "7": 0.036678019911050797, "8": 0.00041750591481104493, "9": 0.00038651557406410575, "10": 0.02568693645298481, "11": 0.00033655279548838735, "12": 0.0003161211498081684, "13": 0.0002980282297357917, "14": 0.00028189431759528816, "15": 0.00026741751935333014, "16": 0.11579027771949768, "17": 0.00024250919523183256, "18": 0.00023171765496954322, "19": 0.0002218456065747887}}, {"key": "sap2022neural", "year": "2022", "title": "Neural Theory-of-mind? On The Limits Of Social Intelligence In Large Lms", "topic_distr": {"0": 0.4477027356624603, "1": 0.16370049118995667, "2": 0.15436440706253052, "3": 0.0005607209750451148, "4": 0.0004945318796671927, "5": 0.0004423217906150967, "6": 0.0004000837216153741, "7": 0.0003652092709671706, "8": 0.00033592726686038077, "9": 0.12755434215068817, "10": 0.0002895032521337271, "11": 0.0635928064584732, "12": 0.0002543525770306587, "13": 0.00023979495745152235, "14": 0.00022681352857034653, "15": 0.00021516541892196983, "16": 0.00020465526904445142, "17": 0.00019512407016009092, "18": 0.0001864411315182224, "19": 0.038674499839544296}}, {"key": "saparov2022language", "year": "2022", "title": "Language Models Are Greedy Reasoners: A Systematic Formal Analysis Of Chain-of-thought", "topic_distr": {"0": 0.09570281952619553, "1": 0.05516531690955162, "2": 0.0009783005807548761, "3": 0.8411868214607239, "4": 0.0007473189034499228, "5": 0.0006684215622954071, "6": 0.0006045929621905088, "7": 0.0005518919206224382, "8": 0.000507641932927072, "9": 0.0004699610290117562, "10": 0.0004374875279609114, "11": 0.0004092117305845022, "12": 0.00038436902104876935, "13": 0.00036237004678696394, "14": 0.0003427529300097376, "15": 0.0003251507005188614, "16": 0.00030926812905818224, "17": 0.00029486490529961884, "18": 0.0002817435597535223, "19": 0.0002697402087505907}}, {"key": "sarkar2022what", "year": "2022", "title": "What Is It Like To Program With Artificial Intelligence?", "topic_distr": {"0": 0.1180383637547493, "1": 0.001095341518521309, "2": 0.0009258128120563924, "3": 0.08999065309762955, "4": 0.0007072131265886128, "5": 0.019095079973340034, "6": 0.23954075574874878, "7": 0.0005222737090662122, "8": 0.0004803984484169632, "9": 0.4321608543395996, "10": 0.000414009002270177, "11": 0.0945969671010971, "12": 0.00036374121555127203, "13": 0.000342922838171944, "14": 0.0003243585233576596, "15": 0.00030770094599574804, "16": 0.00029267073841765523, "17": 0.0002790404832921922, "18": 0.00026662330492399633, "19": 0.0002552641381043941}}, {"key": "sarsa2022automatic", "year": "2022", "title": "Automatic Generation Of Programming Exercises And Code Explanations Using Large Language Models", "topic_distr": {"0": 0.14686138927936554, "1": 0.0011073072673752904, "2": 0.0009358628303743899, "3": 0.1496027708053589, "4": 0.0007148986915126443, "5": 0.039233069866895676, "6": 0.1651582270860672, "7": 0.07196662575006485, "8": 0.0004856194427702576, "9": 0.42066553235054016, "10": 0.00041850845445878804, "11": 0.0003914593253284693, "12": 0.0003676943597383797, "13": 0.00034664972918108106, "14": 0.00032788366661407053, "15": 0.00031104503432288766, "16": 0.0002958514669444412, "17": 0.0002820730733219534, "18": 0.0002695209695957601, "19": 0.0002580383443273604}}, {"key": "saunders2020reducing", "year": "2020", "title": "Reducing Gender Bias In Neural Machine Translation As A Domain Adaptation Problem", "topic_distr": {"0": 0.13554474711418152, "1": 0.10695171356201172, "2": 0.2560828626155853, "3": 0.0005523877334780991, "4": 0.12333852052688599, "5": 0.0004357488651294261, "6": 0.00039413856575265527, "7": 0.0003597823088057339, "8": 0.0003309354360681027, "9": 0.0003063709882553667, "10": 0.000285201269434765, "11": 0.0002667680673766881, "12": 0.0002505729498807341, "13": 0.12196443974971771, "14": 0.22480110824108124, "15": 0.0002119680866599083, "16": 0.027370987460017204, "17": 0.00019222455739509314, "18": 0.00018367065058555454, "19": 0.00017584559100214392}}, {"key": "savage2023diagnostic", "year": "2023", "title": "Diagnostic Reasoning Prompts Reveal The Potential For Large Language Model Interpretability In Medicine", "topic_distr": {"0": 0.24683275818824768, "1": 0.0013400925090536475, "2": 0.0011329231783747673, "3": 0.34021660685539246, "4": 0.0008654394187033176, "5": 0.057506710290908813, "6": 0.0007001539343036711, "7": 0.0006391230272129178, "8": 0.0005878789233975112, "9": 0.11160685867071152, "10": 0.0005066360463388264, "11": 0.07649917155504227, "12": 0.0004451217537280172, "13": 0.11808401346206665, "14": 0.0003969278768636286, "15": 0.00037654346670024097, "16": 0.0003581505152396858, "17": 0.041266199201345444, "18": 0.00032627544715069234, "19": 0.0003123748756479472}}, {"key": "savelka2023large", "year": "2023", "title": "Large Language Models (GPT) Struggle To Answer Multiple-choice Questions About Code", "topic_distr": {"0": 0.2942968010902405, "1": 0.0010498439660295844, "2": 0.0008875239291228354, "3": 0.1653793305158615, "4": 0.0006779808318242431, "5": 0.055793873965740204, "6": 0.23837009072303772, "7": 0.0005006861756555736, "8": 0.09474842995405197, "9": 0.11219456046819687, "10": 0.03339780494570732, "11": 0.000371244183043018, "12": 0.0003487064386717975, "13": 0.00032874857424758375, "14": 0.0003109515819232911, "15": 0.0002949825138784945, "16": 0.0002805735566653311, "17": 0.00026750669348984957, "18": 0.0002556027611717582, "19": 0.0002447131264489144}}, {"key": "savelka2023thrilled", "year": "2023", "title": "Thrilled By Your Progress! Large Language Models (GPT-4) No Longer Struggle To Pass Assessments In Higher Education Programming Courses", "topic_distr": {"0": 0.283664733171463, "1": 0.0005658402806147933, "2": 0.0004783456679433584, "3": 0.27962231636047363, "4": 0.0003654048196040094, "5": 0.03582886978983879, "6": 0.17776049673557281, "7": 0.00026984981377609074, "8": 0.0002482136187609285, "9": 0.16616909205913544, "10": 0.00021391132031567395, "11": 0.00020008576393593103, "12": 0.04084384813904762, "13": 0.0001771823299350217, "14": 0.00016759046411607414, "15": 0.00015898377751000226, "16": 0.012851392850279808, "17": 0.00014417539932765067, "18": 0.00013775966363027692, "19": 0.000131890585180372}}, {"key": "scao2021how", "year": "2021", "title": "How Many Data Points Is A Prompt Worth?", "topic_distr": {"0": 0.0023100017569959164, "1": 0.1492554396390915, "2": 0.3393837511539459, "3": 0.0013810481177642941, "4": 0.001218023244291544, "5": 0.001089432742446661, "6": 0.0009854008676484227, "7": 0.0641089677810669, "8": 0.0008273844141513109, "9": 0.0007659698603674769, "10": 0.0007130426238290966, "11": 0.0006669571157544851, "12": 0.0006264670519158244, "13": 0.0005906117730773985, "14": 0.0005586387123912573, "15": 0.0005299495533108711, "16": 0.0005040632095187902, "17": 0.4335860311985016, "18": 0.0004592020413838327, "19": 0.000439638301031664}}, {"key": "schaeffer2023are", "year": "2023", "title": "Are Emergent Abilities Of Large Language Models A Mirage?", "topic_distr": {"0": 0.5457316040992737, "1": 0.0008933520875871181, "2": 0.0679955780506134, "3": 0.18599703907966614, "4": 0.0005769240669906139, "5": 0.08928699046373367, "6": 0.0004667401371989399, "7": 0.00042605542694218457, "8": 0.00039189483504742384, "9": 0.0003628055565059185, "10": 0.0003377363027539104, "11": 0.0003159076441079378, "12": 0.08875302970409393, "13": 0.017056597396731377, "14": 0.00026460207300260663, "15": 0.0002510133199393749, "16": 0.0002387521235505119, "17": 0.0002276329614687711, "18": 0.0002175034023821354, "19": 0.00020823693193960935}}, {"key": "schick2020few", "year": "2020", "title": "Few-shot Text Generation With Pattern-exploiting Training", "topic_distr": {"0": 0.0014342281501740217, "1": 0.001170871313661337, "2": 0.346232533454895, "3": 0.0008571089128963649, "4": 0.0007559331133961678, "5": 0.0006761265103705227, "6": 0.0006115621072240174, "7": 0.1278415471315384, "8": 0.000513493490871042, "9": 0.00047537824138998985, "10": 0.00044253040687181056, "11": 0.09364042431116104, "12": 0.08150302618741989, "13": 0.0003665470576379448, "14": 0.0003467038332019001, "15": 0.08964504301548004, "16": 0.0003128330281469971, "17": 0.16385094821453094, "18": 0.0002849911688826978, "19": 0.08903812617063522}}, {"key": "schick2020not", "year": "2020", "title": "It's Not Just Size That Matters: Small Language Models Are Also Few-shot Learners", "topic_distr": {"0": 0.0019798174034804106, "1": 0.001616814755834639, "2": 0.2091706097126007, "3": 0.13258078694343567, "4": 0.0010439897887408733, "5": 0.0009337720111943781, "6": 0.0008446046849712729, "7": 0.0007709822966717184, "8": 0.020242219790816307, "9": 0.0006565264193341136, "10": 0.0006111615803092718, "11": 0.0005716608138754964, "12": 0.0005369560676626861, "13": 0.4501684010028839, "14": 0.0004788191872648895, "15": 0.0004542292153928429, "16": 0.00043204156099818647, "17": 0.00041192054050043225, "18": 0.0003935902495868504, "19": 0.17610110342502594}}, {"key": "schick2021generating", "year": "2021", "title": "Generating Datasets With Pretrained Language Models", "topic_distr": {"0": 0.0015786520671099424, "1": 0.0012892975937575102, "2": 0.1970595121383667, "3": 0.000943891704082489, "4": 0.0008324725204147398, "5": 0.0007445852388627827, "6": 0.0006734835915267467, "7": 0.0006147774984128773, "8": 0.0005654854467138648, "9": 0.0005235109711065888, "10": 0.0004873372381553054, "11": 0.0004558395594358444, "12": 0.0004281661531422287, "13": 0.05711755156517029, "14": 0.18058724701404572, "15": 0.2823386788368225, "16": 0.06407243758440018, "17": 0.00032846341491676867, "18": 0.0003138469473924488, "19": 0.20904472470283508}}, {"key": "schick2021true", "year": "2021", "title": "True Few-shot Learning With Prompts -- A Real-world Perspective", "topic_distr": {"0": 0.1866961121559143, "1": 0.18256402015686035, "2": 0.13269810378551483, "3": 0.0008984275045804679, "4": 0.0007923729135654867, "5": 0.0007087191333994269, "6": 0.0006410424248315394, "7": 0.0005851641180925071, "8": 0.0005382464150898159, "9": 0.0004982938407920301, "10": 0.00046386258327402174, "11": 0.09334651380777359, "12": 0.0004075417236890644, "13": 0.00038421645876951516, "14": 0.000363416678737849, "15": 0.0003447532362770289, "16": 0.0003279131487943232, "17": 0.3971565365791321, "18": 0.00029872916638851166, "19": 0.00028600217774510384}}, {"key": "schick2023language", "year": "2023", "title": "Toolformer: Language Models Can Teach Themselves To Use Tools", "topic_distr": {"0": 0.0014500182587653399, "1": 0.0011842887615785003, "2": 0.0010011804988607764, "3": 0.5211399793624878, "4": 0.000764773110859096, "5": 0.0006840320420451462, "6": 0.0006187126273289323, "7": 0.0005647807265631855, "8": 0.0005194973782636225, "9": 0.0004809364618267864, "10": 0.00044770457316190004, "11": 0.060510460287332535, "12": 0.0003933455445803702, "13": 0.00037083280039951205, "14": 0.09558089077472687, "15": 0.0003327442391309887, "16": 0.08881936222314835, "17": 0.00030175113352015615, "18": 0.00028832335374318063, "19": 0.22454634308815002}}, {"key": "schmidt2019generalization", "year": "2019", "title": "Generalization In Generation: A Closer Look At Exposure Bias", "topic_distr": {"0": 0.19774624705314636, "1": 0.06692233681678772, "2": 0.17606541514396667, "3": 0.0012225928949192166, "4": 0.025166239589452744, "5": 0.0009644355741329491, "6": 0.09517068415880203, "7": 0.1932530254125595, "8": 0.0007324538892135024, "9": 0.00067808578023687, "10": 0.0006312312325462699, "11": 0.15882480144500732, "12": 0.07946853339672089, "13": 0.000522847578395158, "14": 0.0004945429391227663, "15": 0.0004691454232670367, "16": 0.0004462291835807264, "17": 0.0004254473897162825, "18": 0.00040651517338119447, "19": 0.00038919609505683184}}, {"key": "schmitt2021supporting", "year": "2021", "title": "Characterchat: Supporting The Creation Of Fictional Characters Through Conversation And Progressive Manifestation With A Chatbot", "topic_distr": {"0": 0.0016428554663434625, "1": 0.0013401191681623459, "2": 0.22148005664348602, "3": 0.0009812869830057025, "4": 0.000865452631842345, "5": 0.0007740830187685788, "6": 0.07103971391916275, "7": 0.07133108377456665, "8": 0.0005878879455849528, "9": 0.5496953129768372, "10": 0.0005066437879577279, "11": 0.036874208599328995, "12": 0.00044512853492051363, "13": 0.0004196520312689245, "14": 0.0003969339304603636, "15": 0.0003765492292586714, "16": 0.00035815598675981164, "17": 0.04024617746472359, "18": 0.00032628042390570045, "19": 0.0003123796486761421}}, {"key": "schneider2022towards", "year": "2022", "title": "Towards Trustworthy Autograding Of Short, Multi-lingual, Multi-type Answers", "topic_distr": {"0": 0.15165480971336365, "1": 0.07336553186178207, "2": 0.000789922138210386, "3": 0.3862226903438568, "4": 0.0006034097750671208, "5": 0.0005397052736952901, "6": 0.0004881680360995233, "7": 0.00044561547110788524, "8": 0.09708821773529053, "9": 0.1131226196885109, "10": 0.046837177127599716, "11": 0.0003304108395241201, "12": 0.00031035204301588237, "13": 0.07554280012845993, "14": 0.051462944597005844, "15": 0.00026253724354319274, "16": 0.0002497131354175508, "17": 0.00023808350670151412, "18": 0.00022748889750801027, "19": 0.00021779700182378292}}, {"key": "schneider2023towards", "year": "2023", "title": "Towards Llm-based Autograding For Short Textual Answers", "topic_distr": {"0": 0.22486528754234314, "1": 0.05056340992450714, "2": 0.0011328933760523796, "3": 0.369884192943573, "4": 0.0008654217817820609, "5": 0.0007740549044683576, "6": 0.0007001390913501382, "7": 0.000639109464827925, "8": 0.0005878664669580758, "9": 0.2448938488960266, "10": 0.0005066253361292183, "11": 0.0004738809948321432, "12": 0.10158197581768036, "13": 0.0004196367517579347, "14": 0.00039691946585662663, "15": 0.0003765354922506958, "16": 0.00035814291913993657, "17": 0.0003414635139051825, "18": 0.0003262685495428741, "19": 0.0003123682690784335}}, {"key": "schramowski2021large", "year": "2021", "title": "Large Pre-trained Language Models Contain Human-like Biases Of What Is Right And Wrong To Do", "topic_distr": {"0": 0.18393437564373016, "1": 0.0010955317411571741, "2": 0.1649414449930191, "3": 0.10292994976043701, "4": 0.0007072871667332947, "5": 0.0006326159345917404, "6": 0.0005722062778659165, "7": 0.05072231590747833, "8": 0.000480448710732162, "9": 0.05788389593362808, "10": 0.07427992671728134, "11": 0.02584480680525303, "12": 0.11229948699474335, "13": 0.0003429587231948972, "14": 0.00032439245842397213, "15": 0.0003077331348322332, "16": 0.05672009289264679, "17": 0.0002790696744341403, "18": 0.0002666511863935739, "19": 0.1654348373413086}}, {"key": "schramowski2022can", "year": "2022", "title": "Can Machines Help Us Answering Question 16 In Datasheets, And In Turn Reflecting On Inappropriate Content?", "topic_distr": {"0": 0.3317646086215973, "1": 0.001050089835189283, "2": 0.1540174037218094, "3": 0.0007688520126976073, "4": 0.0006780888652428985, "5": 0.0006065004272386432, "6": 0.08461350947618484, "7": 0.0005007657455280423, "8": 0.1955433487892151, "9": 0.08835771679878235, "10": 0.00039695954183116555, "11": 0.0003713031474035233, "12": 0.00034876185236498713, "13": 0.00032880078651942313, "14": 0.00031100097112357616, "15": 0.00029502937104552984, "16": 0.00028061814373359084, "17": 0.0002675491850823164, "18": 0.13925431668758392, "19": 0.0002447520091664046}}, {"key": "schuhmann2021laion", "year": "2021", "title": "LAION-400M: Open Dataset Of Clip-filtered 400 Million Image-text Pairs", "topic_distr": {"0": 0.0025450517423450947, "1": 0.3315736651420593, "2": 0.0017570924246683717, "3": 0.0015218876069411635, "4": 0.0013422376941889524, "5": 0.0012005320750176907, "6": 0.0010858913883566856, "7": 0.0009912365349009633, "8": 0.0009117604931816459, "9": 0.0008440829697065055, "10": 0.0007857582531869411, "11": 0.0007349729421548545, "12": 0.1302490532398224, "13": 0.0006508419755846262, "14": 0.20195776224136353, "15": 0.027667609974741936, "16": 0.0005554672097787261, "17": 0.1140952780842781, "18": 0.17904531955718994, "19": 0.00048447231529280543}}, {"key": "schuhmann2022laion", "year": "2022", "title": "LAION-5B: An Open Large-scale Dataset For Training Next Generation Image-text Models", "topic_distr": {"0": 0.0012862664880231023, "1": 0.19810467958450317, "2": 0.0008876901702024043, "3": 0.00076885154703632, "4": 0.000678091833833605, "5": 0.0006065033376216888, "6": 0.0005485871224664152, "7": 0.000500767957419157, "8": 0.00046061704051680863, "9": 0.00042642667540349066, "10": 0.0003969613171648234, "11": 0.0003713048354256898, "12": 0.18842922151088715, "13": 0.17767742276191711, "14": 0.09475348889827728, "15": 0.07920122146606445, "16": 0.014617896638810635, "17": 0.0002675503783393651, "18": 0.2397717386484146, "19": 0.0002447530860081315}}, {"key": "schumann2023verbalization", "year": "2023", "title": "VELMA: Verbalization Embodiment Of LLM Agents For Vision And Language Navigation In Street View", "topic_distr": {"0": 0.07250268757343292, "1": 0.0010184310376644135, "2": 0.0008609538781456649, "3": 0.175024151802063, "4": 0.0006576756131835282, "5": 0.0005882423720322549, "6": 0.0005320702330209315, "7": 0.00048569083446636796, "8": 0.00044674877426587045, "9": 0.0571637786924839, "10": 0.00038500959635712206, "11": 0.5022315382957458, "12": 0.0003382628201507032, "13": 0.00031890266109257936, "14": 0.0003016387054231018, "15": 0.0002861479006242007, "16": 0.0002721704950090498, "17": 0.00025949496193788946, "18": 0.18608899414539337, "19": 0.00023738406889606267}}, {"key": "schuster2018cross", "year": "2018", "title": "Cross-lingual Transfer Learning For Multilingual Task Oriented Dialog", "topic_distr": {"0": 0.019543930888175964, "1": 0.17380109429359436, "2": 0.2998003363609314, "3": 0.0006658557103946805, "4": 0.03634224832057953, "5": 0.0005252573755569756, "6": 0.07493161410093307, "7": 0.0004336862766649574, "8": 0.0003989138640463352, "9": 0.029993120580911636, "10": 0.10051365196704865, "11": 0.0003215657197870314, "12": 0.00030204388895072043, "13": 0.0002847566793207079, "14": 0.24321116507053375, "15": 0.00025550907594151795, "16": 0.00024302827659994364, "17": 0.00023170997155830264, "18": 0.00022139899374451488, "19": 0.01797911711037159}}, {"key": "schuster2022confident", "year": "2022", "title": "Confident Adaptive Language Modeling", "topic_distr": {"0": 0.001300741801969707, "1": 0.0010610368335619569, "2": 0.3090859055519104, "3": 0.16743610799312592, "4": 0.000685113191138953, "5": 0.0006127830711193383, "6": 0.0005542674916796386, "7": 0.16977377235889435, "8": 0.00046538651804439723, "9": 0.00043084213393740356, "10": 0.1112913116812706, "11": 0.00037514950963668525, "12": 0.00035237468546256423, "13": 0.234903484582901, "14": 0.0003142226778436452, "15": 0.00029808562248945236, "16": 0.0002835250925272703, "17": 0.0002703207719605416, "18": 0.0002582916058599949, "19": 0.0002472874184604734}}, {"key": "schwartz2019inducing", "year": "2019", "title": "Inducing Brain-relevant Bias In Natural Language Processing Models", "topic_distr": {"0": 0.1887616366147995, "1": 0.0012271790765225887, "2": 0.3233153522014618, "3": 0.0008984507876448333, "4": 0.000792394217569381, "5": 0.0007087384583428502, "6": 0.0006410599453374743, "7": 0.0005851801251992583, "8": 0.000538261141628027, "9": 0.0004983074613846838, "10": 0.355376660823822, "11": 0.00043389396159909666, "12": 0.04926158860325813, "13": 0.0003842269361484796, "14": 0.00036342660314403474, "15": 0.0003447626659180969, "16": 0.04587189853191376, "17": 0.0003126501105725765, "18": 0.029398344457149506, "19": 0.0002860100066754967}}, {"key": "schwenk2022benchmark", "year": "2022", "title": "A-OKVQA: A Benchmark For Visual Question Answering Using World Knowledge", "topic_distr": {"0": 0.0014184815809130669, "1": 0.0011574155651032925, "2": 0.1299561709165573, "3": 0.0008473922498524189, "4": 0.0007473612204194069, "5": 0.0006684599793516099, "6": 0.0006046275375410914, "7": 0.0005519235273823142, "8": 0.20333990454673767, "9": 0.026668740436434746, "10": 0.0004375125572551042, "11": 0.0667140856385231, "12": 0.04801877588033676, "13": 0.00036239076871424913, "14": 0.00034277254599146545, "15": 0.0003251693269703537, "16": 0.1584092527627945, "17": 0.00029488178552128375, "18": 0.358864963054657, "19": 0.00026975563378073275}}, {"key": "sch\u00e4fer2023empirical", "year": "2023", "title": "An Empirical Evaluation Of Using Large Language Models For Automated Unit Test Generation", "topic_distr": {"0": 0.18117572367191315, "1": 0.0007225155713967979, "2": 0.0006106220535002649, "3": 0.6857492327690125, "4": 0.0004664394073188305, "5": 0.0004171953769400716, "6": 0.12777091562747955, "7": 0.00034446336212567985, "8": 0.0003168447292409837, "9": 0.0002933262148872018, "10": 0.0002730578707996756, "11": 0.00025540951173752546, "12": 0.00023990395129658282, "13": 0.00022617327340412885, "14": 0.00021392926282715052, "15": 0.00020294282876420766, "16": 0.00019302971486467868, "17": 0.0001840399345383048, "18": 0.000175850247615017, "19": 0.00016835836868267506}}, {"key": "scialom2022fine", "year": "2022", "title": "Fine-tuned Language Models Are Continual Learners", "topic_distr": {"0": 0.07360350340604782, "1": 0.0012127355439588428, "2": 0.14813180267810822, "3": 0.2891581356525421, "4": 0.0007829659734852612, "5": 0.0007003055070526898, "6": 0.0006334322388283908, "7": 0.0005782173248007894, "8": 0.0005318566109053791, "9": 0.0004923783126287162, "10": 0.0004583558184094727, "11": 0.251403272151947, "12": 0.1217518225312233, "13": 0.000379655190045014, "14": 0.00035910235601477325, "15": 0.0003406604810152203, "16": 0.1085950955748558, "17": 0.0003089300589635968, "18": 0.00029518280643969774, "19": 0.0002826068957801908}}, {"key": "sclar2023quantifying", "year": "2023", "title": "Quantifying Language Models' Sensitivity To Spurious Features In Prompt Design Or: How I Learned To Start Worrying About Prompt Formatting", "topic_distr": {"0": 0.20616872608661652, "1": 0.0008487639133818448, "2": 0.169804185628891, "3": 0.309479683637619, "4": 0.000548071984667331, "5": 0.0004902101354673505, "6": 0.0004433991853147745, "7": 0.0004047490656375885, "8": 0.00037229681038297713, "9": 0.062091290950775146, "10": 0.0003208466514479369, "11": 0.00030010961927473545, "12": 0.00028189035947434604, "13": 0.00026575662195682526, "14": 0.00025136975455097854, "15": 0.0002384605468250811, "16": 0.00022681249538436532, "17": 0.2470589578151703, "18": 0.00020662639872170985, "19": 0.00019782333401963115}}, {"key": "see2016compression", "year": "2016", "title": "Compression Of Neural Machine Translation Models Via Pruning", "topic_distr": {"0": 0.0018350325990468264, "1": 0.001498006284236908, "2": 0.309695839881897, "3": 0.0010966280242428184, "4": 0.0009671793086454272, "5": 0.0008650700328871608, "6": 0.0007824631175026298, "7": 0.0007142575341276824, "8": 0.0006569892866536975, "9": 0.0006082227337174118, "10": 0.0005661955801770091, "11": 0.0005296010640449822, "12": 0.000497449713293463, "13": 0.3177608847618103, "14": 0.3600098192691803, "15": 0.0004208094615023583, "16": 0.0004002542409580201, "17": 0.0003816136159002781, "18": 0.0003646319964900613, "19": 0.000349097274011001}}, {"key": "see2019do", "year": "2019", "title": "Do Massively Pretrained Language Models Make Better Storytellers?", "topic_distr": {"0": 0.2563157081604004, "1": 0.12111196666955948, "2": 0.0012299559311941266, "3": 0.15633240342140198, "4": 0.0009395439410582185, "5": 0.0008403529645875096, "6": 0.0007601064280606806, "7": 0.27905622124671936, "8": 0.0006382176070474088, "9": 0.0005908444290980697, "10": 0.0005500180996023118, "11": 0.0005144691676832736, "12": 0.0004832364502362907, "13": 0.00045557887642644346, "14": 0.00043091585393995047, "15": 0.00040878597064875066, "16": 0.0003888180945068598, "17": 0.00037071004044264555, "18": 0.0003542136400938034, "19": 0.178227961063385}}, {"key": "see2019what", "year": "2019", "title": "What Makes A Good Conversation? How Controllable Attributes Affect Human Judgments", "topic_distr": {"0": 0.4137919247150421, "1": 0.0013950505526736379, "2": 0.0011793144512921572, "3": 0.0010214372305199504, "4": 0.0009008697816170752, "5": 0.0008057618979364634, "6": 0.1856735497713089, "7": 0.261734277009964, "8": 0.04328208416700363, "9": 0.0005665234057232738, "10": 0.0005273775896057487, "11": 0.06702011078596115, "12": 0.0004633449134416878, "13": 0.01944013684988022, "14": 0.00041317802970297635, "15": 0.00039195906720124185, "16": 0.0003728131123352796, "17": 0.0003554504655767232, "18": 0.00033963308669626713, "19": 0.00032516344799660146}}, {"key": "seenivasan2023end", "year": "2023", "title": "Surgicalgpt: End-to-end Language-vision GPT For Visual Question Answering In Surgery", "topic_distr": {"0": 0.000991193694062531, "1": 0.0008084527216851711, "2": 0.0006833253428339958, "3": 0.23012050986289978, "4": 0.0005219770246185362, "5": 0.00046687008580192924, "6": 0.0004222878778818995, "7": 0.11593055725097656, "8": 0.07922229915857315, "9": 0.00032825200469233096, "10": 0.1540086716413498, "11": 0.00028582062805071473, "12": 0.0002684688661247492, "13": 0.00025310329510830343, "14": 0.0002394014154560864, "15": 0.0002271068369736895, "16": 0.00021601338812615722, "17": 0.0002059532271232456, "18": 0.4146113395690918, "19": 0.00018840446136891842}}, {"key": "sejnowski2022large", "year": "2022", "title": "Large Language Models And The Reverse Turing Test", "topic_distr": {"0": 0.11751257628202438, "1": 0.0010611367179080844, "2": 0.06930281966924667, "3": 0.42988449335098267, "4": 0.018491696566343307, "5": 0.0006128044915385544, "6": 0.0005542864673770964, "7": 0.0005059704999439418, "8": 0.00046540243783965707, "9": 0.3584762215614319, "10": 0.0004010853881482035, "11": 0.00037516234442591667, "12": 0.0003523867344483733, "13": 0.0003322182164993137, "14": 0.00031423341715708375, "15": 0.0002980958088301122, "16": 0.0002835347841028124, "17": 0.0002703299978747964, "18": 0.00025830045342445374, "19": 0.00024729585857130587}}, {"key": "sekuli\u01072022evaluating", "year": "2022", "title": "Evaluating Mixed-initiative Conversational Search Systems Via User Simulation", "topic_distr": {"0": 0.06300504505634308, "1": 0.0008936083177104592, "2": 0.0007551735616289079, "3": 0.08173996210098267, "4": 0.35417523980140686, "5": 0.0005159755819477141, "6": 0.15818405151367188, "7": 0.00042602259782142937, "8": 0.2319968193769455, "9": 0.05793919414281845, "10": 0.0003377102839294821, "11": 0.04804714024066925, "12": 0.00029670645017176867, "13": 0.0002797247434500605, "14": 0.0002645817003212869, "15": 0.00025099399499595165, "16": 0.00023873372992966324, "17": 0.00022761542641092092, "18": 0.0002174866385757923, "19": 0.00020822088117711246}}, {"key": "sellam2020learning", "year": "2020", "title": "BLEURT: Learning Robust Metrics For Text Generation", "topic_distr": {"0": 0.1923513412475586, "1": 0.1528192162513733, "2": 0.3209892213344574, "3": 0.0010807235958054662, "4": 0.0009531545802019536, "5": 0.0008525255252607167, "6": 0.0007711165817454457, "7": 0.0744645968079567, "8": 0.0006474622059613466, "9": 0.0005994028178974986, "10": 0.1186610534787178, "11": 0.000521921319887042, "12": 0.08350218087434769, "13": 0.00046217793715186417, "14": 0.0494353286921978, "15": 0.00041470726137049496, "16": 0.0003944501222576946, "17": 0.00037607981357723475, "18": 0.00035934444167651236, "19": 0.0003440349828451872}}, {"key": "sen2020what", "year": "2020", "title": "What Do Models Learn From Question Answering Datasets?", "topic_distr": {"0": 0.06082066521048546, "1": 0.001358229317702353, "2": 0.3102826774120331, "3": 0.15916894376277924, "4": 0.023913998156785965, "5": 0.0007842954364605248, "6": 0.020374255254864693, "7": 0.0006475648260675371, "8": 0.2749398648738861, "9": 0.0005514308577403426, "10": 0.02257225103676319, "11": 0.0004801503964699805, "12": 0.12154087424278259, "13": 0.00042518851114436984, "14": 0.00040217069908976555, "15": 0.0003815170202869922, "16": 0.00036288113915361464, "17": 0.00034598103957250714, "18": 0.0003305850550532341, "19": 0.0003165008674841374}}, {"key": "sengupta2023jais", "year": "2023", "title": "Jais And Jais-chat: Arabic-centric Foundation And Instruction-tuned Open Generative Large Language Models", "topic_distr": {"0": 0.0017566451570019126, "1": 0.0014343701768666506, "2": 0.0012125193607062101, "3": 0.10050851106643677, "4": 0.0009262282983399928, "5": 0.0008284430368803442, "6": 0.0931708887219429, "7": 0.0006840159767307341, "8": 0.0006291724857874215, "9": 0.0005824706749990582, "10": 0.0005422229296527803, "11": 0.0005071779014542699, "12": 0.4269111156463623, "13": 0.18990156054496765, "14": 0.08674609661102295, "15": 0.07083719223737717, "16": 0.0003833075752481818, "17": 0.00036545615876093507, "18": 0.00034919354948215187, "19": 0.021723443642258644}}, {"key": "seo2016bidirectional", "year": "2016", "title": "Bidirectional Attention Flow For Machine Comprehension", "topic_distr": {"0": 0.001708224299363792, "1": 0.001395018887706101, "2": 0.6771248579025269, "3": 0.0010215295478701591, "4": 0.04256012290716171, "5": 0.0008058317471295595, "6": 0.0007288816850632429, "7": 0.0006653466261923313, "8": 0.1793278157711029, "9": 0.0005665728822350502, "10": 0.09050378203392029, "11": 0.0004933350719511509, "12": 0.0004633853677660227, "13": 0.0004368639492895454, "14": 0.00041321408934891224, "15": 0.00039199329330585897, "16": 0.0003728456504177302, "17": 0.0003554814902599901, "18": 0.00033966274349950254, "19": 0.0003251918242312968}}, {"key": "seo2019real", "year": "2019", "title": "Real-time Open-domain Question Answering With Dense-sparse Phrase Index", "topic_distr": {"0": 0.0018080701120197773, "1": 0.001476073986850679, "2": 0.3989962041378021, "3": 0.001080760732293129, "4": 0.0009531890391372144, "5": 0.0008525570156052709, "6": 0.0007711450452916324, "7": 0.0007039260235615075, "8": 0.20683367550373077, "9": 0.0005994249950163066, "10": 0.0005580057040788233, "11": 0.0005219405866228044, "12": 0.0004902542568743229, "13": 0.19985923171043396, "14": 0.0004371738468762487, "15": 0.0004147225699853152, "16": 0.18256410956382751, "17": 0.0003760936961043626, "18": 0.00035935771302320063, "19": 0.0003440477012190968}}, {"key": "seo2020look", "year": "2020", "title": "Look Before You Speak: Visually Contextualized Utterances", "topic_distr": {"0": 0.0013853880809620023, "1": 0.06134307384490967, "2": 0.24471956491470337, "3": 0.0008285705116577446, "4": 0.0007307641208171844, "5": 0.0006536147557199001, "6": 0.20719043910503387, "7": 0.0005396661581471562, "8": 0.0004963963874615729, "9": 0.029331764206290245, "10": 0.00042779609793797135, "11": 0.000400146673200652, "12": 0.00037585431709885597, "13": 0.0003543426573742181, "14": 0.0003351601189933717, "15": 0.00031794782262295485, "16": 0.0003024170873686671, "17": 0.0002883329289034009, "18": 0.42543861269950867, "19": 0.0245401319116354}}, {"key": "seo2023leveraging", "year": "2023", "title": "Chacha: Leveraging Large Language Models To Prompt Children To Share Their Emotions About Personal Events", "topic_distr": {"0": 0.0016855227295309305, "1": 0.0013765329495072365, "2": 0.0011636377312242985, "3": 0.12703517079353333, "4": 0.0008888755110092461, "5": 0.03512315824627876, "6": 0.04450151324272156, "7": 0.051549144089221954, "8": 0.000603799126110971, "9": 0.5096215009689331, "10": 0.0005203561158850789, "11": 0.00048672434058971703, "12": 0.0004571759491227567, "13": 0.00043100991751998663, "14": 0.039897605776786804, "15": 0.07478418946266174, "16": 0.0003678494831547141, "17": 0.10885033756494522, "18": 0.0003351112245582044, "19": 0.0003208341950085014}}, {"key": "serapiogarc\u00eda2023personality", "year": "2023", "title": "Personality Traits In Large Language Models", "topic_distr": {"0": 0.4020729959011078, "1": 0.10445186495780945, "2": 0.0009158693719655275, "3": 0.23395556211471558, "4": 0.0006996333249844611, "5": 0.0006257702480070293, "6": 0.0005660144961439073, "7": 0.09842519462108612, "8": 0.0004752498061861843, "9": 0.12602545320987701, "10": 0.0004095718904864043, "11": 0.028970535844564438, "12": 0.0003598428447730839, "13": 0.00033924757735803723, "14": 0.000320882216328755, "15": 0.0003044031618628651, "16": 0.0002895340439863503, "17": 0.00027604986098594964, "18": 0.0002637657744344324, "19": 0.00025252834893763065}}, {"key": "serban2016generative", "year": "2016", "title": "Generative Deep Neural Networks For Dialogue: A Short Review", "topic_distr": {"0": 0.0016009635291993618, "1": 0.0013058072654530406, "2": 0.1440272480249405, "3": 0.0009560253820382059, "4": 0.0008431775495409966, "5": 0.10372728109359741, "6": 0.3007308542728424, "7": 0.0006226831465028226, "8": 0.0005727572133764625, "9": 0.0005302429781295359, "10": 0.000493604049552232, "11": 0.03072413243353367, "12": 0.11058497428894043, "13": 0.0004088512796442956, "14": 0.0003867178747896105, "15": 0.23263898491859436, "16": 0.06889082491397858, "17": 0.000332687224727124, "18": 0.0003178828046657145, "19": 0.0003043398028239608}}, {"key": "serban2017deep", "year": "2017", "title": "A Deep Reinforcement Learning Chatbot", "topic_distr": {"0": 0.0019187784055247903, "1": 0.10807313024997711, "2": 0.23125681281089783, "3": 0.0011471675243228674, "4": 0.29038846492767334, "5": 0.0009049410000443459, "6": 0.16848134994506836, "7": 0.0007471774588339031, "8": 0.000687269726768136, "9": 0.08172909170389175, "10": 0.0005922913551330566, "11": 0.110593780875206, "12": 0.0005203770124353468, "13": 0.0004905937821604311, "14": 0.00046403519809246063, "15": 0.00044020445784553885, "16": 0.0004187018785160035, "17": 0.00039920207927934825, "18": 0.00038143779966048896, "19": 0.00036518709384836257}}, {"key": "sha2023large", "year": "2023", "title": "Languagempc: Large Language Models As Decision Makers For Autonomous Driving", "topic_distr": {"0": 0.057745784521102905, "1": 0.0010720532154664397, "2": 0.0009062878089025617, "3": 0.4290708899497986, "4": 0.0006923051550984383, "5": 0.07961050420999527, "6": 0.0005600850563496351, "7": 0.0005112636717967689, "8": 0.0004702711885329336, "9": 0.00043536422890610993, "10": 0.0004052812873851508, "11": 0.11544527858495712, "12": 0.0925874412059784, "13": 0.090605229139328, "14": 0.0003175207239110023, "15": 0.0003012143133673817, "16": 0.08655314892530441, "17": 0.04219920560717583, "18": 0.00026100262766703963, "19": 0.0002498829271644354}}, {"key": "shaer2024ai", "year": "2024", "title": "Ai-augmented Brainwriting: Investigating The Use Of Llms In Group Ideation", "topic_distr": {"0": 0.05719759315252304, "1": 0.0012891254154965281, "2": 0.0010897931642830372, "3": 0.18925316631793976, "4": 0.0641859769821167, "5": 0.0007446073577739298, "6": 0.0006735037313774228, "7": 0.0006147958338260651, "8": 0.0005655023269355297, "9": 0.6122785210609436, "10": 0.00048735179007053375, "11": 0.0004558531509246677, "12": 0.00042817892972379923, "13": 0.0004036725149489939, "14": 0.00038181946729309857, "15": 0.06866320222616196, "16": 0.00034451810643076897, "17": 0.0003284732229076326, "18": 0.00031385631882585585, "19": 0.0003004848549608141}}, {"key": "shah2018building", "year": "2018", "title": "Building A Conversational Agent Overnight With Dialogue Self-play", "topic_distr": {"0": 0.05394567549228668, "1": 0.030473705381155014, "2": 0.0010501791257411242, "3": 0.0009095823625102639, "4": 0.13918203115463257, "5": 0.2692547142505646, "6": 0.17405466735363007, "7": 0.07967932522296906, "8": 0.0005449304007925093, "9": 0.020030587911605835, "10": 0.00046962284250184894, "11": 0.057537976652383804, "12": 0.0004126025887671858, "13": 0.0506758838891983, "14": 0.0003679296059999615, "15": 0.00034903440973721445, "16": 0.12015307694673538, "17": 0.00031652397592552006, "18": 0.00030243879882618785, "19": 0.00028955377638339996}}, {"key": "shah2022lm", "year": "2022", "title": "Lm-nav: Robotic Navigation With Large Pre-trained Models Of Language, Vision, And Action", "topic_distr": {"0": 0.0014504538848996162, "1": 0.0011845298577100039, "2": 0.0010011153062805533, "3": 0.1396656185388565, "4": 0.000764735508710146, "5": 0.15417645871639252, "6": 0.0006186828832142055, "7": 0.0005647536600008607, "8": 0.0005194724071770906, "9": 0.0004809133824892342, "10": 0.0004476830654311925, "11": 0.43852055072784424, "12": 0.0003933266852982342, "13": 0.00037081498885527253, "14": 0.0003507407382130623, "15": 0.00033272826112806797, "16": 0.016187872737646103, "17": 0.00030173666891641915, "18": 0.15884751081466675, "19": 0.08382029831409454}}, {"key": "shahriar2023have", "year": "2023", "title": "Let's Have A Chat! A Conversation With Chatgpt: Technology, Applications, And Limitations", "topic_distr": {"0": 0.10602491348981857, "1": 0.0014979529660195112, "2": 0.0012661486398428679, "3": 0.0010966387344524264, "4": 0.0009671898442320526, "5": 0.0008650796371512115, "6": 0.10577511042356491, "7": 0.0007142654503695667, "8": 0.032301921397447586, "9": 0.6012765169143677, "10": 0.08027690649032593, "11": 0.0005296069430187345, "12": 0.0645788162946701, "13": 0.00046898386790417135, "14": 0.00044359517050907016, "15": 0.0004208141181152314, "16": 0.00040025869384407997, "17": 0.0003816178650595248, "18": 0.00036463604192249477, "19": 0.0003491011739242822}}, {"key": "shaikh2022second", "year": "2022", "title": "On Second Thought, Let's Not Think Step By Step! Bias And Toxicity In Zero-shot Reasoning", "topic_distr": {"0": 0.1650627851486206, "1": 0.0011315512238070369, "2": 0.0009565746877342463, "3": 0.6933867931365967, "4": 0.0007307276828214526, "5": 0.0006535819848068058, "6": 0.0005911705084145069, "7": 0.04951517656445503, "8": 0.03637727349996567, "9": 0.0004595274804159999, "10": 0.00042777491034939885, "11": 0.0004001268825959414, "12": 0.04816959425806999, "13": 0.0003543251077644527, "14": 0.0003351435298100114, "15": 0.00031793207745067775, "16": 0.0003024020988959819, "17": 0.00028831863892264664, "18": 0.0002754885936155915, "19": 0.00026375174638815224}}, {"key": "shakeri2020end", "year": "2020", "title": "End-to-end Synthetic Data Generation For Domain Adaptation Of Question Answering Systems", "topic_distr": {"0": 0.041305359452962875, "1": 0.11356497555971146, "2": 0.13971036672592163, "3": 0.001285731210373342, "4": 0.16850604116916656, "5": 0.0010142485843971372, "6": 0.0009173963917419314, "7": 0.22525402903556824, "8": 0.1894194781780243, "9": 0.0007131087477318943, "10": 0.045608941465616226, "11": 0.0006209290586411953, "12": 0.0005832333117723465, "13": 0.000549852498807013, "14": 0.0005200859159231186, "15": 0.000493376690428704, "16": 0.00046927679795771837, "17": 0.00044742165482603014, "18": 0.0004275116079952568, "19": 0.06858861446380615}}, {"key": "shanahan2022talking", "year": "2022", "title": "Talking About Large Language Models", "topic_distr": {"0": 0.26905444264411926, "1": 0.002078691031783819, "2": 0.031491585075855255, "3": 0.0015220582718029618, "4": 0.0013423869386315346, "5": 0.001200665719807148, "6": 0.0010860121110454202, "7": 0.0009913468966260552, "8": 0.000911861949134618, "9": 0.5286353230476379, "10": 0.0007858456810936332, "11": 0.000735054723918438, "12": 0.15623828768730164, "13": 0.0006509143859148026, "14": 0.0006156768067739904, "15": 0.0005840584053657949, "16": 0.0005555290263146162, "17": 0.0005296569433994591, "18": 0.000506087439134717, "19": 0.0004845262155868113}}, {"key": "shankar2024who", "year": "2024", "title": "Who Validates The Validators? Aligning Llm-assisted Evaluation Of LLM Outputs With Human Preferences", "topic_distr": {"0": 0.20178982615470886, "1": 0.0008416942437179387, "2": 0.000711555068846792, "3": 0.369183748960495, "4": 0.2785241901874542, "5": 0.09140551090240479, "6": 0.00043974112486466765, "7": 0.00040140983765013516, "8": 0.0003692253085318953, "9": 0.05384780466556549, "10": 0.0003181996289640665, "11": 0.00029763366910628974, "12": 0.00027956473059020936, "13": 0.0002635641139931977, "14": 0.0002492959320079535, "15": 0.00023649321519769728, "16": 0.00022494127915706486, "17": 0.00021446531172841787, "18": 0.00020492170006036758, "19": 0.00019619126396719366}}, {"key": "shao2017generating", "year": "2017", "title": "Generating High-quality And Informative Conversation Responses With Sequence-to-sequence Models", "topic_distr": {"0": 0.001433964935131371, "1": 0.0011709247482940555, "2": 0.269940584897995, "3": 0.06288203597068787, "4": 0.0007559902151115239, "5": 0.0006761769764125347, "6": 0.3526073396205902, "7": 0.18410931527614594, "8": 0.000513531849719584, "9": 0.0004754137771669775, "10": 0.0004425634688232094, "11": 0.00041395961306989193, "12": 0.00038882868830114603, "13": 0.1018100455403328, "14": 0.020881379023194313, "15": 0.00032892325543798506, "16": 0.0003128564276266843, "17": 0.0002982860605698079, "18": 0.00028501247288659215, "19": 0.0002728698600549251}}, {"key": "shao2019long", "year": "2019", "title": "Long And Diverse Text Generation With Planning-based Hierarchical Variational Model", "topic_distr": {"0": 0.0015399642288684845, "1": 0.056011609733104706, "2": 0.13993403315544128, "3": 0.0009206686518155038, "4": 0.03664422780275345, "5": 0.000726269674487412, "6": 0.20184946060180664, "7": 0.4779626727104187, "8": 0.0005515755619853735, "9": 0.0005106335738673806, "10": 0.00047534966142848134, "11": 0.0004446267557796091, "12": 0.00041763405897654593, "13": 0.0003937311703339219, "14": 0.0003724163107108325, "15": 0.07998951524496078, "16": 0.0003360335831530392, "17": 0.00032038381323218346, "18": 0.00030612689442932606, "19": 0.00029308474040590227}}, {"key": "shao2023character", "year": "2023", "title": "Character-llm: A Trainable Agent For Role-playing", "topic_distr": {"0": 0.1490904837846756, "1": 0.0012125312350690365, "2": 0.0010250145569443703, "3": 0.14931197464466095, "4": 0.0007829804089851677, "5": 0.0007003182545304298, "6": 0.0006334437057375908, "7": 0.037129759788513184, "8": 0.0005318662151694298, "9": 0.1723812371492386, "10": 0.0004583641130011529, "11": 0.40352141857147217, "12": 0.00040271083707921207, "13": 0.0003796620585490018, "14": 0.0003591088461689651, "15": 0.03220858797430992, "16": 0.0003240261576138437, "17": 0.032004907727241516, "18": 0.0002951881324406713, "19": 0.017246369272470474}}, {"key": "shao2023closed", "year": "2023", "title": "Lmdrive: Closed-loop End-to-end Driving With Large Language Models", "topic_distr": {"0": 0.001287079998292029, "1": 0.1083439365029335, "2": 0.0008875548373907804, "3": 0.2846686840057373, "4": 0.0006779980612918735, "5": 0.05837481468915939, "6": 0.0005485106375999749, "7": 0.0005006981082260609, "8": 0.00046055277925916016, "9": 0.08371993154287338, "10": 0.0003969059616792947, "11": 0.14946101605892181, "12": 0.11492382735013962, "13": 0.0003287564031779766, "14": 0.00031095900340005755, "15": 0.00029498955700546503, "16": 0.06854686141014099, "17": 0.0772903710603714, "18": 0.04873186722397804, "19": 0.00024471894721500576}}, {"key": "shao2023enhancing", "year": "2023", "title": "Enhancing Retrieval-augmented Large Language Models With Iterative Retrieval-generation Synergy", "topic_distr": {"0": 0.043861113488674164, "1": 0.0008704517385922372, "2": 0.05180332064628601, "3": 0.25250062346458435, "4": 0.0005621157470159233, "5": 0.0005027708830311894, "6": 0.07178325206041336, "7": 0.1478857547044754, "8": 0.15477746725082397, "9": 0.00035349358222447336, "10": 0.0003290677850600332, "11": 0.02717677503824234, "12": 0.0002891132899094373, "13": 0.0002725661906879395, "14": 0.00025781066506169736, "15": 0.0002445706631988287, "16": 0.24589307606220245, "17": 0.0002217904111603275, "18": 0.0002119208365911618, "19": 0.00020289220265112817}}, {"key": "shapira2023clever", "year": "2023", "title": "Clever Hans Or Neural Theory Of Mind? Stress Testing Social Reasoning In Large Language Models", "topic_distr": {"0": 0.31316787004470825, "1": 0.09508249908685684, "2": 0.0012298347428441048, "3": 0.48512908816337585, "4": 0.0009394744411110878, "5": 0.0008402905659750104, "6": 0.0007600499666295946, "7": 0.0006937980651855469, "8": 0.0006381702260114253, "9": 0.042307306081056595, "10": 0.0005499772378243506, "11": 0.0005144309834577143, "12": 0.00048320056521333754, "13": 0.00045554505777545273, "14": 0.055346958339214325, "15": 0.00040875564445741475, "16": 0.0003887892235070467, "17": 0.00037068253732286394, "18": 0.0003541873302310705, "19": 0.0003390976053196937}}, {"key": "sharma2021towards", "year": "2021", "title": "Towards Facilitating Empathic Conversations In Online Mental Health Support: A Reinforcement Learning Approach", "topic_distr": {"0": 0.0008206818602047861, "1": 0.24288971722126007, "2": 0.09207770973443985, "3": 0.0004905967507511377, "4": 0.00043268638546578586, "5": 0.00038700594450347126, "6": 0.23549804091453552, "7": 0.05188116058707237, "8": 0.0002939169353339821, "9": 0.10145991295576096, "10": 0.023171305656433105, "11": 0.24910908937454224, "12": 0.00022254380746744573, "13": 0.00020980671979486942, "14": 0.00019844871712848544, "15": 0.00018825729785021394, "16": 0.0001790615206118673, "17": 0.00017072226910386235, "18": 0.00016312520892824978, "19": 0.00015617546159774065}}, {"key": "sharma2023facilitating", "year": "2023", "title": "Facilitating Self-guided Mental Health Interventions Through Human-language Model Interaction: A Case Study Of Cognitive Restructuring", "topic_distr": {"0": 0.19961901009082794, "1": 0.26026037335395813, "2": 0.0010011711856350303, "3": 0.09427161514759064, "4": 0.000764769094530493, "5": 0.0006840286660008132, "6": 0.0006187097169458866, "7": 0.0005647781072184443, "8": 0.0005194949335418642, "9": 0.3719845414161682, "10": 0.00044770247768610716, "11": 0.049203719943761826, "12": 0.0003933437110390514, "13": 0.00037083105416968465, "14": 0.00035075590130873024, "15": 0.0177625622600317, "16": 0.0003164892550557852, "17": 0.0003017497365362942, "18": 0.0002883220149669796, "19": 0.0002760383940767497}}, {"key": "sharma2023towards", "year": "2023", "title": "Towards Understanding Sycophancy In Language Models", "topic_distr": {"0": 0.5318609476089478, "1": 0.0011072667548432946, "2": 0.0009359078831039369, "3": 0.02704361267387867, "4": 0.13146251440048218, "5": 0.000639453821349889, "6": 0.0762958973646164, "7": 0.0005279742763377726, "8": 0.0004856419691350311, "9": 0.1461031287908554, "10": 0.0004185278667137027, "11": 0.0003914774861186743, "12": 0.00036771141458302736, "13": 0.0003466657944954932, "14": 0.00032789885881356895, "15": 0.0003110594698227942, "16": 0.0002958652039524168, "17": 0.00028208617004565895, "18": 0.00026953345513902605, "19": 0.08052688091993332}}, {"key": "shavrina2020russian", "year": "2020", "title": "Russiansuperglue: A Russian Language Understanding Evaluation Benchmark", "topic_distr": {"0": 0.14220541715621948, "1": 0.0014346743701025844, "2": 0.05663143843412399, "3": 0.23474302887916565, "4": 0.0009263469255529344, "5": 0.0008285486837849021, "6": 0.0007494292804040015, "7": 0.0006841031135991216, "8": 0.0006292525795288384, "9": 0.0005825448897667229, "10": 0.2027920037508011, "11": 0.0005072424537502229, "12": 0.296530157327652, "13": 0.00044917938066646457, "14": 0.020867979153990746, "15": 0.0380062572658062, "16": 0.00038335638237185776, "17": 0.00036550272488966584, "18": 0.00034923802013508976, "19": 0.00033435915247537196}}, {"key": "shayegani2023survey", "year": "2023", "title": "Survey Of Vulnerabilities In Large Language Models Revealed By Adversarial Attacks", "topic_distr": {"0": 0.07567503303289413, "1": 0.24618013203144073, "2": 0.000789835408795625, "3": 0.17656682431697845, "4": 0.07829748094081879, "5": 0.0005396477645263076, "6": 0.00048811594024300575, "7": 0.00044556791544891894, "8": 0.0004098428471479565, "9": 0.06604111194610596, "10": 0.0003532039700075984, "11": 0.000330375594785437, "12": 0.3081507086753845, "13": 0.0002925581356976181, "14": 0.0002767203259281814, "15": 0.00026250924565829337, "16": 0.044217053800821304, "17": 0.0002380580990575254, "18": 0.00022746462491340935, "19": 0.00021777377696707845}}, {"key": "shazeer2019fast", "year": "2019", "title": "Fast Transformer Decoding: One Write-head Is All You Need", "topic_distr": {"0": 0.001979569438844919, "1": 0.0016163942636922002, "2": 0.42425858974456787, "3": 0.0011836140183731914, "4": 0.0010439010802656412, "5": 0.0009336926159448922, "6": 0.0008445329149253666, "7": 0.08872250467538834, "8": 0.0007091056322678924, "9": 0.0006564706563949585, "10": 0.2147795855998993, "11": 0.0005716122686862946, "12": 0.00053691043285653, "13": 0.25961634516716003, "14": 0.0004787785292137414, "15": 0.00045419062371365726, "16": 0.00043200486106798053, "17": 0.0004118855285923928, "18": 0.0003935568092856556, "19": 0.00037678980152122676}}, {"key": "shazeer2020talking", "year": "2020", "title": "Talking-heads Attention", "topic_distr": {"0": 0.004617728758603334, "1": 0.003771989606320858, "2": 0.47893407940864563, "3": 0.0027616950683295727, "4": 0.002435702132061124, "5": 0.002178556751459837, "6": 0.001970522804185748, "7": 0.0017987567698583007, "8": 0.12494567781686783, "9": 0.001531723071821034, "10": 0.24992261826992035, "11": 0.0013337255222722888, "12": 0.0012527569197118282, "13": 0.11660110950469971, "14": 0.0011171193327754736, "15": 0.0010597491636872292, "16": 0.0010079838102683425, "17": 0.000961040030233562, "18": 0.0009182741632685065, "19": 0.000879152212291956}}, {"key": "shen2019modular", "year": "2019", "title": "Lingvo: A Modular And Scalable Framework For Sequence-to-sequence Modeling", "topic_distr": {"0": 0.0019202003022655845, "1": 0.21413125097751617, "2": 0.0013248289469629526, "3": 0.1265394389629364, "4": 0.21224427223205566, "5": 0.0009051654487848282, "6": 0.0008187294588424265, "7": 0.0007473625591956079, "8": 0.0006874399841763079, "9": 0.3451210558414459, "10": 0.09152554720640182, "11": 0.000554147525690496, "12": 0.0005205059424042702, "13": 0.0004907153197564185, "14": 0.00046415015822276473, "15": 0.00044031350989826024, "16": 0.0004188056045677513, "17": 0.0003993010031990707, "18": 0.000381532299797982, "19": 0.00036527757765725255}}, {"key": "shen2020curriculum", "year": "2020", "title": "CDL: Curriculum Dual Learning For Emotion-controllable Response Generation", "topic_distr": {"0": 0.0013130806619301438, "1": 0.0010722524020820856, "2": 0.0009063357138074934, "3": 0.0007849897956475616, "4": 0.17902807891368866, "5": 0.0006192387663759291, "6": 0.49235448241233826, "7": 0.0005112834041938186, "8": 0.00047028937842696905, "9": 0.1348848193883896, "10": 0.0004052969452459365, "11": 0.0003791017225012183, "12": 0.000356086966348812, "13": 0.00033570665982551873, "14": 0.000317533005727455, "15": 0.185190811753273, "16": 0.0002865120186470449, "17": 0.000273168581770733, "18": 0.00026101269759237766, "19": 0.000249892589636147}}, {"key": "shen2020simple", "year": "2020", "title": "A Simple But Tough-to-beat Data Augmentation Approach For Natural Language Understanding And Generation", "topic_distr": {"0": 0.0012725937413051724, "1": 0.14188873767852783, "2": 0.46629422903060913, "3": 0.0007609208696521819, "4": 0.0006710988818667829, "5": 0.0006002482259646058, "6": 0.0005429295706562698, "7": 0.04297827556729317, "8": 0.00045586671330966055, "9": 0.0004220289411023259, "10": 0.10375341773033142, "11": 0.000367475557141006, "12": 0.00034516662708483636, "13": 0.05531954765319824, "14": 0.07106286287307739, "15": 0.0002919880498666316, "16": 0.11221258342266083, "17": 0.00026479116058908403, "18": 0.000253008067375049, "19": 0.0002422289690002799}}, {"key": "shen2022multitask", "year": "2022", "title": "Multitask Vision-language Prompt Tuning", "topic_distr": {"0": 0.0009818339021876454, "1": 0.0008018491789698601, "2": 0.000677907548379153, "3": 0.0005871540633961558, "4": 0.0005178467836230993, "5": 0.0004631759657058865, "6": 0.00041894661262631416, "7": 0.0003824279410764575, "8": 0.0003517653385642916, "9": 0.0003256547497585416, "10": 0.00030315257026813924, "11": 0.0002835591440089047, "12": 0.0002663446357473731, "13": 0.0002511006605345756, "14": 0.00023750719265080988, "15": 0.00022530989372171462, "16": 0.07428276538848877, "17": 0.7597156763076782, "18": 0.1587391197681427, "19": 0.0001869137486210093}}, {"key": "shen2023anything", "year": "2023", "title": "\"do Anything Now\": Characterizing And Evaluating In-the-wild Jailbreak Prompts On Large Language Models", "topic_distr": {"0": 0.05870796740055084, "1": 0.2079588919878006, "2": 0.0008524667355231941, "3": 0.2291661500930786, "4": 0.0006511771352961659, "5": 0.0005824293475598097, "6": 0.0005268121603876352, "7": 0.0004808911180589348, "8": 0.008601099252700806, "9": 0.16890768706798553, "10": 0.00038120485260151327, "11": 0.0003565667138900608, "12": 0.11023632436990738, "13": 0.00031575121101923287, "14": 0.0002986578329000622, "15": 0.000283320143353194, "16": 0.00026948083541356027, "17": 0.21094262599945068, "18": 0.00024549730005674064, "19": 0.0002350381837459281}}, {"key": "shen2023chatgpt", "year": "2023", "title": "In Chatgpt We Trust? Measuring And Characterizing The Reliability Of Chatgpt", "topic_distr": {"0": 0.19048097729682922, "1": 0.07959344983100891, "2": 0.0008359024068340659, "3": 0.188259556889534, "4": 0.0006385332671925426, "5": 0.000571120239328593, "6": 0.000516583037097007, "7": 0.0004715536197181791, "8": 0.07727234810590744, "9": 0.4397037625312805, "10": 0.00037380296271294355, "11": 0.00034964323276653886, "12": 0.00032841687789186835, "13": 0.0003096202271990478, "14": 0.0002928587782662362, "15": 0.0002778188791126013, "16": 0.019000930711627007, "17": 0.00025194173213094473, "18": 0.00024073045642580837, "19": 0.00023047442664392292}}, {"key": "shen2023large", "year": "2023", "title": "Large Language Model Alignment: A Survey", "topic_distr": {"0": 0.23463742434978485, "1": 0.0609666109085083, "2": 0.0008046891889534891, "3": 0.14714743196964264, "4": 0.0006146930973045528, "5": 0.045350801199674606, "6": 0.0004972965107299387, "7": 0.0004539482470136136, "8": 0.0004175512585788965, "9": 0.1739131212234497, "10": 0.0003598470939323306, "11": 0.000336589349899441, "12": 0.33270207047462463, "13": 0.00029806062229909003, "14": 0.00028192493482492864, "15": 0.00026744656497612596, "16": 0.00025438264128752053, "17": 0.0002425355341983959, "18": 0.00023174281523097306, "19": 0.00022186970454640687}}, {"key": "shen2023mixture", "year": "2023", "title": "Mixture-of-experts Meets Instruction Tuning:a Winning Combination For Large Language Models", "topic_distr": {"0": 0.0013420964824035764, "1": 0.0010952219599857926, "2": 0.1531582772731781, "3": 0.402878075838089, "4": 0.0007072451990097761, "5": 0.0006325787398964167, "6": 0.0005721728666685522, "7": 0.0005222978070378304, "8": 0.0004804206546396017, "9": 0.00044476031325757504, "10": 0.0004140281234867871, "11": 0.048123642802238464, "12": 0.00036375800846144557, "13": 0.0937516987323761, "14": 0.0003243735118303448, "15": 0.00030771514866501093, "16": 0.03138621151447296, "17": 0.14624463021755219, "18": 0.00026663561584427953, "19": 0.11698413640260696}}, {"key": "shen2023scaling", "year": "2023", "title": "Scaling Vision-language Models With Sparse Mixture Of Experts", "topic_distr": {"0": 0.001452270895242691, "1": 0.001184409367851913, "2": 0.06157669797539711, "3": 0.04986264184117317, "4": 0.0007648108876310289, "5": 0.042181968688964844, "6": 0.0006187439430505037, "7": 0.0005648094229400158, "8": 0.0005195237463340163, "9": 0.0004809608799405396, "10": 0.00044772730325348675, "11": 0.030006922781467438, "12": 0.345695823431015, "13": 0.25453534722328186, "14": 0.016842911019921303, "15": 0.0003327611484564841, "16": 0.0003165068046655506, "17": 0.00030176647123880684, "18": 0.19203732907772064, "19": 0.0002760537026915699}}, {"key": "shen2023solving", "year": "2023", "title": "Hugginggpt: Solving AI Tasks With Chatgpt And Its Friends In Hugging Face", "topic_distr": {"0": 0.0011335986200720072, "1": 0.030949272215366364, "2": 0.0007826847140677273, "3": 0.3114192485809326, "4": 0.000597893784288317, "5": 0.0005347714759409428, "6": 0.0004837053711526096, "7": 0.00044154177885502577, "8": 0.0004061395302414894, "9": 0.44168224930763245, "10": 0.0003500124148558825, "11": 0.0646013393998146, "12": 0.03342617303133011, "13": 0.0002899145765695721, "14": 0.0002742198994383216, "15": 0.0002601371961645782, "16": 0.000247430318268016, "17": 0.00023590700584463775, "18": 0.11166795343160629, "19": 0.00021580596512649208}}, {"key": "sheng2021revealing", "year": "2021", "title": "Revealing Persona Biases In Dialogue Systems", "topic_distr": {"0": 0.7407365441322327, "1": 0.0009259175858460367, "2": 0.0007827771478332579, "3": 0.06486466526985168, "4": 0.06713710725307465, "5": 0.08925977349281311, "6": 0.0004837692831642926, "7": 0.000441600161138922, "8": 0.0004061932268086821, "9": 0.0003760425897780806, "10": 0.00035005868994630873, "11": 0.0003274336049798876, "12": 0.00030755557236261666, "13": 0.0002899529063142836, "14": 0.0002742561628110707, "15": 0.03211167827248573, "16": 0.0002474630600772798, "17": 0.00023593820515088737, "18": 0.0002254390565212816, "19": 0.0002158345014322549}}, {"key": "sheng2021societal", "year": "2021", "title": "Societal Biases In Language Generation: Progress And Challenges", "topic_distr": {"0": 0.23121008276939392, "1": 0.0011446117423474789, "2": 0.0009673071326687932, "3": 0.0008378125494346023, "4": 0.0007389196543954313, "5": 0.0006609084666706622, "6": 0.0005977972177788615, "7": 0.1535966545343399, "8": 0.0005019359523430467, "9": 0.2447938770055771, "10": 0.0004325700574554503, "11": 0.013949892483651638, "12": 0.25474050641059875, "13": 0.0003582969366107136, "14": 0.0003389003104530275, "15": 0.09398728609085083, "16": 0.0003057918802369386, "17": 0.000291550561087206, "18": 0.0002785766846500337, "19": 0.00026670825900509953}}, {"key": "sheng2023high", "year": "2023", "title": "Flexgen: High-throughput Generative Inference Of Large Language Models With A Single GPU", "topic_distr": {"0": 0.00135610846336931, "1": 0.00110692682210356, "2": 0.0740041434764862, "3": 0.28112825751304626, "4": 0.0007148688891902566, "5": 0.0006393970106728375, "6": 0.044230639934539795, "7": 0.0005279272445477545, "8": 0.00048559869173914194, "9": 0.00044955400517210364, "10": 0.0004184905847068876, "11": 0.0003914426197297871, "12": 0.0003676786436699331, "13": 0.5590749382972717, "14": 0.0003278696385677904, "15": 0.03367071971297264, "16": 0.000295838835882023, "17": 0.00028206102433614433, "18": 0.00026950944447889924, "19": 0.00025802734307944775}}, {"key": "shi2018sentiment", "year": "2018", "title": "Sentiment Adaptive End-to-end Dialog Systems", "topic_distr": {"0": 0.0016624534036964178, "1": 0.26142147183418274, "2": 0.001147876144386828, "3": 0.0009941993048414588, "4": 0.4825671315193176, "5": 0.0007842723280191422, "6": 0.0007093808962963521, "7": 0.0006475456757470965, "8": 0.0005956263048574328, "9": 0.0005514145595952868, "10": 0.0005133127560839057, "11": 0.0004801361938007176, "12": 0.00045098777627572417, "13": 0.01852487027645111, "14": 0.00040215879562310874, "15": 0.000381505728000775, "16": 0.14923185110092163, "17": 0.00034597079502418637, "18": 0.0782712921500206, "19": 0.00031649149605073035}}, {"key": "shi2018toward", "year": "2018", "title": "Toward Diverse Text Generation With Inverse Reinforcement Learning", "topic_distr": {"0": 0.09135207533836365, "1": 0.13674797117710114, "2": 0.0411008782684803, "3": 0.0008286087540909648, "4": 0.0007308011990971863, "5": 0.0006536470609717071, "6": 0.0005912292981520295, "7": 0.13382118940353394, "8": 0.000496421183925122, "9": 0.0004595732025336474, "10": 0.0004278174601495266, "11": 0.3394232988357544, "12": 0.00037587308906950057, "13": 0.04481617361307144, "14": 0.00033517685369588435, "15": 0.20670917630195618, "16": 0.00030243219225667417, "17": 0.0002883473061956465, "18": 0.0002755159803200513, "19": 0.00026377796893939376}}, {"key": "shi2022language", "year": "2022", "title": "Language Models Are Multilingual Chain-of-thought Reasoners", "topic_distr": {"0": 0.03401987627148628, "1": 0.00199698144569993, "2": 0.0016879946924746037, "3": 0.7269752621650696, "4": 0.00128945370670408, "5": 0.001153321354649961, "6": 0.001043188851326704, "7": 0.0009522563777863979, "8": 0.0008759056800045073, "9": 0.0008108895854093134, "10": 0.0007548584253527224, "11": 0.0007060702773742378, "12": 0.0006632056902162731, "13": 0.0006252477178350091, "14": 0.19063851237297058, "15": 0.0005610280204564333, "16": 0.0005336235626600683, "17": 0.0005087716854177415, "18": 0.00048613158287480474, "19": 0.03371739014983177}}, {"key": "shi2023exploring", "year": "2023", "title": "Badgpt: Exploring Security Vulnerabilities Of Chatgpt Via Backdoor Attacks To Instructgpt", "topic_distr": {"0": 0.002599624451249838, "1": 0.17586952447891235, "2": 0.001793628209270537, "3": 0.0015534809790551662, "4": 0.3317948579788208, "5": 0.0012254544999450445, "6": 0.001108433585613966, "7": 0.0010118138743564487, "8": 0.0009306879946961999, "9": 0.2797752618789673, "10": 0.0008020700188353658, "11": 0.19682294130325317, "12": 0.0007046849932521582, "13": 0.0006643530214205384, "14": 0.0006283879047259688, "15": 0.0005961167626082897, "16": 0.0005669983220286667, "17": 0.0005405921256169677, "18": 0.000516536005306989, "19": 0.0004945296095684171}}, {"key": "shi2023interpretable", "year": "2023", "title": "Chatgraph: Interpretable Text Classification By Converting Chatgpt Knowledge To Graphs", "topic_distr": {"0": 0.0013264002045616508, "1": 0.0010837181471288204, "2": 0.04979579150676727, "3": 0.0007932460284791887, "4": 0.0006996071897447109, "5": 0.09786663204431534, "6": 0.0005659934249706566, "7": 0.000516657019034028, "8": 0.0004752321110572666, "9": 0.14443351328372955, "10": 0.0004095566109754145, "11": 0.0003830860659945756, "12": 0.00035982942790724337, "13": 0.000339234946295619, "14": 0.0003208702546544373, "15": 0.13045547902584076, "16": 0.23906828463077545, "17": 0.3305906355381012, "18": 0.000263755937339738, "19": 0.00025251894840039313}}, {"key": "shi2023large", "year": "2023", "title": "Large Language Models Can Be Easily Distracted By Irrelevant Context", "topic_distr": {"0": 0.001950248028151691, "1": 0.0015912781236693263, "2": 0.0013452067505568266, "3": 0.6450762748718262, "4": 0.0010275604436174035, "5": 0.0009190775454044342, "6": 0.0008313133148476481, "7": 0.21434815227985382, "8": 0.127566397190094, "9": 0.0006461948505602777, "10": 0.0006015438702888787, "11": 0.0005626647616736591, "12": 0.000528506119735539, "13": 0.000498257577419281, "14": 0.0004712841473519802, "15": 0.0004470811109058559, "16": 0.00042524264426901937, "17": 0.00040543824434280396, "18": 0.00038739643059670925, "19": 0.0003708918811753392}}, {"key": "shi2023retrieval", "year": "2023", "title": "REPLUG: Retrieval-augmented Black-box Language Models", "topic_distr": {"0": 0.0021500145085155964, "1": 0.0017559119733050466, "2": 0.31318628787994385, "3": 0.08762781322002411, "4": 0.0011339046759530902, "5": 0.0010141938691958785, "6": 0.000917346915230155, "7": 0.1344335526227951, "8": 0.14356085658073425, "9": 0.0007130703306756914, "10": 0.000663798360619694, "11": 0.00062089558923617, "12": 0.0005832018214277923, "13": 0.0005498228128999472, "14": 0.0005200578598305583, "15": 0.0004933500895276666, "16": 0.000469251477625221, "17": 0.0004473975277505815, "18": 0.04639793932437897, "19": 0.26276132464408875}}, {"key": "shi2023towards", "year": "2023", "title": "Towards Efficient Fine-tuning Of Pre-trained Code Models: An Experimental Study And Beyond", "topic_distr": {"0": 0.1121864914894104, "1": 0.0009015282266773283, "2": 0.04067983105778694, "3": 0.04865339770913124, "4": 0.0005820531514473259, "5": 0.0005206033238209784, "6": 0.11454862356185913, "7": 0.00042984363972209394, "8": 0.00039537932025268674, "9": 0.0003660313959699124, "10": 0.46409937739372253, "11": 0.0003187165129929781, "12": 0.0002993676462210715, "13": 0.142240971326828, "14": 0.00026695476844906807, "15": 0.00025324517628178, "16": 0.07259837538003922, "17": 0.00022965692915022373, "18": 0.00021943729370832443, "19": 0.0002100884448736906}}, {"key": "shi2023trusting", "year": "2023", "title": "Trusting Your Evidence: Hallucinate Less With Context-aware Decoding", "topic_distr": {"0": 0.22233280539512634, "1": 0.0015671445289626718, "2": 0.2630740702152252, "3": 0.0011472434271126986, "4": 0.00101181969512254, "5": 0.0009049978689290583, "6": 0.0008185782935470343, "7": 0.2771725356578827, "8": 0.0006873130332678556, "9": 0.000636295648291707, "10": 0.0005923287244513631, "11": 0.03237228840589523, "12": 0.09238500893115997, "13": 0.0004906246904283762, "14": 0.00046406444744206965, "15": 0.0004402321937959641, "16": 0.041130516678094864, "17": 0.00039922725409269333, "18": 0.0003814618394244462, "19": 0.061991460621356964}}, {"key": "shin2019generating", "year": "2019", "title": "Generating Empathetic Responses By Looking Ahead The User's Sentiment", "topic_distr": {"0": 0.0014501645928248763, "1": 0.0011844256659969687, "2": 0.0010010694386437535, "3": 0.0008670485112816095, "4": 0.12166864424943924, "5": 0.000683970982208848, "6": 0.23633116483688354, "7": 0.3054110109806061, "8": 0.0005194510449655354, "9": 0.11690674722194672, "10": 0.0004476646427065134, "11": 0.19378457963466644, "12": 0.0003933104744646698, "13": 0.0003707997384481132, "14": 0.01746477745473385, "15": 0.0003327145823277533, "16": 0.0003164625377394259, "17": 0.0003017242415808141, "18": 0.00028829765506088734, "19": 0.00027601508190855384}}, {"key": "shin2020eliciting", "year": "2020", "title": "Autoprompt: Eliciting Knowledge From Language Models With Automatically Generated Prompts", "topic_distr": {"0": 0.0013274135999381542, "1": 0.045144401490688324, "2": 0.0009159151231870055, "3": 0.4110773205757141, "4": 0.0006996654556132853, "5": 0.0006257991190068424, "6": 0.0005660405731759965, "7": 0.0005167000344954431, "8": 0.00047527169226668775, "9": 0.0004399935423862189, "10": 0.00040959074976854026, "11": 0.0003831179637927562, "12": 0.0003598594048526138, "13": 0.00033926317701116204, "14": 0.00032089700107462704, "15": 0.00030441718990914524, "16": 0.1302211731672287, "17": 0.24777239561080933, "18": 0.00026377791073173285, "19": 0.15783697366714478}}, {"key": "shin2021constrained", "year": "2021", "title": "Constrained Language Models Yield Few-shot Semantic Parsers", "topic_distr": {"0": 0.002113067777827382, "1": 0.0017265677452087402, "2": 0.2593560218811035, "3": 0.21381062269210815, "4": 0.0011147074401378632, "5": 0.0009970231913030148, "6": 0.000901815656106919, "7": 0.08026165515184402, "8": 0.0007572027388960123, "9": 0.0007009975961409509, "10": 0.0006525598582811654, "11": 0.0006103834602981806, "12": 0.0005733278812840581, "13": 0.0005405140109360218, "14": 0.14964839816093445, "15": 0.0004849973483942449, "16": 0.2088465690612793, "17": 0.0004398228193167597, "18": 0.0004202509007882327, "19": 0.07604348659515381}}, {"key": "shin2022effect", "year": "2022", "title": "On The Effect Of Pretraining Corpora On In-context Learning By A Large-scale Language Model", "topic_distr": {"0": 0.13257679343223572, "1": 0.0012272070161998272, "2": 0.3150704503059387, "3": 0.0008984415326267481, "4": 0.0007923872908577323, "5": 0.0007087319390848279, "6": 0.0006410540663637221, "7": 0.0005851747118867934, "8": 0.0005382561939768493, "9": 0.0004983028629794717, "10": 0.00046387099428102374, "11": 0.1153973862528801, "12": 0.00040754908695816994, "13": 0.0003842234145849943, "14": 0.232293963432312, "15": 0.0003447594936005771, "16": 0.0003279190859757364, "17": 0.00031264725839719176, "18": 0.0002987345797009766, "19": 0.1962321251630783}}, {"key": "shinn2023language", "year": "2023", "title": "Reflexion: Language Agents With Verbal Reinforcement Learning", "topic_distr": {"0": 0.11382769048213959, "1": 0.03737061098217964, "2": 0.0008785502868704498, "3": 0.313315749168396, "4": 0.06850522756576538, "5": 0.0006002553272992373, "6": 0.0005429359734989703, "7": 0.0004956094198860228, "8": 0.00045587209751829505, "9": 0.0004220339469611645, "10": 0.0003928721125703305, "11": 0.2930384576320648, "12": 0.0003451707016211003, "13": 0.0714532881975174, "14": 0.0003077986475545913, "15": 0.000291991513222456, "16": 0.09699583053588867, "17": 0.0002647942746989429, "18": 0.00025301106506958604, "19": 0.0002422318357275799}}, {"key": "shleifer2020pre", "year": "2020", "title": "Pre-trained Summarization Distillation", "topic_distr": {"0": 0.0015783848939463496, "1": 0.0012893043458461761, "2": 0.22551698982715607, "3": 0.0009439119603484869, "4": 0.0008324890513904393, "5": 0.0007446007803082466, "6": 0.0006734975031577051, "7": 0.054810166358947754, "8": 0.0005654970300383866, "9": 0.0005235217395238578, "10": 0.16386045515537262, "11": 0.0004558489308692515, "12": 0.00042817494249902666, "13": 0.4296157658100128, "14": 0.09279801696538925, "15": 0.0003622076183091849, "16": 0.024058369919657707, "17": 0.00032847016700543463, "18": 0.0003138534084428102, "19": 0.00030048206099309027}}, {"key": "shleifer2021improved", "year": "2021", "title": "Normformer: Improved Transformer Pretraining With Extra Normalization", "topic_distr": {"0": 0.0015985165955498815, "1": 0.0013057368341833353, "2": 0.3653216063976288, "3": 0.0009559958707541227, "4": 0.0008431488531641662, "5": 0.0007541346130892634, "6": 0.0006821212591603398, "7": 0.0006226622499525547, "8": 0.0005727379466407001, "9": 0.0005302251665852964, "10": 0.34834620356559753, "11": 0.0004616858495865017, "12": 0.00043365752208046615, "13": 0.2175883799791336, "14": 0.0003867048944812268, "15": 0.00036684548831544816, "16": 0.0003489262599032372, "17": 0.00033267607796005905, "18": 0.00031787215266376734, "19": 0.05823017656803131}}, {"key": "shoeybi2019megatron", "year": "2019", "title": "Megatron-lm: Training Multi-billion Parameter Language Models Using Model Parallelism", "topic_distr": {"0": 0.021113969385623932, "1": 0.0008781886426731944, "2": 0.1756463199853897, "3": 0.02286565490067005, "4": 0.0005670732934959233, "5": 0.00050720403669402, "6": 0.0004587702569551766, "7": 0.0004187802551314235, "8": 0.00038520299131050706, "9": 0.00035661039873957634, "10": 0.17730779945850372, "11": 0.00031051330734044313, "12": 0.00029166246531531215, "13": 0.5816696882247925, "14": 0.016098948195576668, "15": 0.0002467271115165204, "16": 0.00023467527353204787, "17": 0.00022374597028829157, "18": 0.00021378938981797546, "19": 0.00020468114234972745}}, {"key": "shridhar2019benchmark", "year": "2019", "title": "ALFRED: A Benchmark For Interpreting Grounded Instructions For Everyday Tasks", "topic_distr": {"0": 0.0019488779362291098, "1": 0.0015912848757579923, "2": 0.14774930477142334, "3": 0.0011651264503598213, "4": 0.0010275959502905607, "5": 0.0009191089193336666, "6": 0.0008313417201861739, "7": 0.0007588754524476826, "8": 0.000698029762133956, "9": 0.0006462169112637639, "10": 0.0006015644175931811, "11": 0.4768720269203186, "12": 0.2246720939874649, "13": 0.0004982746322639287, "14": 0.0004713002417702228, "15": 0.0004470963904168457, "16": 0.0004252571670804173, "17": 0.00040545209776610136, "18": 0.13790029287338257, "19": 0.0003709045413415879}}, {"key": "shridhar2020aligning", "year": "2020", "title": "Alfworld: Aligning Text And Embodied Environments For Interactive Learning", "topic_distr": {"0": 0.04833931475877762, "1": 0.0010288498597219586, "2": 0.0008697822922840714, "3": 0.000753331754822284, "4": 0.0006644038367085159, "5": 0.0005942600546404719, "6": 0.000537513114977628, "7": 0.04981514811515808, "8": 0.0004513188323471695, "9": 0.031715523451566696, "10": 0.00038894807221367955, "11": 0.542158305644989, "12": 0.00034172312007285655, "13": 0.013506300747394562, "14": 0.0003047243517357856, "15": 0.0002890750765800476, "16": 0.01836787909269333, "17": 0.0002621494932100177, "18": 0.23264305293560028, "19": 0.05696844682097435}}, {"key": "shridhar2022distilling", "year": "2022", "title": "Distilling Reasoning Capabilities Into Smaller Language Models", "topic_distr": {"0": 0.0012348199961706996, "1": 0.0010082228109240532, "2": 0.0008523930446244776, "3": 0.6736409664154053, "4": 0.0006511210813187063, "5": 0.0005823798710480332, "6": 0.0005267675151117146, "7": 0.0004808503435924649, "8": 0.0004422963538672775, "9": 0.0004094658943358809, "10": 0.031366899609565735, "11": 0.00035653647501021624, "12": 0.0003348916070535779, "13": 0.26467767357826233, "14": 0.00029863251256756485, "15": 0.00028329610358923674, "16": 0.02211538515985012, "17": 0.0002569087955635041, "18": 0.0002454764617141336, "19": 0.00023501823307015002}}, {"key": "shtedritski2023what", "year": "2023", "title": "What Does CLIP Know About A Red Circle? Visual Prompt Engineering For Vlms", "topic_distr": {"0": 0.09152980148792267, "1": 0.0012892278609797359, "2": 0.14726996421813965, "3": 0.13064713776111603, "4": 0.0008325427770614624, "5": 0.0007446480449289083, "6": 0.0006735405186191201, "7": 0.035920530557632446, "8": 0.0005655332352034748, "9": 0.13922621309757233, "10": 0.00048737842007540166, "11": 0.00045587809290736914, "12": 0.00042820232920348644, "13": 0.0004036945756524801, "14": 0.0003818403638433665, "15": 0.000362230755854398, "16": 0.0003445369366090745, "17": 0.13419772684574127, "18": 0.31393885612487793, "19": 0.0003005012695211917}}, {"key": "shu2022test", "year": "2022", "title": "Test-time Prompt Tuning For Zero-shot Generalization In Vision-language Models", "topic_distr": {"0": 0.0013425350189208984, "1": 0.15587539970874786, "2": 0.07945507764816284, "3": 0.15866313874721527, "4": 0.0007071714499033988, "5": 0.0006325127906166017, "6": 0.0005721131456084549, "7": 0.0005222433246672153, "8": 0.00048037050873972476, "9": 0.00044471389264799654, "10": 0.0004139849334023893, "11": 0.0003872281522490084, "12": 0.00036372005706653, "13": 0.0003429028729442507, "14": 0.00032433963497169316, "15": 0.00030768304714001715, "16": 0.04459228739142418, "17": 0.4523606300354004, "18": 0.10195669531822205, "19": 0.00025524929515086114}}, {"key": "shumailov2023curse", "year": "2023", "title": "The Curse Of Recursion: Training On Generated Data Makes Models Forget", "topic_distr": {"0": 0.28536123037338257, "1": 0.2709640562534332, "2": 0.0010898238979279995, "3": 0.0009439248242415488, "4": 0.0008325011003762484, "5": 0.0007446108502335846, "6": 0.0006735067581757903, "7": 0.0006147986277937889, "8": 0.0005655048880726099, "9": 0.2518239915370941, "10": 0.00048735400196164846, "11": 0.00045585521729663014, "12": 0.00042818087968043983, "13": 0.09341001510620117, "14": 0.000381821213522926, "15": 0.000362212595064193, "16": 0.00034451967803761363, "17": 0.0003284747072029859, "18": 0.08988712728023529, "19": 0.0003004862228408456}}, {"key": "shuster2018engaging", "year": "2018", "title": "Engaging Image Captioning Via Personality", "topic_distr": {"0": 0.20446689426898956, "1": 0.0013228565221652389, "2": 0.1704493761062622, "3": 0.0009684493415988982, "4": 0.0008541337447240949, "5": 0.03080681338906288, "6": 0.1501396894454956, "7": 0.05660960078239441, "8": 0.0005801992956548929, "9": 0.0005371326697058976, "10": 0.03192527964711189, "11": 0.00046770047629252076, "12": 0.00043930698302574456, "13": 0.0468362420797348, "14": 0.0003917427093256265, "15": 0.019343506544828415, "16": 0.0003534718998707831, "17": 0.00033701001666486263, "18": 0.2828623354434967, "19": 0.00030829422757960856}}, {"key": "shuster2020multi", "year": "2020", "title": "Multi-modal Open-domain Dialogue", "topic_distr": {"0": 0.05661118030548096, "1": 0.0013059631455689669, "2": 0.2755301594734192, "3": 0.0009560323669575155, "4": 0.06567589193582535, "5": 0.05937549099326134, "6": 0.14597037434577942, "7": 0.0006226826808415353, "8": 0.0005727568059228361, "9": 0.0005302426288835704, "10": 0.0004936037585139275, "11": 0.12792816758155823, "12": 0.07352817803621292, "13": 0.050907447934150696, "14": 0.0003867176128551364, "15": 0.0003668575664050877, "16": 0.0003489377268124372, "17": 0.0003326869918964803, "18": 0.1382523477077484, "19": 0.0003043395990971476}}, {"key": "shuster2021retrieval", "year": "2021", "title": "Retrieval Augmentation Reduces Hallucination In Conversation", "topic_distr": {"0": 0.16532352566719055, "1": 0.0637383759021759, "2": 0.166230246424675, "3": 0.09660802036523819, "4": 0.0009262420353479683, "5": 0.0651150718331337, "6": 0.2372525930404663, "7": 0.0006840257556177676, "8": 0.06624843180179596, "9": 0.0005824789986945689, "10": 0.0005422307294793427, "11": 0.0005071851192042232, "12": 0.0004763946053571999, "13": 0.00044912859448231757, "14": 0.0004248147888574749, "15": 0.0004029982374049723, "16": 0.13343924283981323, "17": 0.0003654613974504173, "18": 0.00034919852623715997, "19": 0.00033432134659960866}}, {"key": "shuster2022blenderbot", "year": "2022", "title": "Blenderbot 3: A Deployed Conversational Agent That Continually Learns To Responsibly Engage", "topic_distr": {"0": 0.0017108403844758868, "1": 0.0013955432223156095, "2": 0.06736591458320618, "3": 0.020159976556897163, "4": 0.0009009921923279762, "5": 0.06073436141014099, "6": 0.19399437308311462, "7": 0.00066537776729092, "8": 0.0006120286416262388, "9": 0.13427430391311646, "10": 0.0005274483701214194, "11": 0.14780227839946747, "12": 0.2092064917087555, "13": 0.10582323372364044, "14": 0.00041323344339616597, "15": 0.0003920116287190467, "16": 0.053001221269369125, "17": 0.00035549813765101135, "18": 0.0003396786341909319, "19": 0.00032520704553462565}}, {"key": "shuster2022language", "year": "2022", "title": "Language Models That Seek For Knowledge: Modular Search & Generation For Dialogue And Prompt Completion", "topic_distr": {"0": 0.0017325225053355098, "1": 0.001414781087078154, "2": 0.13239508867263794, "3": 0.0010357372229918838, "4": 0.07057934254407883, "5": 0.06290552765130997, "6": 0.3788110911846161, "7": 0.07044713944196701, "8": 0.000620506121776998, "9": 0.0005744476220570505, "10": 0.0005347542464733124, "11": 0.0005001919344067574, "12": 0.000469825929030776, "13": 0.032991934567689896, "14": 0.00041895732283592224, "15": 0.00039744155947119, "16": 0.07412571460008621, "17": 0.0912315770983696, "18": 0.0003443836758378893, "19": 0.07846904546022415}}, {"key": "si2019what", "year": "2019", "title": "What Does BERT Learn From Multiple-choice Reading Comprehension Datasets?", "topic_distr": {"0": 0.0014342879876494408, "1": 0.09454971551895142, "2": 0.3889274597167969, "3": 0.1766837239265442, "4": 0.000755920133087784, "5": 0.0006761149852536619, "6": 0.0006115516880527139, "7": 0.000558244064450264, "8": 0.12085859477519989, "9": 0.0004753702087327838, "10": 0.21145522594451904, "11": 0.00041392166167497635, "12": 0.00038879303610883653, "13": 0.00036654085852205753, "14": 0.00034669795422814786, "15": 0.00032889313297346234, "16": 0.00031282773124985397, "17": 0.000298258732073009, "18": 0.00028498636675067246, "19": 0.00027284485986456275}}, {"key": "si2020better", "year": "2020", "title": "Better Robustness By More Coverage: Adversarial Training With Mixup Augmentation For Robust Fine-tuning", "topic_distr": {"0": 0.0011440592352300882, "1": 0.627746045589447, "2": 0.14005553722381592, "3": 0.0006841607973910868, "4": 0.0006034018588252366, "5": 0.0005396973574534059, "6": 0.00048816087655723095, "7": 0.00044560895184986293, "8": 0.0004098805948160589, "9": 0.00037945626536384225, "10": 0.19494177401065826, "11": 0.0003304060082882643, "12": 0.0003103475028183311, "13": 0.0002925850567407906, "14": 0.0002767458208836615, "15": 0.00026253340183757246, "16": 0.0002497094974387437, "17": 0.030394604429602623, "18": 0.00022748556511942297, "19": 0.0002177938149543479}}, {"key": "si2022prompting", "year": "2022", "title": "Prompting GPT-3 To Be Reliable", "topic_distr": {"0": 0.3563235402107239, "1": 0.00109508924651891, "2": 0.0009257982019335032, "3": 0.48732978105545044, "4": 0.0007072059088386595, "5": 0.0006325433496385813, "6": 0.0005721407942473888, "7": 0.0266493558883667, "8": 0.0004803936753887683, "9": 0.05524204671382904, "10": 0.0004140048986300826, "11": 0.00038724683690816164, "12": 0.0003637376066762954, "13": 0.0003429194330237806, "14": 0.0003243552928324789, "15": 0.0003076978900935501, "16": 0.0191667303442955, "17": 0.04821348190307617, "18": 0.00026662065647542477, "19": 0.00025526160607114434}}, {"key": "siddhant2022towards", "year": "2022", "title": "Towards The Next 1000 Languages In Multilingual Machine Translation: Exploring The Synergy Between Supervised And Self-supervised Learning", "topic_distr": {"0": 0.03348459675908089, "1": 0.000989090302027762, "2": 0.22619664669036865, "3": 0.06809493154287338, "4": 0.0006386100430972874, "5": 0.0005711892736144364, "6": 0.0005166454939171672, "7": 0.0004716106050182134, "8": 0.0004337974824011326, "9": 0.0004015978774987161, "10": 0.0003738481318578124, "11": 0.00034968549152836204, "12": 0.15436072647571564, "13": 0.01646609418094158, "14": 0.4953855574131012, "15": 0.00027785246493294835, "16": 0.00026428024284541607, "17": 0.00025197220384143293, "18": 0.00024075954570434988, "19": 0.00023050227900967002}}, {"key": "siddiq2023using", "year": "2023", "title": "Using Large Language Models To Generate Junit Tests: An Empirical Study", "topic_distr": {"0": 0.1884361058473587, "1": 0.001376303960569203, "2": 0.0011633794056251645, "3": 0.5129480361938477, "4": 0.0008887104922905564, "5": 0.0007948862621560693, "6": 0.2885102331638336, "7": 0.0006563093047589064, "8": 0.0006036873091943562, "9": 0.0005588771891780198, "10": 0.0005202597239986062, "11": 0.00048663417692296207, "12": 0.0004570912860799581, "13": 0.0004309300857130438, "14": 0.00040760147385299206, "15": 0.0003866688930429518, "16": 0.0003677813510876149, "17": 0.00035065304837189615, "18": 0.0003350491460878402, "19": 0.0003207747940905392}}, {"key": "sileo2021zero", "year": "2021", "title": "Zero-shot Recommendation As Language Modeling", "topic_distr": {"0": 0.030200578272342682, "1": 0.19833552837371826, "2": 0.0012851275969296694, "3": 0.0011130733182653785, "4": 0.3041842579841614, "5": 0.000878044287674129, "6": 0.1486799120903015, "7": 0.03040236234664917, "8": 0.0006668420974165201, "9": 0.0006173442234285176, "10": 0.0005746867973357439, "11": 0.0005375434993766248, "12": 0.0005049099563620985, "13": 0.0004760119190905243, "14": 0.00045024274731986225, "15": 0.03287523239850998, "16": 0.0004062568477820605, "17": 0.07440531998872757, "18": 0.0003701003734022379, "19": 0.1730366349220276}}, {"key": "silver2023generalized", "year": "2023", "title": "Generalized Planning In PDDL Domains With Pretrained Large Language Models", "topic_distr": {"0": 0.0014024315169081092, "1": 0.001144417910836637, "2": 0.14160190522670746, "3": 0.6790310144424438, "4": 0.0007389535894617438, "5": 0.0006609392585232854, "6": 0.0005978250992484391, "7": 0.08677470684051514, "8": 0.0005019593518227339, "9": 0.00046470024972222745, "10": 0.00043259025551378727, "11": 0.0004046309622935951, "12": 0.00038006636896170676, "13": 0.00035831364220939577, "14": 0.00033891614293679595, "15": 0.00032151094637811184, "16": 0.05511145293712616, "17": 0.0002915641525760293, "18": 0.00027858969406224787, "19": 0.029163504019379616}}, {"key": "sima2023driving", "year": "2023", "title": "Drivelm: Driving With Graph Visual Question Answering", "topic_distr": {"0": 0.001124251284636557, "1": 0.0009178092586807907, "2": 0.08747092634439468, "3": 0.15003520250320435, "4": 0.0005925190052948892, "5": 0.05913860350847244, "6": 0.0004793565603904426, "7": 0.0004375720745883882, "8": 0.07270706444978714, "9": 0.0003726124996319413, "10": 0.0003468656213954091, "11": 0.20740289986133575, "12": 0.06371158361434937, "13": 0.00028730809572152793, "14": 0.0002717545139603317, "15": 0.00025779844145290554, "16": 0.06837916374206543, "17": 0.0002337860787520185, "18": 0.2856190502643585, "19": 0.00021386575826909393}}, {"key": "singer2022make", "year": "2022", "title": "Make-a-video: Text-to-video Generation Without Text-video Data", "topic_distr": {"0": 0.0013859964674338698, "1": 0.13017034530639648, "2": 0.12123744189739227, "3": 0.0008286104421131313, "4": 0.0007308003841899335, "5": 0.038940150290727615, "6": 0.000591229007113725, "7": 0.17309394478797913, "8": 0.0004964209510944784, "9": 0.00045957296970300376, "10": 0.0004278172564227134, "11": 0.0004001664638053626, "12": 0.00037587288534268737, "13": 0.00035436017788015306, "14": 0.0003351766790729016, "15": 0.0003179635386914015, "16": 0.00030243201763369143, "17": 0.00028834716067649424, "18": 0.5289996266365051, "19": 0.0002637778234202415}}, {"key": "singh2019cross", "year": "2019", "title": "XLDA: Cross-lingual Data Augmentation For Natural Language Inference And Question Answering", "topic_distr": {"0": 0.0017324114451184869, "1": 0.22027060389518738, "2": 0.1898176223039627, "3": 0.10286397486925125, "4": 0.0009134247666224837, "5": 0.0008169910288415849, "6": 0.0007389751845039427, "7": 0.0006745603168383241, "8": 0.06414666771888733, "9": 0.0005744187510572374, "10": 0.0005347274127416313, "11": 0.0005001667886972427, "12": 0.09921091049909592, "13": 0.0004429136461112648, "14": 0.2691395580768585, "15": 0.00039742159424349666, "16": 0.00037800881545990705, "17": 0.0003604041994549334, "18": 0.000344366388162598, "19": 0.04614190757274628}}, {"key": "singh2020are", "year": "2020", "title": "Are We Pretraining It Right? Digging Deeper Into Visio-linguistic Pretraining", "topic_distr": {"0": 0.04812585934996605, "1": 0.001028886646963656, "2": 0.1727953404188156, "3": 0.15561407804489136, "4": 0.0006643882370553911, "5": 0.0005942463758401573, "6": 0.0005375008331611753, "7": 0.0004906480317004025, "8": 0.0004513085004873574, "9": 0.0004178090894129127, "10": 0.0003889391664415598, "11": 0.0003638011694420129, "12": 0.0003417152911424637, "13": 0.0003221575461793691, "14": 0.000304717366816476, "15": 0.00028906847001053393, "16": 0.0002749483974184841, "17": 0.11112382262945175, "18": 0.15507853031158447, "19": 0.35079219937324524}}, {"key": "singh2021foundational", "year": "2021", "title": "FLAVA: A Foundational Language And Vision Alignment Model", "topic_distr": {"0": 0.0027107587084174156, "1": 0.08085942268371582, "2": 0.0018716431222856045, "3": 0.0016210690373554826, "4": 0.001429711701348424, "5": 0.0012787727173417807, "6": 0.0011566606117412448, "7": 0.0010558371432125568, "8": 0.0009711814345791936, "9": 0.0008990932838059962, "10": 0.0008369674324057996, "11": 0.0007828723755665123, "12": 0.06742788106203079, "13": 0.000693258480168879, "14": 0.08390113711357117, "15": 0.000622053281404078, "16": 0.0005916679510846734, "17": 0.0005641127936542034, "18": 0.6459219455718994, "19": 0.10480398684740067}}, {"key": "singh2021nlp", "year": "2021", "title": "The NLP Cookbook: Modern Recipes For Transformer Based Deep Learning Architectures", "topic_distr": {"0": 0.0885346457362175, "1": 0.0007602538680657744, "2": 0.08063796162605286, "3": 0.0005565538886003196, "4": 0.0004908578121103346, "5": 0.012707334943115711, "6": 0.00039711076533421874, "7": 0.000362495455192402, "8": 0.0003334310313221067, "9": 0.03377475589513779, "10": 0.20613470673561096, "11": 0.0002687798114493489, "12": 0.22976422309875488, "13": 0.19021116197109222, "14": 0.036807768046855927, "15": 0.06918583065271378, "16": 0.0485161729156971, "17": 0.00019367413187865168, "18": 0.00018505573098082095, "19": 0.00017717164882924408}}, {"key": "singh2022generating", "year": "2022", "title": "Progprompt: Generating Situated Robot Task Plans Using Large Language Models", "topic_distr": {"0": 0.0013266645837575197, "1": 0.0010833078995347023, "2": 0.000915858312509954, "3": 0.3324827551841736, "4": 0.015301323495805264, "5": 0.0006257481873035431, "6": 0.000565994530916214, "7": 0.12954697012901306, "8": 0.00047523301327601075, "9": 0.0004399577737785876, "10": 0.0004095574258826673, "11": 0.42008471488952637, "12": 0.00035983012639917433, "13": 0.00033923558657988906, "14": 0.00032087089493870735, "15": 0.00030439242254942656, "16": 0.03520727530121803, "17": 0.059694044291973114, "18": 0.00026375646120868623, "19": 0.0002525194431655109}}, {"key": "singh2024rethinking", "year": "2024", "title": "Rethinking Interpretability In The Era Of Large Language Models", "topic_distr": {"0": 0.09396485239267349, "1": 0.001083485083654523, "2": 0.10064148157835007, "3": 0.21971821784973145, "4": 0.0006996498559601605, "5": 0.17188537120819092, "6": 0.0005660278256982565, "7": 0.0005166883929632604, "8": 0.0004752609529532492, "9": 0.37032654881477356, "10": 0.000409581494750455, "11": 0.00038310931995511055, "12": 0.0003598512848839164, "13": 0.03726267069578171, "14": 0.0003208897542208433, "15": 0.000304410292301327, "16": 0.0002895408251788467, "17": 0.0002760563511401415, "18": 0.00026377197355031967, "19": 0.0002525342861190438}}, {"key": "singha2023visual", "year": "2023", "title": "Applenet: Visual Attention Parameterized Prompt Learning For Few-shot Remote Sensing Image Generalization Using CLIP", "topic_distr": {"0": 0.0011452238541096449, "1": 0.000934311596211046, "2": 0.0007899029296822846, "3": 0.0006841403665021062, "4": 0.0006033846293576062, "5": 0.0005396822234615684, "6": 0.00048814713954925537, "7": 0.06267141550779343, "8": 0.000409869069699198, "9": 0.04259853437542915, "10": 0.00035322652547620237, "11": 0.0003303967241663486, "12": 0.0003103387716691941, "13": 0.07809684425592422, "14": 0.0002767380210570991, "15": 0.00026252600946463645, "16": 0.0002497024543117732, "17": 0.2514747977256775, "18": 0.5575630068778992, "19": 0.00021778768859803677}}, {"key": "singhal2022large", "year": "2022", "title": "Large Language Models Encode Clinical Knowledge", "topic_distr": {"0": 0.10026866942644119, "1": 0.0006835523527115583, "2": 0.0005778256454505026, "3": 0.31326159834861755, "4": 0.00044139521196484566, "5": 0.00039479503175243735, "6": 0.0003570954722817987, "7": 0.02623920887708664, "8": 0.07270944863557816, "9": 0.05579611286520958, "10": 0.00025839664158411324, "11": 0.00024169590324163437, "12": 0.24410054087638855, "13": 0.10185184329748154, "14": 0.00020244282495696098, "15": 0.00019204628188163042, "16": 0.03797562047839165, "17": 0.04412197694182396, "18": 0.00016640838293824345, "19": 0.00015931874804664403}}, {"key": "singhal2023towards", "year": "2023", "title": "Towards Expert-level Medical Question Answering With Large Language Models", "topic_distr": {"0": 0.0009251057635992765, "1": 0.03874462470412254, "2": 0.08503736555576324, "3": 0.20789338648319244, "4": 0.02143576182425022, "5": 0.0004357673169579357, "6": 0.000394155242247507, "7": 0.00035979755921289325, "8": 0.22607123851776123, "9": 0.0437227226793766, "10": 0.0002852133475244045, "11": 0.0002667793887667358, "12": 0.2729714810848236, "13": 0.10026778280735016, "14": 0.00022345258912537247, "15": 0.00021197707974351943, "16": 0.000201622664462775, "17": 0.00019223270646762103, "18": 0.00018367843586020172, "19": 0.00017585304158274084}}, {"key": "sinha2020unnatural", "year": "2020", "title": "Unnatural Language Inference", "topic_distr": {"0": 0.35474130511283875, "1": 0.05902918428182602, "2": 0.0011038322700187564, "3": 0.311187744140625, "4": 0.0008432009490206838, "5": 0.0007541807135567069, "6": 0.0006821625865995884, "7": 0.0006226999103091657, "8": 0.0005727726384066045, "9": 0.0005302572972141206, "10": 0.21076034009456635, "11": 0.00046171381836757064, "12": 0.056244246661663055, "13": 0.0004088623099960387, "14": 0.00038672832306474447, "15": 0.0003668677236419171, "16": 0.0003489473892841488, "17": 0.0003326962178107351, "18": 0.00031789139029569924, "19": 0.0003043480101041496}}, {"key": "siriwardhana2022improving", "year": "2022", "title": "Improving The Domain Adaptation Of Retrieval Augmented Generation (RAG) Models For Open Domain Question Answering", "topic_distr": {"0": 0.0011986522004008293, "1": 0.000979329808615148, "2": 0.21344567835330963, "3": 0.0007170067983679473, "4": 0.0006323724519461393, "5": 0.0005656101275235415, "6": 0.0005115990643389523, "7": 0.0004670040507335216, "8": 0.19078753888607025, "9": 0.0003976751759182662, "10": 0.022659145295619965, "11": 0.00034626986598595977, "12": 0.09101603925228119, "13": 0.06690718978643417, "14": 0.00029003326199017465, "15": 0.1311189830303192, "16": 0.2772437036037445, "17": 0.0002495110093150288, "18": 0.00023840786889195442, "19": 0.00022825079213362187}}, {"key": "sison2023more", "year": "2023", "title": "Chatgpt: More Than A Weapon Of Mass Deception, Ethical Challenges And Responses From The Human-centered Artificial Intelligence (HCAI) Perspective", "topic_distr": {"0": 0.27864328026771545, "1": 0.04746465012431145, "2": 0.0009258414502255619, "3": 0.07832693308591843, "4": 0.0007072423468343914, "5": 0.0006325755384750664, "6": 0.0005721698980778456, "7": 0.0005222950712777674, "8": 0.00048041812260635197, "9": 0.5260761380195618, "10": 0.0004140259698033333, "11": 0.00038726654020138085, "12": 0.0003637561167124659, "13": 0.00034293686621822417, "14": 0.00032437179470434785, "15": 0.06272242963314056, "16": 0.00029268270009197295, "17": 0.00027905189199373126, "18": 0.0002666342188604176, "19": 0.00025527458637952805}}, {"key": "sivarajkumar2022zero", "year": "2022", "title": "Healthprompt: A Zero-shot Learning Paradigm For Clinical Natural Language Processing", "topic_distr": {"0": 0.0016011109109967947, "1": 0.07098085433244705, "2": 0.20365920662879944, "3": 0.0009560714825056493, "4": 0.08737026900053024, "5": 0.000754194101318717, "6": 0.000682174926623702, "7": 0.0006227112025953829, "8": 0.0005727829993702471, "9": 0.0005302669014781713, "10": 0.0004936263430863619, "11": 0.0004617221711669117, "12": 0.00043369163176976144, "13": 0.18971364200115204, "14": 0.0003867353079840541, "15": 0.1757059395313263, "16": 0.0003489537048153579, "17": 0.26410380005836487, "18": 0.00031789715285412967, "19": 0.0003043535107281059}}, {"key": "skreta2023errors", "year": "2023", "title": "Errors Are Useful Prompts: Instruction Guided Task Programming With Verifier-assisted Iterative Prompting", "topic_distr": {"0": 0.001640874776057899, "1": 0.001340303337201476, "2": 0.0011328895343467593, "3": 0.6213557720184326, "4": 0.0008653996046632528, "5": 0.0007740356959402561, "6": 0.0007001218618825078, "7": 0.19010087847709656, "8": 0.0005878520314581692, "9": 0.0005442173569463193, "10": 0.0005066128796897829, "11": 0.17747463285923004, "12": 0.0004451013810466975, "13": 0.00041962641989812255, "14": 0.0003969097160734236, "15": 0.0003765262372326106, "16": 0.00035813412978313863, "17": 0.0003414551028981805, "18": 0.00032626051688566804, "19": 0.00031236058566719294}}, {"key": "small2023opportunities", "year": "2023", "title": "Opportunities And Risks Of Llms For Scalable Deliberation With Polis", "topic_distr": {"0": 0.0015044223982840776, "1": 0.2446938008069992, "2": 0.0010373288532719016, "3": 0.0008984539890661836, "4": 0.0007923961384221911, "5": 0.0007087391568347812, "6": 0.043626438826322556, "7": 0.032036807388067245, "8": 0.0005382616072893143, "9": 0.6705402731895447, "10": 0.0004638756799977273, "11": 0.00043389436905272305, "12": 0.0004075532197020948, "13": 0.00038422728539444506, "14": 0.0003634269523900002, "15": 0.0003447629860602319, "16": 0.00032792240381240845, "17": 0.0003126504016108811, "18": 0.0002987376064993441, "19": 0.0002860102686099708}}, {"key": "smith2020can", "year": "2020", "title": "Can You Put It All Together: Evaluating Conversational Agents' Ability To Blend Skills", "topic_distr": {"0": 0.13129913806915283, "1": 0.0010288853663951159, "2": 0.39438506960868835, "3": 0.12583380937576294, "4": 0.000664317631162703, "5": 0.0005941824056208134, "6": 0.15417033433914185, "7": 0.000490595237351954, "8": 0.00045125995529815555, "9": 0.00041776415309868753, "10": 0.00038889734423719347, "11": 0.1879909783601761, "12": 0.00034167853300459683, "13": 0.0003221229126211256, "14": 0.0003046845959033817, "15": 0.00028903738711960614, "16": 0.00027491882792674005, "17": 0.0002621153253130615, "18": 0.00025045129586942494, "19": 0.0002397811331320554}}, {"key": "smith2020controlling", "year": "2020", "title": "Controlling Style In Generated Dialogue", "topic_distr": {"0": 0.04348712041974068, "1": 0.0011195415863767266, "2": 0.2931027114391327, "3": 0.0008195245754905045, "4": 0.0007227828027680516, "5": 0.06839325278997421, "6": 0.13895493745803833, "7": 0.23798564076423645, "8": 0.0004909750423394144, "9": 0.00045453128404915333, "10": 0.00042312394361943007, "11": 0.06290212273597717, "12": 0.0003717494255397469, "13": 0.14900830388069153, "14": 0.0003314996720291674, "15": 0.0003144753572996706, "16": 0.0002991142391692847, "17": 0.0002851838944479823, "18": 0.0002724933438003063, "19": 0.00026088408776558936}}, {"key": "smith2022coda", "year": "2022", "title": "Coda-prompt: Continual Decomposed Attention-based Prompting For Rehearsal-free Continual Learning", "topic_distr": {"0": 0.0010941865621134639, "1": 0.0008935944060795009, "2": 0.46018946170806885, "3": 0.0006541170296259224, "4": 0.0005769028211943805, "5": 0.0005159970605745912, "6": 0.0004667236062232405, "7": 0.0004260403220541775, "8": 0.000391880952520296, "9": 0.0003627926926128566, "10": 0.00033772431197576225, "11": 0.00031589643913321197, "12": 0.0002967187901958823, "13": 0.08700143545866013, "14": 0.00026459270156919956, "15": 0.00025100441416725516, "16": 0.17141631245613098, "17": 0.2223956286907196, "18": 0.05194080248475075, "19": 0.00020822953956667334}}, {"key": "smith2022using", "year": "2022", "title": "Using Deepspeed And Megatron To Train Megatron-turing NLG 530B, A Large-scale Generative Language Model", "topic_distr": {"0": 0.0014335496816784143, "1": 0.001170752220787108, "2": 0.0009895728435367346, "3": 0.0008570951176807284, "4": 0.0007559214718639851, "5": 0.0006761160911992192, "6": 0.0006115526775829494, "7": 0.0005582449375651777, "8": 0.0005134855746291578, "9": 0.07126860320568085, "10": 0.13585640490055084, "11": 0.09601080417633057, "12": 0.29029765725135803, "13": 0.2751469612121582, "14": 0.00034669850720092654, "15": 0.1223376989364624, "16": 0.00031282822601497173, "17": 0.0002982591977342963, "18": 0.0002849868033081293, "19": 0.0002728452964220196}}, {"key": "so2019evolved", "year": "2019", "title": "The Evolved Transformer", "topic_distr": {"0": 0.0015026346081867814, "1": 0.0012272205203771591, "2": 0.27820509672164917, "3": 0.0008984441519714892, "4": 0.0007923895609565079, "5": 0.000708733918145299, "6": 0.01920466125011444, "7": 0.000585176341701299, "8": 0.0005382576491683722, "9": 0.0004983042599633336, "10": 0.22894832491874695, "11": 0.0004338911676313728, "12": 0.00040755022200755775, "13": 0.18025898933410645, "14": 0.28422027826309204, "15": 0.0003447604540269822, "16": 0.00032791998819448054, "17": 0.000312648102408275, "18": 0.00029873542371205986, "19": 0.00028600814403034747}}, {"key": "so2021searching", "year": "2021", "title": "Primer: Searching For Efficient Transformers For Language Modeling", "topic_distr": {"0": 0.0010668067261576653, "1": 0.0008706997032277286, "2": 0.25585901737213135, "3": 0.0804392546415329, "4": 0.0005621783784590662, "5": 0.0005028272862546146, "6": 0.0004548115539364517, "7": 0.0004151666071265936, "8": 0.00038187907193787396, "9": 0.00035353322164155543, "10": 0.1979111284017563, "11": 0.0003078338922932744, "12": 0.0002891457115765661, "13": 0.40131086111068726, "14": 0.03534148260951042, "15": 0.012689228169620037, "16": 0.0002326502581126988, "17": 0.010596642270684242, "18": 0.0002119445998687297, "19": 0.00020291496184654534}}, {"key": "sohail2023decoding", "year": "2023", "title": "Decoding Chatgpt: A Taxonomy Of Existing Research, Current Challenges, And Possible Future Directions", "topic_distr": {"0": 0.06854110211133957, "1": 0.0007894063019193709, "2": 0.0006673875614069402, "3": 0.0005780447972938418, "4": 0.0005098125548101962, "5": 0.00045598988072015345, "6": 0.00041244673775509, "7": 0.010775446891784668, "8": 0.0003463077882770449, "9": 0.5494480729103088, "10": 0.01954675279557705, "11": 0.00027915977989323437, "12": 0.33307504653930664, "13": 0.0002472048799972981, "14": 0.00023382231302093714, "15": 0.013305607251822948, "16": 0.00021097934222780168, "17": 0.00020115361257921904, "18": 0.0001922023802762851, "19": 0.00018401382840238512}}, {"key": "sohn2022visual", "year": "2022", "title": "Visual Prompt Tuning For Generative Transfer Learning", "topic_distr": {"0": 0.001449510338716209, "1": 0.001184283522889018, "2": 0.001001005875878036, "3": 0.0008670088136568666, "4": 0.00076466822065413, "5": 0.0006839393172413111, "6": 0.0006186288665048778, "7": 0.000564704358112067, "8": 0.000519427063409239, "9": 0.00048087138566188514, "10": 0.16539964079856873, "11": 0.0004187117738183588, "12": 0.0003932923427782953, "13": 0.00037078262539580464, "14": 0.05642115697264671, "15": 0.10422118753194809, "16": 0.07961347699165344, "17": 0.27068302035331726, "18": 0.3140687346458435, "19": 0.0002760023344308138}}, {"key": "solaiman2021process", "year": "2021", "title": "Process For Adapting Language Models To Society (PALMS) With Values-targeted Datasets", "topic_distr": {"0": 0.3226919174194336, "1": 0.0011709578102454543, "2": 0.19000370800495148, "3": 0.3032303750514984, "4": 0.0007559879450127482, "5": 0.0006761751137673855, "6": 0.0006116059375926852, "7": 0.095331110060215, "8": 0.0005135303363204002, "9": 0.00047541235107928514, "10": 0.00044256215915083885, "11": 0.00041395839070901275, "12": 0.00038882752414792776, "13": 0.0814492255449295, "14": 0.0003467286878731102, "15": 0.00032892229501158, "16": 0.0003128554963041097, "17": 0.0002982851874548942, "18": 0.0002850116288755089, "19": 0.0002728690451476723}}, {"key": "soldaini2020cascade", "year": "2020", "title": "The Cascade Transformer: An Application For Efficient Answer Sentence Selection", "topic_distr": {"0": 0.0017318585887551308, "1": 0.0014145984314382076, "2": 0.2755224108695984, "3": 0.001035721623338759, "4": 0.0009134598658420146, "5": 0.0008170224027708173, "6": 0.0007390034152194858, "7": 0.0006745861028321087, "8": 0.06128917261958122, "9": 0.0005744406953454018, "10": 0.23556791245937347, "11": 0.0005001858808100224, "12": 0.00046982025378383696, "13": 0.37347474694252014, "14": 0.043465111404657364, "15": 0.0003974367573391646, "16": 0.0003780232509598136, "17": 0.00036041796556673944, "18": 0.000344379513990134, "19": 0.00032970766187645495}}, {"key": "soltan2022alexatm", "year": "2022", "title": "Alexatm 20B: Few-shot Learning Using A Large-scale Multilingual Seq2seq Model", "topic_distr": {"0": 0.0020460456144064665, "1": 0.036009833216667175, "2": 0.0014114760560914874, "3": 0.15269850194454193, "4": 0.0010781893506646156, "5": 0.0009643613011576235, "6": 0.0008722729398868978, "7": 0.0007962387753650546, "8": 0.0007323973695747554, "9": 0.0006780335097573698, "10": 0.08475526422262192, "11": 0.0005903877899982035, "12": 0.0005545461317524314, "13": 0.2918802797794342, "14": 0.3216891884803772, "15": 0.00046910924720577896, "16": 0.00044619475374929607, "17": 0.1015319898724556, "18": 0.00040648382855579257, "19": 0.00038916608900763094}}, {"key": "soman2023biomedical", "year": "2023", "title": "Biomedical Knowledge Graph-optimized Prompt Generation For Large Language Models", "topic_distr": {"0": 0.0008973603835329413, "1": 0.0007329233339987695, "2": 0.05545937269926071, "3": 0.29302605986595154, "4": 0.0004731826775241643, "5": 0.00042322720400989056, "6": 0.01106205489486456, "7": 0.016395747661590576, "8": 0.07450259476900101, "9": 0.00029756707954220474, "10": 0.0002770056889858097, "11": 0.00025910220574587584, "12": 0.00024337245849892497, "13": 0.17170503735542297, "14": 0.0002170222287531942, "15": 0.20909331738948822, "16": 0.11352908611297607, "17": 0.051056742668151855, "18": 0.00017839267093222588, "19": 0.000170792467542924}}, {"key": "soman2023observations", "year": "2023", "title": "Observations On Llms For Telecom Domain: Capabilities And Limitations", "topic_distr": {"0": 0.001783019513823092, "1": 0.10903464257717133, "2": 0.0012298496440052986, "3": 0.0010652290657162666, "4": 0.07755748182535172, "5": 0.0008402998792007565, "6": 0.09631042927503586, "7": 0.0006938055739738047, "8": 0.000638177094515413, "9": 0.4580613076686859, "10": 0.0005499831750057638, "11": 0.000514436571393162, "12": 0.24897338449954987, "13": 0.0004555499763227999, "14": 0.0004308885254431516, "15": 0.0004087600391358137, "16": 0.00038879341445863247, "17": 0.0003706865245476365, "18": 0.00035419114283286035, "19": 0.00033910127240233123}}, {"key": "song2017unified", "year": "2017", "title": "A Unified Query-based Generative Model For Question Generation And Question Answering", "topic_distr": {"0": 0.01749764010310173, "1": 0.0011073757195845246, "2": 0.2863002121448517, "3": 0.0008105109445750713, "4": 0.0007148375152610242, "5": 0.0006393683725036681, "6": 0.0005783141241408885, "7": 0.05708228796720505, "8": 0.3605935573577881, "9": 0.0004495339817367494, "10": 0.09246110916137695, "11": 0.08752495795488358, "12": 0.0003676622873172164, "13": 0.0003466194903012365, "14": 0.00032785505754873157, "15": 0.09209274500608444, "16": 0.0002958256518468261, "17": 0.0002820484805852175, "18": 0.00026949745370075107, "19": 0.00025801584706641734}}, {"key": "song2019exploiting", "year": "2019", "title": "Exploiting Persona Information For Diverse Generation Of Conversational Responses", "topic_distr": {"0": 0.2137455940246582, "1": 0.06595418602228165, "2": 0.0010373004479333758, "3": 0.0008984211599454284, "4": 0.0007923715165816247, "5": 0.0007087183184921741, "6": 0.4908992648124695, "7": 0.08854583650827408, "8": 0.0005382456001825631, "9": 0.0004982930840924382, "10": 0.0004638618556782603, "11": 0.00043388144695200026, "12": 0.00040754108340479434, "13": 0.00038421584758907557, "14": 0.0003634161257650703, "15": 0.13310351967811584, "16": 0.000327912624925375, "17": 0.00031264108838513494, "18": 0.00029872870072722435, "19": 0.000286001741187647}}, {"key": "song2019generating", "year": "2019", "title": "Generating Persona Consistent Dialogues By Exploiting Natural Language Inference", "topic_distr": {"0": 0.09051543474197388, "1": 0.00114435947034508, "2": 0.13336144387722015, "3": 0.0008378429338335991, "4": 0.2820785641670227, "5": 0.0006609310512430966, "6": 0.37314921617507935, "7": 0.0005457070074044168, "8": 0.0005019529489800334, "9": 0.0004646943125408143, "10": 0.0004325847257860005, "11": 0.11376579105854034, "12": 0.0003800615086220205, "13": 0.0003583090438041836, "14": 0.0003389118064660579, "15": 0.00032150684273801744, "16": 0.0003058022412005812, "17": 0.00029156042728573084, "18": 0.0002785861142911017, "19": 0.0002667173102963716}}, {"key": "song2019masked", "year": "2019", "title": "MASS: Masked Sequence To Sequence Pre-training For Language Generation", "topic_distr": {"0": 0.0015205425443127751, "1": 0.001241934485733509, "2": 0.19958911836147308, "3": 0.0009094043052755296, "4": 0.0008020559325814247, "5": 0.0007173799676820636, "6": 0.04402120038866997, "7": 0.11529871076345444, "8": 0.0005448240553960204, "9": 0.0005043832352384925, "10": 0.42134225368499756, "11": 0.0004391843394841999, "12": 0.000412522058468312, "13": 0.00038891175063326955, "14": 0.14119292795658112, "15": 0.032813508063554764, "16": 0.01642022654414177, "17": 0.0003164622175972909, "18": 0.0003023797762580216, "19": 0.021222054958343506}}, {"key": "song2020delete", "year": "2020", "title": "Generate, Delete And Rewrite: A Three-stage Framework For Improving Persona Consistency Of Dialogue Generation", "topic_distr": {"0": 0.19569836556911469, "1": 0.0016426712973043323, "2": 0.17889778316020966, "3": 0.0012027337215840816, "4": 0.07545949518680573, "5": 0.05870416760444641, "6": 0.23722834885120392, "7": 0.2449287325143814, "8": 0.0007205571746453643, "9": 0.0006670721923001111, "10": 0.0006209785933606327, "11": 0.0005808433634229004, "12": 0.0005455811624415219, "13": 0.0005143553134985268, "14": 0.00048651042743586004, "15": 0.00046152545837685466, "16": 0.00043898142757825553, "17": 0.00041853717993944883, "18": 0.00039991247467696667, "19": 0.00038287468487396836}}, {"key": "song2020kvl", "year": "2020", "title": "KVL-BERT: Knowledge Enhanced Visual-and-linguistic BERT For Visual Commonsense Reasoning", "topic_distr": {"0": 0.06638692319393158, "1": 0.0008347676484845579, "2": 0.0007057489128783345, "3": 0.036690838634967804, "4": 0.0005391072481870651, "5": 0.00048219162272289395, "6": 0.00043614639434963465, "7": 0.00039812849718146026, "8": 0.19029468297958374, "9": 0.00033902449649758637, "10": 0.1705717295408249, "11": 0.02356169931590557, "12": 0.00027727941051125526, "13": 0.00026140958652831614, "14": 0.0002472580235917121, "15": 0.00023455997870769352, "16": 0.2504284679889679, "17": 0.00021271214063744992, "18": 0.2569027543067932, "19": 0.00019458748283796012}}, {"key": "song2021bert", "year": "2021", "title": "Bob: BERT Over BERT For Training Persona-based Dialogue Models From Limited Personalized Data", "topic_distr": {"0": 0.16336800158023834, "1": 0.23095731437206268, "2": 0.0012298875954002142, "3": 0.001065227435901761, "4": 0.10628850758075714, "5": 0.06628412008285522, "6": 0.18157973885536194, "7": 0.0006938074948266149, "8": 0.0006381788989529014, "9": 0.0005908086313866079, "10": 0.19321440160274506, "11": 0.050858817994594574, "12": 0.0004832071717828512, "13": 0.00045555125689134, "14": 0.0004308897478040308, "15": 0.000408761203289032, "16": 0.0003887945204041898, "17": 0.00037068757228553295, "18": 0.00035419216146692634, "19": 0.0003391022328287363}}, {"key": "song2022clip", "year": "2022", "title": "CLIP Models Are Few-shot Learners: Empirical Studies On VQA And Visual Entailment", "topic_distr": {"0": 0.0018345462158322334, "1": 0.0014976108213886619, "2": 0.0012660574866458774, "3": 0.21259960532188416, "4": 0.0009671199368312955, "5": 0.000865018053445965, "6": 0.0007824161439202726, "7": 0.0007142146350815892, "8": 0.04630992189049721, "9": 0.0006081861793063581, "10": 0.0005661615869030356, "11": 0.0005295692826621234, "12": 0.0004974198527634144, "13": 0.0004689504858106375, "14": 0.0004435635928530246, "15": 0.00042078419937752187, "16": 0.0004002302302978933, "17": 0.07009788602590561, "18": 0.6587817072868347, "19": 0.00034907631925307214}}, {"key": "song2022llm", "year": "2022", "title": "Llm-planner: Few-shot Grounded Planning For Embodied Agents With Large Language Models", "topic_distr": {"0": 0.0012987974332645535, "1": 0.05255209654569626, "2": 0.0008968072943389416, "3": 0.2645103633403778, "4": 0.0006850563804619014, "5": 0.000612732139416039, "6": 0.0005542213330045342, "7": 0.0005059110699221492, "8": 0.00046534775174222887, "9": 0.0004308062489144504, "10": 0.00040103826904669404, "11": 0.3348340392112732, "12": 0.058380067348480225, "13": 0.13101431727409363, "14": 0.00031419648439623415, "15": 0.00029806079692207277, "16": 0.00028350146021693945, "17": 0.0002702982455957681, "18": 0.15144504606723785, "19": 0.00024726681294851005}}, {"key": "song2023fast", "year": "2023", "title": "Powerinfer: Fast Large Language Model Serving With A Consumer-grade GPU", "topic_distr": {"0": 0.0015028368216007948, "1": 0.001227349042892456, "2": 0.1282843053340912, "3": 0.1836073398590088, "4": 0.0007924562669359148, "5": 0.0007087923004291952, "6": 0.0006411086651496589, "7": 0.0005852245958521962, "8": 0.0005383020616136491, "9": 0.0004983453545719385, "10": 0.000463910517282784, "11": 0.0004339269653428346, "12": 0.0004075838369317353, "13": 0.48572418093681335, "14": 0.00036345425178296864, "15": 0.036696720868349075, "16": 0.00032794702565297484, "17": 0.15661147236824036, "18": 0.00029876004555262625, "19": 0.0002860317472368479}}, {"key": "song2023from", "year": "2023", "title": "Moviechat: From Dense Token To Sparse Memory For Long Video Understanding", "topic_distr": {"0": 0.0018333487678319216, "1": 0.0014978440012782812, "2": 0.12421881407499313, "3": 0.001096635009162128, "4": 0.044008854776620865, "5": 0.0008650755626149476, "6": 0.0007824680651538074, "7": 0.0007142620161175728, "8": 0.0006569933611899614, "9": 0.0006082265172153711, "10": 0.1840200126171112, "11": 0.0005296043818816543, "12": 0.0004974528565071523, "13": 0.1714766025543213, "14": 0.00044359301682561636, "15": 0.0004208120808470994, "16": 0.0004002567729912698, "17": 0.00038161600241437554, "18": 0.46519845724105835, "19": 0.0003490994859021157}}, {"key": "song2023preference", "year": "2023", "title": "Preference Ranking Optimization For Human Alignment", "topic_distr": {"0": 0.2495492845773697, "1": 0.0010499457130208611, "2": 0.07385333627462387, "3": 0.08928950875997543, "4": 0.3836412727832794, "5": 0.0006064442568458617, "6": 0.05333909019827843, "7": 0.0005007194704376161, "8": 0.00046057242434471846, "9": 0.05523562803864479, "10": 0.00039692287100479007, "11": 0.0003712688630912453, "12": 0.00034872963442467153, "13": 0.08970283716917038, "14": 0.00031097224564291537, "15": 0.00029500212986022234, "16": 0.0002805922122206539, "17": 0.00026752447593025863, "18": 0.0002556197578087449, "19": 0.0002447293954901397}}, {"key": "sood2020improving", "year": "2020", "title": "Improving Natural Language Processing Tasks With Human Gaze-guided Neural Attention", "topic_distr": {"0": 0.10743142664432526, "1": 0.0009889495559036732, "2": 0.551978349685669, "3": 0.0007239860715344548, "4": 0.0006385267479345202, "5": 0.0005711150588467717, "6": 0.000516578322276473, "7": 0.0004715493123512715, "8": 0.009096094407141209, "9": 0.00040154566522687674, "10": 0.07185973972082138, "11": 0.0003496400313451886, "12": 0.00032841385109350085, "13": 0.0356772281229496, "14": 0.00029285610071383417, "15": 0.1864059418439865, "16": 0.03154487535357475, "17": 0.00025193943292833865, "18": 0.00024072824453469366, "19": 0.0002304723166162148}}, {"key": "soong2023improving", "year": "2023", "title": "Improving Accuracy Of GPT-3/4 Results On Biomedical Data Using A Retrieval-augmented Language Model", "topic_distr": {"0": 0.20667679607868195, "1": 0.0009345804573968053, "2": 0.0007898534531705081, "3": 0.34886085987091064, "4": 0.0006033544195815921, "5": 0.0005396559718064964, "6": 0.13248422741889954, "7": 0.0004455747257452458, "8": 0.029315395280718803, "9": 0.00037942713242955506, "10": 0.0003532093542162329, "11": 0.000330380629748106, "12": 0.20497986674308777, "13": 0.000292562588583678, "14": 0.00027672454598359764, "15": 0.07180453091859818, "16": 0.0002496903180144727, "17": 0.0002380617370363325, "18": 0.00022746810282114893, "19": 0.00021777709480375051}}, {"key": "sordoni2016iterative", "year": "2016", "title": "Iterative Alternating Neural Attention For Machine Reading", "topic_distr": {"0": 0.002709233434870839, "1": 0.0022134401369839907, "2": 0.6933817863464355, "3": 0.0016209095483645797, "4": 0.0014295803848654032, "5": 0.0012786550214514136, "6": 0.0011565543245524168, "7": 0.0010557400528341532, "8": 0.2586289942264557, "9": 0.0008990105707198381, "10": 0.000836890481878072, "11": 0.0007828003726899624, "12": 0.0007352776010520756, "13": 0.0006931946845725179, "14": 0.0006556682055816054, "15": 0.02971162460744381, "16": 0.0005916135269217193, "17": 0.0005640609306283295, "18": 0.0005389605066739023, "19": 0.0005159987485967577}}, {"key": "sridhar2023harnessing", "year": "2023", "title": "Harnessing Llms In Curricular Design: Using GPT-4 To Support Authoring Of Learning Objectives", "topic_distr": {"0": 0.2640601396560669, "1": 0.0009519682498648763, "2": 0.0008047319133765996, "3": 0.12287024408578873, "4": 0.0006147189415059984, "5": 0.014175767078995705, "6": 0.000497317174449563, "7": 0.0004539670771919191, "8": 0.00041756860446184874, "9": 0.28192633390426636, "10": 0.04016795754432678, "11": 0.12918616831302643, "12": 0.0003161685890518129, "13": 0.00029807299142703414, "14": 0.00028193663456477225, "15": 0.07088222354650497, "16": 0.013474635779857635, "17": 0.058166421949863434, "18": 0.00023175243404693902, "19": 0.00022187891590874642}}, {"key": "srinivasan2021predicting", "year": "2021", "title": "Predicting The Performance Of Multilingual NLP Models", "topic_distr": {"0": 0.0017825757386162877, "1": 0.00145496625918895, "2": 0.5155395269393921, "3": 0.001065257005393505, "4": 0.0009395117522217333, "5": 0.0008403226966038346, "6": 0.0007600790122523904, "7": 0.0006938245496712625, "8": 0.0006381945568136871, "9": 0.11403854936361313, "10": 0.0246786717325449, "11": 0.0005144505994394422, "12": 0.2474507838487625, "13": 0.0004555624327622354, "14": 0.08728615939617157, "15": 0.0004087712150067091, "16": 0.00038880406646057963, "17": 0.0003706966817844659, "18": 0.00035420083440840244, "19": 0.00033911055652424693}}, {"key": "srinivasan2022continual", "year": "2022", "title": "Climb: A Continual Learning Benchmark For Vision-and-language Tasks", "topic_distr": {"0": 0.11927519738674164, "1": 0.0014978721737861633, "2": 0.0012661986984312534, "3": 0.0010966826230287552, "4": 0.0009672301239334047, "5": 0.0008651151438243687, "6": 0.000782503979280591, "7": 0.0007142947870306671, "8": 0.0006570235709659755, "9": 0.0006082544568926096, "10": 0.03482060134410858, "11": 0.22348327934741974, "12": 0.12769952416419983, "13": 0.00046900310553610325, "14": 0.0004436133895069361, "15": 0.0004208314057905227, "16": 0.11902937293052673, "17": 0.13303418457508087, "18": 0.23252014815807343, "19": 0.0003491154930088669}}, {"key": "srivastava2022beyond", "year": "2022", "title": "Beyond The Imitation Game: Quantifying And Extrapolating The Capabilities Of Language Models", "topic_distr": {"0": 0.24726994335651398, "1": 0.0007657893584109843, "2": 0.21354398131370544, "3": 0.24626724421977997, "4": 0.0004945015534758568, "5": 0.00044229422928765416, "6": 0.00040005886694416404, "7": 0.0003651865990832448, "8": 0.0003359063994139433, "9": 0.0003109729732386768, "10": 0.0002894852659665048, "11": 0.0894974023103714, "12": 0.0782540962100029, "13": 0.12055656313896179, "14": 0.00022679944231640548, "15": 0.0002151520602637902, "16": 0.00020464256522245705, "17": 0.0001951119484147057, "18": 0.00018642956274561584, "19": 0.00017848695279099047}}, {"key": "staab2023beyond", "year": "2023", "title": "Beyond Memorization: Violating Privacy Via Inference With Large Language Models", "topic_distr": {"0": 0.2965295612812042, "1": 0.05813516676425934, "2": 0.000735834299121052, "3": 0.0006373360520228744, "4": 0.0005621019518002868, "5": 0.0005027587758377194, "6": 0.0004547495918814093, "7": 0.0004151100292801857, "8": 0.03240467235445976, "9": 0.33445286750793457, "10": 0.0003290598397143185, "11": 0.00030779195367358625, "12": 0.044415902346372604, "13": 0.09894029796123505, "14": 0.0002578044368419796, "15": 0.1076374351978302, "16": 0.0002326185640413314, "17": 0.00022178505605552346, "18": 0.0002119157143170014, "19": 0.022615259513258934}}, {"key": "stahlberg2018simple", "year": "2018", "title": "Simple Fusion: Return Of The Language Model", "topic_distr": {"0": 0.0014668216463178396, "1": 0.0011983431177213788, "2": 0.47919532656669617, "3": 0.0008772536530159414, "4": 0.0007737036794424057, "5": 0.0006920213345438242, "6": 0.0006259391084313393, "7": 0.04008696973323822, "8": 0.0005255650612525642, "9": 0.00048655379214324057, "10": 0.00045293374569155276, "11": 0.0004236596287228167, "12": 0.00039793981704860926, "13": 0.00037516411975957453, "14": 0.36194589734077454, "15": 0.00033663067733868957, "16": 0.00032018733327277005, "17": 0.00030527557828463614, "18": 0.0002916909579653293, "19": 0.10922207683324814}}, {"key": "stahlberg2019nmt", "year": "2019", "title": "On NMT Search Errors And Model Errors: Cat Got Your Tongue?", "topic_distr": {"0": 0.19290199875831604, "1": 0.0011982443975284696, "2": 0.2579009234905243, "3": 0.12900525331497192, "4": 0.0007738323183730245, "5": 0.0006921362364664674, "6": 0.04008065536618233, "7": 0.0005714722792617977, "8": 0.0005256523727439344, "9": 0.0004866346134804189, "10": 0.0004530089790932834, "11": 0.0004237300017848611, "12": 0.0003980059118475765, "13": 0.0003752264310605824, "14": 0.3726799488067627, "15": 0.00033668658579699695, "16": 0.00032024053507484496, "17": 0.00030532627715729177, "18": 0.00029173941584303975, "19": 0.00027931021759286523}}, {"key": "stern2019insertion", "year": "2019", "title": "Insertion Transformer: Flexible Sequence Generation Via Insertion Operations", "topic_distr": {"0": 0.0015045353211462498, "1": 0.03742234781384468, "2": 0.3079610764980316, "3": 0.0008985669701360166, "4": 0.0007924938690848649, "5": 0.0007088269921950996, "6": 0.0006411399808712304, "7": 0.2887031137943268, "8": 0.0005383283132687211, "9": 0.0004983696853742003, "10": 0.1927286982536316, "11": 0.07225824147462845, "12": 0.0004076037148479372, "13": 0.00038427492836490273, "14": 0.09298210591077805, "15": 0.0003448057104833424, "16": 0.0003279630618635565, "17": 0.00031268916791304946, "18": 0.0002987746265716851, "19": 0.0002860457170754671}}, {"key": "stevenson2022putting", "year": "2022", "title": "Putting Gpt-3's Creativity To The (alternative Uses) Test", "topic_distr": {"0": 0.4283791482448578, "1": 0.001132001867517829, "2": 0.0009566593798808753, "3": 0.2402646839618683, "4": 0.0007307741325348616, "5": 0.0006536223227158189, "6": 0.11628726124763489, "7": 0.0005396725027821958, "8": 0.0004964022664353251, "9": 0.1326112300157547, "10": 0.00042780113290064037, "11": 0.029061175882816315, "12": 0.0003758587408810854, "13": 0.0003543468192219734, "14": 0.00033516407711431384, "15": 0.04626419395208359, "16": 0.00030242063803598285, "17": 0.0002883363049477339, "18": 0.00027550547383725643, "19": 0.00026376789901405573}}, {"key": "straka2021czech", "year": "2021", "title": "Robeczech: Czech Roberta, A Monolingual Contextualized Language Representation Model", "topic_distr": {"0": 0.003464065957814455, "1": 0.0028294757939875126, "2": 0.002391836605966091, "3": 0.0020713028497993946, "4": 0.001826802035793662, "5": 0.0016339407302439213, "6": 0.0014779125340282917, "7": 0.0013490860583260655, "8": 0.001240918063558638, "9": 0.0011488080490380526, "10": 0.5498987436294556, "11": 0.0010003079660236835, "12": 0.000939580553676933, "13": 0.0008858045912347734, "14": 0.3085769712924957, "15": 0.0007948228158056736, "16": 0.0007559982477687299, "17": 0.0007207899470813572, "18": 0.0006887150811962783, "19": 0.11630412191152573}}, {"key": "strobelt2018visual", "year": "2018", "title": "Seq2seq-vis: A Visual Debugging Tool For Sequence-to-sequence Models", "topic_distr": {"0": 0.0018625907832756639, "1": 0.0015202551148831844, "2": 0.2145247906446457, "3": 0.1843639612197876, "4": 0.0009816107340157032, "5": 0.0008779774070717394, "6": 0.0007941379444673657, "7": 0.14028675854206085, "8": 0.0006667919224128127, "9": 0.15513016283512115, "10": 0.1378263533115387, "11": 0.00053750304505229, "12": 0.000504871946759522, "13": 0.0004759760631714016, "14": 0.09631312638521194, "15": 0.00042708817636594176, "16": 0.0004062262596562505, "17": 0.0003873074892908335, "18": 0.06175825744867325, "19": 0.0003543060156516731}}, {"key": "strobelt2022interactive", "year": "2022", "title": "Interactive And Visual Prompt Engineering For Ad-hoc Task Adaptation With Large Language Models", "topic_distr": {"0": 0.00141955038998276, "1": 0.08455323427915573, "2": 0.0233797337859869, "3": 0.34472477436065674, "4": 0.0007473664591088891, "5": 0.0006684628315269947, "6": 0.0006046301568858325, "7": 0.0005519258556887507, "8": 0.0005076731322333217, "9": 0.20299899578094482, "10": 0.0004375144199002534, "11": 0.00040923687629401684, "12": 0.0003843926533591002, "13": 0.00036239231121726334, "14": 0.0003427740011829883, "15": 0.0003251706948503852, "16": 0.0003092871338594705, "17": 0.2953994572162628, "18": 0.04160362854599953, "19": 0.000269756797933951}}, {"key": "strub2017end", "year": "2017", "title": "End-to-end Optimization Of Goal-driven And Visually Grounded Dialogue Systems", "topic_distr": {"0": 0.0013874744763597846, "1": 0.0011317157186567783, "2": 0.000956792791839689, "3": 0.0008286946685984731, "4": 0.11530385911464691, "5": 0.16745269298553467, "6": 0.1661192625761032, "7": 0.0005397424683906138, "8": 0.04139723256230354, "9": 0.0528503842651844, "10": 0.00042785657569766045, "11": 0.2590523064136505, "12": 0.00037590746069326997, "13": 0.09411944448947906, "14": 0.0003352075000293553, "15": 0.00031799275893718004, "16": 0.015803271904587746, "17": 0.0002883736742660403, "18": 0.08104800432920456, "19": 0.0002638020960148424}}, {"key": "strudel2022self", "year": "2022", "title": "Self-conditioned Embedding Diffusion For Text Generation", "topic_distr": {"0": 0.04346898943185806, "1": 0.0830545723438263, "2": 0.0011959344847127795, "3": 0.0010357938008382916, "4": 0.0009135258733294904, "5": 0.0008170814253389835, "6": 0.0007390569662675261, "7": 0.426967054605484, "8": 0.0006205436075106263, "9": 0.0005744823720306158, "10": 0.2696269154548645, "11": 0.0005002221441827714, "12": 0.00046985430526547134, "13": 0.047311730682849884, "14": 0.0004189826431684196, "15": 0.0003974655701313168, "16": 0.00037805066676810384, "17": 0.00036044407170265913, "18": 0.12081954628229141, "19": 0.00032973155612125993}}, {"key": "su2017sample", "year": "2017", "title": "Sample-efficient Actor-critic Reinforcement Learning With Supervised Data For Dialogue Management", "topic_distr": {"0": 0.06533316522836685, "1": 0.0011448296718299389, "2": 0.2587592303752899, "3": 0.0008379085338674486, "4": 0.09160485118627548, "5": 0.05259949713945389, "6": 0.0005978629924356937, "7": 0.000545748567674309, "8": 0.0005019911332055926, "9": 0.00046472970279864967, "10": 0.00043261764221824706, "11": 0.4486583173274994, "12": 0.00038009046693332493, "13": 0.000358336343197152, "14": 0.00033893759245984256, "15": 0.00032153131905943155, "16": 0.029516909271478653, "17": 0.0002915826335083693, "18": 0.04704509675502777, "19": 0.0002667375956661999}}, {"key": "su2018unsupervised", "year": "2018", "title": "Unsupervised Multi-modal Neural Machine Translation", "topic_distr": {"0": 0.06412369757890701, "1": 0.052784185856580734, "2": 0.0012126272777095437, "3": 0.1028309017419815, "4": 0.0009263090905733407, "5": 0.0008285145740956068, "6": 0.0007493984303437173, "7": 0.0006840749410912395, "8": 0.0006292266771197319, "9": 0.0005825209082104266, "10": 0.08268865942955017, "11": 0.0005072216154076159, "12": 0.0004764288605656475, "13": 0.00044916089973412454, "14": 0.46770918369293213, "15": 0.00040302719571627676, "16": 0.0003833406080957502, "17": 0.0003654876782093197, "18": 0.22133171558380127, "19": 0.0003343453863635659}}, {"key": "su2019vl", "year": "2019", "title": "VL-BERT: Pre-training Of Generic Visual-linguistic Representations", "topic_distr": {"0": 0.0017811752622947097, "1": 0.0014547220198437572, "2": 0.23086775839328766, "3": 0.0010652441997081041, "4": 0.0009395012748427689, "5": 0.0008403149549849331, "6": 0.0007600719691254199, "7": 0.0006938180886209011, "8": 0.06174754723906517, "9": 0.0005908176535740495, "10": 0.2684214115142822, "11": 0.0005144458264112473, "12": 0.00048321453505195677, "13": 0.0004555582127068192, "14": 0.000430896325269714, "15": 0.0004087674315087497, "16": 0.000388800457585603, "17": 0.000370693247532472, "18": 0.427446186542511, "19": 0.0003391074133105576}}, {"key": "su2020bert", "year": "2020", "title": "Bert-hlstms: BERT And Hierarchical Lstms For Visual Storytelling", "topic_distr": {"0": 0.018472028896212578, "1": 0.0011704959906637669, "2": 0.25627774000167847, "3": 0.0008571543730795383, "4": 0.0007559767109341919, "5": 0.0006761650438420475, "6": 0.21132637560367584, "7": 0.1536840945482254, "8": 0.0005135227693244815, "9": 0.000475405395263806, "10": 0.17248950898647308, "11": 0.0004139523080084473, "12": 0.00038882181979715824, "13": 0.0003665679832920432, "14": 0.014669287018477917, "15": 0.00032891746377572417, "16": 0.00031285089789889753, "17": 0.0002982808218803257, "18": 0.16625000536441803, "19": 0.0002728650579228997}}, {"key": "su2021improving", "year": "2021", "title": "Tacl: Improving BERT Pre-training With Token-aware Contrastive Learning", "topic_distr": {"0": 0.001643239171244204, "1": 0.10657794773578644, "2": 0.3797750473022461, "3": 0.0009812242351472378, "4": 0.0008654011762700975, "5": 0.0007740372093394399, "6": 0.0007001232006587088, "7": 0.0006390950293280184, "8": 0.0005878531956113875, "9": 0.0005442184628918767, "10": 0.36800411343574524, "11": 0.0004738702846225351, "12": 0.08138775080442429, "13": 0.0004196272639092058, "14": 0.00039691050187684596, "15": 0.00037652699393220246, "16": 0.05487293750047684, "17": 0.00034145580139011145, "18": 0.0003262611571699381, "19": 0.00031236119684763253}}, {"key": "su2021multi", "year": "2021", "title": "Multi-task Pre-training For Plug-and-play Task-oriented Dialogue System", "topic_distr": {"0": 0.17263290286064148, "1": 0.053721833974123, "2": 0.0011328893015161157, "3": 0.1343740075826645, "4": 0.026929108425974846, "5": 0.2507953643798828, "6": 0.1133134588599205, "7": 0.0006390862399712205, "8": 0.0005878451047465205, "9": 0.0005442109541036189, "10": 0.12240470945835114, "11": 0.0004738637653645128, "12": 0.0004450961423572153, "13": 0.0004196214722469449, "14": 0.00039690505946055055, "15": 0.07360386848449707, "16": 0.04660516977310181, "17": 0.00034145108656957746, "18": 0.00032625667518004775, "19": 0.0003123569185845554}}, {"key": "su2021plan", "year": "2021", "title": "Plan-then-generate: Controlled Data-to-text Generation Via Planning", "topic_distr": {"0": 0.0020462824031710625, "1": 0.0016694196965545416, "2": 0.07541170716285706, "3": 0.0012223344529047608, "4": 0.0010780459269881248, "5": 0.0009642319637350738, "6": 0.0008721559424884617, "7": 0.6085306406021118, "8": 0.0007322991150431335, "9": 0.000677942531183362, "10": 0.0006310978787951171, "11": 0.0005903085693717003, "12": 0.13383212685585022, "13": 0.0005227371002547443, "14": 0.0004944384563714266, "15": 0.16905716061592102, "16": 0.00044613488717004657, "17": 0.0004253575170878321, "18": 0.00040642928797751665, "19": 0.00038911387673579156}}, {"key": "su2021transferability", "year": "2021", "title": "On Transferability Of Prompt Tuning For Natural Language Processing", "topic_distr": {"0": 0.07371661067008972, "1": 0.11431737244129181, "2": 0.0008440593373961747, "3": 0.0007310648798011243, "4": 0.0006447701598517597, "5": 0.0005766996182501316, "6": 0.0005216296412982047, "7": 0.0004761603195220232, "8": 0.00043798238039016724, "9": 0.00040547215030528605, "10": 0.0003774547076318413, "11": 0.0003530589456204325, "12": 0.00033162522595375776, "13": 0.05195314809679985, "14": 0.0002957197721116245, "15": 0.01667971722781658, "16": 0.00026682979660108685, "17": 0.7365947961807251, "18": 0.00024308219144586474, "19": 0.00023272597172763199}}, {"key": "su2022contrastive", "year": "2022", "title": "Contrastive Search Is What You Need For Neural Text Generation", "topic_distr": {"0": 0.03456166014075279, "1": 0.0007489890558645129, "2": 0.2900330424308777, "3": 0.04496331140398979, "4": 0.00048359378706663847, "5": 0.00043253879994153976, "6": 0.0003912349930033088, "7": 0.16947297751903534, "8": 0.05127964913845062, "9": 0.00030411401530727744, "10": 0.18608002364635468, "11": 0.00026480286032892764, "12": 0.00024872703943401575, "13": 0.000234491380979307, "14": 0.03579585999250412, "15": 0.07517863065004349, "16": 0.00020012888126075268, "17": 0.0001908084814203903, "18": 0.00018231758440379053, "19": 0.10895310342311859}}, {"key": "su2022language", "year": "2022", "title": "Language Models Can See: Plugging Visual Controls In Text Generation", "topic_distr": {"0": 0.0010232874192297459, "1": 0.0008348433766514063, "2": 0.11114484071731567, "3": 0.08072420954704285, "4": 0.0005391151062212884, "5": 0.00048219854943454266, "6": 0.00043615270988084376, "7": 0.3801315724849701, "8": 0.00036621230538003147, "9": 0.00033902935683727264, "10": 0.0003156030143145472, "11": 0.0002952048962470144, "12": 0.00027728339773602784, "13": 0.036744680255651474, "14": 0.00024726157425902784, "15": 0.0002345633547520265, "16": 0.00022310568601824343, "17": 0.03749997168779373, "18": 0.28636518120765686, "19": 0.06177569180727005}}, {"key": "su2022one", "year": "2022", "title": "One Embedder, Any Task: Instruction-finetuned Text Embeddings", "topic_distr": {"0": 0.0013562648091465235, "1": 0.0011072270572185516, "2": 0.29752272367477417, "3": 0.0008105167071335018, "4": 0.0007148394361138344, "5": 0.0006393713993020356, "6": 0.0005783168599009514, "7": 0.0005279062315821648, "8": 0.00048557936679571867, "9": 0.00044953610631637275, "10": 0.139860600233078, "11": 0.10414113849401474, "12": 0.00036766400444321334, "13": 0.09549751877784729, "14": 0.00032785660005174577, "15": 0.2724341154098511, "16": 0.000295827048830688, "17": 0.0002820498193614185, "18": 0.05129019170999527, "19": 0.031310755759477615}}, {"key": "su2022selective", "year": "2022", "title": "Selective Annotation Makes Language Models Better Few-shot Learners", "topic_distr": {"0": 0.0010310671059414744, "1": 0.23300369083881378, "2": 0.08949095010757446, "3": 0.23425033688545227, "4": 0.0005435339407995343, "5": 0.0004861512570641935, "6": 0.06880273669958115, "7": 0.00040139761404134333, "8": 0.000369214074453339, "9": 0.0003418083069846034, "10": 0.0003181899373885244, "11": 0.0002976246178150177, "12": 0.00027955620316788554, "13": 0.07872889190912247, "14": 0.0002492883359082043, "15": 0.00023648601199965924, "16": 0.0002249344252049923, "17": 0.2905430197715759, "18": 0.00020491547184064984, "19": 0.00019618529768195003}}, {"key": "su2023distilled", "year": "2023", "title": "Distilled GPT For Source Code Summarization", "topic_distr": {"0": 0.0014857626520097256, "1": 0.0012124736094847322, "2": 0.001025047735311091, "3": 0.36755767464637756, "4": 0.0007830049726180732, "5": 0.0007003401406109333, "6": 0.2269834578037262, "7": 0.0724872574210167, "8": 0.043507128953933716, "9": 0.0004924026434309781, "10": 0.08057081699371338, "11": 0.00042875242070294917, "12": 0.0004027234099339694, "13": 0.20045256614685059, "14": 0.0003591200802475214, "15": 0.0003406773030292243, "16": 0.0003240362857468426, "17": 0.0003089452802669257, "18": 0.0002951973583549261, "19": 0.0002826208365149796}}, {"key": "su2023one", "year": "2023", "title": "Pandagpt: One Model To Instruction-follow Them All", "topic_distr": {"0": 0.05338459461927414, "1": 0.11752378940582275, "2": 0.0011636806884780526, "3": 0.1344524472951889, "4": 0.0008888926822692156, "5": 0.0007950486615300179, "6": 0.0007191282929852605, "7": 0.05356021597981453, "8": 0.0006038106512278318, "9": 0.000558991392608732, "10": 0.0005203660111874342, "11": 0.00048673362471163273, "12": 0.00045718468027189374, "13": 0.0004310181539040059, "14": 0.0004076847399119288, "15": 0.00038674790994264185, "16": 0.016731973737478256, "17": 0.0003507247020024806, "18": 0.6162561178207397, "19": 0.0003208403359167278}}, {"key": "subramanian2017neural", "year": "2017", "title": "Neural Models For Key Phrase Detection And Question Generation", "topic_distr": {"0": 0.001757828169502318, "1": 0.0014346723910421133, "2": 0.307218074798584, "3": 0.0010502816876396537, "4": 0.0009263035608455539, "5": 0.0008285084622912109, "6": 0.0007493929588235915, "7": 0.19574087858200073, "8": 0.3178190588951111, "9": 0.0005825166590511799, "10": 0.0005422657122835517, "11": 0.0005072178901173174, "12": 0.0004764253681059927, "13": 0.00044915761100128293, "14": 0.0004248422337695956, "15": 0.07610612362623215, "16": 0.09233745187520981, "17": 0.0003654850006569177, "18": 0.00034922108170576394, "19": 0.00033434294164180756}}, {"key": "sudhakaran2023open", "year": "2023", "title": "Mariogpt: Open-ended Text2level Generation Through Large Language Models", "topic_distr": {"0": 0.039254724979400635, "1": 0.07796976715326309, "2": 0.0009896414121612906, "3": 0.3016646206378937, "4": 0.0007559508667327464, "5": 0.0006761425174772739, "6": 0.0006115763098932803, "7": 0.28654491901397705, "8": 0.0005135054234415293, "9": 0.0004753893008455634, "10": 0.0004425406805239618, "11": 0.07898901402950287, "12": 0.0003888086648657918, "13": 0.0003665555559564382, "14": 0.00034671189496293664, "15": 0.20884114503860474, "16": 0.0003128403041046113, "17": 0.0002982707228511572, "18": 0.00028499780455604196, "19": 0.00027285583200864494}}, {"key": "suglia2021embodied", "year": "2021", "title": "Embodied BERT: A Transformer Model For Embodied, Language-guided Visual Task Completion", "topic_distr": {"0": 0.0019488775869831443, "1": 0.0015913527458906174, "2": 0.04963885247707367, "3": 0.001165154855698347, "4": 0.0010276202810928226, "5": 0.0009191305725835264, "6": 0.0008313614525832236, "7": 0.0007588934386149049, "8": 0.0006980463513173163, "9": 0.0006462322780862451, "10": 0.14555667340755463, "11": 0.49667713046073914, "12": 0.0005285367369651794, "13": 0.0004982864484190941, "14": 0.00047131141764111817, "15": 0.0004471070133149624, "16": 0.0004252672370057553, "17": 0.0004054617020301521, "18": 0.29539379477500916, "19": 0.00037091333069838583}}, {"key": "suh2023structured", "year": "2023", "title": "Luminate: Structured Generation And Exploration Of Design Space With Large Language Models For Human-ai Co-creation", "topic_distr": {"0": 0.0014179936842992902, "1": 0.0011575005482882261, "2": 0.0009784746216610074, "3": 0.1858873814344406, "4": 0.06827016919851303, "5": 0.000668541993945837, "6": 0.029867023229599, "7": 0.037404075264930725, "8": 0.0005077333189547062, "9": 0.5049917697906494, "10": 0.0004375662829261273, "11": 0.0004092853923793882, "12": 0.00038443822995759547, "13": 0.0003624352684710175, "14": 0.00034281465923413634, "15": 0.00032520925742574036, "16": 0.08311355113983154, "17": 0.0002949179906863719, "18": 0.08290939033031464, "19": 0.00026978878304362297}}, {"key": "sukhbaatar2019adaptive", "year": "2019", "title": "Adaptive Attention Span In Transformers", "topic_distr": {"0": 0.0031962080392986536, "1": 0.0026109900791198015, "2": 0.5723192095756531, "3": 0.001911908620968461, "4": 0.001686231349594891, "5": 0.0015082102036103606, "6": 0.001364189083687961, "7": 0.0455925390124321, "8": 0.001145430956967175, "9": 0.0010604087729007006, "10": 0.2644963562488556, "11": 0.0009233354940079153, "12": 0.0008672809926792979, "13": 0.09720318764448166, "14": 0.0007733794627711177, "15": 0.0007336622220464051, "16": 0.0006978251622058451, "17": 0.000665326020680368, "18": 0.0006357193342410028, "19": 0.0006086353096179664}}, {"key": "sukhbaatar2019augmenting", "year": "2019", "title": "Augmenting Self-attention With Persistent Memory", "topic_distr": {"0": 0.002045833272859454, "1": 0.001669604447670281, "2": 0.4027208089828491, "3": 0.0012224926613271236, "4": 0.0010781900491565466, "5": 0.0009643617668189108, "6": 0.0008722728816792369, "7": 0.0007962387171573937, "8": 0.0007323973113670945, "9": 0.0006780334515497088, "10": 0.39066508412361145, "11": 0.0005903877899982035, "12": 0.047175075858831406, "13": 0.0005228071822784841, "14": 0.042653851211071014, "15": 0.0004691092181019485, "16": 0.10392234474420547, "17": 0.0004254145605955273, "18": 0.0004064837994519621, "19": 0.0003891660599038005}}, {"key": "sultanum2023investigating", "year": "2023", "title": "Datatales: Investigating The Use Of Large Language Models For Authoring Data-driven Articles", "topic_distr": {"0": 0.1300157904624939, "1": 0.001698035397566855, "2": 0.0014348969561979175, "3": 0.18669022619724274, "4": 0.001096125110052526, "5": 0.0009804037399590015, "6": 0.0008867831202223897, "7": 0.107542484998703, "8": 0.0007445807568728924, "9": 0.5638988614082336, "10": 0.0006416821852326393, "11": 0.0006002088193781674, "12": 0.0005637709400616586, "13": 0.0005315040471032262, "14": 0.0005027307779528201, "15": 0.0004769128281623125, "16": 0.0004536171618383378, "17": 0.0004324913024902344, "18": 0.00041324563790112734, "19": 0.00039563982863910496}}, {"key": "sulubacak2019multimodal", "year": "2019", "title": "Multimodal Machine Translation Through Visuals And Speech", "topic_distr": {"0": 0.03672393783926964, "1": 0.049444641917943954, "2": 0.0011039163218811154, "3": 0.0009561320766806602, "4": 0.03764916956424713, "5": 0.0007542400271631777, "6": 0.04193272814154625, "7": 0.030151013284921646, "8": 0.0005728175747208297, "9": 0.04548180475831032, "10": 0.0004936561454087496, "11": 0.00046175005263648927, "12": 0.19535674154758453, "13": 0.000408894382417202, "14": 0.19467492401599884, "15": 0.0003668965073302388, "16": 0.0003489747759886086, "17": 0.0003327223239466548, "18": 0.36248064041137695, "19": 0.00030437190434895456}}, {"key": "sumers2023cognitive", "year": "2023", "title": "Cognitive Architectures For Language Agents", "topic_distr": {"0": 0.08951716125011444, "1": 0.014563625678420067, "2": 0.0009674577158875763, "3": 0.044130660593509674, "4": 0.0007390498067252338, "5": 0.000661025638692081, "6": 0.01694219559431076, "7": 0.0005457851802930236, "8": 0.0005020248354412615, "9": 0.16526536643505096, "10": 0.00043264671694487333, "11": 0.3696090877056122, "12": 0.12791654467582703, "13": 0.00035836041206493974, "14": 0.00033896035165525973, "15": 0.0003215528849978, "16": 0.14004389941692352, "17": 0.02659919299185276, "18": 0.00027862604474648833, "19": 0.00026675552362576127}}, {"key": "sun2018improving", "year": "2018", "title": "Improving Machine Reading Comprehension With General Reading Strategies", "topic_distr": {"0": 0.027871284633874893, "1": 0.0008214015979319811, "2": 0.5077171921730042, "3": 0.15784800052642822, "4": 0.0005303995567373931, "5": 0.00047440314665436745, "6": 0.00042910166666842997, "7": 0.00039169780211523175, "8": 0.1206316351890564, "9": 0.00033354846527799964, "10": 0.0003105008217971772, "11": 0.00029043247923254967, "12": 0.0002728007093537599, "13": 0.07859339565038681, "14": 0.0002432642359053716, "15": 0.04944351315498352, "16": 0.053196750581264496, "17": 0.00020927636069245636, "18": 0.0001999636588152498, "19": 0.00019144444377161562}}, {"key": "sun2019how", "year": "2019", "title": "How To Fine-tune BERT For Text Classification?", "topic_distr": {"0": 0.0029014546889811754, "1": 0.002368571702390909, "2": 0.18981853127479553, "3": 0.0017341816565021873, "4": 0.0015294641489163041, "5": 0.001367992372252047, "6": 0.0012373605277389288, "7": 0.0011295025469735265, "8": 0.0010389405069872737, "9": 0.0009618227486498654, "10": 0.6723228693008423, "11": 0.0008374931639991701, "12": 0.0007866500527597964, "13": 0.0007416268927045166, "14": 0.000701478507835418, "15": 0.11815695464611053, "16": 0.000632948474958539, "17": 0.000603470834903419, "18": 0.000576616614125669, "19": 0.0005520505947060883}}, {"key": "sun2019language", "year": "2019", "title": "LAMOL: Language Modeling For Lifelong Language Learning", "topic_distr": {"0": 0.002187286037951708, "1": 0.05521601438522339, "2": 0.5161346197128296, "3": 0.0013081792276352644, "4": 0.0011537583777680993, "5": 0.0010319513967260718, "6": 0.12244565784931183, "7": 0.0008520454866811633, "8": 0.000783729599788785, "9": 0.0007255554664880037, "10": 0.07613814622163773, "11": 0.05416301637887955, "12": 0.01943502202630043, "13": 0.0005594496615231037, "14": 0.0005291635752655566, "15": 0.0005019881064072251, "16": 0.10680892318487167, "17": 0.0004552309983409941, "18": 0.039153799414634705, "19": 0.0004164419078733772}}, {"key": "sun2019sequential", "year": "2019", "title": "Bert4rec: Sequential Recommendation With Bidirectional Encoder Representations From Transformer", "topic_distr": {"0": 0.001154472935013473, "1": 0.0009432101505808532, "2": 0.3968522250652313, "3": 0.0006904785404913127, "4": 0.22767417132854462, "5": 0.0005446835421025753, "6": 0.0004926708643324673, "7": 0.04386833310127258, "8": 0.00041366738150827587, "9": 0.0003829619672615081, "10": 0.3245551884174347, "11": 0.0003334585635457188, "12": 0.00031321472488343716, "13": 0.0002952881914097816, "14": 0.00027930259238928556, "15": 0.0002649588859640062, "16": 0.0002520164998713881, "17": 0.00024027957988437265, "18": 0.0002295872545801103, "19": 0.0002198059664806351}}, {"key": "sun2020compact", "year": "2020", "title": "Mobilebert: A Compact Task-agnostic BERT For Resource-limited Devices", "topic_distr": {"0": 0.0016414098208770156, "1": 0.001340069924481213, "2": 0.08868766576051712, "3": 0.0009812118951231241, "4": 0.0008653878467157483, "5": 0.030641520395874977, "6": 0.0007001127232797444, "7": 0.0006390854250639677, "8": 0.03196718916296959, "9": 0.0005442102556116879, "10": 0.41598665714263916, "11": 0.0004738631541840732, "12": 0.00044509556028060615, "13": 0.3409755825996399, "14": 0.08239621669054031, "15": 0.0003765213186852634, "16": 0.0003581294440664351, "17": 0.0003414506500121206, "18": 0.00032625626772642136, "19": 0.000312356511130929}}, {"key": "sun2020contextualized", "year": "2020", "title": "Colake: Contextualized Language And Knowledge Embedding", "topic_distr": {"0": 0.001401299494318664, "1": 0.03932637721300125, "2": 0.11805994808673859, "3": 0.0008378886850550771, "4": 0.0007389822858385742, "5": 0.0006609653937630355, "6": 0.0005978487897664309, "7": 0.0005457355873659253, "8": 0.0005019792006351054, "9": 0.00046471867244690657, "10": 0.2732216417789459, "11": 0.00040464699850417674, "12": 0.0003800814156420529, "13": 0.0003583278157748282, "14": 0.0003389295598026365, "15": 0.00032152366475202143, "16": 0.42240360379219055, "17": 0.0002915757067967206, "18": 0.000278600724413991, "19": 0.13886530697345734}}, {"key": "sun2020contrastive", "year": "2020", "title": "Contrastive Distillation On Intermediate Representations For Language Model Compression", "topic_distr": {"0": 0.001433408004231751, "1": 0.031068777665495872, "2": 0.09004098922014236, "3": 0.0008571158396080136, "4": 0.0007559413206763566, "5": 0.0006761334952898324, "6": 0.000611568451859057, "7": 0.0005582594312727451, "8": 0.000513498904183507, "9": 0.0004753832472488284, "10": 0.3518780469894409, "11": 0.00041393304127268493, "12": 0.00038880371721461415, "13": 0.33624139428138733, "14": 0.0003467074711807072, "15": 0.00032890215516090393, "16": 0.13782262802124023, "17": 0.00029826691024936736, "18": 0.0002849941956810653, "19": 0.04500520974397659}}, {"key": "sun2020mixup", "year": "2020", "title": "Mixup-transformer: Dynamic Data Augmentation For NLP Tasks", "topic_distr": {"0": 0.0015821476699784398, "1": 0.2808018624782562, "2": 0.24010023474693298, "3": 0.0009439579444006085, "4": 0.07252603769302368, "5": 0.000744636170566082, "6": 0.0006735295755788684, "7": 0.000614819407928735, "8": 0.0005655239801853895, "9": 0.0005235466524027288, "10": 0.21856968104839325, "11": 0.0004558706423267722, "12": 0.0004281953442841768, "13": 0.0004036879981867969, "14": 0.00038183413562364876, "15": 0.0003622248477768153, "16": 0.0003445313195697963, "17": 0.12966059148311615, "18": 0.05001658573746681, "19": 0.000300496380077675}}, {"key": "sun2021chinese", "year": "2021", "title": "Psyqa: A Chinese Dataset For Generating Long Counseling Text For Mental Health Support", "topic_distr": {"0": 0.0014692231779918075, "1": 0.2969762086868286, "2": 0.00101291888859123, "3": 0.0008773298468440771, "4": 0.0007737667765468359, "5": 0.0006920768064446747, "6": 0.0006259892834350467, "7": 0.0005714230937883258, "8": 0.18250609934329987, "9": 0.19939149916172028, "10": 0.00045297000906430185, "11": 0.0004236935346852988, "12": 0.06818138062953949, "13": 0.0003751941549126059, "14": 0.0003548828244674951, "15": 0.2299249917268753, "16": 0.00032021297374740243, "17": 0.0003053000255022198, "18": 0.00029171432834118605, "19": 0.014473123475909233}}, {"key": "sun2021defending", "year": "2021", "title": "Defending Against Backdoor Attacks In Natural Language Generation", "topic_distr": {"0": 0.18993665277957916, "1": 0.190211683511734, "2": 0.12648695707321167, "3": 0.04100843891501427, "4": 0.06469955295324326, "5": 0.000708780949935317, "6": 0.0006410983623936772, "7": 0.18536782264709473, "8": 0.000538293388672173, "9": 0.0004983373219147325, "10": 0.00046390306670218706, "11": 0.000433919980423525, "12": 0.13106319308280945, "13": 0.0003842499863822013, "14": 0.06598693132400513, "15": 0.0003447833296377212, "16": 0.0003279417578596622, "17": 0.00031266885343939066, "18": 0.0002987552434206009, "19": 0.0002860271488316357}}, {"key": "sun2021ernie", "year": "2021", "title": "ERNIE 3.0: Large-scale Knowledge Enhanced Pre-training For Language Understanding And Generation", "topic_distr": {"0": 0.0013271913630887866, "1": 0.0010834530694410205, "2": 0.1285945028066635, "3": 0.0007932898006401956, "4": 0.0006996456650085747, "5": 0.0006257812492549419, "6": 0.0005660244496539235, "7": 0.000516685307957232, "8": 0.0004752581298816949, "9": 0.0004399810277391225, "10": 0.13331831991672516, "11": 0.10668561607599258, "12": 0.08305583149194717, "13": 0.10354650765657425, "14": 0.00032088783336803317, "15": 0.19034399092197418, "16": 0.14018890261650085, "17": 0.00027605469222180545, "18": 0.000263770401943475, "19": 0.10687830299139023}}, {"key": "sun2021multimodal", "year": "2021", "title": "Multimodal Dialogue Response Generation", "topic_distr": {"0": 0.029544027522206306, "1": 0.000989007530733943, "2": 0.13526679575443268, "3": 0.0007239854312501848, "4": 0.0006385249434970319, "5": 0.11283204704523087, "6": 0.18471668660640717, "7": 0.10399709641933441, "8": 0.0004337397695053369, "9": 0.00040154444286599755, "10": 0.00037379839341156185, "11": 0.08579288423061371, "12": 0.0003284128615632653, "13": 0.07585743814706802, "14": 0.00029285519849509, "15": 0.00027781547396443784, "16": 0.00026424508541822433, "17": 0.00025193867622874677, "18": 0.26678669452667236, "19": 0.00023047160357236862}}, {"key": "sun2021nsp", "year": "2021", "title": "NSP-BERT: A Prompt-based Few-shot Learner Through An Original Pre-training Task--next Sentence Prediction", "topic_distr": {"0": 0.0016001597978174686, "1": 0.13044781982898712, "2": 0.3359092175960541, "3": 0.0009560346370562911, "4": 0.0008431821479462087, "5": 0.0007541637169197202, "6": 0.0006821474526077509, "7": 0.0006226861150935292, "8": 0.0005727599491365254, "9": 0.0005302455392666161, "10": 0.1658550649881363, "11": 0.0004617035447154194, "12": 0.00043367414036765695, "13": 0.0004088532296009362, "14": 0.00038671973743475974, "15": 0.0003668595745693892, "16": 0.041076481342315674, "17": 0.3174700140953064, "18": 0.00031788431806489825, "19": 0.0003043412580154836}}, {"key": "sun2021pre", "year": "2021", "title": "Lightningdot: Pre-training Visual-semantic Embeddings For Real-time Image-text Retrieval", "topic_distr": {"0": 0.0014028564328327775, "1": 0.001144286128692329, "2": 0.2628827691078186, "3": 0.0008379178470931947, "4": 0.053482331335544586, "5": 0.000660987920127809, "6": 0.0005978691624477506, "7": 0.0005457541556097567, "8": 0.04912694916129112, "9": 0.0004647344758268446, "10": 0.22136147320270538, "11": 0.00040466076461598277, "12": 0.07737196236848831, "13": 0.2413925975561142, "14": 0.00033894108491949737, "15": 0.00032153460779227316, "16": 0.0003058286674786359, "17": 0.00029158563120290637, "18": 0.08679823577404022, "19": 0.0002667403605300933}}, {"key": "sun2022black", "year": "2022", "title": "Black-box Tuning For Language-model-as-a-service", "topic_distr": {"0": 0.001731497934088111, "1": 0.0014146683970466256, "2": 0.0011957871029153466, "3": 0.10869739949703217, "4": 0.08789603412151337, "5": 0.0008170282235369086, "6": 0.0007390088867396116, "7": 0.0006745911086909473, "8": 0.0006205032113939524, "9": 0.0005744449445046484, "10": 0.05096582695841789, "11": 0.0005001896061003208, "12": 0.00046982374624349177, "13": 0.1847643256187439, "14": 0.00041895537287928164, "15": 0.0003974397259298712, "16": 0.01699814386665821, "17": 0.5404502153396606, "18": 0.0003443820751272142, "19": 0.0003297101065982133}}, {"key": "sun2022contrastive", "year": "2022", "title": "Contrastive Learning Reduces Hallucination In Conversations", "topic_distr": {"0": 0.20846618711948395, "1": 0.00114444678183645, "2": 0.09647399187088013, "3": 0.0008379147620871663, "4": 0.0007390074897557497, "5": 0.000660987279843539, "6": 0.20227576792240143, "7": 0.09838211536407471, "8": 0.000501995615195483, "9": 0.0004647338355425745, "10": 0.0004326215130276978, "11": 0.044774238020181656, "12": 0.0003800938429776579, "13": 0.11407176405191422, "14": 0.00033894061925821006, "15": 0.0003215341712348163, "16": 0.11486300081014633, "17": 0.00029158522374928, "18": 0.00027860983391292393, "19": 0.11430051922798157}}, {"key": "sun2022investigating", "year": "2022", "title": "Investigating Explainability Of Generative AI For Code Through Scenario-based Design", "topic_distr": {"0": 0.11222705990076065, "1": 0.001144446199759841, "2": 0.0009673961903899908, "3": 0.0008378727361559868, "4": 0.10330279916524887, "5": 0.09593775123357773, "6": 0.16652551293373108, "7": 0.0005457245279103518, "8": 0.0005019690142944455, "9": 0.4282738268375397, "10": 0.0004325985792092979, "11": 0.00040463879122398794, "12": 0.00038007370312698185, "13": 0.000358320539817214, "14": 0.0193575918674469, "15": 0.0003215171454939991, "16": 0.0003058120491914451, "17": 0.06762978434562683, "18": 0.0002785950491670519, "19": 0.00026672586682252586}}, {"key": "sun2022length", "year": "2022", "title": "A Length-extrapolatable Transformer", "topic_distr": {"0": 0.0756061002612114, "1": 0.001755907665938139, "2": 0.20894640684127808, "3": 0.0012856748653575778, "4": 0.0011339137563481927, "5": 0.0698210671544075, "6": 0.0009173534926958382, "7": 0.0008373897289857268, "8": 0.0007702489383518696, "9": 0.0007130753947421908, "10": 0.5950203537940979, "11": 0.0006209000130183995, "12": 0.0005832060123793781, "13": 0.0005498267710208893, "14": 0.0005200615851208568, "15": 0.03916503116488457, "16": 0.000469254853669554, "17": 0.00044740072917193174, "18": 0.000427491613663733, "19": 0.00040927884401753545}}, {"key": "sun2022long", "year": "2022", "title": "Long-form Video-language Pre-training With Multimodal Temporal Contrastive Learning", "topic_distr": {"0": 0.0011445640120655298, "1": 0.0009343284764327109, "2": 0.21327809989452362, "3": 0.0006841173744760454, "4": 0.0006033644312992692, "5": 0.0005396647029556334, "6": 0.000488131248857826, "7": 0.00044558191439136863, "8": 0.00040985571104101837, "9": 0.00037943324423395097, "10": 0.10897714644670486, "11": 0.0003303859557490796, "12": 0.0003103286726400256, "13": 0.05249106138944626, "14": 0.000276729027973488, "15": 0.0002625174820423126, "16": 0.00024969433434307575, "17": 0.00023806556419003755, "18": 0.5976602435112, "19": 0.020296653732657433}}, {"key": "sun2022recitation", "year": "2022", "title": "Recitation-augmented Language Models", "topic_distr": {"0": 0.00186056992970407, "1": 0.0015198778128251433, "2": 0.0012849138583987951, "3": 0.40455061197280884, "4": 0.000981538207270205, "5": 0.0008779129711911082, "6": 0.0007940796785987914, "7": 0.10923077166080475, "8": 0.23280923068523407, "9": 0.000617252488154918, "10": 0.0005746013484895229, "11": 0.0005374635802581906, "12": 0.000504834926687181, "13": 0.028769085183739662, "14": 0.0004501758376136422, "15": 0.083195261657238, "16": 0.1303301751613617, "17": 0.0003872790839523077, "18": 0.00037004536716267467, "19": 0.0003542800259310752}}, {"key": "sun2023aligning", "year": "2023", "title": "Aligning Large Multimodal Models With Factually Augmented RLHF", "topic_distr": {"0": 0.1589876264333725, "1": 0.0008935655932873487, "2": 0.07125148922204971, "3": 0.0006541186012327671, "4": 0.1070624515414238, "5": 0.0005159970023669302, "6": 0.03372456878423691, "7": 0.000426040351158008, "8": 0.00039188098162412643, "9": 0.0003627926926128566, "10": 0.0003377243410795927, "11": 0.17692391574382782, "12": 0.0002967188192997128, "13": 0.0002797363849822432, "14": 0.00026459270156919956, "15": 0.06262388825416565, "16": 0.00023874366888776422, "17": 0.00022762489970773458, "18": 0.38432833552360535, "19": 0.00020822955411858857}}, {"key": "sun2023alpha", "year": "2023", "title": "Alpha-clip: A CLIP Model Focusing On Wherever You Want", "topic_distr": {"0": 0.07447536289691925, "1": 0.0012573814019560814, "2": 0.001062947791069746, "3": 0.0009206684771925211, "4": 0.0008119881968013942, "5": 0.0007262637955136597, "6": 0.0006569117540493608, "7": 0.09679093211889267, "8": 0.0005515710217878222, "9": 0.02678176946938038, "10": 0.00047534576151520014, "11": 0.000444623117800802, "12": 0.1154458299279213, "13": 0.0003937279398087412, "14": 0.0003724132548086345, "15": 0.00035328781814314425, "16": 0.0179640743881464, "17": 0.00032038119388744235, "18": 0.6599014401435852, "19": 0.00029308232478797436}}, {"key": "sun2023is", "year": "2023", "title": "Is Chatgpt Good At Search? Investigating Large Language Models As Re-ranking Agents", "topic_distr": {"0": 0.06067750230431557, "1": 0.0009176607127301395, "2": 0.000775648804847151, "3": 0.3675823211669922, "4": 0.11378087848424911, "5": 0.0005299563053995371, "6": 0.04264106601476669, "7": 0.0004375660791993141, "8": 0.03068844974040985, "9": 0.07893969863653183, "10": 0.0003468608483672142, "11": 0.05234234780073166, "12": 0.00030474597588181496, "13": 0.13463972508907318, "14": 0.0002717507886700332, "15": 0.08789266645908356, "16": 0.026560137048363686, "17": 0.00023378286277875304, "18": 0.00022337964037433267, "19": 0.0002138628187822178}}, {"key": "sun2023principle", "year": "2023", "title": "Principle-driven Self-alignment Of Language Models From Scratch With Minimal Human Supervision", "topic_distr": {"0": 0.11283037811517715, "1": 0.06525558233261108, "2": 0.0005857101059518754, "3": 0.15423373878002167, "4": 0.10071603953838348, "5": 0.0004001794441137463, "6": 0.11008793860673904, "7": 0.0003304138081148267, "8": 0.00030392163898795843, "9": 0.12427757680416107, "10": 0.0002619207079987973, "11": 0.15646816790103912, "12": 0.00023011903977021575, "13": 0.05411041900515556, "14": 0.00020520377438515425, "15": 0.00019466543744783849, "16": 0.00018515664851292968, "17": 0.11899269372224808, "18": 0.00016867787053342909, "19": 0.00016149156726896763}}, {"key": "sun2023retentive", "year": "2023", "title": "Retentive Network: A Successor To Transformer For Large Language Models", "topic_distr": {"0": 0.0015783734852448106, "1": 0.0012891519581899047, "2": 0.26736682653427124, "3": 0.0009439222048968077, "4": 0.0008325022063218057, "5": 0.0007446096278727055, "6": 0.0006735057104378939, "7": 0.04597925767302513, "8": 0.0005655040149576962, "9": 0.0005235281423665583, "10": 0.291724294424057, "11": 0.0004558545188046992, "12": 0.0004281802102923393, "13": 0.3395302891731262, "14": 0.00038182063144631684, "15": 0.00036221204209141433, "16": 0.04567735269665718, "17": 0.0003284742124378681, "18": 0.00031385725014843047, "19": 0.0003004857571795583}}, {"key": "sun2023safety", "year": "2023", "title": "Safety Assessment Of Chinese Large Language Models", "topic_distr": {"0": 0.29157593846321106, "1": 0.04662656784057617, "2": 0.0006887516938149929, "3": 0.287581205368042, "4": 0.0005261341575533152, "5": 0.00047058769268915057, "6": 0.00042565056355670094, "7": 0.0003885475161951035, "8": 0.000357394281309098, "9": 0.2145601511001587, "10": 0.0003080035967286676, "11": 0.0002880966349039227, "12": 0.08616364002227783, "13": 0.0002551187644712627, "14": 0.00024130777455866337, "15": 0.06872931122779846, "16": 0.00021773351181764156, "17": 0.00020759322796948254, "18": 0.00019835542479995638, "19": 0.00018990473472513258}}, {"key": "sun2023short", "year": "2023", "title": "A Short Survey Of Viewing Large Language Models In Legal Aspect", "topic_distr": {"0": 0.05802978575229645, "1": 0.0010608227457851171, "2": 0.0008967183530330658, "3": 0.0007766882190480828, "4": 0.0006850060308352113, "5": 0.047916900366544724, "6": 0.0005541809950955212, "7": 0.000505874224472791, "8": 0.00046531387488357723, "9": 0.6577986478805542, "10": 0.00040100907790474594, "11": 0.0003750909527298063, "12": 0.22853033244609833, "13": 0.0003321550029795617, "14": 0.00031417360878549516, "15": 0.00029803908546455204, "16": 0.0002834808256011456, "17": 0.00027027857140637934, "18": 0.0002582512970548123, "19": 0.00024724879767745733}}, {"key": "sun2023simple", "year": "2023", "title": "A Simple And Effective Pruning Approach For Large Language Models", "topic_distr": {"0": 0.0012722655665129423, "1": 0.0010391682153567672, "2": 0.46077537536621094, "3": 0.3369603455066681, "4": 0.0006710896268486977, "5": 0.0006002401933073997, "6": 0.0005429223529063165, "7": 0.0004955969634465873, "8": 0.0004558606306090951, "9": 0.00042202332406304777, "10": 0.00039286224637180567, "11": 0.00036747066769748926, "12": 0.0003451620286796242, "13": 0.16353024542331696, "14": 0.0003077909059356898, "15": 0.0002919841790571809, "16": 0.016427665948867798, "17": 0.00026478763902559876, "18": 0.000253004691330716, "19": 0.014584127813577652}}, {"key": "sun2023think", "year": "2023", "title": "Think-on-graph: Deep And Responsible Reasoning Of Large Language Model On Knowledge Graph", "topic_distr": {"0": 0.07089817523956299, "1": 0.0007894595619291067, "2": 0.0006674053147435188, "3": 0.48282918334007263, "4": 0.0005098187830299139, "5": 0.0004559949738904834, "6": 0.00041245133616030216, "7": 0.00037649882142432034, "8": 0.0003463116299826652, "9": 0.0003206058463547379, "10": 0.0002984525344800204, "11": 0.09056811779737473, "12": 0.0002622152678668499, "13": 0.1467168778181076, "14": 0.00023382491781376302, "15": 0.0002218167355749756, "16": 0.2035154104232788, "17": 0.0002011558535741642, "18": 0.00019220450485590845, "19": 0.0001840158656705171}}, {"key": "sundararaman2019syntax", "year": "2019", "title": "Syntax-infused Transformer And BERT Models For Machine Translation And Natural Language Understanding", "topic_distr": {"0": 0.0013856770237907767, "1": 0.21899981796741486, "2": 0.3231053650379181, "3": 0.000828507705591619, "4": 0.0007307081832550466, "5": 0.0006535645807161927, "6": 0.0005911547341383994, "7": 0.0005396250053308904, "8": 0.0004963585524819791, "9": 0.0004595152277033776, "10": 0.2693095803260803, "11": 0.03605552762746811, "12": 0.00037582567892968655, "13": 0.00035431564901955426, "14": 0.1446666121482849, "15": 0.0003179235791321844, "16": 0.0003023940371349454, "17": 0.0002883109264075756, "18": 0.00027548123034648597, "19": 0.0002637447032611817}}, {"key": "sung2021vl", "year": "2021", "title": "Vl-adapter: Parameter-efficient Transfer Learning For Vision-and-language Tasks", "topic_distr": {"0": 0.001355571672320366, "1": 0.0011070809559896588, "2": 0.16108828783035278, "3": 0.16611377894878387, "4": 0.0007148716249503195, "5": 0.0006393999792635441, "6": 0.000578342704102397, "7": 0.0005279298056848347, "8": 0.0004856010782532394, "9": 0.00044955621706321836, "10": 0.00041849265107885003, "11": 0.00039144454058259726, "12": 0.0003676804481074214, "13": 0.33249443769454956, "14": 0.1172504723072052, "15": 0.00031103327637538314, "16": 0.0002958402910735458, "17": 0.09350541979074478, "18": 0.1216466873884201, "19": 0.0002580285945441574}}, {"key": "suri2023do", "year": "2023", "title": "Do Large Language Models Show Decision Heuristics Similar To Humans? A Case Study Using GPT-3.5", "topic_distr": {"0": 0.3646712601184845, "1": 0.0007959272479638457, "2": 0.0006726632709614933, "3": 0.20212730765342712, "4": 0.05204812437295914, "5": 0.0004595888312906027, "6": 0.0587894469499588, "7": 0.03656904771924019, "8": 0.0003490410454105586, "9": 0.1314915269613266, "10": 0.0003008047351613641, "11": 0.020188892260193825, "12": 0.0002642819017637521, "13": 0.0002491559716872871, "14": 0.0002356677723582834, "15": 0.06191938742995262, "16": 0.0002126445178873837, "17": 0.06827607750892639, "18": 0.00019371934467926621, "19": 0.00018546616774983704}}, {"key": "sur\u00eds2023visual", "year": "2023", "title": "Vipergpt: Visual Inference Via Python Execution For Reasoning", "topic_distr": {"0": 0.001918173860758543, "1": 0.0015668985433876514, "2": 0.0013245465233922005, "3": 0.5040560960769653, "4": 0.0010118137579411268, "5": 0.0909961611032486, "6": 0.0008185734623111784, "7": 0.0007472201832570136, "8": 0.08678565174341202, "9": 0.0006362919230014086, "10": 0.0005923252319917083, "11": 0.12062785029411316, "12": 0.0005204068147577345, "13": 0.0004906217800453305, "14": 0.0004640617407858372, "15": 0.00044022963265888393, "16": 0.0004187258018646389, "17": 0.0003992249257862568, "18": 0.18581995368003845, "19": 0.00036520796129480004}}, {"key": "susnjak2022end", "year": "2022", "title": "Chatgpt: The End Of Online Exam Integrity?", "topic_distr": {"0": 0.17346574366092682, "1": 0.31795811653137207, "2": 0.0008785206591710448, "3": 0.0007609226158820093, "4": 0.0006711017340421677, "5": 0.0006002509617246687, "6": 0.0005429320153780282, "7": 0.0004956058692187071, "8": 0.00045586880878545344, "9": 0.4276646077632904, "10": 0.00039286926039494574, "11": 0.0738053247332573, "12": 0.00034516819869168103, "13": 0.0003254128387197852, "14": 0.0003077964356634766, "15": 0.00029198938864283264, "16": 0.0002777266490738839, "17": 0.00026479235384613276, "18": 0.00025300923152826726, "19": 0.00024223007494583726}}, {"key": "suzgun2022challenging", "year": "2022", "title": "Challenging Big-bench Tasks And Whether Chain-of-thought Can Solve Them", "topic_distr": {"0": 0.0014341443311423063, "1": 0.001170812058262527, "2": 0.3433411717414856, "3": 0.5771012306213379, "4": 0.0007559688528999686, "5": 0.0006761575932614505, "6": 0.0006115902797318995, "7": 0.0005582792800851166, "8": 0.0005135171813890338, "9": 0.030192917212843895, "10": 0.0004425508086569607, "11": 0.00041394776781089604, "12": 0.00038881757063791156, "13": 0.040554340928792953, "14": 0.00034671981120482087, "15": 0.00032891385490074754, "16": 0.00031284746364690363, "17": 0.00029827753314748406, "18": 0.00028500432381406426, "19": 0.0002728620602283627}}, {"key": "svyatkovskiy2019ai", "year": "2019", "title": "Pythia: Ai-assisted Code Completion System", "topic_distr": {"0": 0.0016630764584988356, "1": 0.0013579856604337692, "2": 0.18243221938610077, "3": 0.11075101792812347, "4": 0.17476481199264526, "5": 0.0007844085921533406, "6": 0.422988623380661, "7": 0.0006476580165326595, "8": 0.0005957296234555542, "9": 0.08148493617773056, "10": 0.0005134018138051033, "11": 0.00048021948896348476, "12": 0.00045106600737199187, "13": 0.0004252496873959899, "14": 0.00040222855750471354, "15": 0.0003815719101112336, "16": 0.000362933351425454, "17": 0.00034603080712258816, "18": 0.018850233405828476, "19": 0.0003165464149788022}}, {"key": "svyatkovskiy2020intellicode", "year": "2020", "title": "Intellicode Compose: Code Generation Using Transformer", "topic_distr": {"0": 0.0015401088166981936, "1": 0.0012574443826451898, "2": 0.08675353229045868, "3": 0.047031745314598083, "4": 0.0008120248094201088, "5": 0.000726295926142484, "6": 0.3137243688106537, "7": 0.0005996766849420965, "8": 0.000551595410797745, "9": 0.13689717650413513, "10": 0.10615096986293793, "11": 0.04376297444105148, "12": 0.0004176490765530616, "13": 0.17810523509979248, "14": 0.026847295463085175, "15": 0.00035330341779626906, "16": 0.03569165989756584, "17": 0.0003203953674528748, "18": 0.018163451924920082, "19": 0.0002930952759925276}}, {"key": "tack2022ai", "year": "2022", "title": "The AI Teacher Test: Measuring The Pedagogical Ability Of Blender And GPT-3 In Educational Dialogues", "topic_distr": {"0": 0.23924103379249573, "1": 0.0010609956225380301, "2": 0.0008968638139776886, "3": 0.16191606223583221, "4": 0.0006851059733889997, "5": 0.0006127770757302642, "6": 0.12063895165920258, "7": 0.0005059479153715074, "8": 0.0004653816868085414, "9": 0.22148872911930084, "10": 0.0004010674892924726, "11": 0.12325521558523178, "12": 0.0003523710183799267, "13": 0.1268077939748764, "14": 0.0003142193891108036, "15": 0.0002980825083795935, "16": 0.00028352212393656373, "17": 0.0002703179488889873, "18": 0.00025828892830759287, "19": 0.00024728482821956277}}, {"key": "tafjord2020generating", "year": "2020", "title": "Proofwriter: Generating Implications, Proofs, And Abductive Statements Over Natural Language", "topic_distr": {"0": 0.26699402928352356, "1": 0.0012271918822079897, "2": 0.2138907015323639, "3": 0.2061644345521927, "4": 0.0007923910161480308, "5": 0.0007087355479598045, "6": 0.0006410570931620896, "7": 0.06736545264720917, "8": 0.015337739139795303, "9": 0.0004983052494935691, "10": 0.03216308355331421, "11": 0.13701768219470978, "12": 0.00040755103691481054, "13": 0.0003842252481263131, "14": 0.0003634250024333596, "15": 0.05481866002082825, "16": 0.00032792065758258104, "17": 0.00031264874269254506, "18": 0.000298736005788669, "19": 0.0002860087261069566}}, {"key": "tafjord2021general", "year": "2021", "title": "General-purpose Question-answering With Macaw", "topic_distr": {"0": 0.05959383025765419, "1": 0.0011317364405840635, "2": 0.12772047519683838, "3": 0.16990123689174652, "4": 0.0007307620253413916, "5": 0.0006536121945828199, "6": 0.0463666096329689, "7": 0.06598404794931412, "8": 0.20187979936599731, "9": 0.06990107893943787, "10": 0.0004277946427464485, "11": 0.000400145334424451, "12": 0.10421118140220642, "13": 0.07108612358570099, "14": 0.0003351589839439839, "15": 0.00031794674578122795, "16": 0.0003024160396307707, "17": 0.00028833193937316537, "18": 0.0002755013119895011, "19": 0.07849220186471939}}, {"key": "talmor2019empirical", "year": "2019", "title": "Multiqa: An Empirical Investigation Of Generalization And Transfer In Reading Comprehension", "topic_distr": {"0": 0.0013282205909490585, "1": 0.08694654703140259, "2": 0.5126262307167053, "3": 0.0007933120359666646, "4": 0.000699665688443929, "5": 0.0006257997010834515, "6": 0.0005660410970449448, "7": 0.0005167005001567304, "8": 0.00047527209972031415, "9": 0.0004399939498398453, "10": 0.04081366956233978, "11": 0.0003831183130387217, "12": 0.08683324605226517, "13": 0.022370800375938416, "14": 0.18110378086566925, "15": 0.00030441745184361935, "16": 0.0002895476354751736, "17": 0.04630207270383835, "18": 0.0002637781435623765, "19": 0.016317784786224365}}, {"key": "talmor2019olmpics", "year": "2019", "title": "Olmpics -- On What Language Model Pre-training Captures", "topic_distr": {"0": 0.13812260329723358, "1": 0.0011707115918397903, "2": 0.06252170354127884, "3": 0.3274839520454407, "4": 0.00075597467366606, "5": 0.0006761623080819845, "6": 0.0006115944706834853, "7": 0.0005582831799983978, "8": 0.0005135207320563495, "9": 0.00047540347441099584, "10": 0.08037187904119492, "11": 0.186249777674675, "12": 0.0003888202481903136, "13": 0.0003665664989966899, "14": 0.0003467222268227488, "15": 0.0003289161541033536, "16": 0.0003128496464341879, "17": 0.0002982795995194465, "18": 0.0002850063028745353, "19": 0.1981613039970398}}, {"key": "talmor2020leap", "year": "2020", "title": "Leap-of-thought: Teaching Pre-trained Models To Systematically Reason Over Implicit Knowledge", "topic_distr": {"0": 0.15831255912780762, "1": 0.0009608220425434411, "2": 0.11465927958488464, "3": 0.22244584560394287, "4": 0.000620452978182584, "5": 0.04580630362033844, "6": 0.0005019556847400963, "7": 0.0004582013061735779, "8": 0.0004214633081573993, "9": 0.0003901792224496603, "10": 0.00036321848165243864, "11": 0.19139842689037323, "12": 0.00031911753467284143, "13": 0.021547233685851097, "14": 0.0002845663111656904, "15": 0.00026995225925929844, "16": 0.1680106222629547, "17": 0.0002448078594170511, "18": 0.0002339140191907063, "19": 0.07275109738111496}}, {"key": "talmor2021complex", "year": "2021", "title": "Multimodalqa: Complex Question Answering Over Text, Tables And Images", "topic_distr": {"0": 0.0012869351776316762, "1": 0.0010501848300918937, "2": 0.2405831515789032, "3": 0.0007688026526011527, "4": 0.0006780512048862875, "5": 0.0006064669578336179, "6": 0.0005485545261763036, "7": 0.03742165118455887, "8": 0.28863638639450073, "9": 0.00042640132596716285, "10": 0.000396937713958323, "11": 0.06662815064191818, "12": 0.00034874267294071615, "13": 0.0003287827130407095, "14": 0.00031098388717509806, "15": 0.053496718406677246, "16": 0.0002806026895996183, "17": 0.00026753448764793575, "18": 0.23688502609729767, "19": 0.06904991716146469}}, {"key": "talmor2022commonsenseqa", "year": "2022", "title": "Commonsenseqa 2.0: Exposing The Limits Of AI Through Gamification", "topic_distr": {"0": 0.0016002437332645059, "1": 0.3026215732097626, "2": 0.19968727231025696, "3": 0.0009560442413203418, "4": 0.0008431897731497884, "5": 0.0007541694794781506, "6": 0.0006821524584665895, "7": 0.0006226906552910805, "8": 0.03212927654385567, "9": 0.07122490555047989, "10": 0.0004936100449413061, "11": 0.3125700354576111, "12": 0.0004336773417890072, "13": 0.07332371175289154, "14": 0.00038672256050631404, "15": 0.00036686225212179124, "16": 0.0003489422088023275, "17": 0.00033269127015955746, "18": 0.00031788667547516525, "19": 0.0003043434990104288}}, {"key": "tam2021improving", "year": "2021", "title": "Improving And Simplifying Pattern Exploiting Training", "topic_distr": {"0": 0.002496629487723112, "1": 0.0020373573061078787, "2": 0.40297630429267883, "3": 0.0014913133345544338, "4": 0.0013152708997949958, "5": 0.0011764129158109426, "6": 0.0010640752734616399, "7": 0.0009713220642879605, "8": 0.0008934427169151604, "9": 0.0008271248661912978, "10": 0.0007699719280935824, "11": 0.000720206939149648, "12": 0.0006764841382391751, "13": 0.24186722934246063, "14": 0.28406137228012085, "15": 0.0005722607020288706, "16": 0.0005443075788207352, "17": 0.0005189580842852592, "18": 0.0004958647186867893, "19": 0.05452405661344528}}, {"key": "tambe2020sentence", "year": "2020", "title": "Edgebert: Sentence-level Energy Optimizations For Latency-aware Multi-task NLP Inference", "topic_distr": {"0": 0.0013700091512873769, "1": 0.0011192183010280132, "2": 0.2871137857437134, "3": 0.0008195051341317594, "4": 0.0007227719761431217, "5": 0.03845471143722534, "6": 0.0005847331485711038, "7": 0.0005337632028385997, "8": 0.0004909667768515646, "9": 0.05018962547183037, "10": 0.1993265599012375, "11": 0.0003957698354497552, "12": 0.0003717431682161987, "13": 0.3638368248939514, "14": 0.0003314940840937197, "15": 0.00031447006040252745, "16": 0.05320552736520767, "17": 0.00028517909231595695, "18": 0.00027248874539509416, "19": 0.0002608796930871904}}, {"key": "tambwekar2018controllable", "year": "2018", "title": "Controllable Neural Story Plot Generation Via Reward Shaping", "topic_distr": {"0": 0.0017341370694339275, "1": 0.0014147859765216708, "2": 0.06503280252218246, "3": 0.0010357745923101902, "4": 0.024827539920806885, "5": 0.0008170666988007724, "6": 0.000739043578505516, "7": 0.5021982192993164, "8": 0.00062053237343207, "9": 0.0005744719528593123, "10": 0.0005347768892534077, "11": 0.23023495078086853, "12": 0.000469845806946978, "13": 0.0004429546243045479, "14": 0.0004189750470686704, "15": 0.00039745838148519397, "16": 0.00037804379826411605, "17": 0.08181082457304001, "18": 0.00034439825685694814, "19": 0.08597344905138016}}, {"key": "tamkin2021understanding", "year": "2021", "title": "Understanding The Capabilities, Limitations, And Societal Impact Of Large Language Models", "topic_distr": {"0": 0.12191381305456161, "1": 0.0022141090594232082, "2": 0.0018715441692620516, "3": 0.0016210598405450583, "4": 0.0014297126326709986, "5": 0.0012787730665877461, "6": 0.001156661193817854, "7": 0.0010558374924585223, "8": 0.0671059861779213, "9": 0.766535758972168, "10": 0.0008369677816517651, "11": 0.0007828726666048169, "12": 0.0007353455293923616, "13": 0.0006932587129995227, "14": 0.0006557287997566164, "15": 0.0006220535724423826, "16": 0.0005916681839153171, "17": 0.0005641130264848471, "18": 0.0005390102742239833, "19": 0.02779570035636425}}, {"key": "tan2019learning", "year": "2019", "title": "LXMERT: Learning Cross-modality Encoder Representations From Transformers", "topic_distr": {"0": 0.0011766962707042694, "1": 0.0009608648833818734, "2": 0.14889582991600037, "3": 0.02466869354248047, "4": 0.0006205102545209229, "5": 0.0005550005007535219, "6": 0.0005020026583224535, "7": 0.0004582441470120102, "8": 0.03657374903559685, "9": 0.00039021571865305305, "10": 0.34423452615737915, "11": 0.0003397746477276087, "12": 0.00031914739520289004, "13": 0.0003008812782354653, "14": 0.0002845929120667279, "15": 0.0002699775213841349, "16": 0.00025678996462374926, "17": 0.0002448307641316205, "18": 0.43872368335723877, "19": 0.000223969342187047}}, {"key": "tan2020improving", "year": "2020", "title": "Vokenization: Improving Language Understanding With Contextualized, Visual-grounded Supervision", "topic_distr": {"0": 0.16095489263534546, "1": 0.0014978244435042143, "2": 0.36803728342056274, "3": 0.001096604741178453, "4": 0.0009671556763350964, "5": 0.0008650482050143182, "6": 0.0007824433851055801, "7": 0.0007142394897527993, "8": 0.0006569726974703372, "9": 0.0006082073668949306, "10": 0.0005661812610924244, "11": 0.000529587734490633, "12": 0.0004974371404387057, "13": 0.0004689668130595237, "14": 0.00044357901788316667, "15": 0.09033067524433136, "16": 0.0004002441419288516, "17": 0.0003816039825323969, "18": 0.33758261799812317, "19": 0.03261841461062431}}, {"key": "tan2020progressive", "year": "2020", "title": "Progressive Generation Of Long Text With Pretrained Language Models", "topic_distr": {"0": 0.0011251618852838874, "1": 0.02987516112625599, "2": 0.0007756630657240748, "3": 0.203224778175354, "4": 0.0005925186560489237, "5": 0.0005299631739035249, "6": 0.0004793559783138335, "7": 0.23881693184375763, "8": 0.036426279693841934, "9": 0.000372612033970654, "10": 0.00034686518483795226, "11": 0.0003244465042371303, "12": 0.0003047497884836048, "13": 0.06822434067726135, "14": 0.0002717541647143662, "15": 0.30431199073791504, "16": 0.00024520550505258143, "17": 0.00023378578771371394, "18": 0.022975772619247437, "19": 0.09054269641637802}}, {"key": "tan2023can", "year": "2023", "title": "Can Chatgpt Replace Traditional KBQA Models? An In-depth Analysis Of The Question Answering Performance Of The GPT LLM Family", "topic_distr": {"0": 0.001261466764844954, "1": 0.08066978305578232, "2": 0.0008696933509781957, "3": 0.47490206360816956, "4": 0.0006643374799750745, "5": 0.0005942006828263402, "6": 0.0005374595057219267, "7": 0.0004906103131361306, "8": 0.17296163737773895, "9": 0.18059641122817993, "10": 0.0003889092768076807, "11": 0.000363773200660944, "12": 0.0003416890394873917, "13": 0.0003221327788196504, "14": 0.04055933654308319, "15": 0.00028904626378789544, "16": 0.043435048311948776, "17": 0.00026212335797026753, "18": 0.0002504589792806655, "19": 0.00023978848184924573}}, {"key": "tan2024large", "year": "2024", "title": "Large Language Models For Data Annotation And Synthesis: A Survey", "topic_distr": {"0": 0.0011762416688725352, "1": 0.36443373560905457, "2": 0.0008121588034555316, "3": 0.0007034520385786891, "4": 0.0006204144447110593, "5": 0.0005549148772843182, "6": 0.0005019252421334386, "7": 0.017380045726895332, "8": 0.00042143772589042783, "9": 0.28683093190193176, "10": 0.0003631964500527829, "11": 0.00033972226083278656, "12": 0.3240470886230469, "13": 0.00030083488672971725, "14": 0.0002845490234903991, "15": 0.0002699358738027513, "16": 0.0002567503834143281, "17": 0.00024479301646351814, "18": 0.00023389983107335865, "19": 0.0002239348104922101}}, {"key": "tandon2018reasoning", "year": "2018", "title": "Reasoning About Actions And State Changes By Injecting Commonsense Knowledge", "topic_distr": {"0": 0.05977785214781761, "1": 0.0013056962052360177, "2": 0.4421299397945404, "3": 0.00095600780332461, "4": 0.02834797091782093, "5": 0.000754142994992435, "6": 0.0006821284769102931, "7": 0.09837094694375992, "8": 0.14438503980636597, "9": 0.0005302307545207441, "10": 0.0004935926990583539, "11": 0.08285795152187347, "12": 0.00043366209138184786, "13": 0.00040884187910705805, "14": 0.0003867089981213212, "15": 0.0003668493591248989, "16": 0.08900929242372513, "17": 0.04818093404173851, "18": 0.00031787549960426986, "19": 0.0003043327888008207}}, {"key": "tang2017question", "year": "2017", "title": "Question Answering And Question Generation As Dual Tasks", "topic_distr": {"0": 0.0014023290714249015, "1": 0.0011444415431469679, "2": 0.35416945815086365, "3": 0.0008378844358958304, "4": 0.0007389776292257011, "5": 0.0006609605043195188, "6": 0.04120809584856033, "7": 0.09582103043794632, "8": 0.37106314301490784, "9": 0.0004647151508834213, "10": 0.0004326041089370847, "11": 0.0004046439426019788, "12": 0.00038007856346666813, "13": 0.017013397067785263, "14": 0.0003389269986655563, "15": 0.0003215212491340935, "16": 0.11276087164878845, "17": 0.0002915734949056059, "18": 0.0002785986289381981, "19": 0.0002667292719706893}}, {"key": "tang2020multilingual", "year": "2020", "title": "Multilingual Translation With Extensible Multilingual Pretraining And Finetuning", "topic_distr": {"0": 0.0012224063975736499, "1": 0.0009986261138692498, "2": 0.05227907374501228, "3": 0.0007311514928005636, "4": 0.000644842570181936, "5": 0.0005767641123384237, "6": 0.014784647151827812, "7": 0.0004762136086355895, "8": 0.00043803142034448683, "9": 0.0004055175231769681, "10": 0.000377496937289834, "11": 0.00035309846862219274, "12": 0.0003316623333375901, "13": 0.026133567094802856, "14": 0.646466851234436, "15": 0.00028056433075107634, "16": 0.00026685965713113546, "17": 0.0002544314775150269, "18": 0.00024310940352734178, "19": 0.25273510813713074}}, {"key": "tang2020rapidly", "year": "2020", "title": "Rapidly Bootstrapping A Question Answering Dataset For COVID-19", "topic_distr": {"0": 0.0018088503275066614, "1": 0.001476349658332765, "2": 0.001247837208211422, "3": 0.0010807942599058151, "4": 0.09606076776981354, "5": 0.0008525801822543144, "6": 0.02654670923948288, "7": 0.0007039449410513043, "8": 0.10141061246395111, "9": 0.04155728965997696, "10": 0.000558020721655339, "11": 0.0005219546146690845, "12": 0.5631824731826782, "13": 0.0004622074484359473, "14": 0.1606408804655075, "15": 0.00041473371675238013, "16": 0.0003944752970710397, "17": 0.0003761037951335311, "18": 0.0003593673463910818, "19": 0.000344056956237182}}, {"key": "tang2021clip", "year": "2021", "title": "Clip4caption: CLIP For Video Caption", "topic_distr": {"0": 0.0013120933435857296, "1": 0.02527894824743271, "2": 0.239393413066864, "3": 0.0007849183166399598, "4": 0.026392929255962372, "5": 0.0006191812572069466, "6": 0.0005600546137429774, "7": 0.0005112358485348523, "8": 0.0004702456353697926, "9": 0.0004353405674919486, "10": 0.08915502578020096, "11": 0.00037906644865870476, "12": 0.0003560538461897522, "13": 0.00033567543141543865, "14": 0.00031750346533954144, "15": 0.06040765345096588, "16": 0.00028648535953834653, "17": 0.00027314317412674427, "18": 0.5524811148643494, "19": 0.0002498693356756121}}, {"key": "tang2023does", "year": "2023", "title": "Does Synthetic Data Generation Of Llms Help Clinical Text Mining?", "topic_distr": {"0": 0.0010063317604362965, "1": 0.13336101174354553, "2": 0.0006943383486941457, "3": 0.1304461807012558, "4": 0.0005303968791849911, "5": 0.00047440084745176136, "6": 0.0004290995711926371, "7": 0.08966098725795746, "8": 0.02372680976986885, "9": 0.30796074867248535, "10": 0.00031049930839799345, "11": 0.0002904310531448573, "12": 0.0002727993705775589, "13": 0.058971941471099854, "14": 0.0002432630572002381, "15": 0.00023077017976902425, "16": 0.0885811373591423, "17": 0.1624174565076828, "18": 0.0001999626838369295, "19": 0.000191443512449041}}, {"key": "tang2023graph", "year": "2023", "title": "Graphgpt: Graph Instruction Tuning For Large Language Models", "topic_distr": {"0": 0.001210840535350144, "1": 0.08289899677038193, "2": 0.0008359114872291684, "3": 0.22785042226314545, "4": 0.0006385442684404552, "5": 0.0005711300764232874, "6": 0.0005165920010767877, "7": 0.00047156179789453745, "8": 0.00043375257519073784, "9": 0.00040155628812499344, "10": 0.00037380942376330495, "11": 0.07887967675924301, "12": 0.08730846643447876, "13": 0.0003096256114076823, "14": 0.0002928638714365661, "15": 0.0002778237103484571, "16": 0.33082476258277893, "17": 0.18543244898319244, "18": 0.0002407346328254789, "19": 0.00023047842842061073}}, {"key": "tang2023large", "year": "2023", "title": "Medagents: Large Language Models As Collaborators For Zero-shot Medical Reasoning", "topic_distr": {"0": 0.001450748648494482, "1": 0.015390261076390743, "2": 0.0010012086713686585, "3": 0.4886193573474884, "4": 0.02668374963104725, "5": 0.0006840749410912395, "6": 0.0006187515682540834, "7": 0.0005648163496516645, "8": 0.0005195300909690559, "9": 0.10030140727758408, "10": 0.0004477327747736126, "11": 0.0979592576622963, "12": 0.19607587158679962, "13": 0.0003708561707753688, "14": 0.00035077965003438294, "15": 0.000332765222992748, "16": 0.06776263564825058, "17": 0.00030177016742527485, "18": 0.00028834151453338563, "19": 0.0002760570787359029}}, {"key": "tang2023science", "year": "2023", "title": "The Science Of Detecting Llm-generated Texts", "topic_distr": {"0": 0.12183175981044769, "1": 0.0017262687906622887, "2": 0.001459168503060937, "3": 0.0012638636399060488, "4": 0.0011146749602630734, "5": 0.0009969938546419144, "6": 0.0009017893462441862, "7": 0.04441267251968384, "8": 0.0007571805617772043, "9": 0.14452242851257324, "10": 0.0006525407661683857, "11": 0.0006103655905462801, "12": 0.3938903212547302, "13": 0.0005404982366599143, "14": 0.000511238060425967, "15": 0.28308457136154175, "16": 0.0004612932971213013, "17": 0.00043980995542369783, "18": 0.00042023861897177994, "19": 0.000402334873797372}}, {"key": "tang2023when", "year": "2023", "title": "When Prompt-based Incremental Learning Does Not Meet Strong Pretraining", "topic_distr": {"0": 0.001200114726088941, "1": 0.031065920367836952, "2": 0.10210941731929779, "3": 0.0007170878816395998, "4": 0.0006324431160464883, "5": 0.0005656727007590234, "6": 0.0005116556421853602, "7": 0.02674214541912079, "8": 0.00042960778228007257, "9": 0.00039771918090991676, "10": 0.0003702374524436891, "11": 0.00034630816662684083, "12": 0.00032528425799682736, "13": 0.08619022369384766, "14": 0.00029006536351516843, "15": 0.00027516891714185476, "16": 0.18230979144573212, "17": 0.40380391478538513, "18": 0.00023843425151426345, "19": 0.16147875785827637}}, {"key": "tay2018multi", "year": "2018", "title": "Multi-cast Attention Networks For Retrieval-based Question Answering And Response Prediction", "topic_distr": {"0": 0.020342741161584854, "1": 0.017883989959955215, "2": 0.6118236780166626, "3": 0.0006905290065333247, "4": 0.031592484563589096, "5": 0.10502972453832626, "6": 0.03893044963479042, "7": 0.0004497569752857089, "8": 0.04963525012135506, "9": 0.0003829884808510542, "10": 0.12081030011177063, "11": 0.000333481642883271, "12": 0.0003132364363409579, "13": 0.0002953086222987622, "14": 0.0002793219464365393, "15": 0.00026497722137719393, "16": 0.00025203393306583166, "17": 0.00024029621272347867, "18": 0.0002296031452715397, "19": 0.00021982118778396398}}, {"key": "tay2019simple", "year": "2019", "title": "Simple And Effective Curriculum Pointer-generator Networks For Reading Comprehension Over Long Narratives", "topic_distr": {"0": 0.0015398154500871897, "1": 0.0012575285509228706, "2": 0.6514280438423157, "3": 0.0009206411777995527, "4": 0.02458007261157036, "5": 0.0007262430153787136, "6": 0.0006568928947672248, "7": 0.0005996329709887505, "8": 0.055909838527441025, "9": 0.0005106147145852447, "10": 0.00047533211181871593, "11": 0.0004446103412192315, "12": 0.00041761863394640386, "13": 0.0315467044711113, "14": 0.0003724025737028569, "15": 0.12072831392288208, "16": 0.0003360211558174342, "17": 0.000320371997077018, "18": 0.08798200637102127, "19": 0.019247349351644516}}, {"key": "tay2020long", "year": "2020", "title": "Long Range Arena: A Benchmark For Efficient Transformers", "topic_distr": {"0": 0.0011348663829267025, "1": 0.034365471452474594, "2": 0.09295165538787842, "3": 0.20193293690681458, "4": 0.0005979317938908935, "5": 0.0005348057602532208, "6": 0.00048373633762821555, "7": 0.0004415700677782297, "8": 0.00040616554906591773, "9": 0.00037601697840727866, "10": 0.39202356338500977, "11": 0.00032741131144575775, "12": 0.14010865986347198, "13": 0.0002899331448134035, "14": 0.00027423747815191746, "15": 0.0002601538726594299, "16": 0.03364992514252663, "17": 0.05376363545656204, "18": 0.045861490070819855, "19": 0.00021581980399787426}}, {"key": "tay2020rethinking", "year": "2020", "title": "Synthesizer: Rethinking Self-attention In Transformer Models", "topic_distr": {"0": 0.10211050510406494, "1": 0.03755202144384384, "2": 0.46795153617858887, "3": 0.0008571523358114064, "4": 0.10267986357212067, "5": 0.000676159979775548, "6": 0.0006115923752076924, "7": 0.0005582812009379268, "8": 0.0005135189276188612, "9": 0.0004754018154926598, "10": 0.20795974135398865, "11": 0.0004139491938985884, "12": 0.0003888188803102821, "13": 0.0003665652184281498, "14": 0.031379375606775284, "15": 0.04433653876185417, "16": 0.00031284854048863053, "17": 0.00029827855178155005, "18": 0.0002850053133442998, "19": 0.0002728629915509373}}, {"key": "tay2021are", "year": "2021", "title": "Are Pre-trained Convolutions Better Than Pre-trained Transformers?", "topic_distr": {"0": 0.21094389259815216, "1": 0.0019590104930102825, "2": 0.28295964002609253, "3": 0.0014341258211061358, "4": 0.0012648346601054072, "5": 0.0011313008144497871, "6": 0.00102327112108469, "7": 0.0009340748656541109, "8": 0.0008591819205321372, "9": 0.045040640980005264, "10": 0.15214915573596954, "11": 0.000692589208483696, "12": 0.21572533249855042, "13": 0.0006133098504506052, "14": 0.0005801079678349197, "15": 0.0005503162392415106, "16": 0.0005234350683167577, "17": 0.08068239688873291, "18": 0.0004768498183693737, "19": 0.00045653420966118574}}, {"key": "tay2021scale", "year": "2021", "title": "Scale Efficiently: Insights From Pre-training And Fine-tuning Transformers", "topic_distr": {"0": 0.0013002515770494938, "1": 0.0010610967874526978, "2": 0.17109525203704834, "3": 0.0007768372306600213, "4": 0.0006851379876025021, "5": 0.0006128050736151636, "6": 0.0005542872822843492, "7": 0.0005059712566435337, "8": 0.012383004650473595, "9": 0.08956350386142731, "10": 0.13886931538581848, "11": 0.0003751628682948649, "12": 0.1033802181482315, "13": 0.29289767146110535, "14": 0.0003142338537145406, "15": 0.00029809624538756907, "16": 0.0002835351915564388, "17": 0.00027033037622459233, "18": 0.0002583008026704192, "19": 0.18451498448848724}}, {"key": "tay2022unifying", "year": "2022", "title": "UL2: Unifying Language Learning Paradigms", "topic_distr": {"0": 0.0011140950955450535, "1": 0.00090938585344702, "2": 0.24691912531852722, "3": 0.0877392590045929, "4": 0.0005872425972484052, "5": 0.0005252451519481838, "6": 0.0004750887455884367, "7": 0.012467894703149796, "8": 0.0003989046672359109, "9": 0.0003692950413096696, "10": 0.00034377738484181464, "11": 0.0003215582692064345, "12": 0.1035492941737175, "13": 0.04586970433592796, "14": 0.00026933502522297204, "15": 0.0002555031969677657, "16": 0.012334740720689297, "17": 0.3757937550544739, "18": 0.0002213938714703545, "19": 0.10953540354967117}}, {"key": "taylor2022clinical", "year": "2022", "title": "Clinical Prompt Learning With Frozen Language Models", "topic_distr": {"0": 0.017540013417601585, "1": 0.000777607609052211, "2": 0.0006572639103978872, "3": 0.0005692634149454534, "4": 0.0005020663957111537, "5": 0.0004490609862841666, "6": 0.0004061793442815542, "7": 0.00037077360320836306, "8": 0.0003410454373806715, "9": 0.00031573057640343904, "10": 0.0002939141122624278, "11": 0.07708501070737839, "12": 0.0953589379787445, "13": 0.329565167427063, "14": 0.00023026925919111818, "15": 0.04377466067671776, "16": 0.00020777339523192495, "17": 0.4311847388744354, "18": 0.00018928175268229097, "19": 0.00018121763423550874}}, {"key": "taylor2022large", "year": "2022", "title": "Galactica: A Large Language Model For Science", "topic_distr": {"0": 0.0014681622851639986, "1": 0.001198301324620843, "2": 0.06823918223381042, "3": 0.14550042152404785, "4": 0.0007737792911939323, "5": 0.0006920886225998402, "6": 0.0006259999354369938, "7": 0.0005714328726753592, "8": 0.0005256161093711853, "9": 0.33573687076568604, "10": 0.0004529777215793729, "11": 0.00042370078153908253, "12": 0.0640212893486023, "13": 0.023992158472537994, "14": 0.17715585231781006, "15": 0.00033666339004412293, "16": 0.1417308747768402, "17": 0.00030530523508787155, "18": 0.00029171930509619415, "19": 0.035957589745521545}}, {"key": "tenney2019what", "year": "2019", "title": "What Do You Learn From Context? Probing For Sentence Structure In Contextualized Word Representations", "topic_distr": {"0": 0.05482117831707001, "1": 0.001476154662668705, "2": 0.22243420779705048, "3": 0.0010808337246999145, "4": 0.0009532507392577827, "5": 0.0008526121382601559, "6": 0.0007711949874646962, "7": 0.0007039715419523418, "8": 0.0006475280388258398, "9": 0.000599463761318475, "10": 0.2776034474372864, "11": 0.0005219743470661342, "12": 0.0823930874466896, "13": 0.0004622249398380518, "14": 0.04720399156212807, "15": 0.0004147494037169963, "16": 0.06942402571439743, "17": 0.00037611802690662444, "18": 0.00035938096698373556, "19": 0.23690064251422882}}, {"key": "tenney2020language", "year": "2020", "title": "The Language Interpretability Tool: Extensible, Interactive Visualizations And Analysis For NLP Models", "topic_distr": {"0": 0.1435399204492569, "1": 0.0013583749532699585, "2": 0.0011480461107566953, "3": 0.2869654893875122, "4": 0.0008769728592596948, "5": 0.16878165304660797, "6": 0.0007094842148944736, "7": 0.10112939029932022, "8": 0.0005957130924798548, "9": 0.13175463676452637, "10": 0.11914245039224625, "11": 0.0004802061594091356, "12": 0.0004510534927248955, "13": 0.00042523787124082446, "14": 0.00040221738163381815, "15": 0.00038156131631694734, "16": 0.04086441174149513, "17": 0.00034602120285853744, "18": 0.0003306234139017761, "19": 0.00031653762562200427}}, {"key": "tevet2018evaluating", "year": "2018", "title": "Evaluating Text Gans As Language Models", "topic_distr": {"0": 0.29100412130355835, "1": 0.07494226098060608, "2": 0.13562805950641632, "3": 0.03709501028060913, "4": 0.0010962201049551368, "5": 0.0009804867440834641, "6": 0.0008868586155585945, "7": 0.0008095530793070793, "8": 0.0007446441450156271, "9": 0.0006893711979500949, "10": 0.0006417368422262371, "11": 0.0006002599257044494, "12": 0.04469950497150421, "13": 0.0005315493326634169, "14": 0.0005027736187912524, "15": 0.25959426164627075, "16": 0.00045365578262135386, "17": 0.0004325281479395926, "18": 0.00041328082443214953, "19": 0.14825385808944702}}, {"key": "thakur2022benchmarking", "year": "2022", "title": "Benchmarking Large Language Models For Automated Verilog RTL Code Generation", "topic_distr": {"0": 0.0014349714620038867, "1": 0.0011710975086316466, "2": 0.0009895953116938472, "3": 0.769011914730072, "4": 0.0007559631485491991, "5": 0.0006761530530638993, "6": 0.1673167198896408, "7": 0.0005582752637565136, "8": 0.0005135134560987353, "9": 0.00047539675142616034, "10": 0.00044254763633944094, "11": 0.00041394479922018945, "12": 0.05402868986129761, "13": 0.0003665613185148686, "14": 0.00034671733737923205, "15": 0.00032891149749048054, "16": 0.00031284522265195847, "17": 0.0002982754085678607, "18": 0.0002850022865459323, "19": 0.0002728601102717221}}, {"key": "thakur2023large", "year": "2023", "title": "Verigen: A Large Language Model For Verilog Code Generation", "topic_distr": {"0": 0.0018341265385970473, "1": 0.0014975081430748105, "2": 0.0012660339707508683, "3": 0.8515474796295166, "4": 0.0009671273292042315, "5": 0.0008650235249660909, "6": 0.13562141358852386, "7": 0.0007142191170714796, "8": 0.000656953954603523, "9": 0.0006081900210119784, "10": 0.0005661651375703514, "11": 0.0005295726004987955, "12": 0.0004974229959771037, "13": 0.0004689534252975136, "14": 0.00044356638682074845, "15": 0.000420786818722263, "16": 0.00040023273322731256, "17": 0.0003815930976998061, "18": 0.00036461238050833344, "19": 0.00034907853114418685}}, {"key": "theophilou2023learning", "year": "2023", "title": "Learning To Prompt In The Classroom To Understand AI Limits: A Pilot Study", "topic_distr": {"0": 0.026291120797395706, "1": 0.14496251940727234, "2": 0.00061499432194978, "3": 0.27277517318725586, "4": 0.0004697931872215122, "5": 0.0004201953415758908, "6": 0.014415133744478226, "7": 0.02050105482339859, "8": 0.0003191229188814759, "9": 0.5034593939781189, "10": 0.00027502121520228684, "11": 0.013880772516131401, "12": 0.0002416289207758382, "13": 0.000227799522690475, "14": 0.00021546747302636504, "15": 0.00020440203661564738, "16": 0.00019441764743532985, "17": 0.00018536322750151157, "18": 0.00017711464897729456, "19": 0.00016956889885477722}}, {"key": "thomason2019improving", "year": "2019", "title": "Improving Grounded Natural Language Understanding Through Human-robot Dialog", "topic_distr": {"0": 0.0016862102784216404, "1": 0.0013764481991529465, "2": 0.10576426982879639, "3": 0.0010077854385599494, "4": 0.07352682948112488, "5": 0.0666065365076065, "6": 0.03988703340291977, "7": 0.0006563912029378116, "8": 0.0006037626299075782, "9": 0.0005589469219557941, "10": 0.0005203246255405247, "11": 0.5474042892456055, "12": 0.0004571483295876533, "13": 0.00043098386959172785, "14": 0.00040765231824479997, "15": 0.0003867171471938491, "16": 0.00036782724782824516, "17": 0.11519253998994827, "18": 0.04283754527568817, "19": 0.0003208148118574172}}, {"key": "thompson2020paraphrase", "year": "2020", "title": "Paraphrase Generation As Zero-shot Multilingual Translation: Disentangling Semantic Similarity From Lexical And Syntactic Diversity", "topic_distr": {"0": 0.09809193760156631, "1": 0.0011578690027818084, "2": 0.11480270326137543, "3": 0.0008473708294332027, "4": 0.0007473468431271613, "5": 0.0006684469990432262, "6": 0.0006046160124242306, "7": 0.23659434914588928, "8": 0.0005076612578704953, "9": 0.0004699789278674871, "10": 0.00043750417535193264, "11": 0.00040922730113379657, "12": 0.0003843836602754891, "13": 0.00036238384200260043, "14": 0.26795607805252075, "15": 0.23185625672340393, "16": 0.04325546324253082, "17": 0.0002948761102743447, "18": 0.00028175426996313035, "19": 0.0002697504824027419}}, {"key": "thoppilan2022language", "year": "2022", "title": "Lamda: Language Models For Dialog Applications", "topic_distr": {"0": 0.24401427805423737, "1": 0.05736895278096199, "2": 0.08728399872779846, "3": 0.0006373376818373799, "4": 0.16057871282100677, "5": 0.0005027618026360869, "6": 0.07657892256975174, "7": 0.05297703668475151, "8": 0.0003818293334916234, "9": 0.0617341585457325, "10": 0.00032906181877478957, "11": 0.0003077938163187355, "12": 0.0002891080512199551, "13": 0.08647600561380386, "14": 0.00025780597934499383, "15": 0.0002445662394165993, "16": 0.08763282746076584, "17": 0.00022178638027980924, "18": 0.0819801539182663, "19": 0.0002028885210165754}}, {"key": "thrush2022probing", "year": "2022", "title": "Winoground: Probing Vision And Language Models For Visio-linguistic Compositionality", "topic_distr": {"0": 0.13703946769237518, "1": 0.0013765518087893724, "2": 0.15138989686965942, "3": 0.23041848838329315, "4": 0.0008887877920642495, "5": 0.0007949554128572345, "6": 0.0007190437172539532, "7": 0.0006563662318512797, "8": 0.0006037396378815174, "9": 0.0005589256761595607, "10": 0.0005203048349358141, "11": 0.0688534826040268, "12": 0.15257863700389862, "13": 0.00043096745503135026, "14": 0.00040763680590316653, "15": 0.000386702420655638, "16": 0.0003678132488857955, "17": 0.00035068346187472343, "18": 0.2109116017818451, "19": 0.04074598848819733}}, {"key": "thulke2021efficient", "year": "2021", "title": "Efficient Retrieval Augmented Generation From Unstructured Knowledge For Task-oriented Dialog", "topic_distr": {"0": 0.0014171433867886662, "1": 0.0011572673683986068, "2": 0.000978361931629479, "3": 0.0321914404630661, "4": 0.13012921810150146, "5": 0.0006684503750875592, "6": 0.27698761224746704, "7": 0.00055191561114043, "8": 0.10593993216753006, "9": 0.0004699811979662627, "10": 0.0738474428653717, "11": 0.0004092293092980981, "12": 0.0003843855229206383, "13": 0.12249615788459778, "14": 0.0003427676565479487, "15": 0.0985272154211998, "16": 0.07708338648080826, "17": 0.0002948775654658675, "18": 0.0002817556378431618, "19": 0.07584146410226822}}, {"key": "tian2019sticking", "year": "2019", "title": "Sticking To The Facts: Confident Decoding For Faithful Data-to-text Generation", "topic_distr": {"0": 0.1487455666065216, "1": 0.16198000311851501, "2": 0.0016243456630036235, "3": 0.0014068675227463245, "4": 0.0012408040929585695, "5": 0.0011098072864115238, "6": 0.0010038301115855575, "7": 0.4576122760772705, "8": 0.0008428583387285471, "9": 0.0007802952313795686, "10": 0.0007263781735673547, "11": 0.0006794307264499366, "12": 0.0006381833809427917, "13": 0.0006016575498506427, "14": 0.21854908764362335, "15": 0.0005398608045652509, "16": 0.0005134903476573527, "17": 0.0004895760794170201, "18": 0.0004677901742979884, "19": 0.0004478605405893177}}, {"key": "tian2023graph", "year": "2023", "title": "Graph Neural Prompting With Large Language Models", "topic_distr": {"0": 0.001259529497474432, "1": 0.0010286514880135655, "2": 0.07391165941953659, "3": 0.3167509138584137, "4": 0.0006642760126851499, "5": 0.0005941455019637942, "6": 0.0005374097381718457, "7": 0.0004905648529529572, "8": 0.012780070304870605, "9": 0.0004177382797934115, "10": 0.030883969739079475, "11": 0.00036373952752910554, "12": 0.0003416573745198548, "13": 0.07820111513137817, "14": 0.00030466573662124574, "15": 0.05511939525604248, "16": 0.233310729265213, "17": 0.09932160377502441, "18": 0.09347836673259735, "19": 0.00023976627562660724}}, {"key": "tian2023is", "year": "2023", "title": "Is Chatgpt The Ultimate Programming Assistant -- How Far Is It?", "topic_distr": {"0": 0.07792521268129349, "1": 0.0007381378090940416, "2": 0.03887315094470978, "3": 0.2786804437637329, "4": 0.00047658567200414836, "5": 0.017060600221157074, "6": 0.2152656465768814, "7": 0.00035195660893805325, "8": 0.00032373718568123877, "9": 0.23951393365859985, "10": 0.0002789977879729122, "11": 0.00026096554938703775, "12": 0.07394491881132126, "13": 0.00023109331959858537, "14": 0.00021858295076526701, "15": 0.00020735753059852868, "16": 0.00019722877186723053, "17": 0.05509978532791138, "18": 0.00017967559688258916, "19": 0.00017202073649968952}}, {"key": "tian2023just", "year": "2023", "title": "Just Ask For Calibration: Strategies For Eliciting Calibrated Confidence Scores From Language Models Fine-tuned With Human Feedback", "topic_distr": {"0": 0.1868363618850708, "1": 0.001454880926758051, "2": 0.0012299539521336555, "3": 0.34083208441734314, "4": 0.0009395427769050002, "5": 0.0008403505198657513, "6": 0.0007601039833389223, "7": 0.28916439414024353, "8": 0.02757888101041317, "9": 0.0005908425664529204, "10": 0.0005500163533724844, "11": 0.10338138788938522, "12": 0.0004832349077332765, "13": 0.0004555774212349206, "14": 0.000430914486059919, "15": 0.00040878469008021057, "16": 0.00038881684304215014, "17": 0.0003707088762894273, "18": 0.0003542125050444156, "19": 0.042948950082063675}}, {"key": "tian2023opportunities", "year": "2023", "title": "Opportunities And Challenges For Chatgpt And Large Language Models In Biomedicine And Health", "topic_distr": {"0": 0.07884631305932999, "1": 0.10521450638771057, "2": 0.0006378199905157089, "3": 0.024508923292160034, "4": 0.00048722801147960126, "5": 0.0004357880970928818, "6": 0.000394174043321982, "7": 0.01976127363741398, "8": 0.02389625273644924, "9": 0.35932230949401855, "10": 0.0002852269681170583, "11": 0.0002667921071406454, "12": 0.2617291510105133, "13": 0.0002362529339734465, "14": 0.00022346324112731963, "15": 0.12300106883049011, "16": 0.00020163228327874094, "17": 0.0001922418741742149, "18": 0.0001836871961131692, "19": 0.00017586142348591238}}, {"key": "tinn2021fine", "year": "2021", "title": "Fine-tuning Large Neural Language Models For Biomedical Natural Language Processing", "topic_distr": {"0": 0.001014356384985149, "1": 0.0008282363996841013, "2": 0.0007000283803790808, "3": 0.17054036259651184, "4": 0.0005347402766346931, "5": 0.00047828551032580435, "6": 0.0004326131893321872, "7": 0.00039490326889790595, "8": 0.00036324039683677256, "9": 0.0003362780262250453, "10": 0.11745160818099976, "11": 0.00029280921444296837, "12": 0.26912522315979004, "13": 0.10842986404895782, "14": 0.04307732358574867, "15": 0.1728491336107254, "16": 0.00022129510762169957, "17": 0.00021098896104376763, "18": 0.0002016000507865101, "19": 0.1125170886516571}}, {"key": "tiong2022plug", "year": "2022", "title": "Plug-and-play VQA: Zero-shot VQA By Conjoining Large Pretrained Models With Zero Training", "topic_distr": {"0": 0.0016205268912017345, "1": 0.0013228136813268065, "2": 0.13909123837947845, "3": 0.0009684792603366077, "4": 0.0008541542920283973, "5": 0.0007639771793037653, "6": 0.000691023888066411, "7": 0.0006307888543233275, "8": 0.07062786817550659, "9": 0.0005371453589759767, "10": 0.12589141726493835, "11": 0.00046771150664426386, "12": 0.0004393173730932176, "13": 0.03757553547620773, "14": 0.0003917519352398813, "15": 0.00037163333036005497, "16": 0.0003534802235662937, "17": 0.14061027765274048, "18": 0.42911434173583984, "19": 0.04767647385597229}}, {"key": "tirumala2022memorization", "year": "2022", "title": "Memorization Without Overfitting: Analyzing The Training Dynamics Of Large Language Models", "topic_distr": {"0": 0.395449697971344, "1": 0.16266940534114838, "2": 0.1750883013010025, "3": 0.000877310405485332, "4": 0.0007737540872767568, "5": 0.000692064524628222, "6": 0.0006259781657718122, "7": 0.0005714130238629878, "8": 0.0005255978321656585, "9": 0.00048658414743840694, "10": 0.07718633115291595, "11": 0.0004236860550008714, "12": 0.00039796464261598885, "13": 0.18234385550022125, "14": 0.00035487653804011643, "15": 0.00033665169030427933, "16": 0.0003202073276042938, "17": 0.0003052946412935853, "18": 0.0002917091769631952, "19": 0.0002792812592815608}}, {"key": "todd2023level", "year": "2023", "title": "Level Generation Through Large Language Models", "topic_distr": {"0": 0.0016001093899831176, "1": 0.07258578389883041, "2": 0.001103834598325193, "3": 0.4937053620815277, "4": 0.0008431953028775752, "5": 0.0007541764061897993, "6": 0.0006821589195169508, "7": 0.12065273523330688, "8": 0.033328499644994736, "9": 0.11957323551177979, "10": 0.0004936147597618401, "11": 0.1104450598359108, "12": 0.0004336814454291016, "13": 0.00040886009810492396, "14": 0.0003867262275889516, "15": 0.00036686574458144605, "16": 0.0003489455266389996, "17": 0.0003326944133732468, "18": 0.04165007919073105, "19": 0.000304346380289644}}, {"key": "toma2023clinical", "year": "2023", "title": "Clinical Camel: An Open Expert-level Medical Language Model With Dialogue-based Knowledge Encoding", "topic_distr": {"0": 0.12939634919166565, "1": 0.0009432481601834297, "2": 0.0007972613675519824, "3": 0.12813417613506317, "4": 0.0006090351962484419, "5": 0.0005447356961667538, "6": 0.01239803247153759, "7": 0.00044976890785619617, "8": 0.00041370702092535794, "9": 0.04862649738788605, "10": 0.0003565340884961188, "11": 0.0003334905195515603, "12": 0.3475373089313507, "13": 0.2658787965774536, "14": 0.00027932936791330576, "15": 0.00026498426450416446, "16": 0.06234697997570038, "17": 0.00024030260101426393, "18": 0.00022960924252402037, "19": 0.00021982702310197055}}, {"key": "toneva2019interpreting", "year": "2019", "title": "Interpreting And Improving Natural-language Processing (in Machines) With Natural Language-processing (in The Brain)", "topic_distr": {"0": 0.1809941977262497, "1": 0.0009522438631393015, "2": 0.44356754422187805, "3": 0.0006969476817175746, "4": 0.033958353102207184, "5": 0.0005497855599969625, "6": 0.000497285567689687, "7": 0.0004539382643997669, "8": 0.00041754209087230265, "9": 0.00038654907257296145, "10": 0.30134516954421997, "11": 0.000336581957526505, "12": 0.018174389377236366, "13": 0.00029805407393723726, "14": 0.00028191873570904136, "15": 0.0002674406860023737, "16": 0.00025437705335207283, "17": 0.00024253020819742233, "18": 0.00023173773661255836, "19": 0.016093438491225243}}, {"key": "tong2024eyes", "year": "2024", "title": "Eyes Wide Shut? Exploring The Visual Shortcomings Of Multimodal Llms", "topic_distr": {"0": 0.12425460666418076, "1": 0.0008148244814947248, "2": 0.0006887677009217441, "3": 0.21046121418476105, "4": 0.0005261455662548542, "5": 0.04419178515672684, "6": 0.0004256597312632948, "7": 0.00038855589809827507, "8": 0.00035740199382416904, "9": 0.000330873008351773, "10": 0.00030801023240201175, "11": 0.0002881028631236404, "12": 0.13427262008190155, "13": 0.000255124265095219, "14": 0.0002413129695923999, "15": 0.00022892023844178766, "16": 0.00021773821208626032, "17": 0.00020759770995937288, "18": 0.4813508093357086, "19": 0.00018990883836522698}}, {"key": "tonmoy2024comprehensive", "year": "2024", "title": "A Comprehensive Survey Of Hallucination Mitigation Techniques In Large Language Models", "topic_distr": {"0": 0.20288991928100586, "1": 0.1669101119041443, "2": 0.0005590896471403539, "3": 0.00048423404223285615, "4": 0.00042707365355454385, "5": 0.0003819853882305324, "6": 0.0003455090045463294, "7": 0.05403982102870941, "8": 0.032963767647743225, "9": 0.2164374440908432, "10": 0.0002500126138329506, "11": 0.00023385375970974565, "12": 0.24062122404575348, "13": 0.00020708495867438614, "14": 0.0001958743087016046, "15": 0.00018581509357318282, "16": 0.058214303106069565, "17": 0.024337684735655785, "18": 0.0001610090403119102, "19": 0.00015414944209624082}}, {"key": "tony2023dataset", "year": "2023", "title": "Llmseceval: A Dataset Of Natural Language Prompts For Security Evaluations", "topic_distr": {"0": 0.0013281635474413633, "1": 0.16999661922454834, "2": 0.0009159310138784349, "3": 0.2984410524368286, "4": 0.0006996951415203512, "5": 0.000625824963208288, "6": 0.3668517768383026, "7": 0.0005167213967069983, "8": 0.0004752913082484156, "9": 0.07583049684762955, "10": 0.0004096076590940356, "11": 0.00038313379627652466, "12": 0.0003598742769099772, "13": 0.023182228207588196, "14": 0.00032091024331748486, "15": 0.00030442976276390254, "16": 0.0002895593352150172, "17": 0.058552373200654984, "18": 0.0002637888246681541, "19": 0.00025255040964111686}}, {"key": "topal2021exploring", "year": "2021", "title": "Exploring Transformers In Natural Language Generation: GPT, BERT, And Xlnet", "topic_distr": {"0": 0.0019482619827613235, "1": 0.001591220498085022, "2": 0.2544368803501129, "3": 0.001165119931101799, "4": 0.001027591060847044, "5": 0.0009191037970595062, "6": 0.0008313371799886227, "7": 0.0007588713197037578, "8": 0.0006980259786359966, "9": 0.12933211028575897, "10": 0.30643755197525024, "11": 0.000562680943403393, "12": 0.14113599061965942, "13": 0.0004982718965038657, "14": 0.0004712976806331426, "15": 0.15659667551517487, "16": 0.00042525483877398074, "17": 0.00040544988587498665, "18": 0.0003874075482599437, "19": 0.0003709025331772864}}, {"key": "touvron2023llama", "year": "2023", "title": "Llama 2: Open Foundation And Fine-tuned Chat Models", "topic_distr": {"0": 0.21557435393333435, "1": 0.0018518525175750256, "2": 0.0015653388109058142, "3": 0.14994235336780548, "4": 0.0011957534588873386, "5": 0.021628981456160545, "6": 0.0009673828608356416, "7": 0.0008830581209622324, "8": 0.0008122556610032916, "9": 0.07450898736715317, "10": 0.0007000046316534281, "11": 0.0006547617958858609, "12": 0.33949264883995056, "13": 0.15653184056282043, "14": 0.0005484239663928747, "15": 0.0005202594329603016, "16": 0.0004948464338667691, "17": 0.0004718004202004522, "18": 0.0004508055280894041, "19": 0.031204260885715485}}, {"key": "touvron2023open", "year": "2023", "title": "Llama: Open And Efficient Foundation Language Models", "topic_distr": {"0": 0.0037773377262055874, "1": 0.003085690550506115, "2": 0.002608702750876546, "3": 0.0022594246547669172, "4": 0.001992717618122697, "5": 0.0017823402304202318, "6": 0.0016121419612318277, "7": 0.0014716149307787418, "8": 0.0013536227634176612, "9": 0.0012531470274552703, "10": 0.04314534366130829, "11": 0.00109115953091532, "12": 0.6048614978790283, "13": 0.32484281063079834, "14": 0.0009139477042481303, "15": 0.0008670114912092686, "16": 0.000824660761281848, "17": 0.0007862546481192112, "18": 0.0007512667216360569, "19": 0.0007192599005065858}}, {"key": "tran2023instruction", "year": "2023", "title": "Bioinstruct: Instruction Tuning Of Large Language Models For Biomedical Natural Language Processing", "topic_distr": {"0": 0.0011146116303279996, "1": 0.0009095094865188003, "2": 0.0007687368197366595, "3": 0.4104962646961212, "4": 0.0005872310721315444, "5": 0.0005252348491922021, "6": 0.00047507937415502965, "7": 0.00043366773752495646, "8": 0.05928269401192665, "9": 0.00036928776535205543, "10": 0.0003437706036493182, "11": 0.0003215519536752254, "12": 0.34815511107444763, "13": 0.05645713582634926, "14": 0.00026932969922199845, "15": 0.11858273297548294, "16": 0.00024301788653247058, "17": 0.00023170006170403212, "18": 0.00022138952044770122, "19": 0.00021195747831370682}}, {"key": "trautmann2022legal", "year": "2022", "title": "Legal Prompt Engineering For Multilingual Legal Judgement Prediction", "topic_distr": {"0": 0.001666563912294805, "1": 0.0013580138329416513, "2": 0.2757298946380615, "3": 0.13225135207176208, "4": 0.000876863079611212, "5": 0.0007842895574867725, "6": 0.0007093963213264942, "7": 0.0006475597620010376, "8": 0.03183193504810333, "9": 0.308876633644104, "10": 0.0005133239319548011, "11": 0.00048014664207585156, "12": 0.0004509975842665881, "13": 0.038013260811567307, "14": 0.08912479132413864, "15": 0.0003815140516962856, "16": 0.0003628782869782299, "17": 0.115293487906456, "18": 0.00033058246481232345, "19": 0.0003164983936585486}}, {"key": "trischler2016natural", "year": "2016", "title": "Natural Language Comprehension With The Epireader", "topic_distr": {"0": 0.0017824749229475856, "1": 0.0014549080515280366, "2": 0.5142468810081482, "3": 0.0010652504861354828, "4": 0.0009395090164616704, "5": 0.0008403198444284499, "6": 0.024493034929037094, "7": 0.0006938220467418432, "8": 0.11964089423418045, "9": 0.0005908209714107215, "10": 0.0005499962717294693, "11": 0.0005144487950019538, "12": 0.09655587375164032, "13": 0.0004555608029477298, "14": 0.07050689309835434, "15": 0.16421650350093842, "16": 0.00038880264037288725, "17": 0.0003706953430082649, "18": 0.0003541995829436928, "19": 0.00033910933416336775}}, {"key": "trivedi2019repurposing", "year": "2019", "title": "Repurposing Entailment For Multi-hop Question Answering Tasks", "topic_distr": {"0": 0.07374079525470734, "1": 0.0011705993674695492, "2": 0.447305291891098, "3": 0.0008571168291382492, "4": 0.0007559373043477535, "5": 0.0006761302356608212, "6": 0.0006115654832683504, "7": 0.0005582566373050213, "8": 0.2406730204820633, "9": 0.00047538086073473096, "10": 0.0004425328515935689, "11": 0.0004139309749007225, "12": 0.00038880176725797355, "13": 0.00036654906580224633, "14": 0.00034670575405471027, "15": 0.0003289004962425679, "16": 0.07600018382072449, "17": 0.00029826542595401406, "18": 0.15431718528270721, "19": 0.0002728510007727891}}, {"key": "trivedi2022interleaving", "year": "2022", "title": "Interleaving Retrieval With Chain-of-thought Reasoning For Knowledge-intensive Multi-step Questions", "topic_distr": {"0": 0.029912203550338745, "1": 0.028017176315188408, "2": 0.1966063529253006, "3": 0.3762948513031006, "4": 0.0006710847374051809, "5": 0.0006002355949021876, "6": 0.0005429182201623917, "7": 0.000495593179948628, "8": 0.2537503242492676, "9": 0.0004220201226416975, "10": 0.0003928592486772686, "11": 0.0003674678737297654, "12": 0.00034515938023105264, "13": 0.0003254045150242746, "14": 0.00030778857762925327, "15": 0.0002919819380622357, "16": 0.05231105908751488, "17": 0.057850323617458344, "18": 0.00025300277047790587, "19": 0.0002422238903818652}}, {"key": "trott2022do", "year": "2022", "title": "Do Large Language Models Know What Humans Know?", "topic_distr": {"0": 0.5629988312721252, "1": 0.1993415802717209, "2": 0.03395949304103851, "3": 0.0009811876807361841, "4": 0.0008653673576191068, "5": 0.07362034916877747, "6": 0.0007000957848504186, "7": 0.0006390700000338256, "8": 0.015281064435839653, "9": 0.09037037938833237, "10": 0.0005065940204076469, "11": 0.00047385174548253417, "12": 0.0004450848209671676, "13": 0.00041961082024499774, "14": 0.00039689496043138206, "15": 0.0003765122382901609, "16": 0.017643971368670464, "17": 0.00034144241362810135, "18": 0.0003262483805883676, "19": 0.0003123489732388407}}, {"key": "tschannen2022image", "year": "2022", "title": "CLIPPO: Image-and-language Understanding From Pixels Only", "topic_distr": {"0": 0.07747720181941986, "1": 0.0009610109846107662, "2": 0.28058576583862305, "3": 0.0007034800364635885, "4": 0.0006204394157975912, "5": 0.0005549369379878044, "6": 0.000501945149153471, "7": 0.0004581916728056967, "8": 0.0430913120508194, "9": 0.0003901710151694715, "10": 0.17259320616722107, "11": 0.00033973573590628803, "12": 0.0003191108407918364, "13": 0.0003008468193002045, "14": 0.0625530481338501, "15": 0.0002699465840123594, "16": 0.00025676056975498796, "17": 0.00024480270803906024, "18": 0.357554167509079, "19": 0.0002239436871604994}}, {"key": "tsimpoukelli2021multimodal", "year": "2021", "title": "Multimodal Few-shot Learning With Frozen Language Models", "topic_distr": {"0": 0.06791964173316956, "1": 0.0012272829189896584, "2": 0.0010373390978202224, "3": 0.04381783306598663, "4": 0.0007924050441943109, "5": 0.0007087440462782979, "6": 0.0006410644855350256, "7": 0.0005851842579431832, "8": 0.0005382649251259863, "9": 0.0004983109538443387, "10": 0.0720139741897583, "11": 0.0004338970175012946, "12": 0.00040755572263151407, "13": 0.0003842296719085425, "14": 0.00036342916428111494, "15": 0.00034476511063985527, "16": 0.012006234377622604, "17": 0.24159225821495056, "18": 0.48932647705078125, "19": 0.06536109745502472}}, {"key": "tu2020empirical", "year": "2020", "title": "An Empirical Study On Robustness To Spurious Correlations Using Pre-trained Language Models", "topic_distr": {"0": 0.001920755603350699, "1": 0.33513155579566956, "2": 0.5604895353317261, "3": 0.0011471748584881425, "4": 0.0010117592755705118, "5": 0.0009049425716511905, "6": 0.0008185282931663096, "7": 0.0007471789722330868, "8": 0.000687271123751998, "9": 0.0006362568237818778, "10": 0.09247126430273056, "11": 0.0005540113779716194, "12": 0.0005203780601732433, "13": 0.0004905947134830058, "14": 0.00046403612941503525, "15": 0.00044020533096045256, "16": 0.0004187026934232563, "17": 0.00039920289418660104, "18": 0.00038143855636008084, "19": 0.000365187821444124}}, {"key": "tu2022visual", "year": "2022", "title": "Visual Query Tuning: Towards Effective Usage Of Intermediate Representations For Parameter And Memory Efficient Transfer Learning", "topic_distr": {"0": 0.023980360478162766, "1": 0.0008213997934944928, "2": 0.10587605088949203, "3": 0.0006013953243382275, "4": 0.0005304058431647718, "5": 0.00047440899652428925, "6": 0.00042910693446174264, "7": 0.0003917026042472571, "8": 0.021395031362771988, "9": 0.00033355256891809404, "10": 0.1449384242296219, "11": 0.09684786945581436, "12": 0.0002728040562942624, "13": 0.2230081856250763, "14": 0.00024326723359990865, "15": 0.00023077413788996637, "16": 0.07442951947450638, "17": 0.1863732784986496, "18": 0.11863098293542862, "19": 0.00019144680118188262}}, {"key": "tu2024towards", "year": "2024", "title": "Towards Conversational Diagnostic AI", "topic_distr": {"0": 0.17315033078193665, "1": 0.0009429959463886917, "2": 0.0007971760351210833, "3": 0.07451242208480835, "4": 0.18918702006340027, "5": 0.03908040001988411, "6": 0.0004926518304273486, "7": 0.0004497084009926766, "8": 0.00041365137440152466, "9": 0.32112032175064087, "10": 0.0003564861253835261, "11": 0.02174166589975357, "12": 0.04507174715399742, "13": 0.1311974972486496, "14": 0.0002792917948681861, "15": 0.00026494861231185496, "16": 0.0002520067209843546, "17": 0.00024027028121054173, "18": 0.00022957836335990578, "19": 0.0002197974536102265}}, {"key": "tuan2019benchmarking", "year": "2019", "title": "Dykgchat: Benchmarking Dialogue Generation Grounding On Dynamic Knowledge Graphs", "topic_distr": {"0": 0.0015405527083203197, "1": 0.001257240423001349, "2": 0.0010629120515659451, "3": 0.0009205985115841031, "4": 0.000811929174233228, "5": 0.06563872843980789, "6": 0.24299637973308563, "7": 0.08590575307607651, "8": 0.0005515305674634874, "9": 0.0005105919553898275, "10": 0.00047531092423014343, "11": 0.0839681401848793, "12": 0.17421621084213257, "13": 0.00039369906880892813, "14": 0.0003723859554156661, "15": 0.00035326191573403776, "16": 0.33810529112815857, "17": 0.00032035770709626377, "18": 0.00030610195244662464, "19": 0.0002930608461610973}}, {"key": "tuan2019capturing", "year": "2019", "title": "Capturing Greater Context For Question Generation", "topic_distr": {"0": 0.0015595065196976066, "1": 0.0012729442678391933, "2": 0.3598122000694275, "3": 0.0009321009856648743, "4": 0.0008220794261433184, "5": 0.03216680511832237, "6": 0.0006650745053775609, "7": 0.20062348246574402, "8": 0.2904229164123535, "9": 0.0005169743672013283, "10": 0.00048125232569873333, "11": 0.0004501479270402342, "12": 0.04774950444698334, "13": 0.00039862035191617906, "14": 0.0003770408220589161, "15": 0.0604780875146389, "16": 0.0003402062866371125, "17": 0.0003243622195441276, "18": 0.0003099282330367714, "19": 0.0002967241161968559}}, {"key": "tunstall2022efficient", "year": "2022", "title": "Efficient Few-shot Learning Without Prompts", "topic_distr": {"0": 0.0013703705044463277, "1": 0.0011190620716661215, "2": 0.32801976799964905, "3": 0.0008193927933461964, "4": 0.0007226713350974023, "5": 0.0006463759928010404, "6": 0.0005846525891683996, "7": 0.06152937561273575, "8": 0.0004908991395495832, "9": 0.0004544609982986003, "10": 0.08905785530805588, "11": 0.00039571529487147927, "12": 0.00037169194547459483, "13": 0.2082160860300064, "14": 0.052109211683273315, "15": 0.0003144267247989774, "16": 0.00029906799318268895, "17": 0.25294560194015503, "18": 0.00027245120145380497, "19": 0.0002608437498565763}}, {"key": "tunstall2023direct", "year": "2023", "title": "Zephyr: Direct Distillation Of LM Alignment", "topic_distr": {"0": 0.06306552141904831, "1": 0.21201670169830322, "2": 0.15884682536125183, "3": 0.0009321048855781555, "4": 0.14377710223197937, "5": 0.0007352861575782299, "6": 0.0006650725263170898, "7": 0.0006070995586924255, "8": 0.0005584231112152338, "9": 0.0206428412348032, "10": 0.00048125089961104095, "11": 0.0004501465882640332, "12": 0.0004228187899570912, "13": 0.2426159530878067, "14": 0.0003770396870095283, "15": 0.00035767664667218924, "16": 0.00034020529710687697, "17": 0.13172867894172668, "18": 0.00030992733081802726, "19": 0.021069331094622612}}, {"key": "turc2019well", "year": "2019", "title": "Well-read Students Learn Better: On The Importance Of Pre-training Compact Models", "topic_distr": {"0": 0.0014017800567671657, "1": 0.0011446023127064109, "2": 0.4284825325012207, "3": 0.03051089122891426, "4": 0.0007389848469756544, "5": 0.0006609663832932711, "6": 0.0005978497210890055, "7": 0.000545736460480839, "8": 0.0005019800155423582, "9": 0.00046471937093883753, "10": 0.08516167849302292, "11": 0.0004046476387884468, "12": 0.08863652497529984, "13": 0.3589438796043396, "14": 0.0003389300836715847, "15": 0.0003215241595171392, "16": 0.00030581874307245016, "17": 0.0002915761433541775, "18": 0.0002786011609714478, "19": 0.0002667316875886172}}, {"key": "turc2021revisiting", "year": "2021", "title": "Revisiting The Primacy Of English In Zero-shot Cross-lingual Transfer", "topic_distr": {"0": 0.0018915432738140225, "1": 0.10883375257253647, "2": 0.0013045461382716894, "3": 0.28494569659233093, "4": 0.0009965186472982168, "5": 0.0008913118508644402, "6": 0.0008061989792622626, "7": 0.0007359244045801461, "8": 0.03346404805779457, "9": 0.058850448578596115, "10": 0.021062636747956276, "11": 0.0005456664366647601, "12": 0.0005125397583469748, "13": 0.0004832050180993974, "14": 0.4404432773590088, "15": 0.0004335746343713254, "16": 0.0004123958933632821, "17": 0.042651355266571045, "18": 0.00037569302367046475, "19": 0.0003596870810724795}}, {"key": "uchendu2021benchmark", "year": "2021", "title": "TURINGBENCH: A Benchmark Environment For Turing Test In The Age Of Neural Text Generation", "topic_distr": {"0": 0.1612582951784134, "1": 0.042262617498636246, "2": 0.0012298636138439178, "3": 0.0010652124183252454, "4": 0.0009394732187502086, "5": 0.0008402900421060622, "6": 0.0007600492681376636, "7": 0.0006937973666936159, "8": 0.0006381695857271552, "9": 0.0005908000166527927, "10": 0.0005499767139554024, "11": 0.10640335828065872, "12": 0.14137938618659973, "13": 0.0004555445921141654, "14": 0.13911163806915283, "15": 0.4003688097000122, "16": 0.00038878884515725076, "17": 0.000370682158973068, "18": 0.00035418698098510504, "19": 0.00033909728517755866}}, {"key": "ullman2023large", "year": "2023", "title": "Large Language Models Fail On Trivial Alterations To Theory-of-mind Tasks", "topic_distr": {"0": 0.1927952617406845, "1": 0.0018188597168773413, "2": 0.18469837307929993, "3": 0.4225319027900696, "4": 0.0011744521325454116, "5": 0.001050461083650589, "6": 0.0009501510066911578, "7": 0.0008673283737152815, "8": 0.0007977870991453528, "9": 0.18794551491737366, "10": 0.0006875356193631887, "11": 0.0006430986686609685, "12": 0.0006040569860488176, "13": 0.0005694843712262809, "14": 0.0005386550328694284, "15": 0.0005109921330586076, "16": 0.0004860317858401686, "17": 0.00046339633991010487, "18": 0.00044277540291659534, "19": 0.0004239114932715893}}, {"key": "ushio2022generative", "year": "2022", "title": "Generative Language Models For Paragraph-level Question Generation", "topic_distr": {"0": 0.001451736083254218, "1": 0.06301309168338776, "2": 0.0010011555859819055, "3": 0.24366016685962677, "4": 0.0007647605380043387, "5": 0.0006840209825895727, "6": 0.0006187027902342379, "7": 0.0005647717625834048, "8": 0.09040989726781845, "9": 0.00048092883662320673, "10": 0.0004476974718272686, "11": 0.00041876177419908345, "12": 0.292860209941864, "13": 0.0003708269214257598, "14": 0.0716794952750206, "15": 0.23039114475250244, "16": 0.0003164857334922999, "17": 0.00030174636049196124, "18": 0.0002883187844417989, "19": 0.00027603530907072127}}, {"key": "ushio2022t", "year": "2022", "title": "T-NER: An All-round Python Library For Transformer-based Named Entity Recognition", "topic_distr": {"0": 0.0013265497982501984, "1": 0.0010836945148184896, "2": 0.000915958487894386, "3": 0.19536276161670685, "4": 0.0431915707886219, "5": 0.0006258194916881621, "6": 0.0005660590250045061, "7": 0.0005167168565094471, "8": 0.0004752871464006603, "9": 0.0004400078614708036, "10": 0.11916959285736084, "11": 0.00038313044933602214, "12": 0.17734335362911224, "13": 0.0003392742364667356, "14": 0.000320907449349761, "15": 0.0003044270852115005, "16": 0.089699886739254, "17": 0.1811635047197342, "18": 0.0002637864963617176, "19": 0.18650774657726288}}, {"key": "valipour2022parameter", "year": "2022", "title": "Dylora: Parameter Efficient Tuning Of Pre-trained Models Using Dynamic Search-free Low-rank Adaptation", "topic_distr": {"0": 0.0012241238728165627, "1": 0.023757142946124077, "2": 0.3743880093097687, "3": 0.0007311426452361047, "4": 0.0006448351196013391, "5": 0.0005767573602497578, "6": 0.03530248627066612, "7": 0.00047620804980397224, "8": 0.00043802629807032645, "9": 0.00040551277925260365, "10": 0.20707830786705017, "11": 0.00035309436498209834, "12": 0.00033165846252813935, "13": 0.2361263930797577, "14": 0.00029574939981102943, "15": 0.0002805610711220652, "16": 0.0002668565430212766, "17": 0.08585767447948456, "18": 0.00024310656590387225, "19": 0.031222354620695114}}, {"key": "valmeekam2022extensible", "year": "2022", "title": "Planbench: An Extensible Benchmark For Evaluating Large Language Models On Planning And Reasoning About Change", "topic_distr": {"0": 0.0011774180456995964, "1": 0.0009609140106476843, "2": 0.0008122576400637627, "3": 0.6837269067764282, "4": 0.0006204883102327585, "5": 0.0005549808847717941, "6": 0.000501984846778214, "7": 0.0004582278779707849, "8": 0.00042148775537498295, "9": 0.043827589601278305, "10": 0.00036323958192951977, "11": 0.12859691679477692, "12": 0.10966581106185913, "13": 0.00030087059712968767, "14": 0.0002845828130375594, "15": 0.0002699679462239146, "16": 0.026753675192594528, "17": 0.00024482206208631396, "18": 0.00023392759612761438, "19": 0.00022396139684133232}}, {"key": "vanaken2019how", "year": "2019", "title": "How Does BERT Answer Questions? A Layer-wise Analysis Of Transformer Representations", "topic_distr": {"0": 0.001067207776941359, "1": 0.0008705013897269964, "2": 0.32991692423820496, "3": 0.0006373852957040071, "4": 0.0005621446180157363, "5": 0.0005027967854402959, "6": 0.0004547838179860264, "7": 0.0004151413158979267, "8": 0.10012366622686386, "9": 0.00035351168480701745, "10": 0.3635796904563904, "11": 0.00030781514942646027, "12": 0.07262887805700302, "13": 0.0002725801314227283, "14": 0.00025782384909689426, "15": 0.00024458320694975555, "16": 0.10701300948858261, "17": 0.00022180176165420562, "18": 0.00021193169231992215, "19": 0.020357808098196983}}, {"key": "vanaken2020hidden", "year": "2020", "title": "Visbert: Hidden-state Visualizations For Transformers", "topic_distr": {"0": 0.07066166400909424, "1": 0.0010608143638819456, "2": 0.2125312238931656, "3": 0.06655246019363403, "4": 0.0006851145881228149, "5": 0.07719619572162628, "6": 0.0005542688304558396, "7": 0.0005059544346295297, "8": 0.025041908025741577, "9": 0.15042360126972198, "10": 0.39205533266067505, "11": 0.0003751504118554294, "12": 0.0003523755294736475, "13": 0.0003322076518088579, "14": 0.00031422340543940663, "15": 0.0002980863209813833, "16": 0.0002835257619153708, "17": 0.00027032141224481165, "18": 0.0002582922170404345, "19": 0.00024728800053708255}}, {"key": "vanbiljon2020optimal", "year": "2020", "title": "On Optimal Transformer Depth For Low-resource Language Translation", "topic_distr": {"0": 0.0011343839578330517, "1": 0.0009259930229745805, "2": 0.3910931944847107, "3": 0.0006779112154617906, "4": 0.0005978890112601221, "5": 0.0005347676924429834, "6": 0.00048370190779678524, "7": 0.00044153863564133644, "8": 0.0004061366489622742, "9": 0.09901754558086395, "10": 0.02233397215604782, "11": 0.0003273879992775619, "12": 0.11590062081813812, "13": 0.08068864047527313, "14": 0.24032548069953918, "15": 0.0002601353626232594, "16": 0.0002474285720381886, "17": 0.044162098318338394, "18": 0.00022540765348821878, "19": 0.0002158044371753931}}, {"key": "vannguyen2021light", "year": "2021", "title": "Trankit: A Light-weight Transformer-based Toolkit For Multilingual Natural Language Processing", "topic_distr": {"0": 0.0016197931254282594, "1": 0.001322616240940988, "2": 0.0011181870941072702, "3": 0.0009684995748102665, "4": 0.0008541736169718206, "5": 0.0007639958057552576, "6": 0.0006910406518727541, "7": 0.0006308041047304869, "8": 0.0005802270025014877, "9": 0.0005371583392843604, "10": 0.5501663684844971, "11": 0.01838994026184082, "12": 0.0004393279959913343, "13": 0.09105097502470016, "14": 0.15993283689022064, "15": 0.0003716423234436661, "16": 0.000353488780092448, "17": 0.0003370261110831052, "18": 0.07733713835477829, "19": 0.09253475815057755}}, {"key": "vansonsbeek2023open", "year": "2023", "title": "Open-ended Medical Visual Question Answering Through Prefix Tuning Of Language Models", "topic_distr": {"0": 0.0014846085105091333, "1": 0.026591166853904724, "2": 0.2197335809469223, "3": 0.0008877711370587349, "4": 0.0007829751702956855, "5": 0.0007003134815022349, "6": 0.0006334393983706832, "7": 0.0005782238440588117, "8": 0.09772326797246933, "9": 0.0004923839005641639, "10": 0.00045836096978746355, "11": 0.00042873609345406294, "12": 0.14036975800991058, "13": 0.0897570252418518, "14": 0.00035910640144720674, "15": 0.029249902814626694, "16": 0.06504730880260468, "17": 0.11455201357603073, "18": 0.20988745987415314, "19": 0.0002826100680977106}}, {"key": "vanveen2023adapted", "year": "2023", "title": "Adapted Large Language Models Can Outperform Medical Experts In Clinical Text Summarization", "topic_distr": {"0": 0.10071214288473129, "1": 0.0008633675170131028, "2": 0.0007297187694348395, "3": 0.21206948161125183, "4": 0.000557410647161305, "5": 0.010019476525485516, "6": 0.00045095401583239436, "7": 0.09148816764354706, "8": 0.02383248880505562, "9": 0.141514852643013, "10": 0.00032631331123411655, "11": 0.00030522295855917037, "12": 0.2608877122402191, "13": 0.11863365024328232, "14": 0.000255652645137161, "15": 0.00024252348521258682, "16": 0.03647956997156143, "17": 0.0002199339069193229, "18": 0.00021014694357290864, "19": 0.00020119389228057116}}, {"key": "varia2022instruction", "year": "2022", "title": "Instruction Tuning For Few-shot Aspect-based Sentiment Analysis", "topic_distr": {"0": 0.0015787448501214385, "1": 0.18870921432971954, "2": 0.44196441769599915, "3": 0.10011391341686249, "4": 0.0008324664668180048, "5": 0.0007445793016813695, "6": 0.0006734783528372645, "7": 0.0006147726671770215, "8": 0.0005654810229316354, "9": 0.0005235068965703249, "10": 0.00048733342555351555, "11": 0.00045583597966469824, "12": 0.0004281628062017262, "13": 0.00040365729364566505, "14": 0.00038180509000085294, "15": 0.12279220670461655, "16": 0.00034450512612238526, "17": 0.1377715915441513, "18": 0.0003138445026706904, "19": 0.00030047353357076645}}, {"key": "vari\u01612021sequence", "year": "2021", "title": "Sequence Length Is A Domain: Length-based Overfitting In Transformer Models", "topic_distr": {"0": 0.001286882907152176, "1": 0.13328184187412262, "2": 0.5108848810195923, "3": 0.0007687371107749641, "4": 0.0006779933464713395, "5": 0.0006064149783924222, "6": 0.0005485073197633028, "7": 0.028790662065148354, "8": 0.00046055001439526677, "9": 0.0004263646260369569, "10": 0.1726190149784088, "11": 0.00037125078961253166, "12": 0.0003487126377876848, "13": 0.04958679899573326, "14": 0.0979980006814003, "15": 0.0002949877525679767, "16": 0.0002805785625241697, "17": 0.00026751146651804447, "18": 0.0002556073304731399, "19": 0.0002447174920234829}}, {"key": "varshney2023stitch", "year": "2023", "title": "A Stitch In Time Saves Nine: Detecting And Mitigating Hallucinations Of Llms By Validating Low-confidence Generation", "topic_distr": {"0": 0.2619810700416565, "1": 0.15455123782157898, "2": 0.0006999559700489044, "3": 0.34353479743003845, "4": 0.0005346868420019746, "5": 0.00047823754721321166, "6": 0.000432569911936298, "7": 0.14113278687000275, "8": 0.010386382229626179, "9": 0.0003362444113008678, "10": 0.0003130104742012918, "11": 0.0002927799359895289, "12": 0.0002750056446529925, "13": 0.0002592659729998559, "14": 0.00024523044703528285, "15": 0.08371994644403458, "16": 0.00022127297415863723, "17": 0.0002109678607666865, "18": 0.0002015798818320036, "19": 0.00019299182167742401}}, {"key": "vashishth2019attention", "year": "2019", "title": "Attention Interpretability Across NLP Tasks", "topic_distr": {"0": 0.002399083925411105, "1": 0.0019587331917136908, "2": 0.3605862855911255, "3": 0.10249612480401993, "4": 0.0012648510746657848, "5": 0.23856273293495178, "6": 0.0010232849745079875, "7": 0.0009340873803012073, "8": 0.000859193445648998, "9": 0.000795417872723192, "10": 0.0007404558127745986, "11": 0.0006925985217094421, "12": 0.18865637481212616, "13": 0.000613318057730794, "14": 0.0005801157676614821, "15": 0.0005503236316144466, "16": 0.0005234421114437282, "17": 0.09583015739917755, "18": 0.00047685622121207416, "19": 0.0004565403505694121}}, {"key": "vaswani2017attention", "year": "2017", "title": "Attention Is All You Need", "topic_distr": {"0": 0.001618680777028203, "1": 0.0013226334704086185, "2": 0.5270457863807678, "3": 0.0009684095857664943, "4": 0.0008540950948372483, "5": 0.0007639251998625696, "6": 0.000690976798068732, "7": 0.0006307458970695734, "8": 0.0005801735096611083, "9": 0.000537108804564923, "10": 0.06299438327550888, "11": 0.0004676796670537442, "12": 0.0004392874543555081, "13": 0.08857322484254837, "14": 0.3108205199241638, "15": 0.00037160803913138807, "16": 0.00035345618380233645, "17": 0.0003369950281921774, "18": 0.00032199890119954944, "19": 0.00030828051967546344}}, {"key": "vaswani2018neural", "year": "2018", "title": "Tensor2tensor For Neural Machine Translation", "topic_distr": {"0": 0.007789713330566883, "1": 0.006363709457218647, "2": 0.005380289163440466, "3": 0.004660150036215782, "4": 0.14754609763622284, "5": 0.003676166059449315, "6": 0.003325123805552721, "7": 0.0030352799221873283, "8": 0.002791915088891983, "9": 0.0025846788194030523, "10": 0.23358091711997986, "11": 0.0022505715023726225, "12": 0.002113942289724946, "13": 0.0019929527770727873, "14": 0.5647646188735962, "15": 0.001788254827260971, "16": 0.001700904336757958, "17": 0.0016216898802667856, "18": 0.0015495254192501307, "19": 0.0014835097827017307}}, {"key": "venkatesh2018evaluating", "year": "2018", "title": "On Evaluating And Comparing Open Domain Dialog Systems", "topic_distr": {"0": 0.07006606459617615, "1": 0.08911611884832382, "2": 0.000735906942281872, "3": 0.0006373769720084965, "4": 0.2284582555294037, "5": 0.000502793409395963, "6": 0.17053164541721344, "7": 0.0004151384928263724, "8": 0.0003818532277364284, "9": 0.017225662246346474, "10": 0.0003290823951829225, "11": 0.16831348836421967, "12": 0.2516423761844635, "13": 0.0002725782978814095, "14": 0.00025782210286706686, "15": 0.0002445815480314195, "16": 0.0002326345129404217, "17": 0.0002218002628069371, "18": 0.00021193025168031454, "19": 0.00020290121028665453}}, {"key": "verga2020facts", "year": "2020", "title": "Facts As Experts: Adaptable And Interpretable Neural Memory Over Symbolic Knowledge", "topic_distr": {"0": 0.14982087910175323, "1": 0.0013059742050245404, "2": 0.001103933434933424, "3": 0.16688241064548492, "4": 0.0008432636968791485, "5": 0.04677044600248337, "6": 0.0006822136929258704, "7": 0.0006227465928532183, "8": 0.0005728155956603587, "9": 0.0005302970530465245, "10": 0.0004936543991789222, "11": 0.0004617484228219837, "12": 0.037040069699287415, "13": 0.11398039758205414, "14": 0.11155473440885544, "15": 0.00036689519765786827, "16": 0.36601248383522034, "17": 0.00033272115979343653, "18": 0.0003179152263328433, "19": 0.00030437082750722766}}, {"key": "vig2019multiscale", "year": "2019", "title": "A Multiscale Visualization Of Attention In The Transformer Model", "topic_distr": {"0": 0.16465185582637787, "1": 0.0016426561633124948, "2": 0.4712526500225067, "3": 0.0012027346529066563, "4": 0.0010607613949105144, "5": 0.0009487734059803188, "6": 0.0008581732981838286, "7": 0.0007833681302145123, "8": 0.000720558688044548, "9": 0.13832733035087585, "10": 0.2143220156431198, "11": 0.0005808445857837796, "12": 0.0005455822683870792, "13": 0.0005143564194440842, "14": 0.000486511446069926, "15": 0.00046152641880325973, "16": 0.0004389823297969997, "17": 0.00041853805305436254, "18": 0.0003999133186880499, "19": 0.00038287549978122115}}, {"key": "vig2019visualizing", "year": "2019", "title": "Visualizing Attention In Transformer-based Language Representation Models", "topic_distr": {"0": 0.4528948962688446, "1": 0.002314287703484297, "2": 0.14057199656963348, "3": 0.0016946630785241723, "4": 0.0014946239534765482, "5": 0.0013368315994739532, "6": 0.0012091754470020533, "7": 0.0011037742951884866, "8": 0.0010152750182896852, "9": 0.17869101464748383, "10": 0.21171458065509796, "11": 0.000818416359834373, "12": 0.0007687314064241946, "13": 0.0007247338071465492, "14": 0.000685499922838062, "15": 0.0006502957548946142, "16": 0.0006185309030115604, "17": 0.0005897246883250773, "18": 0.0005634822300635278, "19": 0.0005394757608883083}}, {"key": "vijayakumar2016diverse", "year": "2016", "title": "Diverse Beam Search: Decoding Diverse Solutions From Neural Sequence Models", "topic_distr": {"0": 0.0011459289817139506, "1": 0.0009345515863969922, "2": 0.24749962985515594, "3": 0.09902766346931458, "4": 0.000603402906563133, "5": 0.0005396981723606586, "6": 0.0004881616332568228, "7": 0.21892395615577698, "8": 0.07913780212402344, "9": 0.033737581223249435, "10": 0.06553027778863907, "11": 0.0003304065321572125, "12": 0.0003103479975834489, "13": 0.10760509967803955, "14": 0.05148185044527054, "15": 0.00026253380929119885, "16": 0.00024970987578853965, "17": 0.00023808037803974003, "18": 0.09173554927110672, "19": 0.00021779414964839816}}, {"key": "vilar2022prompting", "year": "2022", "title": "Prompting Palm For Translation: Assessing Strategies And Performance", "topic_distr": {"0": 0.17429940402507782, "1": 0.09968245774507523, "2": 0.0011793987359851599, "3": 0.42487427592277527, "4": 0.0009009222849272192, "5": 0.0008058081730268896, "6": 0.0007288602646440268, "7": 0.0006653271266259253, "8": 0.000611982075497508, "9": 0.0005665562930516899, "10": 0.0005274082068353891, "11": 0.0004933206364512444, "12": 0.00046337180538102984, "13": 0.08356884866952896, "14": 0.20884689688682556, "15": 0.00039198179729282856, "16": 0.00037283473648130894, "17": 0.00035547110019251704, "18": 0.00033965278998948634, "19": 0.0003251823072787374}}, {"key": "vilares2019head", "year": "2019", "title": "HEAD-QA: A Healthcare Dataset For Complex Reasoning", "topic_distr": {"0": 0.0024983829353004694, "1": 0.1492207795381546, "2": 0.0017219951841980219, "3": 0.30177369713783264, "4": 0.0013153926702216268, "5": 0.0011765210656449199, "6": 0.0010641731787472963, "7": 0.0009714114712551236, "8": 0.19342125952243805, "9": 0.0008272010018117726, "10": 0.000770042825024575, "11": 0.0007202732376754284, "12": 0.24234256148338318, "13": 0.0006378249381668866, "14": 0.09893210232257843, "15": 0.0005723133799619973, "16": 0.0005443576956167817, "17": 0.0005190058727748692, "18": 0.0004959103534929454, "19": 0.0004747826897073537}}, {"key": "villegas2022variable", "year": "2022", "title": "Phenaki: Variable Length Video Generation From Open Domain Textual Description", "topic_distr": {"0": 0.0009527844376862049, "1": 0.03544830530881882, "2": 0.0811600461602211, "3": 0.0005692272097803652, "4": 0.0005020358948968351, "5": 0.00044903415255248547, "6": 0.08259733766317368, "7": 0.16164179146289825, "8": 0.00034102509380318224, "9": 0.0003157117171213031, "10": 0.12159516662359238, "11": 0.00027490139473229647, "12": 0.0002582125016488135, "13": 0.11068973690271378, "14": 0.0002302555221831426, "15": 0.0002184306358685717, "16": 0.00020776099700015038, "17": 0.09335293620824814, "18": 0.30901408195495605, "19": 0.00018120682216249406}}, {"key": "vlasov2018few", "year": "2018", "title": "Few-shot Generalization Across Dialogue Tasks", "topic_distr": {"0": 0.0019203831907361746, "1": 0.001566598191857338, "2": 0.5887422561645508, "3": 0.06260965019464493, "4": 0.0010117803467437625, "5": 0.17927239835262299, "6": 0.0008185450569726527, "7": 0.0007471942226402462, "8": 0.0006872851517982781, "9": 0.0006362698040902615, "10": 0.0005923046264797449, "11": 0.15791557729244232, "12": 0.0005203887121751904, "13": 0.0004906047834083438, "14": 0.0004640455881599337, "15": 0.0004402143240440637, "16": 0.00041871124994941056, "17": 0.00039921104325912893, "18": 0.0003814463270828128, "19": 0.0003651952720247209}}, {"key": "vlasov2019dialogue", "year": "2019", "title": "Dialogue Transformers", "topic_distr": {"0": 0.001837586285546422, "1": 0.0014979089610278606, "2": 0.312457412481308, "3": 0.0010967374546453357, "4": 0.13405391573905945, "5": 0.14368468523025513, "6": 0.12322287261486053, "7": 0.0007143328548409045, "8": 0.0006570585537701845, "9": 0.050018347799777985, "10": 0.22690270841121674, "11": 0.0005296569433994591, "12": 0.000497502158395946, "13": 0.00046902813483029604, "14": 0.00044363702181726694, "15": 0.00042085384484380484, "16": 0.0004002964706160128, "17": 0.00038165386649779975, "18": 0.00036467044265009463, "19": 0.0003491341194603592}}, {"key": "voita2019analyzing", "year": "2019", "title": "Analyzing Multi-head Self-attention: Specialized Heads Do The Heavy Lifting, The Rest Can Be Pruned", "topic_distr": {"0": 0.0867302268743515, "1": 0.0017260625027120113, "2": 0.7400144934654236, "3": 0.0012638712069019675, "4": 0.0011146849719807506, "5": 0.0009970040991902351, "6": 0.0009017987176775932, "7": 0.0008231908432208002, "8": 0.0007571884780190885, "9": 0.0007009843830019236, "10": 0.0006525475764647126, "11": 0.0006103719933889806, "12": 0.0005733171128667891, "13": 0.05521262809634209, "14": 0.10571298003196716, "15": 0.00048498823889531195, "16": 0.00046129809925332665, "17": 0.00043981452472507954, "18": 0.00042024298454634845, "19": 0.00040233906474895775}}, {"key": "voita2019bottom", "year": "2019", "title": "The Bottom-up Evolution Of Representations In The Transformer: A Study With Machine Translation And Language Modeling Objectives", "topic_distr": {"0": 0.0013419438619166613, "1": 0.001095083192922175, "2": 0.2352849394083023, "3": 0.0008017869549803436, "4": 0.0007071449072100222, "5": 0.0006324887508526444, "6": 0.0005720914923585951, "7": 0.0005222235340625048, "8": 0.00048035228974185884, "9": 0.0004446970415301621, "10": 0.511802613735199, "11": 0.0003872134839184582, "12": 0.0003637062618508935, "13": 0.000342889892635867, "14": 0.07041367888450623, "15": 0.000307671376504004, "16": 0.09898695349693298, "17": 0.0002790136495605111, "18": 0.0002665976935531944, "19": 0.07496694475412369}}, {"key": "voskarides2020query", "year": "2020", "title": "Query Resolution For Conversational Search With Limited Supervision", "topic_distr": {"0": 0.0011337029282003641, "1": 0.09087754786014557, "2": 0.2549210786819458, "3": 0.0006778770475648344, "4": 0.0005978627596050501, "5": 0.12429222464561462, "6": 0.2440333515405655, "7": 0.0004415182920638472, "8": 0.24748314917087555, "9": 0.0003759728861041367, "10": 0.032782115042209625, "11": 0.00032737289438955486, "12": 0.00030749852885492146, "13": 0.00028989915153943, "14": 0.0002742052893154323, "15": 0.00026012337184511125, "16": 0.00024741716333664954, "17": 0.00023589444754179567, "18": 0.00022539726342074573, "19": 0.0002157944836653769}}, {"key": "vu2018grounded", "year": "2018", "title": "Grounded Textual Entailment", "topic_distr": {"0": 0.3308219909667969, "1": 0.1336023062467575, "2": 0.12382947653532028, "3": 0.0009812737116590142, "4": 0.0008654434350319207, "5": 0.0007740746950730681, "6": 0.0007001570775173604, "7": 0.0006391258793883026, "8": 0.0005878816009499133, "9": 0.0005442447145469487, "10": 0.000506638316437602, "11": 0.00047389318933710456, "12": 0.0004451237618923187, "13": 0.0004196475201752037, "14": 0.00039692968130111694, "15": 0.0003765451838262379, "16": 0.087273508310318, "17": 0.00034147227415814996, "18": 0.3161078989505768, "19": 0.00031237630173563957}}, {"key": "vu2020exploring", "year": "2020", "title": "Exploring And Predicting Transferability Across NLP Tasks", "topic_distr": {"0": 0.001418736414052546, "1": 0.08104389160871506, "2": 0.2913229465484619, "3": 0.022875186055898666, "4": 0.0007473658188246191, "5": 0.0006684638210572302, "6": 0.000604631204623729, "7": 0.048134662210941315, "8": 0.04705781489610672, "9": 0.0004699907440226525, "10": 0.0004375151765998453, "11": 0.00040923760388977826, "12": 0.029750192537903786, "13": 0.0003623929515015334, "14": 0.15331852436065674, "15": 0.00032517124782316387, "16": 0.00030928768683224916, "17": 0.32019248604774475, "18": 0.0002817613712977618, "19": 0.00026975726359523833}}, {"key": "vu2021better", "year": "2021", "title": "Spot: Better Frozen Model Adaptation Through Soft Prompt Transfer", "topic_distr": {"0": 0.001417199382558465, "1": 0.001157543039880693, "2": 0.22704775631427765, "3": 0.0008474003407172859, "4": 0.0007473742589354515, "5": 0.0006684705149382353, "6": 0.0006046373164281249, "7": 0.000551932374946773, "8": 0.014531487599015236, "9": 0.00046999548794701695, "10": 0.041850510984659195, "11": 0.00040924170752987266, "12": 0.0003843971935566515, "13": 0.04349681735038757, "14": 0.00034277804661542177, "15": 0.0003251745365560055, "16": 0.00030929080094210804, "17": 0.6642864942550659, "18": 0.0002817641943693161, "19": 0.0002697599702514708}}, {"key": "vu2023refreshing", "year": "2023", "title": "Freshllms: Refreshing Large Language Models With Search Engine Augmentation", "topic_distr": {"0": 0.1415485441684723, "1": 0.07636111229658127, "2": 0.06828676909208298, "3": 0.3618103563785553, "4": 0.0004908036789856851, "5": 0.0004389877140056342, "6": 0.0003970680700149387, "7": 0.00036245648516342044, "8": 0.1660427451133728, "9": 0.0003086481592617929, "10": 0.0002873211051337421, "11": 0.0002687509113457054, "12": 0.06477592140436172, "13": 0.00023798749316483736, "14": 0.00022510391136165708, "15": 0.00021354359341785312, "16": 0.11738806217908859, "17": 0.00019365330808795989, "18": 0.00018503582396078855, "19": 0.00017715260037221014}}, {"key": "vuli\u01072020probing", "year": "2020", "title": "Probing Pretrained Language Models For Lexical Semantics", "topic_distr": {"0": 0.291603147983551, "1": 0.0008559361449442804, "2": 0.17113761603832245, "3": 0.0006266931304708123, "4": 0.0005527168395929039, "5": 0.0096960524097085, "6": 0.00044715660624206066, "7": 0.0004081789229530841, "8": 0.0003754516365006566, "9": 0.0003475828852970153, "10": 0.17033424973487854, "11": 0.0003026527410838753, "12": 0.0002842790854629129, "13": 0.00026800864725373685, "14": 0.0397690013051033, "15": 0.0002404812548775226, "16": 0.15841799974441528, "17": 0.00021808188466820866, "18": 0.00020837734336964786, "19": 0.15390633046627045}}, {"key": "wadhwa2023revisiting", "year": "2023", "title": "Revisiting Relation Extraction In The Era Of Large Language Models", "topic_distr": {"0": 0.0014518548268824816, "1": 0.0011844743276014924, "2": 0.2068573236465454, "3": 0.1784043163061142, "4": 0.0007647869642823935, "5": 0.03098512999713421, "6": 0.0006187239778228104, "7": 0.13922536373138428, "8": 0.0005195069243200123, "9": 0.00048094530939124525, "10": 0.00044771278044208884, "11": 0.0004187761223874986, "12": 0.09980540722608566, "13": 0.00037083961069583893, "14": 0.0003507639921735972, "15": 0.00033275035093538463, "16": 0.0003164965601172298, "17": 0.3369004428386688, "18": 0.00028832865064032376, "19": 0.0002760447678156197}}, {"key": "wallace2019allennlp", "year": "2019", "title": "Allennlp Interpret: A Framework For Explaining Predictions Of NLP Models", "topic_distr": {"0": 0.1626371145248413, "1": 0.03886343166232109, "2": 0.13683688640594482, "3": 0.11677594482898712, "4": 0.0008654723642393947, "5": 0.19632506370544434, "6": 0.0007001804769970477, "7": 0.0006391472415998578, "8": 0.000587901275139302, "9": 0.0005442629335448146, "10": 0.2796180844306946, "11": 0.000473909021820873, "12": 0.06260118633508682, "13": 0.0004196615482214838, "14": 0.0003969429526478052, "15": 0.0003765577566809952, "16": 0.00035816410672850907, "17": 0.00034148371196351945, "18": 0.0003262878453824669, "19": 0.00031238675001077354}}, {"key": "wallace2019do", "year": "2019", "title": "Do NLP Models Know Numbers? Probing Numeracy In Embeddings", "topic_distr": {"0": 0.17220571637153625, "1": 0.03590134531259537, "2": 0.21790771186351776, "3": 0.15346229076385498, "4": 0.0009263196843676269, "5": 0.0008285251678898931, "6": 0.0007494079764001071, "7": 0.025039970874786377, "8": 0.0569680854678154, "9": 0.0005825283587910235, "10": 0.293550968170166, "11": 0.0005072280764579773, "12": 0.00047643494326621294, "13": 0.0004491666331887245, "14": 0.00042485076119191945, "15": 0.0004030323470942676, "16": 0.00038334549753926694, "17": 0.0003654923348221928, "18": 0.000349228095728904, "19": 0.03851834312081337}}, {"key": "wallace2019universal", "year": "2019", "title": "Universal Adversarial Triggers For Attacking And Analyzing NLP", "topic_distr": {"0": 0.20657113194465637, "1": 0.15028052031993866, "2": 0.27848580479621887, "3": 0.07200122624635696, "4": 0.0008654644479975104, "5": 0.0007740918081253767, "6": 0.0007001725607551634, "7": 0.07023004442453384, "8": 0.03881816938519478, "9": 0.0005442567635327578, "10": 0.15019045770168304, "11": 0.0004739036376122385, "12": 0.0004451335989870131, "13": 0.0004196568042971194, "14": 0.0003969384415540844, "15": 0.02746478095650673, "16": 0.0003581600612960756, "17": 0.00034147981205023825, "18": 0.00032628412009216845, "19": 0.0003123831993434578}}, {"key": "wan2022factuality", "year": "2022", "title": "Factpegasus: Factuality-aware Pre-training And Fine-tuning For Abstractive Summarization", "topic_distr": {"0": 0.14035800099372864, "1": 0.0013954825699329376, "2": 0.20845894515514374, "3": 0.0010215359507128596, "4": 0.0009009510395117104, "5": 0.0008058332023210824, "6": 0.0007288830238394439, "7": 0.1780666559934616, "8": 0.0006120011094026268, "9": 0.0005665739299729466, "10": 0.21120913326740265, "11": 0.0004933360032737255, "12": 0.0004633862408809364, "13": 0.0004368647641967982, "14": 0.06490800529718399, "15": 0.0003919940209016204, "16": 0.11305780708789825, "17": 0.07545974105596542, "18": 0.0003396633837837726, "19": 0.00032519243541173637}}, {"key": "wan2022what", "year": "2022", "title": "What Do They Capture? -- A Structural Analysis Of Pre-trained Language Models For Source Code", "topic_distr": {"0": 0.19364704191684723, "1": 0.000943121500313282, "2": 0.000797248852904886, "3": 0.0006905174814164639, "4": 0.000609007547609508, "5": 0.050783999264240265, "6": 0.32277607917785645, "7": 0.00044974975753575563, "8": 0.00041368938400410116, "9": 0.0003829823399428278, "10": 0.2532568573951721, "11": 0.00033347628777846694, "12": 0.08175276219844818, "13": 0.0002953039074782282, "14": 0.00027931746444664896, "15": 0.012795589864253998, "16": 0.07079080492258072, "17": 0.00024029237101785839, "18": 0.0002295994636369869, "19": 0.008532548323273659}}, {"key": "wan2023felt", "year": "2023", "title": "\"it Felt Like Having A Second Mind\": Investigating Human-ai Co-creativity In Prewriting With Large Language Models", "topic_distr": {"0": 0.2172081172466278, "1": 0.0012577174929901958, "2": 0.0010631150798872113, "3": 0.20010565221309662, "4": 0.06502881646156311, "5": 0.0007263521547429264, "6": 0.000656991614960134, "7": 0.0005997231346555054, "8": 0.0005516380770131946, "9": 0.5090887546539307, "10": 0.00047540353261865675, "11": 0.0004446771345101297, "12": 0.0004176813818048686, "13": 0.0003937757865060121, "14": 0.0003724585403688252, "15": 0.00035333074629306793, "16": 0.0003360716800671071, "17": 0.00032042013481259346, "18": 0.0003061615861952305, "19": 0.0002931179478764534}}, {"key": "wan2023gpt", "year": "2023", "title": "GPT-RE: In-context Learning For Relation Extraction Using Large Language Models", "topic_distr": {"0": 0.0017828784184530377, "1": 0.001455393387004733, "2": 0.17294812202453613, "3": 0.37231311202049255, "4": 0.0009395881206728518, "5": 0.000840391730889678, "6": 0.02488502860069275, "7": 0.0006938815349712968, "8": 0.0006382470019161701, "9": 0.0005908716702833772, "10": 0.026357758790254593, "11": 0.0005144929164089262, "12": 0.00048325874377042055, "13": 0.0004555998893920332, "14": 0.0004309357318561524, "15": 0.08437749743461609, "16": 0.08212634921073914, "17": 0.22747327387332916, "18": 0.00035422996734268963, "19": 0.0003391384379938245}}, {"key": "wan2023is", "year": "2023", "title": "\"kelly Is A Warm Person, Joseph Is A Role Model\": Gender Biases In Llm-generated Reference Letters", "topic_distr": {"0": 0.45836275815963745, "1": 0.01766081340610981, "2": 0.0007620500982739031, "3": 0.019279425963759422, "4": 0.14468297362327576, "5": 0.0005206610658206046, "6": 0.00047094235196709633, "7": 0.018787479028105736, "8": 0.0003954232088290155, "9": 0.3364158570766449, "10": 0.0003407770418561995, "11": 0.00031875187414698303, "12": 0.0002994008536916226, "13": 0.00028226495487615466, "14": 0.00026698436704464257, "15": 0.00025327326147817075, "16": 0.00024090167426038533, "17": 0.0002296824095537886, "18": 0.00021946165361441672, "19": 0.00021011175704188645}}, {"key": "wan2023poisoning", "year": "2023", "title": "Poisoning Language Models During Instruction Tuning", "topic_distr": {"0": 0.12892486155033112, "1": 0.3102399706840515, "2": 0.0012126676738262177, "3": 0.20331290364265442, "4": 0.03961717337369919, "5": 0.0008285462972708046, "6": 0.000749426893889904, "7": 0.07414093613624573, "8": 0.0006292506586760283, "9": 0.023861676454544067, "10": 0.0005422903341241181, "11": 0.0005072408821433783, "12": 0.00047644699225202203, "13": 0.00044917798368260264, "14": 0.000424861500505358, "15": 0.00040304253343492746, "16": 0.00038335518911480904, "17": 0.06033405289053917, "18": 0.00034923694329336286, "19": 0.15261292457580566}}, {"key": "wang2016chinese", "year": "2016", "title": "Chinese Song Iambics Generation With Neural Attention-based Model", "topic_distr": {"0": 0.0015596289886161685, "1": 0.001273076399229467, "2": 0.43524909019470215, "3": 0.0009321380639448762, "4": 0.0008221063762903214, "5": 0.0007353133405558765, "6": 0.0006650972063653171, "7": 0.24561680853366852, "8": 0.000558443833142519, "9": 0.000516992062330246, "10": 0.0004812687693629414, "11": 0.00045016329386271536, "12": 0.07590746879577637, "13": 0.00039863394340500236, "14": 0.040592268109321594, "15": 0.07040343433618546, "16": 0.12290698289871216, "17": 0.00032437327899970114, "18": 0.00030993882683105767, "19": 0.00029673424432985485}}, {"key": "wang2016multimodal", "year": "2016", "title": "Multimodal Memory Modelling For Video Captioning", "topic_distr": {"0": 0.0010485155507922173, "1": 0.0008559497073292732, "2": 0.30942949652671814, "3": 0.0006267037242650986, "4": 0.0005527259199880064, "5": 0.0004943725652992725, "6": 0.0004471641732379794, "7": 0.05603525787591934, "8": 0.00037545801023952663, "9": 0.020030023530125618, "10": 0.00032357097370550036, "11": 0.0003026578633580357, "12": 0.00028428391669876873, "13": 0.0002680131874512881, "14": 0.021068328991532326, "15": 0.0826454907655716, "16": 0.09562718868255615, "17": 0.00021808558085467666, "18": 0.40916720032691956, "19": 0.00019950306159444153}}, {"key": "wang2016neural", "year": "2016", "title": "Neural Machine Translation Advised By Statistical Machine Translation", "topic_distr": {"0": 0.0011543716536834836, "1": 0.0009430149802938104, "2": 0.39083537459373474, "3": 0.0006904111942276359, "4": 0.10706295073032379, "5": 0.0005446303985081613, "6": 0.0004926228430122137, "7": 0.1490512639284134, "8": 0.00041362704359926283, "9": 0.0003829246270470321, "10": 0.00035646517062559724, "11": 0.0003334260545670986, "12": 0.00031318419496528804, "13": 0.00029525940772145987, "14": 0.34592393040657043, "15": 0.0002649330417625606, "16": 0.00025199190713465214, "17": 0.00024025615130085498, "18": 0.00022956485918257385, "19": 0.00021978453150950372}}, {"key": "wang2017joint", "year": "2017", "title": "A Joint Model For Question Answering And Question Generation", "topic_distr": {"0": 0.0023119617253541946, "1": 0.0018860436975955963, "2": 0.39770662784576416, "3": 0.0013810248346999288, "4": 0.0012180105550214648, "5": 0.0010894211009144783, "6": 0.0009853903902694583, "7": 0.0008994960226118565, "8": 0.304978609085083, "9": 0.07271850854158401, "10": 0.0007130350568331778, "11": 0.11008293926715851, "12": 0.0006264603580348194, "13": 0.0005906054866500199, "14": 0.0005586327752098441, "15": 0.10036977380514145, "16": 0.0005040578544139862, "17": 0.0004805828502867371, "18": 0.00045919715194031596, "19": 0.0004396336153149605}}, {"key": "wang2017reinforced", "year": "2017", "title": "R\\(^3\\): Reinforced Reader-ranker For Open-domain Question Answering", "topic_distr": {"0": 0.001056456589139998, "1": 0.0008630548254586756, "2": 0.4560380280017853, "3": 0.0006319304811768234, "4": 0.0005573362577706575, "5": 0.0004984958795830607, "6": 0.00045089368359185755, "7": 0.016080141067504883, "8": 0.3848496079444885, "9": 0.0003504877968225628, "10": 0.00032626965548843145, "11": 0.04920573905110359, "12": 0.08746135234832764, "13": 0.00027024850714951754, "14": 0.0002556184772402048, "15": 0.00024249106354545802, "16": 0.00023064613924361765, "17": 0.00021990449749864638, "18": 0.00021011884382460266, "19": 0.0002011669857893139}}, {"key": "wang2017steering", "year": "2017", "title": "Steering Output Style And Topic In Neural Response Generation", "topic_distr": {"0": 0.09886821359395981, "1": 0.0013951536966487765, "2": 0.0011792995501309633, "3": 0.0010214283829554915, "4": 0.0009008586639538407, "5": 0.0008057508384808898, "6": 0.14919887483119965, "7": 0.5866814255714417, "8": 0.0006119384779594839, "9": 0.0005665159551426768, "10": 0.0005273706628941, "11": 0.1284676343202591, "12": 0.00046333883074112236, "13": 0.00043682006071321666, "14": 0.00041317258728668094, "15": 0.000391953915823251, "16": 0.027050016447901726, "17": 0.0003554457798600197, "18": 0.0003396286047063768, "19": 0.00032515914062969387}}, {"key": "wang2018can", "year": "2018", "title": "Can You Tell Me How To Get Past Sesame Street? Sentence-level Pretraining Beyond Language Modeling", "topic_distr": {"0": 0.0016204409766942263, "1": 0.0013232637429609895, "2": 0.18935558199882507, "3": 0.0009685253025963902, "4": 0.053081076592206955, "5": 0.0007640161202289164, "6": 0.0006910590454936028, "7": 0.0006308209267444909, "8": 0.0005802424857392907, "9": 0.0005371726583689451, "10": 0.24592901766300201, "11": 0.000467735284473747, "12": 0.13257786631584167, "13": 0.00041419451008550823, "14": 0.11986582726240158, "15": 0.00037165224784985185, "16": 0.000353498209733516, "17": 0.00033703510416671634, "18": 0.0003220372018404305, "19": 0.2498089224100113}}, {"key": "wang2018learning", "year": "2018", "title": "Learning To Ask Questions In Open-domain Conversational Systems With Typed Decoders", "topic_distr": {"0": 0.08280312269926071, "1": 0.001376273576170206, "2": 0.30688178539276123, "3": 0.0010076889302581549, "4": 0.15258008241653442, "5": 0.01932673342525959, "6": 0.0007190048927441239, "7": 0.2514888644218445, "8": 0.179193913936615, "9": 0.0005588954081758857, "10": 0.000520276662427932, "11": 0.000486650038510561, "12": 0.00045710618724115193, "13": 0.0004309441428631544, "14": 0.00040761474519968033, "15": 0.0003866814950015396, "16": 0.00036779334186576307, "17": 0.00035066448617726564, "18": 0.0003350600600242615, "19": 0.0003207852423656732}}, {"key": "wang2018multi", "year": "2018", "title": "Multi-granularity Hierarchical Attention Fusion Networks For Reading Comprehension And Question Answering", "topic_distr": {"0": 0.0013706396566703916, "1": 0.0011190176010131836, "2": 0.5754960179328918, "3": 0.0008194382535293698, "4": 0.0007227151072584093, "5": 0.0006464148173108697, "6": 0.04029536619782448, "7": 0.0319722518324852, "8": 0.21855099499225616, "9": 0.0004544882685877383, "10": 0.06255152821540833, "11": 0.00039573904359713197, "12": 0.0003717142390087247, "13": 0.00035043954267166555, "14": 0.00033146829809993505, "15": 0.00031444558408111334, "16": 0.06341885030269623, "17": 0.00028515688609331846, "18": 0.00027246755780652165, "19": 0.00026085940771736205}}, {"key": "wang2018reinforced", "year": "2018", "title": "Reinforced Cross-modal Matching And Self-supervised Imitation Learning For Vision-language Navigation", "topic_distr": {"0": 0.0012995995348319411, "1": 0.001060902839526534, "2": 0.0008968501351773739, "3": 0.0007767699426040053, "4": 0.11921708285808563, "5": 0.0006127513479441404, "6": 0.0005542387370951474, "7": 0.0005059269606135786, "8": 0.00046536236186511815, "9": 0.0004308197821956128, "10": 0.0004010508710052818, "11": 0.6591014266014099, "12": 0.0003523564082570374, "13": 0.047174111008644104, "14": 0.000314206350594759, "15": 0.0002980701392516494, "16": 0.04897904396057129, "17": 0.000270306714810431, "18": 0.11704187095165253, "19": 0.000247274583671242}}, {"key": "wang2018robust", "year": "2018", "title": "Robust Text-to-sql Generation With Execution-guided Decoding", "topic_distr": {"0": 0.002308477181941271, "1": 0.0018860838608816266, "2": 0.2662420868873596, "3": 0.2999624013900757, "4": 0.0012178986798971891, "5": 0.0010893209837377071, "6": 0.0009852999355643988, "7": 0.197231724858284, "8": 0.11408683657646179, "9": 0.0007658914546482265, "10": 0.0007129696314223111, "11": 0.0006668888381682336, "12": 0.0006264029070734978, "13": 0.0005905513535253704, "14": 0.0005585814942605793, "15": 0.0005298953037708998, "16": 0.10915938019752502, "17": 0.0004805387870874256, "18": 0.00045915503869764507, "19": 0.0004395933065097779}}, {"key": "wang2018task", "year": "2018", "title": "A Task In A Suit And A Tie: Paraphrase Generation With Semantic Augmentation", "topic_distr": {"0": 0.13034853339195251, "1": 0.12792710959911346, "2": 0.3158152401447296, "3": 0.001080797053873539, "4": 0.0009532175026834011, "5": 0.0008525819866918027, "6": 0.000771167513448745, "7": 0.05910062417387962, "8": 0.0006475049303844571, "9": 0.0005994423991069198, "10": 0.06261666119098663, "11": 0.0005219557788223028, "12": 0.027569783851504326, "13": 0.0004622084670700133, "14": 0.02252725511789322, "15": 0.10784244537353516, "16": 0.11763322353363037, "17": 0.00037610463914461434, "18": 0.022010039538145065, "19": 0.0003440577129367739}}, {"key": "wang2019bert", "year": "2019", "title": "BERT Has A Mouth, And It Must Speak: BERT As A Markov Random Field Language Model", "topic_distr": {"0": 0.0034656873904168606, "1": 0.0028292699716985226, "2": 0.3482162058353424, "3": 0.0020713212434202433, "4": 0.0018268248531967402, "5": 0.0016339608700945973, "6": 0.0014779313933104277, "7": 0.29613927006721497, "8": 0.0012409338960424066, "9": 0.0011488227173686028, "10": 0.2660316824913025, "11": 0.0010003206552937627, "12": 0.06757435947656631, "13": 0.0008858158253133297, "14": 0.0008378617349080741, "15": 0.0007948329439386725, "16": 0.0007560078520327806, "17": 0.0007207990856841207, "18": 0.0006887238705530763, "19": 0.000659381621517241}}, {"key": "wang2019improving", "year": "2019", "title": "Improving Knowledge-aware Dialogue Generation Via Knowledge Base Question Answering", "topic_distr": {"0": 0.001707513933070004, "1": 0.0013951443834230304, "2": 0.0011793372686952353, "3": 0.001021421398036182, "4": 0.0009008548804558814, "5": 0.12919390201568604, "6": 0.34326252341270447, "7": 0.057503070682287216, "8": 0.15003973245620728, "9": 0.0005665134522132576, "10": 0.0005273683345876634, "11": 0.0004932833835482597, "12": 0.0004633367934729904, "13": 0.0004368181398604065, "14": 0.00041317075374536216, "15": 0.00039195219869725406, "16": 0.3094838559627533, "17": 0.0003554442373570055, "18": 0.0003396271204110235, "19": 0.0003251577145420015}}, {"key": "wang2019incorporating", "year": "2019", "title": "Structbert: Incorporating Language Structures Into Pre-training For Deep Language Understanding", "topic_distr": {"0": 0.001619772519916296, "1": 0.034396011382341385, "2": 0.30419808626174927, "3": 0.0009685244876891375, "4": 0.0008542016730643809, "5": 0.0007640188559889793, "6": 0.0006910614902153611, "7": 0.0006308231386356056, "8": 0.05881022289395332, "9": 0.0005371745792217553, "10": 0.4994276463985443, "11": 0.00046773694339208305, "12": 0.0004393412673380226, "13": 0.0004141959943808615, "14": 0.00039177326834760606, "15": 0.0003716535575222224, "16": 0.09405041486024857, "17": 0.00033703629742376506, "18": 0.0003220383368898183, "19": 0.0003083182964473963}}, {"key": "wang2019learning", "year": "2019", "title": "Learning From Explanations With Neural Execution Tree", "topic_distr": {"0": 0.0010565737029537559, "1": 0.18767684698104858, "2": 0.3162338137626648, "3": 0.0006319651147350669, "4": 0.0005573650123551488, "5": 0.10443021357059479, "6": 0.00045091708307154477, "7": 0.000411611603340134, "8": 0.019980326294898987, "9": 0.00035050598671659827, "10": 0.00032628662302158773, "11": 0.14558112621307373, "12": 0.07574187219142914, "13": 0.0002702625351957977, "14": 0.02804393880069256, "15": 0.00024250365095213056, "16": 0.11738263070583344, "17": 0.00021991592075210065, "18": 0.00021012975776102394, "19": 0.00020117743406444788}}, {"key": "wang2019multi", "year": "2019", "title": "Multi-passage BERT: A Globally Normalized BERT Model For Open-domain Question Answering", "topic_distr": {"0": 0.0017089524772018194, "1": 0.037751708179712296, "2": 0.40473872423171997, "3": 0.0010214761132374406, "4": 0.000900898186955601, "5": 0.033305779099464417, "6": 0.000728841288946569, "7": 0.000665309838950634, "8": 0.29152917861938477, "9": 0.0005665415665134788, "10": 0.22349080443382263, "11": 0.0004933077725581825, "12": 0.00046335975639522076, "13": 0.00043683979311026633, "14": 0.0004131912428420037, "15": 0.0003919716109521687, "16": 0.00037282504490576684, "17": 0.0003554618451744318, "18": 0.0003396439424250275, "19": 0.0003251738380640745}}, {"key": "wang2019stickier", "year": "2019", "title": "Superglue: A Stickier Benchmark For General-purpose Language Understanding Systems", "topic_distr": {"0": 0.0024965060874819756, "1": 0.002036816906183958, "2": 0.38043445348739624, "3": 0.0014914068160578609, "4": 0.05930251628160477, "5": 0.0011764918453991413, "6": 0.0010641467524692416, "7": 0.0009713873732835054, "8": 0.0008935027872212231, "9": 0.07551531493663788, "10": 0.0007700237329117954, "11": 0.000720255367923528, "12": 0.44475480914115906, "13": 0.0006378091056831181, "14": 0.0006032809615135193, "15": 0.0005722991772927344, "16": 0.0005443441914394498, "17": 0.0005189930088818073, "18": 0.0004958980716764927, "19": 0.024999720975756645}}, {"key": "wang2019structured", "year": "2019", "title": "Structured Pruning Of Large Language Models", "topic_distr": {"0": 0.0016637955559417605, "1": 0.001357866101898253, "2": 0.4221906363964081, "3": 0.0009942527394741774, "4": 0.0008768883999437094, "5": 0.0007843123166821897, "6": 0.0007094171596691012, "7": 0.0006475787959061563, "8": 0.03020675852894783, "9": 0.0005514427903108299, "10": 0.22953955829143524, "11": 0.0004801607574336231, "12": 0.00045101085561327636, "13": 0.3074066936969757, "14": 0.00040217937203124166, "15": 0.00038152525667101145, "16": 0.0003628889680840075, "17": 0.00034598849015310407, "18": 0.000330592185491696, "19": 0.00031650770688429475}}, {"key": "wang2019tree", "year": "2019", "title": "Tree Transformer: Integrating Tree Structures Into Self-attention", "topic_distr": {"0": 0.0015783975832164288, "1": 0.0012892746599391103, "2": 0.3733179569244385, "3": 0.0009439291316084564, "4": 0.00083251140313223, "5": 0.0007446190575137734, "6": 0.0006735142669640481, "7": 0.07864581793546677, "8": 0.0005655111744999886, "9": 0.0005235347780399024, "10": 0.2581385374069214, "11": 0.2130959928035736, "12": 0.0004281856236048043, "13": 0.00040367883048020303, "14": 0.00038182546268217266, "15": 0.0003622166404966265, "16": 0.0671316459774971, "17": 0.000328478345181793, "18": 0.00031386123737320304, "19": 0.00030048954067751765}}, {"key": "wang2020confidence", "year": "2020", "title": "Confidence-aware Non-repetitive Multimodal Transformers For Textcaps", "topic_distr": {"0": 0.001370705314911902, "1": 0.0011192313395440578, "2": 0.17639730870723724, "3": 0.0008194709080271423, "4": 0.0007227394380606711, "5": 0.0006464365869760513, "6": 0.0005847073625773191, "7": 0.18200109899044037, "8": 0.1383245438337326, "9": 0.0004545035772025585, "10": 0.08137868344783783, "11": 0.00039575237315148115, "12": 0.00037172678275965154, "13": 0.000350451358826831, "14": 0.00033147947397083044, "15": 0.0003144561778753996, "16": 0.0002990960201714188, "17": 0.00028516651946119964, "18": 0.4135715663433075, "19": 0.00026086819707416}}, {"key": "wang2020deep", "year": "2020", "title": "Minilm: Deep Self-attention Distillation For Task-agnostic Compression Of Pre-trained Transformers", "topic_distr": {"0": 0.0010310212383046746, "1": 0.0008417089702561498, "2": 0.27947285771369934, "3": 0.0006162666832096875, "4": 0.0005435242783278227, "5": 0.0004861414199694991, "6": 0.04667890444397926, "7": 0.0004013896977994591, "8": 0.00036920676939189434, "9": 0.00034180155489593744, "10": 0.2595694661140442, "11": 0.00029761873884126544, "12": 0.0002795507025439292, "13": 0.380409836769104, "14": 0.027583731338381767, "15": 0.00023648134083487093, "16": 0.00022492998687084764, "17": 0.00021445454331114888, "18": 0.00020491142640821636, "19": 0.00019618141232058406}}, {"key": "wang2020efficient", "year": "2020", "title": "Efficient Object-level Visual Context Modeling For Multimodal Machine Translation: Masking Irrelevant Objects Helps Grounding", "topic_distr": {"0": 0.001343194511719048, "1": 0.0010950213763862848, "2": 0.0009257701458409429, "3": 0.0008018130902200937, "4": 0.0007071676081977785, "5": 0.0006325095309875906, "6": 0.0005721102352254093, "7": 0.07160402089357376, "8": 0.00048036803491413593, "9": 0.00044471159344539046, "10": 0.09602705389261246, "11": 0.0003872261440847069, "12": 0.0003637181653175503, "13": 0.00034290109761059284, "14": 0.20173364877700806, "15": 0.00030768144642934203, "16": 0.0002926521992776543, "17": 0.0002790227881632745, "18": 0.5978764295578003, "19": 0.023782970383763313}}, {"key": "wang2020encoding", "year": "2020", "title": "Encoding Syntactic Knowledge In Transformer Encoder For Intent Detection And Slot Filling", "topic_distr": {"0": 0.0014325006632134318, "1": 0.0011705824872478843, "2": 0.3887871205806732, "3": 0.0008570366771891713, "4": 0.0007558733923360705, "5": 0.0006760734249837697, "6": 0.2793252766132355, "7": 0.0005582097801379859, "8": 0.0005134532111696899, "9": 0.0004753409593831748, "10": 0.24055810272693634, "11": 0.00041389622492715716, "12": 0.00038876914186403155, "13": 0.00036651830305345356, "14": 0.00034667665022425354, "15": 0.0003288729058112949, "16": 0.08218964189291, "17": 0.00029824039665982127, "18": 0.0002849688462447375, "19": 0.00027282809605821967}}, {"key": "wang2020fairseq", "year": "2020", "title": "Fairseq S2T: Fast Speech-to-text Modeling With Fairseq", "topic_distr": {"0": 0.0032827917020767927, "1": 0.13964203000068665, "2": 0.2034294605255127, "3": 0.001962898066267371, "4": 0.056424904614686966, "5": 0.001548426691442728, "6": 0.0423344224691391, "7": 0.0012784802820533514, "8": 0.001175973447971046, "9": 0.08258213102817535, "10": 0.253635048866272, "11": 0.0009479558211751282, "12": 0.0008904066635295749, "13": 0.0008394450997002423, "14": 0.20659534633159637, "15": 0.0007532249437645078, "16": 0.0007164323469623923, "17": 0.0006830666679888964, "18": 0.0006526705110445619, "19": 0.0006248642457649112}}, {"key": "wang2020hardware", "year": "2020", "title": "HAT: Hardware-aware Transformers For Efficient Natural Language Processing", "topic_distr": {"0": 0.0013857724843546748, "1": 0.0011318083852529526, "2": 0.1689652055501938, "3": 0.0008286511292681098, "4": 0.000730833038687706, "5": 0.0006536757573485374, "6": 0.03627452254295349, "7": 0.00053971674060449, "8": 0.0004964429535903037, "9": 0.0004595933423843235, "10": 0.36365288496017456, "11": 0.0004001842171419412, "12": 0.0003758895618375391, "13": 0.2500589191913605, "14": 0.172597736120224, "15": 0.00031797762494534254, "16": 0.000302445434499532, "17": 0.0002883599663618952, "18": 0.0002755280875135213, "19": 0.0002637895231600851}}, {"key": "wang2020high", "year": "2020", "title": "Lightseq: A High Performance Inference Library For Transformers", "topic_distr": {"0": 0.002043060725554824, "1": 0.0016694259829819202, "2": 0.0014113070210441947, "3": 0.001222382765263319, "4": 0.0010780955199152231, "5": 0.0009642749209888279, "6": 0.0008721948252059519, "7": 0.0007961674709804356, "8": 0.000732331769540906, "9": 0.000677972799167037, "10": 0.34758812189102173, "11": 0.0005903349374420941, "12": 0.1748662143945694, "13": 0.38817062973976135, "14": 0.07518132776021957, "15": 0.00046906722127459943, "16": 0.000446154794190079, "17": 0.0004253764927852899, "18": 0.0004064474196638912, "19": 0.0003891312226187438}}, {"key": "wang2020large", "year": "2020", "title": "A Large-scale Chinese Short-text Conversation Dataset", "topic_distr": {"0": 0.0020111091434955597, "1": 0.15150991082191467, "2": 0.0013885651715099812, "3": 0.00120267563033849, "4": 0.0010607122676447034, "5": 0.15398837625980377, "6": 0.34216219186782837, "7": 0.0007833316340111196, "8": 0.000720525102224201, "9": 0.0006670425063930452, "10": 0.0006209510029293597, "11": 0.0005808175192214549, "12": 0.15058541297912598, "13": 0.0005143324378877878, "14": 0.00048648877418600023, "15": 0.19007734954357147, "16": 0.0004389618698041886, "17": 0.0004185185534879565, "18": 0.00039989466313272715, "19": 0.0003828576591331512}}, {"key": "wang2020modelling", "year": "2020", "title": "Modelling Hierarchical Structure Between Dialogue Policy And Natural Language Generator With Option Framework For Task-oriented Dialogue System", "topic_distr": {"0": 0.18099944293498993, "1": 0.0008019873057492077, "2": 0.000677922333125025, "3": 0.0005871522589586675, "4": 0.2009444385766983, "5": 0.12692032754421234, "6": 0.16628113389015198, "7": 0.00038242535083554685, "8": 0.0003517629811540246, "9": 0.00032565256697125733, "10": 0.00030315053300000727, "11": 0.3196435868740082, "12": 0.00026634286041371524, "13": 0.0002510989725124091, "14": 0.00023750559194013476, "15": 0.00022530838032253087, "16": 0.00021430278138723224, "17": 0.0002043222775682807, "18": 0.0001952300372067839, "19": 0.00018691249715629965}}, {"key": "wang2020multi", "year": "2020", "title": "Minilmv2: Multi-head Self-attention Relation Distillation For Compressing Pretrained Transformers", "topic_distr": {"0": 0.0015602072235196829, "1": 0.0012731736060231924, "2": 0.1943352222442627, "3": 0.0009321589022874832, "4": 0.0008221311727538705, "5": 0.0007353336550295353, "6": 0.0006651155999861658, "7": 0.000607138907071203, "8": 0.02162991091609001, "9": 0.0005170063232071698, "10": 0.22249440848827362, "11": 0.00045017575030215085, "12": 0.000422846176661551, "13": 0.23345977067947388, "14": 0.04024779796600342, "15": 0.017993900924921036, "16": 0.07349101454019547, "17": 0.13327167928218842, "18": 0.0003099474124610424, "19": 0.05478106439113617}}, {"key": "wang2020narrative", "year": "2020", "title": "Narrative Interpolation For Generating And Understanding Stories", "topic_distr": {"0": 0.0021146938670426607, "1": 0.0017264490015804768, "2": 0.13551683723926544, "3": 0.1170320212841034, "4": 0.001114665879867971, "5": 0.0009969858219847083, "6": 0.0009017821284942329, "7": 0.6602323055267334, "8": 0.0007571745663881302, "9": 0.0007009715191088617, "10": 0.0006525355856865644, "11": 0.0006103607593104243, "12": 0.07438287883996964, "13": 0.0005404939292930067, "14": 0.000511233985889703, "15": 0.0004849793331231922, "16": 0.00046128963003866374, "17": 0.000439806462964043, "18": 0.0004202352720312774, "19": 0.00040233167237602174}}, {"key": "wang2020pretrain", "year": "2020", "title": "To Pretrain Or Not To Pretrain: Examining The Benefits Of Pretraining On Resource Rich Tasks", "topic_distr": {"0": 0.0022677292581647635, "1": 0.1308048963546753, "2": 0.38803985714912415, "3": 0.0013559033395722508, "4": 0.0011958535760641098, "5": 0.0010696032550185919, "6": 0.0009674652246758342, "7": 0.0008831333252601326, "8": 0.0008123248699121177, "9": 0.0007520281942561269, "10": 0.13253013789653778, "11": 0.000654817558825016, "12": 0.0006150644621811807, "13": 0.12350598722696304, "14": 0.0005484707071445882, "15": 0.0005203037289902568, "16": 0.0004948885762132704, "17": 0.00047184061259031296, "18": 0.000450843945145607, "19": 0.21205882728099823}}, {"key": "wang2020rethinking", "year": "2020", "title": "Rethinking The Value Of Transformer Components", "topic_distr": {"0": 0.16629758477210999, "1": 0.0014977689133957028, "2": 0.6493269801139832, "3": 0.0010966785484924912, "4": 0.0009672237792983651, "5": 0.0008651097305119038, "6": 0.0007824990898370743, "7": 0.0007142903632484376, "8": 0.0006570194964297116, "9": 0.0006082507316023111, "10": 0.0005662215990014374, "11": 0.0005296254530549049, "12": 0.000497472588904202, "13": 0.00046900022425688803, "14": 0.12374058365821838, "15": 0.00042082881554961205, "16": 0.0004002726636826992, "17": 0.04984884709119797, "18": 0.00036464876029640436, "19": 0.0003491133393254131}}, {"key": "wang2020self", "year": "2020", "title": "Linformer: Self-attention With Linear Complexity", "topic_distr": {"0": 0.002353932010009885, "1": 0.0019212912302464247, "2": 0.44213539361953735, "3": 0.001406876021064818, "4": 0.0012408075854182243, "5": 0.001109811244532466, "6": 0.0010038336040452123, "7": 0.0009163316572085023, "8": 0.0008428613655269146, "9": 0.0007802980835549533, "10": 0.36555537581443787, "11": 0.000679433171171695, "12": 0.0006381857092492282, "13": 0.17638787627220154, "14": 0.0005690885591320693, "15": 0.0005398627836257219, "16": 0.0005134922103025019, "17": 0.0004895778256468475, "18": 0.00046779183321632445, "19": 0.0004478621412999928}}, {"key": "wang2020vd", "year": "2020", "title": "VD-BERT: A Unified Vision And Dialog Transformer With BERT", "topic_distr": {"0": 0.0012984659988433123, "1": 0.001060868613421917, "2": 0.1110820323228836, "3": 0.00077673519263044, "4": 0.22167177498340607, "5": 0.000612725387327373, "6": 0.0005542152212001383, "7": 0.0005059054819867015, "8": 0.06440041959285736, "9": 0.00043080150499008596, "10": 0.21173134446144104, "11": 0.02864777483046055, "12": 0.00035234144888818264, "13": 0.0003321755211800337, "14": 0.0003141930210404098, "15": 0.0002980574790854007, "16": 0.0002834983461070806, "17": 0.00027029524790123105, "18": 0.29688191413879395, "19": 0.05849449336528778}}, {"key": "wang2021adversarial", "year": "2021", "title": "Adversarial GLUE: A Multi-task Benchmark For Robustness Evaluation Of Language Models", "topic_distr": {"0": 0.12120643258094788, "1": 0.4209570586681366, "2": 0.13579557836055756, "3": 0.15228381752967834, "4": 0.0005769351264461875, "5": 0.0005160256405360997, "6": 0.00046674953773617744, "7": 0.00042606398346833885, "8": 0.0003919027221854776, "9": 0.0003628128324635327, "10": 0.00033774308394640684, "11": 0.0003159139887429774, "12": 0.14865891635417938, "13": 0.0002797519264277071, "14": 0.01628115028142929, "15": 0.00025101835490204394, "16": 0.00023875691113062203, "17": 0.0002276375307701528, "18": 0.0002175077679567039, "19": 0.0002082411083392799}}, {"key": "wang2021automatic", "year": "2021", "title": "Screen2words: Automatic Mobile UI Summarization With Multimodal Learning", "topic_distr": {"0": 0.0015603607753291726, "1": 0.0012732436880469322, "2": 0.0010761646553874016, "3": 0.0009320836397819221, "4": 0.17976325750350952, "5": 0.21585626900196075, "6": 0.0006650566356256604, "7": 0.30150511860847473, "8": 0.0005584097816608846, "9": 0.0005169605137780309, "10": 0.000481239432701841, "11": 0.00045013584895059466, "12": 0.0004228087200317532, "13": 0.00039860967081040144, "14": 0.0003770307230297476, "15": 0.0003576681192498654, "16": 0.00034019717713817954, "17": 0.000324353517498821, "18": 0.292844295501709, "19": 0.0002967161708511412}}, {"key": "wang2021can", "year": "2021", "title": "Can Generative Pre-trained Language Models Serve As Knowledge Bases For Closed-book QA?", "topic_distr": {"0": 0.0019487844547256827, "1": 0.0015914048999547958, "2": 0.05438403785228729, "3": 0.1534290909767151, "4": 0.001027609221637249, "5": 0.0009191212011501193, "6": 0.0008313529542647302, "7": 0.08950361609458923, "8": 0.2367740124464035, "9": 0.0006462256424129009, "10": 0.000601572566665709, "11": 0.0005626915954053402, "12": 0.09557632356882095, "13": 0.07337089627981186, "14": 0.0004713066155090928, "15": 0.05596742779016495, "16": 0.16592299938201904, "17": 0.0004054575692862272, "18": 0.0003874149115290493, "19": 0.06567864865064621}}, {"key": "wang2021entailment", "year": "2021", "title": "Entailment As Few-shot Learner", "topic_distr": {"0": 0.0017835800535976887, "1": 0.07761728763580322, "2": 0.2707153260707855, "3": 0.0010653139324858785, "4": 0.0009395584347657859, "5": 0.0008403657120652497, "6": 0.0007601177785545588, "7": 0.0006938599399290979, "8": 0.0006382271531037986, "9": 0.0005908532766625285, "10": 0.0005500263068825006, "11": 0.0005144768510945141, "12": 0.07697764784097672, "13": 0.1277989149093628, "14": 0.02750755287706852, "15": 0.0004087920824531466, "16": 0.00038882388616912067, "17": 0.336606502532959, "18": 0.0003542189078871161, "19": 0.07324852049350739}}, {"key": "wang2021ernie", "year": "2021", "title": "ERNIE 3.0 Titan: Exploring Larger-scale Knowledge Enhanced Pre-training For Language Understanding And Generation", "topic_distr": {"0": 0.0016404803609475493, "1": 0.0211770199239254, "2": 0.0011327610118314624, "3": 0.0009811309864744544, "4": 0.0008653181721456349, "5": 0.0007739629363641143, "6": 0.0007000560872256756, "7": 0.04817531630396843, "8": 0.0005877967923879623, "9": 0.0005441661924123764, "10": 0.21462196111679077, "11": 0.0004738248244393617, "12": 0.0004450595297385007, "13": 0.3493286073207855, "14": 0.0003968724049627781, "15": 0.25875750184059143, "16": 0.049485690891742706, "17": 0.00034142303047701716, "18": 0.00032622984144836664, "19": 0.049244869500398636}}, {"key": "wang2021identifier", "year": "2021", "title": "Codet5: Identifier-aware Unified Pre-trained Encoder-decoder Models For Code Understanding And Generation", "topic_distr": {"0": 0.001248219981789589, "1": 0.0010185897117480636, "2": 0.000860963249579072, "3": 0.0007456986350007355, "4": 0.0006576735759153962, "5": 0.000588240276556462, "6": 0.2819887399673462, "7": 0.0321219265460968, "8": 0.0004467471444513649, "9": 0.0004135862982366234, "10": 0.3981017768383026, "11": 0.0003601242497097701, "12": 0.04083418846130371, "13": 0.0003189014969393611, "14": 0.0003016375994775444, "15": 0.11277557164430618, "16": 0.00027216950547881424, "17": 0.00025949403061531484, "18": 0.1264483630657196, "19": 0.00023738319578114897}}, {"key": "wang2021math", "year": "2021", "title": "Math Word Problem Generation With Mathematical Consistency And Problem Context Constraints", "topic_distr": {"0": 0.0016853533452376723, "1": 0.0013761938316747546, "2": 0.001163393259048462, "3": 0.5287759304046631, "4": 0.10566829890012741, "5": 0.0007948749116621912, "6": 0.0723935067653656, "7": 0.2829165756702423, "8": 0.0006036786362528801, "9": 0.0005588692147284746, "10": 0.0005202522734180093, "11": 0.0004866272211074829, "12": 0.0004570847377181053, "13": 0.000430923915700987, "14": 0.00040759562398307025, "15": 0.00038666336331516504, "16": 0.0003677760832943022, "17": 0.00035064801340922713, "18": 0.00033504434395581484, "19": 0.00032077019568532705}}, {"key": "wang2021scene", "year": "2021", "title": "SGEITL: Scene Graph Enhanced Image-text Learning For Visual Commonsense Reasoning", "topic_distr": {"0": 0.0010936891194432974, "1": 0.0008932964992709458, "2": 0.0007551845628768206, "3": 0.0006540751201100647, "4": 0.0005768671981059015, "5": 0.0005159651627764106, "6": 0.0004666948225349188, "7": 0.0004260140412952751, "8": 0.09573159366846085, "9": 0.0003627703117672354, "10": 0.07051639258861542, "11": 0.0003158769686706364, "12": 0.0002967005129903555, "13": 0.00027971912641078234, "14": 0.00026457637432031333, "15": 0.0002509889309294522, "16": 0.2980814278125763, "17": 0.026789946481585503, "18": 0.5015199780464172, "19": 0.00020821670477744192}}, {"key": "wang2021simple", "year": "2021", "title": "Simvlm: Simple Visual Language Model Pretraining With Weak Supervision", "topic_distr": {"0": 0.0012503282632678747, "1": 0.0010190146276727319, "2": 0.13322336971759796, "3": 0.0007457785541191697, "4": 0.0006577444146387279, "5": 0.0005883024423383176, "6": 0.0005321245407685637, "7": 0.0004857403982896358, "8": 0.0004467943508643657, "9": 0.0004136300121899694, "10": 0.00038504888652823865, "11": 0.0003601623175200075, "12": 0.0003382973372936249, "13": 0.0922146886587143, "14": 0.00030166946817189455, "15": 0.02225818671286106, "16": 0.0002721982600633055, "17": 0.13366158306598663, "18": 0.409889817237854, "19": 0.2009555548429489}}, {"key": "wang2021unified", "year": "2021", "title": "UFO: A Unified Transformer For Vision-language Representation Learning", "topic_distr": {"0": 0.001401093089953065, "1": 0.0011441264068707824, "2": 0.15123876929283142, "3": 0.0008377822232432663, "4": 0.0007388916565105319, "5": 0.0006608840194530785, "6": 0.0005977751570753753, "7": 0.0005456684157252312, "8": 0.05112963169813156, "9": 0.00046466145431622863, "10": 0.36080631613731384, "11": 0.00040459720185026526, "12": 0.0003800346457865089, "13": 0.015143325552344322, "14": 0.00033888782490976155, "15": 0.0003214840835426003, "16": 0.00030578061705455184, "17": 0.000291539792669937, "18": 0.4129820764064789, "19": 0.00026669842191040516}}, {"key": "wang2022clip", "year": "2022", "title": "CLIP-TD: CLIP Targeted Distillation For Vision-language Tasks", "topic_distr": {"0": 0.00096691440558061, "1": 0.0007895747548900545, "2": 0.3140413761138916, "3": 0.11897367984056473, "4": 0.0005098331021144986, "5": 0.00045600809971801937, "6": 0.0004124630941078067, "7": 0.0003765095607377589, "8": 0.06327195465564728, "9": 0.00032061501406133175, "10": 0.00029846103279851377, "11": 0.00027917083934880793, "12": 0.0002622227475512773, "13": 0.09264284372329712, "14": 0.00023383158259093761, "15": 0.00022182305110618472, "16": 0.000210987709579058, "17": 0.0002011615870287642, "18": 0.3098546862602234, "19": 0.09567592293024063}}, {"key": "wang2022code", "year": "2022", "title": "Code4struct: Code Generation For Few-shot Event Structure Prediction", "topic_distr": {"0": 0.00129979127086699, "1": 0.05613899230957031, "2": 0.18994776904582977, "3": 0.11251414567232132, "4": 0.0006851156358607113, "5": 0.0006127858068794012, "6": 0.18233175575733185, "7": 0.0005059554241597652, "8": 0.0004653885553125292, "9": 0.00043084402568638325, "10": 0.0004010734264738858, "11": 0.0003751511685550213, "12": 0.00035237622796557844, "13": 0.0003322083211969584, "14": 0.01777658984065056, "15": 0.0002980869321618229, "16": 0.14538145065307617, "17": 0.2190662920475006, "18": 0.07083693146705627, "19": 0.0002472884953022003}}, {"key": "wang2022complementary", "year": "2022", "title": "Dualprompt: Complementary Prompting For Rehearsal-free Continual Learning", "topic_distr": {"0": 0.0013698965776711702, "1": 0.001119135064072907, "2": 0.31020841002464294, "3": 0.0008194285910576582, "4": 0.0007227007881738245, "5": 0.000646401837002486, "6": 0.0005846759304404259, "7": 0.0005337109905667603, "8": 0.0004909186973236501, "9": 0.0004544791590888053, "10": 0.00042307539843022823, "11": 0.146453395485878, "12": 0.04958650469779968, "13": 0.07892362773418427, "14": 0.0003314616624265909, "15": 0.0003144392976537347, "16": 0.1769028902053833, "17": 0.22958150506019592, "18": 0.0002724620862863958, "19": 0.00026085416902787983}}, {"key": "wang2022enabling", "year": "2022", "title": "Enabling Conversational Interaction With Mobile UI Using Large Language Models", "topic_distr": {"0": 0.0015583694912493229, "1": 0.0012732625473290682, "2": 0.0010762192541733384, "3": 0.45317769050598145, "4": 0.14520393311977386, "5": 0.13907180726528168, "6": 0.04519600421190262, "7": 0.0006071164389140904, "8": 0.0005584385944530368, "9": 0.09396577626466751, "10": 0.0004812642582692206, "11": 0.05567891523241997, "12": 0.0004228305188007653, "13": 0.0003986302181147039, "14": 0.0003770501643884927, "15": 0.000357686571078375, "16": 0.00034021472674794495, "17": 0.05964815616607666, "18": 0.000309935916448012, "19": 0.00029673147946596146}}, {"key": "wang2022end", "year": "2022", "title": "End-to-end Transformer Based Model For Image Captioning", "topic_distr": {"0": 0.0009383991709910333, "1": 0.0007658362155780196, "2": 0.3239632248878479, "3": 0.0005606836639344692, "4": 0.016995079815387726, "5": 0.0004422932106535882, "6": 0.032276701182127, "7": 0.00036518575507216156, "8": 0.0003359056427143514, "9": 0.0003109722747467458, "10": 0.2078857570886612, "11": 0.000270774558885023, "12": 0.00025433622067794204, "13": 0.02393786609172821, "14": 0.00022679891844745725, "15": 0.00021515156549867243, "16": 0.00020464209956116974, "17": 0.00019511151185724884, "18": 0.3896768093109131, "19": 0.00017848654533736408}}, {"key": "wang2022exploring", "year": "2022", "title": "Exploring The Limits Of Domain-adaptive Training For Detoxifying Large-scale Language Models", "topic_distr": {"0": 0.11840921640396118, "1": 0.0010500624775886536, "2": 0.0008876240462996066, "3": 0.0007687810575589538, "4": 0.0006780317635275424, "5": 0.000606449437327683, "6": 0.0005485386354848742, "7": 0.0005007237195968628, "8": 0.0004605762951541692, "9": 0.0004263889859430492, "10": 0.0003969262179452926, "11": 0.00037127197720110416, "12": 0.00034873257391154766, "13": 0.3526498079299927, "14": 0.0003109748649876565, "15": 0.20805595815181732, "16": 0.0002805945696309209, "17": 0.16519653797149658, "18": 0.0002556219114921987, "19": 0.14779719710350037}}, {"key": "wang2022faithful", "year": "2022", "title": "PINTO: Faithful Language Reasoning Using Prompt-generated Rationales", "topic_distr": {"0": 0.0011242276523262262, "1": 0.0009178241016343236, "2": 0.15030892193317413, "3": 0.2295922040939331, "4": 0.0005925040459260345, "5": 0.0005299512995406985, "6": 0.00047934535541571677, "7": 0.12983080744743347, "8": 0.00040247870492748916, "9": 0.00037260379758663476, "10": 0.0003468575014267117, "11": 0.17505361139774323, "12": 0.0003047430654987693, "13": 0.032343678176403046, "14": 0.0002717481693252921, "15": 0.000257792416960001, "16": 0.06974386423826218, "17": 0.03477034345269203, "18": 0.00022337748669087887, "19": 0.17253313958644867}}, {"key": "wang2022foundation", "year": "2022", "title": "Omnivl:one Foundation Model For Image-language And Video-language Tasks", "topic_distr": {"0": 0.0012590845581144094, "1": 0.0010287929326295853, "2": 0.000869662209879607, "3": 0.0007532211020588875, "4": 0.0006643113447353244, "5": 0.0005941775161772966, "6": 0.0005374386091716588, "7": 0.000490591221023351, "8": 0.0004512562300078571, "9": 0.00041776071884669363, "10": 0.05325328931212425, "11": 0.03938066586852074, "12": 0.000341675739036873, "13": 0.04072476923465729, "14": 0.0003046820929739624, "15": 0.0002890350006055087, "16": 0.0002749165578279644, "17": 0.06003528833389282, "18": 0.6436160206794739, "19": 0.15471334755420685}}, {"key": "wang2022generative", "year": "2022", "title": "GIT: A Generative Image-to-text Transformer For Vision And Language", "topic_distr": {"0": 0.0016865043435245752, "1": 0.0013763322494924068, "2": 0.23912078142166138, "3": 0.001007630373351276, "4": 0.0008886857540346682, "5": 0.0007948642014525831, "6": 0.0007189612952060997, "7": 0.0006562909693457186, "8": 0.06289756298065186, "9": 0.000558861589524895, "10": 0.20387998223304749, "11": 0.0004866205854341388, "12": 0.0004570785094983876, "13": 0.04100283607840538, "14": 0.000407590065151453, "15": 0.09272807836532593, "16": 0.00036777107743546367, "17": 0.00035064324038103223, "18": 0.3502921164035797, "19": 0.00032076583011075854}}, {"key": "wang2022image", "year": "2022", "title": "Image As A Foreign Language: Beit Pretraining For All Vision And Vision-language Tasks", "topic_distr": {"0": 0.0016413955017924309, "1": 0.039477404206991196, "2": 0.0011329662520438433, "3": 0.0009812760399654508, "4": 0.0008654462289996445, "5": 0.0007740776636637747, "6": 0.0007001598714850843, "7": 0.0006391284405253828, "8": 0.0005878839874640107, "9": 0.0005442469264380634, "10": 0.20895591378211975, "11": 0.00047389508108608425, "12": 0.0004451255372259766, "13": 0.00041964920819737017, "14": 0.09091363847255707, "15": 0.00037654669722542167, "16": 0.043376628309488297, "17": 0.0003414736420381814, "18": 0.5094002485275269, "19": 0.09795289486646652}}, {"key": "wang2022iteratively", "year": "2022", "title": "Iteratively Prompt Pre-trained Language Models For Chain Of Thought", "topic_distr": {"0": 0.001559125492349267, "1": 0.0012729935115203261, "2": 0.09465387463569641, "3": 0.4895164370536804, "4": 0.0008220856543630362, "5": 0.0007352950051426888, "6": 0.0006650805589742959, "7": 0.0006071069510653615, "8": 0.06414014846086502, "9": 0.0005169791402295232, "10": 0.00048125674948096275, "11": 0.00045015205978415906, "12": 0.0004228239122312516, "13": 0.00039862398989498615, "14": 0.00037704425631091, "15": 0.0003576809831429273, "16": 0.11276937276124954, "17": 0.2296472191810608, "18": 0.0003099310852121562, "19": 0.00029672685195691884}}, {"key": "wang2022knowledge", "year": "2022", "title": "Knowledge Prompting In Pre-trained Language Model For Natural Language Understanding", "topic_distr": {"0": 0.0015211020363494754, "1": 0.0012419180711731315, "2": 0.0010500031057745218, "3": 0.0009094093111343682, "4": 0.02895543724298477, "5": 0.0007173852063715458, "6": 0.024454034864902496, "7": 0.016527563333511353, "8": 0.0005448279553093016, "9": 0.0005043868441134691, "10": 0.17383109033107758, "11": 0.00043918751180171967, "12": 0.00041252499795518816, "13": 0.0003889145446009934, "14": 0.00036786042619496584, "15": 0.0003489687805995345, "16": 0.3959488272666931, "17": 0.35124465823173523, "18": 0.00030238195904530585, "19": 0.00028949935222044587}}, {"key": "wang2022language", "year": "2022", "title": "Language Models With Image Descriptors Are Strong Few-shot Video-language Learners", "topic_distr": {"0": 0.0010400937171652913, "1": 0.0008489351603202522, "2": 0.0007175368955358863, "3": 0.0006214817985892296, "4": 0.00054811907466501, "5": 0.0004902523360215127, "6": 0.00044343722402118146, "7": 0.07236558198928833, "8": 0.04265235364437103, "9": 0.0003446917689871043, "10": 0.0003208741545677185, "11": 0.019771244376897812, "12": 0.0589708611369133, "13": 0.0002657794102560729, "14": 0.016210297122597694, "15": 0.00023848097771406174, "16": 0.00022683195129502565, "17": 0.2771144211292267, "18": 0.45355212688446045, "19": 0.05325660854578018}}, {"key": "wang2022mixture", "year": "2022", "title": "Adamix: Mixture-of-adaptations For Parameter-efficient Model Tuning", "topic_distr": {"0": 0.0014337998582050204, "1": 0.0011706763179972768, "2": 0.07690133154392242, "3": 0.0008572126971557736, "4": 0.062049515545368195, "5": 0.0006762109696865082, "6": 0.0006116385338827968, "7": 0.0005583233432844281, "8": 0.0005135576939210296, "9": 0.00047543770051561296, "10": 0.17260344326496124, "11": 0.00041398045141249895, "12": 0.041154488921165466, "13": 0.42384621500968933, "14": 0.019016116857528687, "15": 0.0003289398446213454, "16": 0.0003128721727989614, "17": 0.19651834666728973, "18": 0.0002850268210750073, "19": 0.00027288359706290066}}, {"key": "wang2022multi", "year": "2022", "title": "Instructionner: A Multi-task Instruction-based Generative Framework For Few-shot NER", "topic_distr": {"0": 0.0018608554964885116, "1": 0.001519920420832932, "2": 0.0012849632184952497, "3": 0.001112923608161509, "4": 0.000981552293524146, "5": 0.0008779255440458655, "6": 0.0007940909708850086, "7": 0.0007248718175105751, "8": 0.02042420394718647, "9": 0.0006172612775117159, "10": 0.10958990454673767, "11": 0.06403552740812302, "12": 0.0005048420862294734, "13": 0.0004759479488711804, "14": 0.0004501822404563427, "15": 0.08015800267457962, "16": 0.1468823254108429, "17": 0.5669803619384766, "18": 0.00037005063495598733, "19": 0.00035428506089374423}}, {"key": "wang2022no", "year": "2022", "title": "No More Fine-tuning? An Experimental Evaluation Of Prompt Tuning In Code Intelligence", "topic_distr": {"0": 0.022893037647008896, "1": 0.13235922157764435, "2": 0.0006833143415860832, "3": 0.000591837044339627, "4": 0.0005219751037657261, "5": 0.00046686833957210183, "6": 0.00042228633537888527, "7": 0.00038547656731680036, "8": 0.00035456952173262835, "9": 0.06662324070930481, "10": 0.12502892315387726, "11": 0.00028581960941664875, "12": 0.00026846787659451365, "13": 0.0002531023637857288, "14": 0.05933575704693794, "15": 0.00022710600751452148, "16": 0.017793875187635422, "17": 0.5711199045181274, "18": 0.0001967876887647435, "19": 0.00018840377742890269}}, {"key": "wang2022position", "year": "2022", "title": "Position-guided Text Prompt For Vision-language Pre-training", "topic_distr": {"0": 0.0010938819032162428, "1": 0.0008935522055253386, "2": 0.20116399228572845, "3": 0.0006541143520735204, "4": 0.0005768998526036739, "5": 0.0005159943830221891, "6": 0.0004667213070206344, "7": 0.0004260381974745542, "8": 0.0003918790025636554, "9": 0.0003627908881753683, "10": 0.16167052090168, "11": 0.0003158948675263673, "12": 0.0002967173350043595, "13": 0.00027973498799838126, "14": 0.000264591391896829, "15": 0.0002510031627025455, "16": 0.00023874246107880026, "17": 0.18180596828460693, "18": 0.44812270998954773, "19": 0.00020822850638069212}}, {"key": "wang2022prompt", "year": "2022", "title": "Promda: Prompt-based Data Augmentation For Low-resource NLU Tasks", "topic_distr": {"0": 0.028052154928445816, "1": 0.4073338806629181, "2": 0.14513038098812103, "3": 0.0010653197532519698, "4": 0.0009395679226145148, "5": 0.000840374210383743, "6": 0.0007601255783811212, "7": 0.0006938670412637293, "8": 0.0006382336723618209, "9": 0.0005908593302592635, "10": 0.2165430337190628, "11": 0.0005144821479916573, "12": 0.0004832486156374216, "13": 0.0004555903433356434, "14": 0.00043092670966871083, "15": 0.00040879627340473235, "16": 0.00038882787339389324, "17": 0.19403696060180664, "18": 0.00035422254586592317, "19": 0.00033913133665919304}}, {"key": "wang2022rationale", "year": "2022", "title": "Rationale-augmented Ensembles In Language Models", "topic_distr": {"0": 0.05774478241801262, "1": 0.0011318169999867678, "2": 0.0009566438966430724, "3": 0.2086125910282135, "4": 0.0007307520718313754, "5": 0.1165955662727356, "6": 0.0005911900661885738, "7": 0.09078115969896317, "8": 0.035485249012708664, "9": 0.0004595427308231592, "10": 0.00042778911301866174, "11": 0.17650844156742096, "12": 0.03084045648574829, "13": 0.0003543368657119572, "14": 0.00033515464747324586, "15": 0.0003179426130373031, "16": 0.0003024121397174895, "17": 0.2772848904132843, "18": 0.00027549773221835494, "19": 0.00026376047753728926}}, {"key": "wang2022self", "year": "2022", "title": "Self-consistency Improves Chain Of Thought Reasoning In Language Models", "topic_distr": {"0": 0.0018616029992699623, "1": 0.001520198886282742, "2": 0.0012851509964093566, "3": 0.8548940420150757, "4": 0.0009817015379667282, "5": 0.0008780595962889493, "6": 0.0007942123920656741, "7": 0.06828015297651291, "8": 0.029246361926198006, "9": 0.0006173556321300566, "10": 0.0005746973911300302, "11": 0.035690125077962875, "12": 0.0005049192695878446, "13": 0.0004760206793434918, "14": 0.0004502510419115424, "15": 0.00042712819413281977, "16": 0.00040626435657031834, "17": 0.0003873438108712435, "18": 0.00037010718369856477, "19": 0.0003543392231222242}}, {"key": "wang2022simple", "year": "2022", "title": "Lilt: A Simple Yet Effective Language-independent Layout Transformer For Structured Document Understanding", "topic_distr": {"0": 0.0017088111490011215, "1": 0.0013955864124000072, "2": 0.34945148229599, "3": 0.0010215775109827518, "4": 0.02592545934021473, "5": 0.000805865041911602, "6": 0.0007289118366315961, "7": 0.0006653741584159434, "8": 0.10689129680395126, "9": 0.0005665963399223983, "10": 0.23746439814567566, "11": 0.0004933555028401315, "12": 0.1552657037973404, "13": 0.00043688202276825905, "14": 0.00041323117329739034, "15": 0.00039200950413942337, "16": 0.11535309255123138, "17": 0.0003554962167982012, "18": 0.00033967680064961314, "19": 0.0003252052702009678}}, {"key": "wang2022super", "year": "2022", "title": "Super-naturalinstructions: Generalization Via Declarative Instructions On 1600+ NLP Tasks", "topic_distr": {"0": 0.0948045402765274, "1": 0.0011575795942917466, "2": 0.08617840707302094, "3": 0.04409152641892433, "4": 0.000747382699046284, "5": 0.000668478780426085, "6": 0.0006046447088010609, "7": 0.000551939127035439, "8": 0.00963241420686245, "9": 0.00047000122140161693, "10": 0.04519137740135193, "11": 0.2659004330635071, "12": 0.24179591238498688, "13": 0.08283475041389465, "14": 0.00034278223756700754, "15": 0.04085478559136391, "16": 0.0003092945844400674, "17": 0.08331220597028732, "18": 0.00028176762862131, "19": 0.0002697632589843124}}, {"key": "wang2022towards", "year": "2022", "title": "Towards Unified Conversational Recommender Systems Via Knowledge-enhanced Prompt Learning", "topic_distr": {"0": 0.0010396281722933054, "1": 0.0008488215389661491, "2": 0.0007174984202720225, "3": 0.0006214379682205617, "4": 0.40031567215919495, "5": 0.03218052536249161, "6": 0.09482192993164062, "7": 0.00040475704008713365, "8": 0.0003723041445482522, "9": 0.00034466900979168713, "10": 0.09187237173318863, "11": 0.059024978429079056, "12": 0.0002818959183059633, "13": 0.00026576186064630747, "14": 0.0002513747022021562, "15": 0.00023846524709369987, "16": 0.12713861465454102, "17": 0.18885479867458344, "18": 0.0002066304732579738, "19": 0.00019782723393291235}}, {"key": "wang2022unifying", "year": "2022", "title": "OFA: Unifying Architectures, Tasks, And Modalities Through A Simple Sequence-to-sequence Learning Framework", "topic_distr": {"0": 0.001619509537704289, "1": 0.0013227747986093163, "2": 0.18482305109500885, "3": 0.0009684332762844861, "4": 0.0008541152346879244, "5": 0.0007639431278221309, "6": 0.000690992979798466, "7": 0.0006307605654001236, "8": 0.0005801870138384402, "9": 0.0005371213192120194, "10": 0.0005000071250833571, "11": 0.000467690551886335, "12": 0.0004392976697999984, "13": 0.0004141548997722566, "14": 0.00039173438563011587, "15": 0.06792420148849487, "16": 0.00035346439108252525, "17": 0.18618439137935638, "18": 0.4262676239013672, "19": 0.12426648288965225}}, {"key": "wang2022use", "year": "2022", "title": "On The Use Of BERT For Automated Essay Scoring: Joint Learning Of Multi-scale Essay Representation", "topic_distr": {"0": 0.0017088358290493488, "1": 0.0013953081797808409, "2": 0.3341614007949829, "3": 0.0010215352522209287, "4": 0.1366937905550003, "5": 0.0008058315725065768, "6": 0.0007288815104402602, "7": 0.0006653465097770095, "8": 0.0006119998288340867, "9": 0.0005665727658197284, "10": 0.3371567726135254, "11": 0.0004933349555358291, "12": 0.040318381041288376, "13": 0.00043686386197805405, "14": 0.06663589179515839, "15": 0.0003919932059943676, "16": 0.0003728455922100693, "17": 0.0003554814320523292, "18": 0.00033966265618801117, "19": 0.07513931393623352}}, {"key": "wang2022what", "year": "2022", "title": "What Language Model Architecture And Pretraining Objective Work Best For Zero-shot Generalization?", "topic_distr": {"0": 0.0009825278539210558, "1": 0.0008019420201890171, "2": 0.0006779376417398453, "3": 0.0005871806642971933, "4": 0.0005178659339435399, "5": 0.00046319302055053413, "6": 0.0004189620085526258, "7": 0.04633532837033272, "8": 0.00035177828976884484, "9": 0.00032566674053668976, "10": 0.2747837007045746, "11": 0.0002835695631802082, "12": 0.000266354443738237, "13": 0.11448446661233902, "14": 0.0002375159237999469, "15": 0.00022531818831339478, "16": 0.00021431210916489363, "17": 0.1967974305152893, "18": 0.00019523852097336203, "19": 0.36104971170425415}}, {"key": "wang2023aligning", "year": "2023", "title": "Aligning Large Language Models With Human: A Survey", "topic_distr": {"0": 0.21357357501983643, "1": 0.06943414360284805, "2": 0.0006832910585217178, "3": 0.23828987777233124, "4": 0.08095753937959671, "5": 0.00046684968401677907, "6": 0.00042226945515722036, "7": 0.0003854611422866583, "8": 0.0003545553772710264, "9": 0.00032823768560774624, "10": 0.00030555701232515275, "11": 0.00028580817161127925, "12": 0.39298614859580994, "13": 0.0002530922647565603, "14": 0.00023939096718095243, "15": 0.0002270969416713342, "16": 0.00021600397303700447, "17": 0.00020594423403963447, "18": 0.00019677981617860496, "19": 0.00018839625408872962}}, {"key": "wang2023caption", "year": "2023", "title": "Caption Anything: Interactive Image Description With Diverse Multimodal Controls", "topic_distr": {"0": 0.0011558374390006065, "1": 0.1676226705312729, "2": 0.000797234708443284, "3": 0.0006905136397108436, "4": 0.06181703880429268, "5": 0.0005447085131891072, "6": 0.0004926933906972408, "7": 0.17732299864292145, "8": 0.0004136862698942423, "9": 0.06914424896240234, "10": 0.00035651621874421835, "11": 0.00033347378484904766, "12": 0.00031322904396802187, "13": 0.00029530166648328304, "14": 0.0002793153398670256, "15": 0.0002649709931574762, "16": 0.0002520279958844185, "17": 0.03689241036772728, "18": 0.4807913303375244, "19": 0.00021981599275022745}}, {"key": "wang2023document", "year": "2023", "title": "Document-level Machine Translation With Large Language Models", "topic_distr": {"0": 0.09452805668115616, "1": 0.0685744509100914, "2": 0.0007115541375242174, "3": 0.2918075919151306, "4": 0.000543541566003114, "5": 0.00048615760169923306, "6": 0.0004397336451802403, "7": 0.03311106190085411, "8": 0.0003692190221045166, "9": 0.13343018293380737, "10": 0.00031819421565160155, "11": 0.00029762860503979027, "12": 0.11963765323162079, "13": 0.00026355963200330734, "14": 0.1610606610774994, "15": 0.00023648918431717902, "16": 0.03850318491458893, "17": 0.020128194242715836, "18": 0.000204918222152628, "19": 0.03534796088933945}}, {"key": "wang2023element", "year": "2023", "title": "Element-aware Summarization With Large Language Models: Expert-aligned Evaluation And Chain-of-thought Method", "topic_distr": {"0": 0.1982138305902481, "1": 0.0009608356631360948, "2": 0.0008122518192976713, "3": 0.2316766381263733, "4": 0.000620463804807514, "5": 0.0005549578345380723, "6": 0.057411905378103256, "7": 0.2080632448196411, "8": 0.061863068491220474, "9": 0.00039018571260385215, "10": 0.00036322453524917364, "11": 0.00033974851248785853, "12": 0.05196954682469368, "13": 0.00030085816979408264, "14": 0.0002845710259862244, "15": 0.18521520495414734, "16": 0.0002567702322266996, "17": 0.000244811933953315, "18": 0.00023391791910398751, "19": 0.00022395212727133185}}, {"key": "wang2023emotional", "year": "2023", "title": "Emotional Intelligence Of Large Language Models", "topic_distr": {"0": 0.24523232877254486, "1": 0.04771250858902931, "2": 0.0007175430655479431, "3": 0.3246004581451416, "4": 0.0005481003317981958, "5": 0.0004902348737232387, "6": 0.00044342162436805665, "7": 0.00040476949652656913, "8": 0.0003723156114574522, "9": 0.21468621492385864, "10": 0.00032086283317767084, "11": 0.00030012475326657295, "12": 0.05862577259540558, "13": 0.0002657700388226658, "14": 0.0002513824438210577, "15": 0.034130316227674484, "16": 0.037805140018463135, "17": 0.00021626031957566738, "18": 0.03267862647771835, "19": 0.0001978333166334778}}, {"key": "wang2023evaluation", "year": "2023", "title": "Evaluation And Analysis Of Hallucination In Large Vision-language Models", "topic_distr": {"0": 0.33163097500801086, "1": 0.10207851231098175, "2": 0.0010372577235102654, "3": 0.18899670243263245, "4": 0.0007923442753963172, "5": 0.0007086929399520159, "6": 0.0006410187925212085, "7": 0.0005851425812579691, "8": 0.0005382265662774444, "9": 0.12247522920370102, "10": 0.0004638454702217132, "11": 0.00043386610923334956, "12": 0.00040752667700871825, "13": 0.08574852347373962, "14": 0.0003634032909758389, "15": 0.08004659414291382, "16": 0.00032790107070468366, "17": 0.00031263005803339183, "18": 0.08212564885616302, "19": 0.0002859916421584785}}, {"key": "wang2023generative", "year": "2023", "title": "Generative Recommendation: Towards Next-generation Recommender Paradigm", "topic_distr": {"0": 0.0008660817402414978, "1": 0.03443409129977226, "2": 0.0005978865083307028, "3": 0.0005178594146855175, "4": 0.3598765432834625, "5": 0.023348644375801086, "6": 0.0003695017658174038, "7": 0.09127884358167648, "8": 0.00031024933559820056, "9": 0.30763694643974304, "10": 0.00026737392181530595, "11": 0.05766148865222931, "12": 0.00023491015599574894, "13": 0.00022146529227029532, "14": 0.0002094761439366266, "15": 0.1214623674750328, "16": 0.00018901164003182203, "17": 0.00018020899733528495, "18": 0.00017218978609889746, "19": 0.0001648538454901427}}, {"key": "wang2023how", "year": "2023", "title": "How Far Can Camels Go? Exploring The State Of Instruction Tuning On Open Resources", "topic_distr": {"0": 0.0009759410168044269, "1": 0.027942180633544922, "2": 0.0006726713036186993, "3": 0.542294979095459, "4": 0.0005138331325724721, "5": 0.00045958603732287884, "6": 0.0004156992072239518, "7": 0.00037946359952911735, "8": 0.0003490386880002916, "9": 0.0003231304872315377, "10": 0.00030080272699706256, "11": 0.00028136116452515125, "12": 0.2866472005844116, "13": 0.014648187905550003, "14": 0.0002356661861995235, "15": 0.00022356344561558217, "16": 0.03590910881757736, "17": 0.00020273987320251763, "18": 0.00019371803500689566, "19": 0.08703115582466125}}, {"key": "wang2023improving", "year": "2023", "title": "Improving Text Embeddings With Large Language Models", "topic_distr": {"0": 0.0014665116323158145, "1": 0.27130335569381714, "2": 0.26109540462493896, "3": 0.1954513043165207, "4": 0.0007737113046459854, "5": 0.0006920277373865247, "6": 0.0006259449291974306, "7": 0.10893211513757706, "8": 0.00052556989248842, "9": 0.0004865582741331309, "10": 0.09842202067375183, "11": 0.0004236635286360979, "12": 0.0003979434841312468, "13": 0.0575159415602684, "14": 0.00035485767875798047, "15": 0.00033663379144854844, "16": 0.00032019030186347663, "17": 0.00030527840135619044, "18": 0.00029169366462156177, "19": 0.00027926641632802784}}, {"key": "wang2023is", "year": "2023", "title": "Is Chatgpt A Good Sentiment Analyzer? A Preliminary Study", "topic_distr": {"0": 0.0014858737122267485, "1": 0.2648409307003021, "2": 0.0010248812614008784, "3": 0.15331697463989258, "4": 0.0007829003734514117, "5": 0.12346156686544418, "6": 0.0006333786295726895, "7": 0.000578168430365622, "8": 0.000531811616383493, "9": 0.1402938961982727, "10": 0.07280221581459045, "11": 0.00042869499884545803, "12": 0.2375287264585495, "13": 0.00037962308852002025, "14": 0.0003590720007196069, "15": 0.0003406316973268986, "16": 0.0003239929210394621, "17": 0.0003089039237238467, "18": 0.00029515783535316586, "19": 0.00028258300153538585}}, {"key": "wang2023large", "year": "2023", "title": "Recmind: Large Language Model Powered Agent For Recommendation", "topic_distr": {"0": 0.0013850555988028646, "1": 0.0011317600728943944, "2": 0.0009565887157805264, "3": 0.3216606676578522, "4": 0.2631320655345917, "5": 0.0006535769789479673, "6": 0.000591165735386312, "7": 0.0005396350752562284, "8": 0.0004963678075000644, "9": 0.0004595237842295319, "10": 0.00042777147609740496, "11": 0.19072243571281433, "12": 0.0003758326929528266, "13": 0.03378422558307648, "14": 0.0003351408231537789, "15": 0.00031792951631359756, "16": 0.18220268189907074, "17": 0.0002883163106162101, "18": 0.0002754863817244768, "19": 0.0002637496218085289}}, {"key": "wang2023multitask", "year": "2023", "title": "Multitask Prompt Tuning Enables Parameter-efficient Transfer Learning", "topic_distr": {"0": 0.0015028439229354262, "1": 0.0012271224986761808, "2": 0.13249941170215607, "3": 0.0008985327440313995, "4": 0.0007924663368612528, "5": 0.0007088028360158205, "6": 0.0006411182112060487, "7": 0.0005852333270013332, "8": 0.0005383100942708552, "9": 0.0004983527469448745, "10": 0.0004639174439944327, "11": 0.000433933426393196, "12": 0.0004075898905284703, "13": 0.06727888435125351, "14": 0.0003634596650954336, "15": 0.0003447940107434988, "16": 0.07443602383136749, "17": 0.6802434921264648, "18": 0.0358496829867363, "19": 0.00028603599639609456}}, {"key": "wang2023one", "year": "2023", "title": "One Adapter For All Programming Languages? Adapter Tuning For Code Search And Summarization", "topic_distr": {"0": 0.0015795943327248096, "1": 0.0012892327504232526, "2": 0.07915771752595901, "3": 0.0009439043351449072, "4": 0.0008324839291162789, "5": 0.0007445954834111035, "6": 0.24795590341091156, "7": 0.04545754939317703, "8": 0.0005654931883327663, "9": 0.01487438753247261, "10": 0.00048734393203631043, "11": 0.0004558458167593926, "12": 0.0004281720030121505, "13": 0.21918603777885437, "14": 0.12066256999969482, "15": 0.00036220511537976563, "16": 0.14193038642406464, "17": 0.09021199494600296, "18": 0.0003138512547593564, "19": 0.032560691237449646}}, {"key": "wang2023open", "year": "2023", "title": "Voyager: An Open-ended Embodied Agent With Large Language Models", "topic_distr": {"0": 0.01776130683720112, "1": 0.0010834259446710348, "2": 0.0009159940527752042, "3": 0.3664883077144623, "4": 0.023910164833068848, "5": 0.0006258427747525275, "6": 0.0005660800961777568, "7": 0.0005167361232452095, "8": 0.016050510108470917, "9": 0.0004400242760311812, "10": 0.05942574888467789, "11": 0.37777188420295715, "12": 0.00035988452145829797, "13": 0.026984356343746185, "14": 0.00032091938192024827, "15": 0.00030443843570537865, "16": 0.10568199306726456, "17": 0.0002760818460956216, "18": 0.00026379633345641196, "19": 0.00025255759828723967}}, {"key": "wang2023plan", "year": "2023", "title": "Describe, Explain, Plan And Select: Interactive Planning With Large Language Models Enables Open-world Multi-task Agents", "topic_distr": {"0": 0.001124110771343112, "1": 0.0009175215382128954, "2": 0.0007756921695545316, "3": 0.5097010135650635, "4": 0.0005925411242060363, "5": 0.029288960620760918, "6": 0.06356889754533768, "7": 0.0004375888383947313, "8": 0.00040250353049486876, "9": 0.0003726267896126956, "10": 0.0003468788927420974, "11": 0.3468377888202667, "12": 0.0003047618374694139, "13": 0.0002873190969694406, "14": 0.00027176490402780473, "15": 0.00025780830765143037, "16": 0.043841201812028885, "17": 0.00023379502817988396, "18": 0.00022339126735460013, "19": 0.0002138739509973675}}, {"key": "wang2023pre", "year": "2023", "title": "Missrec: Pre-training And Transferring Multi-modal Interest-aware Sequence Representation For Recommendation", "topic_distr": {"0": 0.001248319516889751, "1": 0.0010187808657065034, "2": 0.0008610089425928891, "3": 0.0007457260508090258, "4": 0.3977622389793396, "5": 0.0005882629775442183, "6": 0.000532088743057102, "7": 0.00048570771468803287, "8": 0.0004467642866075039, "9": 0.07086794078350067, "10": 0.24863621592521667, "11": 0.00036013807402923703, "12": 0.0003382745780982077, "13": 0.0003189137496519834, "14": 0.0003016491828020662, "15": 0.0002861578541342169, "16": 0.08400028198957443, "17": 0.19071617722511292, "18": 0.00024795616627670825, "19": 0.00023739230528008193}}, {"key": "wang2023prompting", "year": "2023", "title": "Prompting Large Language Models For Topic Modeling", "topic_distr": {"0": 0.0014350276906043291, "1": 0.0011710250983014703, "2": 0.0009896180126816034, "3": 0.23414237797260284, "4": 0.0007559588411822915, "5": 0.0006761482800357044, "6": 0.000611581897828728, "7": 0.35448554158210754, "8": 0.025226809084415436, "9": 0.00047539363731630147, "10": 0.00044254472595639527, "11": 0.000413942092563957, "12": 0.09236221760511398, "13": 0.0003665589028969407, "14": 0.00034671503817662597, "15": 0.12152551859617233, "16": 0.09064541012048721, "17": 0.07336969673633575, "18": 0.0002850003947969526, "19": 0.00027285830583423376}}, {"key": "wang2023query", "year": "2023", "title": "Query2doc: Query Expansion With Large Language Models", "topic_distr": {"0": 0.02993607334792614, "1": 0.0017867216374725103, "2": 0.15599846839904785, "3": 0.24678954482078552, "4": 0.0011537563987076283, "5": 0.0010319495340809226, "6": 0.0009334071073681116, "7": 0.13965590298175812, "8": 0.2932761609554291, "9": 0.0007255541859194636, "10": 0.0006754196365363896, "11": 0.0006317657534964383, "12": 0.0005934120854362845, "13": 0.0005594487302005291, "14": 0.000529162643942982, "15": 0.0005019872332923114, "16": 0.000477466790471226, "17": 0.0004552302125375718, "18": 0.00043497266597114503, "19": 0.12385360151529312}}, {"key": "wang2023radiology", "year": "2023", "title": "R2gengpt: Radiology Report Generation With Frozen Llms", "topic_distr": {"0": 0.0012352225603535771, "1": 0.0010083237430080771, "2": 0.06227007135748863, "3": 0.2932811379432678, "4": 0.0006512035615742207, "5": 0.0005824534455314279, "6": 0.0005268340464681387, "7": 0.0004809110832866281, "8": 0.00044235223322175443, "9": 0.00040951764094643295, "10": 0.0003812206559814513, "11": 0.0003565814986359328, "12": 0.000334933924023062, "13": 0.24991768598556519, "14": 0.00029867023113183677, "15": 0.038326483219861984, "16": 0.00026949201128445566, "17": 0.05552605167031288, "18": 0.293465793132782, "19": 0.00023504793352913111}}, {"key": "wang2023rethinking", "year": "2023", "title": "Rethinking The Evaluation For Conversational Recommendation In The Era Of Large Language Models", "topic_distr": {"0": 0.044053737074136734, "1": 0.06915298849344254, "2": 0.0008524671429768205, "3": 0.23281919956207275, "4": 0.27681249380111694, "5": 0.06223370507359505, "6": 0.11713498830795288, "7": 0.0004809087549801916, "8": 0.0004423501086421311, "9": 0.11858183145523071, "10": 0.00038121879333630204, "11": 0.00035657978150993586, "12": 0.0747927650809288, "13": 0.0003157627652399242, "14": 0.00029866877594031394, "15": 0.0002833305043168366, "16": 0.00026949073071591556, "17": 0.0002569399948697537, "18": 0.00024550629314035177, "19": 0.0002350467984797433}}, {"key": "wang2023robustness", "year": "2023", "title": "On The Robustness Of Chatgpt: An Adversarial And Out-of-distribution Perspective", "topic_distr": {"0": 0.07923762500286102, "1": 0.24354183673858643, "2": 0.11608466506004333, "3": 0.0007767581846565008, "4": 0.000685068138409406, "5": 0.0006127427914179862, "6": 0.0005542311118915677, "7": 0.0005059199756942689, "8": 0.01252402737736702, "9": 0.23692509531974792, "10": 0.00040104531217366457, "11": 0.0003751248586922884, "12": 0.29004913568496704, "13": 0.00033218503813259304, "14": 0.01603708043694496, "15": 0.000298066035611555, "16": 0.00028350643697194755, "17": 0.00027030298952013254, "18": 0.0002582746383268386, "19": 0.0002472711494192481}}, {"key": "wang2023unleashing", "year": "2023", "title": "Unleashing The Emergent Cognitive Synergy In Large Language Models: A Task-solving Agent Through Multi-persona Self-collaboration", "topic_distr": {"0": 0.3750098943710327, "1": 0.0009609205881133676, "2": 0.10808272659778595, "3": 0.4391612112522125, "4": 0.0006204555975273252, "5": 0.00055495131528005, "6": 0.0005019581876695156, "7": 0.00045820357627235353, "8": 0.0004214654036331922, "9": 0.0003901811724063009, "10": 0.00036322028608992696, "11": 0.048241011798381805, "12": 0.00031911913538351655, "13": 0.0003008546482305974, "14": 0.00028456770814955235, "15": 0.00026995359803549945, "16": 0.023356657475233078, "17": 0.00024480908177793026, "18": 0.00023391518334392458, "19": 0.00022394950792659074}}, {"key": "wang2023zero", "year": "2023", "title": "Zero-shot Next-item Recommendation Using Large Pretrained Language Models", "topic_distr": {"0": 0.0010845977813005447, "1": 0.0008856897475197911, "2": 0.0007486491813324392, "3": 0.5024598240852356, "4": 0.33632248640060425, "5": 0.0005114988307468593, "6": 0.00046265500714071095, "7": 0.0004223263531457633, "8": 0.00038846477400511503, "9": 0.0003596300957724452, "10": 0.00033478025579825044, "11": 0.0003131426637992263, "12": 0.07199715077877045, "13": 0.048865724354982376, "14": 0.00026228613569401205, "15": 0.000248816329985857, "16": 0.00023666243941988796, "17": 0.00022564060054719448, "18": 0.00021559969172812998, "19": 0.033654361963272095}}, {"key": "wang2024fostering", "year": "2024", "title": "Farsight: Fostering Responsible AI Awareness During AI Application Prototyping", "topic_distr": {"0": 0.16186705231666565, "1": 0.0010390336392447352, "2": 0.0008784756646491587, "3": 0.0007608875748701394, "4": 0.0006710716406814754, "5": 0.0006002229638397694, "6": 0.0005429067532531917, "7": 0.0004955827025696635, "8": 0.00045584753388538957, "9": 0.7214426398277283, "10": 0.00039285095408558846, "11": 0.00036746010300703347, "12": 0.04254051297903061, "13": 0.0003253976465202868, "14": 0.0003077820874750614, "15": 0.018426185473799706, "16": 0.00027771369786933064, "17": 0.04811318963766098, "18": 0.0002529974444769323, "19": 0.00024221878265962005}}, {"key": "wang2024searching", "year": "2024", "title": "Searching For Best Practices In Retrieval-augmented Generation", "topic_distr": {"0": 0.0753646269440651, "1": 0.0012272364692762494, "2": 0.0010373147670179605, "3": 0.3211449384689331, "4": 0.0007923921220935881, "5": 0.00070873589720577, "6": 0.04558244347572327, "7": 0.11762003600597382, "8": 0.08367303013801575, "9": 0.0004983056569471955, "10": 0.0004638735845219344, "11": 0.000433892389992252, "12": 0.000407551386160776, "13": 0.1465775966644287, "14": 0.0003634252934716642, "15": 0.00034476141445338726, "16": 0.07187917083501816, "17": 0.00031264900462701917, "18": 0.1312820017337799, "19": 0.00028600895893760026}}, {"key": "warstadt2025findings", "year": "2025", "title": "Findings Of The Babylm Challenge: Sample-efficient Pretraining On Developmentally Plausible Corpora", "topic_distr": {"0": 0.1273307502269745, "1": 0.09286447614431381, "2": 0.3179931342601776, "3": 0.0008984892047010362, "4": 0.020845657214522362, "5": 0.0007087692501954734, "6": 0.0006410878268070519, "7": 0.0005852055619470775, "8": 0.0005382845411077142, "9": 0.0004983291146345437, "10": 0.06607706099748611, "11": 0.0004339128208812326, "12": 0.14439070224761963, "13": 0.13182519376277924, "14": 0.00036344240652397275, "15": 0.0003447776543907821, "16": 0.0003279363736510277, "17": 0.0003126637311652303, "18": 0.0002987503248732537, "19": 0.0927213579416275}}, {"key": "webb2022emergent", "year": "2022", "title": "Emergent Analogical Reasoning In Large Language Models", "topic_distr": {"0": 0.3178088068962097, "1": 0.0013765348121523857, "2": 0.0011634993134066463, "3": 0.4647292494773865, "4": 0.0008887887233868241, "5": 0.0007949531427584589, "6": 0.0007190417964011431, "7": 0.0006563644856214523, "8": 0.0006037380080670118, "9": 0.0005589241627603769, "10": 0.0005203034379519522, "11": 0.022096926346421242, "12": 0.00045712970313616097, "13": 0.05117759481072426, "14": 0.00040763572906143963, "15": 0.000386701402021572, "16": 0.00036781225935555995, "17": 0.0003506825305521488, "18": 0.0003350773185957223, "19": 0.1346002221107483}}, {"key": "webersinke2021pretrained", "year": "2021", "title": "Climatebert: A Pretrained Language Model For Climate-related Text", "topic_distr": {"0": 0.06259312480688095, "1": 0.23776742815971375, "2": 0.00116357475053519, "3": 0.0010077842744067311, "4": 0.0008888232987374067, "5": 0.0007949875434860587, "6": 0.0007190729374997318, "7": 0.02560601383447647, "8": 0.0006037640850991011, "9": 0.000558948318939656, "10": 0.09235519915819168, "11": 0.000486696109874174, "12": 0.2234705090522766, "13": 0.00043098494643345475, "14": 0.00040765333687886596, "15": 0.1493615210056305, "16": 0.0003678281500469893, "17": 0.0003506976645439863, "18": 0.0003350917831994593, "19": 0.2007303237915039}}, {"key": "webson2021do", "year": "2021", "title": "Do Prompt-based Models Really Understand The Meaning Of Their Prompts?", "topic_distr": {"0": 0.2526962459087372, "1": 0.0848354920744896, "2": 0.1280091553926468, "3": 0.000943933438975364, "4": 0.0008325061644427478, "5": 0.0007446156814694405, "6": 0.0006735110655426979, "7": 0.0445544607937336, "8": 0.0005655084969475865, "9": 0.0005235323333181441, "10": 0.00048735711607150733, "11": 0.1287379115819931, "12": 0.0004281835863366723, "13": 0.06547844409942627, "14": 0.00038182365824468434, "15": 0.00036221492337062955, "16": 0.0003445218608248979, "17": 0.28878626227378845, "18": 0.00031385975307784975, "19": 0.00030048811458982527}}, {"key": "webster2020measuring", "year": "2020", "title": "Measuring And Reducing Gendered Correlations In Pre-trained Models", "topic_distr": {"0": 0.40364694595336914, "1": 0.13829177618026733, "2": 0.001565504469908774, "3": 0.1256566345691681, "4": 0.08792398869991302, "5": 0.0010696016252040863, "6": 0.0009674635948613286, "7": 0.0008831318700686097, "8": 0.0008123234729282558, "9": 0.18559981882572174, "10": 0.0007000631303526461, "11": 0.0006548165110871196, "12": 0.0006150634726509452, "13": 0.000579860876314342, "14": 0.0005484697758220136, "15": 0.0005203028558753431, "16": 0.0004948877613060176, "17": 0.0004718398267868906, "18": 0.0004508431884460151, "19": 0.0485466793179512}}, {"key": "wei2020learning", "year": "2020", "title": "On Learning Universal Representations Across Languages", "topic_distr": {"0": 0.0017560456180945039, "1": 0.0014343829825520515, "2": 0.26111331582069397, "3": 0.0010502833174541593, "4": 0.0009262998937629163, "5": 0.0008285064832307398, "6": 0.06897880882024765, "7": 0.050227001309394836, "8": 0.0006292206235229969, "9": 0.000582515262067318, "10": 0.3972182273864746, "11": 0.0005072166677564383, "12": 0.00047642423305660486, "13": 0.0004491565632633865, "14": 0.21198713779449463, "15": 0.00040302329580299556, "16": 0.0003833369119092822, "17": 0.000365484127542004, "18": 0.00034922026679851115, "19": 0.0003343421558383852}}, {"key": "wei2021emotion", "year": "2021", "title": "Emotion-aware Chat Machine: Automatic Emotional Response Generation For Human-like Emotional Interaction", "topic_distr": {"0": 0.0021872182842344046, "1": 0.0017871251329779625, "2": 0.0015104669146239758, "3": 0.001308234641328454, "4": 0.19204580783843994, "5": 0.05679016932845116, "6": 0.4456371068954468, "7": 0.000852085358928889, "8": 0.0007837662124074996, "9": 0.26336947083473206, "10": 0.02912839688360691, "11": 0.0006317963707260787, "12": 0.0005934408982284367, "13": 0.0005594758549705148, "14": 0.0005291883135214448, "15": 0.0005020116223022342, "16": 0.00047748995712026954, "17": 0.00045525230234488845, "18": 0.00043499376624822617, "19": 0.0004164614074397832}}, {"key": "wei2021finetuned", "year": "2021", "title": "Finetuned Language Models Are Zero-shot Learners", "topic_distr": {"0": 0.002151052001863718, "1": 0.0017559875268489122, "2": 0.0014843306271359324, "3": 0.33669352531433105, "4": 0.00113385240547359, "5": 0.0010141478851437569, "6": 0.0009173052967526019, "7": 0.0008373457822017372, "8": 0.0007702084840275347, "9": 0.0007130379672162235, "10": 0.0006637682672590017, "11": 0.2210685759782791, "12": 0.0005831753951497376, "13": 0.0005497979000210762, "14": 0.0005200342857278883, "15": 0.0004933277377858758, "16": 0.0004692302318289876, "17": 0.3247568607330322, "18": 0.00042746917461045086, "19": 0.10299701243638992}}, {"key": "wei2021why", "year": "2021", "title": "Why Do Pretrained Language Models Help In Downstream Tasks? An Analysis Of Head And Prompt Tuning", "topic_distr": {"0": 0.0014187395572662354, "1": 0.0011574982199817896, "2": 0.4866802394390106, "3": 0.0008473880006931722, "4": 0.000747361802496016, "5": 0.0006684601539745927, "6": 0.0006046278867870569, "7": 0.0005519237602129579, "8": 0.0005076712695881724, "9": 0.0004699881828855723, "10": 0.00043751279008574784, "11": 0.0004092353628948331, "12": 0.00038439122727140784, "13": 0.00036239097244106233, "14": 0.0003427727206144482, "15": 0.04893814027309418, "16": 0.0003092859988100827, "17": 0.3418012261390686, "18": 0.0002817598287947476, "19": 0.11307937651872635}}, {"key": "wei2022chain", "year": "2022", "title": "Chain-of-thought Prompting Elicits Reasoning In Large Language Models", "topic_distr": {"0": 0.0017311966512352228, "1": 0.0014142753789201379, "2": 0.001195750548504293, "3": 0.9696955680847168, "4": 0.0009133591665886343, "5": 0.0008169332868419588, "6": 0.0007389227976091206, "7": 0.0006745125283487141, "8": 0.0006204309756867588, "9": 0.0005743780639022589, "10": 0.0005346895195543766, "11": 0.0005001313402317464, "12": 0.0004697690310422331, "13": 0.000442882243078202, "14": 0.0004189065657556057, "15": 0.00039739342173561454, "16": 0.0003779820108320564, "17": 0.0003603786462917924, "18": 0.0003443419700488448, "19": 0.0177781879901886}}, {"key": "wei2022emergent", "year": "2022", "title": "Emergent Abilities Of Large Language Models", "topic_distr": {"0": 0.12856638431549072, "1": 0.002314718207344413, "2": 0.0019566845148801804, "3": 0.2821879982948303, "4": 0.0014946978772059083, "5": 0.00133689702488482, "6": 0.001209234818816185, "7": 0.001103828428313136, "8": 0.0010153248440474272, "9": 0.0009399600676260889, "10": 0.0008750103879719973, "11": 0.0008184565231204033, "12": 0.0007687691249884665, "13": 0.44490477442741394, "14": 0.00068553356686607, "15": 0.0006503277109004557, "16": 0.0006185612292028964, "17": 0.0005897536175325513, "18": 0.0005635098787024617, "19": 0.12739957869052887}}, {"key": "wei2022multimodality", "year": "2022", "title": "MVP: Multimodality-guided Visual Pre-training", "topic_distr": {"0": 0.0019178191432729363, "1": 0.0015667857369408011, "2": 0.16366177797317505, "3": 0.0011472059413790703, "4": 0.0010117841884493828, "5": 0.0009049666114151478, "6": 0.0008185499464161694, "7": 0.0007471987046301365, "8": 0.000687289284542203, "9": 0.0006362736457958817, "10": 0.0851910412311554, "11": 0.0005540259880945086, "12": 0.11868160218000412, "13": 0.0004906076937913895, "14": 0.00046404838212765753, "15": 0.00044021697249263525, "16": 0.02569829672574997, "17": 0.0003992134297732264, "18": 0.5064647197723389, "19": 0.08851655572652817}}, {"key": "wei2023copiloting", "year": "2023", "title": "Copiloting The Copilots: Fusing Large Language Models With Completion Engines For Automated Program Repair", "topic_distr": {"0": 0.0011767481919378042, "1": 0.0009607789688743651, "2": 0.000812188838608563, "3": 0.5428963899612427, "4": 0.0006204301025718451, "5": 0.0005549277411773801, "6": 0.14006708562374115, "7": 0.1907883733510971, "8": 0.0004214475047774613, "9": 0.07804928719997406, "10": 0.0003632048610597849, "11": 0.00033973014797084033, "12": 0.0003191055729985237, "13": 0.00030084187164902687, "14": 0.0002845556300599128, "15": 0.0002699421311262995, "16": 0.0410723052918911, "17": 0.0002447986917104572, "18": 0.0002339052443858236, "19": 0.00022394000552594662}}, {"key": "wei2023evaluation", "year": "2023", "title": "Evaluation Of Chatgpt-generated Medical Responses: A Systematic Review And Meta-analysis", "topic_distr": {"0": 0.16477598249912262, "1": 0.07066062092781067, "2": 0.0009359466494061053, "3": 0.11278943717479706, "4": 0.000714967492967844, "5": 0.000639484147541225, "6": 0.0005784188979305327, "7": 0.0005279993638396263, "8": 0.0393565408885479, "9": 0.2582572102546692, "10": 0.0004185477737337351, "11": 0.00039149608346633613, "12": 0.3478620648384094, "13": 0.0003466822672635317, "14": 0.00032791445846669376, "15": 0.0003110742545686662, "16": 0.0002958792611025274, "17": 0.0002820995869114995, "18": 0.00026954628992825747, "19": 0.00025806258781813085}}, {"key": "wei2023how", "year": "2023", "title": "Jailbroken: How Does LLM Safety Training Fail?", "topic_distr": {"0": 0.2798958122730255, "1": 0.22495950758457184, "2": 0.0534171536564827, "3": 0.19807294011116028, "4": 0.0007389970123767853, "5": 0.0006609777919948101, "6": 0.0005978599074296653, "7": 0.0005457457737065852, "8": 0.0005019886302761734, "9": 0.030279148370027542, "10": 0.0004326154594309628, "11": 0.08376944065093994, "12": 0.00038008851697668433, "13": 0.0003583345387596637, "14": 0.00033893590443767607, "15": 0.000321529689244926, "16": 0.0003058239817619324, "17": 0.12387772649526596, "18": 0.00027860593399964273, "19": 0.0002667362568899989}}, {"key": "wei2023large", "year": "2023", "title": "Llmrec: Large Language Models With Graph Augmentation For Recommendation", "topic_distr": {"0": 0.0008378688362427056, "1": 0.12723717093467712, "2": 0.10314474999904633, "3": 0.09387053549289703, "4": 0.25219616293907166, "5": 0.00039480897248722613, "6": 0.00035710801603272557, "7": 0.01620767079293728, "8": 0.0002998430572915822, "9": 0.1290374994277954, "10": 0.0002584057510830462, "11": 0.00024170441611204296, "12": 0.0002270308614242822, "13": 0.05229150503873825, "14": 0.00020244995539542288, "15": 0.0001920530485222116, "16": 0.22250346839427948, "17": 0.00017416448099538684, "18": 0.00016641423280816525, "19": 0.00015932436508592218}}, {"key": "wei2023larger", "year": "2023", "title": "Larger Language Models Do In-context Learning Differently", "topic_distr": {"0": 0.0015415409579873085, "1": 0.0012574464781209826, "2": 0.16625910997390747, "3": 0.2805744707584381, "4": 0.0008119483245536685, "5": 0.0007262283470481634, "6": 0.0006568796816281974, "7": 0.0005996208637952805, "8": 0.0005515440716408193, "9": 0.000510604411829263, "10": 0.0004753225075546652, "11": 0.0004446013772394508, "12": 0.00041761022293940187, "13": 0.05545893311500549, "14": 0.00037239506491459906, "15": 0.00035327053046785295, "16": 0.13296742737293243, "17": 0.2974454164505005, "18": 0.000306109432131052, "19": 0.05826949700713158}}, {"key": "wei2023symbol", "year": "2023", "title": "Symbol Tuning Improves In-context Learning In Language Models", "topic_distr": {"0": 0.0017332162242382765, "1": 0.0014146125176921487, "2": 0.2523297667503357, "3": 0.0010356460697948933, "4": 0.0009133923449553549, "5": 0.0008169625070877373, "6": 0.0007389493985101581, "7": 0.0006745367427356541, "8": 0.0006204532692208886, "9": 0.0005743986694142222, "10": 0.000534708728082478, "11": 0.10110912472009659, "12": 0.000469785911263898, "13": 0.00044289816287346184, "14": 0.00041892161243595183, "15": 0.0003974077117163688, "16": 0.10753178596496582, "17": 0.5275693535804749, "18": 0.0003443543391767889, "19": 0.0003296835348010063}}, {"key": "weissenborn2016separating", "year": "2016", "title": "Separating Answers From Queries For Neural Reading Comprehension", "topic_distr": {"0": 0.0019489008700475097, "1": 0.0015913553070276976, "2": 0.43192383646965027, "3": 0.0011651648674160242, "4": 0.0010276313405483961, "5": 0.0009191394201479852, "6": 0.000831369252409786, "7": 0.0007589005399495363, "8": 0.41017627716064453, "9": 0.0006462382734753191, "10": 0.0006015843246132135, "11": 0.0005627025966532528, "12": 0.0005285416846163571, "13": 0.018955683335661888, "14": 0.0004713158414233476, "15": 0.0004471111751627177, "16": 0.12628044188022614, "17": 0.0004054655146319419, "18": 0.00038742247852496803, "19": 0.00037091682315804064}}, {"key": "welbl2017constructing", "year": "2017", "title": "Constructing Datasets For Multi-hop Reading Comprehension Across Documents", "topic_distr": {"0": 0.07459424436092377, "1": 0.0010190034518018365, "2": 0.47527408599853516, "3": 0.12302741408348083, "4": 0.0006577225285582244, "5": 0.0005882836412638426, "6": 0.0005321074859239161, "7": 0.00048572488594800234, "8": 0.20032548904418945, "9": 0.00041361679905094206, "10": 0.00038503657560795546, "11": 0.0003601507924031466, "12": 0.09041399508714676, "13": 0.00031892501283437014, "14": 0.00030165983480401337, "15": 0.0002861679531633854, "16": 0.030271483585238457, "17": 0.0002595131518319249, "18": 0.0002479649265296757, "19": 0.0002374007017351687}}, {"key": "welbl2021challenges", "year": "2021", "title": "Challenges In Detoxifying Language Models", "topic_distr": {"0": 0.35652250051498413, "1": 0.1319051831960678, "2": 0.001025197096168995, "3": 0.10687636584043503, "4": 0.0007831300608813763, "5": 0.0007004515500739217, "6": 0.06288141012191772, "7": 0.1727360039949417, "8": 0.0005319675547070801, "9": 0.0004924810491502285, "10": 0.0004584514244925231, "11": 0.00042882069828920066, "12": 0.0004027875838801265, "13": 0.025373689830303192, "14": 0.0003591772692743689, "15": 0.00034073155256919563, "16": 0.00032408791594207287, "17": 0.00030899449484422803, "18": 0.0002952443901449442, "19": 0.13725335896015167}}, {"key": "welleck2019non", "year": "2019", "title": "Non-monotonic Sequential Text Generation", "topic_distr": {"0": 0.0017804672243073583, "1": 0.0014549603220075369, "2": 0.31791168451309204, "3": 0.0010652001947164536, "4": 0.0800786241889, "5": 0.000840282067656517, "6": 0.000760042283218354, "7": 0.4678282141685486, "8": 0.0006381637649610639, "9": 0.0005907946033403277, "10": 0.0005499716498889029, "11": 0.12327055633068085, "12": 0.0004831956757698208, "13": 0.0004555404302664101, "14": 0.00043087950325571, "15": 0.00040875148260965943, "16": 0.0003887852653861046, "17": 0.000370678782928735, "18": 0.00035418375045992434, "19": 0.0003390941710676998}}, {"key": "welleck2022generating", "year": "2022", "title": "Generating Sequences By Learning To Self-correct", "topic_distr": {"0": 0.0017577350372448564, "1": 0.0014345485251396894, "2": 0.0012126413639634848, "3": 0.4294266998767853, "4": 0.04298309609293938, "5": 0.0008285110234282911, "6": 0.0007493951707147062, "7": 0.31408217549324036, "8": 0.0006292239995673299, "9": 0.0005825184052810073, "10": 0.0005422673420980573, "11": 0.0005072194035165012, "12": 0.00047642679419368505, "13": 0.0870445966720581, "14": 0.0004248435143381357, "15": 0.0004030254785902798, "16": 0.1158660426735878, "17": 0.00036548610660247505, "18": 0.0003492221294436604, "19": 0.00033434396027587354}}, {"key": "wen2017latent", "year": "2017", "title": "Latent Intention Dialogue Models", "topic_distr": {"0": 0.001559084514155984, "1": 0.06616833060979843, "2": 0.0010761793237179518, "3": 0.0009320996468886733, "4": 0.20804141461849213, "5": 0.18284164369106293, "6": 0.24772736430168152, "7": 0.0006070933886803687, "8": 0.0005584174068644643, "9": 0.0005169676151126623, "10": 0.0004812460101675242, "11": 0.22871993482112885, "12": 0.0004228144825901836, "13": 0.0003986150841228664, "14": 0.05831995978951454, "15": 0.00035767300869338214, "16": 0.00034020180464722216, "17": 0.00032435794128105044, "18": 0.0003099241585005075, "19": 0.0002967202162835747}}, {"key": "wen2018sequence", "year": "2018", "title": "Sequence-to-sequence Learning For Task-oriented Dialogue With Dialogue State Representation", "topic_distr": {"0": 0.001860839081928134, "1": 0.0015198092442005873, "2": 0.12828055024147034, "3": 0.0011128553887829185, "4": 0.0009814962977543473, "5": 0.23820830881595612, "6": 0.22402465343475342, "7": 0.0007248300826177001, "8": 0.044605594128370285, "9": 0.0006172257708385587, "10": 0.07711754739284515, "11": 0.05742958188056946, "12": 0.0005048130406066775, "13": 0.00047592056216672063, "14": 0.0004501563380472362, "15": 0.00042703835060819983, "16": 0.22054718434810638, "17": 0.0003872623492497951, "18": 0.000370029330952093, "19": 0.0003542646882124245}}, {"key": "wen2019adapting", "year": "2019", "title": "Adapting And Evaluating A Deep Learning Language Model For Clinical Why-question Answering", "topic_distr": {"0": 0.0016219794051721692, "1": 0.16363881528377533, "2": 0.0011182068847119808, "3": 0.22438666224479675, "4": 0.0008541724528186023, "5": 0.0007639937102794647, "6": 0.0006910387892276049, "7": 0.0006308024167083204, "8": 0.05475355684757233, "9": 0.06588191539049149, "10": 0.24838319420814514, "11": 0.00046772154746577144, "12": 0.0004393268027342856, "13": 0.20773501694202423, "14": 0.00039176037535071373, "15": 0.026920977979898453, "16": 0.0003534878487698734, "17": 0.00033702520886436105, "18": 0.00032202774309553206, "19": 0.0003083081392105669}}, {"key": "wen2023hard", "year": "2023", "title": "Hard Prompts Made Easy: Gradient-based Discrete Optimization For Prompt Tuning And Discovery", "topic_distr": {"0": 0.0015595885924994946, "1": 0.0012732923496514559, "2": 0.10178567469120026, "3": 0.0009322073892690241, "4": 0.0008221652242355049, "5": 0.07242867350578308, "6": 0.0006651444127783179, "7": 0.13433489203453064, "8": 0.0005584834725596011, "9": 0.0005170287331566215, "10": 0.00048130290815606713, "11": 0.00045019524986855686, "12": 0.0004228644829709083, "13": 0.0538993701338768, "14": 0.00037708046147599816, "15": 0.15164248645305634, "16": 0.0003402420552447438, "17": 0.41508832573890686, "18": 0.035306062549352646, "19": 0.027114931493997574}}, {"key": "wen2023knowledge", "year": "2023", "title": "Mindmap: Knowledge Graph Prompting Sparks Graph Of Thoughts In Large Language Models", "topic_distr": {"0": 0.11076506972312927, "1": 0.0009610073175281286, "2": 0.0008121992577798665, "3": 0.4051516652107239, "4": 0.0006204319652169943, "5": 0.000554930476937443, "6": 0.0005019392701797187, "7": 0.0004581863177008927, "8": 0.027533596381545067, "9": 0.00039016647497192025, "10": 0.00036320663639344275, "11": 0.0003397317777853459, "12": 0.10497657209634781, "13": 0.0003008433268405497, "14": 0.00028455699793994427, "15": 0.02375447377562523, "16": 0.32152876257896423, "17": 0.0002447998558636755, "18": 0.00023390637943521142, "19": 0.00022394108236767352}}, {"key": "wen2023llm", "year": "2023", "title": "Autodroid: Llm-powered Task Automation In Android", "topic_distr": {"0": 0.0011763406218960881, "1": 0.0009608342661522329, "2": 0.0008122330764308572, "3": 0.343237966299057, "4": 0.07020426541566849, "5": 0.04316355660557747, "6": 0.0005019544041715562, "7": 0.0004582001129165292, "8": 0.01544103305786848, "9": 0.0003901782038155943, "10": 0.000363217550329864, "11": 0.07864928990602493, "12": 0.16818657517433167, "13": 0.1364189237356186, "14": 0.00028456555446609855, "15": 0.0002699515607673675, "16": 0.1387781947851181, "17": 0.00024480721913278103, "18": 0.00023391342256218195, "19": 0.00022394781990442425}}, {"key": "weng2019acquiring", "year": "2019", "title": "Acquiring Knowledge From Pre-trained Model To Neural Machine Translation", "topic_distr": {"0": 0.0012340315151959658, "1": 0.001008403836749494, "2": 0.2212282419204712, "3": 0.0007383004412986338, "4": 0.0006511507090181112, "5": 0.0005824061809107661, "6": 0.0005267913802526891, "7": 0.0004808720841538161, "8": 0.00044231637730263174, "9": 0.0004094844334758818, "10": 0.10439625382423401, "11": 0.00035655259853228927, "12": 0.00033490677014924586, "13": 0.08723296970129013, "14": 0.37524789571762085, "15": 0.0002833089092746377, "16": 0.20410870015621185, "17": 0.00025692040799185634, "18": 0.0002454875793773681, "19": 0.00023502887052018195}}, {"key": "weng2022large", "year": "2022", "title": "Large Language Models Are Better Reasoners With Self-verification", "topic_distr": {"0": 0.0012997443554922938, "1": 0.001060722628608346, "2": 0.0008967939065769315, "3": 0.9073541760444641, "4": 0.0006850458448752761, "5": 0.0006127230008132756, "6": 0.0005542131257243454, "7": 0.0005059035611338913, "8": 0.039966464042663574, "9": 0.0004307998460717499, "10": 0.0004010323027614504, "11": 0.043876320123672485, "12": 0.00035234011011198163, "13": 0.00033217426971532404, "14": 0.0003141918277833611, "15": 0.0002980563440360129, "16": 0.0002834972401615232, "17": 0.00027029422926716506, "18": 0.0002582662564236671, "19": 0.0002472631458658725}}, {"key": "west2021symbolic", "year": "2021", "title": "Symbolic Knowledge Distillation: From General Language Models To Commonsense Models", "topic_distr": {"0": 0.0011454623891040683, "1": 0.026933321729302406, "2": 0.0007899089250713587, "3": 0.19568496942520142, "4": 0.0006033952231518924, "5": 0.0005396915948949754, "6": 0.0004881555796600878, "7": 0.0004456041206140071, "8": 0.07453358173370361, "9": 0.0003794521326199174, "10": 0.0003532326372805983, "11": 0.0003304024285171181, "12": 0.00031034412677399814, "13": 0.2824430465698242, "14": 0.046216174960136414, "15": 0.0002625305496621877, "16": 0.15999677777290344, "17": 0.16988219320774078, "18": 0.00022748310584574938, "19": 0.03843428194522858}}, {"key": "west2023ai", "year": "2023", "title": "AI And The FCI: Can Chatgpt Project An Understanding Of Introductory Physics?", "topic_distr": {"0": 0.33872783184051514, "1": 0.0009985717479139566, "2": 0.050684329122304916, "3": 0.13278500735759735, "4": 0.0006448118365369737, "5": 0.0005767367547377944, "6": 0.06346512585878372, "7": 0.015456898137927055, "8": 0.03199861943721771, "9": 0.3014157712459564, "10": 0.0003774790093302727, "11": 0.00035308170481584966, "12": 0.06062963232398033, "13": 0.00031266509904526174, "14": 0.0002957388060167432, "15": 0.00028055100119672716, "16": 0.0002668469969648868, "17": 0.0002544193994253874, "18": 0.00024309784930665046, "19": 0.0002327409602003172}}, {"key": "weston2018retrieve", "year": "2018", "title": "Retrieve And Refine: Improved Sequence Generation Models For Dialogue", "topic_distr": {"0": 0.05526844412088394, "1": 0.0016973173478618264, "2": 0.1822715699672699, "3": 0.12488646805286407, "4": 0.0010961451334878802, "5": 0.0009804214350879192, "6": 0.25273239612579346, "7": 0.22334398329257965, "8": 0.15202201902866364, "9": 0.0006893249810673296, "10": 0.000641693826764822, "11": 0.0006002197042107582, "12": 0.0005637811846099794, "13": 0.0005315137095749378, "14": 0.0005027399165555835, "15": 0.00047692147199995816, "16": 0.0004536253691185266, "17": 0.00043249913142062724, "18": 0.0004132531466893852, "19": 0.0003956469881813973}}, {"key": "wettig2022should", "year": "2022", "title": "Should You Mask 15% In Masked Language Modeling?", "topic_distr": {"0": 0.2570958435535431, "1": 0.0011707956437021494, "2": 0.1838052123785019, "3": 0.0008571235230192542, "4": 0.0007559478981420398, "5": 0.0006761399563401937, "6": 0.0006115742144174874, "7": 0.0005582646117545664, "8": 0.0005135036772117019, "9": 0.00047538767103105783, "10": 0.26196983456611633, "11": 0.0004139368829783052, "12": 0.0003888073260895908, "13": 0.23711204528808594, "14": 0.0003467107017058879, "15": 0.0003289052110631019, "16": 0.0003128392272628844, "17": 0.0002982697042170912, "18": 0.0002849968441296369, "19": 0.05202387273311615}}, {"key": "whang2019effective", "year": "2019", "title": "An Effective Domain Adaptive Post-training Method For BERT In Response Selection", "topic_distr": {"0": 0.0018079412402585149, "1": 0.001475922646932304, "2": 0.14580214023590088, "3": 0.0010807013604789972, "4": 0.06613200902938843, "5": 0.0008525092271156609, "6": 0.13889513909816742, "7": 0.0007038863841444254, "8": 0.0006474496913142502, "9": 0.0005993912345729768, "10": 0.2993919849395752, "11": 0.0005219111917540431, "12": 0.0004902266664430499, "13": 0.00046216900227591395, "14": 0.0004371492250356823, "15": 0.29996076226234436, "16": 0.00039444249705411494, "17": 0.00037607253761962056, "18": 0.0003593374858610332, "19": 0.039608895778656006}}, {"key": "whang2020do", "year": "2020", "title": "Do Response Selection Models Really Know What's Next? Utterance Manipulation Strategies For Multi-turn Response Selection", "topic_distr": {"0": 0.0011354910675436258, "1": 0.0009260585065931082, "2": 0.22847606241703033, "3": 0.04582199826836586, "4": 0.2622625231742859, "5": 0.000534826482180506, "6": 0.35564109683036804, "7": 0.000441587035311386, "8": 0.00040618114871904254, "9": 0.00037603144301101565, "10": 0.10159417241811752, "11": 0.00032742388430051506, "12": 0.00030754643375985324, "13": 0.0002899442915804684, "14": 0.0002742480137385428, "15": 0.000260163884377107, "16": 0.00024745569680817425, "17": 0.0002359311911277473, "18": 0.00022543236264027655, "19": 0.00021582809858955443}}, {"key": "whitehouse2023llm", "year": "2023", "title": "Llm-powered Data Augmentation For Enhanced Cross-lingual Performance", "topic_distr": {"0": 0.10871725529432297, "1": 0.2402702271938324, "2": 0.0007972183520905674, "3": 0.33755573630332947, "4": 0.0006089823436923325, "5": 0.0005446899449452758, "6": 0.0004926766850985587, "7": 0.11572661250829697, "8": 0.028858408331871033, "9": 0.04015298932790756, "10": 0.013375934213399887, "11": 0.00033346249256283045, "12": 0.00031321842106990516, "13": 0.01749492809176445, "14": 0.09355100989341736, "15": 0.00026496200007386506, "16": 0.00025201946846209466, "17": 0.00024028241750784218, "18": 0.0002295899612363428, "19": 0.00021980855672154576}}, {"key": "wiegreffe2020measuring", "year": "2020", "title": "Measuring Association Between Labels And Free-text Rationales", "topic_distr": {"0": 0.23029190301895142, "1": 0.04558597505092621, "2": 0.20658323168754578, "3": 0.10022302716970444, "4": 0.0008769772248342633, "5": 0.052952203899621964, "6": 0.0007094891625456512, "7": 0.09301670640707016, "8": 0.0005957171670161188, "9": 0.0005514987278729677, "10": 0.05253167077898979, "11": 0.18213224411010742, "12": 0.00045105660683475435, "13": 0.0004252408107277006, "14": 0.000402220175601542, "15": 0.03131474554538727, "16": 0.00036292578442953527, "17": 0.0003460235893726349, "18": 0.00033062571310438216, "19": 0.0003165398084092885}}, {"key": "wiegreffe2021reframing", "year": "2021", "title": "Reframing Human-ai Collaboration For Generating Free-text Explanations", "topic_distr": {"0": 0.17262262105941772, "1": 0.0012421805877238512, "2": 0.0010500367498025298, "3": 0.15737758576869965, "4": 0.0008020895766094327, "5": 0.1866430938243866, "6": 0.0006489029037766159, "7": 0.19583910703659058, "8": 0.0005448464071378112, "9": 0.0005044039571657777, "10": 0.00046955046127550304, "11": 0.10583197325468063, "12": 0.00041253899689763784, "13": 0.00038892769953235984, "14": 0.0003678729117382318, "15": 0.0003489806258585304, "16": 0.07160784304141998, "17": 0.10270550101995468, "18": 0.0003023922035936266, "19": 0.0002895091602113098}}, {"key": "winata2018learn", "year": "2018", "title": "Learn To Code-switch: Data Augmentation Using Copy Mechanism On Language Modeling", "topic_distr": {"0": 0.0021134172566235065, "1": 0.046103280037641525, "2": 0.6576511263847351, "3": 0.0012638053158298135, "4": 0.09504682570695877, "5": 0.0009969518287107348, "6": 0.0009017512784339488, "7": 0.05886309593915939, "8": 0.0007571486639790237, "9": 0.0007009475375525653, "10": 0.0006525132339447737, "11": 0.0006103398627601564, "12": 0.0005732869612984359, "13": 0.0005404754192568362, "14": 0.13101646304130554, "15": 0.00048496274393983185, "16": 0.0004612738557625562, "17": 0.0004397914162836969, "18": 0.0004202208947390318, "19": 0.0004023179062642157}}, {"key": "winata2021language", "year": "2021", "title": "Language Models Are Few-shot Multilingual Learners", "topic_distr": {"0": 0.0025460487231612206, "1": 0.0020785739179700613, "2": 0.0017569276969879866, "3": 0.5543780326843262, "4": 0.0013420728500932455, "5": 0.0012003859737887979, "6": 0.001085759256966412, "7": 0.0009911159286275506, "8": 0.0009116494911722839, "9": 0.0008439802331849933, "10": 0.0007856626180000603, "11": 0.0007348834769800305, "12": 0.0006902696914039552, "13": 0.000650762754958123, "14": 0.1670055240392685, "15": 0.0005839223740622401, "16": 0.0005553996306844056, "17": 0.260868638753891, "18": 0.0005059695686213672, "19": 0.0004844133509323001}}, {"key": "wiratunga2024cbr", "year": "2024", "title": "CBR-RAG: Case-based Reasoning For Retrieval Augmented Generation In Llms For Legal Question Answering", "topic_distr": {"0": 0.0013707170728594065, "1": 0.001119081163778901, "2": 0.0009460653527639806, "3": 0.30673107504844666, "4": 0.0007226938614621758, "5": 0.000646396481897682, "6": 0.0005846710992045701, "7": 0.1603379249572754, "8": 0.21778711676597595, "9": 0.13926294445991516, "10": 0.04866718873381615, "11": 0.00039572780951857567, "12": 0.00037170370342209935, "13": 0.00035042958916164935, "14": 0.00033145889756269753, "15": 0.0003144366783089936, "16": 0.11924190074205399, "17": 0.00028514882433228195, "18": 0.00027245981618762016, "19": 0.00026085201534442604}}, {"key": "wiseman2016sequence", "year": "2016", "title": "Sequence-to-sequence Learning As Beam-search Optimization", "topic_distr": {"0": 0.036894530057907104, "1": 0.0015667994739487767, "2": 0.2562713027000427, "3": 0.001147248549386859, "4": 0.0010118253994733095, "5": 0.000905002758372575, "6": 0.0008185826009139419, "7": 0.0007472285069525242, "8": 0.0006873167003504932, "9": 0.048958778381347656, "10": 0.21722812950611115, "11": 0.0005540481070056558, "12": 0.000520412577316165, "13": 0.2553522288799286, "14": 0.17533166706562042, "15": 0.00044023452210240066, "16": 0.00041873048758134246, "17": 0.00039922937867231667, "18": 0.00038146384758874774, "19": 0.000365212035831064}}, {"key": "wiseman2018learning", "year": "2018", "title": "Learning Neural Templates For Text Generation", "topic_distr": {"0": 0.0021500259172171354, "1": 0.0017561509739607573, "2": 0.3583354353904724, "3": 0.0012856367975473404, "4": 0.1748955100774765, "5": 0.001014171401038766, "6": 0.0009173264261335135, "7": 0.3967570662498474, "8": 0.0007702262373641133, "9": 0.0007130543817766011, "10": 0.0006637835176661611, "11": 0.0006208817358128726, "12": 0.0005831888411194086, "13": 0.0005498105892911553, "14": 0.0005200462765060365, "15": 0.0004933390882797539, "16": 0.00046924102935008705, "17": 0.00044738754513673484, "18": 0.00042747901170514524, "19": 0.05663026124238968}}, {"key": "witteveen2019paraphrasing", "year": "2019", "title": "Paraphrasing With Large Language Models", "topic_distr": {"0": 0.002549332333728671, "1": 0.002078769728541374, "2": 0.001757102902047336, "3": 0.2632652223110199, "4": 0.0013422257034108043, "5": 0.0012005219468846917, "6": 0.0010858823079615831, "7": 0.3227832615375519, "8": 0.0558154322206974, "9": 0.0008440759847871959, "10": 0.15306298434734344, "11": 0.0007349668885581195, "12": 0.0006903480389155447, "13": 0.09816889464855194, "14": 0.0006156032322905958, "15": 0.0919298455119133, "16": 0.0005554626113735139, "17": 0.0005295936134643853, "18": 0.0005060269613750279, "19": 0.0004844682989642024}}, {"key": "wolf2019transfer", "year": "2019", "title": "Transfertransfo: A Transfer Learning Approach For Neural Network Based Conversational Agents", "topic_distr": {"0": 0.0022257918026298285, "1": 0.0018183497013524175, "2": 0.5736377239227295, "3": 0.0013314730022102594, "4": 0.001174311270006001, "5": 0.0010503338417038321, "6": 0.20154927670955658, "7": 0.0008672229596413672, "8": 0.000797690125182271, "9": 0.07603032886981964, "10": 0.000687452033162117, "11": 0.0787731260061264, "12": 0.0006039835861884058, "13": 0.0005694151623174548, "14": 0.05655672773718834, "15": 0.0005109300254844129, "16": 0.0004859727341681719, "17": 0.0004633400239981711, "18": 0.00044272158993408084, "19": 0.00042385997949168086}}, {"key": "wolf2023fundamental", "year": "2023", "title": "Fundamental Limitations Of Alignment In Large Language Models", "topic_distr": {"0": 0.3664126992225647, "1": 0.10220599919557571, "2": 0.0008122888393700123, "3": 0.1844867467880249, "4": 0.18603633344173431, "5": 0.0005549744819290936, "6": 0.0005019791424274445, "7": 0.0004582226974889636, "8": 0.00042148298234678805, "9": 0.09308990836143494, "10": 0.0003632354782894254, "11": 0.0003397587570361793, "12": 0.00031913246493786573, "13": 0.0003008672210853547, "14": 0.00028457961161620915, "15": 0.00026996489032171667, "16": 0.0002567779447417706, "17": 0.06242717057466507, "18": 0.00023392494767904282, "19": 0.00022395886480808258}}, {"key": "wong2023from", "year": "2023", "title": "From Word Models To World Models: Translating From Natural Language To The Probabilistic Language Of Thought", "topic_distr": {"0": 0.2087245136499405, "1": 0.0007957134512253106, "2": 0.0006726421997882426, "3": 0.26012274622917175, "4": 0.0005138206179253757, "5": 0.00045957459951750934, "6": 0.12085331976413727, "7": 0.00037945431540720165, "8": 0.00034903016057796776, "9": 0.05601855367422104, "10": 0.04318200796842575, "11": 0.14766478538513184, "12": 0.00026427366537973285, "13": 0.00024914820096455514, "14": 0.04108097031712532, "15": 0.0002235579740954563, "16": 0.09780558198690414, "17": 0.00020273491099942476, "18": 0.020252089947462082, "19": 0.00018546039063949138}}, {"key": "wong2023natural", "year": "2023", "title": "Natural Language Generation And Understanding Of Big Code For Ai-assisted Programming: A Review", "topic_distr": {"0": 0.0012348152231425047, "1": 0.027034612372517586, "2": 0.0008524329750798643, "3": 0.0007383413030765951, "4": 0.0006511850515380502, "5": 0.0005824375548399985, "6": 0.2576179504394531, "7": 0.00048089769552461803, "8": 0.0004423399514053017, "9": 0.3225339353084564, "10": 0.027077071368694305, "11": 0.0003565716033335775, "12": 0.3404402434825897, "13": 0.00031575551838614047, "14": 0.018351076170802116, "15": 0.00028332401416264474, "16": 0.0002694845316000283, "17": 0.000256934086792171, "18": 0.00024550064699724317, "19": 0.00023504139971919358}}, {"key": "workshop2022open", "year": "2022", "title": "BLOOM: A 176b-parameter Open-access Multilingual Language Model", "topic_distr": {"0": 0.13834451138973236, "1": 0.0015201941132545471, "2": 0.001285000704228878, "3": 0.28895846009254456, "4": 0.0009816053789108992, "5": 0.0008779741474427283, "6": 0.000794135092291981, "7": 0.0007249119807966053, "8": 0.0006667894776910543, "9": 0.15007305145263672, "10": 0.06368087977170944, "11": 0.0005375010659918189, "12": 0.19047562777996063, "13": 0.00047597434604540467, "14": 0.10992176085710526, "15": 0.0004270866047590971, "16": 0.0004062247753608972, "17": 0.00038730609230697155, "18": 0.00037007115315645933, "19": 0.04909094423055649}}, {"key": "wu2016response", "year": "2016", "title": "Response Selection With Topic Clues For Retrieval-based Chatbots", "topic_distr": {"0": 0.001662747235968709, "1": 0.001358159352093935, "2": 0.3045685887336731, "3": 0.0009942245669662952, "4": 0.2701554000377655, "5": 0.0007842946797609329, "6": 0.29668229818344116, "7": 0.06999833136796951, "8": 0.0005956433014944196, "9": 0.049191031605005264, "10": 0.0005133274244144559, "11": 0.00048014993080869317, "12": 0.0004510006692726165, "13": 0.000425188074586913, "14": 0.00040217029163613915, "15": 0.00038151664193719625, "16": 0.0003628807608038187, "17": 0.00034598069032654166, "18": 0.0003305847058072686, "19": 0.0003165005473420024}}, {"key": "wu2017are", "year": "2017", "title": "Are You Talking To Me? Reasoned Visual Dialog Generation Through Adversarial Learning", "topic_distr": {"0": 0.0012735666241496801, "1": 0.12994085252285004, "2": 0.17506614327430725, "3": 0.0007609144086018205, "4": 0.020011696964502335, "5": 0.04979194328188896, "6": 0.10471086949110031, "7": 0.04954753816127777, "8": 0.1932295858860016, "9": 0.0004220274568069726, "10": 0.0003928660589735955, "11": 0.1398428976535797, "12": 0.0003451653756201267, "13": 0.0003254101611673832, "14": 0.00030779390363022685, "15": 0.03348274156451225, "16": 0.00027772437897510827, "17": 0.00026479020016267896, "18": 0.09976325184106827, "19": 0.0002422280958853662}}, {"key": "wu2017neural", "year": "2017", "title": "Neural Response Generation With Dynamic Vocabularies", "topic_distr": {"0": 0.0013276441022753716, "1": 0.0715462937951088, "2": 0.207267627120018, "3": 0.0007933086599223316, "4": 0.0006996660958975554, "5": 0.0006257994100451469, "6": 0.18412275612354279, "7": 0.3982524275779724, "8": 0.0004752719250973314, "9": 0.03253190219402313, "10": 0.000409590924391523, "11": 0.0003831181675195694, "12": 0.00035985957947559655, "13": 0.09949752688407898, "14": 0.0003208971465937793, "15": 0.0003044173354282975, "16": 0.00028954751905985177, "17": 0.00027606269577518106, "18": 0.00026377805625088513, "19": 0.0002525401068851352}}, {"key": "wu2018faithful", "year": "2018", "title": "Faithful Multimodal Explanation For Visual Question Answering", "topic_distr": {"0": 0.07313204556703568, "1": 0.0014759571058675647, "2": 0.0012476921547204256, "3": 0.0010806694626808167, "4": 0.22556006908416748, "5": 0.11871323734521866, "6": 0.000771074031945318, "7": 0.11576969176530838, "8": 0.1444910168647766, "9": 0.02365764230489731, "10": 0.0005579543067142367, "11": 0.0005218925070948899, "12": 0.000490209087729454, "13": 0.00046215244219638407, "14": 0.0004371335671748966, "15": 0.00041468438575975597, "16": 0.00039442835259251297, "17": 0.0003760590625461191, "18": 0.29010242223739624, "19": 0.0003440160071477294}}, {"key": "wu2018response", "year": "2018", "title": "Response Generation By Context-aware Prototype Editing", "topic_distr": {"0": 0.0017330159898847342, "1": 0.0014145716559141874, "2": 0.0011958127142861485, "3": 0.10674978047609329, "4": 0.0009134560241363943, "5": 0.0008170178043656051, "6": 0.4802108407020569, "7": 0.26218003034591675, "8": 0.000620495353359729, "9": 0.0347609706223011, "10": 0.0005347449914552271, "11": 0.0005001832032576203, "12": 0.07400083541870117, "13": 0.0004429281980264932, "14": 0.00041895004687830806, "15": 0.00039743466186337173, "16": 0.0003780212427955121, "17": 0.0003604160447139293, "18": 0.0003443777095526457, "19": 0.032026126980781555}}, {"key": "wu2018study", "year": "2018", "title": "A Study Of Reinforcement Learning For Neural Machine Translation", "topic_distr": {"0": 0.0013136756606400013, "1": 0.001072225975804031, "2": 0.0009062692988663912, "3": 0.21843788027763367, "4": 0.000692286528646946, "5": 0.0006191989523358643, "6": 0.0005600705626420677, "7": 0.0005112504586577415, "8": 0.0004702590231318027, "9": 0.0004353529657237232, "10": 0.00040527081000618637, "11": 0.22756236791610718, "12": 0.08695297688245773, "13": 0.0003356850065756589, "14": 0.4583534896373749, "15": 0.0003012065135408193, "16": 0.00028649353771470487, "17": 0.0002731509739533067, "18": 0.00026099587557837367, "19": 0.000249876466114074}}, {"key": "wu2019pay", "year": "2019", "title": "Pay Less Attention With Lightweight And Dynamic Convolutions", "topic_distr": {"0": 0.001807458815164864, "1": 0.0014758274191990495, "2": 0.7757586240768433, "3": 0.001080663176253438, "4": 0.0009531040559522808, "5": 0.000852481578476727, "6": 0.0007710768259130418, "7": 0.00070386374136433, "8": 0.0006474288529716432, "9": 0.0005993719678372145, "10": 0.08633267879486084, "11": 0.0005218943697400391, "12": 0.0004902108921669424, "13": 0.00046215413021855056, "14": 0.08922003209590912, "15": 0.017390679568052292, "16": 0.0003944298077840358, "17": 0.00037606043042615056, "18": 0.019817929714918137, "19": 0.00034401725861243904}}, {"key": "wu2019surprising", "year": "2019", "title": "Beto, Bentz, Becas: The Surprising Cross-lingual Effectiveness Of BERT", "topic_distr": {"0": 0.0021155807189643383, "1": 0.28311261534690857, "2": 0.001459305640310049, "3": 0.0012639452470466495, "4": 0.0011147459736093879, "5": 0.000997057999484241, "6": 0.0009018474956974387, "7": 0.000823235372081399, "8": 0.0007572293980047107, "9": 0.0007010223343968391, "10": 0.21785005927085876, "11": 0.0006104049389250576, "12": 0.0005733480793423951, "13": 0.0005405330448411405, "14": 0.25770947337150574, "15": 0.00048501446144655347, "16": 0.0004613230412360281, "17": 0.0004398383025545627, "18": 0.00042026571463793516, "19": 0.22766314446926117}}, {"key": "wu2020are", "year": "2020", "title": "Are All Languages Created Equal In Multilingual BERT?", "topic_distr": {"0": 0.0017584962770342827, "1": 0.0014346399111673236, "2": 0.13122029602527618, "3": 0.0010503903031349182, "4": 0.0009263984393328428, "5": 0.0008285950170829892, "6": 0.0007494711317121983, "7": 0.0006841413560323417, "8": 0.000629287795163691, "9": 0.0005825774278491735, "10": 0.2659076452255249, "11": 0.0005072708008810878, "12": 0.00047647510655224323, "13": 0.00044920449727214873, "14": 0.3596285283565521, "15": 0.0004030663112644106, "16": 0.0003833778027910739, "17": 0.06919021159410477, "18": 0.0003492575488053262, "19": 0.16284066438674927}}, {"key": "wu2020contrastive", "year": "2020", "title": "CLEAR: Contrastive Learning For Sentence Representation", "topic_distr": {"0": 0.001861422904767096, "1": 0.09124775975942612, "2": 0.5775586366653442, "3": 0.0011129911290481687, "4": 0.0009816127130761743, "5": 0.0008779795607551932, "6": 0.0007941396906971931, "7": 0.0007249162881635129, "8": 0.0006667934358119965, "9": 0.0006172991706989706, "10": 0.0005746448296122253, "11": 0.0005375042674131691, "12": 0.0005048731109127402, "13": 0.000475977169116959, "14": 0.00045020985999144614, "15": 0.00042708913679234684, "16": 0.0004062271909788251, "17": 0.00038730839150957763, "18": 0.31943827867507935, "19": 0.00035430683055892587}}, {"key": "wu2020controllable", "year": "2020", "title": "A Controllable Model Of Grounded Response Generation", "topic_distr": {"0": 0.04541432112455368, "1": 0.0013762495946139097, "2": 0.08074688911437988, "3": 0.0010077552869915962, "4": 0.021597983315587044, "5": 0.0007949625723995268, "6": 0.3548952043056488, "7": 0.19106422364711761, "8": 0.0006037450511939824, "9": 0.0005589306820183992, "10": 0.03992043435573578, "11": 0.0004866807721555233, "12": 0.00045713502913713455, "13": 0.000430971325840801, "14": 0.0004076404729858041, "15": 0.0003867059131152928, "16": 0.2173829823732376, "17": 0.00035068660508841276, "18": 0.02287016250193119, "19": 0.019246362149715424}}, {"key": "wu2020lite", "year": "2020", "title": "Lite Transformer With Long-short Range Attention", "topic_distr": {"0": 0.001030411571264267, "1": 0.0008416112395934761, "2": 0.16345477104187012, "3": 0.0006162981735542417, "4": 0.0005435521015897393, "5": 0.041704047471284866, "6": 0.00043974234722554684, "7": 0.00040141097269952297, "8": 0.024051209911704063, "9": 0.00034181965747848153, "10": 0.36472925543785095, "11": 0.000297634513117373, "12": 0.0002795655163936317, "13": 0.18255648016929626, "14": 0.21763518452644348, "15": 0.00023649387003388256, "16": 0.00022494190488941967, "17": 0.00021446590835694224, "18": 0.00020492228213697672, "19": 0.00019619181693997234}}, {"key": "wu2020tod", "year": "2020", "title": "TOD-BERT: Pre-trained Natural Language Understanding For Task-oriented Dialogue", "topic_distr": {"0": 0.16225877404212952, "1": 0.04142019525170326, "2": 0.0012125835055485368, "3": 0.0010502520017325878, "4": 0.0009262823150493205, "5": 0.24352966248989105, "6": 0.1691950112581253, "7": 0.0006840546848252416, "8": 0.0006292080506682396, "9": 0.0005825036205351353, "10": 0.37481847405433655, "11": 0.0005072065396234393, "12": 0.0004764147161040455, "13": 0.00044914757017977536, "14": 0.00042483271681703627, "15": 0.00040301523404195905, "16": 0.00038332922849804163, "17": 0.00036547682248055935, "18": 0.00034921328187920153, "19": 0.00033433549106121063}}, {"key": "wu2021additive", "year": "2021", "title": "Fastformer: Additive Attention Can Be All You Need", "topic_distr": {"0": 0.001640535774640739, "1": 0.0013400005409494042, "2": 0.36211511492729187, "3": 0.000981187098659575, "4": 0.022187814116477966, "5": 0.0007740080473013222, "6": 0.0007000968907959759, "7": 0.038327448070049286, "8": 0.0005878310767002404, "9": 0.0005441979737952352, "10": 0.4984413981437683, "11": 0.00047385244397446513, "12": 0.0004450854903552681, "13": 0.0693298801779747, "14": 0.00039689557161182165, "15": 0.00037651282036677003, "16": 0.0003581213532015681, "17": 0.00034144293749704957, "18": 0.00032624887535348535, "19": 0.000312349438900128}}, {"key": "wu2021ai", "year": "2021", "title": "AI Chains: Transparent And Controllable Human-ai Interaction By Chaining Large Language Model Prompts", "topic_distr": {"0": 0.1436646729707718, "1": 0.0010609986493363976, "2": 0.066872239112854, "3": 0.4047423005104065, "4": 0.0883672684431076, "5": 0.0006127948872745037, "6": 0.0005542782018892467, "7": 0.10521184653043747, "8": 0.00046539545292034745, "9": 0.15042465925216675, "10": 0.00040107936365529895, "11": 0.00037515669828280807, "12": 0.0003523814375512302, "13": 0.0003322132397443056, "14": 0.0003142286732327193, "15": 0.0002980913268402219, "16": 0.00028353050583973527, "17": 0.035161279141902924, "18": 0.00025829655351117253, "19": 0.0002472921332810074}}, {"key": "wu2021distilling", "year": "2021", "title": "Newsbert: Distilling Pre-trained Language Model For Intelligent News Application", "topic_distr": {"0": 0.0009045794140547514, "1": 0.0007380618480965495, "2": 0.0006239135982468724, "3": 0.0005403805989772081, "4": 0.02121013216674328, "5": 0.0004262775182723999, "6": 0.00038557162042707205, "7": 0.00035196219687350094, "8": 0.00032374230795539916, "9": 0.15740585327148438, "10": 0.12307249009609222, "11": 0.0002609696821309626, "12": 0.0002451265463605523, "13": 0.23821212351322174, "14": 0.00021858641412109137, "15": 0.23439446091651917, "16": 0.08433707058429718, "17": 0.1359969675540924, "18": 0.0001796784345060587, "19": 0.00017202345770783722}}, {"key": "wu2021empowering", "year": "2021", "title": "Empowering News Recommendation With Pre-trained Language Models", "topic_distr": {"0": 0.001299571362324059, "1": 0.02418706938624382, "2": 0.0008967954199761152, "3": 0.0007767503266222775, "4": 0.31461045145988464, "5": 0.0006127362139523029, "6": 0.0005542251165024936, "7": 0.0005059145041741431, "8": 0.0004653509531635791, "9": 0.00043080918840132654, "10": 0.000401041004806757, "11": 0.00037512084236368537, "12": 0.00035234776441939175, "13": 0.00033218145836144686, "14": 0.07683415710926056, "15": 0.4757685363292694, "16": 0.10082109272480011, "17": 0.00027030007913708687, "18": 0.0002582718734629452, "19": 0.00024726850097067654}}, {"key": "wu2021explaining", "year": "2021", "title": "On Explaining Your Explanations Of BERT: An Empirical Study With Sequence Classification", "topic_distr": {"0": 0.03549351170659065, "1": 0.039629027247428894, "2": 0.356045126914978, "3": 0.0008773024892434478, "4": 0.0007737439591437578, "5": 0.13421660661697388, "6": 0.0006259711808525026, "7": 0.0005714066792279482, "8": 0.0005255920113995671, "9": 0.000486578734125942, "10": 0.2801732122898102, "11": 0.00042368134018033743, "12": 0.11937810480594635, "13": 0.000375183328287676, "14": 0.0003548725799191743, "15": 0.0003366479359101504, "16": 0.028837185353040695, "17": 0.00030529123614542186, "18": 0.00029170591733418405, "19": 0.0002792781451717019}}, {"key": "wu2021good", "year": "2021", "title": "Good For Misconceived Reasons: An Empirical Revisiting On The Need For Visual Context In Multimodal Machine Translation", "topic_distr": {"0": 0.12853577733039856, "1": 0.001322635100223124, "2": 0.0011181803420186043, "3": 0.0009684668621048331, "4": 0.0008541453862562776, "5": 0.10039389878511429, "6": 0.0006910170195624232, "7": 0.000630782509688288, "8": 0.0005802072118967772, "9": 0.205910786986351, "10": 0.0005000245291739702, "11": 0.00046770682092756033, "12": 0.0004393129493109882, "13": 0.0004141693061683327, "14": 0.2541433274745941, "15": 0.00037162963417358696, "16": 0.00035347670200280845, "17": 0.00033701458596624434, "18": 0.30165910720825195, "19": 0.00030829841853119433}}, {"key": "wu2021linear", "year": "2021", "title": "Linear-time Self Attention With Codeword Histogram For Efficient Recommendation", "topic_distr": {"0": 0.0013555648038163781, "1": 0.0011068482417613268, "2": 0.4307567775249481, "3": 0.0008104980806820095, "4": 0.09245292097330093, "5": 0.0006393602816388011, "6": 0.0005783068481832743, "7": 0.0005278970929794014, "8": 0.00048557098489254713, "9": 0.00044952836469747126, "10": 0.21393711864948273, "11": 0.00039142026798799634, "12": 0.00036765768891200423, "13": 0.25439634919166565, "14": 0.00032785095390863717, "15": 0.0003110140096396208, "16": 0.00029582195566035807, "17": 0.00028204492991790175, "18": 0.0002694940776564181, "19": 0.00025801261654123664}}, {"key": "wu2021one", "year": "2021", "title": "One Teacher Is Enough? Pre-trained Language Model Distillation From Multiple Teachers", "topic_distr": {"0": 0.0012740714009851217, "1": 0.0010391197865828872, "2": 0.0008785550016909838, "3": 0.0007609322783537209, "4": 0.10202637314796448, "5": 0.0006002596928738058, "6": 0.0005429398734122515, "7": 0.0004956129705533385, "8": 0.0004558753571473062, "9": 0.000422036973759532, "10": 0.2247307151556015, "11": 0.0003674825420603156, "12": 0.00034517317544668913, "13": 0.4023514688014984, "14": 0.000307800859445706, "15": 0.00029199360869824886, "16": 0.04716171696782112, "17": 0.2027060091495514, "18": 0.00025301286950707436, "19": 0.01298886351287365}}, {"key": "wu2021recursively", "year": "2021", "title": "Recursively Summarizing Books With Human Feedback", "topic_distr": {"0": 0.0014514030190184712, "1": 0.0011844640830531716, "2": 0.0010011838749051094, "3": 0.11554162204265594, "4": 0.0882895290851593, "5": 0.0006840404239483178, "6": 0.0006187203107401729, "7": 0.26572224497795105, "8": 0.062318529933691025, "9": 0.0004809424572158605, "10": 0.0004477101319935173, "11": 0.1561436504125595, "12": 0.04857119917869568, "13": 0.19729816913604736, "14": 0.05873122438788414, "15": 0.0003327483718749136, "16": 0.00031649466836825013, "17": 0.00030175488791428506, "18": 0.0002883269335143268, "19": 0.00027604313800111413}}, {"key": "wu2021visual", "year": "2021", "title": "N\\\"UWA: Visual Synthesis Pre-training For Neural Visual World Creation", "topic_distr": {"0": 0.0015997625887393951, "1": 0.11905834078788757, "2": 0.24776819348335266, "3": 0.0009559909231029451, "4": 0.0008431446040049195, "5": 0.0007541304221376777, "6": 0.0006821173010393977, "7": 0.04535651206970215, "8": 0.000572734628804028, "9": 0.000530222081579268, "10": 0.0004935846081934869, "11": 0.00046168314293026924, "12": 0.00043365496094338596, "13": 0.00040883515612222254, "14": 0.0003867026243824512, "15": 0.00036684333463199437, "16": 0.00034892422263510525, "17": 0.00033267412800341845, "18": 0.5783416032791138, "19": 0.0003043278120458126}}, {"key": "wu2022efficient", "year": "2022", "title": "An Efficient Memory-augmented Transformer For Knowledge-intensive NLP Tasks", "topic_distr": {"0": 0.0013122442178428173, "1": 0.0010719943093135953, "2": 0.2759121358394623, "3": 0.000784912845119834, "4": 0.0006922612665221095, "5": 0.05655389279127121, "6": 0.045276302844285965, "7": 0.0005112321232445538, "8": 0.08352912962436676, "9": 0.0004353373951744288, "10": 0.09167900681495667, "11": 0.00037906368379481137, "12": 0.0003560512268450111, "13": 0.18141356110572815, "14": 0.0003175011370331049, "15": 0.00030119571601971984, "16": 0.2586901783943176, "17": 0.00027314116596244276, "18": 0.00026098653324879706, "19": 0.0002498675021342933}}, {"key": "wu2022instance", "year": "2022", "title": "IDPG: An Instance-dependent Prompt Generation Method", "topic_distr": {"0": 0.0017076032236218452, "1": 0.001394959050230682, "2": 0.2023318111896515, "3": 0.001021439558826387, "4": 0.0009008690831251442, "5": 0.0008057606755755842, "6": 0.0007288173655979335, "7": 0.1149296686053276, "8": 0.0006119459867477417, "9": 0.0005665228818543255, "10": 0.04993797838687897, "11": 0.0004932915326207876, "12": 0.00046334447688423097, "13": 0.03341309726238251, "14": 0.00041317762224934995, "15": 0.0003919586888514459, "16": 0.0003728127630893141, "17": 0.5888500809669495, "18": 0.0003396327665541321, "19": 0.00032516312785446644}}, {"key": "wu2022little", "year": "2022", "title": "Noisytune: A Little Noise Can Help You Finetune Pretrained Language Models Better", "topic_distr": {"0": 0.0014335832092911005, "1": 0.07868794351816177, "2": 0.1412210315465927, "3": 0.0008572674705646932, "4": 0.0007560756057500839, "5": 0.0006762537523172796, "6": 0.0006116773001849651, "7": 0.0005583587335422635, "8": 0.0005135902320034802, "9": 0.0004754678229801357, "10": 0.026889469474554062, "11": 0.00041400667396374047, "12": 0.0003888728970196098, "13": 0.033412866294384, "14": 0.031713929027318954, "15": 0.00032896065386012197, "16": 0.00031289199250750244, "17": 0.5100119113922119, "18": 0.00028504489455372095, "19": 0.1704508513212204}}, {"key": "wu2022memorizing", "year": "2022", "title": "Memorizing Transformers", "topic_distr": {"0": 0.0017820028588175774, "1": 0.0014551052590832114, "2": 0.519464910030365, "3": 0.17599116265773773, "4": 0.0009395297383889556, "5": 0.0008403401589021087, "6": 0.0007600947865284979, "7": 0.000693838985171169, "8": 0.0006382078281603754, "9": 0.0005908354069106281, "10": 0.14792239665985107, "11": 0.0005144613096490502, "12": 0.0004832290578633547, "13": 0.0004555719206109643, "14": 0.00043090927647426724, "15": 0.0004087797424290329, "16": 0.1082693487405777, "17": 0.00037070439429953694, "18": 0.00035420822678133845, "19": 0.03763433173298836}}, {"key": "wu2022personalized", "year": "2022", "title": "Personalized Prompt For Sequential Recommendation", "topic_distr": {"0": 0.0012228795094415545, "1": 0.0701901912689209, "2": 0.0008440407109446824, "3": 0.0007310460205189884, "4": 0.42003533244132996, "5": 0.0005766829708591104, "6": 0.0005216145655140281, "7": 0.00047614655341021717, "8": 0.000437969749327749, "9": 0.000405460421461612, "10": 0.12710027396678925, "11": 0.00035304875927977264, "12": 0.0003316156507935375, "13": 0.0003126359370071441, "14": 0.0002957112155854702, "15": 0.00028052483685314655, "16": 0.038867466151714325, "17": 0.3365415632724762, "18": 0.00024307516287080944, "19": 0.00023271924874279648}}, {"key": "wu2022self", "year": "2022", "title": "Self-adaptive In-context Learning: An Information Compression Perspective For In-context Example Selection And Ordering", "topic_distr": {"0": 0.001579586765728891, "1": 0.0012895123800262809, "2": 0.22896742820739746, "3": 0.21954414248466492, "4": 0.022097647190093994, "5": 0.0007446488016285002, "6": 0.0006735412171110511, "7": 0.0006148300599306822, "8": 0.000565533759072423, "9": 0.0005235557327978313, "10": 0.00048737891484051943, "11": 0.000455878529464826, "12": 0.11323823779821396, "13": 0.06233593448996544, "14": 0.000381840713089332, "15": 0.0003622311051003635, "16": 0.00034453728585503995, "17": 0.34517917037010193, "18": 0.0003138737811241299, "19": 0.0003005015605594963}}, {"key": "wu2022tune", "year": "2022", "title": "Tune-a-video: One-shot Tuning Of Image Diffusion Models For Text-to-video Generation", "topic_distr": {"0": 0.0015798677923157811, "1": 0.0012894247192889452, "2": 0.19316211342811584, "3": 0.0009439596906304359, "4": 0.03635500743985176, "5": 0.000744636869058013, "6": 0.0006735302740707994, "7": 0.17557033896446228, "8": 0.0005655245622619987, "9": 0.0005235472344793379, "10": 0.0004873709985986352, "11": 0.00045587113709189, "12": 0.00042819580994546413, "13": 0.08639688789844513, "14": 0.0003818345139734447, "15": 0.00036222522612661123, "16": 0.00034453169791959226, "17": 0.20172947645187378, "18": 0.29770517349243164, "19": 0.00030049670021981}}, {"key": "wu2023chatgpt", "year": "2023", "title": "Chatgpt Or Grammarly? Evaluating Chatgpt On Grammatical Error Correction Benchmark", "topic_distr": {"0": 0.22857961058616638, "1": 0.0012732954928651452, "2": 0.21494369208812714, "3": 0.11964964866638184, "4": 0.0008221326279453933, "5": 0.0007353357505053282, "6": 0.0006651174044236541, "7": 0.11201297491788864, "8": 0.038655634969472885, "9": 0.2789035439491272, "10": 0.0004812834085896611, "11": 0.0004501770017668605, "12": 0.00042284734081476927, "13": 0.0003986460797023028, "14": 0.0003770651528611779, "15": 0.0003577008028514683, "16": 0.00034022826002910733, "17": 0.000324383145198226, "18": 0.00030994825647212565, "19": 0.0002967432956211269}}, {"key": "wu2023clip", "year": "2023", "title": "Tinyclip: CLIP Distillation Via Affinity Mimicking And Weight Inheritance", "topic_distr": {"0": 0.040484603494405746, "1": 0.0011318954639136791, "2": 0.000956704665441066, "3": 0.0008286373340524733, "4": 0.000730822968762368, "5": 0.0006536663277074695, "6": 0.0005912467022426426, "7": 0.0005397089989855886, "8": 0.0004964357940480113, "9": 0.0004595867358148098, "10": 0.060377802699804306, "11": 0.00040017845458351076, "12": 0.0003758841485250741, "13": 0.5360001921653748, "14": 0.0003351867198944092, "15": 0.00031797305564396083, "16": 0.0003024410689249635, "17": 0.07451266050338745, "18": 0.28024056553840637, "19": 0.0002637857396621257}}, {"key": "wu2023comparative", "year": "2023", "title": "A Comparative Study Of Open-source Large Language Models, GPT-4 And Claude 2: Multiple-choice Test Taking In Nephrology", "topic_distr": {"0": 0.05928679183125496, "1": 0.04269680380821228, "2": 0.0006943159969523549, "3": 0.3038415312767029, "4": 0.0005303835496306419, "5": 0.000474388973088935, "6": 0.00042908883187919855, "7": 0.00039168610237538815, "8": 0.0702633410692215, "9": 0.2605132460594177, "10": 0.00031049156677909195, "11": 0.00029042380629107356, "12": 0.2587261497974396, "13": 0.0002571795484982431, "14": 0.00024325698905158788, "15": 0.0002307644026586786, "16": 0.00021949229994788766, "17": 0.00020927010336890817, "18": 0.00019995769253000617, "19": 0.0001914387394208461}}, {"key": "wu2023decoder", "year": "2023", "title": "On Decoder-only Architecture For Speech-to-text And Large Language Model Integration", "topic_distr": {"0": 0.0016856815200299025, "1": 0.1055867150425911, "2": 0.001163449021987617, "3": 0.2388244867324829, "4": 0.0008887398871593177, "5": 0.0007949120481498539, "6": 0.0007190046599134803, "7": 0.0006563305505551398, "8": 0.0006037068087607622, "9": 0.0005588952917605639, "10": 0.15661577880382538, "11": 0.0004866499511990696, "12": 0.06230993941426277, "13": 0.00043094405555166304, "14": 0.08174778521060944, "15": 0.0003866814076900482, "16": 0.09084039181470871, "17": 0.0003506643988657743, "18": 0.25502851605415344, "19": 0.00032078518415801227}}, {"key": "wu2023enabling", "year": "2023", "title": "Autogen: Enabling Next-gen LLM Applications Via Multi-agent Conversation", "topic_distr": {"0": 0.0017575793899595737, "1": 0.0014345359522849321, "2": 0.03920150548219681, "3": 0.31758785247802734, "4": 0.0009263684041798115, "5": 0.000828567601274699, "6": 0.1397296041250229, "7": 0.0006841187132522464, "8": 0.03484734147787094, "9": 0.3262833058834076, "10": 0.0005423043621703982, "11": 0.13299089670181274, "12": 0.0004764593322761357, "13": 0.00044918962521478534, "14": 0.0004248725017532706, "15": 0.00040305298171006143, "16": 0.0003833651135209948, "17": 0.00036551104858517647, "18": 0.00034924596548080444, "19": 0.0003343667776789516}}, {"key": "wu2023fake", "year": "2023", "title": "Fake News In Sheep's Clothing: Robust Fake News Detection Against Llm-empowered Style Attacks", "topic_distr": {"0": 0.10188035666942596, "1": 0.24377357959747314, "2": 0.001037438167259097, "3": 0.2968166172504425, "4": 0.0007924764067865908, "5": 0.0007088109268806875, "6": 0.000641125428956002, "7": 0.10360358655452728, "8": 0.0005383160896599293, "9": 0.0004983583348803222, "10": 0.000463922624476254, "11": 0.00043393828673288226, "12": 0.000407594459829852, "13": 0.0003842661972157657, "14": 0.00036346373963169754, "15": 0.2200854867696762, "16": 0.0003279556112829596, "17": 0.000312682066578418, "18": 0.026644010096788406, "19": 0.00028603922692127526}}, {"key": "wu2023fine", "year": "2023", "title": "Fine-grained Human Feedback Gives Better Rewards For Language Model Training", "topic_distr": {"0": 0.14475950598716736, "1": 0.144928976893425, "2": 0.07511874288320541, "3": 0.0006428371998481452, "4": 0.25269588828086853, "5": 0.0005070981569588184, "6": 0.0004586744762491435, "7": 0.15747065842151642, "8": 0.02538342960178852, "9": 0.00035653592203743756, "10": 0.00033189987880177796, "11": 0.1485714614391327, "12": 0.0002916015509981662, "13": 0.0002749120176304132, "14": 0.0002600295119918883, "15": 0.0002466755686327815, "16": 0.0002346262481296435, "17": 0.0002236992440884933, "18": 0.0002137447299901396, "19": 0.047029029577970505}}, {"key": "wu2023lamini", "year": "2023", "title": "Lamini-lm: A Diverse Herd Of Distilled Models From Large-scale Instructions", "topic_distr": {"0": 0.001621693721972406, "1": 0.0013228104216977954, "2": 0.0011181290028616786, "3": 0.5648307800292969, "4": 0.0008541230345144868, "5": 0.0007639488321729004, "6": 0.07895580679178238, "7": 0.08215421438217163, "8": 0.0005801914376206696, "9": 0.0005371253937482834, "10": 0.0005000109085813165, "11": 0.00046769410255365074, "12": 0.13098756968975067, "13": 0.0964251235127449, "14": 0.0003917373833246529, "15": 0.037168238312006, "16": 0.00035346709773875773, "17": 0.0003370054473634809, "18": 0.00032200885470956564, "19": 0.00030829006573185325}}, {"key": "wu2023next", "year": "2023", "title": "Next-gpt: Any-to-any Multimodal LLM", "topic_distr": {"0": 0.06838759779930115, "1": 0.0009700552327558398, "2": 0.0008200086886063218, "3": 0.0007102425443008542, "4": 0.0006264014518819749, "5": 0.0005602696328423917, "6": 0.0005067685851827264, "7": 0.11280068010091782, "8": 0.00042550437501631677, "9": 0.16646456718444824, "10": 0.0003667011042125523, "11": 0.05344582349061966, "12": 0.06252892315387726, "13": 0.03173135221004486, "14": 0.0002872947952710092, "15": 0.0002725406375247985, "16": 0.019521471112966537, "17": 0.00024715514155104756, "18": 0.4791005551815033, "19": 0.00022609566804021597}}, {"key": "wu2023pmc", "year": "2023", "title": "Pmc-llama: Towards Building Open-source Language Models For Medicine", "topic_distr": {"0": 0.04304942861199379, "1": 0.000998466508463025, "2": 0.0008441077661700547, "3": 0.3229452073574066, "4": 0.0006448150961659849, "5": 0.0005767390830442309, "6": 0.07036180049180984, "7": 0.0004761926829814911, "8": 0.011524704284965992, "9": 0.06272168457508087, "10": 0.00037748037721030414, "11": 0.01332117710262537, "12": 0.33794984221458435, "13": 0.10702639073133469, "14": 0.0002957398828584701, "15": 0.025889089331030846, "16": 0.00026684795739129186, "17": 0.00025442030164413154, "18": 0.00024309872242156416, "19": 0.00023274178965948522}}, {"key": "wu2023prompt", "year": "2023", "title": "Prompt-and-align: Prompt-based Social Alignment For Few-shot Fake News Detection", "topic_distr": {"0": 0.11619240790605545, "1": 0.04501775652170181, "2": 0.2031889408826828, "3": 0.000665863452013582, "4": 0.07732129096984863, "5": 0.0005252632545307279, "6": 0.00047510501462966204, "7": 0.0004336911370046437, "8": 0.0003989183169323951, "9": 0.0003693077014759183, "10": 0.0003437891718931496, "11": 0.016884656623005867, "12": 0.0003020472649950534, "13": 0.00028475988074205816, "14": 0.0002693442511372268, "15": 0.24176372587680817, "16": 0.10021381825208664, "17": 0.19491593539714813, "18": 0.0002214014675701037, "19": 0.0002119689161190763}}, {"key": "wu2023q", "year": "2023", "title": "Q-instruct: Improving Low-level Visual Abilities For Multi-modality Foundation Models", "topic_distr": {"0": 0.19021256268024445, "1": 0.08322273939847946, "2": 0.05008441209793091, "3": 0.16570453345775604, "4": 0.0006324148271232843, "5": 0.021447520703077316, "6": 0.0005116327665746212, "7": 0.00046703481348231435, "8": 0.0004295885737519711, "9": 0.00039770136936567724, "10": 0.00037022086326032877, "11": 0.00034629268338903785, "12": 0.15147963166236877, "13": 0.00030665320809930563, "14": 0.0002900523832067847, "15": 0.00027515660622157156, "16": 0.000261716078966856, "17": 0.0002495274238754064, "18": 0.33308231830596924, "19": 0.000228265838813968}}, {"key": "wu2023survey", "year": "2023", "title": "A Survey On Large Language Models For Recommendation", "topic_distr": {"0": 0.0010141340317204595, "1": 0.0008281180635094643, "2": 0.0006999860052019358, "3": 0.1950477808713913, "4": 0.21729923784732819, "5": 0.00047824883949942887, "6": 0.00043258009827695787, "7": 0.0003948730300180614, "8": 0.0003632126026786864, "9": 0.13735418021678925, "10": 0.00031301783747039735, "11": 0.0002927868044935167, "12": 0.2913355231285095, "13": 0.00025927205570042133, "14": 0.0002452362095937133, "15": 0.028797978535294533, "16": 0.06800072640180588, "17": 0.05644848570227623, "18": 0.00020158462575636804, "19": 0.00019299636187497526}}, {"key": "wu2023unveiling", "year": "2023", "title": "Unveiling Security, Privacy, And Ethical Concerns Of Chatgpt", "topic_distr": {"0": 0.09161590784788132, "1": 0.1645190417766571, "2": 0.0011180202709510922, "3": 0.0009683814714662731, "4": 0.0008540754206478596, "5": 0.0007639072719030082, "6": 0.0006909606163389981, "7": 0.0006307311123237014, "8": 0.0005801598890684545, "9": 0.6134165525436401, "10": 0.0004999837256036699, "11": 0.00046766866580583155, "12": 0.00043927712249569595, "13": 0.00041413551662117243, "14": 0.0003917160793207586, "15": 0.12130875885486603, "16": 0.00035344786010682583, "17": 0.0003369871119502932, "18": 0.0003219913342036307, "19": 0.0003082732728216797}}, {"key": "wu2023visual", "year": "2023", "title": "Visual Chatgpt: Talking, Drawing And Editing With Visual Foundation Models", "topic_distr": {"0": 0.0010847856756299734, "1": 0.0008855791529640555, "2": 0.0007486888789571822, "3": 0.17784267663955688, "4": 0.05450234189629555, "5": 0.0005115277599543333, "6": 0.0004626810841728002, "7": 0.07083781808614731, "8": 0.01805700920522213, "9": 0.2503387928009033, "10": 0.03133086487650871, "11": 0.00031316030072048306, "12": 0.00029414874734357, "13": 0.0002773134328890592, "14": 0.00026230092043988407, "15": 0.0002488303289283067, "16": 0.00023667576897423714, "17": 0.00022565330436918885, "18": 0.3913327157497406, "19": 0.00020642596064135432}}, {"key": "wu2024continual", "year": "2024", "title": "Continual Learning For Large Language Models: A Survey", "topic_distr": {"0": 0.10623224824666977, "1": 0.0013580108061432838, "2": 0.0011479489039629698, "3": 0.3095930218696594, "4": 0.0008769101114012301, "5": 0.0007843312923796475, "6": 0.0007094342727214098, "7": 0.03855901584029198, "8": 0.0005956711247563362, "9": 0.0005514560616575181, "10": 0.0005133514059707522, "11": 0.07852939516305923, "12": 0.2146422564983368, "13": 0.11871030926704407, "14": 0.00040218906360678375, "15": 0.0003815344534814358, "16": 0.10915051400661469, "17": 0.00034599684295244515, "18": 0.00033060015994124115, "19": 0.016585784032940865}}, {"key": "xi2023rise", "year": "2023", "title": "The Rise And Potential Of Large Language Model Based Agents: A Survey", "topic_distr": {"0": 0.058892764151096344, "1": 0.0006365583394654095, "2": 0.0005381213850341737, "3": 0.09739279001951218, "4": 0.00041107030119746923, "5": 0.000367671629646793, "6": 0.0003325619618408382, "7": 0.00030357326613739133, "8": 0.0002792331506498158, "9": 0.2996850311756134, "10": 0.00024064407625701278, "11": 0.22109290957450867, "12": 0.3038155734539032, "13": 0.00019932500435970724, "14": 0.0001885344390757382, "15": 0.0001788521622074768, "16": 0.00017011580348480493, "17": 0.014971326105296612, "18": 0.0001549756561871618, "19": 0.00014837310300208628}}, {"key": "xi2023towards", "year": "2023", "title": "Towards Open-world Recommendation With Knowledge Augmentation From Large Language Models", "topic_distr": {"0": 0.0010402569314464927, "1": 0.05815776437520981, "2": 0.000717484625056386, "3": 0.2788282334804535, "4": 0.2465093582868576, "5": 0.0004902130458503962, "6": 0.0004434018337633461, "7": 0.00040475145215168595, "8": 0.0003722989931702614, "9": 0.0003446642658673227, "10": 0.01633388362824917, "11": 0.0003001113946083933, "12": 0.0002818920183926821, "13": 0.03997831046581268, "14": 0.00025137123884633183, "15": 0.028875896707177162, "16": 0.32604941725730896, "17": 0.00021625067165587097, "18": 0.00020662762108258903, "19": 0.00019782449817284942}}, {"key": "xia2020cg", "year": "2020", "title": "CG-BERT: Conditional Text Generation With BERT For Generalized Few-shot Intent Detection", "topic_distr": {"0": 0.0016849359963089228, "1": 0.1172211617231369, "2": 0.001163399196229875, "3": 0.0010076555190607905, "4": 0.0008887115982361138, "5": 0.0007948871934786439, "6": 0.3869953453540802, "7": 0.0006563100614584982, "8": 0.0006036879494786263, "9": 0.0005588778294622898, "10": 0.15754882991313934, "11": 0.00048663472989574075, "12": 0.0004570918099489063, "13": 0.0004309305804781616, "14": 0.0004076019104104489, "15": 0.32771965861320496, "16": 0.0003677817585412413, "17": 0.00035065345582552254, "18": 0.00033504952443763614, "19": 0.0003207751433365047}}, {"key": "xia2020cross", "year": "2020", "title": "XGPT: Cross-modal Generative Pre-training For Image Captioning", "topic_distr": {"0": 0.0017829207936301827, "1": 0.06679931282997131, "2": 0.12354593724012375, "3": 0.0010652542114257812, "4": 0.0009395111119374633, "5": 0.0008403206593357027, "6": 0.032800596207380295, "7": 0.06231148540973663, "8": 0.0006381930434145033, "9": 0.0005908216699026525, "10": 0.08604982495307922, "11": 0.000514449377078563, "12": 0.00048321785288862884, "13": 0.00045556132681667805, "14": 0.00043089926475659013, "15": 0.11354181915521622, "16": 0.000388803135138005, "17": 0.00037069577956572175, "18": 0.5061112642288208, "19": 0.00033910974161699414}}, {"key": "xia2020which", "year": "2020", "title": "Which *BERT? A Survey Organizing Contextualized Encoders", "topic_distr": {"0": 0.08798470348119736, "1": 0.0023144043516367674, "2": 0.0019566533155739307, "3": 0.0016947234980762005, "4": 0.0014946813462302089, "5": 0.0013368824729695916, "6": 0.0012092216638848186, "7": 0.001103816321119666, "8": 0.0010153137845918536, "9": 0.0009399497648701072, "10": 0.23474308848381042, "11": 0.0008184476173482835, "12": 0.4518071711063385, "13": 0.0007247614557854831, "14": 0.0006855261162854731, "15": 0.08312562853097916, "16": 0.0006185544771142304, "17": 0.0005897471564821899, "18": 0.0005635037086904049, "19": 0.12527327239513397}}, {"key": "xia2021using", "year": "2021", "title": "Using Prior Knowledge To Guide Bert's Attention In Semantic Textual Matching Tasks", "topic_distr": {"0": 0.001313361106440425, "1": 0.022331979125738144, "2": 0.4453307092189789, "3": 0.0007849798421375453, "4": 0.0006923156324774027, "5": 0.0006192247965373099, "6": 0.0005600940203294158, "7": 0.0005112718790769577, "8": 0.00047027875552885234, "9": 0.00043537124292925, "10": 0.2643084228038788, "11": 0.00037909316597506404, "12": 0.0003560789336916059, "13": 0.0003356990928296, "14": 0.0003175258170813322, "15": 0.0003012191446032375, "16": 0.22006560862064362, "17": 0.00027316241175867617, "18": 0.0002610068186186254, "19": 0.04035259038209915}}, {"key": "xia2022structured", "year": "2022", "title": "Structured Pruning Learns Compact And Accurate Models", "topic_distr": {"0": 0.0012218684423714876, "1": 0.0009984851349145174, "2": 0.4618113338947296, "3": 0.0007310423534363508, "4": 0.0006447509513236582, "5": 0.0005766823887825012, "6": 0.0005216140998527408, "7": 0.00047614617506042123, "8": 0.0004379693709779531, "9": 0.00040546010131947696, "10": 0.000377443473553285, "11": 0.00035304846824146807, "12": 0.00033161535975523293, "13": 0.5295392870903015, "14": 0.00029571098275482655, "15": 0.0002805246040225029, "16": 0.0002668218803592026, "17": 0.0002543954469729215, "18": 0.00024307497369591147, "19": 0.0002327190595678985}}, {"key": "xia2023conversational", "year": "2023", "title": "Conversational Automated Program Repair", "topic_distr": {"0": 0.0013277118559926748, "1": 0.0010833825217559934, "2": 0.0009158945758827031, "3": 0.7624924778938293, "4": 0.0006996365264058113, "5": 0.0006257724016904831, "6": 0.18208253383636475, "7": 0.0005166779737919569, "8": 0.00047525137779302895, "9": 0.0004399747704155743, "10": 0.00040957325836643577, "11": 0.0003831016074400395, "12": 0.00035984403803013265, "13": 0.00033924871240742505, "14": 0.0003208832931704819, "15": 0.0003044041804969311, "16": 0.04643131047487259, "17": 0.00027605079230852425, "18": 0.0002637666475493461, "19": 0.0002525291929487139}}, {"key": "xiang2023language", "year": "2023", "title": "Language Models Meet World Models: Embodied Experiences Enhance Language Models", "topic_distr": {"0": 0.0010241117561236024, "1": 0.0008349461131729186, "2": 0.050562482327222824, "3": 0.2786535620689392, "4": 0.0005391195300035179, "5": 0.010431710630655289, "6": 0.0004361564642749727, "7": 0.00039813766488805413, "8": 0.0003662155068013817, "9": 0.00033903232542797923, "10": 0.0003156057500746101, "11": 0.2556852400302887, "12": 0.00027728581335395575, "13": 0.07077248394489288, "14": 0.00024726372794248164, "15": 0.00023456539202015847, "16": 0.1536494642496109, "17": 0.0002127170591847971, "18": 0.00020325124205555767, "19": 0.17481665313243866}}, {"key": "xiao2018dual", "year": "2018", "title": "Dual Ask-answer Network For Machine Reading Comprehension", "topic_distr": {"0": 0.001313120243139565, "1": 0.001072002574801445, "2": 0.3956233263015747, "3": 0.000784912845119834, "4": 0.0006922628381289542, "5": 0.0006191774737089872, "6": 0.0005600512959063053, "7": 0.08683370053768158, "8": 0.2296523004770279, "9": 0.00043533797725103796, "10": 0.00040525684016756713, "11": 0.0003790642076637596, "12": 0.0003560517216101289, "13": 0.0003356734523549676, "14": 0.00031750157359056175, "15": 0.00030119612347334623, "16": 0.00028648367151618004, "17": 0.0002731415443122387, "18": 0.2795095443725586, "19": 0.0002498678513802588}}, {"key": "xiao2020ernie", "year": "2020", "title": "ERNIE-GEN: An Enhanced Multi-flow Pre-training And Fine-tuning Framework For Natural Language Generation", "topic_distr": {"0": 0.027439475059509277, "1": 0.025649653747677803, "2": 0.18209372460842133, "3": 0.0008984589949250221, "4": 0.0007924034725874662, "5": 0.01710282824933529, "6": 0.0006410665228031576, "7": 0.26594048738479614, "8": 0.05436909571290016, "9": 0.0004983125836588442, "10": 0.17216093838214874, "11": 0.00043389841448515654, "12": 0.0004075570323038846, "13": 0.04424149915575981, "14": 0.00036343035753816366, "15": 0.07275912165641785, "16": 0.10041038691997528, "17": 0.03321292623877525, "18": 0.00029874040046706796, "19": 0.00028601294616237283}}, {"key": "xiao2021hallucination", "year": "2021", "title": "On Hallucination And Predictive Uncertainty In Conditional Language Generation", "topic_distr": {"0": 0.3421018719673157, "1": 0.0015429826453328133, "2": 0.3051118850708008, "3": 0.001129825133830309, "4": 0.000996457994915545, "5": 0.06665423512458801, "6": 0.11600209772586823, "7": 0.1032857894897461, "8": 0.0006768784951418638, "9": 0.0006266356795094907, "10": 0.0005833361647091806, "11": 0.0005456338985823095, "12": 0.0005125091411173344, "13": 0.00048317620530724525, "14": 0.00045701919589191675, "15": 0.00043354876106604934, "16": 0.0004123712715227157, "17": 0.0003931663231924176, "18": 0.05769096687436104, "19": 0.0003596656315494329}}, {"key": "xiao2021pre", "year": "2021", "title": "Lawformer: A Pre-trained Language Model For Chinese Legal Long Documents", "topic_distr": {"0": 0.017731351777911186, "1": 0.0012573313433676958, "2": 0.0010629389435052872, "3": 0.0009206197573803365, "4": 0.0008119469275698066, "5": 0.0007262263679876924, "6": 0.0006568778189830482, "7": 0.000599619175773114, "8": 0.10045113414525986, "9": 0.303012490272522, "10": 0.2638113796710968, "11": 0.0004446000966709107, "12": 0.06423766165971756, "13": 0.0003937075671274215, "14": 0.00037239398807287216, "15": 0.1290874034166336, "16": 0.00033601344330236316, "17": 0.11348710209131241, "18": 0.0003061085590161383, "19": 0.0002930671616923064}}, {"key": "xiao2021training", "year": "2021", "title": "Training Large-scale News Recommenders With Pretrained Language Models In The Loop", "topic_distr": {"0": 0.0010063063818961382, "1": 0.027292786166071892, "2": 0.12438207864761353, "3": 0.03105401247739792, "4": 0.11958690732717514, "5": 0.00047442945651710033, "6": 0.0004291254444979131, "7": 0.0003917195135727525, "8": 0.00036031194031238556, "9": 0.070109523832798, "10": 0.1605668067932129, "11": 0.00029044857365079224, "12": 0.00027281581424176693, "13": 0.2124291956424713, "14": 0.0002432777255307883, "15": 0.1956930011510849, "16": 0.00021951102826278657, "17": 0.00020928795856889337, "18": 0.00019997474737465382, "19": 0.0547885037958622}}, {"key": "xiao2022accurate", "year": "2022", "title": "Smoothquant: Accurate And Efficient Post-training Quantization For Large Language Models", "topic_distr": {"0": 0.001640600967220962, "1": 0.001339880283921957, "2": 0.001132798264734447, "3": 0.3042285442352295, "4": 0.038338348269462585, "5": 0.0007739949505776167, "6": 0.0007000849582254887, "7": 0.0006390601047314703, "8": 0.0005878211231902242, "9": 0.0005441887187771499, "10": 0.0005065862205810845, "11": 0.0004738444113172591, "12": 0.0004450779524631798, "13": 0.6465376615524292, "14": 0.0003968888195231557, "15": 0.00037650641752406955, "16": 0.00035811527050100267, "17": 0.0003414371458347887, "18": 0.00032624334562569857, "19": 0.0003123441420029849}}, {"key": "xiao2022pre", "year": "2022", "title": "Retromae: Pre-training Retrieval-oriented Language Models Via Masked Auto-encoder", "topic_distr": {"0": 0.0014677505241706967, "1": 0.0011980741983279586, "2": 0.0010128881549462676, "3": 0.15447036921977997, "4": 0.0007737394771538675, "5": 0.0006920523592270911, "6": 0.0006259672809392214, "7": 0.0005714030703529716, "8": 0.04660264775156975, "9": 0.00048657567822374403, "10": 0.7245590686798096, "11": 0.0004236786626279354, "12": 0.033376868814229965, "13": 0.000375180970877409, "14": 0.00035487033892422915, "15": 0.00033664581133052707, "16": 0.00032020173966884613, "17": 0.0003052893152926117, "18": 0.0002917040837928653, "19": 0.031755004078149796}}, {"key": "xiao2022robotic", "year": "2022", "title": "Robotic Skill Acquisition Via Instruction Augmentation With Vision-language Models", "topic_distr": {"0": 0.018007420003414154, "1": 0.10635452717542648, "2": 0.0007898673648014665, "3": 0.0006841302383691072, "4": 0.0006033734534867108, "5": 0.0005396727356128395, "6": 0.0004881384375039488, "7": 0.0004455884627532214, "8": 0.0004098617355339229, "9": 0.0003794388030655682, "10": 0.0003532202390488237, "11": 0.4144737422466278, "12": 0.0003103332419414073, "13": 0.0002925716107711196, "14": 0.00027673307340592146, "15": 0.0002625213237479329, "16": 0.060961391776800156, "17": 0.10848938673734665, "18": 0.24922814965248108, "19": 0.03664994239807129}}, {"key": "xiao2023contrastive", "year": "2023", "title": "Contrastive Video Question Answering Via Video Graph Transformer", "topic_distr": {"0": 0.0326310433447361, "1": 0.000848850526381284, "2": 0.0007175476639531553, "3": 0.0006214556633494794, "4": 0.0005480966065078974, "5": 0.0004902317887172103, "6": 0.00044341885950416327, "7": 0.013208265416324139, "8": 0.09823135286569595, "9": 0.00034467747900635004, "10": 0.1267058402299881, "11": 0.0003001228906214237, "12": 0.000281902845017612, "13": 0.0002657683799043298, "14": 0.000251380872214213, "15": 0.00023847109696362168, "16": 0.1255401074886322, "17": 0.00021625896624755114, "18": 0.494123637676239, "19": 0.1039915606379509}}, {"key": "xiao2023efficient", "year": "2023", "title": "Efficient Streaming Language Models With Attention Sinks", "topic_distr": {"0": 0.0011245880741626024, "1": 0.0009175530285574496, "2": 0.4192695915699005, "3": 0.09307130426168442, "4": 0.028561566025018692, "5": 0.013057771138846874, "6": 0.0004793642438016832, "7": 0.07810861617326736, "8": 0.0004024945665150881, "9": 0.00037261846591718495, "10": 0.12762537598609924, "11": 0.00032445212127640843, "12": 0.00030475505627691746, "13": 0.23493413627147675, "14": 0.00027175885043106973, "15": 0.0002578025741968304, "16": 0.00024520972510799766, "17": 0.0002337898185942322, "18": 0.00022338629059959203, "19": 0.0002138691779691726}}, {"key": "xiao2023supporting", "year": "2023", "title": "Supporting Qualitative Analysis With Large Language Models: Combining Codebook With GPT-3 For Deductive Coding", "topic_distr": {"0": 0.00141801661811769, "1": 0.059363171458244324, "2": 0.0009783647255972028, "3": 0.4381599426269531, "4": 0.0007473502773791552, "5": 0.0006684499094262719, "6": 0.0006046185153536499, "7": 0.0005519152036868036, "8": 0.014851550571620464, "9": 0.3664138615131378, "10": 0.0004375060088932514, "11": 0.0004092290182597935, "12": 0.0003843852609861642, "13": 0.0003623853554017842, "14": 0.00034276742371730506, "15": 0.000325164437526837, "16": 0.0003092811966780573, "17": 0.11312049627304077, "18": 0.0002817554341163486, "19": 0.00026975158834829926}}, {"key": "xie2017neural", "year": "2017", "title": "Neural Text Generation: A Practical Guide", "topic_distr": {"0": 0.0016872083069756627, "1": 0.0013762930175289512, "2": 0.0011634582187980413, "3": 0.001007689512334764, "4": 0.0870920717716217, "5": 0.0007949132705107331, "6": 0.09392929822206497, "7": 0.4306115210056305, "8": 0.0006037074490450323, "9": 0.000558895873837173, "10": 0.16076131165027618, "11": 0.0004866504459641874, "12": 0.0004571065364871174, "13": 0.0004309444921091199, "14": 0.19511596858501434, "15": 0.0003866818151436746, "16": 0.00036779363290406764, "17": 0.0225126463919878, "18": 0.00033506035106256604, "19": 0.0003207855043001473}}, {"key": "xie2019visual", "year": "2019", "title": "Visual Entailment: A Novel Task For Fine-grained Image Understanding", "topic_distr": {"0": 0.09102562069892883, "1": 0.01658782921731472, "2": 0.10087423771619797, "3": 0.0007382952026091516, "4": 0.0006511464016512036, "5": 0.11316542327404022, "6": 0.0005267871310934424, "7": 0.00048086821334436536, "8": 0.10265517979860306, "9": 0.00040948111563920975, "10": 0.054859574884176254, "11": 0.00035654971725307405, "12": 0.0003349040634930134, "13": 0.00031573616433888674, "14": 0.00029864360112696886, "15": 0.0002833066100720316, "16": 0.00026946800062432885, "17": 0.0002569183416198939, "18": 0.5156750082969666, "19": 0.00023502697877120227}}, {"key": "xie2021explanation", "year": "2021", "title": "An Explanation Of In-context Learning As Implicit Bayesian Inference", "topic_distr": {"0": 0.15505541861057281, "1": 0.09027579426765442, "2": 0.0008785426034592092, "3": 0.0007609216845594347, "4": 0.0006711005116812885, "5": 0.0322614461183548, "6": 0.08817284554243088, "7": 0.0004956049961037934, "8": 0.0004558680229820311, "9": 0.0004220301634632051, "10": 0.07043831050395966, "11": 0.10704342275857925, "12": 0.0003451676166150719, "13": 0.05291367322206497, "14": 0.00030779591179452837, "15": 0.00029198889387771487, "16": 0.0002777261834125966, "17": 0.18688572943210602, "18": 0.0002530087949708104, "19": 0.21179361641407013}}, {"key": "xie2022unifying", "year": "2022", "title": "Unifiedskg: Unifying And Multi-tasking Structured Knowledge Grounding With Text-to-text Language Models", "topic_distr": {"0": 0.00141875387635082, "1": 0.0011576209217309952, "2": 0.0009785154834389687, "3": 0.41431567072868347, "4": 0.0007474665762856603, "5": 0.039422549307346344, "6": 0.0006047110073268414, "7": 0.04636896029114723, "8": 0.03963682800531387, "9": 0.0004700528224930167, "10": 0.018123861402273178, "11": 0.0004092916497029364, "12": 0.10170123726129532, "13": 0.0003624408273026347, "14": 0.0003428198688197881, "15": 0.000325214205076918, "16": 0.26712334156036377, "17": 0.00029492247267626226, "18": 0.0659259781241417, "19": 0.00026979288668371737}}, {"key": "xie2023empirical", "year": "2023", "title": "Empirical Study Of Zero-shot NER With Chatgpt", "topic_distr": {"0": 0.0011884571285918355, "1": 0.034820254892110825, "2": 0.17672032117843628, "3": 0.37803980708122253, "4": 0.0006263861432671547, "5": 0.0005602562450803816, "6": 0.0005067564779892564, "7": 0.0004625836154446006, "8": 0.00042549424688331783, "9": 0.07160666584968567, "10": 0.0003666923730634153, "11": 0.0003429922217037529, "12": 0.08216274529695511, "13": 0.00030373057234101, "14": 0.0002872879267670214, "15": 0.00027253414737060666, "16": 0.025747207924723625, "17": 0.22509759664535522, "18": 0.0002361512160860002, "19": 0.00022609028383158147}}, {"key": "xie2023prompt", "year": "2023", "title": "A Prompt Log Analysis Of Text-to-image Generation Systems", "topic_distr": {"0": 0.07099601626396179, "1": 0.1504668891429901, "2": 0.0007971900631673634, "3": 0.000690467597451061, "4": 0.06557458639144897, "5": 0.0005446713767014444, "6": 0.0004926597466692328, "7": 0.13815249502658844, "8": 0.08907382935285568, "9": 0.21854045987129211, "10": 0.0003564918879419565, "11": 0.0003334510256536305, "12": 0.12140875309705734, "13": 0.0002952814975287765, "14": 0.00027929627685807645, "15": 0.0002649528905749321, "16": 0.00025201079552061856, "17": 0.09186974167823792, "18": 0.049390990287065506, "19": 0.000219800989725627}}, {"key": "xie2023translating", "year": "2023", "title": "Translating Natural Language To Planning Goals With Large-language Models", "topic_distr": {"0": 0.06779869645833969, "1": 0.0009608755935914814, "2": 0.0008122243452817202, "3": 0.6909313797950745, "4": 0.0006204564706422389, "5": 0.04467533901333809, "6": 0.0005019586533308029, "7": 0.0004582039837259799, "8": 0.009537968784570694, "9": 0.02138454280793667, "10": 0.000363220606232062, "11": 0.08404969424009323, "12": 0.00031911939731799066, "13": 0.0003008549101650715, "14": 0.031030042096972466, "15": 0.0002699538308661431, "16": 0.0452827587723732, "17": 0.00024480928550474346, "18": 0.00023391538707073778, "19": 0.00022394971165340394}}, {"key": "xin2020dynamic", "year": "2020", "title": "Deebert: Dynamic Early Exiting For Accelerating BERT Inference", "topic_distr": {"0": 0.03648414462804794, "1": 0.0016166362911462784, "2": 0.14477571845054626, "3": 0.03231491521000862, "4": 0.0010439733741804957, "5": 0.0009337565861642361, "6": 0.0008445907733403146, "7": 0.0007709696074016392, "8": 0.0007091542356647551, "9": 0.0006565156509168446, "10": 0.4750737249851227, "11": 0.0005716514424420893, "12": 0.0005369472200982273, "13": 0.30111992359161377, "14": 0.0004788113001268357, "15": 0.0004542217357084155, "16": 0.000432034459663555, "17": 0.00041191375930793583, "18": 0.000393583788536489, "19": 0.0003768156166188419}}, {"key": "xin2023mmap", "year": "2023", "title": "Mmap : Multi-modal Alignment Prompt For Cross-domain Multi-task Learning", "topic_distr": {"0": 0.0011777615873143077, "1": 0.0499449148774147, "2": 0.0008123057195916772, "3": 0.0007035473827272654, "4": 0.0006204984383657575, "5": 0.0005549899651668966, "6": 0.0005019931122660637, "7": 0.00045823544496670365, "8": 0.0004214947111904621, "9": 0.0003902082971762866, "10": 0.0003632455482147634, "11": 0.0003397681866772473, "12": 0.0003191413125023246, "13": 0.08180159330368042, "14": 0.0002845874987542629, "15": 0.00026997237000614405, "16": 0.10293460637331009, "17": 0.30153360962867737, "18": 0.45634356141090393, "19": 0.00022396509302780032}}, {"key": "xin2023survey", "year": "2023", "title": "A Survey Of Large Language Models", "topic_distr": {"0": 0.000855320889968425, "1": 0.0006975671276450157, "2": 0.13877977430820465, "3": 0.13785365223884583, "4": 0.0004504796816036105, "5": 0.0004029207630082965, "6": 0.00036444520810618997, "7": 0.00033267730032093823, "8": 0.00030600366881117225, "9": 0.2110113799571991, "10": 0.0002637149882502854, "11": 0.00024667050456628203, "12": 0.22486881911754608, "13": 0.1654541939496994, "14": 0.00020660951850004494, "15": 0.11720915883779526, "16": 0.00018642506620381027, "17": 0.00017774288426153362, "18": 0.00016983340901788324, "19": 0.000162597862072289}}, {"key": "xing2016topic", "year": "2016", "title": "Topic Aware Neural Response Generation", "topic_distr": {"0": 0.09517114609479904, "1": 0.0010082843946292996, "2": 0.24144922196865082, "3": 0.0007383322226814926, "4": 0.027487987652420998, "5": 0.0005824330728501081, "6": 0.2507087290287018, "7": 0.33869075775146484, "8": 0.00044233680819161236, "9": 0.00040950332186184824, "10": 0.00038120735553093255, "11": 0.0003565690713003278, "12": 0.0003349222242832184, "13": 0.0003157532773911953, "14": 0.00029865981196053326, "15": 0.00028332200599834323, "16": 0.040603362023830414, "17": 0.0002569322823546827, "18": 0.00024549890076741576, "19": 0.00023503972624894232}}, {"key": "xing2021km", "year": "2021", "title": "KM-BART: Knowledge Enhanced Multimodal BART For Visual Commonsense Generation", "topic_distr": {"0": 0.0017554601654410362, "1": 0.001434234669432044, "2": 0.1458090990781784, "3": 0.0010502225486561656, "4": 0.0009262514067813754, "5": 0.0008284634677693248, "6": 0.0007493521552532911, "7": 0.1236417293548584, "8": 0.11468079686164856, "9": 0.000582484994083643, "10": 0.0005422362592071295, "11": 0.0005071902996860445, "12": 0.0004763994656968862, "13": 0.00044913319288752973, "14": 0.000424819125328213, "15": 0.0360119454562664, "16": 0.2117142677307129, "17": 0.00036546512274071574, "18": 0.27036190032958984, "19": 0.08768857270479202}}, {"key": "xing2022dual", "year": "2022", "title": "Dual Modality Prompt Tuning For Vision-language Pre-trained Model", "topic_distr": {"0": 0.0011236920254305005, "1": 0.000917503668460995, "2": 0.0007756681879982352, "3": 0.0006718139047734439, "4": 0.0005925102159380913, "5": 0.0005299564218148589, "6": 0.0004793500993400812, "7": 0.00043756619561463594, "8": 0.00040248269215226173, "9": 0.00037260749377310276, "10": 0.0003468609356787056, "11": 0.00032444254611618817, "12": 0.0003047460631933063, "13": 0.0002873042249120772, "14": 0.00027175084687769413, "15": 0.00025779494899325073, "16": 0.06849823147058487, "17": 0.45478978753089905, "18": 0.46840205788612366, "19": 0.00021386287698987871}}, {"key": "xiong2019pretrained", "year": "2019", "title": "Pretrained Encyclopedia: Weakly Supervised Knowledge-pretrained Language Model", "topic_distr": {"0": 0.022955289110541344, "1": 0.0012573669664561749, "2": 0.24682271480560303, "3": 0.0009206298273056746, "4": 0.0008119574631564319, "5": 0.0007262362632900476, "6": 0.0006568868411704898, "7": 0.0005996274412609637, "8": 0.039682742208242416, "9": 0.0005106099997647107, "10": 0.16890469193458557, "11": 0.0004446062375791371, "12": 0.0004176147631369531, "13": 0.00039371298043988645, "14": 0.00037239911034703255, "15": 0.0003532744012773037, "16": 0.2643754184246063, "17": 0.00032036902848631144, "18": 0.0003061127499677241, "19": 0.24916775524616241}}, {"key": "xiong2023can", "year": "2023", "title": "Can Llms Express Their Uncertainty? An Empirical Evaluation Of Confidence Elicitation In Llms", "topic_distr": {"0": 0.143717959523201, "1": 0.0007434660219587386, "2": 0.0006284588016569614, "3": 0.6535283923149109, "4": 0.0004800664901267737, "5": 0.0004293837700970471, "6": 0.00038838127511553466, "7": 0.00035452688462100923, "8": 0.0003261013771407306, "9": 0.07549045979976654, "10": 0.00028103525983169675, "11": 0.0002628713264130056, "12": 0.0687142163515091, "13": 0.00023278094886336476, "14": 0.00022017922310624272, "15": 0.00020887181744910777, "16": 0.053449247032403946, "17": 0.0001894166780402884, "18": 0.00018098772852681577, "19": 0.00017327695968560874}}, {"key": "xiong2023fine", "year": "2023", "title": "Doctorglm: Fine-tuning Your Chinese Doctor Is Not A Herculean Task", "topic_distr": {"0": 0.0627322793006897, "1": 0.001498000230640173, "2": 0.0012662310618907213, "3": 0.37543782591819763, "4": 0.046566665172576904, "5": 0.06077203527092934, "6": 0.0007825292414054275, "7": 0.0007143178954720497, "8": 0.000657044758554548, "9": 0.10483047366142273, "10": 0.00056624342687428, "11": 0.0005296458257362247, "12": 0.19622842967510223, "13": 0.10627207905054092, "14": 0.03922965005040169, "15": 0.000420844997279346, "16": 0.0004002880596090108, "17": 0.00038164586294442415, "18": 0.0003646627883426845, "19": 0.0003491267852950841}}, {"key": "xiong2024benchmarking", "year": "2024", "title": "Benchmarking Retrieval-augmented Generation For Medicine", "topic_distr": {"0": 0.039570316672325134, "1": 0.0009698978974483907, "2": 0.0008199968724511564, "3": 0.26907259225845337, "4": 0.000626385968644172, "5": 0.0005602555465884507, "6": 0.0005067558377049863, "7": 0.00046258303336799145, "8": 0.1747482866048813, "9": 0.00039391047903336585, "10": 0.000366691907402128, "11": 0.0003429918142501265, "12": 0.1948380321264267, "13": 0.100661501288414, "14": 0.00028728757752105594, "15": 0.1386391818523407, "16": 0.00025922138593159616, "17": 0.0764118954539299, "18": 0.00023615092504769564, "19": 0.00022609000734519213}}, {"key": "xu2018d", "year": "2018", "title": "D-PAGE: Diverse Paraphrase Generation", "topic_distr": {"0": 0.0018634834559634328, "1": 0.02944342792034149, "2": 0.2769739329814911, "3": 0.0011129551567137241, "4": 0.047163136303424835, "5": 0.0008779538911767304, "6": 0.0007941165240481496, "7": 0.2591434121131897, "8": 0.0006667739362455904, "9": 0.0006172810681164265, "10": 0.0005746280075982213, "11": 0.0005374884931370616, "12": 0.0005048583261668682, "13": 0.0004759632283821702, "14": 0.07158743590116501, "15": 0.30614525079727173, "16": 0.0004062152875121683, "17": 0.0003872970410156995, "18": 0.0003700625093188137, "19": 0.0003542964404914528}}, {"key": "xu2018dp", "year": "2018", "title": "DP-GAN: Diversity-promoting Generative Adversarial Network For Generating Informative And Diversified Text", "topic_distr": {"0": 0.001708345371298492, "1": 0.03723404183983803, "2": 0.1101032942533493, "3": 0.0010214766953140497, "4": 0.0009009024943225086, "5": 0.0008057905361056328, "6": 0.1785246729850769, "7": 0.31633928418159485, "8": 0.0006119685131125152, "9": 0.0005665437201969326, "10": 0.0005273965070955455, "11": 0.05615537613630295, "12": 0.01636897400021553, "13": 0.0004368414811324328, "14": 0.0004131928435526788, "15": 0.27688878774642944, "16": 0.0003728264709934592, "17": 0.00035546321305446327, "18": 0.00033964525209739804, "19": 0.00032517508952878416}}, {"key": "xu2018multi", "year": "2018", "title": "Multi-task Learning With Sample Re-weighting For Machine Reading Comprehension", "topic_distr": {"0": 0.0023980841506272554, "1": 0.0019590072333812714, "2": 0.5121728181838989, "3": 0.001433909754268825, "4": 0.0012646481627598405, "5": 0.0011311336420476437, "6": 0.0010231201304122806, "7": 0.0009339368552900851, "8": 0.0008590549696236849, "9": 0.0007952896412461996, "10": 0.19620086252689362, "11": 0.0006924868794158101, "12": 0.0006504469201900065, "13": 0.0006132192211225629, "14": 0.1272890716791153, "15": 0.14862734079360962, "16": 0.0005233577103354037, "17": 0.0004989838926121593, "18": 0.0004767793579958379, "19": 0.00045646674698218703}}, {"key": "xu2018towards", "year": "2018", "title": "Towards Explainable And Controllable Open Domain Dialogue Generation With Dialogue Acts", "topic_distr": {"0": 0.029715584591031075, "1": 0.00185156159568578, "2": 0.0015653049340471625, "3": 0.001355743850581348, "4": 0.20127761363983154, "5": 0.16611121594905853, "6": 0.268390953540802, "7": 0.0736328586935997, "8": 0.0008122310973703861, "9": 0.000751941348426044, "10": 0.0006999835022725165, "11": 0.24972254037857056, "12": 0.0006149935070425272, "13": 0.0005797949270345271, "14": 0.0005484073772095144, "15": 0.000520243716891855, "16": 0.0004948314162902534, "17": 0.0004717861593235284, "18": 0.00045079190749675035, "19": 0.0004315864644013345}}, {"key": "xu2019forget", "year": "2019", "title": "Forget Me Not: Reducing Catastrophic Forgetting For Domain Adaptation In Reading Comprehension", "topic_distr": {"0": 0.02864961512386799, "1": 0.1676568239927292, "2": 0.4442991018295288, "3": 0.0008772772853262722, "4": 0.0007737226551398635, "5": 0.0006920379237271845, "6": 0.0006259541842155159, "7": 0.0005713910795748234, "8": 0.0005255776923149824, "9": 0.0004865654918830842, "10": 0.0004529446305241436, "11": 0.00042366981506347656, "12": 0.13109959661960602, "13": 0.0003751731419470161, "14": 0.0003548629174474627, "15": 0.00033663876820355654, "16": 0.17995627224445343, "17": 0.04127178713679314, "18": 0.00029169797198846936, "19": 0.0002792705490719527}}, {"key": "xu2019review", "year": "2019", "title": "Review Conversational Reading Comprehension", "topic_distr": {"0": 0.002266124589368701, "1": 0.03733118250966072, "2": 0.2585446238517761, "3": 0.0013557187048718333, "4": 0.0011956884991377592, "5": 0.0010694528464227915, "6": 0.22934295237064362, "7": 0.0008830091683194041, "8": 0.14420484006404877, "9": 0.0007519224309362471, "10": 0.0991716980934143, "11": 0.026685209944844246, "12": 0.19370019435882568, "13": 0.0005797803169116378, "14": 0.0005483935819938779, "15": 0.0005202305619604886, "16": 0.0004948189598508179, "17": 0.00047177428496070206, "18": 0.00045078055700287223, "19": 0.0004315755795687437}}, {"key": "xu2020bert", "year": "2020", "title": "Bert-of-theseus: Compressing BERT By Progressive Module Replacing", "topic_distr": {"0": 0.001784309046342969, "1": 0.0014548392500728369, "2": 0.2902226746082306, "3": 0.0010653362842276692, "4": 0.14299276471138, "5": 0.0008403898100368679, "6": 0.0007601397228427231, "7": 0.0006938799633644521, "8": 0.018856439739465714, "9": 0.0005908703315071762, "10": 0.14786392450332642, "11": 0.000514491752255708, "12": 0.0004832576378248632, "13": 0.3536398112773895, "14": 0.0004309347423259169, "15": 0.000408803898608312, "16": 0.036333080381155014, "17": 0.00037072630948387086, "18": 0.00035422915243543684, "19": 0.00033913765219040215}}, {"key": "xu2020edit", "year": "2020", "title": "EDITOR: An Edit-based Transformer With Repositioning For Neural Machine Translation With Soft Lexical Constraints", "topic_distr": {"0": 0.0016865357756614685, "1": 0.0013762670569121838, "2": 0.13612094521522522, "3": 0.0010077119804918766, "4": 0.040974441915750504, "5": 0.000794932886492461, "6": 0.0007190235191956162, "7": 0.37171027064323425, "8": 0.0006037226412445307, "9": 0.000558909960091114, "10": 0.1925017386674881, "11": 0.04012501239776611, "12": 0.0004571180616039783, "13": 0.00043095534783788025, "14": 0.14808641374111176, "15": 0.00038669153582304716, "16": 0.0003678028879221529, "17": 0.06143563613295555, "18": 0.00033506876206956804, "19": 0.0003207935660611838}}, {"key": "xu2020incorporating", "year": "2020", "title": "Incorporating External Knowledge Through Pre-training For Natural Language To Code Generation", "topic_distr": {"0": 0.0021134349517524242, "1": 0.05901359021663666, "2": 0.0014592071529477835, "3": 0.0012638772604987025, "4": 0.0011146855540573597, "5": 0.08214294910430908, "6": 0.5519101619720459, "7": 0.0008231910178437829, "8": 0.05413814261555672, "9": 0.0007009845576249063, "10": 0.0006525476928800344, "11": 0.0006103721098043025, "12": 0.0005733172292821109, "13": 0.0005405039410106838, "14": 0.1334238201379776, "15": 0.0004849883262068033, "16": 0.1077718511223793, "17": 0.0004398146120365709, "18": 0.0004202430718578398, "19": 0.00040233912295661867}}, {"key": "xu2020megatron", "year": "2020", "title": "MEGATRON-CNTRL: Controllable Story Generation With External Knowledge Using Large-scale Language Models", "topic_distr": {"0": 0.00140148785430938, "1": 0.0011444872943684459, "2": 0.21684542298316956, "3": 0.0008378187194466591, "4": 0.0007389200036413968, "5": 0.0006609089323319495, "6": 0.0005977976834401488, "7": 0.5009194016456604, "8": 0.019435612484812737, "9": 0.0004646789457183331, "10": 0.0004325704067014158, "11": 0.00040461242315359414, "12": 0.0003800489357672632, "13": 0.08931037038564682, "14": 0.0003389005723875016, "15": 0.0003214961907360703, "16": 0.1649285852909088, "17": 0.0002915507648140192, "18": 0.00027857691748067737, "19": 0.00026670846273191273}}, {"key": "xu2020multi", "year": "2020", "title": "Layoutlmv2: Multi-modal Pre-training For Visually-rich Document Understanding", "topic_distr": {"0": 0.0016195757780224085, "1": 0.001322450116276741, "2": 0.0011180242290720344, "3": 0.0009683443931862712, "4": 0.0008540417184121907, "5": 0.0007638765382580459, "6": 0.0006909328512847424, "7": 0.0006307057337835431, "8": 0.0005801365477964282, "9": 0.0005370745784603059, "10": 0.7046659588813782, "11": 0.0004676498647313565, "12": 0.0004392594564706087, "13": 0.0004141188692301512, "14": 0.00039170030504465103, "15": 0.00037158437771722674, "16": 0.00035343365743756294, "17": 0.00033697354956530035, "18": 0.28316593170166016, "19": 0.00030826087458990514}}, {"key": "xu2020recipes", "year": "2020", "title": "Recipes For Safety In Open-domain Chatbots", "topic_distr": {"0": 0.5224382281303406, "1": 0.0014759564073756337, "2": 0.15375851094722748, "3": 0.0010806836653500795, "4": 0.05490836873650551, "5": 0.05759201943874359, "6": 0.0007710872450843453, "7": 0.000703873229213059, "8": 0.0006474375841207802, "9": 0.0005993800587020814, "10": 0.0005579639109782875, "11": 0.0005219014128670096, "12": 0.0004902174696326256, "13": 0.04184951260685921, "14": 0.00043714107596315444, "15": 0.1317138522863388, "16": 0.029374493286013603, "17": 0.00037606549449265003, "18": 0.0003593307628761977, "19": 0.0003440219152253121}}, {"key": "xu2020user", "year": "2020", "title": "User Memory Reasoning For Conversational Recommendation", "topic_distr": {"0": 0.001450009411200881, "1": 0.0011841454543173313, "2": 0.06740562617778778, "3": 0.0008670861134305596, "4": 0.47048696875572205, "5": 0.1462700068950653, "6": 0.0006186810205690563, "7": 0.0005647519137710333, "8": 0.000519470835570246, "9": 0.00048091192729771137, "10": 0.0004476817266549915, "11": 0.0004187470767647028, "12": 0.0003933254920411855, "13": 0.036811113357543945, "14": 0.0003507396613713354, "15": 0.00033272727159783244, "16": 0.27053192257881165, "17": 0.00030173573759384453, "18": 0.0002883086563088, "19": 0.0002760256174951792}}, {"key": "xu2021beyond", "year": "2021", "title": "Beyond Goldfish Memory: Long-term Open-domain Conversation", "topic_distr": {"0": 0.12270224094390869, "1": 0.0015433115186169744, "2": 0.5101088881492615, "3": 0.0011298598255962133, "4": 0.11666350066661835, "5": 0.00089128443505615, "6": 0.24036520719528198, "7": 0.0007359014707617462, "8": 0.0006768978200852871, "9": 0.0006266535492613912, "10": 0.0005833528703078628, "11": 0.0005456494400277734, "12": 0.0005125238094478846, "13": 0.00048319000052288175, "14": 0.00045703223440796137, "15": 0.00043356113019399345, "16": 0.00041238305857405066, "17": 0.0003931775572709739, "18": 0.0003756813530344516, "19": 0.0003596759052015841}}, {"key": "xu2021end", "year": "2021", "title": "E2E-VLP: End-to-end Vision-language Pre-training Enhanced By Visual Learning", "topic_distr": {"0": 0.0015015625394880772, "1": 0.04183228686451912, "2": 0.0010372884571552277, "3": 0.0008984339656308293, "4": 0.0007923833909444511, "5": 0.0007087280391715467, "6": 0.0006410504574887455, "7": 0.0005851714522577822, "8": 0.0005382531671784818, "9": 0.0004983000690117478, "10": 0.23682275414466858, "11": 0.0004338875296525657, "12": 0.0004075468168593943, "13": 0.0003842212609015405, "14": 0.00036342121893540025, "15": 0.08894427120685577, "16": 0.0003279172524344176, "17": 0.0003126454830635339, "18": 0.6226838827133179, "19": 0.00028600575751625}}, {"key": "xu2021gradual", "year": "2021", "title": "Gradual Fine-tuning For Low-resource Domain Adaptation", "topic_distr": {"0": 0.00445316219702363, "1": 0.003639289177954197, "2": 0.5545570254325867, "3": 0.0026629860512912273, "4": 0.002348648849874735, "5": 0.0021006923634558916, "6": 0.0019000940956175327, "7": 0.001734467106871307, "8": 0.001595399691723287, "9": 0.0014769774861633778, "10": 0.001374920830130577, "11": 0.0012860565911978483, "12": 0.0012079818407073617, "13": 0.001138844178058207, "14": 0.001077192253433168, "15": 0.0010218725074082613, "16": 0.0009719572844915092, "17": 0.4137192666530609, "18": 0.0008854540064930916, "19": 0.0008477303199470043}}, {"key": "xu2021human", "year": "2021", "title": "Human Parity On Commonsenseqa: Augmenting Self-attention With External Attention", "topic_distr": {"0": 0.0012748325243592262, "1": 0.001039393013343215, "2": 0.41757214069366455, "3": 0.0007608752348460257, "4": 0.056940119713544846, "5": 0.0006002114969305694, "6": 0.0005428963340818882, "7": 0.0004955732147209346, "8": 0.05457891896367073, "9": 0.1135500892996788, "10": 0.0003928433870896697, "11": 0.00036745305988006294, "12": 0.13277418911457062, "13": 0.0003253913891967386, "14": 0.00030777615029364824, "15": 0.0002919701801147312, "16": 0.21742534637451172, "17": 0.00026477492065168917, "18": 0.00025299255503341556, "19": 0.00024221412604674697}}, {"key": "xu2021multimodal", "year": "2021", "title": "Layoutxlm: Multimodal Pre-training For Multilingual Visually-rich Document Understanding", "topic_distr": {"0": 0.0019493189174681902, "1": 0.0015918510034680367, "2": 0.0301889069378376, "3": 0.0011652701068669558, "4": 0.001027716789394617, "5": 0.0009192173019982874, "6": 0.0008314398000948131, "7": 0.0007589649758301675, "8": 0.0888836607336998, "9": 0.0006462931632995605, "10": 0.0006016353727318347, "11": 0.0005627503851428628, "12": 0.16081611812114716, "13": 0.0004983334220014513, "14": 0.10194206982851028, "15": 0.00044714915566146374, "16": 0.0004253073420841247, "17": 0.18299607932567596, "18": 0.4233769476413727, "19": 0.00037094831350259483}}, {"key": "xu2021raise", "year": "2021", "title": "Raise A Child In Large Language Model: Towards Effective And Generalizable Fine-tuning", "topic_distr": {"0": 0.0018087272765114903, "1": 0.0014759984333068132, "2": 0.4309569299221039, "3": 0.0010806843638420105, "4": 0.0009531156974844635, "5": 0.000852491648402065, "6": 0.0007710859645158052, "7": 0.0007038720650598407, "8": 0.0006474364781752229, "9": 0.000599379010964185, "10": 0.0005579629796557128, "11": 0.0005219005979597569, "12": 0.0004902167129330337, "13": 0.1903349906206131, "14": 0.000437140348367393, "15": 0.00041469078860245645, "16": 0.0003944344643969089, "17": 0.26817113161087036, "18": 0.0003593301516957581, "19": 0.09846851974725723}}, {"key": "xu2021stacked", "year": "2021", "title": "Stacked Acoustic-and-textual Encoding: Integrating The Pre-trained Models Into Speech Translation Encoders", "topic_distr": {"0": 0.018340229988098145, "1": 0.1013093888759613, "2": 0.18747936189174652, "3": 0.0007609302410855889, "4": 0.037927404046058655, "5": 0.0006002557347528636, "6": 0.0005429364391602576, "7": 0.0004956098273396492, "8": 0.00045587244676426053, "9": 0.0004220342671032995, "10": 0.30548813939094543, "11": 0.00036748021375387907, "12": 0.0003451709635555744, "13": 0.06906209886074066, "14": 0.1680561900138855, "15": 0.00029199174605309963, "16": 0.10729486495256424, "17": 0.0002647944784257561, "18": 0.00025301126879639924, "19": 0.00024223202490247786}}, {"key": "xu2021study", "year": "2021", "title": "BERT, Mbert, Or Bibert? A Study On Contextualized Embeddings For Neural Machine Translation", "topic_distr": {"0": 0.0014510552864521742, "1": 0.0011842446401715279, "2": 0.0010011167032644153, "3": 0.0008670968818478286, "4": 0.0007647416787222028, "5": 0.10059641301631927, "6": 0.0006186882383190095, "7": 0.0005647584912367165, "8": 0.000519476889166981, "9": 0.05028100311756134, "10": 0.269753634929657, "11": 0.00041875193710438907, "12": 0.0003933300613425672, "13": 0.00037081819027662277, "14": 0.3520186245441437, "15": 0.0003327311424072832, "16": 0.05225902423262596, "17": 0.08337436616420746, "18": 0.0002883120032493025, "19": 0.08294183760881424}}, {"key": "xu2021task", "year": "2021", "title": "VLM: Task-agnostic Video-language Model Pre-training For Video Understanding", "topic_distr": {"0": 0.0018899762071669102, "1": 0.0015431311912834644, "2": 0.24568593502044678, "3": 0.0011299427133053541, "4": 0.0009965570643544197, "5": 0.0008913471829146147, "6": 0.000806230993475765, "7": 0.0007359535666182637, "8": 0.0006769457249902189, "9": 0.0006266979034990072, "10": 0.12506014108657837, "11": 0.0005456880899146199, "12": 0.0005125600728206336, "13": 0.0004832241975236684, "14": 0.0004570645687635988, "15": 0.00043359180563129485, "16": 0.00041241224971599877, "17": 0.00039320538053289056, "18": 0.5189809203147888, "19": 0.09773848205804825}}, {"key": "xu2022building", "year": "2022", "title": "Bridgetower: Building Bridges Between Encoders In Vision-language Representation Learning", "topic_distr": {"0": 0.0014007885474711657, "1": 0.001144333160482347, "2": 0.1464872509241104, "3": 0.0008378211641684175, "4": 0.0007389247184619308, "5": 0.0006609131814911962, "6": 0.000597801641561091, "7": 0.0005456925719045103, "8": 0.0005019396194256842, "9": 0.0004646820016205311, "10": 0.36002275347709656, "11": 0.00040461510070599616, "12": 0.00038005143869668245, "13": 0.12890280783176422, "14": 0.00033890281338244677, "15": 0.0003214983153156936, "16": 0.0003057941503357142, "17": 0.0002915527147706598, "18": 0.3553851246833801, "19": 0.0002667102380655706}}, {"key": "xu2022exploring", "year": "2022", "title": "Exploring The Universal Vulnerability Of Prompt-based Learning Paradigm", "topic_distr": {"0": 0.001919357804581523, "1": 0.24342502653598785, "2": 0.001324512530118227, "3": 0.3733973503112793, "4": 0.0010117946658283472, "5": 0.0009049754007719457, "6": 0.0008185579790733755, "7": 0.0007472060387954116, "8": 0.0006872960366308689, "9": 0.0006362799322232604, "10": 0.0005923140561208129, "11": 0.0005540314596146345, "12": 0.0005203969776630402, "13": 0.0004906125250272453, "14": 0.00046405295142903924, "15": 0.0004402213089633733, "16": 0.0004187178856227547, "17": 0.37090060114860535, "18": 0.0003814523806795478, "19": 0.0003652010636869818}}, {"key": "xu2022long", "year": "2022", "title": "Long Time No See! Open-domain Conversation With Long-term Persona Memory", "topic_distr": {"0": 0.13397958874702454, "1": 0.001414614380337298, "2": 0.2602361738681793, "3": 0.001035684603266418, "4": 0.12087547034025192, "5": 0.1421193927526474, "6": 0.16552872955799103, "7": 0.0006745572900399566, "8": 0.0006204721285030246, "9": 0.0005744161899201572, "10": 0.0005347249680198729, "11": 0.0005001645185984671, "12": 0.00046980020124465227, "13": 0.0004429116379469633, "14": 0.0004189343599136919, "15": 0.00039741978980600834, "16": 0.16914249956607819, "17": 0.00036040256964042783, "18": 0.00034436481655575335, "19": 0.0003296935756225139}}, {"key": "xu2022survey", "year": "2022", "title": "A Survey On Model Compression And Acceleration For Pretrained Language Models", "topic_distr": {"0": 0.002311458345502615, "1": 0.0018860267009586096, "2": 0.0015943881589919329, "3": 0.0013809445081278682, "4": 0.0012179400073364377, "5": 0.0372772254049778, "6": 0.000985333463177085, "7": 0.0008994441013783216, "8": 0.0008273277780972421, "9": 0.09161379933357239, "10": 0.057713042944669724, "11": 0.000666911480948329, "12": 0.33033281564712524, "13": 0.32692307233810425, "14": 0.000558600528165698, "15": 0.000529913289938122, "16": 0.0005040287505835295, "17": 0.05404408276081085, "18": 0.0004591706383507699, "19": 0.0882745087146759}}, {"key": "xu2022systematic", "year": "2022", "title": "A Systematic Evaluation Of Large Language Models Of Code", "topic_distr": {"0": 0.0014187883352860808, "1": 0.0011575036915019155, "2": 0.0009783984860405326, "3": 0.2649376094341278, "4": 0.0007473844452761114, "5": 0.0006684798281639814, "6": 0.3492700457572937, "7": 0.0005519400001503527, "8": 0.014137716963887215, "9": 0.00047000200720503926, "10": 0.0004375256539788097, "11": 0.0004092473827768117, "12": 0.17793330550193787, "13": 0.04062260687351227, "14": 0.04905768483877182, "15": 0.00032517904764972627, "16": 0.0003092950792051852, "17": 0.00029489060398191214, "18": 0.0002817680942825973, "19": 0.0959906280040741}}, {"key": "xu2023bridging", "year": "2023", "title": "Bridging Vision And Language Encoders: Parameter-efficient Tuning For Referring Image Segmentation", "topic_distr": {"0": 0.002012193202972412, "1": 0.0016425985377281904, "2": 0.19608551263809204, "3": 0.0012027857592329383, "4": 0.0010608003940433264, "5": 0.0009488078067079186, "6": 0.0008582043810747564, "7": 0.0007833965355530381, "8": 0.0007205848232842982, "9": 0.0006670977454632521, "10": 0.06004226952791214, "11": 0.0005808656569570303, "12": 0.0005456020589917898, "13": 0.22883330285549164, "14": 0.0004865290829911828, "15": 0.00046154315350577235, "16": 0.0004389982495922595, "17": 0.21330736577510834, "18": 0.28893864154815674, "19": 0.00038288935320451856}}, {"key": "xu2023chatgpt", "year": "2023", "title": "Chatgpt Vs. Google: A Comparative Study Of Search Performance And User Experience", "topic_distr": {"0": 0.2333219200372696, "1": 0.0008558228728361428, "2": 0.022051170468330383, "3": 0.140574648976326, "4": 0.0005526819732040167, "5": 0.0004943326348438859, "6": 0.00044712808448821306, "7": 0.0004081529041286558, "8": 0.09558950364589691, "9": 0.5031775832176208, "10": 0.0003235448675695807, "11": 0.0003026334452442825, "12": 0.00028426098288036883, "13": 0.00026799156330525875, "14": 0.0002534837112762034, "15": 0.00024046593171078712, "16": 0.0002287199313286692, "17": 0.00021806798758916557, "18": 0.0002083640720229596, "19": 0.00019948696717619896}}, {"key": "xu2023comprehensive", "year": "2023", "title": "Superclue: A Comprehensive Chinese Large Language Model Benchmark", "topic_distr": {"0": 0.15877853333950043, "1": 0.0011192203965038061, "2": 0.0009462268208153546, "3": 0.26935845613479614, "4": 0.18211743235588074, "5": 0.01571512408554554, "6": 0.0005847702268511057, "7": 0.0005337970796972513, "8": 0.08141160011291504, "9": 0.0004545524425338954, "10": 0.0004231436469126493, "11": 0.0003957949229516089, "12": 0.22724005579948425, "13": 0.000350489019183442, "14": 0.00033151512616313994, "15": 0.05912154167890549, "16": 0.000299128150800243, "17": 0.0002851971657946706, "18": 0.00027250603307038546, "19": 0.00026089625316672027}}, {"key": "xu2023empowering", "year": "2023", "title": "Wizardlm: Empowering Large Language Models To Follow Complex Instructions", "topic_distr": {"0": 0.12713073194026947, "1": 0.11880289763212204, "2": 0.029855255037546158, "3": 0.671875, "4": 0.0006711007445119321, "5": 0.0006002502632327378, "6": 0.0005429314915090799, "7": 0.000495605287142098, "8": 0.0004558683140203357, "9": 0.04650183394551277, "10": 0.00039286885294131935, "11": 0.00036747686681337655, "12": 0.0003451678203418851, "13": 0.00032541248947381973, "14": 0.0003077960864175111, "15": 0.0002919890685006976, "16": 0.0002777263580355793, "17": 0.00026479209191165864, "18": 0.0002530089404899627, "19": 0.00024222981301136315}}, {"key": "xu2023how", "year": "2023", "title": "How To Unleash The Power Of Large Language Models For Few-shot Relation Extraction?", "topic_distr": {"0": 0.0017835877370089293, "1": 0.08508367091417313, "2": 0.0012300090165808797, "3": 0.2612796127796173, "4": 0.0009395810193382204, "5": 0.0008403862011618912, "6": 0.000760136463213712, "7": 0.0006938770529814065, "8": 0.0006382428691722453, "9": 0.0005908678285777569, "10": 0.0005500398110598326, "11": 0.0005144895403645933, "12": 0.0752946212887764, "13": 0.0004555968916974962, "14": 0.0004309329087845981, "15": 0.2110447883605957, "16": 0.00038883346132934093, "17": 0.3567873537540436, "18": 0.0003542276390362531, "19": 0.0003391361969988793}}, {"key": "xu2023instructing", "year": "2023", "title": "Expertprompting: Instructing Large Language Models To Be Distinguished Experts", "topic_distr": {"0": 0.0016857029404491186, "1": 0.159238800406456, "2": 0.0011634139809757471, "3": 0.40946078300476074, "4": 0.0008887251606211066, "5": 0.0007948983111418784, "6": 0.17665676772594452, "7": 0.0006563192582689226, "8": 0.0671478807926178, "9": 0.0005588856874965131, "10": 0.0005202676402404904, "11": 0.1497771441936493, "12": 0.0004570982127916068, "13": 0.0004309366340748966, "14": 0.0004076076438650489, "15": 0.028780533000826836, "16": 0.0003677869390230626, "17": 0.00035065837437286973, "18": 0.00033505423925817013, "19": 0.0003207796544302255}}, {"key": "xu2023interpretable", "year": "2023", "title": "Drivegpt4: Interpretable End-to-end Autonomous Driving Via Large Language Model", "topic_distr": {"0": 0.016801944002509117, "1": 0.042540114372968674, "2": 0.0008697386365383863, "3": 0.2975774109363556, "4": 0.000664378225337714, "5": 0.12166249752044678, "6": 0.000537492276635021, "7": 0.0004906402318738401, "8": 0.00045130131184123456, "9": 0.13614287972450256, "10": 0.00038893299642950296, "11": 0.024619758129119873, "12": 0.06257890909910202, "13": 0.0003221524239052087, "14": 0.00030471253558062017, "15": 0.00028906387160532176, "16": 0.0002749440318439156, "17": 0.0002621393359731883, "18": 0.29298117756843567, "19": 0.00023980310652405024}}, {"key": "xu2023large", "year": "2023", "title": "Large Language Models For Generative Information Extraction: A Survey", "topic_distr": {"0": 0.001386363641358912, "1": 0.0011316629825159907, "2": 0.0009566008229739964, "3": 0.2566086947917938, "4": 0.0007307527121156454, "5": 0.0006536042201332748, "6": 0.0005911905318498611, "7": 0.0005396577180363238, "8": 0.0004963886458426714, "9": 0.0004595430800691247, "10": 0.00042778943316079676, "11": 0.00040014044498093426, "12": 0.45548123121261597, "13": 0.0003543371276464313, "14": 0.0003351548803038895, "15": 0.21345488727092743, "16": 0.06516440957784653, "17": 0.0002883284178096801, "18": 0.00027549793594516814, "19": 0.00026376068126410246}}, {"key": "xu2023mental", "year": "2023", "title": "Mental-llm: Leveraging Large Language Models For Mental Health Prediction Via Online Text Data", "topic_distr": {"0": 0.06491667777299881, "1": 0.22081124782562256, "2": 0.0006778901442885399, "3": 0.5494154095649719, "4": 0.0005178356659598649, "5": 0.00046316569205373526, "6": 0.0004189371829852462, "7": 0.00038241935544647276, "8": 0.0003517574805300683, "9": 0.07354891300201416, "10": 0.00030314575997181237, "11": 0.009920603595674038, "12": 0.07675734162330627, "13": 0.00025109504349529743, "14": 0.0002375018666498363, "15": 0.00022530484420713037, "16": 0.0002142994198948145, "17": 0.00020431907614693046, "18": 0.0001952269667526707, "19": 0.00018690957222133875}}, {"key": "xu2023mplug", "year": "2023", "title": "Mplug-2: A Modularized Multi-modal Foundation Model Across Text, Image And Video", "topic_distr": {"0": 0.001312894280999899, "1": 0.0010721903527155519, "2": 0.11377260088920593, "3": 0.11036956310272217, "4": 0.0006923716282472014, "5": 0.0006192748551256955, "6": 0.0005601394223049283, "7": 0.0005113132647238672, "8": 0.013768048956990242, "9": 0.0004354064876679331, "10": 0.0004053206357639283, "11": 0.0003791238705161959, "12": 0.0003561077464837581, "13": 0.00033572627580724657, "14": 0.00031755154486745596, "15": 0.07205108553171158, "16": 0.0002865287533495575, "17": 0.0002731845306698233, "18": 0.5781459808349609, "19": 0.10433562099933624}}, {"key": "xu2023parameter", "year": "2023", "title": "Parameter-efficient Fine-tuning Methods For Pretrained Language Models: A Critical Review And Assessment", "topic_distr": {"0": 0.001123656751587987, "1": 0.0009174986043944955, "2": 0.0007756415870971978, "3": 0.000671823276206851, "4": 0.0005925192381255329, "5": 0.0005299649201333523, "6": 0.00047935775364749134, "7": 0.00043757318053394556, "8": 0.00040248912409879267, "9": 0.14442576467990875, "10": 0.022285273298621178, "11": 0.014254589565098286, "12": 0.23840400576591492, "13": 0.4044440984725952, "14": 0.00027175521245226264, "15": 0.0002577990817371756, "16": 0.00024520643637515604, "17": 0.16904376447200775, "18": 0.00022338327835313976, "19": 0.00021386629668995738}}, {"key": "xu2023understanding", "year": "2023", "title": "Understanding And Detecting Hallucinations In Neural Machine Translation Via Model Introspection", "topic_distr": {"0": 0.4691135287284851, "1": 0.0016982087399810553, "2": 0.001435026410035789, "3": 0.0012429147027432919, "4": 0.0010961975203827024, "5": 0.0009804681176319718, "6": 0.0008868416771292686, "7": 0.2088417410850525, "8": 0.0007446298841387033, "9": 0.0006893580430187285, "10": 0.1641242504119873, "11": 0.0006002484587952495, "12": 0.0005638081929646432, "13": 0.000531539146322757, "14": 0.145279198884964, "15": 0.0004769443185068667, "16": 0.00045364710967987776, "17": 0.00043251985334791243, "18": 0.00041327293729409575, "19": 0.00039566593477502465}}, {"key": "xu2024survey", "year": "2024", "title": "A Survey Of Resource-efficient LLM And Multimodal Foundation Models", "topic_distr": {"0": 0.03879670798778534, "1": 0.001242081867530942, "2": 0.0010500093922019005, "3": 0.08690694719552994, "4": 0.0008020861423574388, "5": 0.0007174061029218137, "6": 0.0006488998187705874, "7": 0.0005923365824855864, "8": 0.000544843846000731, "9": 0.2891940474510193, "10": 0.03582972288131714, "11": 0.00043920028838329017, "12": 0.3360142707824707, "13": 0.09897477924823761, "14": 0.0003678711655084044, "15": 0.00034897896694019437, "16": 0.00033193244598805904, "17": 0.0003164736845064908, "18": 0.10659192502498627, "19": 0.00028950776322744787}}, {"key": "xu2024when", "year": "2024", "title": "When Large Language Model Agents Meet 6G Networks: Perception, Grounding, And Alignment", "topic_distr": {"0": 0.0009528834489174187, "1": 0.0007774121477268636, "2": 0.09300852566957474, "3": 0.0005692671984434128, "4": 0.059820111840963364, "5": 0.04850511625409126, "6": 0.0004061818472109735, "7": 0.0003707758442033082, "8": 0.00034104750375263393, "9": 0.3679449260234833, "10": 0.00029391588759608567, "11": 0.1264948546886444, "12": 0.00025822946918196976, "13": 0.07411324232816696, "14": 0.0002302706561749801, "15": 0.0002184449986089021, "16": 0.09596965461969376, "17": 0.0001980981760425493, "18": 0.1293458193540573, "19": 0.00018121872562915087}}, {"key": "xue2020massively", "year": "2020", "title": "Mt5: A Massively Multilingual Pre-trained Text-to-text Transformer", "topic_distr": {"0": 0.0025460089091211557, "1": 0.0020790710113942623, "2": 0.07577233016490936, "3": 0.0015219347551465034, "4": 0.0013422801857814193, "5": 0.0012005713069811463, "6": 0.09328632801771164, "7": 0.0009912688983604312, "8": 0.0009117902372963727, "9": 0.0008441105019301176, "10": 0.34253957867622375, "11": 0.0007349969237111509, "12": 0.0006903762114234269, "13": 0.0006508632213808596, "14": 0.34454816579818726, "15": 0.04405668005347252, "16": 0.0005554853705689311, "17": 0.0847376212477684, "18": 0.0005060476833023131, "19": 0.00048448811867274344}}, {"key": "xue2021advancing", "year": "2021", "title": "Advancing High-resolution Video-language Representation With Large-scale Video Transcriptions", "topic_distr": {"0": 0.0014341650530695915, "1": 0.09651737660169601, "2": 0.0009896632982417941, "3": 0.04340290650725365, "4": 0.0007559880032204092, "5": 0.0006761748227290809, "6": 0.0006116057629697025, "7": 0.07480194419622421, "8": 0.0005135301616974175, "9": 0.0004754121764563024, "10": 0.1463017761707306, "11": 0.00041395824518986046, "12": 0.0003888273786287755, "13": 0.0003665732219815254, "14": 0.00034672857145778835, "15": 0.00032892217859625816, "16": 0.00031285537988878787, "17": 0.00029828507103957236, "18": 0.6307904720306396, "19": 0.0002728689578361809}}, {"key": "xue2021towards", "year": "2021", "title": "Byt5: Towards A Token-free Future With Pre-trained Byte-to-byte Models", "topic_distr": {"0": 0.0014848237624391913, "1": 0.25606027245521545, "2": 0.3016735017299652, "3": 0.0008877406944520772, "4": 0.0007829482783563435, "5": 0.0007002895581535995, "6": 0.0006334178033284843, "7": 0.0005782041698694229, "8": 0.0005318445037119091, "9": 0.0004923670785501599, "10": 0.32078856229782104, "11": 0.00042872148333117366, "12": 0.00040269436431117356, "13": 0.07310853153467178, "14": 0.0003590941778384149, "15": 0.0398763008415699, "16": 0.00032401291537098587, "17": 0.00030892298673279583, "18": 0.00029517608345486224, "19": 0.0002826004638336599}}, {"key": "xue2023bias", "year": "2023", "title": "Bias And Fairness In Chatbots: An Overview", "topic_distr": {"0": 0.2408355325460434, "1": 0.0012424011947587132, "2": 0.0010499191703274846, "3": 0.0009093710104934871, "4": 0.0008020294480957091, "5": 0.09302937239408493, "6": 0.0006488540675491095, "7": 0.0005922948475927114, "8": 0.0005448053707368672, "9": 0.4039594233036041, "10": 0.00046951512922532856, "11": 0.0004391693219076842, "12": 0.15612463653087616, "13": 0.09739565849304199, "14": 0.00036784520489163697, "15": 0.00034895434509962797, "16": 0.00033190904650837183, "17": 0.0003164513618685305, "18": 0.00030236944439820945, "19": 0.0002894873614422977}}, {"key": "xue2023ulip", "year": "2023", "title": "ULIP-2: Towards Scalable Multimodal Pre-training For 3D Understanding", "topic_distr": {"0": 0.0010754442773759365, "1": 0.1911521852016449, "2": 0.000742184289265424, "3": 0.0006428137421607971, "4": 0.0005669341189786792, "5": 0.0005070805782452226, "6": 0.00045865861466154456, "7": 0.000418678333517164, "8": 0.00038510921876877546, "9": 0.00035652361111715436, "10": 0.00033188844099640846, "11": 0.00031043775379657745, "12": 0.0002915914810728282, "13": 0.0002749025297816843, "14": 0.00026002051890827715, "15": 0.0002466670412104577, "16": 0.00023461815726477653, "17": 0.23537440598011017, "18": 0.5661652088165283, "19": 0.00020463133114390075}}, {"key": "yagcioglu2018challenge", "year": "2018", "title": "Recipeqa: A Challenge Dataset For Multimodal Comprehension Of Cooking Recipes", "topic_distr": {"0": 0.001892049447633326, "1": 0.1324377954006195, "2": 0.12191222608089447, "3": 0.0011299587786197662, "4": 0.0009965739445760846, "5": 0.0008913599886000156, "6": 0.0008062422857619822, "7": 0.0007359638693742454, "8": 0.0006769552128389478, "9": 0.0006267066928558052, "10": 0.0005834022886119783, "11": 0.0005456957151181996, "12": 0.13061465322971344, "13": 0.00048323094961233437, "14": 0.06820118427276611, "15": 0.0004335978883318603, "16": 0.036914318799972534, "17": 0.0003932108811568469, "18": 0.4993651509284973, "19": 0.0003597063769120723}}, {"key": "yager2023domain", "year": "2023", "title": "Domain-specific Chatbots For Science Using Embeddings", "topic_distr": {"0": 0.0016413390403613448, "1": 0.0013406929792836308, "2": 0.001133070094510913, "3": 0.0009813657961785793, "4": 0.08319836109876633, "5": 0.0007741438457742333, "6": 0.0007002195925451815, "7": 0.05115608498454094, "8": 0.12520162761211395, "9": 0.4279782474040985, "10": 0.08713048696517944, "11": 0.00047393544809892774, "12": 0.14031848311424255, "13": 0.00041968494770117104, "14": 0.00039696507155895233, "15": 0.00037657874054275453, "16": 0.04978480935096741, "17": 0.00034150274586863816, "18": 0.026340050622820854, "19": 0.00031240415410138667}}, {"key": "yamada2021efficient", "year": "2021", "title": "Efficient Passage Retrieval With Hashing For Open-domain Question Answering", "topic_distr": {"0": 0.0015020897844806314, "1": 0.001226933323778212, "2": 0.0010373152326792479, "3": 0.0008984416490420699, "4": 0.0007923896191641688, "5": 0.000708733918145299, "6": 0.24969077110290527, "7": 0.0005851761670783162, "8": 0.32053112983703613, "9": 0.0004983040853403509, "10": 0.00046387212933041155, "11": 0.000433891051216051, "12": 0.0004075501055922359, "13": 0.23918262124061584, "14": 0.0003634241584222764, "15": 0.00034476033761166036, "16": 0.00032791990088298917, "17": 0.06277681887149811, "18": 0.0002987353364005685, "19": 0.1179291382431984}}, {"key": "yan2023generative", "year": "2023", "title": "Generative Artificial Intelligence In Learning Analytics: Contextualising Opportunities And Challenges Through The Learning Analytics Cycle", "topic_distr": {"0": 0.18071633577346802, "1": 0.10937438160181046, "2": 0.0009062762255780399, "3": 0.0007849758258089423, "4": 0.0006923177279531956, "5": 0.0006192268338054419, "6": 0.000560095882974565, "7": 0.0005112735670991242, "8": 0.00047028029803186655, "9": 0.6417184472084045, "10": 0.0004052891454193741, "11": 0.0003790944174397737, "12": 0.0003560800978448242, "13": 0.00033570019877515733, "14": 0.00031752686481922865, "15": 0.00030122013413347304, "16": 0.0002865064889192581, "17": 0.00027316331397742033, "18": 0.06074189767241478, "19": 0.0002498877584002912}}, {"key": "yan2023human", "year": "2023", "title": "Human-ai Collaboration In Thematic Analysis Using Chatgpt: A User Study And Design Recommendations", "topic_distr": {"0": 0.0013150559971109033, "1": 0.0010722725419327617, "2": 0.05054245516657829, "3": 0.2099439948797226, "4": 0.07727470248937607, "5": 0.0006192562868818641, "6": 0.0005601225420832634, "7": 0.000511297897901386, "8": 0.0004703026788774878, "9": 0.6121653914451599, "10": 0.00040530841215513647, "11": 0.0003791124327108264, "12": 0.00035609703627415, "13": 0.042695194482803345, "14": 0.0003175419697072357, "15": 0.00030123445321805775, "16": 0.00028652010951191187, "17": 0.00027317629428580403, "18": 0.0002610200899653137, "19": 0.00024989963276311755}}, {"key": "yan2023multimodal", "year": "2023", "title": "Multimodal Chatgpt For Medical Applications: An Experimental Study Of GPT-4V", "topic_distr": {"0": 0.08961685746908188, "1": 0.0013225460425019264, "2": 0.0011180973378941417, "3": 0.28053972125053406, "4": 0.0008541214629076421, "5": 0.000763948482926935, "6": 0.0006909977528266609, "7": 0.0006307650473900139, "8": 0.09090286493301392, "9": 0.0005371251027099788, "10": 0.0005000106175430119, "11": 0.0004676938406191766, "12": 0.21541744470596313, "13": 0.0004141578101553023, "14": 0.00039173715049400926, "15": 0.0003716193023137748, "16": 0.00035346689401194453, "17": 0.00033700524363666773, "18": 0.3144615590572357, "19": 0.00030828986200504005}}, {"key": "yan2023practical", "year": "2023", "title": "Practical And Ethical Challenges Of Large Language Models In Education: A Systematic Scoping Review", "topic_distr": {"0": 0.11086717247962952, "1": 0.06305278092622757, "2": 0.0006888528587296605, "3": 0.0005966330645605922, "4": 0.0412549264729023, "5": 0.0004706478212028742, "6": 0.00042570469668135047, "7": 0.00038859693449921906, "8": 0.0003574397414922714, "9": 0.5975911021232605, "10": 0.0003080427704844624, "11": 0.0002881332766264677, "12": 0.08037320524454117, "13": 0.00025515121524222195, "14": 0.00024133846454788, "15": 0.03748723864555359, "16": 0.06475713104009628, "17": 0.00020761963969562203, "18": 0.00019838065782096237, "19": 0.00018992889090441167}}, {"key": "yang2019data", "year": "2019", "title": "Data Augmentation For BERT Fine-tuning In Open-domain Question Answering", "topic_distr": {"0": 0.0018071033991873264, "1": 0.201427161693573, "2": 0.3907850980758667, "3": 0.0010806421050801873, "4": 0.0009530793176963925, "5": 0.0008524592849425972, "6": 0.0007710565696470439, "7": 0.0007038452313281596, "8": 0.19716446101665497, "9": 0.0005993561935611069, "10": 0.10412061214447021, "11": 0.0005218806327320635, "12": 0.0004901979700662196, "13": 0.00046214196481741965, "14": 0.0004371236718725413, "15": 0.06696394830942154, "16": 0.00039441941771656275, "17": 0.029762132093310356, "18": 0.000359316443791613, "19": 0.000344008207321167}}, {"key": "yang2019making", "year": "2019", "title": "Making History Matter: History-advantage Sequence Training For Visual Dialog", "topic_distr": {"0": 0.03076602704823017, "1": 0.000870490272063762, "2": 0.1635696291923523, "3": 0.0006373688811436296, "4": 0.30453965067863464, "5": 0.0005027843290008605, "6": 0.09756048023700714, "7": 0.00041513112955726683, "8": 0.030746128410100937, "9": 0.00035350301186554134, "10": 0.04940195009112358, "11": 0.12421496212482452, "12": 0.00028912100242450833, "13": 0.00027257343754172325, "14": 0.00025781753356568515, "15": 0.000244577182456851, "16": 0.00023263038019649684, "17": 0.0002217963192379102, "18": 0.1947004646062851, "19": 0.00020289761596359313}}, {"key": "yang2019model", "year": "2019", "title": "Model Compression With Two-stage Multi-teacher Knowledge Distillation For Web Question Answering System", "topic_distr": {"0": 0.04825179651379585, "1": 0.0009886979823932052, "2": 0.10859105736017227, "3": 0.0007239864789880812, "4": 0.0006385250017046928, "5": 0.0005711127887479961, "6": 0.0005165762850083411, "7": 0.0004715474497061223, "8": 0.1275157928466797, "9": 0.0004015440645162016, "10": 0.09139396250247955, "11": 0.00034963866346515715, "12": 0.00032841257052496076, "13": 0.5166060328483582, "14": 0.0002928549365606159, "15": 0.0002778152411337942, "16": 0.10135751217603683, "17": 0.0002519384433981031, "18": 0.00024072729866020381, "19": 0.00023047139984555542}}, {"key": "yang2019towards", "year": "2019", "title": "Towards Making The Most Of BERT In Neural Machine Translation", "topic_distr": {"0": 0.001523315440863371, "1": 0.0012420983985066414, "2": 0.0010500018252059817, "3": 0.0009094289853237569, "4": 0.0008020787499845028, "5": 0.0007173999911174178, "6": 0.0006488944636657834, "7": 0.0005923316930420697, "8": 0.0005448393058031797, "9": 0.0005043973797000945, "10": 0.14207176864147186, "11": 0.08969786018133163, "12": 0.00041253361268900335, "13": 0.14396004378795624, "14": 0.3732038140296936, "15": 0.0003489760565571487, "16": 0.1883164346218109, "17": 0.0003164710651617497, "18": 0.0003023882454726845, "19": 0.05283491313457489}}, {"key": "yang2020generative", "year": "2020", "title": "Generative Data Augmentation For Commonsense Reasoning", "topic_distr": {"0": 0.0012473625829443336, "1": 0.40843307971954346, "2": 0.2047508955001831, "3": 0.09056657552719116, "4": 0.0006576513405889273, "5": 0.0005882204277440906, "6": 0.00053205038420856, "7": 0.00048567267367616296, "8": 0.0004467320686671883, "9": 0.00041357235750183463, "10": 0.000384995189961046, "11": 0.0003601121134124696, "12": 0.025573832914233208, "13": 0.00031889075762592256, "14": 0.00030162741313688457, "15": 0.04968355596065521, "16": 0.04486981779336929, "17": 0.1699000746011734, "18": 0.0002479382965248078, "19": 0.00023737519222777337}}, {"key": "yang2020intent", "year": "2020", "title": "IART: Intent-aware Response Ranking With Transformers In Information-seeking Conversation Systems", "topic_distr": {"0": 0.10627146810293198, "1": 0.0009796015219762921, "2": 0.15982791781425476, "3": 0.000717054819688201, "4": 0.17793624103069305, "5": 0.0005656474968418479, "6": 0.3570312261581421, "7": 0.0004670349881052971, "8": 0.03252898156642914, "9": 0.0003977015148848295, "10": 0.14606569707393646, "11": 0.0003462927998043597, "12": 0.0003252698224969208, "13": 0.00030665332451462746, "14": 0.0002900524705182761, "15": 0.014965246431529522, "16": 0.0002617161662783474, "17": 0.0002495275402907282, "18": 0.00023842367227189243, "19": 0.00022826591157354414}}, {"key": "yang2020just", "year": "2020", "title": "Just Ask: Learning To Answer Questions From Millions Of Narrated Videos", "topic_distr": {"0": 0.049470335245132446, "1": 0.16466708481311798, "2": 0.14748220145702362, "3": 0.0007382809417322278, "4": 0.0006511328974738717, "5": 0.0005823904066346586, "6": 0.0005267769447527826, "7": 0.07054472714662552, "8": 0.20096556842327118, "9": 0.0004094731993973255, "10": 0.06675086170434952, "11": 0.0003565428196452558, "12": 0.000334897602442652, "13": 0.0003157300525344908, "14": 0.00029863783856853843, "15": 0.00028330113855190575, "16": 0.0002694627910386771, "17": 0.0002569133648648858, "18": 0.2948606610298157, "19": 0.0002350224240217358}}, {"key": "yang2020text", "year": "2020", "title": "TAP: Text-aware Pre-training For Text-vqa And Text-caption", "topic_distr": {"0": 0.0012723937397822738, "1": 0.0010392700787633657, "2": 0.19692116975784302, "3": 0.024372080340981483, "4": 0.0006710937013849616, "5": 0.0006002439185976982, "6": 0.0005429256125353277, "7": 0.05699766427278519, "8": 0.02197849005460739, "9": 0.0004220258560962975, "10": 0.1549435555934906, "11": 0.000367472879588604, "12": 0.00034516409505158663, "13": 0.000325408938806504, "14": 0.00030779276858083904, "15": 0.0002919859252870083, "16": 0.0002777233312372118, "17": 0.00026478921063244343, "18": 0.5378164649009705, "19": 0.00024222719366662204}}, {"key": "yang2020towards", "year": "2020", "title": "UBAR: Towards Fully End-to-end Task-oriented Dialog Systems With GPT-2", "topic_distr": {"0": 0.1547616422176361, "1": 0.0009987771045416594, "2": 0.2013285607099533, "3": 0.0007310982909984887, "4": 0.3436279296875, "5": 0.0005767237162217498, "6": 0.1730780452489853, "7": 0.0004761801101267338, "8": 0.00043800059938803315, "9": 0.0004054890014231205, "10": 0.040694255381822586, "11": 0.00035307364305481315, "12": 0.00033163902116939425, "13": 0.05855616554617882, "14": 0.0002957320539280772, "15": 0.0002805445983540267, "16": 0.022335940971970558, "17": 0.00025441357865929604, "18": 0.00024309230502694845, "19": 0.00023273564875125885}}, {"key": "yang2021causal", "year": "2021", "title": "Causal Attention For Vision-language Tasks", "topic_distr": {"0": 0.14564450085163116, "1": 0.0014150486094877124, "2": 0.5841009020805359, "3": 0.0010357366409152746, "4": 0.0009134775609709322, "5": 0.0008170382352545857, "6": 0.0007390179671347141, "7": 0.000674599374178797, "8": 0.000620510836597532, "9": 0.0005744520458392799, "10": 0.07096266746520996, "11": 0.0005001957179047167, "12": 0.0004698295088019222, "13": 0.08875159919261932, "14": 0.0004189605242572725, "15": 0.00039744461537338793, "16": 0.040543083101511, "17": 0.0003604250669013709, "18": 0.06073085591197014, "19": 0.0003297141520306468}}, {"key": "yang2021empirical", "year": "2021", "title": "An Empirical Study Of GPT-3 For Few-shot Knowledge-based VQA", "topic_distr": {"0": 0.0009457736159674823, "1": 0.0007716340478509665, "2": 0.2208377867937088, "3": 0.10686924308538437, "4": 0.0004982688114978373, "5": 0.00044566471478901803, "6": 0.000403107434976846, "7": 0.02086152508854866, "8": 0.11603232473134995, "9": 0.0003133426944259554, "10": 0.0002916912198998034, "11": 0.0002728385734371841, "12": 0.00025627491413615644, "13": 0.00024160726752597839, "14": 0.0002285277150804177, "15": 0.00021679156634490937, "16": 0.17651070654392242, "17": 0.07780200988054276, "18": 0.2760210931301117, "19": 0.00017984707665164024}}, {"key": "yang2021unifying", "year": "2021", "title": "Unitab: Unifying Text And Box Outputs For Grounded Vision-language Modeling", "topic_distr": {"0": 0.0009756185463629663, "1": 0.0007957658963277936, "2": 0.1945781409740448, "3": 0.0005826008855365217, "4": 0.0005138283595442772, "5": 0.0004595817590598017, "6": 0.00041569548193365335, "7": 0.2213757187128067, "8": 0.00034903554478660226, "9": 0.000323127576848492, "10": 0.07702650874853134, "11": 0.0002813586324919015, "12": 0.0002642777399159968, "13": 0.00024915204267017543, "14": 0.00023566406161990017, "15": 0.00022356143745128065, "16": 0.00021264117094688118, "17": 0.00020273803966119885, "18": 0.5007495284080505, "19": 0.00018546325736679137}}, {"key": "yang2022generating", "year": "2022", "title": "Re3: Generating Longer Stories With Recursive Reprompting And Revision", "topic_distr": {"0": 0.02778170444071293, "1": 0.0016166205750778317, "2": 0.13826072216033936, "3": 0.0011837240308523178, "4": 0.10269058495759964, "5": 0.0009337739320471883, "6": 0.1697680503129959, "7": 0.3750186562538147, "8": 0.029068483039736748, "9": 0.0006565276416949928, "10": 0.0006111626862548292, "11": 0.0005716618616133928, "12": 0.0005369570571929216, "13": 0.0005062248092144728, "14": 0.0004788200603798032, "15": 0.00045423005940392613, "16": 0.06888849288225174, "17": 0.08020317554473877, "18": 0.0003935909771826118, "19": 0.00037682251422666013}}, {"key": "yang2022grouping", "year": "2022", "title": "Gtrans: Grouping And Fusing Transformer Layers For Neural Machine Translation", "topic_distr": {"0": 0.0016421355539932847, "1": 0.001339997397735715, "2": 0.001132903154939413, "3": 0.0009812243515625596, "4": 0.0008654006524011493, "5": 0.0007740368018858135, "6": 0.11391075700521469, "7": 0.0006390945636667311, "8": 0.0005878527881577611, "9": 0.0005442180554382503, "10": 0.4709572494029999, "11": 0.0004738699644804001, "12": 0.00044510196312330663, "13": 0.0004196269728709012, "14": 0.27632936835289, "15": 0.00037652673199772835, "16": 0.1276005506515503, "17": 0.00034145553945563734, "18": 0.00032626092433929443, "19": 0.00031236099312081933}}, {"key": "yang2022prompt", "year": "2022", "title": "Prompt Tuning For Generative Multimodal Pretrained Models", "topic_distr": {"0": 0.0012744232080876827, "1": 0.07430870831012726, "2": 0.0008786140824668109, "3": 0.0007609734893776476, "4": 0.014050080440938473, "5": 0.0006002909503877163, "6": 0.0005429682205431163, "7": 0.000495638872962445, "8": 0.00045589919318445027, "9": 0.0004220590344630182, "10": 0.0003928954538423568, "11": 0.00036750175058841705, "12": 0.0745709240436554, "13": 0.0003254345210734755, "14": 0.0003078169538639486, "15": 0.043170735239982605, "16": 0.0002777451591100544, "17": 0.4939410090446472, "18": 0.13166028261184692, "19": 0.1611960381269455}}, {"key": "yang2022vision", "year": "2022", "title": "Vision-language Pre-training With Triple Contrastive Learning", "topic_distr": {"0": 0.0012003451120108366, "1": 0.0009794390061870217, "2": 0.3240267336368561, "3": 0.0007170242606662214, "4": 0.0006323840352706611, "5": 0.0005656203720718622, "6": 0.0005116083775646985, "7": 0.0360797680914402, "8": 0.017408156767487526, "9": 0.0003976824227720499, "10": 0.00037020325544290245, "11": 0.04666066914796829, "12": 0.000325254222843796, "13": 0.00030663859797641635, "14": 0.0002900385588873178, "15": 0.0002751434803940356, "16": 0.06090829148888588, "17": 0.00024951554951258004, "18": 0.5078672766685486, "19": 0.0002282549685332924}}, {"key": "yang2022zero", "year": "2022", "title": "Zero-shot Video Question Answering Via Frozen Bidirectional Language Models", "topic_distr": {"0": 0.0013264388544484973, "1": 0.09941396862268448, "2": 0.15592913329601288, "3": 0.0007932529551908374, "4": 0.000699615222401917, "5": 0.0006257544155232608, "6": 0.0005660001188516617, "7": 0.000516663130838424, "8": 0.11040939390659332, "9": 0.00043996211024932563, "10": 0.18871571123600006, "11": 0.00038309060619212687, "12": 0.00035983367706649005, "13": 0.00033923896262422204, "14": 0.00032087406725622714, "15": 0.0003043954202439636, "16": 0.00028952668071724474, "17": 0.20922183990478516, "18": 0.2290927767753601, "19": 0.00025252194609493017}}, {"key": "yang2023adaptive", "year": "2023", "title": "ALIP: Adaptive Language-image Pre-training With Synthetic Caption", "topic_distr": {"0": 0.0012736873468384147, "1": 0.25431954860687256, "2": 0.0008785193786025047, "3": 0.0007609088206663728, "4": 0.0006710909074172378, "5": 0.0006002410664223135, "6": 0.0005429231678135693, "7": 0.0004955977201461792, "8": 0.0004558612999971956, "9": 0.0004220239643473178, "10": 0.0003928628284484148, "11": 0.00036747122067026794, "12": 0.032009806483983994, "13": 0.14115063846111298, "14": 0.0003077913715969771, "15": 0.00029198461561463773, "16": 0.1334386020898819, "17": 0.0002647880173753947, "18": 0.43111342191696167, "19": 0.00024222610227297992}}, {"key": "yang2023baichuan", "year": "2023", "title": "Baichuan 2: Open Large-scale Language Models", "topic_distr": {"0": 0.0021869416814297438, "1": 0.0017869217554107308, "2": 0.0015103706391528249, "3": 0.19114448130130768, "4": 0.0011537569807842374, "5": 0.0010319509310647845, "6": 0.000933408155106008, "7": 0.0008520449628122151, "8": 0.0007837290759198368, "9": 0.11138974130153656, "10": 0.0006754203932359815, "11": 0.0006317664519883692, "12": 0.23254147171974182, "13": 0.3489440977573395, "14": 0.07775472849607468, "15": 0.0005019878153689206, "16": 0.0004774673143401742, "17": 0.00045523070730268955, "18": 0.024828024208545685, "19": 0.00041644167504273355}}, {"key": "yang2023enhancing", "year": "2023", "title": "Zhongjing: Enhancing The Chinese Medical Capabilities Of Large Language Model Through Expert Feedback And Real-world Multi-turn Dialogue", "topic_distr": {"0": 0.0010144212283194065, "1": 0.06284012645483017, "2": 0.0006999672623351216, "3": 0.30586498975753784, "4": 0.030667155981063843, "5": 0.08451775461435318, "6": 0.04425234720110893, "7": 0.00039487500907853246, "8": 0.00036321443622000515, "9": 0.0003362540155649185, "10": 0.000313019409077242, "11": 0.05572119355201721, "12": 0.19810989499092102, "13": 0.0911862701177597, "14": 0.0002452374610584229, "15": 0.12264645099639893, "16": 0.00022127928968984634, "17": 0.00021097387070767581, "18": 0.00020158564439043403, "19": 0.00019299732230138034}}, {"key": "yang2023generative", "year": "2023", "title": "Generative Speech Recognition Error Correction With Large Language Models And Task-activating Prompting", "topic_distr": {"0": 0.0019187589641660452, "1": 0.001566958730109036, "2": 0.0013245443115010858, "3": 0.3887068033218384, "4": 0.027717100456357002, "5": 0.0009049655636772513, "6": 0.000818548898678273, "7": 0.000747197715099901, "8": 0.0006872883532196283, "9": 0.000636272830888629, "10": 0.0005923074204474688, "11": 0.10674897581338882, "12": 0.0005203911568969488, "13": 0.02947968617081642, "14": 0.00046404777094721794, "15": 0.03658291697502136, "16": 0.0004187132290098816, "17": 0.3691987693309784, "18": 0.0003814481315203011, "19": 0.030584240332245827}}, {"key": "yang2023give", "year": "2023", "title": "Give Us The Facts: Enhancing Large Language Models With Knowledge Graphs For Fact-aware Language Modeling", "topic_distr": {"0": 0.0011142757721245289, "1": 0.0009092438849620521, "2": 0.0007686854223720729, "3": 0.2302723228931427, "4": 0.0005871885223314166, "5": 0.0005251967813819647, "6": 0.05823662504553795, "7": 0.0004336362180765718, "8": 0.00039886782178655267, "9": 0.2536799907684326, "10": 0.00034374563256278634, "11": 0.0003215285832993686, "12": 0.00030200902256183326, "13": 0.00028472382109612226, "14": 0.00026931014144793153, "15": 0.17093895375728607, "16": 0.2799486517906189, "17": 0.0002316832251381129, "18": 0.00022137344058137387, "19": 0.00021194209693931043}}, {"key": "yang2023human", "year": "2023", "title": "Human-centric Autonomous Systems With Llms For User Command Reasoning", "topic_distr": {"0": 0.0015223938971757889, "1": 0.0012419967679306865, "2": 0.001049909507855773, "3": 0.2544080317020416, "4": 0.20834797620773315, "5": 0.20874466001987457, "6": 0.05267229676246643, "7": 0.0005923024727962911, "8": 0.0005448124138638377, "9": 0.16598105430603027, "10": 0.00046952118282206357, "11": 0.00043917499715462327, "12": 0.0004125132691115141, "13": 0.0003889034560415894, "14": 0.0003678499488160014, "15": 0.00034895885619334877, "16": 0.00033191332477144897, "17": 0.10154388099908829, "18": 0.00030237334431149065, "19": 0.00028949108673259616}}, {"key": "yang2023impact", "year": "2023", "title": "The Impact Of Chatgpt And Llms On Medical Imaging Stakeholders: Perspectives And Use Cases", "topic_distr": {"0": 0.002153845503926277, "1": 0.0017561791464686394, "2": 0.0014844404067844152, "3": 0.1635086089372635, "4": 0.0011339898919686675, "5": 0.0010142703540623188, "6": 0.0009174162405543029, "7": 0.013273818418383598, "8": 0.0007703016162849963, "9": 0.5933835506439209, "10": 0.0006638485356234014, "11": 0.0006209425046108663, "12": 0.17080478370189667, "13": 0.0201021209359169, "14": 0.0005200972082093358, "15": 0.0004933873424306512, "16": 0.02611417882144451, "17": 0.00044743134640157223, "18": 0.000427520863013342, "19": 0.0004093068419024348}}, {"key": "yang2023llm", "year": "2023", "title": "Llm-grounder: Open-vocabulary 3D Visual Grounding With Large Language Model As An Agent", "topic_distr": {"0": 0.0012598939938470721, "1": 0.0010289597557857633, "2": 0.0008696338627487421, "3": 0.28492894768714905, "4": 0.0006642966764047742, "5": 0.0005941643030382693, "6": 0.0005374266766011715, "7": 0.000490580394398421, "8": 0.0697418749332428, "9": 0.0004177514638286084, "10": 0.0003888855571858585, "11": 0.30803218483924866, "12": 0.00034166817204095423, "13": 0.0003221131337340921, "14": 0.00030467534088529646, "15": 0.0002890285977628082, "16": 0.00027491047512739897, "17": 0.00026210735086351633, "18": 0.32901111245155334, "19": 0.000239773842622526}}, {"key": "yang2023mm", "year": "2023", "title": "MM-REACT: Prompting Chatgpt For Multimodal Reasoning And Action", "topic_distr": {"0": 0.0012988026719540358, "1": 0.0010608249576762319, "2": 0.0008968061883933842, "3": 0.13041536509990692, "4": 0.0006850762292742729, "5": 0.0006127493106760085, "6": 0.0005542368744499981, "7": 0.0005059252725914121, "8": 0.00046536081936210394, "9": 0.16815391182899475, "10": 0.0004010495322290808, "11": 0.038770489394664764, "12": 0.00035235524410381913, "13": 0.0003321885014884174, "14": 0.00031420530285686255, "15": 0.00029806914972141385, "16": 0.0002835094346664846, "17": 0.08448143303394318, "18": 0.5698703527450562, "19": 0.00024727373966015875}}, {"key": "yang2023open", "year": "2023", "title": "Fingpt: Open-source Financial Large Language Models", "topic_distr": {"0": 0.0017106333980336785, "1": 0.0013957299524918199, "2": 0.0011794952442869544, "3": 0.31338372826576233, "4": 0.099990613758564, "5": 0.0008058734238147736, "6": 0.000728919287212193, "7": 0.0006653809687122703, "8": 0.0006120316102169454, "9": 0.13197024166584015, "10": 0.0005274508730508387, "11": 0.000493360566906631, "12": 0.4439011216163635, "13": 0.0004368865047581494, "14": 0.000413235422456637, "15": 0.0003920135204680264, "16": 0.00037286491715349257, "17": 0.0003554998547770083, "18": 0.0003396802640054375, "19": 0.0003252086171414703}}, {"key": "yang2023set", "year": "2023", "title": "Set-of-mark Prompting Unleashes Extraordinary Visual Grounding In GPT-4V", "topic_distr": {"0": 0.0020786477252840996, "1": 0.001697318279184401, "2": 0.12299437820911407, "3": 0.1712723821401596, "4": 0.001096056425012648, "5": 0.0009803414577618241, "6": 0.0008867271826602519, "7": 0.0008094330551102757, "8": 0.02633018232882023, "9": 0.0006892690435051918, "10": 0.0006416417309083045, "11": 0.0006001709843985736, "12": 0.0005637353751808405, "13": 0.00053147051949054, "14": 0.0005026991129852831, "15": 0.00047688273480162024, "16": 0.0004535885527729988, "17": 0.0852099061012268, "18": 0.5817895531654358, "19": 0.0003956148575525731}}, {"key": "yang2023teaching", "year": "2023", "title": "Gpt4tools: Teaching Large Language Model To Use Tools Via Self-instruction", "topic_distr": {"0": 0.0012464653700590134, "1": 0.0010185358114540577, "2": 0.0008609083015471697, "3": 0.553754448890686, "4": 0.0006576401647180319, "5": 0.0005882106488570571, "6": 0.0005320415366441011, "7": 0.00048566455370746553, "8": 0.0004467245889827609, "9": 0.11153532564640045, "10": 0.00038498875801451504, "11": 0.0003601060889195651, "12": 0.0003382445138413459, "13": 0.08294839411973953, "14": 0.00030162237817421556, "15": 0.0002861324173863977, "16": 0.00027215576847083867, "17": 0.06819187849760056, "18": 0.17555314302444458, "19": 0.00023737121955491602}}, {"key": "yao2016attentional", "year": "2016", "title": "An Attentional Neural Conversation Model With Improved Specificity", "topic_distr": {"0": 0.0018093474209308624, "1": 0.0014762775972485542, "2": 0.2928942143917084, "3": 0.0010808150982484221, "4": 0.05773554742336273, "5": 0.04171696677803993, "6": 0.5136488676071167, "7": 0.0007039578631520271, "8": 0.08397603780031204, "9": 0.0005994521197862923, "10": 0.0005580309662036598, "11": 0.0005219641607254744, "12": 0.0004902764339931309, "13": 0.0004622159176506102, "14": 0.00043719360837712884, "15": 0.0004147413419559598, "16": 0.0003944825439248234, "17": 0.0003761107218451798, "18": 0.0003593739529605955, "19": 0.00034406327176839113}}, {"key": "yao2021colorful", "year": "2021", "title": "CPT: Colorful Prompt Tuning For Pre-trained Vision-language Models", "topic_distr": {"0": 0.0015218412736430764, "1": 0.001242332044057548, "2": 0.0010499587515369058, "3": 0.2948594391345978, "4": 0.0008020295645110309, "5": 0.0007173559861257672, "6": 0.0006488546496257186, "7": 0.0005922953714616597, "8": 0.0005448058946058154, "9": 0.0005043664132244885, "10": 0.0004695155657827854, "11": 0.0004391697293613106, "12": 0.00041250832146033645, "13": 0.0003888987994287163, "14": 0.00036784555413760245, "15": 0.000348954665241763, "16": 0.0003319093375466764, "17": 0.2751006782054901, "18": 0.4193677306175232, "19": 0.0002894876233767718}}, {"key": "yao2021fine", "year": "2021", "title": "FILIP: Fine-grained Interactive Language-image Pre-training", "topic_distr": {"0": 0.0013404759811237454, "1": 0.001095031388103962, "2": 0.0009257273050025105, "3": 0.0008017885265871882, "4": 0.11808280646800995, "5": 0.0006324888090603054, "6": 0.0005720914341509342, "7": 0.0005222234758548439, "8": 0.0004803522606380284, "9": 0.00044469701242633164, "10": 0.2180653065443039, "11": 0.00038721345481462777, "12": 0.00036370623274706304, "13": 0.11775902658700943, "14": 0.00032432732405140996, "15": 0.00030767134740017354, "16": 0.00029264259501360357, "17": 0.0002790136495605111, "18": 0.5370681881904602, "19": 0.00025523960357531905}}, {"key": "yao2022efficient", "year": "2022", "title": "Zeroquant: Efficient And Affordable Post-training Quantization For Large-scale Transformers", "topic_distr": {"0": 0.0013854673597961664, "1": 0.0011316764866933227, "2": 0.17439274489879608, "3": 0.0008285178919322789, "4": 0.0007307199412025511, "5": 0.0006535733700729907, "6": 0.0005911624175496399, "7": 0.000539632048457861, "8": 0.0004963650717400014, "9": 0.0004595212230924517, "10": 0.13365130126476288, "11": 0.00040012141107581556, "12": 0.0003758305683732033, "13": 0.6825803518295288, "14": 0.0003351389605086297, "15": 0.0003179277409799397, "16": 0.00030239796615205705, "17": 0.000288314709905535, "18": 0.0002754848392214626, "19": 0.0002637481375131756}}, {"key": "yao2022end", "year": "2022", "title": "End-to-end Multimodal Fact-checking And Explanation Generation: A Challenging Dataset And Models", "topic_distr": {"0": 0.001327080768533051, "1": 0.0010835918365046382, "2": 0.0009159307228401303, "3": 0.10626675933599472, "4": 0.0006996786105446517, "5": 0.27442750334739685, "6": 0.13173933327198029, "7": 0.0005167099880054593, "8": 0.20544417202472687, "9": 0.00044000204070471227, "10": 0.00040959863690659404, "11": 0.00038312538526952267, "12": 0.00035986636066809297, "13": 0.00033926975447684526, "14": 0.0003209032001905143, "15": 0.0003044230688828975, "16": 0.0002895529614761472, "17": 0.0002760679053608328, "18": 0.27420392632484436, "19": 0.0002525448508094996}}, {"key": "yao2022position", "year": "2022", "title": "PEVL: Position-enhanced Pre-training And Prompt Tuning For Vision-language Models", "topic_distr": {"0": 0.001466913498006761, "1": 0.001198435085825622, "2": 0.12217321246862411, "3": 0.0008772881701588631, "4": 0.0007737301639281213, "5": 0.0006920448504388332, "6": 0.0006259604124352336, "7": 0.0005713967839255929, "8": 0.0005255829310044646, "9": 0.00048657032311894, "10": 0.15761838853359222, "11": 0.0004236740351188928, "12": 0.00039795335032977164, "13": 0.0003751768672373146, "14": 0.0003548664681147784, "15": 0.0003366421442478895, "16": 0.09822317212820053, "17": 0.2560923993587494, "18": 0.3565073311328888, "19": 0.0002792733139358461}}, {"key": "yao2022prompt", "year": "2022", "title": "Prompt Tuning For Discriminative Pre-trained Language Models", "topic_distr": {"0": 0.04926575720310211, "1": 0.0013579422375187278, "2": 0.0011478547239676118, "3": 0.0009942087344825268, "4": 0.0008768505649641156, "5": 0.0007842787308618426, "6": 0.0007093866006471217, "7": 0.0006475508562289178, "8": 0.03513485938310623, "9": 0.0005514189833775163, "10": 0.12736570835113525, "11": 0.00048014006461016834, "12": 0.03072636015713215, "13": 0.00042517934343777597, "14": 0.00040216202614828944, "15": 0.12815263867378235, "16": 0.0003628733102232218, "17": 0.6199677586555481, "18": 0.0003305779246147722, "19": 0.00031649405718781054}}, {"key": "yao2022synergizing", "year": "2022", "title": "React: Synergizing Reasoning And Acting In Language Models", "topic_distr": {"0": 0.02454412542283535, "1": 0.0009013276430778205, "2": 0.1222429946064949, "3": 0.331361323595047, "4": 0.0005820246879011393, "5": 0.05468909069895744, "6": 0.0004708670894615352, "7": 0.04519294947385788, "8": 0.023854561150074005, "9": 0.0003660134971141815, "10": 0.0003407225594855845, "11": 0.2932281494140625, "12": 0.00029935300699435174, "13": 0.00028221981483511627, "14": 0.000266941700829193, "15": 0.00025323277805000544, "16": 0.10046500712633133, "17": 0.00022964569507166743, "18": 0.00021942656894680113, "19": 0.00021007817122153938}}, {"key": "yao2022towards", "year": "2022", "title": "Webshop: Towards Scalable Real-world Web Interaction With Grounded Language Agents", "topic_distr": {"0": 0.13438981771469116, "1": 0.0008350732387043536, "2": 0.0007057592738419771, "3": 0.0006112728733569384, "4": 0.07316841185092926, "5": 0.00048220049939118326, "6": 0.0004361543105915189, "7": 0.0003981356858275831, "8": 0.00036621367326006293, "9": 0.0003390306083019823, "10": 0.00031560417846776545, "11": 0.441120982170105, "12": 0.14267250895500183, "13": 0.00026141430134885013, "14": 0.00024726250558160245, "15": 0.04638662561774254, "16": 0.00022310650092549622, "17": 0.00021271599689498544, "18": 0.15663312375545502, "19": 0.0001945910044014454}}, {"key": "yao2023beyond", "year": "2023", "title": "Beyond Chain-of-thought, Effective Graph-of-thought Reasoning In Language Models", "topic_distr": {"0": 0.06840323656797409, "1": 0.0011707316152751446, "2": 0.12071774899959564, "3": 0.47181791067123413, "4": 0.000755978049710393, "5": 0.0006761659169569612, "6": 0.0006115977885201573, "7": 0.0005582861485891044, "8": 0.0005135234678164124, "9": 0.036592546850442886, "10": 0.0548522062599659, "11": 0.00041395286098122597, "12": 0.00038882234366610646, "13": 0.0003665684489533305, "14": 0.000346724089467898, "15": 0.000328917900333181, "16": 0.09874479472637177, "17": 0.0002982812002301216, "18": 0.09288159757852554, "19": 0.049560386687517166}}, {"key": "yao2023editing", "year": "2023", "title": "Editing Large Language Models: Problems, Methods, And Opportunities", "topic_distr": {"0": 0.06706935167312622, "1": 0.001184436259791255, "2": 0.0010011214762926102, "3": 0.24154312908649445, "4": 0.0007647432503290474, "5": 0.0006840061396360397, "6": 0.08180659264326096, "7": 0.12373312562704086, "8": 0.0005194776458665729, "9": 0.0004809182428289205, "10": 0.00044768760562874377, "11": 0.0653134360909462, "12": 0.3862975239753723, "13": 0.00037081874324940145, "14": 0.00035074425977654755, "15": 0.00033273163717240095, "16": 0.0003164787485729903, "17": 0.0003017397248186171, "18": 0.00028831243980675936, "19": 0.027193645015358925}}, {"key": "yao2023llm", "year": "2023", "title": "LLM Lies: Hallucinations Are Not Bugs, But Features As Adversarial Examples", "topic_distr": {"0": 0.2693963944911957, "1": 0.16920602321624756, "2": 0.0009159280452877283, "3": 0.2921743094921112, "4": 0.0006996726151555777, "5": 0.030971350148320198, "6": 0.000566044996958226, "7": 0.0005167040508240461, "8": 0.00047527538845315576, "9": 0.0004399969766382128, "10": 0.13497330248355865, "11": 0.00038312096148729324, "12": 0.00035986219882033765, "13": 0.023090602830052376, "14": 0.0003208995040040463, "15": 0.00030441954731941223, "16": 0.00028954961453564465, "17": 0.07440023869276047, "18": 0.0002637799771036953, "19": 0.00025254194042645395}}, {"key": "yao2023survey", "year": "2023", "title": "A Survey On Large Language Model (LLM) Security And Privacy: The Good, The Bad, And The Ugly", "topic_distr": {"0": 0.0009598911856301129, "1": 0.22728535532951355, "2": 0.0006622623186558485, "3": 0.2568718492984772, "4": 0.0005059000104665756, "5": 0.00045249046524986625, "6": 0.000409281492466107, "7": 0.0003736053186003119, "8": 0.00034365011379122734, "9": 0.3045540452003479, "10": 0.00029615883249789476, "11": 0.00027701741782948375, "12": 0.10643909126520157, "13": 0.03536941856145859, "14": 0.011449594981968403, "15": 0.05296808481216431, "16": 0.00020936022337991744, "17": 0.0001996099017560482, "18": 0.00019072735449299216, "19": 0.00018260165234096348}}, {"key": "yao2023tree", "year": "2023", "title": "Tree Of Thoughts: Deliberate Problem Solving With Large Language Models", "topic_distr": {"0": 0.11686388403177261, "1": 0.0010834914864972234, "2": 0.0009159308392554522, "3": 0.5441194772720337, "4": 0.0006996702286414802, "5": 0.0006258033099584281, "6": 0.0005660444148816168, "7": 0.03001483529806137, "8": 0.00047527492279186845, "9": 0.05866432189941406, "10": 0.0004095935437362641, "11": 0.2261052131652832, "12": 0.00035986184957437217, "13": 0.0003392655053175986, "14": 0.0003208991838619113, "15": 0.00030441925628110766, "16": 0.00028954935260117054, "17": 0.00027606444200500846, "18": 0.00026377971516922116, "19": 0.017302602529525757}}, {"key": "yao2023visual", "year": "2023", "title": "Visual-language Prompt Tuning With Knowledge-guided Context Optimization", "topic_distr": {"0": 0.0012354586506262422, "1": 0.0010082990629598498, "2": 0.0008523866999894381, "3": 0.0007382763433270156, "4": 0.000651129987090826, "5": 0.011560814455151558, "6": 0.000526774616446346, "7": 0.0004808568046428263, "8": 0.00044230232015252113, "9": 0.0004094713949598372, "10": 0.05674507096409798, "11": 0.0003565412771422416, "12": 0.026448165997862816, "13": 0.13020464777946472, "14": 0.0002986365288961679, "15": 0.00028329991619102657, "16": 0.19624927639961243, "17": 0.5710280537605286, "18": 0.0002454797795508057, "19": 0.0002350214053876698}}, {"key": "yasunaga2022deep", "year": "2022", "title": "Deep Bidirectional Language-knowledge Graph Pretraining", "topic_distr": {"0": 0.001154138590209186, "1": 0.0009430198697373271, "2": 0.10499155521392822, "3": 0.0006904529873281717, "4": 0.0006089495145715773, "5": 0.0005446604336611927, "6": 0.0004926499677821994, "7": 0.0004497067420743406, "8": 0.05487436801195145, "9": 0.00038294572732411325, "10": 0.1403641551733017, "11": 0.0003334444190841168, "12": 0.0003132014535367489, "13": 0.0002952756767626852, "14": 0.0002792907471302897, "15": 0.11811266839504242, "16": 0.21363285183906555, "17": 0.0002402693935437128, "18": 0.15157003700733185, "19": 0.20972633361816406}}, {"key": "yasunaga2022retrieval", "year": "2022", "title": "Retrieval-augmented Multimodal Language Modeling", "topic_distr": {"0": 0.00137041334528476, "1": 0.0011192081728950143, "2": 0.0009460753062739968, "3": 0.0008194161346182227, "4": 0.0007226915331557393, "5": 0.0006463942700065672, "6": 0.0005846690619364381, "7": 0.1284227967262268, "8": 0.09636186808347702, "9": 0.0004544738039840013, "10": 0.06923443078994751, "11": 0.04347142204642296, "12": 0.00037170242285355926, "13": 0.18976333737373352, "14": 0.0003314577625133097, "15": 0.0003144356014672667, "16": 0.10825756937265396, "17": 0.0002851478348020464, "18": 0.3387640714645386, "19": 0.01775844395160675}}, {"key": "yavuz2019grounded", "year": "2019", "title": "Deepcopy: Grounded Response Generation With Hierarchical Pointer Networks", "topic_distr": {"0": 0.030681699514389038, "1": 0.0009984872303903103, "2": 0.05419871211051941, "3": 0.0007311129593290389, "4": 0.019953276962041855, "5": 0.000576736987568438, "6": 0.48668110370635986, "7": 0.10289957374334335, "8": 0.0004380106693133712, "9": 0.00040549831464886665, "10": 0.0003774790675379336, "11": 0.0003530817630235106, "12": 0.1624603271484375, "13": 0.00031266515725292265, "14": 0.026973146945238113, "15": 0.00028055105940438807, "16": 0.11094827950000763, "17": 0.00025441942852921784, "18": 0.00024309787841048092, "19": 0.00023274098930414766}}, {"key": "ye2019bp", "year": "2019", "title": "Bp-transformer: Modelling Long-range Context Via Binary Partitioning", "topic_distr": {"0": 0.04478788003325462, "1": 0.0018516990821808577, "2": 0.3251660466194153, "3": 0.001355913933366537, "4": 0.0011958611430600286, "5": 0.0010696100071072578, "6": 0.0009674712782725692, "7": 0.11492122709751129, "8": 0.0008123299339786172, "9": 0.000752032850869, "10": 0.4543392062187195, "11": 0.0006548216915689409, "12": 0.000615068303886801, "13": 0.0005798654747195542, "14": 0.04856143519282341, "15": 0.0005203069886192679, "16": 0.0004948916612192988, "17": 0.00047184358118101954, "18": 0.00045084673911333084, "19": 0.00043163896771147847}}, {"key": "ye2019mask", "year": "2019", "title": "Align, Mask And Select: A Simple Method For Incorporating Commonsense Knowledge Into Language Representation Models", "topic_distr": {"0": 0.0014499821700155735, "1": 0.0011843147221952677, "2": 0.2553231418132782, "3": 0.0008670805837027729, "4": 0.0007647236925549805, "5": 0.0006839887937530875, "6": 0.0006186736281961203, "7": 0.0005647451616823673, "8": 0.06743111461400986, "9": 0.00048090616473928094, "10": 0.37003442645072937, "11": 0.0004187420418020338, "12": 0.0003933207772206515, "13": 0.0003708094300236553, "14": 0.0003507354704197496, "15": 0.00033272328437305987, "16": 0.16629576683044434, "17": 0.13187049329280853, "18": 0.00028830519295297563, "19": 0.0002760222996585071}}, {"key": "ye2020contrastive", "year": "2020", "title": "Contrastive Triple Extraction With Generative Transformer", "topic_distr": {"0": 0.0018886243924498558, "1": 0.0015431322390213609, "2": 0.20389743149280548, "3": 0.0011297786841169, "4": 0.000996420974843204, "5": 0.0008912248886190355, "6": 0.0008061205153353512, "7": 0.06327500939369202, "8": 0.0006768530001863837, "9": 0.0006266120471991599, "10": 0.2814604640007019, "11": 0.0005456132930703461, "12": 0.000512489874381572, "13": 0.00048315798630937934, "14": 0.00045700196642428637, "15": 0.31472548842430115, "16": 0.09222809970378876, "17": 0.00039315150934271514, "18": 0.03310365974903107, "19": 0.00035965206916444004}}, {"key": "ye2020coreferential", "year": "2020", "title": "Coreferential Reasoning Learning For Language Representation", "topic_distr": {"0": 0.0018612518906593323, "1": 0.0015204761875793338, "2": 0.001285078818909824, "3": 0.0011130119673907757, "4": 0.000981627614237368, "5": 0.0008779929485172033, "6": 0.11639656871557236, "7": 0.0007249275804497302, "8": 0.0006668038549833, "9": 0.02057587541639805, "10": 0.407175213098526, "11": 0.0005375126493163407, "12": 0.0005048809689469635, "13": 0.00047598459059372544, "14": 0.00045021690311841667, "15": 0.00042709580156952143, "16": 0.21054264903068542, "17": 0.2331583946943283, "18": 0.0003700791276060045, "19": 0.00035431236028671265}}, {"key": "ye2020variational", "year": "2020", "title": "Variational Template Machine For Data-to-text Generation", "topic_distr": {"0": 0.0012491797097027302, "1": 0.20653176307678223, "2": 0.0008610661025159061, "3": 0.0007457920582965016, "4": 0.1573975831270218, "5": 0.03230839595198631, "6": 0.24066786468029022, "7": 0.1254957914352417, "8": 0.00044680351857095957, "9": 0.0004136385105084628, "10": 0.00038505677366629243, "11": 0.0003601697098929435, "12": 0.00033830429310910404, "13": 0.04298197105526924, "14": 0.04786968603730202, "15": 0.00028618297073990107, "16": 0.06626338511705399, "17": 0.00025952677242457867, "18": 0.00024797796504572034, "19": 0.07488984614610672}}, {"key": "ye2021few", "year": "2021", "title": "Crossfit: A Few-shot Learning Challenge For Cross-task Generalization In NLP", "topic_distr": {"0": 0.07506200671195984, "1": 0.1411283314228058, "2": 0.03846607729792595, "3": 0.000994312111288309, "4": 0.0008769389241933823, "5": 0.0007843572529964149, "6": 0.0007094578468240798, "7": 0.0006476158741861582, "8": 0.0005956909153610468, "9": 0.000551474338863045, "10": 0.000513368402607739, "11": 0.049914225935935974, "12": 0.15965762734413147, "13": 0.000425222038757056, "14": 0.00040220239316113293, "15": 0.00038154711364768445, "16": 0.0003629097482189536, "17": 0.5278794169425964, "18": 0.0003306111029814929, "19": 0.0003165258385706693}}, {"key": "ye2021tr", "year": "2021", "title": "TR-BERT: Dynamic Token Reduction For Accelerating BERT Inference", "topic_distr": {"0": 0.001416849554516375, "1": 0.0011572142830118537, "2": 0.0009783199056982994, "3": 0.0008473434136249125, "4": 0.0007473225123248994, "5": 0.0006684245890937746, "6": 0.0006045956979505718, "7": 0.0005518944235518575, "8": 0.0005076442030258477, "9": 0.0004699631535913795, "10": 0.2818436920642853, "11": 0.06523662805557251, "12": 0.00038437076727859676, "13": 0.2697739601135254, "14": 0.0003427544725127518, "15": 0.00032515215571038425, "16": 0.00030926952604204416, "17": 0.3732830584049225, "18": 0.0002817448112182319, "19": 0.00026974143111146986}}, {"key": "ye2022efficient", "year": "2022", "title": "Zerogen: Efficient Zero-shot Learning Via Dataset Generation", "topic_distr": {"0": 0.001619602320715785, "1": 0.0013227347517386079, "2": 0.3135584592819214, "3": 0.0009683943935669959, "4": 0.0008540843264199793, "5": 0.0007639151881448925, "6": 0.0006909676012583077, "7": 0.000630737456958741, "8": 0.0731118842959404, "9": 0.0005371015868149698, "10": 0.0004999887896701694, "11": 0.000467673409730196, "12": 0.0505455806851387, "13": 0.2510054409503937, "14": 0.0003917200374417007, "15": 0.24163860082626343, "16": 0.000353451439877972, "17": 0.06040943041443825, "18": 0.00032199459383264184, "19": 0.0003082763869315386}}, {"key": "ye2022shifting", "year": "2022", "title": "Shifting More Attention To Visual Backbone: Query-modulated Refinement Networks For End-to-end Visual Grounding", "topic_distr": {"0": 0.020629459992051125, "1": 0.0009607975371181965, "2": 0.3270142078399658, "3": 0.0007035053567960858, "4": 0.016049781814217567, "5": 0.0005549574852921069, "6": 0.0005019636009819806, "7": 0.0004582084948197007, "8": 0.000421469914726913, "9": 0.0003901853342540562, "10": 0.00036322418600320816, "11": 0.00033974822144955397, "12": 0.00031912254053168, "13": 0.0003008578787557781, "14": 0.0002845707640517503, "15": 0.0002699565084185451, "16": 0.11170805245637894, "17": 0.00024481170112267137, "18": 0.518261194229126, "19": 0.00022395192354451865}}, {"key": "ye2022unreliability", "year": "2022", "title": "The Unreliability Of Explanations In Few-shot Prompting For Textual Reasoning", "topic_distr": {"0": 0.07652860134840012, "1": 0.0009888258064165711, "2": 0.12176632881164551, "3": 0.3782237470149994, "4": 0.0006384988664649427, "5": 0.16628289222717285, "6": 0.0005165557959116995, "7": 0.04045271500945091, "8": 0.038675665855407715, "9": 0.00040152817382477224, "10": 0.0003737832303158939, "11": 0.00034962481004185975, "12": 0.00032839953200891614, "13": 0.0003096038999501616, "14": 0.00029284332413226366, "15": 0.00027780423988588154, "16": 0.00026423437520861626, "17": 0.14597277343273163, "18": 0.027125054970383644, "19": 0.00023046227579470724}}, {"key": "ye2023cognitive", "year": "2023", "title": "Cognitive Mirage: A Review Of Hallucinations In Large Language Models", "topic_distr": {"0": 0.2509531080722809, "1": 0.0013224685098975897, "2": 0.0011181010631844401, "3": 0.000968378153629601, "4": 0.0008540685521438718, "5": 0.0007639008690603077, "6": 0.000690954620949924, "7": 0.0006307255825959146, "8": 0.000580154825001955, "9": 0.1782265156507492, "10": 0.0004999793600291014, "11": 0.0004676645912695676, "12": 0.33132925629615784, "13": 0.0004141319077461958, "14": 0.0003917126450687647, "15": 0.2294681966304779, "16": 0.0003534447751007974, "17": 0.00033698417246341705, "18": 0.0003219885111320764, "19": 0.0003082705952692777}}, {"key": "ye2023compositional", "year": "2023", "title": "Compositional Exemplars For In-context Learning", "topic_distr": {"0": 0.001326667028479278, "1": 0.08343839645385742, "2": 0.0009159089531749487, "3": 0.15998265147209167, "4": 0.030200758948922157, "5": 0.0006257790373638272, "6": 0.0005660224705934525, "7": 0.0005166835035197437, "8": 0.03203439712524414, "9": 0.0004399794852361083, "10": 0.0004095776239410043, "11": 0.10779920220375061, "12": 0.00035984787973575294, "13": 0.00033925235038623214, "14": 0.0003208867274224758, "15": 0.10111283510923386, "16": 0.00028953811852261424, "17": 0.436341255903244, "18": 0.0002637694706209004, "19": 0.04271657019853592}}, {"key": "ye2023comprehensive", "year": "2023", "title": "A Comprehensive Capability Analysis Of GPT-3 And GPT-3.5 Series Models", "topic_distr": {"0": 0.0013418343150988221, "1": 0.08500165492296219, "2": 0.05104127153754234, "3": 0.6049708127975464, "4": 0.0007071594009175897, "5": 0.0006325015565380454, "6": 0.0005721030756831169, "7": 0.0005222340114414692, "8": 0.0004803619522135705, "9": 0.0004447059764061123, "10": 0.0004139775410294533, "11": 0.00038722125464119017, "12": 0.2514157295227051, "13": 0.00034289679024368525, "14": 0.0003243338724132627, "15": 0.00030767754651606083, "16": 0.0002926485030911863, "17": 0.00027901926659978926, "18": 0.00026660304865799844, "19": 0.0002552447549533099}}, {"key": "ye2023ip", "year": "2023", "title": "Ip-adapter: Text Compatible Image Prompt Adapter For Text-to-image Diffusion Models", "topic_distr": {"0": 0.0010656249942258, "1": 0.0008704049978405237, "2": 0.0007358651491813362, "3": 0.04340450465679169, "4": 0.0005621101590804756, "5": 0.0005027657607570291, "6": 0.0004547559656202793, "7": 0.15935878455638885, "8": 0.00038183238939382136, "9": 0.0003534900024533272, "10": 0.016575530171394348, "11": 0.0003077962901443243, "12": 0.0002891103795263916, "13": 0.10893675684928894, "14": 0.00025780804571695626, "15": 0.0002445681893732399, "16": 0.0759747251868248, "17": 0.23186270892620087, "18": 0.30825814604759216, "19": 0.04960273951292038}}, {"key": "ye2023large", "year": "2023", "title": "Large Language Models Are Versatile Decomposers: Decompose Evidence And Questions For Table-based Reasoning", "topic_distr": {"0": 0.03155335783958435, "1": 0.000893568096216768, "2": 0.1175297275185585, "3": 0.29849424958229065, "4": 0.04337559640407562, "5": 0.0005160442087799311, "6": 0.00046676635975018144, "7": 0.035181496292352676, "8": 0.25146591663360596, "9": 0.00036282590008340776, "10": 0.00033775524934753776, "11": 0.00031592536834068596, "12": 0.0002967459731735289, "13": 0.040862008929252625, "14": 0.00026461691595613956, "15": 0.000251027406193316, "16": 0.09122514724731445, "17": 0.00022764572349842638, "18": 0.00021751559688709676, "19": 0.08616204559803009}}, {"key": "ye2023mplug", "year": "2023", "title": "Mplug-owl: Modularization Empowers Large Language Models With Multimodality", "topic_distr": {"0": 0.0009378367685712874, "1": 0.0007657717214897275, "2": 0.0006473048706538975, "3": 0.32074853777885437, "4": 0.07505424320697784, "5": 0.0004422641941346228, "6": 0.04588675498962402, "7": 0.00036516174441203475, "8": 0.013357328251004219, "9": 0.00031095181475393474, "10": 0.0002894655626732856, "11": 0.00027075677644461393, "12": 0.014886037446558475, "13": 0.00023976375814527273, "14": 0.0002267840172862634, "15": 0.00021513742103707045, "16": 0.06364555656909943, "17": 0.00019509867706801742, "18": 0.46133679151535034, "19": 0.00017847481649369001}}, {"key": "ye2023prompt", "year": "2023", "title": "Prompt Engineering A Prompt Engineer", "topic_distr": {"0": 0.001686984789557755, "1": 0.0013763445895165205, "2": 0.0011634635739028454, "3": 0.6585806608200073, "4": 0.0008887482690624893, "5": 0.0007949200225993991, "6": 0.0007190119358710945, "7": 0.0006563371862284839, "8": 0.0006037129205651581, "9": 0.0005589009379036725, "10": 0.0005202818429097533, "11": 0.0004866548697464168, "12": 0.0004571106983348727, "13": 0.0004309483920224011, "14": 0.0004076187906321138, "15": 0.0003866853367071599, "16": 0.00036779697984457016, "17": 0.3292579650878906, "18": 0.00033506337786093354, "19": 0.00032078841468319297}}, {"key": "ye2023universal", "year": "2023", "title": "Ureader: Universal Ocr-free Visually-situated Language Understanding With Multimodal Large Language Model", "topic_distr": {"0": 0.0014167423360049725, "1": 0.0011572267394512892, "2": 0.0009783357381820679, "3": 0.0008473663474433124, "4": 0.0007473401492461562, "5": 0.0006684408872388303, "6": 0.0006046104244887829, "7": 0.0005519078695215285, "8": 0.03989824652671814, "9": 0.0004699746205005795, "10": 0.0004375001590233296, "11": 0.02724706009030342, "12": 0.07631663978099823, "13": 0.06606676429510117, "14": 0.0003427628253120929, "15": 0.00032516010105609894, "16": 0.00030927706393413246, "17": 0.0002948734036181122, "18": 0.6431916952133179, "19": 0.13812808692455292}}, {"key": "yin2020pretraining", "year": "2020", "title": "Tabert: Pretraining For Joint Understanding Of Textual And Tabular Data", "topic_distr": {"0": 0.00186048517934978, "1": 0.0015202047070488334, "2": 0.001284915255382657, "3": 0.0011129019549116492, "4": 0.0009815336670726538, "5": 0.0008779089548625052, "6": 0.0007940760697238147, "7": 0.0007248581387102604, "8": 0.000666739942971617, "9": 0.0006172496359795332, "10": 0.1020066887140274, "11": 0.0005374611355364323, "12": 0.0005048325983807445, "13": 0.00047593898489139974, "14": 0.14556768536567688, "15": 0.00042705488158389926, "16": 0.1961577832698822, "17": 0.0003872773377224803, "18": 0.22840102016925812, "19": 0.31509339809417725}}, {"key": "yin2023language", "year": "2023", "title": "LAMM: Language-assisted Multi-modal Instruction-tuning Dataset, Framework, And Benchmark", "topic_distr": {"0": 0.029362905770540237, "1": 0.0006837362889200449, "2": 0.0005778743652626872, "3": 0.18117132782936096, "4": 0.0004414326685946435, "5": 0.03378700092434883, "6": 0.00035712565295398235, "7": 0.0003259957884438336, "8": 0.0002998578711412847, "9": 0.09654246270656586, "10": 0.00025841849856078625, "11": 0.07084129005670547, "12": 0.29034799337387085, "13": 0.06064729765057564, "14": 0.00020245995256118476, "15": 0.0001920625363709405, "16": 0.00018268088751938194, "17": 0.0001741730811772868, "18": 0.23344460129737854, "19": 0.0001593322231201455}}, {"key": "yin2023survey", "year": "2023", "title": "A Survey On Multimodal Large Language Models", "topic_distr": {"0": 0.057570599019527435, "1": 0.0008782130316831172, "2": 0.0007422834751196206, "3": 0.24220941960811615, "4": 0.0005670166574418545, "5": 0.0005071543273515999, "6": 0.00045872534974478185, "7": 0.009339041076600552, "8": 0.00038516527274623513, "9": 0.2003869265317917, "10": 0.0003319367242511362, "11": 0.0003104829229414463, "12": 0.23447957634925842, "13": 0.00027494251844473183, "14": 0.0002600583538878709, "15": 0.0002467029553372413, "16": 0.00023465229605790228, "17": 0.00022372406965587288, "18": 0.2503887414932251, "19": 0.000204661104362458}}, {"key": "yogatama2019learning", "year": "2019", "title": "Learning And Evaluating General Linguistic Intelligence", "topic_distr": {"0": 0.10742117464542389, "1": 0.1554928869009018, "2": 0.17426371574401855, "3": 0.0007933463202789426, "4": 0.0006996967131271958, "5": 0.0006258264766074717, "6": 0.0005660653696395457, "7": 0.0005167226190678775, "8": 0.04325762391090393, "9": 0.00044001280912198126, "10": 0.00040960864862427115, "11": 0.08532717078924179, "12": 0.2897281050682068, "13": 0.000339278019964695, "14": 0.0003209110291209072, "15": 0.05247043818235397, "16": 0.0865349993109703, "17": 0.00027607465744949877, "18": 0.00026378946495242417, "19": 0.00025255102082155645}}, {"key": "yogatama2021adaptive", "year": "2021", "title": "Adaptive Semiparametric Language Models", "topic_distr": {"0": 0.00226698094047606, "1": 0.0018517120042815804, "2": 0.5809860825538635, "3": 0.0013557206839323044, "4": 0.0011956823291257024, "5": 0.001069449819624424, "6": 0.0009673264576122165, "7": 0.0008830066653899848, "8": 0.000812208338174969, "9": 0.0007519202772527933, "10": 0.16798892617225647, "11": 0.0006547236698679626, "12": 0.0006149762775748968, "13": 0.0005797786870971322, "14": 0.0005483920103870332, "15": 0.0005202291067689657, "16": 0.23559877276420593, "17": 0.00047177294618450105, "18": 0.0004507792473305017, "19": 0.0004315743572078645}}, {"key": "yoo2021leveraging", "year": "2021", "title": "Gpt3mix: Leveraging Large-scale Language Models For Text Augmentation", "topic_distr": {"0": 0.001808072323910892, "1": 0.3261057436466217, "2": 0.0012477618874982, "3": 0.0010807373328134418, "4": 0.0009531653486192226, "5": 0.0008525355369783938, "6": 0.0007711255457252264, "7": 0.1865762621164322, "8": 0.0006474697147496045, "9": 0.0005994098028168082, "10": 0.0005579915596172214, "11": 0.000521927373483777, "12": 0.11284490674734116, "13": 0.07588909566402435, "14": 0.0004371627583168447, "15": 0.0004147120635025203, "16": 0.13673275709152222, "17": 0.15125571191310883, "18": 0.0003593486035242677, "19": 0.0003440389991737902}}, {"key": "you2020hard", "year": "2020", "title": "Hard-coded Gaussian Attention For Neural Machine Translation", "topic_distr": {"0": 0.0017099882243201137, "1": 0.0013950070133432746, "2": 0.5392249822616577, "3": 0.0010215135989710689, "4": 0.0009009366040118039, "5": 0.0008058208622969687, "6": 0.0007288717897608876, "7": 0.0006653376622125506, "8": 0.0006119917379692197, "9": 0.0005665652570314705, "10": 0.17153778672218323, "11": 0.0004933284362778068, "12": 0.10858499258756638, "13": 0.00043685807031579316, "14": 0.16953089833259583, "15": 0.00039198799640871584, "16": 0.0003728406154550612, "17": 0.00035547668812796474, "18": 0.0003396581450942904, "19": 0.0003251874295528978}}, {"key": "you2020knowledge", "year": "2020", "title": "Knowledge Distillation For Improved Accuracy In Spoken Question Answering", "topic_distr": {"0": 0.0015412886859849095, "1": 0.0508117713034153, "2": 0.25035157799720764, "3": 0.0009206102113239467, "4": 0.0008119355770759284, "5": 0.0007262159488163888, "6": 0.2159307301044464, "7": 0.0005996106774546206, "8": 0.16183173656463623, "9": 0.0005105957388877869, "10": 0.00047531441668979824, "11": 0.0004445937811397016, "12": 0.00041760309250093997, "13": 0.2388048619031906, "14": 0.00037238869117572904, "15": 0.0003532645059749484, "16": 0.07417634129524231, "17": 0.00032036006450653076, "18": 0.0003061041934415698, "19": 0.0002930629998445511}}, {"key": "you2023refer", "year": "2023", "title": "Ferret: Refer And Ground Anything Anywhere At Any Granularity", "topic_distr": {"0": 0.07300093024969101, "1": 0.022508913651108742, "2": 0.0008525447337888181, "3": 0.06489399075508118, "4": 0.0006512454128824174, "5": 0.0005824904656037688, "6": 0.0005268676322884858, "7": 0.0004809417005162686, "8": 0.00044238040572963655, "9": 0.0004095437179785222, "10": 0.0003812449285760522, "11": 0.0003566042287275195, "12": 0.0003349552571307868, "13": 0.000315784418489784, "14": 0.0002986892650369555, "15": 0.07280250638723373, "16": 0.045721378177404404, "17": 0.07017503678798676, "18": 0.6450288891792297, "19": 0.0002350629074499011}}, {"key": "young2017augmenting", "year": "2017", "title": "Augmenting End-to-end Dialog Systems With Commonsense Knowledge", "topic_distr": {"0": 0.05140291526913643, "1": 0.0016166458372026682, "2": 0.0013666772283613682, "3": 0.0011837172787636518, "4": 0.1190456971526146, "5": 0.0009337685769423842, "6": 0.24713172018527985, "7": 0.0007709794444963336, "8": 0.0007091633160598576, "9": 0.07411238551139832, "10": 0.0006111593102104962, "11": 0.1964256316423416, "12": 0.000536954088602215, "13": 0.0005062220152467489, "14": 0.0004788174410350621, "15": 0.0004542275273706764, "16": 0.16983529925346375, "17": 0.13210760056972504, "18": 0.000393588823499158, "19": 0.0003768204478546977}}, {"key": "young2021fusing", "year": "2021", "title": "Fusing Task-oriented And Open-domain Dialogues In Conversational Agents", "topic_distr": {"0": 0.11015177518129349, "1": 0.0009518339647911489, "2": 0.0008046674774959683, "3": 0.0006969438400119543, "4": 0.0006146739469841123, "5": 0.21289247274398804, "6": 0.4512736201286316, "7": 0.00045393381151370704, "8": 0.00041753798723220825, "9": 0.0003865452599711716, "10": 0.00035983562702313066, "11": 0.21888212859630585, "12": 0.00031614542240276933, "13": 0.00029805113445036113, "14": 0.00028191597084514797, "15": 0.00026743803755380213, "16": 0.00025437455042265356, "17": 0.00024252782168332487, "18": 0.0002317354519618675, "19": 0.0002218626468675211}}, {"key": "yu2016end", "year": "2016", "title": "End-to-end Answer Chunk Extraction And Ranking For Reading Comprehension", "topic_distr": {"0": 0.0018598656170070171, "1": 0.001519790617749095, "2": 0.6157796382904053, "3": 0.0011129275662824512, "4": 0.044999223202466965, "5": 0.000877934682648629, "6": 0.000794099410995841, "7": 0.0007248794427141547, "8": 0.2716340720653534, "9": 0.0006172677967697382, "10": 0.0005746156093664467, "11": 0.0005374769680202007, "12": 0.0005048474413342774, "13": 0.00047595298383384943, "14": 0.0004501870134845376, "15": 0.056019362062215805, "16": 0.00040620655636303127, "17": 0.0003872887173201889, "18": 0.00037005453486926854, "19": 0.00035428881528787315}}, {"key": "yu2017beyond", "year": "2017", "title": "Beyond Bilinear: Generalized Multimodal Factorized High-order Pooling For Visual Question Answering", "topic_distr": {"0": 0.0008848250145092607, "1": 0.0007222755812108517, "2": 0.35960298776626587, "3": 0.00052885856712237, "4": 0.0004664322186727077, "5": 0.000417189032305032, "6": 0.0003773509815800935, "7": 0.013519433327019215, "8": 0.14487287402153015, "9": 0.00029332173289731145, "10": 0.0002730536798480898, "11": 0.00025540561182424426, "12": 0.0002399002987658605, "13": 0.00022616982460021973, "14": 0.00021392600319813937, "15": 0.00020293972920626402, "16": 0.04950250685214996, "17": 0.00018403712601866573, "18": 0.42704811692237854, "19": 0.00016835579299367964}}, {"key": "yu2018combining", "year": "2018", "title": "Qanet: Combining Local Convolution With Global Self-attention For Reading Comprehension", "topic_distr": {"0": 0.0015602908097207546, "1": 0.0012733618495985866, "2": 0.7014750838279724, "3": 0.0009320784593001008, "4": 0.0008220578893087804, "5": 0.000735268578864634, "6": 0.0006650565192103386, "7": 0.0006070849485695362, "8": 0.05922682583332062, "9": 0.00051696045557037, "10": 0.0933883935213089, "11": 0.0004501357616391033, "12": 0.0004228086327202618, "13": 0.00039860958349891007, "14": 0.13589712977409363, "15": 0.0003576680610422045, "16": 0.00034019711893051863, "17": 0.0003243534592911601, "18": 0.00030991988023743033, "19": 0.0002967161126434803}}, {"key": "yu2018guided", "year": "2018", "title": "Guided Feature Transformation (GFT): A Neural Language Grounding Module For Embodied Agents", "topic_distr": {"0": 0.0016410991083830595, "1": 0.0013402628246694803, "2": 0.31190648674964905, "3": 0.0009812630014494061, "4": 0.060140978544950485, "5": 0.0007740670116618276, "6": 0.0007001501508057117, "7": 0.000639119534753263, "8": 0.0005878757801838219, "9": 0.0005442393012344837, "10": 0.0005066333105787635, "11": 0.5296374559402466, "12": 0.0004451193381100893, "13": 0.00041964335832744837, "14": 0.00039692572318017483, "15": 0.000376541429432109, "16": 0.00035814856528304517, "17": 0.000341468898113817, "18": 0.08795012533664703, "19": 0.0003123731876257807}}, {"key": "yu2019multimodal", "year": "2019", "title": "Multimodal Unified Attention Networks For Vision-and-language Interactions", "topic_distr": {"0": 0.0015988629311323166, "1": 0.0013055235613137484, "2": 0.2442053258419037, "3": 0.0009559241589158773, "4": 0.0008430875022895634, "5": 0.0007540789083577693, "6": 0.0006820707349106669, "7": 0.0006226161494851112, "8": 0.0005726955714635551, "9": 0.0005301859346218407, "10": 0.10092945396900177, "11": 0.00046165165258571506, "12": 0.0004336254205554724, "13": 0.000408807274652645, "14": 0.0003866762563120574, "15": 0.00036681833444163203, "16": 0.00034890041570179164, "17": 0.0003326514270156622, "18": 0.64395672082901, "19": 0.00030430706101469696}}, {"key": "yu2020assessing", "year": "2020", "title": "Assessing Phrasal Representation And Composition In Transformers", "topic_distr": {"0": 0.3098103106021881, "1": 0.18160924315452576, "2": 0.001062937662936747, "3": 0.0009206346003338695, "4": 0.015827132388949394, "5": 0.0007262388244271278, "6": 0.0006568891694769263, "7": 0.0005996295949444175, "8": 0.0005515520460903645, "9": 0.000510611804202199, "10": 0.30801406502723694, "11": 0.00044460780918598175, "12": 0.00041761627653613687, "13": 0.00039371440652757883, "14": 0.00037240044912323356, "15": 0.00035327565274201334, "16": 0.1768096387386322, "17": 0.0003203701926395297, "18": 0.00030611385591328144, "19": 0.00029307225486263633}}, {"key": "yu2020few", "year": "2020", "title": "Few-shot Generative Conversational Query Rewriting", "topic_distr": {"0": 0.11082539707422256, "1": 0.06843594461679459, "2": 0.11141505092382431, "3": 0.0010357386199757457, "4": 0.08970236033201218, "5": 0.0008170365472324193, "6": 0.2744011878967285, "7": 0.0006745979771949351, "8": 0.14511555433273315, "9": 0.0005744508234784007, "10": 0.000534757215064019, "11": 0.024429921060800552, "12": 0.0004698285192716867, "13": 0.00044293832615949214, "14": 0.0004189596220385283, "15": 0.16929370164871216, "16": 0.00037802988663315773, "17": 0.000360424310201779, "18": 0.00034438559669069946, "19": 0.00032971345353871584}}, {"key": "yu2020fine", "year": "2020", "title": "Fine-tuning Pre-trained Language Model With Weak Supervision: A Contrastive-regularized Self-training Approach", "topic_distr": {"0": 0.0017833238234743476, "1": 0.0014553177170455456, "2": 0.3350261151790619, "3": 0.001065304852090776, "4": 0.0009395512752234936, "5": 0.0008403591928072274, "6": 0.0007601118995808065, "7": 0.057721879333257675, "8": 0.000638222205452621, "9": 0.0005908486782573164, "10": 0.22248272597789764, "11": 0.000514472892973572, "12": 0.00048323991359211504, "13": 0.07150520384311676, "14": 0.00043091896804980934, "15": 0.18763059377670288, "16": 0.0003888208884745836, "17": 0.00037071271799504757, "18": 0.00035421617212705314, "19": 0.11501803249120712}}, {"key": "yu2020reading", "year": "2020", "title": "Reclor: A Reading Comprehension Dataset Requiring Logical Reasoning", "topic_distr": {"0": 0.11160033941268921, "1": 0.001072157290764153, "2": 0.3312389552593231, "3": 0.35656002163887024, "4": 0.000692269706632942, "5": 0.0006191844586282969, "6": 0.000560057524126023, "7": 0.0005112385260872543, "8": 0.00047024808009155095, "9": 0.00043534283759072423, "10": 0.0004052613803651184, "11": 0.0003790684277191758, "12": 0.1246459111571312, "13": 0.00033567717764526606, "14": 0.00031750512425787747, "15": 0.06908629089593887, "16": 0.0002864868729375303, "17": 0.00027314460021443665, "18": 0.0002609897928778082, "19": 0.00024987064534798265}}, {"key": "yu2020survey", "year": "2020", "title": "A Survey Of Knowledge-enhanced Text Generation", "topic_distr": {"0": 0.0011885181302204728, "1": 0.000969971064478159, "2": 0.0008199423318728805, "3": 0.0007101694354787469, "4": 0.0006263407412916422, "5": 0.0422358438372612, "6": 0.0005067193997092545, "7": 0.44397225975990295, "8": 0.0004254631348885596, "9": 0.049946386367082596, "10": 0.00036666556843556464, "11": 0.00034296716330572963, "12": 0.3552888333797455, "13": 0.0003037083661183715, "14": 0.015281959436833858, "15": 0.0002725142112467438, "16": 0.08603238314390182, "17": 0.0002471311599947512, "18": 0.00023613394296262413, "19": 0.00022607375285588205}}, {"key": "yu2021few", "year": "2021", "title": "Few-shot Conversational Dense Retrieval", "topic_distr": {"0": 0.0011896098731085658, "1": 0.0009699978982098401, "2": 0.10811687260866165, "3": 0.0007101972587406635, "4": 0.0006263640825636685, "5": 0.0005602356977760792, "6": 0.2545848488807678, "7": 0.00046256667701527476, "8": 0.21027830243110657, "9": 0.00039389653829857707, "10": 0.23818232119083405, "11": 0.000342979677952826, "12": 0.00032215783721767366, "13": 0.08989805728197098, "14": 0.00028727742028422654, "15": 0.00027252416475676, "16": 0.0002592122182250023, "17": 0.0002471401821821928, "18": 0.00023614255769643933, "19": 0.09205931425094604}}, {"key": "yu2021vision", "year": "2021", "title": "Vision Guided Generative Pre-trained Language Models For Multimodal Abstractive Summarization", "topic_distr": {"0": 0.0012601856142282486, "1": 0.0010288426419720054, "2": 0.0008697006851434708, "3": 0.0007532715681008995, "4": 0.0006643511005677283, "5": 0.000594212906435132, "6": 0.0005374706233851612, "7": 0.16492962837219238, "8": 0.0004512831219471991, "9": 0.00041778560262173414, "10": 0.1115039810538292, "11": 0.0003637807385530323, "12": 0.08506028354167938, "13": 0.000322139443596825, "14": 0.00030470025376416743, "15": 0.11904758214950562, "16": 0.00027493294328451157, "17": 0.0002621287712827325, "18": 0.5111139416694641, "19": 0.0002397934440523386}}, {"key": "yu2022contrastive", "year": "2022", "title": "Coca: Contrastive Captioners Are Image-text Foundation Models", "topic_distr": {"0": 0.0009895504917949438, "1": 0.0008084564469754696, "2": 0.07458454370498657, "3": 0.0005919026443734765, "4": 0.0005220334278419614, "5": 0.00046692031901329756, "6": 0.00042233336716890335, "7": 0.00038551949546672404, "8": 0.0003546090447343886, "9": 0.0003282873658463359, "10": 0.3414880335330963, "11": 0.0002858514490071684, "12": 0.0002684977662283927, "13": 0.0619029775261879, "14": 0.00023942720144987106, "15": 0.012969332747161388, "16": 0.022210359573364258, "17": 0.00020597541879396886, "18": 0.4454662799835205, "19": 0.03550911694765091}}, {"key": "yu2022generate", "year": "2022", "title": "Generate Rather Than Retrieve: Large Language Models Are Strong Context Generators", "topic_distr": {"0": 0.0010943195084109902, "1": 0.0008933540084399283, "2": 0.13903456926345825, "3": 0.21813997626304626, "4": 0.0005768983974121511, "5": 0.00051599316066131, "6": 0.048383213579654694, "7": 0.04876311123371124, "8": 0.34961479902267456, "9": 0.00036278978222981095, "10": 0.00033772163442336023, "11": 0.0003158939362037927, "12": 0.0002967164327856153, "13": 0.000279734143987298, "14": 0.0002645905769895762, "15": 0.00025100240600295365, "16": 0.07674555480480194, "17": 0.11370404064655304, "18": 0.00021749394363723695, "19": 0.0002082278806483373}}, {"key": "yu2022legal", "year": "2022", "title": "Legal Prompting: Teaching A Language Model To Think Like A Lawyer", "topic_distr": {"0": 0.0016859733732417226, "1": 0.0013765761395916343, "2": 0.0011634654365479946, "3": 0.6140923500061035, "4": 0.0008887504227459431, "5": 0.08655863255262375, "6": 0.00071901292540133, "7": 0.0006563381757587194, "8": 0.0006037137936800718, "9": 0.12214642018079758, "10": 0.0005202825996093452, "11": 0.00048665556823834777, "12": 0.0409594289958477, "13": 0.00043094903230667114, "14": 0.00040761937270872295, "15": 0.00038668588967993855, "16": 0.0003677975037135184, "17": 0.1258935183286667, "18": 0.0003350638726260513, "19": 0.0003207888803444803}}, {"key": "yu2022multimodal", "year": "2022", "title": "Multimodal Knowledge Alignment With Reinforcement Learning", "topic_distr": {"0": 0.001599998795427382, "1": 0.06887764483690262, "2": 0.0011037344811484218, "3": 0.0009559710160829127, "4": 0.0008431257447227836, "5": 0.0007541141822002828, "6": 0.0006821025745011866, "7": 0.06415525078773499, "8": 0.0005727222887799144, "9": 0.0005302106728777289, "10": 0.0004935740143992007, "11": 0.21824349462985992, "12": 0.0004336456477176398, "13": 0.11801111698150635, "14": 0.00038669430068694055, "15": 0.0003668354474939406, "16": 0.0003489167138468474, "17": 0.0003326669684611261, "18": 0.5210038423538208, "19": 0.0003043212345801294}}, {"key": "yu2022scaling", "year": "2022", "title": "Scaling Autoregressive Models For Content-rich Text-to-image Generation", "topic_distr": {"0": 0.0012601582566276193, "1": 0.0010288405464962125, "2": 0.0008696821168996394, "3": 0.2774633765220642, "4": 0.0006643268279731274, "5": 0.0005941914860159159, "6": 0.000537451240234077, "7": 0.13340282440185547, "8": 0.00045126688200980425, "9": 0.000417770555941388, "10": 0.1260611116886139, "11": 0.00036376764182932675, "12": 0.07458972185850143, "13": 0.07014931738376617, "14": 0.08585599809885025, "15": 0.018598856404423714, "16": 0.0002749230479821563, "17": 0.0002621193416416645, "18": 0.15048548579216003, "19": 0.05666883662343025}}, {"key": "yu2022task", "year": "2022", "title": "Task Residual For Tuning Vision-language Models", "topic_distr": {"0": 0.06886231899261475, "1": 0.02904483489692211, "2": 0.0008278524037450552, "3": 0.0007170193130150437, "4": 0.0006323816487565637, "5": 0.0005656189168803394, "6": 0.0005116070387884974, "7": 0.0004670113557949662, "8": 0.00042956697870977223, "9": 0.00039768137503415346, "10": 0.0003702022659126669, "11": 0.0003462752792984247, "12": 0.0003252533497288823, "13": 0.06312225013971329, "14": 0.0002900378021877259, "15": 0.00027514275279827416, "16": 0.1367897242307663, "17": 0.4666185975074768, "18": 0.22917835414409637, "19": 0.00022825435735285282}}, {"key": "yu2023large", "year": "2023", "title": "Large Language Model As Attributed Training Data Generator: A Tale Of Diversity And Bias", "topic_distr": {"0": 0.13525521755218506, "1": 0.18324342370033264, "2": 0.0006999688339419663, "3": 0.2707333564758301, "4": 0.0005346920806914568, "5": 0.00047824258217588067, "6": 0.0004325745103415102, "7": 0.14305897057056427, "8": 0.00036320791696198285, "9": 0.0003362479619681835, "10": 0.00031301379203796387, "11": 0.0002927830209955573, "12": 0.06429997086524963, "13": 0.07005943357944489, "14": 0.00024523306638002396, "15": 0.00023263899493031204, "16": 0.00022127533156890422, "17": 0.12880517542362213, "18": 0.00020158202096354216, "19": 0.00019299385894555598}}, {"key": "yu2023low", "year": "2023", "title": "Low-rank Adaptation Of Large Language Model Rescoring For Parameter-efficient Speech Recognition", "topic_distr": {"0": 0.0019198926165699959, "1": 0.0015669632703065872, "2": 0.04984724894165993, "3": 0.0011471665930002928, "4": 0.02370363101363182, "5": 0.000904940243344754, "6": 0.0008185259066522121, "7": 0.0007471767603419721, "8": 0.000687269086483866, "9": 0.0006362549611367285, "10": 0.19174623489379883, "11": 0.0005540097481571138, "12": 0.0005203765467740595, "13": 0.3233535587787628, "14": 0.0004640347615350038, "15": 0.00044020405039191246, "16": 0.0004187014710623771, "17": 0.2685852348804474, "18": 0.000381437421310693, "19": 0.13155707716941833}}, {"key": "yu2023mm", "year": "2023", "title": "Mm-vet: Evaluating Large Multimodal Models For Integrated Capabilities", "topic_distr": {"0": 0.001211692811921239, "1": 0.0009886975167319179, "2": 0.0008358390768989921, "3": 0.39335182309150696, "4": 0.1342049241065979, "5": 0.0005710894474759698, "6": 0.0005165551556274295, "7": 0.00047152815386652946, "8": 0.043056078255176544, "9": 0.000401527649955824, "10": 0.0003737827646546066, "11": 0.00034962434438057244, "12": 0.1941683143377304, "13": 0.00030960352160036564, "14": 0.0002928429748862982, "15": 0.02542269043624401, "16": 0.038410235196352005, "17": 0.00025192814064212143, "18": 0.16458076238632202, "19": 0.00023046198475640267}}, {"key": "yu2023rlhf", "year": "2023", "title": "RLHF-V: Towards Trustworthy Mllms Via Behavior Alignment From Fine-grained Correctional Human Feedback", "topic_distr": {"0": 0.23295819759368896, "1": 0.09419496357440948, "2": 0.0007755894330330193, "3": 0.11078695207834244, "4": 0.16553078591823578, "5": 0.0005299244658090174, "6": 0.00047932114102877676, "7": 0.0004375397402327508, "8": 0.0004024583613499999, "9": 0.00037258496740832925, "10": 0.0003468399809207767, "11": 0.00032442293013446033, "12": 0.00030472766957245767, "13": 0.14804565906524658, "14": 0.00027173443231731653, "15": 0.0002577793784439564, "16": 0.0002451876935083419, "17": 0.00023376880562864244, "18": 0.24328769743442535, "19": 0.00021384995488915592}}, {"key": "yu2023scaling", "year": "2023", "title": "Scaling Autoregressive Multi-modal Models: Pretraining And Instruction Tuning", "topic_distr": {"0": 0.0018611953128129244, "1": 0.0015202134381979704, "2": 0.001284965081140399, "3": 0.0011129423510283232, "4": 0.0009815612575039268, "5": 0.000877933984156698, "6": 0.000794098770711571, "7": 0.2747054696083069, "8": 0.0006667590350843966, "9": 0.0006172673311084509, "10": 0.0005746152019128203, "11": 0.0005374765023589134, "12": 0.000504847033880651, "13": 0.24354827404022217, "14": 0.00045018663513474166, "15": 0.0004270671051926911, "16": 0.00040620623622089624, "17": 0.07033082842826843, "18": 0.3123493790626526, "19": 0.0864487811923027}}, {"key": "yu2023self", "year": "2023", "title": "Self-chained Image-language Model For Video Localization And Question Answering", "topic_distr": {"0": 0.0011147076729685068, "1": 0.0009093844564631581, "2": 0.35726460814476013, "3": 0.07180768996477127, "4": 0.0005871898611076176, "5": 0.0005251977709122002, "6": 0.0004750457883346826, "7": 0.00043363706208765507, "8": 0.13555757701396942, "9": 0.00036926165921613574, "10": 0.00034374630195088685, "11": 0.00032152922358363867, "12": 0.0003020096046384424, "13": 0.045612089335918427, "14": 0.00026931066531687975, "15": 0.00025548008852638304, "16": 0.00024300070072058588, "17": 0.00023168367624748498, "18": 0.3831649124622345, "19": 0.0002119424898410216}}, {"key": "yu2024boosting", "year": "2024", "title": "Boosting Continual Learning Of Vision-language Models Via Mixture-of-experts Adapters", "topic_distr": {"0": 0.04524128511548042, "1": 0.0013229504693299532, "2": 0.0011181388981640339, "3": 0.0009684532997198403, "4": 0.000854134967084974, "5": 0.0007639601826667786, "6": 0.027255160734057426, "7": 0.0006307747098617256, "8": 0.0005801999941468239, "9": 0.0005371333099901676, "10": 0.0005000183009542525, "11": 0.00046770102926529944, "12": 0.0004393075068946928, "13": 0.19936127960681915, "14": 0.0003917431749869138, "15": 0.00037162500666454434, "16": 0.2422429472208023, "17": 0.34196507930755615, "18": 0.13467980921268463, "19": 0.0003082946059294045}}, {"key": "yuan2021evaluating", "year": "2021", "title": "Bartscore: Evaluating Generated Text As Text Generation", "topic_distr": {"0": 0.12556549906730652, "1": 0.00098883465398103, "2": 0.0008359397761523724, "3": 0.12874561548233032, "4": 0.13918711245059967, "5": 0.000571137759834528, "6": 0.0005165989277884364, "7": 0.28049978613853455, "8": 0.0004337583959568292, "9": 0.0004015617014374584, "10": 0.00037381445872597396, "11": 0.00034965400118380785, "12": 0.00032842697692103684, "13": 0.0003096297732554376, "14": 0.11953437328338623, "15": 0.20037083327770233, "16": 0.00026425643591210246, "17": 0.0002519495028536767, "18": 0.0002407378633506596, "19": 0.00023048151342663914}}, {"key": "yuan2022pretraining", "year": "2022", "title": "Biobart: Pretraining And Evaluation Of A Biomedical Generative Language Model", "topic_distr": {"0": 0.0015034644166007638, "1": 0.0012268186546862125, "2": 0.0010372331598773599, "3": 0.0008983840234577656, "4": 0.0007923393277451396, "5": 0.01634223200380802, "6": 0.0006410153582692146, "7": 0.1263553500175476, "8": 0.0005382237141020596, "9": 0.0004982728278264403, "10": 0.04109258949756622, "11": 0.0004338638100307435, "12": 0.17810752987861633, "13": 0.00038420024793595076, "14": 0.0003634013410191983, "15": 0.29128411412239075, "16": 0.00032789932447485626, "17": 0.20685508847236633, "18": 0.0002987165644299239, "19": 0.13101930916309357}}, {"key": "yuan2024prompt", "year": "2024", "title": "Unist: A Prompt-empowered Universal Model For Urban Spatio-temporal Prediction", "topic_distr": {"0": 0.0014673605328425765, "1": 0.0011984993470832705, "2": 0.0010129116708412766, "3": 0.6924046874046326, "4": 0.0007737338310107589, "5": 0.0006920471787452698, "6": 0.047719456255435944, "7": 0.0005713986465707421, "8": 0.0005255846190266311, "9": 0.0004865719238296151, "10": 0.0004529505968093872, "11": 0.00042367540299892426, "12": 0.00039795463089831173, "13": 0.10882654041051865, "14": 0.0003548676031641662, "15": 0.0003366432210896164, "16": 0.0003201992658432573, "17": 0.1414639949798584, "18": 0.0002917018427979201, "19": 0.00027927421615459025}}, {"key": "yue2023massive", "year": "2023", "title": "MMMU: A Massive Multi-discipline Multimodal Understanding And Reasoning Benchmark For Expert AGI", "topic_distr": {"0": 0.0014344505034387112, "1": 0.0011707283556461334, "2": 0.000989626976661384, "3": 0.1525995284318924, "4": 0.0007559687946923077, "5": 0.0006761587574146688, "6": 0.000611591269262135, "7": 0.0005582802114076912, "8": 0.022146401926875114, "9": 0.06737891584634781, "10": 0.0004425515653565526, "11": 0.000413948466302827, "12": 0.5064479112625122, "13": 0.00036656457814387977, "14": 0.00034672039328143, "15": 0.0003289144078735262, "16": 0.05383666604757309, "17": 0.00029827802791260183, "18": 0.17499665915966034, "19": 0.014200147241353989}}, {"key": "yuksekgonul2022when", "year": "2022", "title": "When And Why Vision-language Models Behave Like Bags-of-words, And What To Do About It?", "topic_distr": {"0": 0.20892859995365143, "1": 0.043434180319309235, "2": 0.0006622682558372617, "3": 0.0005736018065363169, "4": 0.0005058917449787259, "5": 0.010666446760296822, "6": 0.00040927459485828876, "7": 0.00037359900306910276, "8": 0.000343644293025136, "9": 0.0003181365318596363, "10": 0.0002961538266390562, "11": 0.18408115208148956, "12": 0.0002601956657599658, "13": 0.0002453036140650511, "14": 0.00023202397278510034, "15": 0.0002201082679675892, "16": 0.00020935668726451695, "17": 0.00019960652571171522, "18": 0.4489389657974243, "19": 0.09910143911838531}}, {"key": "zadeh2020quantizing", "year": "2020", "title": "GOBO: Quantizing Attention-based NLP Models For Low Latency And Energy Efficient Inference", "topic_distr": {"0": 0.001370732206851244, "1": 0.0011190141085535288, "2": 0.136027529835701, "3": 0.0008194388938136399, "4": 0.0007227093446999788, "5": 0.0006464103935286403, "6": 0.0005846836138516665, "7": 0.0005337180336937308, "8": 0.0004909252165816724, "9": 0.00045448518358170986, "10": 0.14968016743659973, "11": 0.0003957363369408995, "12": 0.05712076276540756, "13": 0.6482701897621155, "14": 0.0003314660571049899, "15": 0.00031444345950149, "16": 0.00029908388387411833, "17": 0.0002851549652405083, "18": 0.0002724656951613724, "19": 0.0002608576323837042}}, {"key": "zafrir2019quantized", "year": "2019", "title": "Q8BERT: Quantized 8bit BERT", "topic_distr": {"0": 0.07691562175750732, "1": 0.001591412234120071, "2": 0.0013452570419758558, "3": 0.09837833791971207, "4": 0.001027620048262179, "5": 0.0009191308636218309, "6": 0.0008313616272062063, "7": 0.0007588936714455485, "8": 0.000698046525940299, "9": 0.0006462324527092278, "10": 0.30893370509147644, "11": 0.033140700310468674, "12": 0.0005285368533805013, "13": 0.4483427405357361, "14": 0.00047131156316027045, "15": 0.0004471071297302842, "16": 0.02386021800339222, "17": 0.0004054618184454739, "18": 0.00038741895696148276, "19": 0.00037091344711370766}}, {"key": "zafrir2021prune", "year": "2021", "title": "Prune Once For All: Sparse Pre-trained Language Models", "topic_distr": {"0": 0.001400945708155632, "1": 0.0011443221010267735, "2": 0.3548654615879059, "3": 0.0008378081256523728, "4": 0.0007389133679680526, "5": 0.0006609035190194845, "6": 0.000597792852204293, "7": 0.0005456844810396433, "8": 0.0005019322270527482, "9": 0.00046467516222037375, "10": 0.14577142894268036, "11": 0.0004046091344207525, "12": 0.00038004585076123476, "13": 0.3795359432697296, "14": 0.0709109976887703, "15": 0.00032149357139132917, "16": 0.0400802381336689, "17": 0.0002915484074037522, "18": 0.00027857464738190174, "19": 0.00026670630904845893}}, {"key": "zaheer2020big", "year": "2020", "title": "Big Bird: Transformers For Longer Sequences", "topic_distr": {"0": 0.0015036152908578515, "1": 0.0012271892046555877, "2": 0.46605804562568665, "3": 0.000898489379324019, "4": 0.0007924258825369179, "5": 0.0007087664562277496, "6": 0.000641085032839328, "7": 0.0005852031172253191, "8": 0.03969760611653328, "9": 0.0004983270191587508, "10": 0.394474595785141, "11": 0.00043391098733991385, "12": 0.00040756884845905006, "13": 0.09013956040143967, "14": 0.00036344086402095854, "15": 0.0003447761991992593, "16": 0.00032793497666716576, "17": 0.00031266239238902926, "18": 0.00029874907340854406, "19": 0.00028602121165022254}}, {"key": "zaib2021short", "year": "2021", "title": "A Short Survey Of Pre-trained Language Models For Conversational AI-A Newage In NLP", "topic_distr": {"0": 0.0013279542326927185, "1": 0.15918022394180298, "2": 0.20617146790027618, "3": 0.0007933978922665119, "4": 0.0006997401360422373, "5": 0.0936439260840416, "6": 0.17103588581085205, "7": 0.0005167547496967018, "8": 0.00047532201278954744, "9": 0.055433616042137146, "10": 0.00040963408537209034, "11": 0.10208760201931, "12": 0.1931772083044052, "13": 0.00033929909113794565, "14": 0.00032093096524477005, "15": 0.00030444940784946084, "16": 0.0002895780198741704, "17": 0.0002760917996056378, "18": 0.0002638058504089713, "19": 0.01325308345258236}}, {"key": "zaken2021simple", "year": "2021", "title": "Bitfit: Simple Parameter-efficient Fine-tuning For Transformer-based Masked Language-models", "topic_distr": {"0": 0.0028344562742859125, "1": 0.08162219077348709, "2": 0.4421776235103607, "3": 0.049184344708919525, "4": 0.001494844676926732, "5": 0.0013370265951380134, "6": 0.001209351816214621, "7": 0.0011039352975785732, "8": 0.05412859842181206, "9": 0.0009400510462000966, "10": 0.18201357126235962, "11": 0.0008185357437469065, "12": 0.0007688435143791139, "13": 0.0007248395122587681, "14": 0.0006855999235995114, "15": 0.0006503906333819032, "16": 0.07588772475719452, "17": 0.0005898107192479074, "18": 0.0005635644192807376, "19": 0.10126467049121857}}, {"key": "zakka2023retrieval", "year": "2023", "title": "Almanac: Retrieval-augmented Language Models For Clinical Medicine", "topic_distr": {"0": 0.15084782242774963, "1": 0.0014345055678859353, "2": 0.0012126388028264046, "3": 0.2697465717792511, "4": 0.11680953949689865, "5": 0.019665680825710297, "6": 0.0007494157180190086, "7": 0.06780160218477249, "8": 0.028610344976186752, "9": 0.0005825343541800976, "10": 0.0005422822432592511, "11": 0.0005072333151474595, "12": 0.10814155638217926, "13": 0.23108792304992676, "14": 0.0004248551558703184, "15": 0.0004030365089420229, "16": 0.00038334945566020906, "17": 0.00036549611832015216, "18": 0.00034923170460388064, "19": 0.0003343531279824674}}, {"key": "zan2022continual", "year": "2022", "title": "CERT: Continual Pre-training On Sketches For Library-oriented Code Generation", "topic_distr": {"0": 0.0012991288676857948, "1": 0.055803168565034866, "2": 0.0008969090995378792, "3": 0.11966101080179214, "4": 0.000685135368257761, "5": 0.0006128030363470316, "6": 0.5442109107971191, "7": 0.0005059696268290281, "8": 0.0004654016229324043, "9": 0.0004308561037760228, "10": 0.05617348849773407, "11": 0.0003751617041416466, "12": 0.0003523861232679337, "13": 0.12602499127388, "14": 0.00031423286418430507, "15": 0.05244242772459984, "16": 0.038970086723566055, "17": 0.0002703295322135091, "18": 0.00025829998776316643, "19": 0.000247295422013849}}, {"key": "zan2022large", "year": "2022", "title": "Large Language Models Meet Nl2code: A Survey", "topic_distr": {"0": 0.0720907598733902, "1": 0.0012893544044345617, "2": 0.0010898957261815667, "3": 0.17547127604484558, "4": 0.0008325637900270522, "5": 0.0007446673698723316, "6": 0.09839734435081482, "7": 0.0006148453103378415, "8": 0.0005655477871187031, "9": 0.000523568713106215, "10": 0.00048739099293015897, "11": 0.00045588985085487366, "12": 0.6450016498565674, "13": 0.00040370499482378364, "14": 0.0003818502009380609, "15": 0.0003622400981839746, "16": 0.00034454584238119423, "17": 0.0003284996491856873, "18": 0.0003138815809506923, "19": 0.00030050904024392366}}, {"key": "zandie2020multi", "year": "2020", "title": "Emptransfo: A Multi-head Transformer Architecture For Creating Empathetic Dialog Systems", "topic_distr": {"0": 0.0027117207646369934, "1": 0.00221395306289196, "2": 0.1959524154663086, "3": 0.0016210309695452452, "4": 0.28967365622520447, "5": 0.0012787423329427838, "6": 0.0011566332541406155, "7": 0.16648957133293152, "8": 0.00097115826793015, "9": 0.09697230160236359, "10": 0.147816002368927, "11": 0.0007828536909073591, "12": 0.0007353276596404612, "13": 0.0006932418909855187, "14": 0.0006557128508575261, "15": 0.08806487172842026, "16": 0.0005916538066230714, "17": 0.0005640993476845324, "18": 0.0005389971775002778, "19": 0.0005160338478162885}}, {"key": "zang2022unified", "year": "2022", "title": "Unified Vision And Language Prompt Learning", "topic_distr": {"0": 0.001223230268806219, "1": 0.000998459872789681, "2": 0.0008440485689789057, "3": 0.0007310452056117356, "4": 0.0006447528139688075, "5": 0.0005766839603893459, "6": 0.0005216156132519245, "7": 0.0004761474847327918, "8": 0.00043797059333883226, "9": 0.0004054612072650343, "10": 0.00037744452129118145, "11": 0.0003530494577717036, "12": 0.10644545406103134, "13": 0.0003126365481875837, "14": 0.021935157477855682, "15": 0.00028052538982592523, "16": 0.00026682260795496404, "17": 0.5547240376472473, "18": 0.3082127273082733, "19": 0.00023271969985216856}}, {"key": "zang2023contextual", "year": "2023", "title": "Contextual Object Detection With Multimodal Large Language Models", "topic_distr": {"0": 0.0011448682053014636, "1": 0.0009343150886707008, "2": 0.0007898684125393629, "3": 0.11273960769176483, "4": 0.0006033651297912002, "5": 0.0005396653432399035, "6": 0.0004881319182459265, "7": 0.07987848669290543, "8": 0.03484537452459335, "9": 0.026923738420009613, "10": 0.00035321549512445927, "11": 0.00033038639230653644, "12": 0.000310329080093652, "13": 0.00029256768175400794, "14": 0.00027672937721945345, "15": 0.08270640671253204, "16": 0.0002496946544852108, "17": 0.00023806588433217257, "18": 0.6395615339279175, "19": 0.016793638467788696}}, {"key": "zelikman2022bootstrapping", "year": "2022", "title": "Star: Bootstrapping Reasoning With Reasoning", "topic_distr": {"0": 0.001539692166261375, "1": 0.001257477910257876, "2": 0.0010628518648445606, "3": 0.43509534001350403, "4": 0.0008118959376588464, "5": 0.0007261810242198408, "6": 0.000656836898997426, "7": 0.0999511107802391, "8": 0.1905742734670639, "9": 0.0005105711752548814, "10": 0.0004752915701828897, "11": 0.21130764484405518, "12": 0.0004175830399617553, "13": 0.05363216623663902, "14": 0.0003723708214238286, "15": 0.00035324753844179213, "16": 0.00033599251764826477, "17": 0.00032034466858021915, "18": 0.00030608949600718915, "19": 0.00029304891359061003}}, {"key": "zellers2019can", "year": "2019", "title": "Hellaswag: Can A Machine Really Finish Your Sentence?", "topic_distr": {"0": 0.0012876808177679777, "1": 0.2521577775478363, "2": 0.20711903274059296, "3": 0.11685522645711899, "4": 0.0006780675612390041, "5": 0.013401632197201252, "6": 0.0005485670408234, "7": 0.0005007496220059693, "8": 0.10050791501998901, "9": 0.0004264110466465354, "10": 0.06345440447330475, "11": 0.03173353895545006, "12": 0.10363775491714478, "13": 0.054309699684381485, "14": 0.03241293132305145, "15": 0.00029501988319680095, "16": 0.0002806090924423188, "17": 0.0002675405703485012, "18": 0.0002556351537350565, "19": 0.01986982859671116}}, {"key": "zellers2021multimodal", "year": "2021", "title": "MERLOT: Multimodal Neural Script Knowledge Models", "topic_distr": {"0": 0.06910380721092224, "1": 0.03701099008321762, "2": 0.13583271205425262, "3": 0.0006717899232171476, "4": 0.0005924899014644325, "5": 0.0005299386102706194, "6": 0.00047933400492183864, "7": 0.00043755146907642484, "8": 0.05998586118221283, "9": 0.0003725949500221759, "10": 0.0003468492650426924, "11": 0.0003244316321797669, "12": 0.00030473581864498556, "13": 0.03989031910896301, "14": 0.04535887762904167, "15": 0.0002577863051556051, "16": 0.04177325218915939, "17": 0.00023377506295219064, "18": 0.4405582845211029, "19": 0.12593460083007812}}, {"key": "zellers2022merlot", "year": "2022", "title": "MERLOT Reserve: Neural Script Knowledge Through Vision And Language And Sound", "topic_distr": {"0": 0.0010952085722237825, "1": 0.0008934346260502934, "2": 0.20669229328632355, "3": 0.0006541643524542451, "4": 0.0005769440322183073, "5": 0.0005160339642316103, "6": 0.04225204512476921, "7": 0.0004260708810761571, "8": 0.03903574123978615, "9": 0.07344303280115128, "10": 0.0003377485554665327, "11": 0.04231138154864311, "12": 0.00029674009419977665, "13": 0.00027975643752142787, "14": 0.00026461167726665735, "15": 0.0002510224294383079, "16": 0.033405009657144547, "17": 0.00022764121240470558, "18": 0.39435532689094543, "19": 0.1626857966184616}}, {"key": "zeng2021pangu", "year": "2021", "title": "Pangu-\\(\u03b1\\): Large-scale Autoregressive Pretrained Chinese Language Models With Auto-parallel Computation", "topic_distr": {"0": 0.0013273912481963634, "1": 0.0010837521404027939, "2": 0.04474779963493347, "3": 0.13783754408359528, "4": 0.0006996727897785604, "5": 0.015782952308654785, "6": 0.0005660464521497488, "7": 0.0005167053896002471, "8": 0.024964330717921257, "9": 0.020644158124923706, "10": 0.13810905814170837, "11": 0.00038312195101752877, "12": 0.09307023137807846, "13": 0.1973215639591217, "14": 0.0003209003189112991, "15": 0.14018619060516357, "16": 0.0002895503712352365, "17": 0.0952058658003807, "18": 0.0002637806464917958, "19": 0.0866793766617775}}, {"key": "zeng2022glm", "year": "2022", "title": "GLM-130B: An Open Bilingual Pre-trained Model", "topic_distr": {"0": 0.03471750393509865, "1": 0.001170861884020269, "2": 0.0009897110285237432, "3": 0.0008572101942263544, "4": 0.000756019726395607, "5": 0.0006762038101442158, "6": 0.0006116320728324354, "7": 0.000558317406103015, "8": 0.0005135522806085646, "9": 0.00047543266555294394, "10": 0.10565599799156189, "11": 0.0004139760567341, "12": 0.21340884268283844, "13": 0.43252211809158325, "14": 0.11160370707511902, "15": 0.0003289363521616906, "16": 0.00031286885496228933, "17": 0.09386922419071198, "18": 0.0002850237942766398, "19": 0.00027288071578368545}}, {"key": "zeng2022socratic", "year": "2022", "title": "Socratic Models: Composing Zero-shot Multimodal Reasoning With Language", "topic_distr": {"0": 0.001371301943436265, "1": 0.0011193023528903723, "2": 0.0009460952715016901, "3": 0.28964942693710327, "4": 0.0007227197638712823, "5": 0.0006464198231697083, "6": 0.05702021345496178, "7": 0.0005337254260666668, "8": 0.0686941146850586, "9": 0.0004544914700090885, "10": 0.0004230868653394282, "11": 0.07207135856151581, "12": 0.0003717168583534658, "13": 0.00035044201649725437, "14": 0.0003314706264063716, "15": 0.00031444779597222805, "16": 0.040690477937459946, "17": 0.00028515889425762, "18": 0.316977858543396, "19": 0.1470262110233307}}, {"key": "zeng2024how", "year": "2024", "title": "How Johnny Can Persuade Llms To Jailbreak Them: Rethinking Persuasion To Challenge AI Safety By Humanizing Llms", "topic_distr": {"0": 0.07466019690036774, "1": 0.14777971804141998, "2": 0.0009895903058350086, "3": 0.15020424127578735, "4": 0.06436198949813843, "5": 0.0006761124241165817, "6": 0.0006115492433309555, "7": 0.0005582418525591493, "8": 0.000513482722453773, "9": 0.3060184121131897, "10": 0.00044252112274989486, "11": 0.0004139200027566403, "12": 0.18355168402194977, "13": 0.00036653937422670424, "14": 0.00034669655724428594, "15": 0.00032889179419726133, "16": 0.00031282647978514433, "17": 0.06730557978153229, "18": 0.0002849852025974542, "19": 0.0002728437539190054}}, {"key": "zenkel2019adding", "year": "2019", "title": "Adding Interpretable Attention To Neural Translation Models Improves Word Alignment", "topic_distr": {"0": 0.0014027549186721444, "1": 0.0011443878756836057, "2": 0.6245882511138916, "3": 0.0008379095233976841, "4": 0.0007390038226731122, "5": 0.000660984602291137, "6": 0.0005978661356493831, "7": 0.0005457513616420329, "8": 0.0005019937525503337, "9": 0.0004647320893127471, "10": 0.09847662597894669, "11": 0.00040465869824402034, "12": 0.00038009241688996553, "13": 0.0003583381767384708, "14": 0.1761477142572403, "15": 0.00032153294887393713, "16": 0.00030582709587179124, "17": 0.0002915841178037226, "18": 0.09156331419944763, "19": 0.00026673899265006185}}, {"key": "zha2019context", "year": "2019", "title": "Context-aware Visual Policy Network For Fine-grained Image Captioning", "topic_distr": {"0": 0.0009669846040196717, "1": 0.0007894893060438335, "2": 0.2359563261270523, "3": 0.0005780388601124287, "4": 0.08567509800195694, "5": 0.0004559841472655535, "6": 0.00041244146996177733, "7": 0.1448105126619339, "8": 0.00034630336449481547, "9": 0.00032059819204732776, "10": 0.0002984454040415585, "11": 0.08220679312944412, "12": 0.0002622090105433017, "13": 0.0002472017367836088, "14": 0.00023381932987831533, "15": 0.00022181142412591726, "16": 0.00021097665012348443, "17": 0.00020115105144213885, "18": 0.4456217586994171, "19": 0.00018401147099211812}}, {"key": "zhai2022high", "year": "2022", "title": "Bytetransformer: A High-performance Transformer Boosted For Variable-length Inputs", "topic_distr": {"0": 0.001400791690684855, "1": 0.001144890091381967, "2": 0.0009674575412645936, "3": 0.06867557764053345, "4": 0.0007390087703242898, "5": 0.0006609878619201481, "6": 0.0005978691042400897, "7": 0.0005457541556097567, "8": 0.000501996255479753, "9": 0.0004647344467230141, "10": 0.5584145188331604, "11": 0.0004046607355121523, "12": 0.0003800943377427757, "13": 0.3632984161376953, "14": 0.0003389410558156669, "15": 0.0003215345786884427, "16": 0.00030582863837480545, "17": 0.0002915856020990759, "18": 0.0002786101831588894, "19": 0.00026674033142626286}}, {"key": "zhan2023deceptive", "year": "2023", "title": "Deceptive AI Ecosystems: The Case Of Chatgpt", "topic_distr": {"0": 0.24777695536613464, "1": 0.0014144012238830328, "2": 0.0011956999078392982, "3": 0.0010356225538998842, "4": 0.05167720094323158, "5": 0.0008169490029104054, "6": 0.0007389372331090271, "7": 0.0006745256832800806, "8": 0.0006204430828802288, "9": 0.6898729801177979, "10": 0.0005346999387256801, "11": 0.000500141060911119, "12": 0.0004697781696449965, "13": 0.00044289088691584766, "14": 0.00041891474393196404, "15": 0.0003974011924583465, "16": 0.0003779894032049924, "17": 0.0003603856894187629, "18": 0.0003443486930336803, "19": 0.00032967812148854136}}, {"key": "zhang2017asking", "year": "2017", "title": "Asking The Difficult Questions: Goal-oriented Visual Question Generation Via Intermediate Rewards", "topic_distr": {"0": 0.0015221817884594202, "1": 0.0012423008447512984, "2": 0.0010500794742256403, "3": 0.05950669199228287, "4": 0.0008021352696232498, "5": 0.0007174505153670907, "6": 0.0006489400984719396, "7": 0.0005923733697272837, "8": 0.19716596603393555, "9": 0.0005044328281655908, "10": 0.0004695773823186755, "11": 0.4877470135688782, "12": 0.07055293768644333, "13": 0.00038895002217032015, "14": 0.00036789398291148245, "15": 0.10393033176660538, "16": 0.0003319530515000224, "17": 0.0003164933295920491, "18": 0.07185276597738266, "19": 0.00028952574939467013}}, {"key": "zhang2017flexible", "year": "2017", "title": "Flexible And Creative Chinese Poetry Generation Using Neural Memory", "topic_distr": {"0": 0.0019206420984119177, "1": 0.00156698958016932, "2": 0.4160226285457611, "3": 0.0011473126942291856, "4": 0.0010118832578882575, "5": 0.0009050550870597363, "6": 0.0008186298655346036, "7": 0.13098010420799255, "8": 0.0006873563979752362, "9": 0.11055530607700348, "10": 0.0005923660355620086, "11": 0.10322751104831696, "12": 0.0005204426706768572, "13": 0.0004906555986963212, "14": 0.00046409369679167867, "15": 0.2275243103504181, "16": 0.000418754672864452, "17": 0.0003992524289060384, "18": 0.0003814858791884035, "19": 0.0003652331361081451}}, {"key": "zhang2017neural", "year": "2017", "title": "Neural Personalized Response Generation As Domain Adaptation", "topic_distr": {"0": 0.0020445024129003286, "1": 0.0016692669596523046, "2": 0.001411217381246388, "3": 0.0012223016237840056, "4": 0.3445492088794708, "5": 0.0009642115910537541, "6": 0.29978615045547485, "7": 0.23777613043785095, "8": 0.0007322836318053305, "9": 0.0006779282120987773, "10": 0.000631084491033107, "11": 0.0005902961129322648, "12": 0.0005544600426219404, "13": 0.0005227260407991707, "14": 0.0004944279789924622, "15": 0.1047067642211914, "16": 0.0004461254575289786, "17": 0.00042534852400422096, "18": 0.0004064207023475319, "19": 0.0003891056403517723}}, {"key": "zhang2018generating", "year": "2018", "title": "Generating Informative And Diverse Conversational Responses Via Adversarial Information Maximization", "topic_distr": {"0": 0.002229080069810152, "1": 0.33198481798171997, "2": 0.0015373950591310859, "3": 0.0013315824326127768, "4": 0.001174401375465095, "5": 0.0010504134697839618, "6": 0.5269647240638733, "7": 0.0008672889671288431, "8": 0.12675203382968903, "9": 0.0007385359494946897, "10": 0.0006875043618492782, "11": 0.0006430693902075291, "12": 0.0006040295120328665, "13": 0.0005694584688171744, "14": 0.0005386305274441838, "15": 0.0005109689082019031, "16": 0.00048600969603285193, "17": 0.0004633752687368542, "18": 0.00044275529216974974, "19": 0.0004238922265358269}}, {"key": "zhang2018improving", "year": "2018", "title": "Improving The Transformer Translation Model With Document-level Context", "topic_distr": {"0": 0.002187938429415226, "1": 0.027703607454895973, "2": 0.5111110210418701, "3": 0.001308225910179317, "4": 0.0011538044782355428, "5": 0.0010319931898266077, "6": 0.0009334465721622109, "7": 0.0008520800620317459, "8": 0.0007837613811716437, "9": 0.000725584861356765, "10": 0.1524875909090042, "11": 0.0006317924708127975, "12": 0.0005934371729381382, "13": 0.00055947236251086, "14": 0.29565009474754333, "15": 0.0005020084790885448, "16": 0.00047748698852956295, "17": 0.0004552494501695037, "18": 0.0004349910595919937, "19": 0.00041645881719887257}}, {"key": "zhang2018language", "year": "2018", "title": "Language Modeling Teaches You More Syntax Than Translation Does: Lessons Learned Through Auxiliary Task Analysis", "topic_distr": {"0": 0.08749983459711075, "1": 0.12318164855241776, "2": 0.5167732834815979, "3": 0.0007687640027143061, "4": 0.0006780195981264114, "5": 0.0006064384942874312, "6": 0.000548528740182519, "7": 0.0005007146974094212, "8": 0.00046056800056248903, "9": 0.0004263813025318086, "10": 0.00039691905840300024, "11": 0.00037126531242392957, "12": 0.000348726287484169, "13": 0.00032876725890673697, "14": 0.06739892065525055, "15": 0.00029499930678866804, "16": 0.00028058953466825187, "17": 0.00026752191479317844, "18": 0.00025561731308698654, "19": 0.1986125409603119}}, {"key": "zhang2018regularizing", "year": "2018", "title": "Regularizing Neural Machine Translation By Target-bidirectional Agreement", "topic_distr": {"0": 0.0015217321924865246, "1": 0.0012421829160302877, "2": 0.23692457377910614, "3": 0.0009094664710573852, "4": 0.13361811637878418, "5": 0.0007174259517341852, "6": 0.0006489178049378097, "7": 0.20539280772209167, "8": 0.0005448589217849076, "9": 0.0005044155404902995, "10": 0.0004695612587966025, "11": 0.00043921248288825154, "12": 0.0004125484556425363, "13": 0.11066295951604843, "14": 0.30440187454223633, "15": 0.000348988629411906, "16": 0.00033194164279848337, "17": 0.00031648247386328876, "18": 0.0003023991594091058, "19": 0.0002895157958846539}}, {"key": "zhang2019addressing", "year": "2019", "title": "Addressing Semantic Drift In Question Generation For Semi-supervised Question Answering", "topic_distr": {"0": 0.0009908481733873487, "1": 0.11734084784984589, "2": 0.16856041550636292, "3": 0.0005918124224990606, "4": 0.14793026447296143, "5": 0.0004668478504754603, "6": 0.00042226779623888433, "7": 0.10264287143945694, "8": 0.33279111981391907, "9": 0.0003282363759353757, "10": 0.04874061793088913, "11": 0.0002858070656657219, "12": 0.0002684560895431787, "13": 0.0002530912752263248, "14": 0.01569247990846634, "15": 0.00022709603945259005, "16": 0.061875831335783005, "17": 0.0002059434336842969, "18": 0.00019677904492709786, "19": 0.00018839551194105297}}, {"key": "zhang2019consistent", "year": "2019", "title": "Consistent Dialogue Generation With Self-supervised Feature Learning", "topic_distr": {"0": 0.14131887257099152, "1": 0.0011193995596840978, "2": 0.15727970004081726, "3": 0.0008194581605494022, "4": 0.026897121220827103, "5": 0.0006464289617724717, "6": 0.4214749336242676, "7": 0.13389408588409424, "8": 0.0004909391282126307, "9": 0.00045449804747477174, "10": 0.00042309300624765456, "11": 0.0636582225561142, "12": 0.0003717222425621003, "13": 0.00035044708056375384, "14": 0.00033147542853839695, "15": 0.00031445236527360976, "16": 0.04933667927980423, "17": 0.0002851630561053753, "18": 0.0002724734367802739, "19": 0.0002608650247566402}}, {"key": "zhang2019detecting", "year": "2019", "title": "Recosa: Detecting The Relevant Contexts With Self-attention For Multi-turn Dialogue Generation", "topic_distr": {"0": 0.06628895550966263, "1": 0.0009175502345897257, "2": 0.3090030550956726, "3": 0.000671832705847919, "4": 0.03381485491991043, "5": 0.07941286265850067, "6": 0.3439134955406189, "7": 0.0004375810967758298, "8": 0.00040249640005640686, "9": 0.0003726201830431819, "10": 0.0911383256316185, "11": 0.00032445360557176173, "12": 0.0003047564532607794, "13": 0.00028731400379911065, "14": 0.00027176010189577937, "15": 0.04424087330698967, "16": 0.027526142075657845, "17": 0.0002337908954359591, "18": 0.00022338730923365802, "19": 0.00021387016749940813}}, {"key": "zhang2019evaluating", "year": "2019", "title": "Bertscore: Evaluating Text Generation With BERT", "topic_distr": {"0": 0.12791584432125092, "1": 0.060475725680589676, "2": 0.18500125408172607, "3": 0.001222437946125865, "4": 0.08948005735874176, "5": 0.0009643165394663811, "6": 0.0008722324855625629, "7": 0.15246236324310303, "8": 0.000732363376300782, "9": 0.0006780020194128156, "10": 0.21520526707172394, "11": 0.0005903603741899133, "12": 0.0005545204039663076, "13": 0.0005227829678915441, "14": 0.07405046373605728, "15": 0.03455710411071777, "16": 0.00044617406092584133, "17": 0.0004253948281984776, "18": 0.053454212844371796, "19": 0.0003891480155289173}}, {"key": "zhang2019large", "year": "2019", "title": "Dialogpt: Large-scale Generative Pre-training For Conversational Response Generation", "topic_distr": {"0": 0.04154813289642334, "1": 0.0018517583375796676, "2": 0.0015654090093448758, "3": 0.07456934452056885, "4": 0.0011957961833104491, "5": 0.0010695516830310225, "6": 0.6125603914260864, "7": 0.0008830904844217002, "8": 0.0008122854051180184, "9": 0.0007519916398450732, "10": 0.07495523989200592, "11": 0.0006547857774421573, "12": 0.07595361769199371, "13": 0.0005798336933366954, "14": 0.0005484441062435508, "15": 0.10865116864442825, "16": 0.0004948645364493132, "17": 0.0004718177078757435, "18": 0.0004508220299612731, "19": 0.00043161530629731715}}, {"key": "zhang2019pre", "year": "2019", "title": "PEGASUS: Pre-training With Extracted Gap-sentences For Abstractive Summarization", "topic_distr": {"0": 0.0013417275622487068, "1": 0.0010952632874250412, "2": 0.12939974665641785, "3": 0.0008018158841878176, "4": 0.0007071648142300546, "5": 0.0006325067952275276, "6": 0.00057210773229599, "7": 0.19822043180465698, "8": 0.00048036593943834305, "9": 0.0004447096725925803, "10": 0.24242588877677917, "11": 0.00038722448516637087, "12": 0.129756897687912, "13": 0.00034289961331523955, "14": 0.00032433654996566474, "15": 0.21064966917037964, "16": 0.0002926509187091142, "17": 0.00027902156580239534, "18": 0.00026660526054911315, "19": 0.08157897740602493}}, {"key": "zhang2019semantics", "year": "2019", "title": "Semantics-aware BERT For Language Understanding", "topic_distr": {"0": 0.0014513242058455944, "1": 0.1371576339006424, "2": 0.2434501051902771, "3": 0.0008671634132042527, "4": 0.0007647991296835244, "5": 0.0006840566638857126, "6": 0.000618735037278384, "7": 0.0005648012738674879, "8": 0.0005195162375457585, "9": 0.00048095392412506044, "10": 0.3317623436450958, "11": 0.00041878363117575645, "12": 0.00039335983456112444, "13": 0.00037084624636918306, "14": 0.00035077030770480633, "15": 0.00033275631722062826, "16": 0.26418548822402954, "17": 0.00030176210566423833, "18": 0.00028833383112214506, "19": 0.015036415308713913}}, {"key": "zhang2019sequence", "year": "2019", "title": "Sequence-to-sequence Pre-training With Data Augmentation For Sentence Rewriting", "topic_distr": {"0": 0.0014859804650768638, "1": 0.2197396159172058, "2": 0.6448391675949097, "3": 0.000887731381226331, "4": 0.000782943912781775, "5": 0.0007002849597483873, "6": 0.0006334136123768985, "7": 0.0005782003863714635, "8": 0.0005318410112522542, "9": 0.0004923638771288097, "10": 0.0004583423724398017, "11": 0.0004287186893634498, "12": 0.00040269174496643245, "13": 0.00037964407238177955, "14": 0.12610769271850586, "15": 0.0003406504984013736, "16": 0.000324010819895193, "17": 0.0003089209785684943, "18": 0.00029517413349822164, "19": 0.00028259860118851066}}, {"key": "zhang2019sg", "year": "2019", "title": "Sg-net: Syntax-guided Machine Reading Comprehension", "topic_distr": {"0": 0.0014035198837518692, "1": 0.0011447457363829017, "2": 0.5400351881980896, "3": 0.024618588387966156, "4": 0.0007391460239887238, "5": 0.0006611109129153192, "6": 0.03834860771894455, "7": 0.0005458557279780507, "8": 0.01633426360785961, "9": 0.000464820972410962, "10": 0.2706713378429413, "11": 0.0004047360853292048, "12": 0.000380165089154616, "13": 0.0003584067162591964, "14": 0.00033900418202392757, "15": 0.0003215944452676922, "16": 0.10239183902740479, "17": 0.0002916398807428777, "18": 0.0002786620461847633, "19": 0.00026678998256102204}}, {"key": "zhang2019synchronous", "year": "2019", "title": "Synchronous Bidirectional Inference For Neural Sequence Generation", "topic_distr": {"0": 0.001247662235982716, "1": 0.001018426613882184, "2": 0.3012157380580902, "3": 0.0007457357132807374, "4": 0.03805333375930786, "5": 0.0005882722325623035, "6": 0.0005320971831679344, "7": 0.19323886930942535, "8": 0.0004467713588383049, "9": 0.00041360873728990555, "10": 0.23873716592788696, "11": 0.00036014377838000655, "12": 0.00033827993320301175, "13": 0.11377070099115372, "14": 0.10798995941877365, "15": 0.00028616239433176816, "16": 0.0002721842611208558, "17": 0.0002595081168692559, "18": 0.00024796012439765036, "19": 0.00023739607422612607}}, {"key": "zhang2019task", "year": "2019", "title": "Task-oriented Dialog Systems That Consider Multiple Appropriate Responses Under The Same Context", "topic_distr": {"0": 0.0011550780618563294, "1": 0.02317693829536438, "2": 0.21260008215904236, "3": 0.0006904871552251279, "4": 0.3549928367137909, "5": 0.0005446885479614139, "6": 0.25040337443351746, "7": 0.00044972990872338414, "8": 0.0004136711359024048, "9": 0.0003829654597211629, "10": 0.00035650318022817373, "11": 0.13493172824382782, "12": 0.0003132175770588219, "13": 0.0002952908689621836, "14": 0.00027930515352636576, "15": 0.0002649613015819341, "16": 0.018059421330690384, "17": 0.0002402817626716569, "18": 0.00022958933550398797, "19": 0.00021980797464493662}}, {"key": "zhang2020accelerating", "year": "2020", "title": "Accelerating Training Of Transformer-based Language Models With Progressive Layer Dropping", "topic_distr": {"0": 0.0015581428306177258, "1": 0.0012731208698824048, "2": 0.27748364210128784, "3": 0.04173347353935242, "4": 0.0008221038151532412, "5": 0.0007353113614954054, "6": 0.000665095285512507, "7": 0.0006071203970350325, "8": 0.0005584422615356743, "9": 0.0005169906071387231, "10": 0.2243885099887848, "11": 0.0004501620423980057, "12": 0.0004228333127684891, "13": 0.39281171560287476, "14": 0.0003770526382140815, "15": 0.000357688928488642, "16": 0.0003402169677428901, "17": 0.05429169908165932, "18": 0.00030993795371614397, "19": 0.00029673342942260206}}, {"key": "zhang2020constrained", "year": "2020", "title": "POINTER: Constrained Progressive Text Generation Via Insertion-based Generative Pre-training", "topic_distr": {"0": 0.0015390744665637612, "1": 0.0012573539279401302, "2": 0.2190413922071457, "3": 0.0009206851827912033, "4": 0.0008120023412629962, "5": 0.0007262764265760779, "6": 0.047274526208639145, "7": 0.31020843982696533, "8": 0.0005515803932212293, "9": 0.0005106381140649319, "10": 0.19132184982299805, "11": 0.026246855035424232, "12": 0.06351620703935623, "13": 0.0003937346627935767, "14": 0.0003724195994436741, "15": 0.13405127823352814, "16": 0.0003360365517437458, "17": 0.0003203866654075682, "18": 0.00030612960108555853, "19": 0.0002930873306468129}}, {"key": "zhang2020distillation", "year": "2020", "title": "Ternarybert: Distillation-aware Ultra-low Bit BERT", "topic_distr": {"0": 0.0020112597849220037, "1": 0.0016424907371401787, "2": 0.16826745867729187, "3": 0.0012026653857901692, "4": 0.0010607020230963826, "5": 0.0009487204952165484, "6": 0.0008581256843172014, "7": 0.0007833247072994709, "8": 0.0007205187575891614, "9": 0.000667036569211632, "10": 0.2689248323440552, "11": 0.0005808123969472945, "12": 0.0005455520586110651, "13": 0.509596049785614, "14": 0.04008873179554939, "15": 0.00046150083653628826, "16": 0.00043895799899473786, "17": 0.0004185148573014885, "18": 0.0003998911415692419, "19": 0.00038285425398498774}}, {"key": "zhang2020large", "year": "2020", "title": "CPM: A Large-scale Generative Chinese Pre-trained Language Model", "topic_distr": {"0": 0.0015781506663188338, "1": 0.18644283711910248, "2": 0.024635355919599533, "3": 0.0009438456618227065, "4": 0.0008324335794895887, "5": 0.0007445503724738955, "6": 0.028009552508592606, "7": 0.0006147486856207252, "8": 0.0005654589622281492, "9": 0.0005234864656813443, "10": 0.0004873144207522273, "11": 0.0004558181972242892, "12": 0.00042814610060304403, "13": 0.2556549608707428, "14": 0.0003817901888396591, "15": 0.39544275403022766, "16": 0.00034449168015271425, "17": 0.00032844801899045706, "18": 0.00031383224995806813, "19": 0.10127202421426773}}, {"key": "zhang2020machine", "year": "2020", "title": "Machine Reading Comprehension: The Role Of Contextualized Language Models And Beyond", "topic_distr": {"0": 0.1668432056903839, "1": 0.0010392386466264725, "2": 0.149296373128891, "3": 0.025163335725665092, "4": 0.0636293888092041, "5": 0.0006002541049383581, "6": 0.000542934809345752, "7": 0.0004956083721481264, "8": 0.0004558711079880595, "9": 0.05383992940187454, "10": 0.00039287126855924726, "11": 0.0003674791078083217, "12": 0.432120680809021, "13": 0.0003254144685342908, "14": 0.0568629689514637, "15": 0.00029199087293818593, "16": 0.0002777280460577458, "17": 0.0002647937217261642, "18": 0.00025301051209680736, "19": 0.04693693295121193}}, {"key": "zhang2020retrospective", "year": "2020", "title": "Retrospective Reader For Machine Reading Comprehension", "topic_distr": {"0": 0.09027594327926636, "1": 0.0009258530917577446, "2": 0.28725674748420715, "3": 0.09510326385498047, "4": 0.0005979331908747554, "5": 0.0005348069244064391, "6": 0.0004837373271584511, "7": 0.00044157099910080433, "8": 0.4013078510761261, "9": 0.021314261481165886, "10": 0.058956414461135864, "11": 0.00032741198083385825, "12": 0.00030753525788895786, "13": 0.0002899337559938431, "14": 0.00027423803112469614, "15": 0.0002601544256322086, "16": 0.04066519811749458, "17": 0.0002359226200496778, "18": 0.00022542416991200298, "19": 0.00021582025510724634}}, {"key": "zhang2020trading", "year": "2020", "title": "Trading Off Diversity And Quality In Natural Language Generation", "topic_distr": {"0": 0.0014519598335027695, "1": 0.0011845164699479938, "2": 0.14682137966156006, "3": 0.13628849387168884, "4": 0.0317266620695591, "5": 0.033992376178503036, "6": 0.02347310073673725, "7": 0.4289831221103668, "8": 0.0005195288686081767, "9": 0.00048096562386490405, "10": 0.0004477316979318857, "11": 0.08624879270792007, "12": 0.0003933694097213447, "13": 0.10612181574106216, "14": 0.00035077883512713015, "15": 0.00033276440808549523, "16": 0.00031650991877540946, "17": 0.00030176943982951343, "18": 0.00028834084514528513, "19": 0.00027605643845163286}}, {"key": "zhang2020trojaning", "year": "2020", "title": "Trojaning Language Models For Fun And Profit", "topic_distr": {"0": 0.051102083176374435, "1": 0.1369001865386963, "2": 0.0007972474559210241, "3": 0.08543353527784348, "4": 0.0715968981385231, "5": 0.0005447125295177102, "6": 0.0004926969995722175, "7": 0.13306185603141785, "8": 0.039422500878572464, "9": 0.03669800981879234, "10": 0.06967040151357651, "11": 0.000333476229570806, "12": 0.16418345272541046, "13": 0.0002953038492705673, "14": 0.00027931740623898804, "15": 0.00026497291401028633, "16": 0.00025202982942573726, "17": 0.07915470749139786, "18": 0.00022959941998124123, "19": 0.129286989569664}}, {"key": "zhang2020unified", "year": "2020", "title": "Unified Mandarin TTS Front-end Based On Distilled BERT Model", "topic_distr": {"0": 0.05413300171494484, "1": 0.0013954221503809094, "2": 0.19058991968631744, "3": 0.0010216791415587068, "4": 0.08881796151399612, "5": 0.020888887345790863, "6": 0.0007289837230928242, "7": 0.0006654397584497929, "8": 0.0006120856269262731, "9": 0.0005666522192768753, "10": 0.20792777836322784, "11": 0.0004934041644446552, "12": 0.00046345024020411074, "13": 0.24144749343395233, "14": 0.024929506704211235, "15": 0.0865306407213211, "16": 0.0003728978626895696, "17": 0.07774990797042847, "18": 0.0003397102700546384, "19": 0.0003252373426221311}}, {"key": "zhang2020when", "year": "2020", "title": "When Do You Need Billions Of Words Of Pretraining Data?", "topic_distr": {"0": 0.14277763664722443, "1": 0.0010611710604280233, "2": 0.12300249189138412, "3": 0.0007767927600070834, "4": 0.0006850974168628454, "5": 0.0006127692759037018, "6": 0.0005542550352402031, "7": 0.0005059418035671115, "8": 0.00046537606976926327, "9": 0.00043083244236186147, "10": 0.2387915700674057, "11": 0.06316710263490677, "12": 0.00035236676922068, "13": 0.03030143491923809, "14": 0.00031421560561284423, "15": 0.00029807889950461686, "16": 0.0807199701666832, "17": 0.00027031468925997615, "18": 0.000258285814197734, "19": 0.31465426087379456}}, {"key": "zhang2021counterfactual", "year": "2021", "title": "Counterfactual Memorization In Neural Language Models", "topic_distr": {"0": 0.27482151985168457, "1": 0.4017133116722107, "2": 0.13493803143501282, "3": 0.0009684654069133103, "4": 0.000854145735502243, "5": 0.0007639703107997775, "6": 0.0006910175434313715, "7": 0.0006307830335572362, "8": 0.04403938353061676, "9": 0.057134393602609634, "10": 0.0005000249366275966, "11": 0.00046770719927735627, "12": 0.00043931329855695367, "13": 0.0004141696263104677, "14": 0.00039174832636490464, "15": 0.05108049884438515, "16": 0.029184162616729736, "17": 0.00033701484790071845, "18": 0.00032201784779317677, "19": 0.00030829868046566844}}, {"key": "zhang2021cpm", "year": "2021", "title": "CPM-2: Large-scale Cost-effective Pre-trained Language Models", "topic_distr": {"0": 0.001370802870951593, "1": 0.001119193504564464, "2": 0.0009462139569222927, "3": 0.14274148643016815, "4": 0.0007227921159937978, "5": 0.0006464828620664775, "6": 0.0005847492720931768, "7": 0.0005337779293768108, "8": 0.0004909802810288966, "9": 0.00045453617349267006, "10": 0.0004231284838169813, "11": 0.00039578074938617647, "12": 0.0003717534418683499, "13": 0.4504130184650421, "14": 0.08196988701820374, "15": 0.00031447873334400356, "16": 0.00029911744059063494, "17": 0.3156684637069702, "18": 0.00027249628328718245, "19": 0.00026088691083714366}}, {"key": "zhang2021differentiable", "year": "2021", "title": "Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners", "topic_distr": {"0": 0.0017818352207541466, "1": 0.0014547802275046706, "2": 0.0012298875954002142, "3": 0.00106524839065969, "4": 0.10805398970842361, "5": 0.0008403169922530651, "6": 0.0007600739481858909, "7": 0.0006938198930583894, "8": 0.0006381903076544404, "9": 0.0005908191669732332, "10": 0.0005499945837073028, "11": 0.0005144472233951092, "12": 0.09488831460475922, "13": 0.045866791158914566, "14": 0.0004308974603191018, "15": 0.0004087685083504766, "16": 0.000388801476219669, "17": 0.7391497492790222, "18": 0.0003541985061019659, "19": 0.0003391082864254713}}, {"key": "zhang2021ernie", "year": "2021", "title": "Ernie-vilg: Unified Generative Pre-training For Bidirectional Vision-language Generation", "topic_distr": {"0": 0.0014326152158901095, "1": 0.001170743489637971, "2": 0.0009895869297906756, "3": 0.0008571170619688928, "4": 0.000755943008698523, "5": 0.0006761351833119988, "6": 0.0006115700234659016, "7": 0.14216020703315735, "8": 0.0005135001265443861, "9": 0.0004753844114020467, "10": 0.24010656774044037, "11": 0.0004139340599067509, "12": 0.0003888046776410192, "13": 0.06292196363210678, "14": 0.00034670831519179046, "15": 0.22155438363552094, "16": 0.00031283710268326104, "17": 0.00029826766694895923, "18": 0.3237408399581909, "19": 0.00027285300893709064}}, {"key": "zhang2021exploratory", "year": "2021", "title": "An Exploratory Study On Long Dialogue Summarization: What Works And What's Next", "topic_distr": {"0": 0.0013561343075707555, "1": 0.0011070447508245707, "2": 0.20291057229042053, "3": 0.0008105653105303645, "4": 0.0007148863514885306, "5": 0.13134656846523285, "6": 0.0961475744843483, "7": 0.11772236973047256, "8": 0.11714974045753479, "9": 0.03316361829638481, "10": 0.11047149449586868, "11": 0.0003914520493708551, "12": 0.04460238292813301, "13": 0.0003466432972345501, "14": 0.0003278775548096746, "15": 0.12329085916280746, "16": 0.00029584599542431533, "17": 0.0002820678346324712, "18": 0.00026951596373692155, "19": 0.0172928124666214}}, {"key": "zhang2021hierarchical", "year": "2021", "title": "Hierarchical Task Learning From Language Instructions With Unified Transformers And Self-monitoring", "topic_distr": {"0": 0.001341905677691102, "1": 0.0010950410505756736, "2": 0.09789960086345673, "3": 0.0008018632070161402, "4": 0.06818264722824097, "5": 0.0006325392168946564, "6": 0.0005721370107494295, "7": 0.0005222650361247361, "8": 0.00048039050307124853, "9": 0.00044473240268416703, "10": 0.17810089886188507, "11": 0.5097768902778625, "12": 0.0994846299290657, "13": 0.00034291716292500496, "14": 0.0003243531391490251, "15": 0.00030769582372158766, "16": 0.00029266587807796896, "17": 0.0002790358557831496, "18": 0.03886249661445618, "19": 0.00025525991804897785}}, {"key": "zhang2021improving", "year": "2021", "title": "Improving Stack Overflow Question Title Generation With Copying Enhanced Codebert Model And Bi-modal Information", "topic_distr": {"0": 0.0010145463747903705, "1": 0.0008282436174340546, "2": 0.3206786811351776, "3": 0.0006063105538487434, "4": 0.04662889242172241, "5": 0.00047828463721089065, "6": 0.24117806553840637, "7": 0.00039490251219831407, "8": 0.133655846118927, "9": 0.0003362774441484362, "10": 0.15551438927650452, "11": 0.00029280869057402015, "12": 0.00027503265300765634, "13": 0.00025929140974767506, "14": 0.000245254545006901, "15": 0.06494936347007751, "16": 0.0320582240819931, "17": 0.0002109885826939717, "18": 0.0002015996869886294, "19": 0.00019301076827105135}}, {"key": "zhang2021multi", "year": "2021", "title": "Summ^n: A Multi-stage Summarization Framework For Long Input Dialogues And Documents", "topic_distr": {"0": 0.001198513898998499, "1": 0.000979617820121348, "2": 0.20408353209495544, "3": 0.0007170589524321258, "4": 0.0006324172718450427, "5": 0.013142319396138191, "6": 0.0005116352695040405, "7": 0.3208177089691162, "8": 0.06536230444908142, "9": 0.012258674018085003, "10": 0.20027796924114227, "11": 0.00034629437141120434, "12": 0.0003252713067922741, "13": 0.0003066547214984894, "14": 0.0002900538092944771, "15": 0.09838802367448807, "16": 0.01618168316781521, "17": 0.000249528675340116, "18": 0.00023842474911361933, "19": 0.06369227916002274}}, {"key": "zhang2021tip", "year": "2021", "title": "Tip-adapter: Training-free Clip-adapter For Better Vision-language Modeling", "topic_distr": {"0": 0.0015217707259580493, "1": 0.0012420264538377523, "2": 0.20106615126132965, "3": 0.0009093750268220901, "4": 0.0008020296227186918, "5": 0.0007173562189564109, "6": 0.0006488548824563622, "7": 0.0005922955460846424, "8": 0.0005448060692287982, "9": 0.0005043665878474712, "10": 0.04474378377199173, "11": 0.00043916984577663243, "12": 0.0004125084378756583, "13": 0.2877933382987976, "14": 0.0003678456414490938, "15": 0.00034895475255325437, "16": 0.05390315130352974, "17": 0.16326241195201874, "18": 0.23989029228687286, "19": 0.0002894877106882632}}, {"key": "zhang2022active", "year": "2022", "title": "Active Example Selection For In-context Learning", "topic_distr": {"0": 0.0018619558541104198, "1": 0.12096482515335083, "2": 0.17162083089351654, "3": 0.3035992681980133, "4": 0.03759923204779625, "5": 0.0008780771167948842, "6": 0.0007942282827571034, "7": 0.0007249971386045218, "8": 0.000666867766994983, "9": 0.0006173679721541703, "10": 0.000574708916246891, "11": 0.35672125220298767, "12": 0.0005049293977208436, "13": 0.0004760302253998816, "14": 0.000450260064098984, "15": 0.00042713675065897405, "16": 0.0004062725056428462, "17": 0.0003873515815939754, "18": 0.00037011460517533123, "19": 0.00035434632445685565}}, {"key": "zhang2022automatic", "year": "2022", "title": "Automatic Chain Of Thought Prompting In Large Language Models", "topic_distr": {"0": 0.001085599884390831, "1": 0.0008857933571562171, "2": 0.000748639227822423, "3": 0.9248453974723816, "4": 0.0005718901520594954, "5": 0.0005115134408697486, "6": 0.0004626682784873992, "7": 0.0004223384603392333, "8": 0.053808026015758514, "9": 0.0003596403985284269, "10": 0.00033478986006230116, "11": 0.013996808789670467, "12": 0.00029414062737487257, "13": 0.0002773057494778186, "14": 0.00026229367358610034, "15": 0.0002488234604243189, "16": 0.00023666922061238438, "17": 0.00022564706159755588, "18": 0.00021560587629210204, "19": 0.00020642024173866957}}, {"key": "zhang2022graph", "year": "2022", "title": "Greaselm: Graph Reasoning Enhanced Language Models For Question Answering", "topic_distr": {"0": 0.0011660745367407799, "1": 0.0009518465376459062, "2": 0.10769592225551605, "3": 0.0006969099631533027, "4": 0.0006146464729681611, "5": 0.0005497556994669139, "6": 0.000497258675750345, "7": 0.00045391370076686144, "8": 0.1920313984155655, "9": 0.00038652814691886306, "10": 0.0003598197072278708, "11": 0.0003365637385286391, "12": 0.016761595383286476, "13": 0.0002980379213113338, "14": 0.00028190348530188203, "15": 0.00026742619229480624, "16": 0.3998335599899292, "17": 0.00024251708236988634, "18": 0.15678749978542328, "19": 0.11978679150342941}}, {"key": "zhang2022open", "year": "2022", "title": "OPT: Open Pre-trained Transformer Language Models", "topic_distr": {"0": 0.0024449361953884363, "1": 0.001996895531192422, "2": 0.001688055694103241, "3": 0.2945232391357422, "4": 0.0012894832761958241, "5": 0.0011533474316820502, "6": 0.001043212483637035, "7": 0.000952277856413275, "8": 0.0008759254706092179, "9": 0.0008109078626148403, "10": 0.1189362108707428, "11": 0.0007060862262733281, "12": 0.1804218739271164, "13": 0.3900110721588135, "14": 0.0005914130015298724, "15": 0.0005610407097265124, "16": 0.0005336356698535383, "17": 0.0005087831523269415, "18": 0.0004861425550188869, "19": 0.00046543104690499604}}, {"key": "zhang2022paradox", "year": "2022", "title": "On The Paradox Of Learning To Reason From Data", "topic_distr": {"0": 0.07180862873792648, "1": 0.12386822700500488, "2": 0.0797349140048027, "3": 0.2126000076532364, "4": 0.0007473859586752951, "5": 0.04191872105002403, "6": 0.0006046475609764457, "7": 0.0005519417463801801, "8": 0.024882884696125984, "9": 0.0004700034623965621, "10": 0.1829725205898285, "11": 0.25726962089538574, "12": 0.00038440374191850424, "13": 0.0003624027594923973, "14": 0.0003427838673815131, "15": 0.00032518006628379226, "16": 0.00030929603963159025, "17": 0.0002948915062006563, "18": 0.000281768967397511, "19": 0.00026976456865668297}}, {"key": "zhang2022pretraining", "year": "2022", "title": "Coditt5: Pretraining For Source Code And Natural Language Editing", "topic_distr": {"0": 0.0020779611077159643, "1": 0.001697674859315157, "2": 0.0014349168632179499, "3": 0.25913193821907043, "4": 0.00109611835796386, "5": 0.0009803968714550138, "6": 0.14694318175315857, "7": 0.2247888445854187, "8": 0.0007445757510140538, "9": 0.000689307926222682, "10": 0.09694796800613403, "11": 0.0006002048030495644, "12": 0.031437356024980545, "13": 0.0005315004964359105, "14": 0.000502727460116148, "15": 0.0004769096558447927, "16": 0.0004536141350399703, "17": 0.00043248842121101916, "18": 0.00041324287303723395, "19": 0.2286190390586853}}, {"key": "zhang2022revisiting", "year": "2022", "title": "Revisiting End-to-end Speech-to-text Translation From Scratch", "topic_distr": {"0": 0.1283196061849594, "1": 0.13204018771648407, "2": 0.32300347089767456, "3": 0.0007102419622242451, "4": 0.0006264037219807506, "5": 0.0005602719611488283, "6": 0.0005067704478278756, "7": 0.00046259636292234063, "8": 0.0004255059757269919, "9": 0.0003939218004234135, "10": 0.08296052366495132, "11": 0.0003430016804486513, "12": 0.00032217850093729794, "13": 0.00030373892514035106, "14": 0.21683059632778168, "15": 0.0002725416561588645, "16": 0.0002592288365121931, "17": 0.0002471560437697917, "18": 0.00023615772079210728, "19": 0.11117587983608246}}, {"key": "zhang2022survey", "year": "2022", "title": "A Survey Of Controllable Text Generation Using Transformer-based Pre-trained Language Models", "topic_distr": {"0": 0.0010070826392620802, "1": 0.0008215924026444554, "2": 0.08307626843452454, "3": 0.023419342935085297, "4": 0.000530399673152715, "5": 0.010474396869540215, "6": 0.00042910181218758225, "7": 0.20374631881713867, "8": 0.0003602921206038445, "9": 0.12640586495399475, "10": 0.0003105009673163295, "11": 0.0002904325956478715, "12": 0.4334767162799835, "13": 0.00025718731922097504, "14": 0.00024326435232069343, "15": 0.11433105915784836, "16": 0.00021949895017314702, "17": 0.00020927644800394773, "18": 0.00019996374612674117, "19": 0.000191444531083107}}, {"key": "zhang2023adaptive", "year": "2023", "title": "Adalora: Adaptive Budget Allocation For Parameter-efficient Fine-tuning", "topic_distr": {"0": 0.174444317817688, "1": 0.001060822862200439, "2": 0.10346516966819763, "3": 0.0007767705246806145, "4": 0.0006850789068266749, "5": 0.0006127525120973587, "6": 0.0005542398430407047, "7": 0.01714017242193222, "8": 0.022121775895357132, "9": 0.00043082062620669603, "10": 0.2023891657590866, "11": 0.00037513079587370157, "12": 0.00035235710674896836, "13": 0.27944812178611755, "14": 0.00031420699087902904, "15": 0.00029807075043208897, "16": 0.0002835109189618379, "17": 0.19474197924137115, "18": 0.00025827871286310256, "19": 0.00024727507843635976}}, {"key": "zhang2023aligning", "year": "2023", "title": "Aligning Instruction Tasks Unlocks Large Language Models As Zero-shot Relation Extractors", "topic_distr": {"0": 0.022383596748113632, "1": 0.03686082735657692, "2": 0.0008696506847627461, "3": 0.5901673436164856, "4": 0.0006643181550316513, "5": 0.0005941835115663707, "6": 0.0005374439642764628, "7": 0.0004905961686745286, "8": 0.0709066390991211, "9": 0.00041776493890210986, "10": 0.0003888980718329549, "11": 0.00036376272328197956, "12": 0.0003416791732888669, "13": 0.0003221234946977347, "14": 0.00030468517797999084, "15": 0.00028903791098855436, "16": 0.0002749193226918578, "17": 0.2374679446220398, "18": 0.00025045176153071225, "19": 0.03610417991876602}}, {"key": "zhang2023automl", "year": "2023", "title": "Automl-gpt: Automatic Machine Learning With GPT", "topic_distr": {"0": 0.0010663270950317383, "1": 0.0008707205415703356, "2": 0.14217013120651245, "3": 0.371628999710083, "4": 0.0005621185409836471, "5": 0.000502773211337626, "6": 0.00045476260129362345, "7": 0.0004151219327468425, "8": 0.00038183797732926905, "9": 0.21384423971176147, "10": 0.00032906924025155604, "11": 0.00030780077213421464, "12": 0.00028911459958180785, "13": 0.1046091765165329, "14": 0.00025781182921491563, "15": 0.00024457176914438605, "16": 0.00023262521426659077, "17": 0.14471320807933807, "18": 0.0169166699051857, "19": 0.00020289311942178756}}, {"key": "zhang2023building", "year": "2023", "title": "Building Cooperative Embodied Agents Modularly With Large Language Models", "topic_distr": {"0": 0.04262852668762207, "1": 0.05752921104431152, "2": 0.0009159721666947007, "3": 0.15792794525623322, "4": 0.0006996954325586557, "5": 0.0006258250796236098, "6": 0.0005660640308633447, "7": 0.0005167213967069983, "8": 0.0004752913664560765, "9": 0.10492102801799774, "10": 0.0004096076881978661, "11": 0.36685943603515625, "12": 0.15955643355846405, "13": 0.00033927723416127264, "14": 0.0003209102724213153, "15": 0.04044193774461746, "16": 0.04284896329045296, "17": 0.00027607398806139827, "18": 0.0002637888246681541, "19": 0.02187729999423027}}, {"key": "zhang2023collaborative", "year": "2023", "title": "Agentcf: Collaborative Learning With Autonomous Language Agents For Recommender Systems", "topic_distr": {"0": 0.14725206792354584, "1": 0.0008212772663682699, "2": 0.0006943094194866717, "3": 0.04341719672083855, "4": 0.5071129202842712, "5": 0.010904595255851746, "6": 0.00042908472823910415, "7": 0.0003916823479812592, "8": 0.0003602777433115989, "9": 0.0003335353103466332, "10": 0.0003104885690845549, "11": 0.20764602720737457, "12": 0.0002727899409364909, "13": 0.00025717707467265427, "14": 0.0002432546461932361, "15": 0.00023076219076756388, "16": 0.05399181321263313, "17": 0.024939294904470444, "18": 0.00019995577167719603, "19": 0.0001914368913276121}}, {"key": "zhang2023empowering", "year": "2023", "title": "Speechgpt: Empowering Large Language Models With Intrinsic Cross-modal Conversational Abilities", "topic_distr": {"0": 0.0019195808563381433, "1": 0.10137887299060822, "2": 0.0013245131121948361, "3": 0.23092226684093475, "4": 0.0010117980418726802, "5": 0.0009049777290783823, "6": 0.12059434503316879, "7": 0.0007472079014405608, "8": 0.0006872977246530354, "9": 0.12214817851781845, "10": 0.0005923155113123357, "11": 0.0842471644282341, "12": 0.1128116324543953, "13": 0.0004906137473881245, "14": 0.00046405408647842705, "15": 0.0004402223858051002, "16": 0.09048546850681305, "17": 0.00039921834832057357, "18": 0.1280650794506073, "19": 0.00036520196590572596}}, {"key": "zhang2023enhanced", "year": "2023", "title": "Llavar: Enhanced Visual Instruction Tuning For Text-rich Image Understanding", "topic_distr": {"0": 0.0011452173348516226, "1": 0.06381313502788544, "2": 0.0007898484473116696, "3": 0.36884409189224243, "4": 0.0006033636163920164, "5": 0.0005396633641794324, "6": 0.05079875886440277, "7": 0.00044558080844581127, "8": 0.00040985472151078284, "9": 0.00037943231291137636, "10": 0.00035321415634825826, "11": 0.0003303851408418268, "12": 0.00031032791594043374, "13": 0.0002925665758084506, "14": 0.000276728329481557, "15": 0.0002625168126542121, "16": 0.00024969372316263616, "17": 0.033513762056827545, "18": 0.47642406821250916, "19": 0.0002177800633944571}}, {"key": "zhang2023extractive", "year": "2023", "title": "Extractive Summarization Via Chatgpt For Faithful Summary Generation", "topic_distr": {"0": 0.0012478610733523965, "1": 0.0010187551379203796, "2": 0.24958474934101105, "3": 0.18138590455055237, "4": 0.0006577094900421798, "5": 0.0005882715340703726, "6": 0.0005320965428836644, "7": 0.13853685557842255, "8": 0.0004467708640731871, "9": 0.15375329554080963, "10": 0.07633505016565323, "11": 0.00036014337092638016, "12": 0.19362875819206238, "13": 0.0003189184353686869, "14": 0.00030165360658429563, "15": 0.0002861620450858027, "16": 0.0002721839409787208, "17": 0.0002595077967271209, "18": 0.0002479598333593458, "19": 0.00023739579773973674}}, {"key": "zhang2023fair", "year": "2023", "title": "\"it's A Fair Game\", Or Is It? Examining How Users Navigate Disclosure Risks And Benefits When Using Llm-based Conversational Agents", "topic_distr": {"0": 0.02309887297451496, "1": 0.02080877497792244, "2": 0.001103922026231885, "3": 0.0009561041952110827, "4": 0.2031175196170807, "5": 0.0007542168605141342, "6": 0.0006821954739280045, "7": 0.0006227299454621971, "8": 0.0005728002870455384, "9": 0.5935223698616028, "10": 0.0004936411860398948, "11": 0.11477424204349518, "12": 0.037026140838861465, "13": 0.0004088820132892579, "14": 0.00038674697862006724, "15": 0.0003668854187708348, "16": 0.0003489642112981528, "17": 0.00033271225402131677, "18": 0.00031790672801434994, "19": 0.00030436270753853023}}, {"key": "zhang2023generative", "year": "2023", "title": "On Generative Agents In Recommendation", "topic_distr": {"0": 0.11296210438013077, "1": 0.0009175545419566333, "2": 0.0007756708655506372, "3": 0.0006718271179124713, "4": 0.4160039722919464, "5": 0.000529966433532536, "6": 0.0004793591215275228, "7": 0.0004375744319986552, "8": 0.0105961998924613, "9": 0.14001387357711792, "10": 0.00034686748404055834, "11": 0.17892473936080933, "12": 0.04428861662745476, "13": 0.00028730963822454214, "14": 0.0002717559691518545, "15": 0.02841145358979702, "16": 0.06341014802455902, "17": 0.00023378733021672815, "18": 0.00022338390408549458, "19": 0.00021386690787039697}}, {"key": "zhang2023heavy", "year": "2023", "title": "H\\(_2\\)O: Heavy-hitter Oracle For Efficient Generative Inference Of Large Language Models", "topic_distr": {"0": 0.0011043257545679808, "1": 0.000901395920664072, "2": 0.17719332873821259, "3": 0.16638346016407013, "4": 0.0005820576916448772, "5": 0.04427749291062355, "6": 0.0004708931955974549, "7": 0.05160420387983322, "8": 0.0003953819104935974, "9": 0.11238043755292892, "10": 0.0003407414769753814, "11": 0.0003187185793649405, "12": 0.0002993695961777121, "13": 0.38817399740219116, "14": 0.0002669565146788955, "15": 0.054407160729169846, "16": 0.00024087652855087072, "17": 0.00022965842799749225, "18": 0.00021943873434793204, "19": 0.00021008981275372207}}, {"key": "zhang2023human", "year": "2023", "title": "VISAR: A Human-ai Argumentative Writing Assistant With Visual Programming And Rapid Draft Prototyping", "topic_distr": {"0": 0.0014849219005554914, "1": 0.0012124270433560014, "2": 0.0010249464539811015, "3": 0.0008877431391738355, "4": 0.04207674041390419, "5": 0.03414933755993843, "6": 0.12571431696414948, "7": 0.22279958426952362, "8": 0.0005318460753187537, "9": 0.5014474987983704, "10": 0.0004583467380143702, "11": 0.00042872276389971375, "12": 0.00040269558667205274, "13": 0.0003796476812567562, "14": 0.0003590952546801418, "15": 0.017900753766298294, "16": 0.0003240139049012214, "17": 0.00030892391805537045, "18": 0.04782582446932793, "19": 0.00028260130784474313}}, {"key": "zhang2023instruction", "year": "2023", "title": "Instruction Tuning For Large Language Models: A Survey", "topic_distr": {"0": 0.0013134347973391414, "1": 0.04156525805592537, "2": 0.0009062906610779464, "3": 0.37935587763786316, "4": 0.0006923198234289885, "5": 0.0006192275905050337, "6": 0.0005600965232588351, "7": 0.020022770389914513, "8": 0.0004702807927969843, "9": 0.05690884590148926, "10": 0.00040528958197683096, "11": 0.0003790947957895696, "12": 0.35656920075416565, "13": 0.0003357005480211228, "14": 0.00031752721406519413, "15": 0.00030122045427560806, "16": 0.01233307272195816, "17": 0.09114199876785278, "18": 0.03555258736014366, "19": 0.0002498880203347653}}, {"key": "zhang2023internlm", "year": "2023", "title": "Internlm-xcomposer: A Vision-language Large Model For Advanced Text-image Comprehension And Composition", "topic_distr": {"0": 0.08335805684328079, "1": 0.0009519162122160196, "2": 0.0714566633105278, "3": 0.15297777950763702, "4": 0.0006146788946352899, "5": 0.0005497843376360834, "6": 0.05140119418501854, "7": 0.0004539373330771923, "8": 0.00041754121775738895, "9": 0.09866321086883545, "10": 0.0003598384209908545, "11": 0.00033658125903457403, "12": 0.17545050382614136, "13": 0.00029805346275679767, "14": 0.03302420675754547, "15": 0.000267440133029595, "16": 0.02549317292869091, "17": 0.00024252971343230456, "18": 0.3034610152244568, "19": 0.00022186436399351805}}, {"key": "zhang2023is", "year": "2023", "title": "Is Chatgpt Fair For Recommendation? Evaluating Fairness In Large Language Model Recommendation", "topic_distr": {"0": 0.12854258716106415, "1": 0.0010951734147965908, "2": 0.0009257480851374567, "3": 0.4238882064819336, "4": 0.33591189980506897, "5": 0.0006325209978967905, "6": 0.00057212047977373, "7": 0.0005222499603405595, "8": 0.00048037662054412067, "9": 0.10419567674398422, "10": 0.00041399020119570196, "11": 0.0003872330707963556, "12": 0.0003637246845755726, "13": 0.0003429072385188192, "14": 0.000324343767715618, "15": 0.00030768694705329835, "16": 0.00029265740886330605, "17": 0.0002790277940221131, "18": 0.00026661116862669587, "19": 0.00025525252567604184}}, {"key": "zhang2023llama", "year": "2023", "title": "Llama-adapter: Efficient Fine-tuning Of Language Models With Zero-init Attention", "topic_distr": {"0": 0.0015778924571350217, "1": 0.00128918734844774, "2": 0.15877865254878998, "3": 0.0009439327986910939, "4": 0.0008325063972733915, "5": 0.0007446153904311359, "6": 0.03447875753045082, "7": 0.0006148023530840874, "8": 0.0005655083223246038, "9": 0.0005235321586951613, "10": 0.13890643417835236, "11": 0.06138776242733002, "12": 0.0004281834699213505, "13": 0.2723240852355957, "14": 0.0003818235418293625, "15": 0.0003622148069553077, "16": 0.08233367651700974, "17": 0.08900846540927887, "18": 0.15421746671199799, "19": 0.0003004880272783339}}, {"key": "zhang2023making", "year": "2023", "title": "Making Large Language Models Perform Better In Knowledge Graph Completion", "topic_distr": {"0": 0.0011668927036225796, "1": 0.0009520758758299053, "2": 0.0008047014707699418, "3": 0.2613435685634613, "4": 0.0006147087551653385, "5": 0.00054981152061373, "6": 0.0004973090835846961, "7": 0.00045395971392281353, "8": 0.00041756179416552186, "9": 0.09524466842412949, "10": 0.053267501294612885, "11": 0.00033659784821793437, "12": 0.0003161634667776525, "13": 0.00029806813108734787, "14": 0.00028193206526339054, "15": 0.0002674533170647919, "16": 0.4482470750808716, "17": 0.05579443275928497, "18": 0.07892369478940964, "19": 0.00022187530703376979}}, {"key": "zhang2023multilevel", "year": "2023", "title": "M3exam: A Multilingual, Multimodal, Multilevel Benchmark For Examining Large Language Models", "topic_distr": {"0": 0.0653982162475586, "1": 0.017834356054663658, "2": 0.0006674443138763309, "3": 0.28780847787857056, "4": 0.0005098612164147198, "5": 0.012066352181136608, "6": 0.0004124859406147152, "7": 0.00037653042818419635, "8": 0.07955425977706909, "9": 0.00032063276739791036, "10": 0.0002984775637742132, "11": 0.00027918629348278046, "12": 0.3015545904636383, "13": 0.0002472283667884767, "14": 0.05794980376958847, "15": 0.00022183533292263746, "16": 0.03767819330096245, "17": 0.00020117273379582912, "18": 0.13643689453601837, "19": 0.00018403130525257438}}, {"key": "zhang2023one", "year": "2023", "title": "One Small Step For Generative AI, One Giant Leap For AGI: A Complete Survey On Chatgpt In AIGC Era", "topic_distr": {"0": 0.0016861489275470376, "1": 0.001376441796310246, "2": 0.0011635053670033813, "3": 0.20552819967269897, "4": 0.0008887893054634333, "5": 0.0007949563441798091, "6": 0.000719044532161206, "7": 0.0006563669885508716, "8": 0.0006037403363734484, "9": 0.6034083962440491, "10": 0.0005203054170124233, "11": 0.00048667695955373347, "12": 0.17956772446632385, "13": 0.000430967949796468, "14": 0.00040763727156445384, "15": 0.0003867028863169253, "16": 0.00036781365633942187, "17": 0.00035068386932834983, "18": 0.0003350785991642624, "19": 0.00032080296659842134}}, {"key": "zhang2023pmc", "year": "2023", "title": "PMC-VQA: Visual Instruction Tuning For Medical Visual Question Answering", "topic_distr": {"0": 0.0011563932057470083, "1": 0.0009431794751435518, "2": 0.0007973102619871497, "3": 0.058448389172554016, "4": 0.04917193949222565, "5": 0.023660924285650253, "6": 0.0004927259869873524, "7": 0.000449776096502319, "8": 0.15997564792633057, "9": 0.04170573502779007, "10": 0.0003565397928468883, "11": 0.00033349584555253386, "12": 0.25818151235580444, "13": 0.055487602949142456, "14": 0.00027933382079936564, "15": 0.031523801386356354, "16": 0.0002520446723792702, "17": 0.00024030644271988422, "18": 0.31632348895072937, "19": 0.0002198305301135406}}, {"key": "zhang2023potential", "year": "2023", "title": "The Potential And Pitfalls Of Using A Large Language Model Such As Chatgpt Or GPT-4 As A Clinical Assistant", "topic_distr": {"0": 0.17734405398368835, "1": 0.04044117033481598, "2": 0.0008122521685436368, "3": 0.18636666238307953, "4": 0.015279772691428661, "5": 0.0005549694178625941, "6": 0.0005019745440222323, "7": 0.00045821850653737783, "8": 0.00042147914064116776, "9": 0.3052310049533844, "10": 0.00036323213134892285, "11": 0.00033975564292632043, "12": 0.1743299961090088, "13": 0.06279121339321136, "14": 0.00028457699227146804, "15": 0.00026996241649612784, "16": 0.0002567756164353341, "17": 0.03349507227540016, "18": 0.00023392280854750425, "19": 0.00022395681298803538}}, {"key": "zhang2023prompting", "year": "2023", "title": "Prompting Large Language Model For Machine Translation: A Case Study", "topic_distr": {"0": 0.04685856029391289, "1": 0.09817633032798767, "2": 0.0008279295288957655, "3": 0.17688412964344025, "4": 0.0006324389250949025, "5": 0.0005656696739606559, "6": 0.0005116529646329582, "7": 0.0004670532653108239, "8": 0.00042960551218129694, "9": 0.0633225068449974, "10": 0.0003702355024870485, "11": 0.017151284962892532, "12": 0.0003252825408708304, "13": 0.00030666531529277563, "14": 0.20918545126914978, "15": 0.0002751674619503319, "16": 0.023013949394226074, "17": 0.36022937297821045, "18": 0.0002384330000495538, "19": 0.00022827484644949436}}, {"key": "zhang2023recommendation", "year": "2023", "title": "Recommendation As Instruction Following: A Large Language Model Empowered Recommendation Approach", "topic_distr": {"0": 0.0008542923606000841, "1": 0.0006976961158216, "2": 0.12887032330036163, "3": 0.2950519919395447, "4": 0.37952497601509094, "5": 0.025019073858857155, "6": 0.0003644264361355454, "7": 0.0003326601581647992, "8": 0.0003059878945350647, "9": 0.00028327523614279926, "10": 0.0002637013967614621, "11": 0.10392361134290695, "12": 0.06319040805101395, "13": 0.0002184233453590423, "14": 0.000206598881050013, "15": 0.00019598889048211277, "16": 0.00018641546193975955, "17": 0.00017773373110685498, "18": 0.000169824663316831, "19": 0.00016258948016911745}}, {"key": "zhang2023repository", "year": "2023", "title": "Repocoder: Repository-level Code Completion Through Iterative Retrieval And Generation", "topic_distr": {"0": 0.0012997202575206757, "1": 0.0010609502205625176, "2": 0.04350017383694649, "3": 0.34984445571899414, "4": 0.0006851434009149671, "5": 0.0006128099048510194, "6": 0.48038843274116516, "7": 0.0005059753311797976, "8": 0.03180602192878723, "9": 0.0004308609932195395, "10": 0.0004010892007499933, "11": 0.00037516592419706285, "12": 0.08708518743515015, "13": 0.0003322213888168335, "14": 0.0003142364148516208, "15": 0.000298098661005497, "16": 0.0002835374907590449, "17": 0.00027033258811570704, "18": 0.0002583028981462121, "19": 0.00024729821598157287}}, {"key": "zhang2023show", "year": "2023", "title": "Show-1: Marrying Pixel And Latent Diffusion Models For Text-to-video Generation", "topic_distr": {"0": 0.0015029005007818341, "1": 0.0012269871076568961, "2": 0.15443956851959229, "3": 0.0008984284941107035, "4": 0.000792375358287245, "5": 0.0007087215781211853, "6": 0.10648879408836365, "7": 0.04169907793402672, "8": 0.0005382482195273042, "9": 0.0004982954706065357, "10": 0.00046386412577703595, "11": 0.00043388354242779315, "12": 0.0004075430624652654, "13": 0.24926608800888062, "14": 0.01850474439561367, "15": 0.0003447544004302472, "16": 0.0003279142256360501, "17": 0.00031264263088814914, "18": 0.3984123468399048, "19": 0.022732799872756004}}, {"key": "zhang2023speak", "year": "2023", "title": "Speak Foreign Languages With Your Own Voice: Cross-lingual Neural Codec Language Modeling", "topic_distr": {"0": 0.0022686480078846216, "1": 0.13421842455863953, "2": 0.001565441838465631, "3": 0.0013558827340602875, "4": 0.001195829827338457, "5": 0.0010695813689380884, "6": 0.040574852377176285, "7": 0.1572912484407425, "8": 0.0008123082807287574, "9": 0.02567700482904911, "10": 0.10731615126132965, "11": 0.04036346822977066, "12": 0.0006150519475340843, "13": 0.0005798500496894121, "14": 0.18704655766487122, "15": 0.0005202931351959705, "16": 0.0004948784480802715, "17": 0.22108817100524902, "18": 0.07551474124193192, "19": 0.00043162747169844806}}, {"key": "zhang2023then", "year": "2023", "title": "Prompt, Generate, Then Cache: Cascade Of Foundation Models Makes Strong Few-shot Learners", "topic_distr": {"0": 0.0014009777223691344, "1": 0.11824469268321991, "2": 0.0009673869353719056, "3": 0.0008378648781217635, "4": 0.0007389620295725763, "5": 0.0006609464762732387, "6": 0.0005978317931294441, "7": 0.0005457200459204614, "8": 0.0005019648815505207, "9": 0.058924321085214615, "10": 0.0004325950285419822, "11": 0.0004046354442834854, "12": 0.00038007055991329253, "13": 0.0003583176003303379, "14": 0.0003389198682270944, "15": 0.00032151449704542756, "16": 0.23423078656196594, "17": 0.2319258600473404, "18": 0.34791991114616394, "19": 0.00026672365493141115}}, {"key": "zhang2023training", "year": "2023", "title": "Controlvideo: Training-free Controllable Text-to-video Generation", "topic_distr": {"0": 0.0012745339190587401, "1": 0.09065837413072586, "2": 0.0008786103571765125, "3": 0.000760988041292876, "4": 0.0006711595924571157, "5": 0.013295937329530716, "6": 0.0005429782904684544, "7": 0.14067839086055756, "8": 0.00045590760419145226, "9": 0.0004220668051857501, "10": 0.17026813328266144, "11": 0.00036750853178091347, "12": 0.00034519759356044233, "13": 0.033182062208652496, "14": 0.00030782262911088765, "15": 0.0002920142433140427, "16": 0.07966811209917068, "17": 0.0469222292304039, "18": 0.41876575350761414, "19": 0.00024225069500971586}}, {"key": "zhang2023trust", "year": "2023", "title": "Don't Trust Chatgpt When Your Question Is Not In English: A Study Of Multilingual Abilities And Types Of Llms", "topic_distr": {"0": 0.15711551904678345, "1": 0.0011444560950621963, "2": 0.0009673406602814794, "3": 0.4539642333984375, "4": 0.0007389417733065784, "5": 0.0006609268020838499, "6": 0.0005978138069622219, "7": 0.0005457036313600838, "8": 0.022713931277394295, "9": 0.050996605306863785, "10": 0.00043258204823359847, "11": 0.00040462330798618495, "12": 0.14382033050060272, "13": 0.0003583068319130689, "14": 0.11849779635667801, "15": 0.0003215048345737159, "16": 0.0003058003494516015, "17": 0.04586830362677574, "18": 0.00027858439716510475, "19": 0.00026671565137803555}}, {"key": "zhang2023video", "year": "2023", "title": "Video-llama: An Instruction-tuned Audio-visual Language Model For Video Understanding", "topic_distr": {"0": 0.0012121425243094563, "1": 0.000988867599517107, "2": 0.0008359829080291092, "3": 0.1333920657634735, "4": 0.015185053460299969, "5": 0.0005711803096346557, "6": 0.01810089871287346, "7": 0.05004173889756203, "8": 0.00043379070120863616, "9": 0.00040159159107133746, "10": 0.0003738422819878906, "11": 0.00034968002000823617, "12": 0.0003284514241386205, "13": 0.00030965282348915935, "14": 0.00029288959922268987, "15": 0.00027784809935837984, "16": 0.0002642761101014912, "17": 0.0002519682457204908, "18": 0.776157557964325, "19": 0.00023049867013469338}}, {"key": "zhang2023xuanyuan", "year": "2023", "title": "Xuanyuan 2.0: A Large Chinese Financial Chat Model With Hundreds Of Billions Parameters", "topic_distr": {"0": 0.0023981595877557993, "1": 0.2262398898601532, "2": 0.001655717147514224, "3": 0.0014340593479573727, "4": 0.0012647826224565506, "5": 0.0011312538990750909, "6": 0.06736640632152557, "7": 0.0009340359247289598, "8": 0.0008591461228206754, "9": 0.0007953740423545241, "10": 0.0007404150092042983, "11": 0.0006925603374838829, "12": 0.25485050678253174, "13": 0.13588622212409973, "14": 0.0005800838116556406, "15": 0.15479497611522675, "16": 0.14694401621818542, "17": 0.0004990368615835905, "18": 0.00047682994045317173, "19": 0.00045651517575606704}}, {"key": "zhang2024autonomous", "year": "2024", "title": "Autocoderover: Autonomous Program Improvement", "topic_distr": {"0": 0.0009104536147788167, "1": 0.023840323090553284, "2": 0.0006284734699875116, "3": 0.38715705275535583, "4": 0.0004800786846317351, "5": 0.0004293948586564511, "6": 0.2581239640712738, "7": 0.00035453602322377264, "8": 0.00032610975904390216, "9": 0.1941804587841034, "10": 0.0002810425066854805, "11": 0.13163699209690094, "12": 0.00024691910948604345, "13": 0.00023278692970052361, "14": 0.00022018488380126655, "15": 0.00020887718710582703, "16": 0.00019867419905494899, "17": 0.0001894215529318899, "18": 0.00018099238513968885, "19": 0.00017328142712358385}}, {"key": "zhang2024chemical", "year": "2024", "title": "Chemllm: A Chemical Large Language Model", "topic_distr": {"0": 0.001312448177486658, "1": 0.04227104410529137, "2": 0.0009063073666766286, "3": 0.41227009892463684, "4": 0.0006923173204995692, "5": 0.08194025605916977, "6": 0.025184091180562973, "7": 0.0005112726357765496, "8": 0.00047027942491695285, "9": 0.09241130948066711, "10": 0.00040528838871978223, "11": 0.0003790937189478427, "12": 0.1945337951183319, "13": 0.0003356995584908873, "14": 0.0003175262827426195, "15": 0.00030121958116069436, "16": 0.14497385919094086, "17": 0.00027316281921230257, "18": 0.00026100719696842134, "19": 0.0002498872927390039}}, {"key": "zhang2024closing", "year": "2024", "title": "Closing The Gap Between Open-source And Commercial Large Language Models For Medical Evidence Summarization", "topic_distr": {"0": 0.12001760303974152, "1": 0.0010289618512615561, "2": 0.0008697365410625935, "3": 0.49950358271598816, "4": 0.0006643677479587495, "5": 0.0005942279822193086, "6": 0.0005374843021854758, "7": 0.04741346091032028, "8": 0.0004512946179602295, "9": 0.031687453389167786, "10": 0.0003889272047672421, "11": 0.0003637899935711175, "12": 0.23388464748859406, "13": 0.00032214762177318335, "14": 0.06095588579773903, "15": 0.00028905956423841417, "16": 0.0002749399282038212, "17": 0.0002621354360599071, "18": 0.00025047053350135684, "19": 0.00023979954130481929}}, {"key": "zhang2024generalized", "year": "2024", "title": "Mgte: Generalized Long-context Text Representation And Reranking Models For Multilingual Text Retrieval", "topic_distr": {"0": 0.0018895667744800448, "1": 0.0015430239727720618, "2": 0.0013043815270066261, "3": 0.0011297559831291437, "4": 0.0009963997872546315, "5": 0.0008912064949981868, "6": 0.00080610386794433, "7": 0.0007358375005424023, "8": 0.04783939942717552, "9": 0.0006265990668907762, "10": 0.21345101296901703, "11": 0.0005456020007841289, "12": 0.11642743647098541, "13": 0.20384924113750458, "14": 0.09584138542413712, "15": 0.18198107182979584, "16": 0.1290135532617569, "17": 0.0003931433893740177, "18": 0.0003756486694328487, "19": 0.0003596446185838431}}, {"key": "zhang2024universal", "year": "2024", "title": "Earthgpt: A Universal Multi-modal Large Language Model For Multi-sensor Image Comprehension In Remote Sensing Domain", "topic_distr": {"0": 0.0013719347771257162, "1": 0.03044665977358818, "2": 0.0009461431764066219, "3": 0.0008194741676561534, "4": 0.0007227391470223665, "5": 0.0006464362959377468, "6": 0.0005847071297466755, "7": 0.000533739454112947, "8": 0.0004909448907710612, "9": 0.04644174501299858, "10": 0.0004230979538988322, "11": 0.0003957521985284984, "12": 0.2810076177120209, "13": 0.0003504512133076787, "14": 0.00033147932845167816, "15": 0.00031445606146007776, "16": 0.0576341412961483, "17": 0.14323094487190247, "18": 0.4330466687679291, "19": 0.00026086808065883815}}, {"key": "zhao2019explicit", "year": "2019", "title": "Explicit Sparse Transformer: Concentrated Attention Through Explicit Selection", "topic_distr": {"0": 0.0013697344111278653, "1": 0.0011191272642463446, "2": 0.5222950577735901, "3": 0.0008194411639124155, "4": 0.0007227107416838408, "5": 0.0006464114412665367, "6": 0.000584684603381902, "7": 0.01568601466715336, "8": 0.0004909260314889252, "9": 0.0004544858820736408, "10": 0.26329851150512695, "11": 0.00039573697722516954, "12": 0.00037171231815591455, "13": 0.0003504377091303468, "14": 0.030042452737689018, "15": 0.00031444395426660776, "16": 0.09375486522912979, "17": 0.0002851554309017956, "18": 0.06673722714185715, "19": 0.0002608580398373306}}, {"key": "zhao2019open", "year": "2019", "title": "UER: An Open-source Toolkit For Pre-training Models", "topic_distr": {"0": 0.12064993381500244, "1": 0.05373748019337654, "2": 0.22286206483840942, "3": 0.0013559994986280799, "4": 0.06412570178508759, "5": 0.0010696740355342627, "6": 0.0009675289620645344, "7": 0.000883191532921046, "8": 0.0008123783627524972, "9": 0.0007520777289755642, "10": 0.3357003331184387, "11": 0.0006548607489094138, "12": 0.0006151050329208374, "13": 0.0005799000500701368, "14": 0.0005485068541020155, "15": 0.09788835048675537, "16": 0.000494921172503382, "17": 0.0004718717245850712, "18": 0.0953984186053276, "19": 0.0004316647246014327}}, {"key": "zhao2019parallel", "year": "2019", "title": "MUSE: Parallel Multi-scale Attention For Sequence To Sequence Learning", "topic_distr": {"0": 0.0010307150660082698, "1": 0.0008418436627835035, "2": 0.4504929184913635, "3": 0.03968585655093193, "4": 0.0005435794591903687, "5": 0.0004861918278038502, "6": 0.0004397644952405244, "7": 0.00040143117075785995, "8": 0.0003692449245136231, "9": 0.04545479640364647, "10": 0.32056063413619995, "11": 0.00029764947248622775, "12": 0.0002795795735437423, "13": 0.00026357811293564737, "14": 0.13777512311935425, "15": 0.00023650577350053936, "16": 0.00022495322627946734, "17": 0.00021447670587804168, "18": 0.0002049325848929584, "19": 0.00019620168313849717}}, {"key": "zhao2019text", "year": "2019", "title": "Moverscore: Text Generation Evaluating With Contextualized Embeddings And Earth Mover Distance", "topic_distr": {"0": 0.3030385375022888, "1": 0.0012573666172102094, "2": 0.0746513083577156, "3": 0.0009205932728946209, "4": 0.14135247468948364, "5": 0.0007262067520059645, "6": 0.0006568601238541305, "7": 0.20157797634601593, "8": 0.0005515275988727808, "9": 0.0005105892196297646, "10": 0.00047530836309306324, "11": 0.000444588134996593, "12": 0.0004175977664999664, "13": 0.00039369697333313525, "14": 0.10053019970655441, "15": 0.00035326002398505807, "16": 0.0003360043920110911, "17": 0.0003203559899702668, "18": 0.07468283921480179, "19": 0.09680268913507462}}, {"key": "zhao2020efficient", "year": "2020", "title": "SPARTA: Efficient Open-domain Question Answering Via Sparse Transformer Matching Retrieval", "topic_distr": {"0": 0.0013702729484066367, "1": 0.0011194244725629687, "2": 0.3379594385623932, "3": 0.0008194721885956824, "4": 0.015320192091166973, "5": 0.054269224405288696, "6": 0.0005847084103152156, "7": 0.03332394361495972, "8": 0.24731889367103577, "9": 0.00045450442121364176, "10": 0.1292477548122406, "11": 0.00039575310074724257, "12": 0.00037172745214775205, "13": 0.13271088898181915, "14": 0.024785049259662628, "15": 0.018831098452210426, "16": 0.00029909657314419746, "17": 0.00028516704333014786, "18": 0.00027247724938206375, "19": 0.0002608686627354473}}, {"key": "zhao2020inducing", "year": "2020", "title": "Inducing Language-agnostic Multilingual Representations", "topic_distr": {"0": 0.0924849584698677, "1": 0.0012892234371975064, "2": 0.32694950699806213, "3": 0.17335514724254608, "4": 0.000832496618386358, "5": 0.0007446066592819989, "6": 0.0006735030910931528, "7": 0.0006147952517494559, "8": 0.0005655017448589206, "9": 0.0005235261050984263, "10": 0.23684921860694885, "11": 0.00045585271436721087, "12": 0.00042817852227017283, "13": 0.0004036721074953675, "14": 0.1350262612104416, "15": 0.00036221061600372195, "16": 0.00034451778628863394, "17": 0.00032847290276549757, "18": 0.0003138559986837208, "19": 0.02745453082025051}}, {"key": "zhao2020knowledge", "year": "2020", "title": "Knowledge-grounded Dialogue Generation With Pre-trained Language Models", "topic_distr": {"0": 0.05716440826654434, "1": 0.002483922755345702, "2": 0.11675882339477539, "3": 0.0018188203684985638, "4": 0.0016041217604652047, "5": 0.0014347669202834368, "6": 0.529654860496521, "7": 0.0011846355628222227, "8": 0.0010896530002355576, "9": 0.0010087710106745362, "10": 0.0009390665800310671, "11": 0.0008783726370893419, "12": 0.0008250477840192616, "13": 0.047262825071811676, "14": 0.0007357188733294606, "15": 0.0006979356985539198, "16": 0.2326415777206421, "17": 0.0006329272291623056, "18": 0.0006047622882761061, "19": 0.0005789971328340471}}, {"key": "zhao2020low", "year": "2020", "title": "Low-resource Knowledge-grounded Dialogue Generation", "topic_distr": {"0": 0.001864893827587366, "1": 0.09429685026407242, "2": 0.24185392260551453, "3": 0.0011130449129268527, "4": 0.000981656601652503, "5": 0.07466721534729004, "6": 0.2552160620689392, "7": 0.0007249495829455554, "8": 0.03499565273523331, "9": 0.0006173274596221745, "10": 0.0005746711976826191, "11": 0.08164849132299423, "12": 0.0005048962775617838, "13": 0.17988811433315277, "14": 0.0004502305237110704, "15": 0.0004271087527740747, "16": 0.02906312234699726, "17": 0.0003873261739499867, "18": 0.0003700903325807303, "19": 0.0003543230704963207}}, {"key": "zhao2020masking", "year": "2020", "title": "Masking As An Efficient Alternative To Finetuning For Pretrained Language Models", "topic_distr": {"0": 0.08114766329526901, "1": 0.00161660835146904, "2": 0.0013667203020304441, "3": 0.11886103451251984, "4": 0.0010440010810270905, "5": 0.000933781499043107, "6": 0.0008446132997050881, "7": 0.0007709901547059417, "8": 0.000709173153154552, "9": 0.0006565331714227796, "10": 0.15940602123737335, "11": 0.0005716666928492486, "12": 0.0005369615973904729, "13": 0.244275763630867, "14": 0.00047882410581223667, "15": 0.00045423387200571597, "16": 0.08587372303009033, "17": 0.0004119247605558485, "18": 0.0003935942950192839, "19": 0.29964613914489746}}, {"key": "zhao2020segment", "year": "2020", "title": "SEAL: Segment-wise Extractive-abstractive Long-form Text Summarization", "topic_distr": {"0": 0.0015588547103106976, "1": 0.0012729750014841557, "2": 0.24112266302108765, "3": 0.0009321285178884864, "4": 0.0008221019525080919, "5": 0.07764901965856552, "6": 0.020203035324811935, "7": 0.2653217017650604, "8": 0.0005584409809671342, "9": 0.0005169894429855049, "10": 0.3867644965648651, "11": 0.00045016102376393974, "12": 0.00042283235234208405, "13": 0.00039863193524070084, "14": 0.0003770517942029983, "15": 0.0003576881135813892, "16": 0.0003402161819394678, "17": 0.00032437164918519557, "18": 0.000309937255224213, "19": 0.00029673276003450155}}, {"key": "zhao2021calibrate", "year": "2021", "title": "Calibrate Before Use: Improving Few-shot Performance Of Language Models", "topic_distr": {"0": 0.14097711443901062, "1": 0.21570169925689697, "2": 0.3172380030155182, "3": 0.0010356239508837461, "4": 0.0009133752901107073, "5": 0.0008169473730958998, "6": 0.0007389357197098434, "7": 0.0006745242862962186, "8": 0.07886707782745361, "9": 0.000574388075619936, "10": 0.0005346988327801228, "11": 0.0005001400713808835, "12": 0.0004697772383224219, "13": 0.0004428899846971035, "14": 0.0004189138999208808, "15": 0.0003974003775510937, "16": 0.00037798864650540054, "17": 0.2386464923620224, "18": 0.00034434799454174936, "19": 0.00032967745210044086}}, {"key": "zhao2021effective", "year": "2021", "title": "Effective Sequence-to-sequence Dialogue State Tracking", "topic_distr": {"0": 0.001620927476324141, "1": 0.0013227430172264576, "2": 0.35979652404785156, "3": 0.12505820393562317, "4": 0.0008541474817320704, "5": 0.2145405411720276, "6": 0.0006910183001309633, "7": 0.08102822303771973, "8": 0.0005802082596346736, "9": 0.0005371409934014082, "10": 0.0005000254604965448, "11": 0.00046770769404247403, "12": 0.00043931379332207143, "13": 0.00041417009197175503, "14": 0.0003917487629223615, "15": 0.0003716303326655179, "16": 0.00035347737139090896, "17": 0.0003370152262505144, "18": 0.00032201819703914225, "19": 0.210373193025589}}, {"key": "zhao2022calibrating", "year": "2022", "title": "Calibrating Sequence Likelihood Improves Conditional Language Generation", "topic_distr": {"0": 0.06108797341585159, "1": 0.0011071327608078718, "2": 0.000935875519644469, "3": 0.0008105847518891096, "4": 0.000714902940671891, "5": 0.0006394277443177998, "6": 0.02074074000120163, "7": 0.5308694243431091, "8": 0.05056263878941536, "9": 0.0004495757457334548, "10": 0.14913561940193176, "11": 0.000391461537219584, "12": 0.015797084197402, "13": 0.1380714476108551, "14": 0.0003278855001553893, "15": 0.027252700179815292, "16": 0.0002958531549666077, "17": 0.00028207467403262854, "18": 0.00026952248299494386, "19": 0.00025803979951888323}}, {"key": "zhao2022description", "year": "2022", "title": "Description-driven Task-oriented Dialog Modeling", "topic_distr": {"0": 0.0015035532414913177, "1": 0.07079886645078659, "2": 0.2967413365840912, "3": 0.0008984580053947866, "4": 0.10805351287126541, "5": 0.07769273221492767, "6": 0.24230550229549408, "7": 0.0005851857713423669, "8": 0.0005382663221098483, "9": 0.0004983122926205397, "10": 0.00046387972543016076, "11": 0.05301962047815323, "12": 0.0004075567703694105, "13": 0.05942002311348915, "14": 0.00036343012470752, "15": 0.00034476598375476897, "16": 0.00032792528509162366, "17": 0.000312653137370944, "18": 0.0002987402258440852, "19": 0.08542567491531372}}, {"key": "zhao2022educational", "year": "2022", "title": "Educational Question Generation Of Children Storybooks Via Question Type Distribution Learning And Event-centric Summarization", "topic_distr": {"0": 0.15601877868175507, "1": 0.0013227781746536493, "2": 0.001118211541324854, "3": 0.0009685005061328411, "4": 0.0008541772258467972, "5": 0.0007639983668923378, "6": 0.0006910430383868515, "7": 0.334383100271225, "8": 0.3831979036331177, "9": 0.0005371602019295096, "10": 0.018626311793923378, "11": 0.09858023375272751, "12": 0.00043932950939051807, "13": 0.0004141849058214575, "14": 0.0003917627618648112, "15": 0.0003716436040122062, "16": 0.0003534900024533272, "17": 0.0003370272752363235, "18": 0.0003220297221560031, "19": 0.00030831003095954657}}, {"key": "zhao2022learning", "year": "2022", "title": "Learning Video Representations From Large Language Models", "topic_distr": {"0": 0.001734773744828999, "1": 0.13369035720825195, "2": 0.1997622698545456, "3": 0.13194383680820465, "4": 0.0009134263382293284, "5": 0.0008169904467649758, "6": 0.0007389748352579772, "7": 0.0006745599675923586, "8": 0.0006204746314324439, "9": 0.0005744184600189328, "10": 0.0005347271217033267, "11": 0.0005001664976589382, "12": 0.00046980209299363196, "13": 0.08174711465835571, "14": 0.00041893604793585837, "15": 0.00039742139051668346, "16": 0.00037800861173309386, "17": 0.00036040402483195066, "18": 0.3746764659881592, "19": 0.06904684752225876}}, {"key": "zhao2022vl", "year": "2022", "title": "Vl-checklist: Evaluating Pre-trained Vision-language Models With Objects, Attributes And Relations", "topic_distr": {"0": 0.0740765780210495, "1": 0.001144350622780621, "2": 0.0009673878084868193, "3": 0.2593557834625244, "4": 0.09676493704319, "5": 0.0006609464180655777, "6": 0.0005978316185064614, "7": 0.0005457199295051396, "8": 0.0005019648233428597, "9": 0.0004647053137887269, "10": 0.0004325949412304908, "11": 0.0004046353860758245, "12": 0.2163570076227188, "13": 0.00035831754212267697, "14": 0.0003389198100194335, "15": 0.00032151443883776665, "16": 0.0003058094880543649, "17": 0.25206759572029114, "18": 0.06491822004318237, "19": 0.029415151104331017}}, {"key": "zhao2023chat", "year": "2023", "title": "Chat With The Environment: Interactive Multimodal Perception Using Large Language Models", "topic_distr": {"0": 0.0010398078011348844, "1": 0.0008486488950438797, "2": 0.0007174458005465567, "3": 0.3422929346561432, "4": 0.000548051088117063, "5": 0.000490190926939249, "6": 0.0004433818394318223, "7": 0.0004047331749461591, "8": 0.00037228220026008785, "9": 0.00034464869531802833, "10": 0.0003208340494893491, "11": 0.3889966607093811, "12": 0.0002818793000187725, "13": 0.00026574620278552175, "14": 0.0002513598883524537, "15": 0.00023845118994358927, "16": 0.0002268036041641608, "17": 0.00021624090732075274, "18": 0.26150211691856384, "19": 0.0001978155632968992}}, {"key": "zhao2023enabling", "year": "2023", "title": "Bubogpt: Enabling Visual Grounding In Multi-modal Llms", "topic_distr": {"0": 0.0009911349043250084, "1": 0.03984317556023598, "2": 0.0006833233055658638, "3": 0.26309943199157715, "4": 0.0005219734157435596, "5": 0.00046686604036949575, "6": 0.051573414355516434, "7": 0.00038547455915249884, "8": 0.00035456771729514003, "9": 0.07389382272958755, "10": 0.00030556763522326946, "11": 0.00028581812512129545, "12": 0.0002684665087144822, "13": 0.0002531010832171887, "14": 0.00023939930542837828, "15": 0.0002271048433613032, "16": 0.03723042830824852, "17": 0.00020595140813384205, "18": 0.5289825797080994, "19": 0.0001884028170024976}}, {"key": "zhao2023evaluating", "year": "2023", "title": "On Evaluating Adversarial Robustness Of Large Vision-language Models", "topic_distr": {"0": 0.07214731723070145, "1": 0.1828150898218155, "2": 0.0009257775964215398, "3": 0.3000071048736572, "4": 0.0007071974687278271, "5": 0.0006325355498120189, "6": 0.09537049382925034, "7": 0.0005222619511187077, "8": 0.00048038765089586377, "9": 0.11324089765548706, "10": 0.00041399968904443085, "11": 0.00038724197656847537, "12": 0.0003637330373749137, "13": 0.000342915125656873, "14": 0.00032435121829621494, "15": 0.00030769401928409934, "16": 0.00029266413184814155, "17": 0.00027903419686481357, "18": 0.21635614335536957, "19": 0.014083150774240494}}, {"key": "zhao2023explainability", "year": "2023", "title": "Explainability For Large Language Models: A Survey", "topic_distr": {"0": 0.12190447002649307, "1": 0.0010609523160383105, "2": 0.0008968474576249719, "3": 0.16756899654865265, "4": 0.0006850776262581348, "5": 0.1368647813796997, "6": 0.0005542378639802337, "7": 0.0005059261457063258, "8": 0.00046536163426935673, "9": 0.1581418216228485, "10": 0.01884579099714756, "11": 0.00037512945709750056, "12": 0.277126282453537, "13": 0.0003321890835650265, "14": 0.02950979582965374, "15": 0.00029806967359036207, "16": 0.08408837020397186, "17": 0.0002703063073568046, "18": 0.00025827778154052794, "19": 0.0002472741762176156}}, {"key": "zhao2023is", "year": "2023", "title": "Is Chatgpt Equipped With Emotional Dialogue Capabilities?", "topic_distr": {"0": 0.002270766533911228, "1": 0.03542134910821915, "2": 0.0015654114540666342, "3": 0.0013558726059272885, "4": 0.001195819117128849, "5": 0.1101435050368309, "6": 0.1309717744588852, "7": 0.0008831071900203824, "8": 0.0008123007719404995, "9": 0.38388383388519287, "10": 0.0007000435725785792, "11": 0.0006547981756739318, "12": 0.21061140298843384, "13": 0.0005798446945846081, "14": 0.0005484544672071934, "15": 0.0005202883621677756, "16": 0.0004948739078827202, "17": 0.0004718266427516937, "18": 0.00045083058648742735, "19": 0.11646390706300735}}, {"key": "zhao2023llm", "year": "2023", "title": "Expel: LLM Agents Are Experiential Learners", "topic_distr": {"0": 0.001356138731352985, "1": 0.001107143354602158, "2": 0.10488110780715942, "3": 0.3794129192829132, "4": 0.000714892172254622, "5": 0.0006394178490154445, "6": 0.0005783587112091482, "7": 0.0005279444740153849, "8": 0.00048561455332674086, "9": 0.12219323962926865, "10": 0.00041850426350720227, "11": 0.3406425714492798, "12": 0.0003676906635519117, "13": 0.00034664623672142625, "14": 0.0003278803778812289, "15": 0.0003110419202130288, "16": 0.044879235327243805, "17": 0.0002820702502503991, "18": 0.00026951826293952763, "19": 0.00025803575408644974}}, {"key": "zhao2023recommender", "year": "2023", "title": "Recommender Systems In The Era Of Large Language Models (llms)", "topic_distr": {"0": 0.000832135381642729, "1": 0.032390791922807693, "2": 0.000573987141251564, "3": 0.11192808300256729, "4": 0.23003393411636353, "5": 0.00039217103039845824, "6": 0.0003547219675965607, "7": 0.00032380162156187, "8": 0.00029783963691443205, "9": 0.13650646805763245, "10": 0.00025667919544503093, "11": 0.0002400894445599988, "12": 0.3300081789493561, "13": 0.00021260685753077269, "14": 0.0002010972675634548, "15": 0.016672002151608467, "16": 0.11708066612482071, "17": 0.021371230483055115, "18": 0.00016530232096556574, "19": 0.000158259819727391}}, {"key": "zhao2023retrieving", "year": "2023", "title": "Retrieving Multimodal Information For Augmented Generation: A Survey", "topic_distr": {"0": 0.001521335681900382, "1": 0.0012421528808772564, "2": 0.0010499657364562154, "3": 0.10163392871618271, "4": 0.0008020737441256642, "5": 0.04843374714255333, "6": 0.000648890680167824, "7": 0.028733359649777412, "8": 0.0005448361625894904, "9": 0.13740187883377075, "10": 0.00046954164281487465, "11": 0.00043919411837123334, "12": 0.21567785739898682, "13": 0.0003889203944709152, "14": 0.0003678659850265831, "15": 0.0584891140460968, "16": 0.21362558007240295, "17": 0.0003164692607242614, "18": 0.17310398817062378, "19": 0.015109321102499962}}, {"key": "zhao2023verify", "year": "2023", "title": "Verify-and-edit: A Knowledge-enhanced Chain-of-thought Framework", "topic_distr": {"0": 0.09799296408891678, "1": 0.0016972291050478816, "2": 0.001434900565072894, "3": 0.5943383574485779, "4": 0.0010961180087178946, "5": 0.000980396755039692, "6": 0.0008867771248333156, "7": 0.1398795247077942, "8": 0.0007445756928063929, "9": 0.0006893078680150211, "10": 0.0006416778778657317, "11": 0.0006002048030495644, "12": 0.09203751385211945, "13": 0.0005315004964359105, "14": 0.0005027274019084871, "15": 0.00047690962674096227, "16": 0.06422792375087738, "17": 0.0004324883921071887, "18": 0.00041324287303723395, "19": 0.00039563715108670294}}, {"key": "zhao2024revolutionizing", "year": "2024", "title": "Revolutionizing Finance With Llms: An Overview Of Applications And Insights", "topic_distr": {"0": 0.0011782690417021513, "1": 0.04059627652168274, "2": 0.0008122070576064289, "3": 0.31649360060691833, "4": 0.0006204377859830856, "5": 0.0005549351335503161, "6": 0.0005019435193389654, "7": 0.00045819018851034343, "8": 0.000421453092712909, "9": 0.2738140821456909, "10": 0.02536858059465885, "11": 0.00033973462996073067, "12": 0.3020910620689392, "13": 0.014054296538233757, "14": 0.0002845594135578722, "15": 0.02145097777247429, "16": 0.0002567597257439047, "17": 0.0002448019222356379, "18": 0.00023390834394376725, "19": 0.0002239429741166532}}, {"key": "zheng2019dynamic", "year": "2019", "title": "Dynamic Past And Future For Neural Machine Translation", "topic_distr": {"0": 0.11208882182836533, "1": 0.001566848368383944, "2": 0.5060737133026123, "3": 0.0011472506448626518, "4": 0.0010118293575942516, "5": 0.0009050064836628735, "6": 0.0008185859769582748, "7": 0.1477152556180954, "8": 0.000687319494318217, "9": 0.0006363016436807811, "10": 0.0005923342541791499, "11": 0.0005540503771044314, "12": 0.0005204147309996188, "13": 0.0004906292888335884, "14": 0.22318679094314575, "15": 0.00044023635564371943, "16": 0.0004187322047073394, "17": 0.00039923100848682225, "18": 0.0003814654191955924, "19": 0.00036521354923024774}}, {"key": "zheng2019pre", "year": "2019", "title": "A Pre-training Based Personalized Dialogue Generation Model With Persona-sparse Data", "topic_distr": {"0": 0.16921783983707428, "1": 0.04564442113041878, "2": 0.0808708518743515, "3": 0.000753214000724256, "4": 0.0006643063388764858, "5": 0.1497277319431305, "6": 0.20149663090705872, "7": 0.1491277813911438, "8": 0.0004512521263677627, "9": 0.0004177569062449038, "10": 0.08424472063779831, "11": 0.00036375573836266994, "12": 0.0003416726249270141, "13": 0.0003221173246856779, "14": 0.00030467932811006904, "15": 0.11502402275800705, "16": 0.00027491405489854515, "17": 0.00026211075601167977, "18": 0.0002504469593986869, "19": 0.0002397769712843001}}, {"key": "zheng2020cross", "year": "2020", "title": "Cross-modality Relevance For Reasoning On Language And Vision", "topic_distr": {"0": 0.0015579478349536657, "1": 0.0012732059694826603, "2": 0.12027541548013687, "3": 0.0009320714161731303, "4": 0.0008220490417443216, "5": 0.000735261884983629, "6": 0.15626980364322662, "7": 0.0006070795352570713, "8": 0.0005584046593867242, "9": 0.0005169557989574969, "10": 0.00048123503802344203, "11": 0.00045013174531050026, "12": 0.00042280484922230244, "13": 0.05698598921298981, "14": 0.00037702725967392325, "15": 0.00035766485962085426, "16": 0.11158142983913422, "17": 0.00032435054890811443, "18": 0.5451744794845581, "19": 0.00029671346419490874}}, {"key": "zheng2020towards", "year": "2020", "title": "Towards Making The Most Of Context In Neural Machine Translation", "topic_distr": {"0": 0.0014333531726151705, "1": 0.0011705065844580531, "2": 0.6297229528427124, "3": 0.0008570651989430189, "4": 0.000755896617192775, "5": 0.0006760932155884802, "6": 0.0006115320138633251, "7": 0.0005582260782830417, "8": 0.05861235782504082, "9": 0.00047535484191030264, "10": 0.09891241043806076, "11": 0.0004139083030167967, "12": 0.01836112141609192, "13": 0.00036652901326306164, "14": 0.1855749487876892, "15": 0.00032888251007534564, "16": 0.0003128176322206855, "17": 0.00029824909870512784, "18": 0.00028497716994024813, "19": 0.00027283604140393436}}, {"key": "zheng2021exploring", "year": "2021", "title": "Exploring Prompt-based Few-shot Learning For Grounded Dialog Generation", "topic_distr": {"0": 0.0016421787440776825, "1": 0.0013399010058492422, "2": 0.0011327721877023578, "3": 0.0009811397176235914, "4": 0.085453562438488, "5": 0.0007739698048681021, "6": 0.18236273527145386, "7": 0.0006390393245965242, "8": 0.0005878019728697836, "9": 0.0005441710236482322, "10": 0.000506569747813046, "11": 0.000473828986287117, "12": 0.1080586239695549, "13": 0.0004195906803943217, "14": 0.00039687592652626336, "15": 0.00037649416481144726, "16": 0.02144496887922287, "17": 0.5089713931083679, "18": 0.05248231440782547, "19": 0.031412072479724884}}, {"key": "zheng2022prompt", "year": "2022", "title": "Prompt Vision Transformer For Domain Generalization", "topic_distr": {"0": 0.0012238683411851525, "1": 0.0009983928175643086, "2": 0.1351076066493988, "3": 0.0007310324581339955, "4": 0.0006447407649829984, "5": 0.0005766729009337723, "6": 0.0005216054851189256, "7": 0.000476138258818537, "8": 0.0004379620950203389, "9": 0.000405453349230811, "10": 0.09260334074497223, "11": 0.00035304261837154627, "12": 0.0003316098591312766, "13": 0.06428933143615723, "14": 0.00029570606420747936, "15": 0.0002805199474096298, "16": 0.1699259728193283, "17": 0.455767422914505, "18": 0.0747968927025795, "19": 0.00023271518875844777}}, {"key": "zheng2023adapting", "year": "2023", "title": "Adapting Large Language Models By Integrating Collaborative Semantics For Recommendation", "topic_distr": {"0": 0.0009235954494215548, "1": 0.0007544675027020276, "2": 0.0006377495592460036, "3": 0.18737779557704926, "4": 0.4477199912071228, "5": 0.0004357386496849358, "6": 0.0003941292525269091, "7": 0.00035977386869490147, "8": 0.0003309276362415403, "9": 0.0003063637705054134, "10": 0.00028519457555375993, "11": 0.0002667618100531399, "12": 0.00025056704180315137, "13": 0.060354821383953094, "14": 0.00022343786258716136, "15": 0.045893095433712006, "16": 0.1712769865989685, "17": 0.081849105656147, "18": 0.00018366632866673172, "19": 0.00017584144370630383}}, {"key": "zheng2023chatgpt", "year": "2023", "title": "Chatgpt Chemistry Assistant For Text Mining And Prediction Of MOF Synthesis", "topic_distr": {"0": 0.0909053385257721, "1": 0.05192192643880844, "2": 0.0007620059768669307, "3": 0.2920401096343994, "4": 0.0005820780643261969, "5": 0.0005206248024478555, "6": 0.0004709095519501716, "7": 0.11904866993427277, "8": 0.02977258525788784, "9": 0.3400229513645172, "10": 0.0003407532931305468, "11": 0.0003187296388205141, "12": 0.00029937998624518514, "13": 0.0002822452806867659, "14": 0.0002669657696969807, "15": 0.00025325562455691397, "16": 0.0002408848813502118, "17": 0.07152102887630463, "18": 0.0002194463595515117, "19": 0.00021009710326325148}}, {"key": "zheng2023judging", "year": "2023", "title": "Judging Llm-as-a-judge With Mt-bench And Chatbot Arena", "topic_distr": {"0": 0.22012852132320404, "1": 0.001095200190320611, "2": 0.0009258190402761102, "3": 0.4724070429801941, "4": 0.1635463386774063, "5": 0.0006325573194772005, "6": 0.0005721533671021461, "7": 0.0005222799954935908, "8": 0.04001014679670334, "9": 0.05723065510392189, "10": 0.00041401400812901556, "11": 0.00038725536433048546, "12": 0.000363745610229671, "13": 0.04003861919045448, "14": 0.0003243624232709408, "15": 0.00030770464218221605, "16": 0.0002926742599811405, "17": 0.00027904383023269475, "18": 0.00026662650634534657, "19": 0.0002552672231104225}}, {"key": "zheng2023pre", "year": "2023", "title": "Codegeex: A Pre-trained Model For Code Generation With Multilingual Benchmarking On Humaneval-x", "topic_distr": {"0": 0.0015404917066916823, "1": 0.0012572526466101408, "2": 0.0010629476746544242, "3": 0.12805627286434174, "4": 0.0008119815611280501, "5": 0.09132464230060577, "6": 0.2709720730781555, "7": 0.0005996439722366631, "8": 0.0005515653174370527, "9": 0.11324937641620636, "10": 0.00047534084296785295, "11": 0.00044461849029175937, "12": 0.05517046898603439, "13": 0.2323167771100998, "14": 0.08227725327014923, "15": 0.0003532841510605067, "16": 0.0003360273549333215, "17": 0.0003203778760507703, "18": 0.018586566671729088, "19": 0.00029307929798960686}}, {"key": "zheng2023preventing", "year": "2023", "title": "Preventing Zero-shot Transfer Degradation In Continual Learning Of Vision-language Models", "topic_distr": {"0": 0.0011145416647195816, "1": 0.11684286594390869, "2": 0.17650991678237915, "3": 0.0006657713674940169, "4": 0.0005871834582649171, "5": 0.0005251921247690916, "6": 0.00047504069516435266, "7": 0.00043363243457861245, "8": 0.00039886432932689786, "9": 0.0003692577010951936, "10": 0.0003437426348682493, "11": 0.0003215257602278143, "12": 0.0003020063741132617, "13": 0.14801837503910065, "14": 0.0423009991645813, "15": 0.0002554773527663201, "16": 0.16280318796634674, "17": 0.15615563094615936, "18": 0.1913648247718811, "19": 0.0002119402342941612}}, {"key": "zheng2023progressive", "year": "2023", "title": "Progressive-hint Prompting Improves Reasoning In Large Language Models", "topic_distr": {"0": 0.0014017709763720632, "1": 0.001144393696449697, "2": 0.07523795962333679, "3": 0.5682637691497803, "4": 0.04649803787469864, "5": 0.0610143318772316, "6": 0.0005978592089377344, "7": 0.043659988790750504, "8": 0.027914440259337425, "9": 0.0004647267051041126, "10": 0.00043261487735435367, "11": 0.0004046540125273168, "12": 0.00038008802221156657, "13": 0.00035833404399454594, "14": 0.00033893543877638876, "15": 0.0003215292526874691, "16": 0.000305823574308306, "17": 0.17071537673473358, "18": 0.0002786055556498468, "19": 0.000266735878540203}}, {"key": "zheng2023secrets", "year": "2023", "title": "Secrets Of RLHF In Large Language Models Part I: PPO", "topic_distr": {"0": 0.1429756134748459, "1": 0.0007956790504977107, "2": 0.0006725954008288682, "3": 0.0005825664848089218, "4": 0.07512002438306808, "5": 0.0004595537611749023, "6": 0.0004156702780164778, "7": 0.00037943717325106263, "8": 0.0003490143863018602, "9": 0.296951562166214, "10": 0.0003007817722391337, "11": 0.28375089168548584, "12": 0.06624705344438553, "13": 0.12974585592746735, "14": 0.00023564978619106114, "15": 0.00022354787506628782, "16": 0.00021262827794998884, "17": 0.0002027257578447461, "18": 0.0001937045599333942, "19": 0.00018545200873631984}}, {"key": "zheng2023why", "year": "2023", "title": "Why Does Chatgpt Fall Short In Providing Truthful Answers?", "topic_distr": {"0": 0.1902928352355957, "1": 0.0013401297619566321, "2": 0.0011329001281410456, "3": 0.12264327704906464, "4": 0.0008654170669615269, "5": 0.0007740512955933809, "6": 0.000700135889928788, "7": 0.0006391065544448793, "8": 0.220002219080925, "9": 0.19902566075325012, "10": 0.0005066230078227818, "11": 0.00047387887025251985, "12": 0.15377400815486908, "13": 0.00041963483090512455, "14": 0.00039691769052296877, "15": 0.00037653380422852933, "16": 0.10565660148859024, "17": 0.0003414619714021683, "18": 0.0003262670652475208, "19": 0.00031236684299074113}}, {"key": "zheng2024harnessing", "year": "2024", "title": "Harnessing Large Language Models For Text-rich Sequential Recommendation", "topic_distr": {"0": 0.04559725150465965, "1": 0.0008349097333848476, "2": 0.10528498888015747, "3": 0.17523238062858582, "4": 0.4082002639770508, "5": 0.0004822222690563649, "6": 0.0004361741303000599, "7": 0.07852611690759659, "8": 0.00036623029154725373, "9": 0.0003390460042282939, "10": 0.0240337997674942, "11": 0.00029521938995458186, "12": 0.05936127156019211, "13": 0.0002614261757116765, "14": 0.00024727373966015875, "15": 0.030352933332324028, "16": 0.0695379227399826, "17": 0.00021272565936669707, "18": 0.0002032594638876617, "19": 0.000194599837413989}}, {"key": "zheng2024unified", "year": "2024", "title": "Llamafactory: Unified Efficient Fine-tuning Of 100+ Language Models", "topic_distr": {"0": 0.0027093959506601095, "1": 0.0022137851919978857, "2": 0.0018715147161856294, "3": 0.22800743579864502, "4": 0.0014296718873083591, "5": 0.0012787353480234742, "6": 0.001156626851297915, "7": 0.15708886086940765, "8": 0.0009711530292406678, "9": 0.0008990669157356024, "10": 0.0008369429269805551, "11": 0.0007828494417481124, "12": 0.0007353237015195191, "13": 0.3800458610057831, "14": 0.0006557093583978713, "15": 0.0006220350624062121, "16": 0.0005916506634093821, "17": 0.21704833209514618, "18": 0.0005389942671172321, "19": 0.0005160310538485646}}, {"key": "zhong2018affect", "year": "2018", "title": "An Affect-rich Neural Conversational Model With Biased Attention And Weighted Cross-entropy Loss", "topic_distr": {"0": 0.2595234215259552, "1": 0.0011841901578009129, "2": 0.38964366912841797, "3": 0.0008671561372466385, "4": 0.0007647977326996624, "5": 0.0006840546266175807, "6": 0.24937744438648224, "7": 0.0005647994112223387, "8": 0.0005195144913159311, "9": 0.09337414056062698, "10": 0.00044771935790777206, "11": 0.000418782263295725, "12": 0.00039335855399258435, "13": 0.00037084505311213434, "14": 0.00035076914355158806, "15": 0.00033275524037890136, "16": 0.00031650118762627244, "17": 0.0003017611161340028, "18": 0.00028833287069574, "19": 0.0002760488132480532}}, {"key": "zhong2019coarse", "year": "2019", "title": "Coarse-grain Fine-grain Coattention Network For Multi-evidence Question Answering", "topic_distr": {"0": 0.001709320698864758, "1": 0.0013948808191344142, "2": 0.585654616355896, "3": 0.0010214170906692743, "4": 0.0009008490014821291, "5": 0.0008057428058236837, "6": 0.0007288010674528778, "7": 0.0006652731099165976, "8": 0.3329291045665741, "9": 0.0005665103089995682, "10": 0.050354257225990295, "11": 0.0004932805895805359, "12": 0.0004633341741282493, "13": 0.00043681569513864815, "14": 0.0004131684254389256, "15": 0.00039194998680613935, "16": 0.00037280446849763393, "17": 0.00035544222919270396, "18": 0.00033962519955821335, "19": 0.020002806559205055}}, {"key": "zhong2021adapting", "year": "2021", "title": "Adapting Language Models For Zero-shot Learning By Meta-tuning On Dataset And Prompt Collections", "topic_distr": {"0": 0.00132763443980366, "1": 0.1182958111166954, "2": 0.21320845186710358, "3": 0.11005881428718567, "4": 0.04599684476852417, "5": 0.0006257782224565744, "6": 0.0005660216556861997, "7": 0.0005166827468201518, "8": 0.046091482043266296, "9": 0.00043997884495183825, "10": 0.00040957704186439514, "11": 0.00038310515810735524, "12": 0.024938516318798065, "13": 0.0003392518265172839, "14": 0.0003208862617611885, "15": 0.0003044070035684854, "16": 0.0002895376819651574, "17": 0.3840799927711487, "18": 0.00026376909227110445, "19": 0.051543429493904114}}, {"key": "zhong2021pre", "year": "2021", "title": "Dialoglm: Pre-trained Model For Long Dialogue Understanding And Summarization", "topic_distr": {"0": 0.0012365347938612103, "1": 0.0010086316615343094, "2": 0.12063972651958466, "3": 0.03967203199863434, "4": 0.11277209967374802, "5": 0.1166212260723114, "6": 0.04011072218418121, "7": 0.10262566059827805, "8": 0.03029763698577881, "9": 0.10235190391540527, "10": 0.1948944479227066, "11": 0.0003566014638636261, "12": 0.00033495266688987613, "13": 0.0003157819446641952, "14": 0.00029868693673051894, "15": 0.09498473256826401, "16": 0.04074108600616455, "17": 0.000256955623626709, "18": 0.0002455211943015456, "19": 0.00023506107390858233}}, {"key": "zhong2022less", "year": "2022", "title": "Less Is More: Learning To Refine Dialogue History For Personalized Dialogue Generation", "topic_distr": {"0": 0.05291818082332611, "1": 0.0009430439095012844, "2": 0.0007971662562340498, "3": 0.0006904430338181555, "4": 0.3771633803844452, "5": 0.15253165364265442, "6": 0.20413580536842346, "7": 0.00044970025192014873, "8": 0.00041364383650943637, "9": 0.00038294019759632647, "10": 0.0003564796643331647, "11": 0.000333439587848261, "12": 0.00031319691333919764, "13": 0.05347415432333946, "14": 0.0002792867016978562, "15": 0.07887512445449829, "16": 0.0752527117729187, "17": 0.00024026591563597322, "18": 0.00022957418696023524, "19": 0.00021979346638545394}}, {"key": "zhong2022towards", "year": "2022", "title": "Towards A Unified Multi-dimensional Evaluator For Text Generation", "topic_distr": {"0": 0.05103186517953873, "1": 0.0009093844564631581, "2": 0.0007687253528274596, "3": 0.18448121845722198, "4": 0.22304125130176544, "5": 0.0005252285627648234, "6": 0.07020401954650879, "7": 0.14023737609386444, "8": 0.061697207391262054, "9": 0.0003692831960506737, "10": 0.00034376635449007154, "11": 0.0003215479664504528, "12": 0.1369260847568512, "13": 0.0002847409632522613, "14": 0.0709567666053772, "15": 0.0002554949896875769, "16": 0.05698096379637718, "17": 0.0002316971804248169, "18": 0.00022138677013572305, "19": 0.0002119548589689657}}, {"key": "zhong2023enhancing", "year": "2023", "title": "Memorybank: Enhancing Large Language Models With Long-term Memory", "topic_distr": {"0": 0.20639288425445557, "1": 0.0008706807857379317, "2": 0.0007359012379311025, "3": 0.0006373876822181046, "4": 0.2326582819223404, "5": 0.0005028002196922898, "6": 0.00045478701940737665, "7": 0.0004151441971771419, "8": 0.0003818584664259106, "9": 0.24267995357513428, "10": 0.0003290869062766433, "11": 0.00030781730310991406, "12": 0.0002891301119234413, "13": 0.000272582023171708, "14": 0.0002578256535343826, "15": 0.01366736926138401, "16": 0.2573208808898926, "17": 0.00022180330415721983, "18": 0.00021193316206336021, "19": 0.04139190912246704}}, {"key": "zhong2023sur", "year": "2023", "title": "Sur-adapter: Enhancing Text-to-image Pre-trained Diffusion Models With Large Language Models", "topic_distr": {"0": 0.0009593928116373718, "1": 0.0007834471180103719, "2": 0.0006622868240810931, "3": 0.14075741171836853, "4": 0.0005059145041741431, "5": 0.00045250251423567533, "6": 0.00040929223177954555, "7": 0.16382698714733124, "8": 0.00034365910687483847, "9": 0.05385635793209076, "10": 0.00029616657411679626, "11": 0.0002770246646832675, "12": 0.0002602068707346916, "13": 0.06082791090011597, "14": 0.00023203396995086223, "15": 0.0002201177558163181, "16": 0.143784299492836, "17": 0.17878185212612152, "18": 0.2525804936885834, "19": 0.0001826064253691584}}, {"key": "zhou2017generating", "year": "2017", "title": "Mojitalk: Generating Emotional Responses At Scale", "topic_distr": {"0": 0.0013864964712411165, "1": 0.17208078503608704, "2": 0.193062424659729, "3": 0.0008285973453894258, "4": 0.0007307872292585671, "5": 0.0006536348373629153, "6": 0.17550994455814362, "7": 0.12679952383041382, "8": 0.000496411812491715, "9": 0.16963796317577362, "10": 0.04047468304634094, "11": 0.11582536995410919, "12": 0.0003758659877348691, "13": 0.00035435365862213075, "14": 0.0003351705090608448, "15": 0.0003179576888214797, "16": 0.0003024264588020742, "17": 0.0002883418637793511, "18": 0.00027551077073439956, "19": 0.00026377299218438566}}, {"key": "zhou2018dataset", "year": "2018", "title": "A Dataset For Document Grounded Conversations", "topic_distr": {"0": 0.0018618956673890352, "1": 0.1847565621137619, "2": 0.0012851778883486986, "3": 0.0011130829807370901, "4": 0.021756991744041443, "5": 0.0008780542993918061, "6": 0.4441084861755371, "7": 0.0007249778718687594, "8": 0.25227904319763184, "9": 0.0006173516158014536, "10": 0.0005746936658397317, "11": 0.04142643138766289, "12": 0.0005049160099588335, "13": 0.0004760175943374634, "14": 0.00045024813152849674, "15": 0.04566806182265282, "16": 0.0004062617081217468, "17": 0.0003873413079418242, "18": 0.0003701047971844673, "19": 0.00035433692391961813}}, {"key": "zhou2018visual", "year": "2018", "title": "A Visual Attention Grounding Neural Model For Multimodal Machine Translation", "topic_distr": {"0": 0.0020472307223826647, "1": 0.0016702086431905627, "2": 0.13707426190376282, "3": 0.0012225719401612878, "4": 0.001078262459486723, "5": 0.02248184196650982, "6": 0.0008723301580175757, "7": 0.000796290987636894, "8": 0.000732445390895009, "9": 0.0006780779804103076, "10": 0.0006312238983809948, "11": 0.025464173406362534, "12": 0.0005545825115405023, "13": 0.000522841524798423, "14": 0.1634330451488495, "15": 0.0004691400099545717, "16": 0.0004462240030989051, "17": 0.0004254424711689353, "18": 0.6390106081962585, "19": 0.00038919158396311104}}, {"key": "zhou2019evaluating", "year": "2019", "title": "Evaluating Commonsense In Pre-trained Language Models", "topic_distr": {"0": 0.1108168214559555, "1": 0.10870953649282455, "2": 0.2446267455816269, "3": 0.13898694515228271, "4": 0.0006089323433116078, "5": 0.0005446451832540333, "6": 0.000492636114358902, "7": 0.00044969411101192236, "8": 0.13636414706707, "9": 0.00038293495890684426, "10": 0.12880219519138336, "11": 0.00033343504765070975, "12": 0.03337462991476059, "13": 0.00029526735306717455, "14": 0.0002792829181998968, "15": 0.00026494020130485296, "16": 0.03176235035061836, "17": 0.00024026264145504683, "18": 0.00022957105829846114, "19": 0.06243503838777542}}, {"key": "zhou2019synchronous", "year": "2019", "title": "Synchronous Bidirectional Neural Machine Translation", "topic_distr": {"0": 0.0014014801708981395, "1": 0.0011443780967965722, "2": 0.31746625900268555, "3": 0.0008378687780350447, "4": 0.04357091337442398, "5": 0.0006609510164707899, "6": 0.0005978358094580472, "7": 0.23402120172977448, "8": 0.0005019683158025146, "9": 0.0004647085734177381, "10": 0.10937386006116867, "11": 0.00040463823825120926, "12": 0.06077253818511963, "13": 0.00035832004505209625, "14": 0.22695882618427277, "15": 0.00032151670893654227, "16": 0.0003058116417378187, "17": 0.00029156936216168106, "18": 0.000278594670817256, "19": 0.0002667254884727299}}, {"key": "zhou2019unified", "year": "2019", "title": "Unified Vision-language Pre-training For Image Captioning And VQA", "topic_distr": {"0": 0.001618740032427013, "1": 0.0013225516304373741, "2": 0.11409229785203934, "3": 0.0009683960233815014, "4": 0.0008540840353816748, "5": 0.0007639155955985188, "6": 0.0006909681251272559, "7": 0.08525285124778748, "8": 0.05996706709265709, "9": 0.0005371019942685962, "10": 0.23527377843856812, "11": 0.000467673729872331, "12": 0.0004392818664200604, "13": 0.00041413999861106277, "14": 0.0003917202993761748, "15": 0.0003716033243108541, "16": 0.021726353093981743, "17": 0.0003369907499291003, "18": 0.4742021858692169, "19": 0.00030827661976218224}}, {"key": "zhou2020bert", "year": "2020", "title": "BERT Loses Patience: Fast And Robust Inference With Early Exit", "topic_distr": {"0": 0.0019477952737361193, "1": 0.05305184796452522, "2": 0.4111100733280182, "3": 0.0011650867527350783, "4": 0.0010275604436174035, "5": 0.0009190773707814515, "6": 0.0008313131402246654, "7": 0.0007588494336232543, "8": 0.0006980058387853205, "9": 0.0006461947923526168, "10": 0.269098699092865, "11": 0.0005626647034659982, "12": 0.000528506061527878, "13": 0.25514698028564453, "14": 0.0004712840891443193, "15": 0.00044708108180202544, "16": 0.00042524258606135845, "17": 0.00040543818613514304, "18": 0.00038739637238904834, "19": 0.0003708918229676783}}, {"key": "zhou2020detecting", "year": "2020", "title": "Detecting Hallucinated Content In Conditional Neural Sequence Generation", "topic_distr": {"0": 0.14265120029449463, "1": 0.06470364332199097, "2": 0.19842785596847534, "3": 0.000684113590978086, "4": 0.015091671608388424, "5": 0.0005396613851189613, "6": 0.00048812819295562804, "7": 0.24485179781913757, "8": 0.0004098531208001077, "9": 0.00037943082861602306, "10": 0.09498647600412369, "11": 0.00033038388937711716, "12": 0.000310326722683385, "13": 0.0002925654698628932, "14": 0.11652102321386337, "15": 0.03333059698343277, "16": 0.0002496927627362311, "17": 0.0853063240647316, "18": 0.00022747032926417887, "19": 0.00021777923393528908}}, {"key": "zhou2020pre", "year": "2020", "title": "Pre-training Text-to-text Transformers For Concept-centric Common Sense", "topic_distr": {"0": 0.0012731427559629083, "1": 0.001039428636431694, "2": 0.13321614265441895, "3": 0.0007609191234223545, "4": 0.0006710963207297027, "5": 0.0006002461886964738, "6": 0.0005429278244264424, "7": 0.0004956019693054259, "8": 0.00045586522901430726, "9": 0.00042202757322229445, "10": 0.25196748971939087, "11": 0.00036747436388395727, "12": 0.08601819723844528, "13": 0.000325410277582705, "14": 0.0003077940200455487, "15": 0.10122697055339813, "16": 0.12686172127723694, "17": 0.2929522693157196, "18": 0.0002530072524677962, "19": 0.00024222816864494234}}, {"key": "zhou2021data", "year": "2021", "title": "MELM: Data Augmentation With Masked Entity Language Modeling For Low-resource NER", "topic_distr": {"0": 0.0015207820106297731, "1": 0.19849631190299988, "2": 0.16924428939819336, "3": 0.0009093172266148031, "4": 0.0008019802044145763, "5": 0.0007173116318881512, "6": 0.0006488144281320274, "7": 0.0005922587006352842, "8": 0.0005447721341624856, "9": 0.000504335155710578, "10": 0.18707193434238434, "11": 0.00043914251727983356, "12": 0.000412482739193365, "13": 0.0003888747014570981, "14": 0.05615789443254471, "15": 0.00034893304109573364, "16": 0.23567332327365875, "17": 0.14493542909622192, "18": 0.0003023509634658694, "19": 0.00028946966631338}}, {"key": "zhou2021learning", "year": "2021", "title": "Learning To Prompt For Vision-language Models", "topic_distr": {"0": 0.0009740767418406904, "1": 0.0007956639165058732, "2": 0.254027783870697, "3": 0.0005825581029057503, "4": 0.0005137926200404763, "5": 0.0004595493956003338, "6": 0.00041566629079170525, "7": 0.000379433564376086, "8": 0.00034901106846518815, "9": 0.062324848026037216, "10": 0.00030077892006374896, "11": 0.00028133890009485185, "12": 0.00026425920077599585, "13": 0.07541466504335403, "14": 0.00023564753064420074, "15": 0.00022354575048666447, "16": 0.014921196736395359, "17": 0.4397691786289215, "18": 0.14758151769638062, "19": 0.00018545023340266198}}, {"key": "zhou2021open", "year": "2021", "title": "EVA: An Open-domain Chinese Dialogue System With Large-scale Generative Pre-training", "topic_distr": {"0": 0.05992099642753601, "1": 0.0016698817489668727, "2": 0.0014113084180280566, "3": 0.0012224008096382022, "4": 0.08998984098434448, "5": 0.310502827167511, "6": 0.061573576182127, "7": 0.0007961796363815665, "8": 0.0007323429454118013, "9": 0.0006779831019230187, "10": 0.00063113565556705, "11": 0.0005903439596295357, "12": 0.0005545049207285047, "13": 0.09130742400884628, "14": 0.08770986646413803, "15": 0.28904226422309875, "16": 0.00044616160448640585, "17": 0.00042538298293948174, "18": 0.0004064536187797785, "19": 0.00038913715980015695}}, {"key": "zhou2021universal", "year": "2021", "title": "UC2: Universal Cross-lingual Cross-modal Vision-and-language Pre-training", "topic_distr": {"0": 0.0014167436165735126, "1": 0.0011575197568163276, "2": 0.056310344487428665, "3": 0.0008473544730804861, "4": 0.0007473299629054964, "5": 0.0006684307008981705, "6": 0.0006046012858860195, "7": 0.0005518994876183569, "8": 0.046235326677560806, "9": 0.0004699674900621176, "10": 0.19204598665237427, "11": 0.00040921734762378037, "12": 0.000384374288842082, "13": 0.0003623749944381416, "14": 0.26710382103919983, "15": 0.0003251551534049213, "16": 0.01587098278105259, "17": 0.0002948689507320523, "18": 0.4139239490032196, "19": 0.0002697439049370587}}, {"key": "zhou2022conditional", "year": "2022", "title": "Conditional Prompt Learning For Vision-language Models", "topic_distr": {"0": 0.0010485126404091716, "1": 0.0008558967965655029, "2": 0.23872599005699158, "3": 0.0006266593700274825, "4": 0.0005526875029318035, "5": 0.0004943383974023163, "6": 0.00044713326497003436, "7": 0.0004081576189491898, "8": 0.0003754320496227592, "9": 0.00034756475361064076, "10": 0.00032354859285987914, "11": 0.0003026369377039373, "12": 0.00028426424250938, "13": 0.12222636491060257, "14": 0.00025348662165924907, "15": 0.0002404686965746805, "16": 0.030715027824044228, "17": 0.44898518919944763, "18": 0.1525871306657791, "19": 0.00019948926637880504}}, {"key": "zhou2022large", "year": "2022", "title": "Large Language Models Are Human-level Prompt Engineers", "topic_distr": {"0": 0.0012243204982951283, "1": 0.02394983172416687, "2": 0.0008440830279141665, "3": 0.5172572135925293, "4": 0.0006447770283557475, "5": 0.0005767052061855793, "6": 0.000521634821780026, "7": 0.0881388857960701, "8": 0.0004379867168609053, "9": 0.0004054761375300586, "10": 0.00037745843292213976, "11": 0.08158046752214432, "12": 0.0003316284855827689, "13": 0.0003126480442006141, "14": 0.00029572268249467015, "15": 0.00028053572168573737, "16": 0.0002668324450496584, "17": 0.28207796812057495, "18": 0.00024308459251187742, "19": 0.00023272827093023807}}, {"key": "zhou2022least", "year": "2022", "title": "Least-to-most Prompting Enables Complex Reasoning In Large Language Models", "topic_distr": {"0": 0.028583025559782982, "1": 0.0011317951139062643, "2": 0.10624044388532639, "3": 0.5750912427902222, "4": 0.0007308305357582867, "5": 0.0006536741275340319, "6": 0.0005912539199925959, "7": 0.0005397155182436109, "8": 0.0004964418476447463, "9": 0.00045959229464642704, "10": 0.00042783524258993566, "11": 0.1722424030303955, "12": 0.00037588871782645583, "13": 0.0003543750790413469, "14": 0.0003351907944306731, "15": 0.0003179768973495811, "16": 0.000302444736007601, "17": 0.11058654636144638, "18": 0.00027552744722925127, "19": 0.00026378894108347595}}, {"key": "zhou2022teaching", "year": "2022", "title": "Teaching Algorithmic Reasoning Via In-context Learning", "topic_distr": {"0": 0.0012721435632556677, "1": 0.04646129533648491, "2": 0.0008785466779954731, "3": 0.7155981659889221, "4": 0.0006711032474413514, "5": 0.0006002525333315134, "6": 0.0005429335287772119, "7": 0.0004956071497872472, "8": 0.00045587000204250216, "9": 0.00042203202610835433, "10": 0.0003928703081328422, "11": 0.15935447812080383, "12": 0.00034516913001425564, "13": 0.04314850643277168, "14": 0.0003077972505707294, "15": 0.00029199017444625497, "16": 0.0002777273766696453, "17": 0.0002647930814418942, "18": 0.00025300990091636777, "19": 0.027965735644102097}}, {"key": "zhou2022unsupervised", "year": "2022", "title": "Unsupervised Vision-and-language Pre-training Via Retrieval-based Multi-granular Alignment", "topic_distr": {"0": 0.0014510025503113866, "1": 0.0011844263644888997, "2": 0.21220168471336365, "3": 0.0008670727838762105, "4": 0.0007647196180187166, "5": 0.0006839850684627891, "6": 0.0006186701357364655, "7": 0.000564742018468678, "8": 0.0005194616969674826, "9": 0.0004809034871868789, "10": 0.0004476738686207682, "11": 0.00041873971349559724, "12": 0.0003933185653295368, "13": 0.00037080736365169287, "14": 0.21621304750442505, "15": 0.00033272142172791064, "16": 0.00031646902789361775, "17": 0.0003017304406967014, "18": 0.5615927577018738, "19": 0.0002760207571554929}}, {"key": "zhou2023analyzing", "year": "2023", "title": "Analyzing And Mitigating Object Hallucination In Large Vision-language Models", "topic_distr": {"0": 0.3363921344280243, "1": 0.0010610973695293069, "2": 0.0008968645706772804, "3": 0.1519019603729248, "4": 0.0006850922363810241, "5": 0.000612764444667846, "6": 0.0005542505532503128, "7": 0.08759365975856781, "8": 0.0004653722862713039, "9": 0.00043082894990220666, "10": 0.00040105939842760563, "11": 0.0003751380427274853, "12": 0.00035236391704529524, "13": 0.0003321967087686062, "14": 0.00031421304447576404, "15": 0.05537225306034088, "16": 0.0002835164195857942, "17": 0.00027031247736886144, "18": 0.3614576458930969, "19": 0.00024727985146455467}}, {"key": "zhou2023chinese", "year": "2023", "title": "Chinese Intermediate English Learners Outdid Chatgpt In Deep Cohesion: Evidence From English Narrative Writing", "topic_distr": {"0": 0.25939109921455383, "1": 0.056527018547058105, "2": 0.14731954038143158, "3": 0.0008019259548746049, "4": 0.0007072617881931365, "5": 0.0006325934664346278, "6": 0.0005721859633922577, "7": 0.05568995699286461, "8": 0.00048043159767985344, "9": 0.27959826588630676, "10": 0.0004140375822316855, "11": 0.05927756056189537, "12": 0.00036376630305312574, "13": 0.00034294649958610535, "14": 0.03763950988650322, "15": 0.06787493824958801, "16": 0.03156595677137375, "17": 0.0002790597209241241, "18": 0.000266641698544845, "19": 0.0002552817459218204}}, {"key": "zhou2023ethical", "year": "2023", "title": "Ethical Chatgpt: Concerns, Challenges, And Commandments", "topic_distr": {"0": 0.20387443900108337, "1": 0.027917735278606415, "2": 0.07689868658781052, "3": 0.0010965613182634115, "4": 0.0009671203442849219, "5": 0.0008650181698612869, "6": 0.0007824162603355944, "7": 0.0007142146932892501, "8": 0.0006569498800672591, "9": 0.6476505994796753, "10": 0.0005661616451106966, "11": 0.0005295693408697844, "12": 0.034651756286621094, "13": 0.0004689505440182984, "14": 0.0004435636510606855, "15": 0.00042078422848135233, "16": 0.00040023025940172374, "17": 0.0003815907402895391, "18": 0.0003646101395133883, "19": 0.00034907637746073306}}, {"key": "zhou2023explicit", "year": "2023", "title": "Navgpt: Explicit Reasoning In Vision-and-language Navigation With Large Language Models", "topic_distr": {"0": 0.0009754364145919681, "1": 0.0007958690403029323, "2": 0.000672611640766263, "3": 0.2722083628177643, "4": 0.0005138060660101473, "5": 0.04370380938053131, "6": 0.0004156767681706697, "7": 0.00037944313953630626, "8": 0.0003490198578219861, "9": 0.0550895594060421, "10": 0.0003007864870596677, "11": 0.4188095033168793, "12": 0.03665260970592499, "13": 0.08389546722173691, "14": 0.00023565348237752914, "15": 0.00022355138207785785, "16": 0.032839786261320114, "17": 0.0002027289301622659, "18": 0.051550865173339844, "19": 0.0001854549191193655}}, {"key": "zhou2023less", "year": "2023", "title": "LIMA: Less Is More For Alignment", "topic_distr": {"0": 0.1706840991973877, "1": 0.09605707973241806, "2": 0.0008278259192593396, "3": 0.0007170132012106478, "4": 0.086346335709095, "5": 0.0005656107096001506, "6": 0.044303856790065765, "7": 0.041664715856313705, "8": 0.00042956083780154586, "9": 0.0003976756997872144, "10": 0.0003701969690155238, "11": 0.17292897403240204, "12": 0.0003252487222198397, "13": 0.17858588695526123, "14": 0.0002900336403399706, "15": 0.0002751388237811625, "16": 0.00026169916964136064, "17": 0.11688612401485443, "18": 0.00023840818903408945, "19": 0.08784449845552444}}, {"key": "zhou2023targeted", "year": "2023", "title": "Universalner: Targeted Distillation From Large Language Models For Open Named Entity Recognition", "topic_distr": {"0": 0.0009531360119581223, "1": 0.0007774921250529587, "2": 0.11000659316778183, "3": 0.16034363210201263, "4": 0.0005020563257858157, "5": 0.00044905213871970773, "6": 0.00040617142803967, "7": 0.00037076632725074887, "8": 0.0003410387726034969, "9": 0.08151667565107346, "10": 0.0002939083497039974, "11": 0.0002749123959802091, "12": 0.15747584402561188, "13": 0.2108859270811081, "14": 0.0002302647480973974, "15": 0.00021843939612153918, "16": 0.000207769320695661, "17": 0.2743758261203766, "18": 0.00018927804194390774, "19": 0.00018121408356819302}}, {"key": "zhou2023vision", "year": "2023", "title": "Vision Language Models In Autonomous Driving: A Survey And Outlook", "topic_distr": {"0": 0.0015622925711795688, "1": 0.0012732744216918945, "2": 0.001076302956789732, "3": 0.05344933271408081, "4": 0.000822177273221314, "5": 0.09756196290254593, "6": 0.000665154482703656, "7": 0.04214439168572426, "8": 0.0005584919126704335, "9": 0.1265827715396881, "10": 0.0004813102132175118, "11": 0.03546483442187309, "12": 0.4766600728034973, "13": 0.02646012045443058, "14": 0.0003770861658267677, "15": 0.0003577207389753312, "16": 0.00034024720662273467, "17": 0.0003244012186769396, "18": 0.1335413157939911, "19": 0.0002967598265968263}}, {"key": "zhu2018contextualized", "year": "2018", "title": "Sdnet: Contextualized Attention-based Deep Network For Conversational Question Answering", "topic_distr": {"0": 0.0016845067730173469, "1": 0.0013764095492661, "2": 0.48549017310142517, "3": 0.0010077515617012978, "4": 0.0008887872099876404, "5": 0.023539770394563675, "6": 0.09410262852907181, "7": 0.0006563644856214523, "8": 0.21091197431087494, "9": 0.0005589241627603769, "10": 0.13024911284446716, "11": 0.00048667509690858424, "12": 0.00045712970313616097, "13": 0.00043096631998196244, "14": 0.00040763572906143963, "15": 0.000386701402021572, "16": 0.00036781225935555995, "17": 0.0003506825305521488, "18": 0.0003350773185957223, "19": 0.04631089046597481}}, {"key": "zhu2018fine", "year": "2018", "title": "Lingke: A Fine-grained Multi-turn Chatbot For Customer Service", "topic_distr": {"0": 0.0024950008373707533, "1": 0.05060616880655289, "2": 0.001721931272186339, "3": 0.0014914103085175157, "4": 0.2736017405986786, "5": 0.05779474228620529, "6": 0.11151643842458725, "7": 0.0009713875479064882, "8": 0.3524027168750763, "9": 0.09645628929138184, "10": 0.0007700238493271172, "11": 0.0007202554843388498, "12": 0.0006765297148376703, "13": 0.0006378092220984399, "14": 0.0006032810197211802, "15": 0.0005722992937080562, "16": 0.0005443442496471107, "17": 0.04544695094227791, "18": 0.0004958981298841536, "19": 0.0004747709899675101}}, {"key": "zhu2018retrieval", "year": "2018", "title": "Retrieval-enhanced Adversarial Training For Neural Response Generation", "topic_distr": {"0": 0.0020782779902219772, "1": 0.2554052472114563, "2": 0.2631640136241913, "3": 0.0012427314650267363, "4": 0.0010960379149764776, "5": 0.0009803237626329064, "6": 0.4687787890434265, "7": 0.0008094183285720646, "8": 0.0007445201626978815, "9": 0.0006892564706504345, "10": 0.0006416299729607999, "11": 0.0006001600413583219, "12": 0.0005637251306325197, "13": 0.0005314608570188284, "14": 0.0005026899161748588, "15": 0.0004768740327563137, "16": 0.00045358025818131864, "17": 0.00043245614506304264, "18": 0.0004132120229769498, "19": 0.0003956076398026198}}, {"key": "zhu2019enhanced", "year": "2019", "title": "Freelb: Enhanced Adversarial Training For Natural Language Understanding", "topic_distr": {"0": 0.0017084818100556731, "1": 0.22276200354099274, "2": 0.39239931106567383, "3": 0.0010214608628302813, "4": 0.0009008818888105452, "5": 0.0008057727245613933, "6": 0.0007288283668458462, "7": 0.0006652979645878077, "8": 0.000611955183558166, "9": 0.0005665314383804798, "10": 0.20933809876441956, "11": 0.0004932989832013845, "12": 0.0004633514618035406, "13": 0.0004368319932837039, "14": 0.0004131838504690677, "15": 0.00039196459692902863, "16": 0.05696946755051613, "17": 0.05315893888473511, "18": 0.04349314793944359, "19": 0.01267120148986578}}, {"key": "zhu2019modeling", "year": "2019", "title": "Modeling Graph Structure In Transformer For Better Amr-to-text Generation", "topic_distr": {"0": 0.0015584973152726889, "1": 0.00127279048319906, "2": 0.16896764934062958, "3": 0.0009320224053226411, "4": 0.000822007074020803, "5": 0.0007352249231189489, "6": 0.0006650171126239002, "7": 0.0006070490344427526, "8": 0.0005583766032941639, "9": 0.0005169298383407295, "10": 0.1589072197675705, "11": 0.0004501091025304049, "12": 0.000422783603426069, "13": 0.00039858598029240966, "14": 0.05932561680674553, "15": 0.08148358762264252, "16": 0.4101455509662628, "17": 0.11162440478801727, "18": 0.00030990151572041214, "19": 0.00029669853392988443}}, {"key": "zhu2019text", "year": "2019", "title": "Text Infilling", "topic_distr": {"0": 0.0014353080186992884, "1": 0.11342670023441315, "2": 0.33091112971305847, "3": 0.0008571731741540134, "4": 0.000755990098696202, "5": 0.0006761764525435865, "6": 0.0006116072763688862, "7": 0.32310956716537476, "8": 0.0005135314422659576, "9": 0.0004754133988171816, "10": 0.10440687835216522, "11": 0.0004139592929277569, "12": 0.12019530683755875, "13": 0.00036657415330410004, "14": 0.0003467294736765325, "15": 0.0003289230226073414, "16": 0.0003128561656922102, "17": 0.00029828582773916423, "18": 0.00028501226915977895, "19": 0.0002728696563281119}}, {"key": "zhu2019vision", "year": "2019", "title": "Vision-language Navigation With Self-supervised Auxiliary Reasoning Tasks", "topic_distr": {"0": 0.0011041448451578617, "1": 0.0009012756636366248, "2": 0.18632592260837555, "3": 0.07633939385414124, "4": 0.0005820033838972449, "5": 0.0005205587367527187, "6": 0.00047084983089007437, "7": 0.00042980685248039663, "8": 0.000395345501601696, "9": 0.00036600008024834096, "10": 0.00034071007394231856, "11": 0.5171330571174622, "12": 0.00029934203485026956, "13": 0.0002822094829753041, "14": 0.00026693192194215953, "15": 0.00025322349392808974, "16": 0.12972252070903778, "17": 0.0002296372695127502, "18": 0.08382698893547058, "19": 0.00021007045870646834}}, {"key": "zhu2020enhance", "year": "2020", "title": "Enhance Multimodal Transformer With External Label And In-domain Pretrain: Hateful Meme Challenge Winning Solution", "topic_distr": {"0": 0.0027720904909074306, "1": 0.0022633480839431286, "2": 0.1717059463262558, "3": 0.0016571211162954569, "4": 0.0014615107793360949, "5": 0.0013072144938632846, "6": 0.0011823861859738827, "7": 0.0010793200926855206, "8": 0.0009927815990522504, "9": 0.12084812670946121, "10": 0.12509380280971527, "11": 0.0008002843242138624, "12": 0.21135295927524567, "13": 0.0007086773402988911, "14": 0.0006703126709908247, "15": 0.07231666892766953, "16": 0.09978951513767242, "17": 0.0005766593385487795, "18": 0.18289370834827423, "19": 0.0005275236326269805}}, {"key": "zhu2020going", "year": "2020", "title": "Babywalk: Going Farther In Vision-and-language Navigation By Taking Baby Steps", "topic_distr": {"0": 0.08110939711332321, "1": 0.0009698885260149837, "2": 0.0813274011015892, "3": 0.0007102013332769275, "4": 0.0006263675168156624, "5": 0.0005602389574050903, "6": 0.0005067408783361316, "7": 0.0004625693545676768, "8": 0.00042548112105578184, "9": 0.0003938988083973527, "10": 0.1080743744969368, "11": 0.6305060982704163, "12": 0.0003221596998628229, "13": 0.0003037212009076029, "14": 0.00028727907920256257, "15": 0.00027252573636360466, "16": 0.09243229776620865, "17": 0.00024714163737371564, "18": 0.00023614394012838602, "19": 0.00022608331346418709}}, {"key": "zhu2020gruen", "year": "2020", "title": "GRUEN For Evaluating Linguistic Quality Of Generated Text", "topic_distr": {"0": 0.21195226907730103, "1": 0.0014552474021911621, "2": 0.1882229894399643, "3": 0.0010653773788362741, "4": 0.15968488156795502, "5": 0.0008404196123592556, "6": 0.0007601666729897261, "7": 0.3012303411960602, "8": 0.0006382681895047426, "9": 0.000590891286265105, "10": 0.09832118451595306, "11": 0.0005145099712535739, "12": 0.00048327475087717175, "13": 0.0004556149651762098, "14": 0.00043095002183690667, "15": 0.000408818363212049, "16": 0.03188072890043259, "17": 0.00037073943531140685, "18": 0.0003542416961863637, "19": 0.0003391496720723808}}, {"key": "zhu2020incorporating", "year": "2020", "title": "Incorporating BERT Into Neural Machine Translation", "topic_distr": {"0": 0.0013860289473086596, "1": 0.0011315293377265334, "2": 0.2259242832660675, "3": 0.0008285511867143214, "4": 0.0007307470077648759, "5": 0.0006535992142744362, "6": 0.0005911859916523099, "7": 0.0005396535852923989, "8": 0.000496384862344712, "9": 0.000459539529401809, "10": 0.4747330844402313, "11": 0.00040013735997490585, "12": 0.0003758455568458885, "13": 0.0003543343918863684, "14": 0.2196018546819687, "15": 0.0003179404011461884, "16": 0.07064768671989441, "17": 0.0002883262059185654, "18": 0.0002754958113655448, "19": 0.0002637586439959705}}, {"key": "zhu2020modifying", "year": "2020", "title": "Modifying Memories In Transformer Models", "topic_distr": {"0": 0.16100050508975983, "1": 0.0011708205565810204, "2": 0.06052087992429733, "3": 0.0008571243961341679, "4": 0.0007559452787972987, "5": 0.01862020045518875, "6": 0.0006115718861110508, "7": 0.0005582625162787735, "8": 0.0005135017563588917, "9": 0.00047538592480123043, "10": 0.2099442034959793, "11": 0.00041393536957912147, "12": 0.12795007228851318, "13": 0.00036655296571552753, "14": 0.09151964634656906, "15": 0.0003289039887022227, "16": 0.2541738450527191, "17": 0.0484611801803112, "18": 0.00028499576728791, "19": 0.021472511813044548}}, {"key": "zhu2020reading", "year": "2020", "title": "DUMA: Reading Comprehension With Transposition Thinking", "topic_distr": {"0": 0.0016858852468430996, "1": 0.001376237953081727, "2": 0.6661485433578491, "3": 0.0010076600592583418, "4": 0.0008887122967280447, "5": 0.0007948864949867129, "6": 0.0007189816096797585, "7": 0.00065630953758955, "8": 0.2394200563430786, "9": 0.0005588773638010025, "10": 0.0005202598986215889, "11": 0.08316700905561447, "12": 0.00045709143159911036, "13": 0.0004309302312321961, "14": 0.0004076015902683139, "15": 0.00038666900945827365, "16": 0.0003677814675029367, "17": 0.000350653164787218, "18": 0.000335049262503162, "19": 0.0003207748814020306}}, {"key": "zhu2020vision", "year": "2020", "title": "Vision-dialog Navigation By Exploring Cross-modal Memory", "topic_distr": {"0": 0.0012109065428376198, "1": 0.0009886613115668297, "2": 0.1352863758802414, "3": 0.0007239331607706845, "4": 0.07235141843557358, "5": 0.022220760583877563, "6": 0.07994602620601654, "7": 0.00047151531907729805, "8": 0.0004337098216637969, "9": 0.0004015167069155723, "10": 0.0003737725783139467, "11": 0.3448132574558258, "12": 0.00032839018967933953, "13": 0.0003095950814895332, "14": 0.0002928349713329226, "15": 0.00027779629454016685, "16": 0.13266189396381378, "17": 0.00025192127213813365, "18": 0.2064252644777298, "19": 0.00023045569832902402}}, {"key": "zhu2021diagnosing", "year": "2021", "title": "Diagnosing Vision-and-language Navigation: What Really Matters", "topic_distr": {"0": 0.060633350163698196, "1": 0.0009700501104816794, "2": 0.19708839058876038, "3": 0.0007102274685166776, "4": 0.0006263883551582694, "5": 0.013030283153057098, "6": 0.0005067583988420665, "7": 0.000462585361674428, "8": 0.00042549584759399295, "9": 0.0003939124580938369, "10": 0.052158158272504807, "11": 0.34481900930404663, "12": 0.09458232671022415, "13": 0.0003037317073903978, "14": 0.02941136062145233, "15": 0.00027253516600467265, "16": 0.0002592226956039667, "17": 0.00024715016479603946, "18": 0.20287300646305084, "19": 0.00022609112784266472}}, {"key": "zhu2022prompt", "year": "2022", "title": "Prompt-aligned Gradient For Prompt Tuning", "topic_distr": {"0": 0.18672651052474976, "1": 0.026869961991906166, "2": 0.02977089025080204, "3": 0.0007687892066314816, "4": 0.0006780386320315301, "5": 0.0006064552580937743, "6": 0.0005485438741743565, "7": 0.04729367792606354, "8": 0.00046058077714405954, "9": 0.0004263930895831436, "10": 0.0003969300596509129, "11": 0.0003712755860760808, "12": 0.00034873594995588064, "13": 0.00032877636840566993, "14": 0.000310977891786024, "15": 0.0002950074558611959, "16": 0.0293667521327734, "17": 0.5348429083824158, "18": 0.13934406638145447, "19": 0.00024473381927236915}}, {"key": "zhu2023can", "year": "2023", "title": "Can Chatgpt Reproduce Human-generated Labels? A Study Of Social Computing Tasks", "topic_distr": {"0": 0.24936068058013916, "1": 0.24135419726371765, "2": 0.12256213277578354, "3": 0.0008571270736865699, "4": 0.000755948422010988, "5": 0.0006761402473784983, "6": 0.000611574505455792, "7": 0.000558264902792871, "8": 0.0005135039100423455, "9": 0.3495256304740906, "10": 0.0004425393999554217, "11": 0.0004139371158089489, "12": 0.000388807529816404, "13": 0.030134903267025948, "14": 0.00034671087632887065, "15": 0.00032890538568608463, "16": 0.0003128394018858671, "17": 0.0002982698497362435, "18": 0.00028499698964878917, "19": 0.00027285501710139215}}, {"key": "zhu2023chatgpt", "year": "2023", "title": "Chatgpt Asks, BLIP-2 Answers: Automatic Questioning Towards Enriched Visual Descriptions", "topic_distr": {"0": 0.10151799768209457, "1": 0.0009887292981147766, "2": 0.0008358798222616315, "3": 0.16224311292171478, "4": 0.05943414941430092, "5": 0.0005711132544092834, "6": 0.0005165768088772893, "7": 0.0004715479153674096, "8": 0.13004979491233826, "9": 0.13906581699848175, "10": 0.0003737984225153923, "11": 0.0003496389836072922, "12": 0.0003284128906670958, "13": 0.0003096164728049189, "14": 0.00029285522759892046, "15": 0.0002778155030682683, "16": 0.030240878462791443, "17": 0.00025193867622874677, "18": 0.3716498613357544, "19": 0.00023047163267619908}}, {"key": "zhu2023collaborative", "year": "2023", "title": "Collaborative Large Language Model For Recommender Systems", "topic_distr": {"0": 0.014168402180075645, "1": 0.00083485635695979, "2": 0.08580008149147034, "3": 0.10682209581136703, "4": 0.30297452211380005, "5": 0.000482199335237965, "6": 0.0004361533501651138, "7": 0.06253442168235779, "8": 0.00036621285835281014, "9": 0.00033902988070622087, "10": 0.17826327681541443, "11": 0.00029520533280447125, "12": 0.00027728380518965423, "13": 0.00026141374837607145, "14": 0.0002472619526088238, "15": 0.09503286331892014, "16": 0.023724783211946487, "17": 0.06888135522603989, "18": 0.00020324978686403483, "19": 0.05805531516671181}}, {"key": "zhu2023ghost", "year": "2023", "title": "Ghost In The Minecraft: Generally Capable Agents For Open-world Environments Via Large Language Models With Text-based Knowledge And Memory", "topic_distr": {"0": 0.0008968664915300906, "1": 0.0007330379448831081, "2": 0.0006194041925482452, "3": 0.2856368124485016, "4": 0.06521955132484436, "5": 0.00042320648208260536, "6": 0.00038279386353679, "7": 0.000349426525644958, "8": 0.000321409956086427, "9": 0.12077534943819046, "10": 0.00027699218480847776, "11": 0.3569051921367645, "12": 0.055570051074028015, "13": 0.055368971079587936, "14": 0.0002170116495108232, "15": 0.00020586691971402615, "16": 0.055562254041433334, "17": 0.00018669167184270918, "18": 0.00017838396888691932, "19": 0.00017078414384741336}}, {"key": "zhu2023minigpt", "year": "2023", "title": "Minigpt-4: Enhancing Vision-language Understanding With Advanced Large Language Models", "topic_distr": {"0": 0.09838217496871948, "1": 0.05225948989391327, "2": 0.0007552718743681908, "3": 0.28736451268196106, "4": 0.0005769527051597834, "5": 0.0005160409491509199, "6": 0.00046676339115947485, "7": 0.07958166301250458, "8": 0.00039191433461382985, "9": 0.08145400881767273, "10": 0.00033775309566408396, "11": 0.00031592336017638445, "12": 0.0002967440814245492, "13": 0.00027976022101938725, "14": 0.0002646152279339731, "15": 0.00025102580548264086, "16": 0.00023876399791333824, "17": 0.00022764428285881877, "18": 0.39583075046539307, "19": 0.00020824729290325195}}, {"key": "zhu2023multilingual", "year": "2023", "title": "Multilingual Machine Translation With Large Language Models: Empirical Results And Analysis", "topic_distr": {"0": 0.001248127780854702, "1": 0.001018385635688901, "2": 0.0008609452052041888, "3": 0.5933582186698914, "4": 0.0006576785235665739, "5": 0.0005882440018467605, "6": 0.0005320717464201152, "7": 0.00048569217324256897, "8": 0.028763825073838234, "9": 0.07994192838668823, "10": 0.0003850106440950185, "11": 0.00036012654891237617, "12": 0.0003382637514732778, "13": 0.0003189035633113235, "14": 0.2898394763469696, "15": 0.00028614868642762303, "16": 0.00027217125170864165, "17": 0.0002594956895336509, "18": 0.000247948250034824, "19": 0.00023738472373224795}}, {"key": "zhu2023pre", "year": "2023", "title": "3d-vista: Pre-trained Transformer For 3D Vision And Text Alignment", "topic_distr": {"0": 0.001371045713312924, "1": 0.14212505519390106, "2": 0.000946163956541568, "3": 0.0008195059490390122, "4": 0.024358687922358513, "5": 0.0006464609177783132, "6": 0.0005847293068654835, "7": 0.0005337597103789449, "8": 0.0004909635754302144, "9": 0.0004545206611510366, "10": 0.17931914329528809, "11": 0.04390715807676315, "12": 0.0003717407525982708, "13": 0.04577748104929924, "14": 0.0003314919304102659, "15": 0.000314467994030565, "16": 0.0002991072542499751, "17": 0.0002851772296708077, "18": 0.5568024516105652, "19": 0.0002608780050650239}}, {"key": "zhu2023survey", "year": "2023", "title": "A Survey On Model Compression For Large Language Models", "topic_distr": {"0": 0.0016410734970122576, "1": 0.001339975860901177, "2": 0.04301053658127785, "3": 0.0009811990894377232, "4": 0.0008653748081997037, "5": 0.0007740138098597527, "6": 0.0007001020712777972, "7": 0.0006390757043845952, "8": 0.0005878354422748089, "9": 0.20090347528457642, "10": 0.0005065985606051981, "11": 0.0004738559655379504, "12": 0.40376803278923035, "13": 0.32127106189727783, "14": 0.0003968985110986978, "15": 0.020802710205316544, "16": 0.00035812403075397015, "17": 0.0003414454695302993, "18": 0.0003262513200752437, "19": 0.00031235176720656455}}, {"key": "zhuang2023dataset", "year": "2023", "title": "Toolqa: A Dataset For LLM Question Answering With External Tools", "topic_distr": {"0": 0.02325408346951008, "1": 0.0008936568046920002, "2": 0.0007552023162133992, "3": 0.45483189821243286, "4": 0.0005768960108980536, "5": 0.0005159906577318907, "6": 0.00046671793097630143, "7": 0.00042603511246852577, "8": 0.10403259843587875, "9": 0.12852758169174194, "10": 0.00033772020833566785, "11": 0.0003158925974275917, "12": 0.1439434438943863, "13": 0.00027973297983407974, "14": 0.00026458947104401886, "15": 0.02058549039065838, "16": 0.11933913826942444, "17": 0.00022762210574001074, "18": 0.00021749302686657757, "19": 0.0002082270075334236}}, {"key": "zhuo2023red", "year": "2023", "title": "Red Teaming Chatgpt Via Jailbreaking: Bias, Robustness, Reliability And Toxicity", "topic_distr": {"0": 0.2572629451751709, "1": 0.05355551838874817, "2": 0.0005978934350423515, "3": 0.1869317889213562, "4": 0.0004567197465803474, "5": 0.0004085020045749843, "6": 0.00036949352943338454, "7": 0.020885849371552467, "8": 0.0003102424379903823, "9": 0.33545002341270447, "10": 0.0002673679846338928, "11": 0.00025008738157339394, "12": 0.14191769063472748, "13": 0.0002214603591710329, "14": 0.00020947148732375354, "15": 0.00019871398399118334, "16": 0.00018900743452832103, "17": 0.00018020498100668192, "18": 0.00017218594439327717, "19": 0.00016485017840750515}}, {"key": "ziegler2019encoder", "year": "2019", "title": "Encoder-agnostic Adaptation For Conditional Language Generation", "topic_distr": {"0": 0.0016852610278874636, "1": 0.001376342959702015, "2": 0.19174139201641083, "3": 0.0010076418984681368, "4": 0.0008886955329217017, "5": 0.0007948724669404328, "6": 0.0007189688622020185, "7": 0.3078913688659668, "8": 0.0006036767736077309, "9": 0.0005588674684986472, "10": 0.047335684299468994, "11": 0.00048662570770829916, "12": 0.00045708331163041294, "13": 0.00043092257692478597, "14": 0.00040759434341453016, "15": 0.0003866621700581163, "16": 0.0003677749482449144, "17": 0.352925568819046, "18": 0.00033504332532174885, "19": 0.08959993720054626}}, {"key": "ziegler2019fine", "year": "2019", "title": "Fine-tuning Language Models From Human Preferences", "topic_distr": {"0": 0.225728839635849, "1": 0.025716783478856087, "2": 0.0726633369922638, "3": 0.0008877516956999898, "4": 0.0007829621899873018, "5": 0.0007003016071394086, "6": 0.0006334286299534142, "7": 0.09537661820650101, "8": 0.0005318535841070116, "9": 0.0004923755768686533, "10": 0.00045835322816856205, "11": 0.4254763722419739, "12": 0.00040270129102282226, "13": 0.0003796530654653907, "14": 0.00035910034785047174, "15": 0.12966030836105347, "16": 0.00032401850330643356, "17": 0.0003089283127337694, "18": 0.0002951811475213617, "19": 0.01882118545472622}}, {"key": "ziems2023can", "year": "2023", "title": "Can Large Language Models Transform Computational Social Science?", "topic_distr": {"0": 0.21150852739810944, "1": 0.12954862415790558, "2": 0.000819974928162992, "3": 0.3916061520576477, "4": 0.0006263769464567304, "5": 0.055147942155599594, "6": 0.0005067485617473722, "7": 0.07255809009075165, "8": 0.00042548764031380415, "9": 0.13438807427883148, "10": 0.00036668666871264577, "11": 0.0003429868957027793, "12": 0.0003221646184101701, "13": 0.0003037258284166455, "14": 0.00028728347388096154, "15": 0.00027252989821136, "16": 0.00025921768974512815, "17": 0.00024714539176784456, "18": 0.00023614754900336266, "19": 0.0002260867622680962}}, {"key": "ziems2023large", "year": "2023", "title": "Large Language Models Are Built-in Autoregressive Search Engines", "topic_distr": {"0": 0.0011442757677286863, "1": 0.0009344365098513663, "2": 0.14807599782943726, "3": 0.3406272232532501, "4": 0.0006033880054019392, "5": 0.0005396854830905795, "6": 0.00048815004993230104, "7": 0.00044559905654750764, "8": 0.3434421718120575, "9": 0.00037944785435684025, "10": 0.06568696349859238, "11": 0.0003303986741229892, "12": 0.00031034063431434333, "13": 0.09551963210105896, "14": 0.00027673967997543514, "15": 0.0002625275810714811, "16": 0.0002497039386071265, "17": 0.00023807473189663142, "18": 0.00022748051560483873, "19": 0.0002177889837184921}}, {"key": "zoph2022st", "year": "2022", "title": "St-moe: Designing Stable And Transferable Sparse Expert Models", "topic_distr": {"0": 0.0018613123102113605, "1": 0.03191259875893593, "2": 0.264806866645813, "3": 0.0011130395578220487, "4": 0.0009816482197493315, "5": 0.0008780111093074083, "6": 0.0200596135109663, "7": 0.056624311953783035, "8": 0.05693938583135605, "9": 0.0006173215224407613, "10": 0.0740862786769867, "11": 0.1092275083065033, "12": 0.07783100754022598, "13": 0.30066579580307007, "14": 0.00045022618724033237, "15": 0.00042710459092631936, "16": 0.0004062419175170362, "17": 0.0003873224195558578, "18": 0.00037008675280958414, "19": 0.00035431963624432683}}, {"key": "zou2021controllable", "year": "2021", "title": "Controllable Generation From Pre-trained Language Models Via Inverse Prompting", "topic_distr": {"0": 0.0014676600694656372, "1": 0.001198159996420145, "2": 0.0010128712747246027, "3": 0.3797993063926697, "4": 0.0007737224805168808, "5": 0.0006920378073118627, "6": 0.03293561935424805, "7": 0.29354310035705566, "8": 0.052262939512729645, "9": 0.00048656531726010144, "10": 0.00045294445590116084, "11": 0.0004236696695443243, "12": 0.00039794924668967724, "13": 0.00037517299642786384, "14": 0.00035486280103214085, "15": 0.11649069935083389, "16": 0.00032019492937251925, "17": 0.11644158512353897, "18": 0.000291697884676978, "19": 0.0002792704326566309}}, {"key": "zou2023universal", "year": "2023", "title": "Universal And Transferable Adversarial Attacks On Aligned Language Models", "topic_distr": {"0": 0.0009754791972227395, "1": 0.2804955542087555, "2": 0.0006726767169311643, "3": 0.26490509510040283, "4": 0.018015030771493912, "5": 0.0004595921200234443, "6": 0.04452478885650635, "7": 0.1529419869184494, "8": 0.08897844702005386, "9": 0.04094575718045235, "10": 0.0003008068015333265, "11": 0.0002813649771269411, "12": 0.00026428367709740996, "13": 0.0002491576597094536, "14": 0.00023566937306895852, "15": 0.00022356647241394967, "16": 0.0002126459585269913, "17": 0.10493890941143036, "18": 0.000193720668903552, "19": 0.0001854674337664619}}, {"key": "zuccon2023chatgpt", "year": "2023", "title": "Chatgpt Hallucinates When Attributing Answers", "topic_distr": {"0": 0.4951011538505554, "1": 0.0009987311204895377, "2": 0.0008440374513156712, "3": 0.0007310676737688482, "4": 0.0006447705673053861, "5": 0.0005767002003267407, "6": 0.000521630106959492, "7": 0.0004761607269756496, "8": 0.24695292115211487, "9": 0.15692846477031708, "10": 0.0003774550277739763, "11": 0.0003530592657625675, "12": 0.00033162551699206233, "13": 0.00031264525023289025, "14": 0.0002957200340460986, "15": 0.00028053318965248764, "16": 0.0002668300294317305, "17": 0.09353064000606537, "18": 0.00024308240972459316, "19": 0.00023272617545444518}}, {"key": "zuccon2023dr", "year": "2023", "title": "Dr Chatgpt, Tell Me What I Want To Hear: How Prompt Knowledge Impacts Health Answer Correctness", "topic_distr": {"0": 0.001300997450016439, "1": 0.0964924767613411, "2": 0.0008968375623226166, "3": 0.17786303162574768, "4": 0.0006850873469375074, "5": 0.0006127593806013465, "6": 0.0005542460130527616, "7": 0.0005059335962869227, "8": 0.17718882858753204, "9": 0.18082475662231445, "10": 0.000401056109694764, "11": 0.0003751349577214569, "12": 0.00035236103576608, "13": 0.00033219397300854325, "14": 0.00031421048333868384, "15": 0.00029807406826876104, "16": 0.22409282624721527, "17": 0.13640360534191132, "18": 0.00025828159414231777, "19": 0.0002472778141964227}}, {"key": "zuo2021taming", "year": "2021", "title": "Taming Sparsely Activated Transformer With Stochastic Experts", "topic_distr": {"0": 0.0012725371634587646, "1": 0.0010393272386863828, "2": 0.32706448435783386, "3": 0.0007608610903844237, "4": 0.0006710479501634836, "5": 0.0006002028821967542, "6": 0.0005428885924629867, "7": 0.0004955661133863032, "8": 0.00045583228347823024, "9": 0.0004219970724079758, "10": 0.08493790775537491, "11": 0.0003674478211905807, "12": 0.03630352020263672, "13": 0.38869529962539673, "14": 0.1550414264202118, "15": 0.0002919660182669759, "16": 0.0002777043846435845, "17": 0.00026477116625756025, "18": 0.0002529889461584389, "19": 0.00024221067724283785}}]}
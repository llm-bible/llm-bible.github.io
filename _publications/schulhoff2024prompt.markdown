---
layout: publication
title: 'The Prompt Report: A Systematic Survey Of Prompt Engineering Techniques'
authors: Sander Schulhoff, Michael Ilie, Nishant Balepur, Konstantine Kahadze, Amanda Liu, Chenglei Si, Yinheng Li, Aayush Gupta, Hyojung Han, Sevien Schulhoff, Pranav Sandeep Dulepet, Saurav Vidyadhara, Dayeon Ki, Sweta Agrawal, Chau Pham, Gerson Kroiz, Feileen Li, Hudson Tao, Ashay Srivastava, Hevander Da Costa, Saloni Gupta, Megan L. Rogers, Inna Goncearenco, Giuseppe Sarli, Igor Galynker, Denis Peskoff, Marine Carpuat, Jules White, Shyamal Anadkat, Alexander Hoyle, Philip Resnik
conference: "Arxiv"
year: 2024
bibkey: schulhoff2024prompt
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2406.06608'}
tags: ['RAG', 'GPT', 'Applications', 'Model Architecture', 'Prompting', 'Survey Paper']
---
Generative Artificial Intelligence (GenAI) systems are increasingly being
deployed across diverse industries and research domains. Developers and
end-users interact with these systems through the use of prompting and prompt
engineering. Although prompt engineering is a widely adopted and extensively
researched area, it suffers from conflicting terminology and a fragmented
ontological understanding of what constitutes an effective prompt due to its
relatively recent emergence. We establish a structured understanding of prompt
engineering by assembling a taxonomy of prompting techniques and analyzing
their applications. We present a detailed vocabulary of 33 vocabulary terms, a
taxonomy of 58 LLM prompting techniques, and 40 techniques for other
modalities. Additionally, we provide best practices and guidelines for prompt
engineering, including advice for prompting state-of-the-art (SOTA) LLMs such
as ChatGPT. We further present a meta-analysis of the entire literature on
natural language prefix-prompting. As a culmination of these efforts, this
paper presents the most comprehensive survey on prompt engineering to date.

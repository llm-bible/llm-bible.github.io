---
layout: publication
title: 'Key-element-informed Sllm Tuning For Document Summarization'
authors: Sangwon Ryu, Heejin Do, Yunsu Kim, Gary Geunbae Lee, Jungseul Ok
conference: "Arxiv"
year: 2024
bibkey: ryu2024key
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2406.04625'}
tags: ['Applications']
---
Remarkable advances in large language models (LLMs) have enabled high-quality
text summarization. However, this capability is currently accessible only
through LLMs of substantial size or proprietary LLMs with usage fees. In
response, smaller-scale LLMs (sLLMs) of easy accessibility and low costs have
been extensively studied, yet they often suffer from missing key information
and entities, i.e., low relevance, in particular, when input documents are
long. We hence propose a key-element-informed instruction tuning for
summarization, so-called KEITSum, which identifies key elements in documents
and instructs sLLM to generate summaries capturing these key elements.
Experimental results on dialogue and news datasets demonstrate that sLLM with
KEITSum indeed provides high-quality summarization with higher relevance and
less hallucinations, competitive to proprietary LLM.

---
layout: publication
title: 'F\`ux\`i: A Benchmark For Evaluating Language Models On Ancient Chinese Text Understanding And Generation'
authors: Shangqing Zhao, Yuhao Zhou, Yupei Ren, Zhe Chen, Chenghao Jia, Fang Zhe, Zhaogaung Long, Shu Liu, Man Lan
conference: "Arxiv"
year: 2025
bibkey: zhao2025benchmark
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2503.15837'}
tags: ['Language Modeling', 'RAG', 'Applications', 'Tools', 'Reinforcement Learning']
---
Ancient Chinese text processing presents unique challenges for large language
models (LLMs) due to its distinct linguistic features, complex structural
constraints, and rich cultural context. While existing benchmarks have
primarily focused on evaluating comprehension through multiple-choice
questions, there remains a critical gap in assessing models' generative
capabilities in classical Chinese. We introduce F\`ux\`i, a comprehensive
benchmark that evaluates both understanding and generation capabilities across
21 diverse tasks. Our benchmark distinguishes itself through three key
contributions: (1) balanced coverage of both comprehension and generation
tasks, including novel tasks like poetry composition and couplet completion,
(2) specialized evaluation metrics designed specifically for classical Chinese
text generation, combining rule-based verification with fine-tuned LLM
evaluators, and (3) a systematic assessment framework that considers both
linguistic accuracy and cultural authenticity. Through extensive evaluation of
state-of-the-art LLMs, we reveal significant performance gaps between
understanding and generation tasks, with models achieving promising results in
comprehension but struggling considerably in generation tasks, particularly
those requiring deep cultural knowledge and adherence to classical formats. Our
findings highlight the current limitations in ancient Chinese text processing
and provide insights for future model development. The benchmark, evaluation
toolkit, and baseline results are publicly available to facilitate research in
this domain.

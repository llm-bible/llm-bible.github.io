---
layout: publication
title: Societal Biases In Language Generation Progress And Challenges
authors: Sheng Emily, Chang Kai-wei, Natarajan Premkumar, Peng Nanyun
conference: "Arxiv"
year: 2021
bibkey: sheng2021societal
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2105.04054"}
tags: ['Agentic', 'Applications', 'Attention Mechanism', 'Bias Mitigation', 'Ethics And Bias', 'Fairness', 'Model Architecture', 'Survey Paper', 'Tools', 'Training Techniques']
---
Technology for language generation has advanced rapidly spurred by advancements in pre45;training large models on massive amounts of data and the need for intelligent agents to communicate in a natural manner. While techniques can effectively generate fluent text they can also produce undesirable societal biases that can have a disproportionately negative impact on marginalized populations. Language generation presents unique challenges for biases in terms of direct user interaction and the structure of decoding techniques. To better understand these challenges we present a survey on societal biases in language generation focusing on how data and techniques contribute to biases and progress towards reducing biases. Motivated by a lack of studies on biases from decoding techniques we also conduct experiments to quantify the effects of these techniques. By further discussing general trends and open challenges we call to attention promising directions for research and the importance of fairness and inclusivity considerations for language generation applications.

---
layout: publication
title: 'Zno-eval: Benchmarking Reasoning Capabilities Of Large Language Models In Ukrainian'
authors: Mykyta Syromiatnikov, Victoria Ruvinskaya, Anastasiya Troynina
conference: "X International conference Informatics. Culture. Technology. (2024) 185-191"
year: 2025
bibkey: syromiatnikov2025zno
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2501.06715"}
tags: ['Security', 'Model Architecture', 'GPT', 'Reinforcement Learning']
---
As the usage of large language models for problems outside of simple text
understanding or generation increases, assessing their abilities and
limitations becomes crucial. While significant progress has been made in this
area over the last few years, most research has focused on benchmarking
English, leaving other languages underexplored. This makes evaluating the
reasoning and robustness level of language models in Ukrainian particularly
challenging. The purpose of this work is to establish a comprehensive benchmark
for the reasoning capabilities evaluation of large language models in the
Ukrainian language. This paper presents the ZNO-Eval benchmark based on real
exam tasks from Ukraine's standardized educational testing system: the External
Independent Evaluation and the National Multi-subject Test. With single-answer
options, multiple-choice, matching, and open-ended questions from diverse
subjects, including Ukrainian language, mathematics, history, and geography,
this dataset paves the way toward a thorough analysis of reasoning capabilities
across different domains and complexities. Evaluation of several well-known
language models, such as GPT-3.5-Turbo, GPT-4o, GPT-4-Turbo, Mistral Large,
Claude 3 Opus, and Gemini-1.5 Pro on this benchmark demonstrated the
superiority of GPT-4o in both common knowledge reasoning and intricate language
tasks. At the same time, Gemini Pro and GPT-4 Turbo excelled in the arithmetic
domain, leading in single-answer and open-ended math problems. While all models
were close to max performance in text-only common knowledge tasks like history
and geography, there still is a gap for Ukrainian language and math, thus
highlighting the importance of developing specialized language benchmarks for
more accurate assessments of model capabilities and limitations across
different languages and contexts.

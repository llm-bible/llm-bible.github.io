---
layout: publication
title: Is GPT45;4 Alone Sufficient For Automated Essay Scoring A Comparative Judgment Approach Based On Rater Cognition
authors: Kim Seungju, Jo Meounggun
conference: "Arxiv"
year: 2024
bibkey: kim2024is
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.05733"}
tags: ['GPT', 'Model Architecture', 'Prompting', 'Reinforcement Learning']
---
Large Language Models (LLMs) have shown promise in Automated Essay Scoring (AES) but their zero45;shot and few45;shot performance often falls short compared to state45;of45;the45;art models and human raters. However fine45;tuning LLMs for each specific task is impractical due to the variety of essay prompts and rubrics used in real45;world educational contexts. This study proposes a novel approach combining LLMs and Comparative Judgment (CJ) for AES using zero45;shot prompting to choose between two essays. We demonstrate that a CJ method surpasses traditional rubric45;based scoring in essay scoring using LLMs.

---
layout: publication
title: Safurai 001 New Qualitative Approach For Code LLM Evaluation
authors: Cifarelli Davide, Boiardi Leonardo, Puppo Alessandro
conference: "Arxiv"
year: 2023
bibkey: cifarelli2023safurai
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.11385"}
tags: ['GPT', 'Model Architecture', 'Prompting', 'Tools']
---
This paper presents Safurai45;001 a new Large Language Model (LLM) with significant potential in the domain of coding assistance. Driven by recent advancements in coding LLMs Safurai45;001 competes in performance with the latest models like WizardCoder Xu et al. 2023 PanguCoder Shen et al. 2023 and Phi45;1 Gunasekar et al. 2023 but aims to deliver a more conversational interaction. By capitalizing on the progress in data engineering (including latest techniques of data transformation and prompt engineering) and instruction tuning this new model promises to stand toe45;to45;toe with recent closed and open source developments. Recognizing the need for an efficacious evaluation metric for coding LLMs this paper also introduces GPT445;based MultiParameters an evaluation benchmark that harnesses varied parameters to present a comprehensive insight into the models functioning and performance. Our assessment shows that Safurai45;001 can outperform GPT45;3.5 by 1.5837; and WizardCoder by 18.7837; in the Code Readability parameter and more.

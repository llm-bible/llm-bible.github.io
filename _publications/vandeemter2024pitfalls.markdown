---
layout: publication
title: 'The Pitfalls Of Defining Hallucination'
authors: Van Deemter Kees
conference: "Arxiv"
year: 2024
bibkey: vandeemter2024pitfalls
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.07897"}
tags: ['Ethics And Bias']
---
Despite impressive advances in Natural Language Generation (NLG) and Large Language Models (LLMs) researchers are still unclear about important aspects of NLG evaluation. To substantiate this claim I examine current classifications of hallucination and omission in Data-text NLG and I propose a logic-based synthesis of these classfications. I conclude by highlighting some remaining limitations of all current thinking about hallucination and by discussing implications for LLMs.

---
layout: publication
title: 'A Computational Framework For Behavioral Assessment Of LLM Therapists'
authors: Yu Ying Chiu, Ashish Sharma, Inna Wanyin Lin, Tim Althoff
conference: "Arxiv"
year: 2024
bibkey: chiu2024computational
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.00820"}
tags: ['Tools', 'GPT', 'Model Architecture', 'Prompting', 'In-Context Learning']
---
The emergence of large language models (LLMs) like ChatGPT has increased
interest in their use as therapists to address mental health challenges and the
widespread lack of access to care. However, experts have emphasized the
critical need for systematic evaluation of LLM-based mental health
interventions to accurately assess their capabilities and limitations. Here, we
propose BOLT, a proof-of-concept computational framework to systematically
assess the conversational behavior of LLM therapists. We quantitatively measure
LLM behavior across 13 psychotherapeutic approaches with in-context learning
methods. Then, we compare the behavior of LLMs against high- and low-quality
human therapy. Our analysis based on Motivational Interviewing therapy reveals
that LLMs often resemble behaviors more commonly exhibited in low-quality
therapy rather than high-quality therapy, such as offering a higher degree of
problem-solving advice when clients share emotions. However, unlike low-quality
therapy, LLMs reflect significantly more upon clients' needs and strengths. Our
findings caution that LLM therapists still require further research for
consistent, high-quality care.

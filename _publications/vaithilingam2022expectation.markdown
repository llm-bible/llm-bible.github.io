---
layout: publication
title: "Expectation vs. Experience: Evaluating the Usability of Code Generation Tools Powered by Large Language Models"
authors: Priyan Vaithilingam, Tianyi Zhang, Elena Glassman
conference: CHI
year: 2022
additional_links:
   - {name: "Preprint", url: "https://tianyi-zhang.github.io/files/chi2022-lbw-copilot.pdf"}
tags: ["human evaluation", "code generation", "language model"]
---
Recent advances in Large Language Models (LLM) have made automatic code generation possible for real-world programming tasks in
general-purpose programming languages such as Python. However,
there are few human studies on the usability of these tools and how
they fit the programming workflow. In this work, we conducted
a within-subjects user study with 24 participants to understand
how programmers use and perceive Copilot, a LLM-based code
generation tool. We found that, while Copilot did not necessarily
improve the task completion time or success rate, most participants preferred to use Copilot in daily programming tasks, since
Copilot often provided a useful starting point and saved the effort
of searching online. However, participants did face difficulties in
understanding, editing, and debugging code snippets generated
by Copilot, which significantly hindered their task-solving effectiveness. Finally, we highlighted several promising directions for
improving the design of Copilot based on our observations and
participantsâ€™ feedback.

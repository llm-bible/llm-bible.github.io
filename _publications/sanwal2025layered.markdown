---
layout: publication
title: 'Layered Chain-of-thought Prompting For Multi-agent LLM Systems: A Comprehensive Approach To Explainable Large Language Models'
authors: Manish Sanwal
conference: "Arxiv"
year: 2025
bibkey: sanwal2025layered
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2501.18645"}
tags: ['Agentic', 'Tools', 'Ethics and Bias', 'Interpretability and Explainability', 'RAG', 'Interpretability', 'Prompting', 'Arxiv']
---
Large Language Models (LLMs) leverage chain-of-thought (CoT) prompting to
provide step-by-step rationales, improving performance on complex tasks.
Despite its benefits, vanilla CoT often fails to fully verify intermediate
inferences and can produce misleading explanations. In this work, we propose
Layered Chain-of-Thought (Layered-CoT) Prompting, a novel framework that
systematically segments the reasoning process into multiple layers, each
subjected to external checks and optional user feedback. We expand on the key
concepts, present three scenarios -- medical triage, financial risk assessment,
and agile engineering -- and demonstrate how Layered-CoT surpasses vanilla CoT
in terms of transparency, correctness, and user engagement. By integrating
references from recent arXiv papers on interactive explainability, multi-agent
frameworks, and agent-based collaboration, we illustrate how Layered-CoT paves
the way for more reliable and grounded explanations in high-stakes domains.

---
layout: publication
title: Logic Agent Enhancing Validity with Logic Rule Invocation
authors: Liu Hanmeng, Teng Zhiyang, Zhang Chaoli, Zhang Yue
conference: "Arxiv"
year: 2024
bibkey: liu2024logic
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.18130"}
tags: ['Agentic', 'Applications', 'Interpretability And Explainability', 'Prompting', 'RAG', 'Tools']
---
Chain-of-Thought (CoT) prompting has emerged as a pivotal technique for augmenting the inferential capabilities of language models during reasoning tasks. Despite its advancements CoT often grapples with challenges in validating reasoning validity and ensuring informativeness. Addressing these limitations this paper introduces the Logic Agent (LA) an agent-based framework aimed at enhancing the validity of reasoning processes in Large Language Models (LLMs) through strategic logic rule invocation. Unlike conventional approaches LA transforms LLMs into logic agents that dynamically apply propositional logic rules initiating the reasoning process by converting natural language inputs into structured logic forms. The logic agent leverages a comprehensive set of predefined functions to systematically navigate the reasoning process. This methodology not only promotes the structured and coherent generation of reasoning constructs but also significantly improves their interpretability and logical coherence. Through extensive experimentation we demonstrate LAs capacity to scale effectively across various model sizes markedly improving the precision of complex reasoning across diverse tasks.

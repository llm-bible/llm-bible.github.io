---
layout: publication
title: GPT45;3.5 GPT45;4 Or BARD Evaluating Llms Reasoning Ability In Zero45;shot Setting And Performance Boosting Through Prompts
authors: Espejel Jessica LÃ³pez, Ettifouri El Hassane, Alassan Mahaman Sanoussi Yahaya, Chouham El Mehdi, Dahhane Walid
conference: "Arxiv"
year: 2023
bibkey: espejel2023gpt
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2305.12477"}
tags: ['Efficiency And Optimization', 'GPT', 'Model Architecture', 'Prompting', 'Reinforcement Learning']
---
Large Language Models (LLMs) have exhibited remarkable performance on various Natural Language Processing (NLP) tasks. However there is a current hot debate regarding their reasoning capacity. In this paper we examine the performance of GPT45;3.5 GPT45;4 and BARD models by performing a thorough technical evaluation on different reasoning tasks across eleven distinct datasets. Our paper provides empirical evidence showcasing the superior performance of ChatGPT45;4 in comparison to both ChatGPT45;3.5 and BARD in zero45;shot setting throughout almost all evaluated tasks. While the superiority of GPT45;4 compared to GPT45;3.5 might be explained by its larger size and NLP efficiency this was not evident for BARD. We also demonstrate that the three models show limited proficiency in Inductive Mathematical and Multi45;hop Reasoning Tasks. To bolster our findings we present a detailed and comprehensive analysis of the results from these three models. Furthermore we propose a set of engineered prompts that enhances the zero45;shot setting performance of all three models.

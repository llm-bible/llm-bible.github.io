---
layout: publication
title: Enhancing Creativity In Large Language Models Through Associative Thinking Strategies
authors: Mehrotra Pronita, Parab Aishni, Gulwani Sumit
conference: "Arxiv"
year: 2024
bibkey: mehrotra2024enhancing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.06715"}
tags: ['GPT', 'Model Architecture', 'Pretraining Methods', 'Prompting', 'RAG']
---
This paper explores the enhancement of creativity in Large Language Models (LLMs) like vGPT45;4 through associative thinking a cognitive process where creative ideas emerge from linking seemingly unrelated concepts. Associative thinking strategies have been found to effectively help humans boost creativity. However whether the same strategies can help LLMs become more creative remains under45;explored. In this work we investigate whether prompting LLMs to connect disparate concepts can augment their creative outputs. Focusing on three domains 45;45; Product Design Storytelling and Marketing 45;45; we introduce creativity tasks designed to assess vGPT45;4s ability to generate original and useful content. By challenging the models to form novel associations we evaluate the potential of associative thinking to enhance the creative capabilities of LLMs. Our findings show that leveraging associative thinking techniques can significantly improve the originality of vGPT45;4s responses.

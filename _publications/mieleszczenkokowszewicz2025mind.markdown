---
layout: publication
title: 'Mind What You Ask For: Emotional And Rational Faces Of Persuasion By Large Language Models'
authors: Wiktoria Mieleszczenko-kowszewicz, Beata Bajcar, Jolanta Babiak, Berenika Dyczek, Jakub Świstak, Przemysław Biecek
conference: "Arxiv"
year: 2025
bibkey: mieleszczenkokowszewicz2025mind
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.09687"}
tags: ['Prompting', 'Reinforcement Learning']
---
Be careful what you ask for, you just might get it. This saying fits with the
way large language models (LLMs) are trained, which, instead of being rewarded
for correctness, are increasingly rewarded for pleasing the recipient. So, they
are increasingly effective at persuading us that their answers are valuable.
But what tricks do they use in this persuasion? In this study, we examine what
are the psycholinguistic features of the responses used by twelve different
language models. By grouping response content according to rational or
emotional prompts and exploring social influence principles employed by LLMs,
we ask whether and how we can mitigate the risks of LLM-driven mass
misinformation. We position this study within the broader discourse on
human-centred AI, emphasizing the need for interdisciplinary approaches to
mitigate cognitive and societal risks posed by persuasive AI responses.

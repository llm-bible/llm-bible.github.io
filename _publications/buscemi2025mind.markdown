---
layout: publication
title: 'Mind The Language Gap: Automated And Augmented Evaluation Of Bias In Llms For High- And Low-resource Languages'
authors: Alessio Buscemi, Cédric Lothritz, Sergio Morales, Marcos Gomez-vazquez, Robert Clarisó, Jordi Cabot, German Castignani
conference: "Arxiv"
year: 2025
bibkey: buscemi2025mind
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2504.18560"}
tags: ['Training Techniques', 'Tools', 'Reinforcement Learning', 'RAG', 'Ethics and Bias']
---
Large Language Models (LLMs) have exhibited impressive natural language
processing capabilities but often perpetuate social biases inherent in their
training data. To address this, we introduce MultiLingual Augmented Bias
Testing (MLA-BiTe), a framework that improves prior bias evaluation methods by
enabling systematic multilingual bias testing. MLA-BiTe leverages automated
translation and paraphrasing techniques to support comprehensive assessments
across diverse linguistic settings. In this study, we evaluate the
effectiveness of MLA-BiTe by testing four state-of-the-art LLMs in six
languages -- including two low-resource languages -- focusing on seven
sensitive categories of discrimination.

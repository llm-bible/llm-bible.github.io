---
layout: publication
title: 'What Should We Engineer In Prompts? Training Humans In Requirement-driven LLM Use'
authors: Qianou Ma, Weirui Peng, Chenyang Yang, Hua Shen, Kenneth Koedinger, Tongshuang Wu
conference: "Arxiv"
year: 2024
bibkey: ma2024what
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2409.08775"}
tags: ['Efficiency and Optimization', 'Training Techniques', 'Model Architecture', 'Reinforcement Learning', 'Prompting', 'Applications', 'Attention Mechanism']
---
Prompting LLMs for complex tasks (e.g., building a trip advisor chatbot)
needs humans to clearly articulate customized requirements (e.g., "start the
response with a tl;dr"). However, existing prompt engineering instructions
often lack focused training on requirement articulation and instead tend to
emphasize increasingly automatable strategies (e.g., tricks like adding
role-plays and "think step-by-step"). To address the gap, we introduce
Requirement-Oriented Prompt Engineering (ROPE), a paradigm that focuses human
attention on generating clear, complete requirements during prompting. We
implement ROPE through an assessment and training suite that provides
deliberate practice with LLM-generated feedback. In a randomized controlled
experiment with 30 novices, ROPE significantly outperforms conventional prompt
engineering training (20% vs. 1% gains), a gap that automatic prompt
optimization cannot close. Furthermore, we demonstrate a direct correlation
between the quality of input requirements and LLM outputs. Our work paves the
way to empower more end-users to build complex LLM applications.

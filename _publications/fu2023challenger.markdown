---
layout: publication
title: A Challenger To GPT45;4V Early Explorations Of Gemini In Visual Expertise
authors: Fu Chaoyou, Zhang Renrui, Wang Zihan, Huang Yubo, Zhang Zhengye, Qiu Longtian, Ye Gaoxiang, Shen Yunhang, Zhang Mengdan, Chen Peixian, Zhao Sirui, Lin Shaohui, Jiang Deqiang, Yin Di, Gao Peng, Li Ke, Li Hongsheng, Sun Xing
conference: "Arxiv"
year: 2023
bibkey: fu2023challenger
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2312.12436"}
  - {name: "Code", url: "https://github.com/BradyFU/Awesome&#45;Multimodal&#45;Large&#45;Language&#45;Models"}
tags: ['Fine Tuning', 'GPT', 'Has Code', 'Interpretability And Explainability', 'Model Architecture', 'Multimodal Models', 'Reinforcement Learning']
---
The surge of interest towards Multi45;modal Large Language Models (MLLMs) e.g. GPT45;4V(ision) from OpenAI has marked a significant trend in both academia and industry. They endow Large Language Models (LLMs) with powerful capabilities in visual understanding enabling them to tackle diverse multi45;modal tasks. Very recently Google released Gemini its newest and most capable MLLM built from the ground up for multi45;modality. In light of the superior reasoning capabilities can Gemini challenge GPT45;4Vs leading position in multi45;modal learning In this paper we present a preliminary exploration of Gemini Pros visual understanding proficiency which comprehensively covers four domains fundamental perception advanced cognition challenging vision tasks and various expert capacities. We compare Gemini Pro with the state45;of45;the45;art GPT45;4V to evaluate its upper limits along with the latest open45;sourced MLLM Sphinx which reveals the gap between manual efforts and black45;box systems. The qualitative samples indicate that while GPT45;4V and Gemini showcase different answering styles and preferences they can exhibit comparable visual reasoning capabilities and Sphinx still trails behind them concerning domain generalizability. Specifically GPT45;4V tends to elaborate detailed explanations and intermediate steps and Gemini prefers to output a direct and concise answer. The quantitative evaluation on the popular MME benchmark also demonstrates the potential of Gemini to be a strong challenger to GPT45;4V. Our early investigation of Gemini also observes some common issues of MLLMs indicating that there still remains a considerable distance towards artificial general intelligence. Our project for tracking the progress of MLLM is released at https://github.com/BradyFU/Awesome&#45;Multimodal&#45;Large&#45;Language&#45;Models.

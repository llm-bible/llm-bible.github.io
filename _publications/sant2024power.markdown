---
layout: publication
title: The Power Of Prompts Evaluating And Mitigating Gender Bias In MT With Llms
authors: Sant Aleix, Escolano Carlos, Mash Audrey, Fornaciari Francesca De Luca, Melero Maite
conference: "Arxiv"
year: 2024
bibkey: sant2024power
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.18786"}
tags: ['Applications', 'Ethics And Bias', 'Prompting']
---
This paper studies gender bias in machine translation through the lens of Large Language Models (LLMs). Four widely45;used test sets are employed to benchmark various base LLMs comparing their translation quality and gender bias against state45;of45;the45;art Neural Machine Translation (NMT) models for English to Catalan (En → Ca) and English to Spanish (En → Es) translation directions. Our findings reveal pervasive gender bias across all models with base LLMs exhibiting a higher degree of bias compared to NMT models. To combat this bias we explore prompting engineering techniques applied to an instruction45;tuned LLM. We identify a prompt structure that significantly reduces gender bias by up to 1237; on the WinoMT evaluation dataset compared to more straightforward prompts. These results significantly reduce the gender bias accuracy gap between LLMs and traditional NMT systems.

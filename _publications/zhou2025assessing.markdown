---
layout: publication
title: 'Assessing The Macro And Micro Effects Of Random Seeds On Fine-tuning Large Language Models'
authors: Hao Zhou, Guergana Savova, Lijing Wang
conference: "Arxiv"
year: 2025
bibkey: zhou2025assessing
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2503.07329'}
tags: ['Reinforcement Learning', 'Fine-Tuning', 'Training Techniques', 'Pretraining Methods']
---
The impact of random seeds in fine-tuning large language models (LLMs) has
been largely overlooked despite its potential influence on model performance.In
this study, we systematically evaluate the effects of random seeds on LLMs
using the GLUE and SuperGLUE benchmarks. We analyze the macro-level impact
through traditional metrics like accuracy and F1, calculating their mean and
variance to quantify performance fluctuations. To capture the micro-level
effects, we introduce a novel metric, consistency, measuring the stability of
individual predictions across runs. Our experiments reveal significant variance
at both macro and micro levels, underscoring the need for careful consideration
of random seeds in fine-tuning and evaluation.

---
layout: publication
title: Thought45;like45;pro Enhancing Reasoning Of Large Language Models Through Self45;driven Prolog45;based Chain45;of45;thought
authors: Tan Xiaoyu, Deng Yongxin, Qiu Xihe, Xu Weidi, Qu Chao, Chu Wei, Xu Yinghui, Qi Yuan
conference: "Arxiv"
year: 2024
bibkey: tan2024thought
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.14562"}
tags: ['Pretraining Methods', 'Prompting', 'RAG', 'Tools']
---
Large language models (LLMs) have shown exceptional performance as general45;purpose assistants excelling across a variety of reasoning tasks. This achievement represents a significant step toward achieving artificial general intelligence (AGI). Despite these advancements the effectiveness of LLMs often hinges on the specific prompting strategies employed and there remains a lack of a robust framework to facilitate learning and generalization across diverse reasoning tasks. To address these challenges we introduce a novel learning framework THOUGHT45;LIKE45;PRO In this framework we utilize imitation learning to imitate the Chain45;of45;Thought (CoT) process which is verified and translated from reasoning trajectories generated by a symbolic Prolog logic engine. This framework proceeds in a self45;driven manner that enables LLMs to formulate rules and statements from given instructions and leverage the symbolic Prolog engine to derive results. Subsequently LLMs convert Prolog45;derived successive reasoning trajectories into natural language CoT for imitation learning. Our empirical findings indicate that our proposed approach substantially enhances the reasoning abilities of LLMs and demonstrates robust generalization across out45;of45;distribution reasoning tasks.

---
layout: publication
title: Large Language Models Are Self45;taught Reasoners Enhancing LLM Applications Via Tailored Problem45;solving Demonstrations
authors: Ong Kai Tzu-iunn, Kwon Taeyoon, Yeo Jinyoung
conference: "Arxiv"
year: 2024
bibkey: ong2024large
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.12315"}
tags: ['Applications', 'Prompting', 'Reinforcement Learning', 'Tools']
---
Guiding large language models with a selected set of human45;authored demonstrations is a common practice for improving LLM applications. However human effort can be costly especially in specialized domains (e.g. clinical diagnosis) and does not guarantee optimal performance due to the potential discrepancy of target skills between selected demonstrations and real test instances. Motivated by these this paper explores the automatic creation of customized demonstrations whose target skills align with the given target instance. We present SELF45;TAUGHT a problem45;solving framework which facilitates demonstrations that are tailored to the target problem and filtered for better quality (i.e. correctness) in a zero45;shot manner. In 15 tasks of multiple45;choice questions of diverse domains and the diagnosis of Alzheimers disease (AD) with real45;world patients SELF45;TAUGHT achieves superior performance to strong baselines (e.g. Few45;shot CoT Plan45;and45;Solve Auto45;CoT). We conduct comprehensive analyses on SELF45;TAUGHT including its generalizability to existing prompting methods and different LLMs the quality of its intermediate generation and more.

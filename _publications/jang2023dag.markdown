---
layout: publication
title: 'Dag LLM Ver 1.0: Pioneering Instruction-tuned Language Modeling For Korean NLP'
authors: Dongjun Jang, Sangah Lee, Sungjoo Byun, Jinwoong Kim, Jean Seo, Minseok Kim, Soyeon Kim, Chaeyoung Oh, Jaeyoon Kim, Hyemi Jo, Hyopil Shin
conference: "Arxiv"
year: 2023
bibkey: jang2023dag
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2311.13784"}
tags: ['Language Modeling']
---
This paper presents the DaG LLM (David and Goliath Large Language Model), a
language model specialized for Korean and fine-tuned through Instruction Tuning
across 41 tasks within 13 distinct categories.

---
layout: publication
title: 'An In-depth Survey Of Large Language Model-based Artificial Intelligence Agents'
authors: Pengyu Zhao, Zijian Jin, Ning Cheng
conference: "Arxiv"
year: 2023
bibkey: zhao2023survey
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.14365"}
tags: ['Agentic', 'RAG', 'Survey Paper', 'Reinforcement Learning']
---
Due to the powerful capabilities demonstrated by large language model (LLM),
there has been a recent surge in efforts to integrate them with AI agents to
enhance their performance. In this paper, we have explored the core differences
and characteristics between LLM-based AI agents and traditional AI agents.
Specifically, we first compare the fundamental characteristics of these two
types of agents, clarifying the significant advantages of LLM-based agents in
handling natural language, knowledge storage, and reasoning capabilities.
Subsequently, we conducted an in-depth analysis of the key components of AI
agents, including planning, memory, and tool use. Particularly, for the crucial
component of memory, this paper introduced an innovative classification scheme,
not only departing from traditional classification methods but also providing a
fresh perspective on the design of an AI agent's memory system. We firmly
believe that in-depth research and understanding of these core components will
lay a solid foundation for the future advancement of AI agent technology. At
the end of the paper, we provide directional suggestions for further research
in this field, with the hope of offering valuable insights to scholars and
researchers in the field.

---
layout: publication
title: Ada45;instruct Adapting Instruction Generators For Complex Reasoning
authors: Cui Wanyun, Wang Qianle
conference: "Arxiv"
year: 2023
bibkey: cui2023ada
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.04484"}
tags: ['Applications', 'Ethics And Bias', 'Prompting', 'RAG']
---
Generating diverse and sophisticated instructions for downstream tasks by Large Language Models (LLMs) is pivotal for advancing the effect. Current approaches leverage closed45;source LLMs employing in45;context prompting for instruction generation. However in this paper we found that in45;context prompting cannot generate complex instructions with length ge 100 for tasks like code completion. To solve this problem we introduce Ada45;Instruct an adaptive instruction generator developed by fine45;tuning open45;source LLMs. Our pivotal finding illustrates that fine45;tuning open45;source LLMs with a mere ten samples generates long instructions that maintain distributional consistency for complex reasoning tasks. We empirically validated Ada45;Instructs efficacy across different applications including code completion mathematical reasoning and commonsense reasoning. The results underscore Ada45;Instructs superiority evidencing its improvements over its base models current self45;instruct methods and other state45;of45;the45;art models.

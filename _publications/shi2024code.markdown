---
layout: publication
title: Ehragent Code Empowers Large Language Models For Few45;shot Complex Tabular Reasoning On Electronic Health Records
authors: Shi Wenqi, Xu Ran, Zhuang Yuchen, Yu Yue, Zhang Jieyu, Wu Hang, Zhu Yuanda, Ho Joyce, Yang Carl, Wang May D.
conference: "Arxiv"
year: 2024
bibkey: shi2024code
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.07128"}
tags: ['Agent', 'Agentic', 'Applications', 'Merging', 'RAG', 'Reinforcement Learning']
---
Large language models (LLMs) have demonstrated exceptional capabilities in planning and tool utilization as autonomous agents but few have been developed for medical problem45;solving. We propose EHRAgent an LLM agent empowered with a code interface to autonomously generate and execute code for multi45;tabular reasoning within electronic health records (EHRs). First we formulate an EHR question45;answering task into a tool45;use planning process efficiently decomposing a complicated task into a sequence of manageable actions. By integrating interactive coding and execution feedback EHRAgent learns from error messages and improves the originally generated code through iterations. Furthermore we enhance the LLM agent by incorporating long45;term memory which allows EHRAgent to effectively select and build upon the most relevant successful cases from past experiences. Experiments on three real45;world multi45;tabular EHR datasets show that EHRAgent outperforms the strongest baseline by up to 29.637; in success rate. EHRAgent leverages the emerging few45;shot learning capabilities of LLMs enabling autonomous code generation and execution to tackle complex clinical tasks with minimal demonstrations.

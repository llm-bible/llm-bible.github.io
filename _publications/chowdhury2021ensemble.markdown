---
layout: publication
title: 'Ensemble Fine-tuned Mbert For Translation Quality Estimation'
authors: Chowdhury Shaika, Baili Naouel, Vannah Brian
conference: "Arxiv"
year: 2021
bibkey: chowdhury2021ensemble
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2109.03914"}
tags: ['Applications', 'BERT', 'Fine Tuning', 'Model Architecture', 'Pretraining Methods', 'Training Techniques']
---
Quality Estimation (QE) is an important component of the machine translation workflow as it assesses the quality of the translated output without consulting reference translations. In this paper we discuss our submission to the WMT 2021 QE Shared Task. We participate in Task 2 sentence-level sub-task that challenge participants to predict the HTER score for sentence-level post-editing effort. Our proposed system is an ensemble of multilingual BERT (mBERT)-based regression models which are generated by fine-tuning on different input settings. It demonstrates comparable performance with respect to the Pearsons correlation and beats the baseline system in MAE/ RMSE for several language pairs. In addition we adapt our system for the zero-shot setting by exploiting target language-relevant language pairs and pseudo-reference translations.

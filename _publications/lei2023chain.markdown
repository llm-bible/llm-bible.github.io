---
layout: publication
title: Chain Of Natural Language Inference For Reducing Large Language Model Ungrounded Hallucinations
authors: Lei Deren, Li Yaxi, Hu Mengya, Wang Mingyu, Yun Vincent, Ching Emily, Kamal Eslam
conference: "Arxiv"
year: 2023
bibkey: lei2023chain
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.03951"}
tags: ['Applications', 'Prompting', 'Reinforcement Learning', 'Tools']
---
Large language models (LLMs) can generate fluent natural language texts when given relevant documents as background context. This ability has attracted considerable interest in developing industry applications of LLMs. However LLMs are prone to generate hallucinations that are not supported by the provided sources. In this paper we propose a hierarchical framework to detect and mitigate such ungrounded hallucination. Our framework uses Chain of Natural Language Inference (CoNLI) for hallucination detection and hallucination reduction via post45;editing. Our approach achieves state45;of45;the45;art performance on hallucination detection and enhances text quality through rewrite using LLMs without any fine45;tuning or domain45;specific prompt engineering. We show that this simple plug45;and45;play framework can serve as an effective choice for hallucination detection and reduction achieving competitive performance across various contexts.

---
layout: publication
title: Towards Few45;shot Fact45;checking Via Perplexity
authors: Lee Nayeon, Bang Yejin, Madotto Andrea, Khabsa Madian, Fung Pascale
conference: "Arxiv"
year: 2021
bibkey: lee2021towards
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2103.09535"}
tags: ['Applications', 'Attention Mechanism', 'Fine Tuning', 'Model Architecture', 'Training Techniques']
---
Few45;shot learning has drawn researchers attention to overcome the problem of data scarcity. Recently large pre45;trained language models have shown great performance in few45;shot learning for various downstream tasks such as question answering and machine translation. Nevertheless little exploration has been made to achieve few45;shot learning for the fact45;checking task. However fact45;checking is an important problem especially when the amount of information online is growing exponentially every day. In this paper we propose a new way of utilizing the powerful transfer learning ability of a language model via a perplexity score. The most notable strength of our methodology lies in its capability in few45;shot learning. With only two training samples our methodology can already outperform the Major Class baseline by more than absolute 1037; on the F145;Macro metric across multiple datasets. Through experiments we empirically verify the plausibility of the rather surprising usage of the perplexity score in the context of fact45;checking and highlight the strength of our few45;shot methodology by comparing it to strong fine45;tuning45;based baseline models. Moreover we construct and publicly release two new fact45;checking datasets related to COVID45;19.

---
layout: publication
title: 'Think Like A Person Before Responding: A Multi-faceted Evaluation Of Persona-guided Llms For Countering Hate'
authors: Mikel K. Ngueajio, Flor Miriam Plaza-del-arco, Yi-ling Chung, Danda B. Rawat, Amanda Cercas Curry
conference: "Arxiv"
year: 2025
bibkey: ngueajio2025think
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2506.04043"}
tags: ['Responsible AI', 'Tools', 'GPT', 'Model Architecture', 'Security', 'Prompting']
---
Automated counter-narratives (CN) offer a promising strategy for mitigating online hate speech, yet concerns about their affective tone, accessibility, and ethical risks remain. We propose a framework for evaluating Large Language Model (LLM)-generated CNs across four dimensions: persona framing, verbosity and readability, affective tone, and ethical robustness. Using GPT-4o-Mini, Cohere's CommandR-7B, and Meta's LLaMA 3.1-70B, we assess three prompting strategies on the MT-Conan and HatEval datasets. Our findings reveal that LLM-generated CNs are often verbose and adapted for people with college-level literacy, limiting their accessibility. While emotionally guided prompts yield more empathetic and readable responses, there remain concerns surrounding safety and effectiveness.

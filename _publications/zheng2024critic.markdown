---
layout: publication
title: Critic45;cot Boosting The Reasoning Abilities Of Large Language Model Via Chain45;of45;thoughts Critic
authors: Zheng Xin, Lou Jie, Cao Boxi, Wen Xueru, Ji Yuqiu, Lin Hongyu, Lu Yaojie, Han Xianpei, Zhang Debing, Sun Le
conference: "Arxiv"
year: 2024
bibkey: zheng2024critic
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.16326"}
tags: ['Applications', 'Prompting', 'Tools', 'Training Techniques']
---
Self45;critic has become an important mechanism for enhancing the reasoning performance of LLMs. However current approaches mainly involve basic prompts without further training which tend to be over45;simplified leading to limited accuracy.Moreover there is a lack of in45;depth investigation of the relationship between LLMs ability to criticism and its task45;solving performance.To address these issues we propose Critic45;CoT a novel framework that pushes LLMs toward System45;245;like critic capability via step45;wise CoT reasoning format and distant45;supervision data construction without the need for human annotation. Experiments on GSM8K and MATH show that via filtering out invalid solutions or iterative refinement our enhanced model boosts task45;solving performance which demonstrates the effectiveness of our method. Further we find that training on critique and refinement alone improves the generation. We hope our work could shed light on future research on improving the reasoning and critic ability of LLMs.

---
layout: publication
title: Performance of ChatGPT on USMLE Unlocking the Potential of Large Language Models for AI-Assisted Medical Education
authors: Sharma Prabin, Thapa Kisan, Thapa Dikshya, Dhakal Prastab, Upadhaya Mala Deep, Adhikari Santosh, Khanal Salik Ram
conference: "Arxiv"
year: 2023
bibkey: sharma2023performance
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2307.00112"}
tags: ['ARXIV', 'Chatgpt', 'GPT', 'Model Architecture', 'Prompt', 'Tools']
---
Artificial intelligence is gaining traction in more ways than ever before. The popularity of language models and AI-based businesses has soared since ChatGPT was made available to the general public via OpenAI. It is becoming increasingly common for people to use ChatGPT both professionally and personally. Considering the widespread use of ChatGPT and the reliance people place on it this study determined how reliable ChatGPT can be for answering complex medical and clinical questions. Harvard University gross anatomy along with the United States Medical Licensing Examination (USMLE) questionnaire were used to accomplish the objective. The paper evaluated the obtained results using a 2-way ANOVA and posthoc analysis. Both showed systematic covariation between format and prompt. Furthermore the physician adjudicators independently rated the outcomes accuracy concordance and insight. As a result of the analysis ChatGPT-generated answers were found to be more context-oriented and represented a better model for deductive reasoning than regular Google search results. Furthermore ChatGPT obtained 58.8 on logical questions and 60 on ethical questions. This means that the ChatGPT is approaching the passing range for logical questions and has crossed the threshold for ethical questions. The paper believes ChatGPT and other language learning models can be invaluable tools for e-learners; however the study suggests that there is still room to improve their accuracy. In order to improve ChatGPTs performance in the future further research is needed to better understand how it can answer different types of questions.

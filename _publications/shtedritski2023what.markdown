---
layout: publication
title: What Does CLIP Know About A Red Circle Visual Prompt Engineering For Vlms
authors: Shtedritski Aleksandar, Rupprecht Christian, Vedaldi Andrea
conference: "Arxiv"
year: 2023
bibkey: shtedritski2023what
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2304.06712"}
tags: ['Applications', 'Attention Mechanism', 'GPT', 'Model Architecture', 'Prompting']
---
Large45;scale Vision45;Language Models such as CLIP learn powerful image45;text representations that have found numerous applications from zero45;shot classification to text45;to45;image generation. Despite that their capabilities for solving novel discriminative tasks via prompting fall behind those of large language models such as GPT45;3. Here we explore the idea of visual prompt engineering for solving computer vision tasks beyond classification by editing in image space instead of text. In particular we discover an emergent ability of CLIP where by simply drawing a red circle around an object we can direct the models attention to that region while also maintaining global information. We show the power of this simple approach by achieving state45;of45;the45;art in zero45;shot referring expressions comprehension and strong performance in keypoint localization tasks. Finally we draw attention to some potential ethical concerns of large language45;vision models.

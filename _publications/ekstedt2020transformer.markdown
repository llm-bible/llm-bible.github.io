---
layout: publication
title: Turngpt A Transformer45;based Language Model For Predicting Turn45;taking In Spoken Dialog
authors: Ekstedt Erik, Skantze Gabriel
conference: "Arxiv"
year: 2020
bibkey: ekstedt2020transformer
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2010.10874"}
tags: ['Attention Mechanism', 'GPT', 'Model Architecture', 'Pretraining Methods', 'RAG', 'Transformer']
---
Syntactic and pragmatic completeness is known to be important for turn45;taking prediction but so far machine learning models of turn45;taking have used such linguistic information in a limited way. In this paper we introduce TurnGPT a transformer45;based language model for predicting turn45;shifts in spoken dialog. The model has been trained and evaluated on a variety of written and spoken dialog datasets. We show that the model outperforms two baselines used in prior work. We also report on an ablation study as well as attention and gradient analyses which show that the model is able to utilize the dialog context and pragmatic completeness for turn45;taking prediction. Finally we explore the models potential in not only detecting but also projecting turn45;completions.

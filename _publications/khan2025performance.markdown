---
layout: publication
title: 'Loxr: Performance Evaluation Of Locally Executing Llms On XR Devices'
authors: Dawar Khan, Xinyu Liu, Omar Mena, Donggang Jia, Alexandre Kouyoumdjian, Ivan Viola
conference: "Arxiv"
year: 2025
bibkey: khan2025performance
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.15761"}
tags: ['Efficiency and Optimization', 'Merging', 'Applications']
---
The deployment of large language models (LLMs) on extended reality (XR)
devices has great potential to advance the field of human-AI interaction. In
the case of direct, on-device model inference, selecting the appropriate model
and device for specific tasks remains challenging. In this paper, we deploy 17
LLMs across four XR devices--Magic Leap 2, Meta Quest 3, Vivo X100s Pro, and
Apple Vision Pro, and conduct a comprehensive evaluation. We devise an
experimental setup and evaluate performance on four key metrics: performance
consistency, processing speed, memory usage, and battery consumption. For each
of the 68 model-device pairs, we assess performance under varying string
lengths, batch sizes, and thread counts, analyzing the trade-offs for real-time
XR applications. We finally propose a unified evaluation method based on the
Pareto Optimality theory to select the optimal device-model pairs from the
quality and speed objectives. We believe our findings offer valuable insights
to guide future optimization efforts for LLM deployment on XR devices. Our
evaluation method can be followed as standard groundwork for further research
and development in this emerging field. All supplemental materials are
available at www.nanovis.org/Loxr.html.

---
layout: publication
title: Deficiency Of Large Language Models In Finance: An Empirical Examination Of Hallucination
authors: Kang Haoqiang, Liu Xiao-yang
conference: "Arxiv"
year: 2023
bibkey: kang2023deficiency
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2311.15548"}
tags: ['Few Shot', 'Prompting', 'RAG']
---
The hallucination issue is recognized as a fundamental deficiency of large language models (LLMs) especially when applied to fields such as finance education and law. Despite the growing concerns there has been a lack of empirical investigation. In this paper we provide an empirical examination of LLMs hallucination behaviors in financial tasks. First we empirically investigate LLM models ability of explaining financial concepts and terminologies. Second we assess LLM models capacity of querying historical stock prices. Third to alleviate the hallucination issue we evaluate the efficacy of four practical methods including few-shot learning Decoding by Contrasting Layers (DoLa) the Retrieval Augmentation Generation (RAG) method and the prompt-based tool learning method for a function to generate a query command. Finally our major finding is that off-the-shelf LLMs experience serious hallucination behaviors in financial tasks. Therefore there is an urgent need to call for research efforts in mitigating LLMs hallucination.

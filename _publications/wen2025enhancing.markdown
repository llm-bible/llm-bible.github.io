---
layout: publication
title: 'Enhancing Reasoning To Adapt Large Language Models For Domain-specific Applications'
authors: Bo Wen, Xin Zhang
conference: "https://neurips.cc/virtual/2024/104981"
year: 2025
bibkey: wen2025enhancing
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2502.04384'}
tags: ['RAG', 'Applications', 'Model Architecture', 'Prompting', 'In-Context Learning']
---
This paper presents SOLOMON, a novel Neuro-inspired Large Language Model
(LLM) Reasoning Network architecture that enhances the adaptability of
foundation models for domain-specific applications. Through a case study in
semiconductor layout design, we demonstrate how SOLOMON enables swift
adaptation of general-purpose LLMs to specialized tasks by leveraging Prompt
Engineering and In-Context Learning techniques. Our experiments reveal the
challenges LLMs face in spatial reasoning and applying domain knowledge to
practical problems. Results show that SOLOMON instances significantly
outperform their baseline LLM counterparts and achieve performance comparable
to state-of-the-art reasoning model, o1-preview. We discuss future research
directions for developing more adaptive AI systems that can continually learn,
adapt, and evolve in response to new information and changing requirements.

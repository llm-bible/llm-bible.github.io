---
layout: publication
title: March In Chat Interactive Prompting For Remote Embodied Referring Expression
authors: Qiao Yanyuan, Qi Yuankai, Yu Zheng, Liu Jing, Wu Qi
conference: "Arxiv"
year: 2023
bibkey: qiao2023march
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2308.10141"}
tags: ['Agentic', 'Ethics And Bias', 'Prompting']
---
Many Vision45;and45;Language Navigation (VLN) tasks have been proposed in recent years from room45;based to object45;based and indoor to outdoor. The REVERIE (Remote Embodied Referring Expression) is interesting since it only provides high45;level instructions to the agent which are closer to human commands in practice. Nevertheless this poses more challenges than other VLN tasks since it requires agents to infer a navigation plan only based on a short instruction. Large Language Models (LLMs) show great potential in robot action planning by providing proper prompts. Still this strategy has not been explored under the REVERIE settings. There are several new challenges. For example the LLM should be environment45;aware so that the navigation plan can be adjusted based on the current visual observation. Moreover the LLM planned actions should be adaptable to the much larger and more complex REVERIE environment. This paper proposes a March45;in45;Chat (MiC) model that can talk to the LLM on the fly and plan dynamically based on a newly proposed Room45;and45;Object Aware Scene Perceiver (ROASP). Our MiC model outperforms the previous state45;of45;the45;art by large margins by SPL and RGSPL metrics on the REVERIE benchmark.

---
layout: publication
title: 'Large Language Models Know What To Say But Not When To Speak'
authors: Muhammad Umair, Vasanth Sarathy, Jp De Ruiter
conference: "Arxiv"
year: 2024
bibkey: umair2024large
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2410.16044"}
tags: ['Applications', 'Reinforcement Learning']
---
Turn-taking is a fundamental mechanism in human communication that ensures
smooth and coherent verbal interactions. Recent advances in Large Language
Models (LLMs) have motivated their use in improving the turn-taking
capabilities of Spoken Dialogue Systems (SDS), such as their ability to respond
at appropriate times. However, existing models often struggle to predict
opportunities for speaking -- called Transition Relevance Places (TRPs) -- in
natural, unscripted conversations, focusing only on turn-final TRPs and not
within-turn TRPs. To address these limitations, we introduce a novel dataset of
participant-labeled within-turn TRPs and use it to evaluate the performance of
state-of-the-art LLMs in predicting opportunities for speaking. Our experiments
reveal the current limitations of LLMs in modeling unscripted spoken
interactions, highlighting areas for improvement and paving the way for more
naturalistic dialogue systems.

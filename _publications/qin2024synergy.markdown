---
layout: publication
title: The Synergy Between Data And Multi45;modal Large Language Models A Survey From Co45;development Perspective
authors: Qin Zhen, Chen Daoyuan, Zhang Wenhao, Yao Liuyi, Huang Yilun, Ding Bolin, Li Yaliang, Deng Shuiguang
conference: "Arxiv"
year: 2024
bibkey: qin2024synergy
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.08583"}
  - {name: "Code", url: "https://github.com/modelscope/data&#45;juicer/blob/main/docs/awesome&#95;llm&#95;data.md"}
tags: ['Attention Mechanism', 'Has Code', 'Model Architecture', 'Pretraining Methods', 'Reinforcement Learning', 'Survey Paper', 'Tools']
---
The rapid development of large language models (LLMs) has been witnessed in recent years. Based on the powerful LLMs multi45;modal LLMs (MLLMs) extend the modality from text to a broader spectrum of domains attracting widespread attention due to the broader range of application scenarios. As LLMs and MLLMs rely on vast amounts of model parameters and data to achieve emergent capabilities the importance of data is receiving increasingly widespread attention and recognition. Tracing and analyzing recent data45;oriented works for MLLMs we find that the development of models and data is not two separate paths but rather interconnected. On the one hand vaster and higher45;quality data contribute to better performance of MLLMs; on the other hand MLLMs can facilitate the development of data. The co45;development of multi45;modal data and MLLMs requires a clear view of 1) at which development stages of MLLMs specific data45;centric approaches can be employed to enhance certain MLLM capabilities and 2) how MLLMs utilizing those capabilities can contribute to multi45;modal data in specific roles. To promote the data45;model co45;development for MLLM community we systematically review existing works related to MLLMs from the data45;model co45;development perspective. A regularly maintained project associated with this survey is accessible at https://github.com/modelscope/data&#45;juicer/blob/main/docs/awesome&#95;llm&#95;data.md.

---
layout: publication
title: 'Adversarial Representation Engineering: A General Model Editing Framework For Large Language Models'
authors: Yihao Zhang, Zeming Wei, Jun Sun, Meng Sun
conference: "Arxiv"
year: 2024
bibkey: zhang2024adversarial
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.13752"}
  - {name: "Code", url: "https://github.com/Zhang-Yihao/Adversarial-Representation-Engineering"}
tags: ['Security', 'Tools', 'RAG', 'Has Code', 'ACL']
---
Since the rapid development of Large Language Models (LLMs) has achieved
remarkable success, understanding and rectifying their internal complex
mechanisms has become an urgent issue. Recent research has attempted to
interpret their behaviors through the lens of inner representation. However,
developing practical and efficient methods for applying these representations
for general and flexible model editing remains challenging. In this work, we
explore how to leverage insights from representation engineering to guide the
editing of LLMs by deploying a representation sensor as an editing oracle. We
first identify the importance of a robust and reliable sensor during editing,
then propose an Adversarial Representation Engineering (ARE) framework to
provide a unified and interpretable approach for conceptual model editing
without compromising baseline performance. Experiments on multiple tasks
demonstrate the effectiveness of ARE in various model editing scenarios. Our
code and data are available at
https://github.com/Zhang-Yihao/Adversarial-Representation-Engineering.

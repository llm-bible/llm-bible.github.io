---
layout: publication
title: 'From Language To Cognition: How Llms Outgrow The Human Language Network'
authors: Badr Alkhamissi, Greta Tuckute, Yingtian Tang, Taha Binhuraib, Antoine Bosselut, Martin Schrimpf
conference: "Arxiv"
year: 2025
bibkey: alkhamissi2025from
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2503.01830"}
tags: ['Training Techniques', 'Tools', 'Reinforcement Learning']
---
Large language models (LLMs) exhibit remarkable similarity to neural activity
in the human language network. However, the key properties of language shaping
brain-like representations, and their evolution during training as a function
of different tasks remain unclear. We here benchmark 34 training checkpoints
spanning 300B tokens across 8 different model sizes to analyze how brain
alignment relates to linguistic competence. Specifically, we find that brain
alignment tracks the development of formal linguistic competence -- i.e.,
knowledge of linguistic rules -- more closely than functional linguistic
competence. While functional competence, which involves world knowledge and
reasoning, continues to develop throughout training, its relationship with
brain alignment is weaker, suggesting that the human language network primarily
encodes formal linguistic structure rather than broader cognitive functions. We
further show that model size is not a reliable predictor of brain alignment
when controlling for feature size and find that the correlation between
next-word prediction, behavioral alignment and brain alignment fades once
models surpass human language proficiency. Finally, using the largest set of
rigorous neural language benchmarks to date, we show that language brain
alignment benchmarks remain unsaturated, highlighting opportunities for
improving future models. Taken together, our findings suggest that the human
language network is best modeled by formal, rather than functional, aspects of
language.

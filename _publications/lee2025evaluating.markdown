---
layout: publication
title: 'Evaluating Step-by-step Reasoning Traces: A Survey'
authors: Jinu Lee, Julia Hockenmaier
conference: "Arxiv"
year: 2025
bibkey: lee2025evaluating
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2502.12289'}
tags: ['RAG', 'Survey Paper']
---
Step-by-step reasoning is widely used to enhance the reasoning ability of large language models (LLMs) in complex problems. Evaluating the quality of reasoning traces is crucial for understanding and improving LLM reasoning. However, existing evaluation practices are highly inconsistent, resulting in fragmented progress across evaluator design and benchmark development. To address this gap, this survey provides a comprehensive overview of step-by-step reasoning evaluation, proposing a taxonomy of evaluation criteria with four top-level categories (factuality, validity, coherence, and utility). Based on the taxonomy, we review different evaluator implementations and recent findings, leading to promising directions for future research.

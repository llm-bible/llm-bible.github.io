---
layout: publication
title: Syllabusqa A Course Logistics Question Answering Dataset
authors: Fernandez Nigel, Scarlatos Alexander, Lan Andrew
conference: "Arxiv"
year: 2024
bibkey: fernandez2024course
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.14666"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Prompting']
---
Automated teaching assistants and chatbots have significant potential to reduce the workload of human instructors especially for logistics45;related question answering which is important to students yet repetitive for instructors. However due to privacy concerns there is a lack of publicly available datasets. We introduce SyllabusQA an open45;source dataset with 63 real course syllabi covering 36 majors containing 5078 open45;ended course logistics45;related question45;answer pairs that are diverse in both question types and answer formats. Since many logistics45;related questions contain critical information like the date of an exam it is important to evaluate the factuality of answers. We benchmark several strong baselines on this task from large language model prompting to retrieval45;augmented generation. We introduce Fact45;QA an LLM45;based (GPT45;4) evaluation metric to evaluate the factuality of predicted answers. We find that despite performing close to humans on traditional metrics of textual similarity there remains a significant gap between automated approaches and humans in terms of fact precision.

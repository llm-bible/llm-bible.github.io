---
layout: publication
title: Code Llama Open Foundation Models For Code
authors: Rozière Baptiste, Gehring Jonas, Gloeckle Fabian, Sootla Sten, Gat Itai, Tan Xiaoqing Ellen, Adi Yossi, Liu Jingyu, Sauvestre Romain, Remez Tal, Rapin Jérémy, Kozhevnikov Artyom, Evtimov Ivan, Bitton Joanna, Bhatt Manish, Ferrer Cristian Canton, Grattafiori Aaron, Xiong Wenhan, Défossez Alexandre, Copet Jade, Azhar Faisal, Touvron Hugo, Martin Louis, Usunier Nicolas, Scialom Thomas, Synnaeve Gabriel
conference: "Arxiv"
year: 2023
bibkey: rozière2023code
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2308.12950"}
tags: ['Applications', 'Pretraining Methods', 'Reinforcement Learning']
---
We release Code Llama a family of large language models for code based on Llama 2 providing state45;of45;the45;art performance among open models infilling capabilities support for large input contexts and zero45;shot instruction following ability for programming tasks. We provide multiple flavors to cover a wide range of applications foundation models (Code Llama) Python specializations (Code Llama 45; Python) and instruction45;following models (Code Llama 45; Instruct) with 7B 13B 34B and 70B parameters each. All models are trained on sequences of 16k tokens and show improvements on inputs with up to 100k tokens. 7B 13B and 70B Code Llama and Code Llama 45; Instruct variants support infilling based on surrounding content. Code Llama reaches state45;of45;the45;art performance among open models on several code benchmarks with scores of up to 6737; and 6537; on HumanEval and MBPP respectively. Notably Code Llama 45; Python 7B outperforms Llama 2 70B on HumanEval and MBPP and all our models outperform every other publicly available model on MultiPL45;E. We release Code Llama under a permissive license that allows for both research and commercial use.

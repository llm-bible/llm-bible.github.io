---
layout: publication
title: Unibucllm Harnessing Llms For Automated Prediction Of Item Difficulty And Response Time For Multiple45;choice Questions
authors: Rogoz Ana-cristina, Ionescu Radu Tudor
conference: "Arxiv"
year: 2024
bibkey: rogoz2024harnessing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.13343"}
  - {name: "Code", url: "https://github.com/ana&#45;rogoz/BEA&#45;2024"}
tags: ['Has Code', 'Model Architecture', 'Pretraining Methods', 'Transformer']
---
This work explores a novel data augmentation method based on Large Language Models (LLMs) for predicting item difficulty and response time of retired USMLE Multiple45;Choice Questions (MCQs) in the BEA 2024 Shared Task. Our approach is based on augmenting the dataset with answers from zero45;shot LLMs (Falcon Meditron Mistral) and employing transformer45;based models based on six alternative feature combinations. The results suggest that predicting the difficulty of questions is more challenging. Notably our top performing methods consistently include the question text and benefit from the variability of LLM answers highlighting the potential of LLMs for improving automated assessment in medical licensing exams. We make our code available https://github.com/ana&#45;rogoz/BEA&#45;2024.

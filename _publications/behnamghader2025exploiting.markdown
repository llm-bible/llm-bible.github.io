---
layout: publication
title: 'Exploiting Instruction-following Retrievers For Malicious Information Retrieval'
authors: Parishad Behnamghader, Nicholas Meade, Siva Reddy
conference: "Arxiv"
year: 2025
bibkey: behnamghader2025exploiting
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2503.08644'}
tags: ['Reinforcement Learning', 'Responsible AI', 'Applications', 'Merging']
---
Instruction-following retrievers have been widely adopted alongside LLMs in
real-world applications, but little work has investigated the safety risks
surrounding their increasing search capabilities. We empirically study the
ability of retrievers to satisfy malicious queries, both when used directly and
when used in a retrieval augmented generation-based setup. Concretely, we
investigate six leading retrievers, including NV-Embed and LLM2Vec, and find
that given malicious requests, most retrievers can (for >50% of queries) select
relevant harmful passages. For example, LLM2Vec correctly selects passages for
61.35% of our malicious queries. We further uncover an emerging risk with
instruction-following retrievers, where highly relevant harmful information can
be surfaced by exploiting their instruction-following capabilities. Finally, we
show that even safety-aligned LLMs, such as Llama3, can satisfy malicious
requests when provided with harmful retrieved passages in-context. In summary,
our findings underscore the malicious misuse risks associated with increasing
retriever capability.

---
layout: publication
title: 'Purposefully Induced Psychosis (PIP): Embracing Hallucination As Imagination In Large Language Models'
authors: Kris Pilcher, Esen K. Tütüncü
conference: "Arxiv"
year: 2025
bibkey: pilcher2025purposefully
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2504.12012"}
tags: ['Fine-Tuning', 'Responsible AI', 'Applications', 'Ethics and Bias', 'RAG']
---
Hallucinations in Large Language Models (LLMs) are widely regarded as errors
- outputs that deviate from factual accuracy. However, in creative or
exploratory contexts, these "mistakes" may represent unexpected avenues for
innovation. We introduce Purposefully Induced Psychosis (PIP), a novel approach
that amplifies LLM hallucinations for imaginative tasks such as speculative
fiction, interactive storytelling, and mixed-reality simulations. Drawing on
Herman Melville's Moby-Dick, where Pip's "madness" reveals profound insight, we
reframe hallucinations as a source of computational imagination rather than a
flaw. Our method fine-tunes LLMs to encourage speculative, metaphorical, and
surreal outputs - hallucinations that are useful when factual accuracy is not
the chief objective. Inspired by the consensual illusions of theater and stage
magic, PIP situates these creative missteps in contexts where users willingly
suspend disbelief, thereby transforming "errors" into catalysts for new ways of
thinking. We discuss potential applications, design principles for ensuring
user consent, preliminary observations, and implications for broader AI ethics
and human-AI collaboration.

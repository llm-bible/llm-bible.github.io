---
layout: publication
title: Bio45;sieve Exploring Instruction Tuning Large Language Models For Systematic Review Automation
authors: Robinson Ambrose, Thorne William, Wu Ben P., Pandor Abdullah, Essat Munira, Stevenson Mark, Song Xingyi
conference: "Arxiv"
year: 2023
bibkey: robinson2023bio
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2308.06610"}
tags: ['GPT', 'Model Architecture', 'Pretraining Methods', 'Reinforcement Learning', 'Responsible AI', 'Survey Paper', 'Training Techniques']
---
Medical systematic reviews can be very costly and resource intensive. We explore how Large Language Models (LLMs) can support and be trained to perform literature screening when provided with a detailed set of selection criteria. Specifically we instruction tune LLaMA and Guanaco models to perform abstract screening for medical systematic reviews. Our best model Bio45;SIEVE outperforms both ChatGPT and trained traditional approaches and generalises better across medical domains. However there remains the challenge of adapting the model to safety45;first scenarios. We also explore the impact of multi45;task training with Bio45;SIEVE45;Multi including tasks such as PICO extraction and exclusion reasoning but find that it is unable to match single45;task Bio45;SIEVEs performance. We see Bio45;SIEVE as an important step towards specialising LLMs for the biomedical systematic review process and explore its future developmental opportunities. We release our models code and a list of DOIs to reconstruct our dataset for reproducibility.

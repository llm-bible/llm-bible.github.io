---
layout: publication
title: 'Rule-guided Feedback: Enhancing Reasoning By Enforcing Rule Adherence In Large Language Models'
authors: Aissatou Diallo, Antonis Bikakis, Luke Dickens, Anthony Hunter, Rob Miller
conference: "Arxiv"
year: 2025
bibkey: diallo2025rule
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2503.11336"}
tags: ['RAG', 'Tools']
---
In this paper, we introduce Rule-Guided Feedback (RGF), a framework designed
to enhance Large Language Model (LLM) performance through structured rule
adherence and strategic information seeking. RGF implements a teacher-student
paradigm where rule-following is forced through established guidelines. Our
framework employs a Teacher model that rigorously evaluates each student output
against task-specific rules, providing constructive guidance rather than direct
answers when detecting deviations. This iterative feedback loop serves two
crucial purposes: maintaining solutions within defined constraints and
encouraging proactive information seeking to resolve uncertainties. We evaluate
RGF on diverse tasks including Checkmate-in-One puzzles, Sonnet Writing,
Penguins-In-a-Table classification, GSM8k, and StrategyQA. Our findings suggest
that structured feedback mechanisms can significantly enhance LLMs' performance
across various domains.

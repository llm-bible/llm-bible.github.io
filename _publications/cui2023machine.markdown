---
layout: publication
title: 'Machine Mindset: An MBTI Exploration Of Large Language Models'
authors: Jiaxi Cui, Liuzhenghao Lv, Jing Wen, Rongsheng Wang, Jing Tang, Yonghong Tian, Li Yuan
conference: "Arxiv"
year: 2023
bibkey: cui2023machine
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2312.12999"}
  - {name: "Code", url: "https://github.com/PKU-YuanGroup/Machine-Mindset"}
tags: ['Fine-Tuning', 'Efficiency and Optimization', 'Applications', 'Reinforcement Learning', 'Training Techniques', 'Has Code', 'Pretraining Methods']
---
We present a novel approach for integrating Myers-Briggs Type Indicator
(MBTI) personality traits into large language models (LLMs), addressing the
challenges of personality consistency in personalized AI. Our method, "Machine
Mindset," involves a two-phase fine-tuning and Direct Preference Optimization
(DPO) to embed MBTI traits into LLMs. This approach ensures that models
internalize these traits, offering a stable and consistent personality profile.
We demonstrate the effectiveness of our models across various domains, showing
alignment between model performance and their respective MBTI traits. The paper
highlights significant contributions in the development of personality datasets
and a new training methodology for personality integration in LLMs, enhancing
the potential for personalized AI applications. We also open-sourced our model
and part of the data at \url\{https://github.com/PKU-YuanGroup/Machine-Mindset\}.

---
layout: publication
title: Context Matters\: Data-efficient Augmentation Of Large Language Models For Scientific Applications
authors: Li Xiang, Tang Haoran, Chen Siyu, Wang Ziwei, Maravi Anurag, Abram Marcin
conference: "Arxiv"
year: 2023
bibkey: li2023context
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2312.07069"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Pretraining Methods', 'Reinforcement Learning', 'Tools']
---
In this paper we explore the challenges inherent to Large Language Models (LLMs) like GPT-4 particularly their propensity for hallucinations logic mistakes and incorrect conclusions when tasked with answering complex questions. The capacity of LLMs to present erroneous answers in a coherent and semantically rigorous manner further complicates the detection of factual inaccuracies. This issue is especially pronounced in fields that require specialized expertise. Our work delves into these challenges aiming to enhance the understanding and mitigation of such errors thereby contributing to the improvement of LLM accuracy and reliability in scientific and other specialized domains. Our findings reveal a non-linear relationship between the contexts relevancy and the answers measured quality. In addition we demonstrate that with the correct calibration it is possible to automate the grading procedure -- a finding suggesting that at least to some degree the LLMs can be used to self-examine the quality of their own performance. Finally we describe an experimental platform that can be seen as a proof-of-concept of the techniques described in this work.

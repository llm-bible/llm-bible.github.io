---
layout: publication
title: "Perspectives On Large Language Models For Relevance Judgment"
authors: Faggioli Guglielmo, Dietz Laura, Clarke Charles, Demartini Gianluca, Hagen Matthias, Hauff Claudia, Kando Noriko, Kanoulas Evangelos, Potthast Martin, Stein Benno, Wachsmuth Henning
conference: "Arxiv"
year: 2023
bibkey: faggioli2023perspectives
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2304.09161"}
tags: ['GPT', 'Model Architecture', 'Pretraining Methods', 'Reinforcement Learning']
---
When asked large language models (LLMs) like ChatGPT claim that they can assist with relevance judgments but it is not clear whether automated judgments can reliably be used in evaluations of retrieval systems. In this perspectives paper we discuss possible ways for LLMs to support relevance judgments along with concerns and issues that arise. We devise a human--machine collaboration spectrum that allows to categorize different relevance judgment strategies based on how much humans rely on machines. For the extreme point of fully automated judgments we further include a pilot experiment on whether LLM-based relevance judgments correlate with judgments from trained human assessors. We conclude the paper by providing opposing perspectives for and against the use of~LLMs for automatic relevance judgments and a compromise perspective informed by our analyses of the literature our preliminary experimental evidence and our experience as IR researchers.

---
layout: publication
title: 'Enhancing RL Safety With Counterfactual LLM Reasoning'
authors: Dennis Gross, Helge Spieker
conference: "Arxiv"
year: 2024
bibkey: gross2024enhancing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2409.10188"}
tags: ['Responsible AI', 'Agentic', 'Training Techniques', 'Reinforcement Learning']
---
Reinforcement learning (RL) policies may exhibit unsafe behavior and are hard
to explain. We use counterfactual large language model reasoning to enhance RL
policy safety post-training. We show that our approach improves and helps to
explain the RL policy safety.

---
layout: publication
title: 'Mitigating Propensity Bias Of Large Language Models For Recommender Systems'
authors: Guixian Zhang, Guan Yuan, Debo Cheng, Lin Liu, Jiuyong Li, Shichao Zhang
conference: "Arxiv"
year: 2024
bibkey: zhang2024mitigating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2409.20052"}
tags: ['Tools', 'Ethics and Bias', 'RAG', 'Reinforcement Learning', 'RecSys']
---
The rapid development of Large Language Models (LLMs) creates new
opportunities for recommender systems, especially by exploiting the side
information (e.g., descriptions and analyses of items) generated by these
models. However, aligning this side information with collaborative information
from historical interactions poses significant challenges. The inherent biases
within LLMs can skew recommendations, resulting in distorted and potentially
unfair user experiences. On the other hand, propensity bias causes side
information to be aligned in such a way that it often tends to represent all
inputs in a low-dimensional subspace, leading to a phenomenon known as
dimensional collapse, which severely restricts the recommender system's ability
to capture user preferences and behaviours. To address these issues, we
introduce a novel framework named Counterfactual LLM Recommendation (CLLMR).
Specifically, we propose a spectrum-based side information encoder that
implicitly embeds structural information from historical interactions into the
side information representation, thereby circumventing the risk of dimension
collapse. Furthermore, our CLLMR approach explores the causal relationships
inherent in LLM-based recommender systems. By leveraging counterfactual
inference, we counteract the biases introduced by LLMs. Extensive experiments
demonstrate that our CLLMR approach consistently enhances the performance of
various recommender models.

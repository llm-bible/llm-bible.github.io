---
layout: publication
title: A Knowledge-grounded Multimodal Search-based Conversational Agent
authors: Agarwal Shubham, Dusek Ondrej, Konstas Ioannis, Rieser Verena
conference: "Proceedings of the"
year: 2018
bibkey: agarwal2018knowledge
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/1810.11954"}
tags: ['Agentic', 'Applications', 'Multimodal Models']
---
Multimodal search-based dialogue is a challenging new task It extends visually grounded question answering systems into multi-turn conversations with access to an external database. We address this new challenge by learning a neural response generation system from the recently released Multimodal Dialogue (MMD) dataset (Saha et al. 2017). We introduce a knowledge-grounded multimodal conversational model where an encoded knowledge base (KB) representation is appended to the decoder input. Our model substantially outperforms strong baselines in terms of text-based similarity measures (over 9 BLEU points 3 of which are solely due to the use of additional information from the KB.

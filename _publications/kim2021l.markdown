---
layout: publication
title: L45;verse Bidirectional Generation Between Image And Text
authors: Kim Taehoon, Song Gwangmo, Lee Sihaeng, Kim Sangyun, Seo Yewon, Lee Soonyoung, Kim Seung Hwan, Lee Honglak, Bae Kyunghoon
conference: "Arxiv"
year: 2021
bibkey: kim2021l
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2111.11133"}
tags: ['Model Architecture', 'Pretraining Methods', 'RAG', 'Security', 'Tools', 'Transformer']
---
Far beyond learning long45;range interactions of natural language transformers are becoming the de45;facto standard for many vision tasks with their power and scalability. Especially with cross45;modal tasks between image and text vector quantized variational autoencoders (VQ45;VAEs) are widely used to make a raw RGB image into a sequence of feature vectors. To better leverage the correlation between image and text we propose L45;Verse a novel architecture consisting of feature45;augmented variational autoencoder (AugVAE) and bidirectional auto45;regressive transformer (BiART) for image45;to45;text and text45;to45;image generation. Our AugVAE shows the state45;of45;the45;art reconstruction performance on ImageNet1K validation set along with the robustness to unseen images in the wild. Unlike other models BiART can distinguish between image (or text) as a conditional reference and a generation target. L45;Verse can be directly used for image45;to45;text or text45;to45;image generation without any finetuning or extra object detection framework. In quantitative and qualitative experiments L45;Verse shows impressive results against previous methods in both image45;to45;text and text45;to45;image generation on MS45;COCO Captions. We furthermore assess the scalability of L45;Verse architecture on Conceptual Captions and present the initial result of bidirectional vision45;language representation learning on general domain.

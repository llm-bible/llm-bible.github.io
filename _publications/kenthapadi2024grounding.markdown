---
layout: publication
title: 'Grounding And Evaluation For Large Language Models: Practical Challenges And Lessons Learned (survey)'
authors: Krishnaram Kenthapadi, Mehrnoosh Sameki, Ankur Taly
conference: "Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 2024)"
year: 2024
bibkey: kenthapadi2024grounding
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.12858"}
tags: ['Responsible AI', 'Tools', 'Survey Paper', 'Ethics and Bias', 'Interpretability and Explainability', 'Security', 'KDD']
---
With the ongoing rapid adoption of Artificial Intelligence (AI)-based systems
in high-stakes domains, ensuring the trustworthiness, safety, and observability
of these systems has become crucial. It is essential to evaluate and monitor AI
systems not only for accuracy and quality-related metrics but also for
robustness, bias, security, interpretability, and other responsible AI
dimensions. We focus on large language models (LLMs) and other generative AI
models, which present additional challenges such as hallucinations, harmful and
manipulative content, and copyright infringement. In this survey article
accompanying our KDD 2024 tutorial, we highlight a wide range of harms
associated with generative AI systems, and survey state of the art approaches
(along with open challenges) to address these harms.

---
layout: publication
title: 'Large Language Models Penetration In Scholarly Writing And Peer Review'
authors: Li Zhou, Ruijie Zhang, Xunlian Dai, Daniel Hershcovich, Haizhou Li
conference: "Arxiv"
year: 2025
bibkey: zhou2025large
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2502.11193'}
tags: ['Tools', 'Survey Paper', 'Reinforcement Learning', 'Ethics and Bias', 'Interpretability', 'Responsible AI']
---
While the widespread use of Large Language Models (LLMs) brings convenience,
it also raises concerns about the credibility of academic research and
scholarly processes. To better understand these dynamics, we evaluate the
penetration of LLMs across academic workflows from multiple perspectives and
dimensions, providing compelling evidence of their growing influence. We
propose a framework with two components: \texttt\{ScholarLens\}, a curated
dataset of human- and LLM-generated content across scholarly writing and peer
review for multi-perspective evaluation, and \texttt\{LLMetrica\}, a tool for
assessing LLM penetration using rule-based metrics and model-based detectors
for multi-dimensional evaluation. Our experiments demonstrate the effectiveness
of \texttt\{LLMetrica\}, revealing the increasing role of LLMs in scholarly
processes. These findings emphasize the need for transparency, accountability,
and ethical practices in LLM usage to maintain academic credibility.

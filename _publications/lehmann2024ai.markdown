---
layout: publication
title: 'AI Meets The Classroom: When Do Large Language Models Harm Learning?'
authors: Matthias Lehmann, Philipp B. Cornelius, Fabian J. Sting
conference: "Arxiv"
year: 2024
bibkey: lehmann2024ai
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2409.09047'}
tags: ['Fine-Tuning', 'Interpretability and Explainability']
---
The effect of large language models (LLMs) in education is debated: Previous
research shows that LLMs can help as well as hurt learning. In two
pre-registered and incentivized laboratory experiments, we find no effect of
LLMs on overall learning outcomes. In exploratory analyses and a field study,
we provide evidence that the effect of LLMs on learning outcomes depends on
usage behavior. Students who substitute some of their learning activities with
LLMs (e.g., by generating solutions to exercises) increase the volume of topics
they can learn about but decrease their understanding of each topic. Students
who complement their learning activities with LLMs (e.g., by asking for
explanations) do not increase topic volume but do increase their understanding.
We also observe that LLMs widen the gap between students with low and high
prior knowledge. While LLMs show great potential to improve learning, their use
must be tailored to the educational context and students' needs.

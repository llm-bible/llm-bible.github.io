---
layout: publication
title: 'Fine-tuning Llms For Reliable Medical Question-answering Services'
authors: Ali Anaissi, Ali Braytee, Junaid Akram
conference: "Arxiv"
year: 2024
bibkey: anaissi2024fine
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2410.16088"}
tags: ['Efficiency and Optimization', 'Training Techniques', 'RAG', 'Pretraining Methods', 'Fine-Tuning']
---
We present an advanced approach to medical question-answering (QA) services,
using fine-tuned Large Language Models (LLMs) to improve the accuracy and
reliability of healthcare information. Our study focuses on optimizing models
like LLaMA-2 and Mistral, which have shown great promise in delivering precise,
reliable medical answers. By leveraging comprehensive datasets, we applied
fine-tuning techniques such as rsDoRA+ and ReRAG. rsDoRA+ enhances model
performance through a combination of decomposed model weights, varied learning
rates for low-rank matrices, and rank stabilization, leading to improved
efficiency. ReRAG, which integrates retrieval on demand and question rewriting,
further refines the accuracy of the responses. This approach enables healthcare
providers to access fast, dependable information, aiding in more efficient
decision-making and fostering greater patient trust. Our work highlights the
potential of fine-tuned LLMs to significantly improve the quality and
accessibility of medical information services, ultimately contributing to
better healthcare outcomes for all.

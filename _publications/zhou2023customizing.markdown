---
layout: publication
title: Characterglm Customizing Chinese Conversational AI Characters With Large Language Models
authors: Zhou Jinfeng, Chen Zhuang, Wan Dazhen, Wen Bosi, Song Yi, Yu Jifan, Huang Yongkang, Peng Libiao, Yang Jiaming, Xiao Xiyao, Sabour Sahand, Zhang Xiaohan, Hou Wenjing, Zhang Yijia, Dong Yuxiao, Tang Jie, Huang Minlie
conference: "Arxiv"
year: 2023
bibkey: zhou2023customizing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2311.16832"}
tags: ['Agentic', 'Applications', 'GPT', 'Model Architecture', 'Training Techniques']
---
In this paper we present CharacterGLM a series of models built upon ChatGLM with model sizes ranging from 6B to 66B parameters. Our CharacterGLM is designed for generating Character45;based Dialogues (CharacterDial) which aims to equip a conversational AI system with character customization for satisfying peoples inherent social desires and emotional needs. On top of CharacterGLM we can customize various AI characters or social agents by configuring their attributes (identities interests viewpoints experiences achievements social relationships etc.) and behaviors (linguistic features emotional expressions interaction patterns etc.). Our model outperforms most mainstream close45;source large langauge models including the GPT series especially in terms of consistency human45;likeness and engagement according to manual evaluations. We will release our 6B version of CharacterGLM and a subset of training data to facilitate further research development in the direction of character45;based dialogue generation.

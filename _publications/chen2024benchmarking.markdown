---
layout: publication
title: Benchmarking Llms For Translating Classical Chinese Poetryevaluating Adequacy Fluency And Elegance
authors: Chen Andong, Lou Lianzhang, Chen Kehai, Bai Xuefeng, Xiang Yang, Yang Muyun, Zhao Tiejun, Zhang Min
conference: "Arxiv"
year: 2024
bibkey: chen2024benchmarking
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.09945"}
tags: ['Ethics And Bias', 'GPT', 'Model Architecture']
---
Large language models (LLMs) have shown remarkable performance in general translation tasks. However the increasing demand for high45;quality translations that are not only adequate but also fluent and elegant. To assess the extent to which current LLMs can meet these demands we introduce a suitable benchmark for translating classical Chinese poetry into English. This task requires not only adequacy in translating culturally and historically significant content but also a strict adherence to linguistic fluency and poetic elegance. Our study reveals that existing LLMs fall short of this task. To address these issues we propose RAT a textbf123;R125;etrieval45;textbf123;A125;ugmented machine textbf123;T125;ranslation method that enhances the translation process by incorporating knowledge related to classical poetry. Additionally we propose an automatic evaluation metric based on GPT45;4 which better assesses translation quality in terms of adequacy fluency and elegance overcoming the limitations of traditional metrics. Our dataset and code will be made available.

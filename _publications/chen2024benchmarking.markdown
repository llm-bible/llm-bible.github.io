---
layout: publication
title: Benchmarking LLMs for Translating Classical Chinese PoetryEvaluating Adequacy Fluency and Elegance
authors: Chen Andong, Lou Lianzhang, Chen Kehai, Bai Xuefeng, Xiang Yang, Yang Muyun, Zhao Tiejun, Zhang Min
conference: "Arxiv"
year: 2024
bibkey: chen2024benchmarking
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.09945"}
tags: ['ARXIV', 'Ethics And Bias', 'GPT', 'LLM', 'Model Architecture']
---
Large language models (LLMs) have shown remarkable performance in general translation tasks. However the increasing demand for high-quality translations that are not only adequate but also fluent and elegant. To assess the extent to which current LLMs can meet these demands we introduce a suitable benchmark for translating classical Chinese poetry into English. This task requires not only adequacy in translating culturally and historically significant content but also a strict adherence to linguistic fluency and poetic elegance. Our study reveals that existing LLMs fall short of this task. To address these issues we propose RAT a textbfRetrieval-textbfAugmented machine textbfTranslation method that enhances the translation process by incorporating knowledge related to classical poetry. Additionally we propose an automatic evaluation metric based on GPT-4 which better assesses translation quality in terms of adequacy fluency and elegance overcoming the limitations of traditional metrics. Our dataset and code will be made available.

---
layout: publication
title: 'LLMER: Crafting Interactive Extended Reality Worlds With JSON Data Generated By Large Language Models'
authors: Jiangong Chen, Xiaoyi Wu, Tian Lan, Bin Li
conference: "Arxiv"
year: 2025
bibkey: chen2025crafting
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2502.02441'}
tags: ['Efficiency and Optimization', 'GPT', 'Model Architecture', 'Tools', 'Reinforcement Learning']
---
The integration of Large Language Models (LLMs) like GPT-4 with Extended
Reality (XR) technologies offers the potential to build truly immersive XR
environments that interact with human users through natural language, e.g.,
generating and animating 3D scenes from audio inputs. However, the complexity
of XR environments makes it difficult to accurately extract relevant contextual
data and scene/object parameters from an overwhelming volume of XR artifacts.
It leads to not only increased costs with pay-per-use models, but also elevated
levels of generation errors. Moreover, existing approaches focusing on coding
script generation are often prone to generation errors, resulting in flawed or
invalid scripts, application crashes, and ultimately a degraded user
experience. To overcome these challenges, we introduce LLMER, a novel framework
that creates interactive XR worlds using JSON data generated by LLMs. Unlike
prior approaches focusing on coding script generation, LLMER translates natural
language inputs into JSON data, significantly reducing the likelihood of
application crashes and processing latency. It employs a multi-stage strategy
to supply only the essential contextual information adapted to the user's
request and features multiple modules designed for various XR tasks. Our
preliminary user study reveals the effectiveness of the proposed system, with
over 80% reduction in consumed tokens and around 60% reduction in task
completion time compared to state-of-the-art approaches. The analysis of users'
feedback also illuminates a series of directions for further optimization.

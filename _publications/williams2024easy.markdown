---
layout: publication
title: 'Easy Problems That Llms Get Wrong'
authors: Williams Sean, Huckle James
conference: "Arxiv"
year: 2024
bibkey: williams2024easy
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.19616"}
tags: ['Applications', 'Prompting', 'Training Techniques']
---
We introduce a comprehensive Linguistic Benchmark designed to evaluate the
limitations of Large Language Models (LLMs) in domains such as logical
reasoning, spatial intelligence, and linguistic understanding, among others.
Through a series of straightforward questions, it uncovers the significant
limitations of well-regarded models to perform tasks that humans manage with
ease. It also highlights the potential of prompt engineering to mitigate some
errors and underscores the necessity for better training methodologies. Our
findings stress the importance of grounding LLMs with human reasoning and
common sense, emphasising the need for human-in-the-loop for enterprise
applications. We hope this work paves the way for future research to enhance
the usefulness and reliability of new models.

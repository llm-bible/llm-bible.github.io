---
layout: publication
title: How To Plant Trees In Language Models Data And Architectural Effects On The Emergence Of Syntactic Inductive Biases
authors: Mueller Aaron, Linzen Tal
conference: "Arxiv"
year: 2023
bibkey: mueller2023how
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2305.19905"}
tags: ['Ethics And Bias', 'Model Architecture', 'Pretraining Methods', 'Reinforcement Learning', 'Training Techniques', 'Transformer']
---
Accurate syntactic representations are essential for robust generalization in natural language. Recent work has found that pre45;training can teach language models to rely on hierarchical syntactic features 45; as opposed to incorrect linear features 45; when performing tasks after fine45;tuning. We test what aspects of pre45;training are important for endowing encoder45;decoder Transformers with an inductive bias that favors hierarchical syntactic generalizations. We focus on architectural features (depth width and number of parameters) as well as the genre and size of the pre45;training corpus diagnosing inductive biases using two syntactic transformation tasks question formation and passivization both in English. We find that the number of parameters alone does not explain hierarchical generalization model depth plays greater role than model width. We also find that pre45;training on simpler language such as child45;directed speech induces a hierarchical bias using an order45;of45;magnitude less data than pre45;training on more typical datasets based on web text or Wikipedia; this suggests that in cognitively plausible language acquisition settings neural language models may be more data45;efficient than previously thought.

---
layout: publication
title: 'Linguistic Blind Spots Of Large Language Models'
authors: Jiali Cheng, Hadi Amiri
conference: "NAACL 2025 CMCL Workshop"
year: 2025
bibkey: cheng2025linguistic
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2503.19260'}
tags: ['Applications']
---
Large language models (LLMs) are the foundation of many AI applications
today. However, despite their remarkable proficiency in generating coherent
text, questions linger regarding their ability to perform fine-grained
linguistic annotation tasks, such as detecting nouns or verbs, or identifying
more complex syntactic structures like clauses in input texts. These tasks
require precise syntactic and semantic understanding of input text, and when
LLMs underperform on specific linguistic structures, it raises concerns about
their reliability for detailed linguistic analysis and whether their (even
correct) outputs truly reflect an understanding of the inputs. In this paper,
we empirically study the performance of recent LLMs on fine-grained linguistic
annotation tasks. Through a series of experiments, we find that recent LLMs
show limited efficacy in addressing linguistic queries and often struggle with
linguistically complex inputs. We show that the most capable LLM (Llama3-70b)
makes notable errors in detecting linguistic structures, such as misidentifying
embedded clauses, failing to recognize verb phrases, and confusing complex
nominals with clauses. Our results provide insights to inform future
advancements in LLM design and development.

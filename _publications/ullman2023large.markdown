---
layout: publication
title: Large Language Models Fail On Trivial Alterations To Theory45;of45;mind Tasks
authors: Ullman Tomer
conference: "Arxiv"
year: 2023
bibkey: ullman2023large
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2302.08399"}
tags: ['Pretraining Methods', 'RAG']
---
Intuitive psychology is a pillar of common45;sense reasoning. The replication of this reasoning in machine intelligence is an important stepping45;stone on the way to human45;like artificial intelligence. Several recent tasks and benchmarks for examining this reasoning in Large45;Large Models have focused in particular on belief attribution in Theory45;of45;Mind tasks. These tasks have shown both successes and failures. We consider in particular a recent purported success case and show that small variations that maintain the principles of ToM turn the results on their head. We argue that in general the zero45;hypothesis for model evaluation in intuitive psychology should be skeptical and that outlying failure cases should outweigh average success rates. We also consider what possible future successes on Theory45;of45;Mind tasks by more powerful LLMs would mean for ToM tasks with people.

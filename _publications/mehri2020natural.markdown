---
layout: publication
title: Dialoglue A Natural Language Understanding Benchmark For Task45;oriented Dialogue
authors: Mehri Shikib, Eric Mihail, Hakkani-tur Dilek
conference: "Arxiv"
year: 2020
bibkey: mehri2020natural
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2009.13570"}
tags: ['Applications', 'BERT', 'Fine Tuning', 'Model Architecture', 'RAG', 'Training Techniques']
---
A long45;standing goal of task45;oriented dialogue research is the ability to flexibly adapt dialogue models to new domains. To progress research in this direction we introduce DialoGLUE (Dialogue Language Understanding Evaluation) a public benchmark consisting of 7 task45;oriented dialogue datasets covering 4 distinct natural language understanding tasks designed to encourage dialogue research in representation45;based transfer domain adaptation and sample45;efficient task learning. We release several strong baseline models demonstrating performance improvements over a vanilla BERT architecture and state45;of45;the45;art results on 5 out of 7 tasks by pre45;training on a large open45;domain dialogue corpus and task45;adaptive self45;supervised training. Through the DialoGLUE benchmark the baseline methods and our evaluation scripts we hope to facilitate progress towards the goal of developing more general task45;oriented dialogue models.

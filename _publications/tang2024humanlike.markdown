---
layout: publication
title: 'Humanlike Cognitive Patterns As Emergent Phenomena In Large Language Models'
authors: Zhisheng Tang, Mayank Kejriwal
conference: "Arxiv"
year: 2024
bibkey: tang2024humanlike
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2412.15501'}
tags: ['Attention Mechanism', 'GPT', 'Model Architecture', 'Survey Paper', 'Reinforcement Learning', 'Ethics and Bias']
---
Research on emergent patterns in Large Language Models (LLMs) has gained
significant traction in both psychology and artificial intelligence, motivating
the need for a comprehensive review that offers a synthesis of this complex
landscape. In this article, we systematically review LLMs' capabilities across
three important cognitive domains: decision-making biases, reasoning, and
creativity. We use empirical studies drawing on established psychological tests
and compare LLMs' performance to human benchmarks. On decision-making, our
synthesis reveals that while LLMs demonstrate several human-like biases, some
biases observed in humans are absent, indicating cognitive patterns that only
partially align with human decision-making. On reasoning, advanced LLMs like
GPT-4 exhibit deliberative reasoning akin to human System-2 thinking, while
smaller models fall short of human-level performance. A distinct dichotomy
emerges in creativity: while LLMs excel in language-based creative tasks, such
as storytelling, they struggle with divergent thinking tasks that require
real-world context. Nonetheless, studies suggest that LLMs hold considerable
potential as collaborators, augmenting creativity in human-machine
problem-solving settings. Discussing key limitations, we also offer guidance
for future research in areas such as memory, attention, and open-source model
development.

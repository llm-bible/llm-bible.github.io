---
layout: publication
title: 'Cops: Empowering LLM Agents With Provable Cross-task Experience Sharing'
authors: Chen Yang, Chenyang Zhao, Quanquan Gu, Dongruo Zhou
conference: "Arxiv"
year: 2024
bibkey: yang2024empowering
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2410.16670'}
  - {name: "Code", url: 'https://github.com/uclaml/COPS}{{https://github.com/uclaml/COPS'}
tags: ['Agentic', 'Has Code', 'RAG', 'Efficiency and Optimization', 'Reinforcement Learning']
---
Sequential reasoning in agent systems has been significantly advanced by
large language models (LLMs), yet existing approaches face limitations.
Reflection-driven reasoning relies solely on knowledge in pretrained models,
limiting performance in novel scenarios, while experience-assisted reasoning
often depends on external experiences and lacks clear principles for selecting
representative experiences. We address these limitations by proposing CoPS
(Cross-Task Experience Sharing), a generalizable algorithm that enhances
sequential reasoning by cross-task experience sharing and selection. In detail,
CoPS leverages agents' experiences on previous tasks, selecting
distribution-matched experiences via a provable pessimism-based strategy to
maximize utility while minimizing risks from distribution shifts. Extensive
experimental results on benchmarks like Alfworld, Webshop, and HotPotQA
demonstrate that CoPS consistently outperforms state-of-the-art baselines, with
superior sample efficiency suitable for resource-constrained scenarios.
Theoretically, we show that the performance of our algorithm depends on both
the quality of the pretrained LLM and the matching between the agent's
task-dependent trial distribution and that generated by the LLM. Our work
bridges the gap between existing sequential reasoning paradigms and validates
the effectiveness of leveraging cross-task experiences, shedding light on the
potential to improve agents' generalization and adaptability across diverse
tasks. Our codes are available at
\\(\href\{https://github.com/uclaml/COPS\}\{\text\{https://github.com/uclaml/COPS\}\}\\).

---
layout: publication
title: Making Long45;context Language Models Better Multi45;hop Reasoners
authors: Li Yanyang, Liang Shuo, Lyu Michael R., Wang Liwei
conference: "Arxiv"
year: 2024
bibkey: li2024making
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.03246"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Pretraining Methods', 'Prompting', 'Training Techniques']
---
Recent advancements in long45;context modeling have enhanced language models (LMs) for complex tasks across multiple NLP applications. Despite this progress we find that these models struggle with multi45;hop reasoning and exhibit decreased performance in the presence of noisy contexts. In this paper we introduce Reasoning with Attributions a novel approach that prompts LMs to supply attributions for each assertion during their reasoning. We validate our approach through experiments on three multi45;hop datasets employing both proprietary and open45;source models and demonstrate its efficacy and resilience. Furthermore we explore methods to augment reasoning capabilities via fine45;tuning and offer an attribution45;annotated dataset and a specialized training strategy. Our fine45;tuned model achieves competitive performance on multi45;hop reasoning benchmarks closely paralleling proprietary LMs such as ChatGPT and Claude45;instant.

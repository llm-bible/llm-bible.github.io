---
layout: publication
title: M45;QALM A Benchmark To Assess Clinical Reading Comprehension And Knowledge Recall In Large Language Models Via Question Answering
authors: Subramanian Anand, Schlegel Viktor, Kashyap Abhinav Ramesh, Nguyen Thanh-tung, Dwivedi Vijay Prakash, Winkler Stefan
conference: "Arxiv"
year: 2024
bibkey: subramanian2024m
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.03699"}
tags: ['Applications', 'Model Architecture', 'RAG']
---
There is vivid research on adapting Large Language Models (LLMs) to perform a variety of tasks in high45;stakes domains such as healthcare. Despite their popularity there is a lack of understanding of the extent and contributing factors that allow LLMs to recall relevant knowledge and combine it with presented information in the clinical and biomedical domain a fundamental pre45;requisite for success on down45;stream tasks. Addressing this gap we use Multiple Choice and Abstractive Question Answering to conduct a large45;scale empirical study on 22 datasets in three generalist and three specialist biomedical sub45;domains. Our multifaceted analysis of the performance of 15 LLMs further broken down by sub45;domain source of knowledge and model architecture uncovers success factors such as instruction tuning that lead to improved recall and comprehension. We further show that while recently proposed domain45;adapted models may lack adequate knowledge directly fine45;tuning on our collected medical knowledge datasets shows encouraging results even generalising to unseen specialist sub45;domains. We complement the quantitative results with a skill45;oriented manual error analysis which reveals a significant gap between the models capabilities to simply recall necessary knowledge and to integrate it with the presented context. To foster research and collaboration in this field we share M45;QALM our resources standardised methodology and evaluation results with the research community to facilitate further advancements in clinical knowledge representation learning within language models.

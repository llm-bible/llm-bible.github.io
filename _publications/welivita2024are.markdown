---
layout: publication
title: 'Are Large Language Models More Empathetic Than Humans?'
authors: Anuradha Welivita, Pearl Pu
conference: "Arxiv"
year: 2024
bibkey: welivita2024are
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.05063"}
tags: ['Tools', 'GPT', 'Survey Paper', 'Model Architecture', 'Prompting']
---
With the emergence of large language models (LLMs), investigating if they can
surpass humans in areas such as emotion recognition and empathetic responding
has become a focal point of research. This paper presents a comprehensive study
exploring the empathetic responding capabilities of four state-of-the-art LLMs:
GPT-4, LLaMA-2-70B-Chat, Gemini-1.0-Pro, and Mixtral-8x7B-Instruct in
comparison to a human baseline. We engaged 1,000 participants in a
between-subjects user study, assessing the empathetic quality of responses
generated by humans and the four LLMs to 2,000 emotional dialogue prompts
meticulously selected to cover a broad spectrum of 32 distinct positive and
negative emotions. Our findings reveal a statistically significant superiority
of the empathetic responding capability of LLMs over humans. GPT-4 emerged as
the most empathetic, marking approximately 31% increase in responses rated as
"Good" compared to the human benchmark. It was followed by LLaMA-2,
Mixtral-8x7B, and Gemini-Pro, which showed increases of approximately 24%, 21%,
and 10% in "Good" ratings, respectively. We further analyzed the response
ratings at a finer granularity and discovered that some LLMs are significantly
better at responding to specific emotions compared to others. The suggested
evaluation framework offers a scalable and adaptable approach for assessing the
empathy of new LLMs, avoiding the need to replicate this study's findings in
future research.

---
layout: publication
title: Are Large Language Models More Empathetic Than Humans
authors: Welivita Anuradha, Pu Pearl
conference: "Arxiv"
year: 2024
bibkey: welivita2024are
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.05063"}
tags: ['Ethics And Bias', 'GPT', 'Model Architecture', 'Prompting', 'Survey Paper', 'Tools']
---
With the emergence of large language models (LLMs) investigating if they can surpass humans in areas such as emotion recognition and empathetic responding has become a focal point of research. This paper presents a comprehensive study exploring the empathetic responding capabilities of four state45;of45;the45;art LLMs GPT45;4 LLaMA45;245;70B45;Chat Gemini45;1.045;Pro and Mixtral45;8x7B45;Instruct in comparison to a human baseline. We engaged 1000 participants in a between45;subjects user study assessing the empathetic quality of responses generated by humans and the four LLMs to 2000 emotional dialogue prompts meticulously selected to cover a broad spectrum of 32 distinct positive and negative emotions. Our findings reveal a statistically significant superiority of the empathetic responding capability of LLMs over humans. GPT45;4 emerged as the most empathetic marking approximately 3137; increase in responses rated as Good compared to the human benchmark. It was followed by LLaMA45;2 Mixtral45;8x7B and Gemini45;Pro which showed increases of approximately 2437; 2137; and 1037; in Good ratings respectively. We further analyzed the response ratings at a finer granularity and discovered that some LLMs are significantly better at responding to specific emotions compared to others. The suggested evaluation framework offers a scalable and adaptable approach for assessing the empathy of new LLMs avoiding the need to replicate this studys findings in future research.

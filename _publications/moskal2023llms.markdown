---
layout: publication
title: 'Llms Killed The Script Kiddie: How Agents Supported By Large Language Models Change The Landscape Of Network Threat Testing'
authors: Moskal Stephen, Laney Sam, Hemberg Erik, O'reilly Una-may
conference: "Arxiv"
year: 2023
bibkey: moskal2023llms
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.06936"}
tags: ['Agentic', 'Fine Tuning', 'Prompting', 'Reinforcement Learning', 'Security', 'Tools']
---
In this paper we explore the potential of Large Language Models (LLMs) to reason about threats generate information about tools and automate cyber campaigns. We begin with a manual exploration of LLMs in supporting specific threat-related actions and decisions. We proceed by automating the decision process in a cyber campaign. We present prompt engineering approaches for a plan-act-report loop for one action of a threat campaign and and a prompt chaining design that directs the sequential decision process of a multi-action campaign. We assess the extent of LLMs cyber-specific knowledge w.r.t the short campaign we demonstrate and provide insights into prompt design for eliciting actionable responses. We discuss the potential impact of LLMs on the threat landscape and the ethical considerations of using LLMs for accelerating threat actor capabilities. We report a promising yet concerning application of generative AI to cyber threats. However the LLMs capabilities to deal with more complex networks sophisticated vulnerabilities and the sensitivity of prompts are open questions. This research should spur deliberations over the inevitable advancements in LLM-supported cyber adversarial landscape.

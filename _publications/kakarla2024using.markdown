---
layout: publication
title: 'Using Large Language Models To Assess Tutors'' Performance In Reacting To Students Making Math Errors'
authors: Sanjit Kakarla, Danielle Thomas, Jionghao Lin, Shivang Gupta, Kenneth R. Koedinger
conference: "Arxiv"
year: 2024
bibkey: kakarla2024using
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2401.03238'}
tags: ['Attention Mechanism', 'GPT', 'Model Architecture']
---
Research suggests that tutors should adopt a strategic approach when
addressing math errors made by low-efficacy students. Rather than drawing
direct attention to the error, tutors should guide the students to identify and
correct their mistakes on their own. While tutor lessons have introduced this
pedagogical skill, human evaluation of tutors applying this strategy is arduous
and time-consuming. Large language models (LLMs) show promise in providing
real-time assessment to tutors during their actual tutoring sessions, yet
little is known regarding their accuracy in this context. In this study, we
investigate the capacity of generative AI to evaluate real-life tutors'
performance in responding to students making math errors. By analyzing 50
real-life tutoring dialogues, we find both GPT-3.5-Turbo and GPT-4 demonstrate
proficiency in assessing the criteria related to reacting to students making
errors. However, both models exhibit limitations in recognizing instances where
the student made an error. Notably, GPT-4 tends to overidentify instances of
students making errors, often attributing student uncertainty or inferring
potential errors where human evaluators did not. Future work will focus on
enhancing generalizability by assessing a larger dataset of dialogues and
evaluating learning transfer. Specifically, we will analyze the performance of
tutors in real-life scenarios when responding to students' math errors before
and after lesson completion on this crucial tutoring skill.

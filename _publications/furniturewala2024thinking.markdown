---
layout: publication
title: Thinking Fair And Slow On The Efficacy Of Structured Prompts For Debiasing Language Models
authors: Furniturewala Shaz, Jandial Surgan, Java Abhinav, Banerjee Pragyan, Shahid Simra, Bhatia Sumit, Jaidka Kokil
conference: "Arxiv"
year: 2024
bibkey: furniturewala2024thinking
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.10431"}
tags: ['Applications', 'Ethics And Bias', 'Language Modeling', 'Prompting', 'Reinforcement Learning', 'Tools', 'Training Techniques']
---
Existing debiasing techniques are typically training45;based or require access to the models internals and output distributions so they are inaccessible to end45;users looking to adapt LLM outputs for their particular needs. In this study we examine whether structured prompting techniques can offer opportunities for fair text generation. We evaluate a comprehensive end45;user45;focused iterative framework of debiasing that applies System 2 thinking processes for prompts to induce logical reflective and critical text generation with single multi45;step instruction and role45;based variants. By systematically evaluating many LLMs across many datasets and different prompting strategies we show that the more complex System 245;based Implicative Prompts significantly improve over other techniques demonstrating lower mean bias in the outputs with competitive performance on the downstream tasks. Our work offers research directions for the design and the potential of end45;user45;focused evaluative frameworks for LLM use.

---
layout: publication
title: 'Policy Guided Tree Search For Enhanced LLM Reasoning'
authors: Yang Li
conference: "Arxiv"
year: 2025
bibkey: li2025policy
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.06813"}
tags: ['Agentic', 'Tools', 'Reinforcement Learning', 'Fine-Tuning', 'Prompting']
---
Despite their remarkable capabilities, large language models often struggle
with tasks requiring complex reasoning and planning. While existing approaches
like Chain-of-Thought prompting and tree search techniques show promise, they
are limited by their reliance on predefined heuristics and computationally
expensive exploration strategies. We propose Policy-Guided Tree Search (PGTS),
a framework that combines reinforcement learning with structured tree
exploration to efficiently navigate reasoning paths. Our key innovation is a
learned policy that dynamically decides between expanding, branching,
backtracking, or terminating exploration, eliminating the need for manual
heuristics or exhaustive search. Experiments across mathematical reasoning,
logical deduction, and planning benchmarks demonstrate that PGTS achieves
superior reasoning performance while significantly reducing computational costs
compared to existing methods. These results establish PGTS as a scalable and
effective solution for tackling complex reasoning tasks with LLMs.

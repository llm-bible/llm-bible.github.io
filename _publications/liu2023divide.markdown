---
layout: publication
title: Divide And Prompt Chain Of Thought Prompting For Text45;to45;sql
authors: Liu Xiping, Tan Zhao
conference: "Arxiv"
year: 2023
bibkey: liu2023divide
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2304.11556"}
tags: ['Pretraining Methods', 'Prompting', 'RAG']
---
Chain45;of45;thought (CoT) prompting combined with large language models (LLMs) have achieved encouraging results on complex reasoning tasks. Text45;to45;SQL is a critical semantic parsing task that converts natural language questions into SQL statements involving a complex reasoning process. However there is little work about using CoT prompting to activate LLMs reasoning capabilities on Text45;to45;SQL tasks. In this work we propose a new paradigm for prompting Text45;to45;SQL tasks called Divide45;and45;Prompt which first divides the task into subtasks and then approach each subtask through CoT. We present 3 prompting45;based methods to enhance the Text45;to45;SQL ability of LLMs. Experiments show that these prompts guide LLMs to generate Text45;to45;SQL with higher execution accuracy.

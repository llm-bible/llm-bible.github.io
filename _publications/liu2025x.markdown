---
layout: publication
title: 'X-driver: Explainable Autonomous Driving With Vision-language Models'
authors: Wei Liu, Jiyuan Zhang, Binxiong Zheng, Yufeng Hu, Yingzhan Lin, Zengfeng Zeng
conference: "Arxiv"
year: 2025
bibkey: liu2025x
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2505.05098"}
tags: ['Tools', 'GPT', 'Interpretability and Explainability', 'RAG', 'Language Modeling', 'Reinforcement Learning', 'Pretraining Methods', 'Multimodal Models']
---
End-to-end autonomous driving has advanced significantly, offering benefits such as system simplicity and stronger driving performance in both open-loop and closed-loop settings than conventional pipelines. However, existing frameworks still suffer from low success rates in closed-loop evaluations, highlighting their limitations in real-world deployment. In this paper, we introduce X-Driver, a unified multi-modal large language models(MLLMs) framework designed for closed-loop autonomous driving, leveraging Chain-of-Thought(CoT) and autoregressive modeling to enhance perception and decision-making. We validate X-Driver across multiple autonomous driving tasks using public benchmarks in CARLA simulation environment, including Bench2Drive[6]. Our experimental results demonstrate superior closed-loop performance, surpassing the current state-of-the-art(SOTA) while improving the interpretability of driving decisions. These findings underscore the importance of structured reasoning in end-to-end driving and establish X-Driver as a strong baseline for future research in closed-loop autonomous driving.

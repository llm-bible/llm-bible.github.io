---
layout: publication
title: ModelGPT Unleashing LLMs Capabilities for Tailored Model Generation
authors: Tang Zihao, Lv Zheqi, Zhang Shengyu, Wu Fei, Kuang Kun
conference: "Arxiv"
year: 2024
bibkey: tang2024modelgpt
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.12408"}
  - {name: "Code", url: "https://github.com/IshiKura-a/ModelGPT"}
tags: ['ARXIV', 'Applications', 'Has Code']
---
The rapid advancement of Large Language Models (LLMs) has revolutionized various sectors by automating routine tasks marking a step toward the realization of Artificial General Intelligence (AGI). However they still struggle to accommodate the diverse and specific needs of users and simplify the utilization of AI models for the average user. In response we propose ModelGPT a novel framework designed to determine and generate AI models specifically tailored to the data or task descriptions provided by the user leveraging the capabilities of LLMs. Given user requirements ModelGPT is able to provide tailored models at most 270x faster than the previous paradigms (e.g. all-parameter or LoRA finetuning). Comprehensive experiments on NLP CV and Tabular datasets attest to the effectiveness of our framework in making AI models more accessible and user-friendly. Our code is available at https://github.com/IshiKura-a/ModelGPT.

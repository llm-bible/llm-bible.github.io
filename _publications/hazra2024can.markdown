---
layout: publication
title: 'Can Large Language Models Reason? A Characterization Via 3-SAT'
authors: Hazra Rishi, Venturato Gabriele, Martires Pedro Zuidberg Dos, De Raedt Luc
conference: "Arxiv"
year: 2024
bibkey: hazra2024can
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.07215"}
tags: ['Training Techniques', 'Uncategorized']
---
Large Language Models (LLMs) are said to possess advanced reasoning
abilities. However, some skepticism exists as recent works show how LLMs often
bypass true reasoning using shortcuts. Current methods for assessing the
reasoning abilities of LLMs typically rely on open-source benchmarks that may
be overrepresented in LLM training data, potentially skewing performance. We
instead provide a computational theory perspective of reasoning, using 3-SAT --
the prototypical NP-complete problem that lies at the core of logical reasoning
and constraint satisfaction tasks. By examining the phase transitions in 3-SAT,
we empirically characterize the reasoning abilities of LLMs and show how they
vary with the inherent hardness of the problems. Our experimental evidence
shows that LLMs cannot perform true reasoning, as is required for solving 3-SAT
problems.

---
layout: publication
title: Can Large Language Models Reason A Characterization Via 345;SAT
authors: Hazra Rishi, Venturato Gabriele, Martires Pedro Zuidberg Dos, De Raedt Luc
conference: "Arxiv"
year: 2024
bibkey: hazra2024can
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.07215"}
tags: ['Pretraining Methods', 'Training Techniques']
---
Large Language Models (LLMs) are said to possess advanced reasoning abilities. However some skepticism exists as recent works show how LLMs often bypass true reasoning using shortcuts. Current methods for assessing the reasoning abilities of LLMs typically rely on open45;source benchmarks that may be overrepresented in LLM training data potentially skewing performance. We instead provide a computational theory perspective of reasoning using 345;SAT 45;45; the prototypical NP45;complete problem that lies at the core of logical reasoning and constraint satisfaction tasks. By examining the phase transitions in 345;SAT we empirically characterize the reasoning abilities of LLMs and show how they vary with the inherent hardness of the problems. Our experimental evidence shows that LLMs cannot perform true reasoning as is required for solving 345;SAT problems.

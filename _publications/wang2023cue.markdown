---
layout: publication
title: Cue45;cot Chain45;of45;thought Prompting For Responding To In45;depth Dialogue Questions With Llms
authors: Wang Hongru, Wang Rui, Mi Fei, Deng Yang, Wang Zezhong, Liang Bin, Xu Ruifeng, Wong Kam-fai
conference: "Arxiv"
year: 2023
bibkey: wang2023cue
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2305.11792"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Prompting', 'Reinforcement Learning']
---
Large Language Models (LLMs) such as texttt123;ChatGPT125; greatly empower dialogue systems with strong language understanding and generation capabilities. However most of the previous works prompt the LLMs to directly generate a response based on the dialogue context overlooking the underlying linguistic cues about the user status exhibited in the context. Such in45;depth dialogue scenarios are challenging for existing LLMs to figure out the users hidden needs and respond satisfactorily through a single45;step inference. To this end we propose a novel linguistic cue45;based chain45;of45;thoughts (textit123;Cue125;45;CoT) which enhances the LLMs inference with an intermediate reasoning step to find cues exhibited in the dialogue aiming to provide a more personalized and engaging response. To evaluate the approach we build a benchmark with in45;depth dialogue questions consisting of 6 datasets in both Chinese and English targeting 3 major linguistic cues during the conversation textit123;personality125; textit123;emotion125; and textit123;psychology125;. We conduct extensive experiments on the proposed benchmark with 5 LLMs under both zero45;shot and one45;shot settings. Empirical results demonstrate our proposed textit123;Cue125;45;CoT method outperforms standard prompting methods in terms of both textit123;helpfulness125; and textit123;acceptability125; on all datasets.

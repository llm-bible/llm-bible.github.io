---
layout: publication
title: 'Heuristics And Biases In AI Decision-making: Implications For Responsible AGI'
authors: Payam Saeedi, Mahsa Goodarzi, M Abdullah Canbaz
conference: "Arxiv"
year: 2024
bibkey: saeedi2024heuristics
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2410.02820'}
tags: ['Ethics and Bias', 'GPT', 'Model Architecture']
---
We investigate the presence of cognitive biases in three large language
models (LLMs): GPT-4o, Gemma 2, and Llama 3.1. The study uses 1,500 experiments
across nine established cognitive biases to evaluate the models' responses and
consistency. GPT-4o demonstrated the strongest overall performance. Gemma 2
showed strengths in addressing the sunk cost fallacy and prospect theory,
however its performance varied across different biases. Llama 3.1 consistently
underperformed, relying on heuristics and exhibiting frequent inconsistencies
and contradictions. The findings highlight the challenges of achieving robust
and generalizable reasoning in LLMs, and underscore the need for further
development to mitigate biases in artificial general intelligence (AGI). The
study emphasizes the importance of integrating statistical reasoning and
ethical considerations in future AI development.

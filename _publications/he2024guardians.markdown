---
layout: publication
title: 'Guardians Of Discourse: Evaluating Llms On Multilingual Offensive Language Detection'
authors: Jianfei He, Lilin Wang, Jiaying Wang, Zhenyu Liu, Hongbin Na, Zimu Wang, Wei Wang, Qi Chen
conference: "Arxiv"
year: 2024
bibkey: he2024guardians
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2410.15623"}
tags: ['Responsible AI', 'GPT', 'Ethics and Bias', 'RAG', 'Model Architecture', 'Reinforcement Learning', 'Prompting']
---
Identifying offensive language is essential for maintaining safety and
sustainability in the social media era. Though large language models (LLMs)
have demonstrated encouraging potential in social media analytics, they lack
thorough evaluation when in offensive language detection, particularly in
multilingual environments. We for the first time evaluate multilingual
offensive language detection of LLMs in three languages: English, Spanish, and
German with three LLMs, GPT-3.5, Flan-T5, and Mistral, in both monolingual and
multilingual settings. We further examine the impact of different prompt
languages and augmented translation data for the task in non-English contexts.
Furthermore, we discuss the impact of the inherent bias in LLMs and the
datasets in the mispredictions related to sensitive topics.

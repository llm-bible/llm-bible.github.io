---
layout: publication
title: Good, Better, Best&#58; Textual Distractors Generation For Multiple-choice Visual Question Answering Via Reinforcement Learning
authors: Lu Jiaying, Ye Xin, Ren Yi, Yang Yezhou
conference: "CVPR"
year: 2019
bibkey: lu2019textual
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/1910.09134"}
tags: ['Agentic', 'Applications', 'Attention Mechanism', 'Model Architecture', 'Reinforcement Learning', 'Security', 'Tools', 'Training Techniques']
---
Multiple-choice VQA has drawn increasing attention from researchers and end-users recently. As the demand for automatically constructing large-scale multiple-choice VQA data grows we introduce a novel task called textual Distractors Generation for VQA (DG-VQA) focusing on generating challenging yet meaningful distractors given the context image question and correct answer. The DG-VQA task aims at generating distractors without ground-truth training samples since such resources are rarely available. To tackle the DG-VQA unsupervisedly we propose Gobbet a reinforcement learning(RL) based framework that utilizes pre-trained VQA models as an alternative knowledge base to guide the distractor generation process. In Gobbet a pre-trained VQA model serves as the environment in RL setting to provide feedback for the input multi-modal query while a neural distractor generator serves as the agent to take actions accordingly. We propose to use existing VQA models performance degradation as indicators of the quality of generated distractors. On the other hand we show the utility of generated distractors through data augmentation experiments since robustness is more and more important when AI models apply to unpredictable open-domain scenarios or security-sensitive applications. We further conduct a manual case study on the factors why distractors generated by Gobbet can fool existing models.

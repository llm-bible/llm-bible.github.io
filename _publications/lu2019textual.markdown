---
layout: publication
title: 'Good, Better, Best: Textual Distractors Generation For Multiple-choice Visual Question Answering Via Reinforcement Learning'
authors: Jiaying Lu, Xin Ye, Yi Ren, Yezhou Yang
conference: "CVPR2022 Workshop on Open-Domain Retrieval Under a Multi-Modal Setting"
year: 2019
bibkey: lu2019textual
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/1910.09134"}
tags: ['Agentic', 'Security', 'Model Architecture', 'Training Techniques', 'Tools', 'Reinforcement Learning', 'Applications', 'Attention Mechanism']
---
Multiple-choice VQA has drawn increasing attention from researchers and
end-users recently. As the demand for automatically constructing large-scale
multiple-choice VQA data grows, we introduce a novel task called textual
Distractors Generation for VQA (DG-VQA) focusing on generating challenging yet
meaningful distractors given the context image, question, and correct answer.
The DG-VQA task aims at generating distractors without ground-truth training
samples since such resources are rarely available. To tackle the DG-VQA
unsupervisedly, we propose Gobbet, a reinforcement learning(RL) based framework
that utilizes pre-trained VQA models as an alternative knowledge base to guide
the distractor generation process. In Gobbet, a pre-trained VQA model serves as
the environment in RL setting to provide feedback for the input multi-modal
query, while a neural distractor generator serves as the agent to take actions
accordingly. We propose to use existing VQA models' performance degradation as
indicators of the quality of generated distractors. On the other hand, we show
the utility of generated distractors through data augmentation experiments,
since robustness is more and more important when AI models apply to
unpredictable open-domain scenarios or security-sensitive applications. We
further conduct a manual case study on the factors why distractors generated by
Gobbet can fool existing models.

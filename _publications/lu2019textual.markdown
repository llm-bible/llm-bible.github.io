---
layout: publication
title: Good Better Best Textual Distractors Generation For Multiple45;choice Visual Question Answering Via Reinforcement Learning
authors: Lu Jiaying, Ye Xin, Ren Yi, Yang Yezhou
conference: "CVPR"
year: 2019
bibkey: lu2019textual
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/1910.09134"}
tags: ['Agentic', 'Applications', 'Attention Mechanism', 'Model Architecture', 'Reinforcement Learning', 'Security', 'Tools', 'Training Techniques']
---
Multiple45;choice VQA has drawn increasing attention from researchers and end45;users recently. As the demand for automatically constructing large45;scale multiple45;choice VQA data grows we introduce a novel task called textual Distractors Generation for VQA (DG45;VQA) focusing on generating challenging yet meaningful distractors given the context image question and correct answer. The DG45;VQA task aims at generating distractors without ground45;truth training samples since such resources are rarely available. To tackle the DG45;VQA unsupervisedly we propose Gobbet a reinforcement learning(RL) based framework that utilizes pre45;trained VQA models as an alternative knowledge base to guide the distractor generation process. In Gobbet a pre45;trained VQA model serves as the environment in RL setting to provide feedback for the input multi45;modal query while a neural distractor generator serves as the agent to take actions accordingly. We propose to use existing VQA models performance degradation as indicators of the quality of generated distractors. On the other hand we show the utility of generated distractors through data augmentation experiments since robustness is more and more important when AI models apply to unpredictable open45;domain scenarios or security45;sensitive applications. We further conduct a manual case study on the factors why distractors generated by Gobbet can fool existing models.

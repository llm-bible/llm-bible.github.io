---
layout: publication
title: Check Your Facts And Try Again Improving Large Language Models With External Knowledge And Automated Feedback
authors: Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng, Yujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou Yu, Weizhu Chen, Jianfeng Gao
conference: "Arxiv"
year: 2023
bibkey: peng2023check
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/http://arxiv.org/abs/2302.12813v3"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Prompting', 'Reinforcement Learning']
---
Large language models (LLMs) such as ChatGPT are able to generate human45;like fluent responses for many downstream tasks e.g. task45;oriented dialog and question answering. However applying LLMs to real45;world mission45;critical applications remains challenging mainly due to their tendency to generate hallucinations and their inability to use external knowledge. This paper proposes a LLM45;Augmenter system which augments a black45;box LLM with a set of plug45;and45;play modules. Our system makes the LLM generate responses grounded in external knowledge e.g. stored in task45;specific databases. It also iteratively revises LLM prompts to improve model responses using feedback generated by utility functions e.g. the factuality score of a LLM45;generated response. The effectiveness of LLM45;Augmenter is empirically validated on two types of scenarios task45;oriented dialog and open45;domain question answering. LLM45;Augmenter significantly reduces ChatGPTs hallucinations without sacrificing the fluency and informativeness of its responses. We make the source code and models publicly available.

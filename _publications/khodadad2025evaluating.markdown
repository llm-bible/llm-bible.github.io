---
layout: publication
title: 'Evaluating Multi-hop Reasoning In Large Language Models: A Chemistry-centric Case Study'
authors: Mohammad Khodadad, Ali Shiraee Kasmaee, Mahdi Astaraki, Nicholas Sherck, Hamidreza Mahyar, Soheila Samiee
conference: "Arxiv"
year: 2025
bibkey: khodadad2025evaluating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2504.16414"}
tags: ['COLING', 'Applications']
---
In this study, we introduced a new benchmark consisting of a curated dataset
and a defined evaluation process to assess the compositional reasoning
capabilities of large language models within the chemistry domain. We designed
and validated a fully automated pipeline, verified by subject matter experts,
to facilitate this task. Our approach integrates OpenAI reasoning models with
named entity recognition (NER) systems to extract chemical entities from recent
literature, which are then augmented with external knowledge bases to form a
comprehensive knowledge graph. By generating multi-hop questions across these
graphs, we assess LLM performance in both context-augmented and non-context
augmented settings. Our experiments reveal that even state-of-the-art models
face significant challenges in multi-hop compositional reasoning. The results
reflect the importance of augmenting LLMs with document retrieval, which can
have a substantial impact on improving their performance. However, even perfect
retrieval accuracy with full context does not eliminate reasoning errors,
underscoring the complexity of compositional reasoning. This work not only
benchmarks and highlights the limitations of current LLMs but also presents a
novel data generation pipeline capable of producing challenging reasoning
datasets across various domains. Overall, this research advances our
understanding of reasoning in computational linguistics.

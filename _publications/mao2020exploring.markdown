---
layout: publication
title: 'Dialoguetrm: Exploring The Intra- And Inter-modal Emotional Behaviors In The
  Conversation'
authors: Yuzhao Mao et al.
conference: Arxiv
year: 2020
citations: 17
bibkey: mao2020exploring
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2010.07637'}]
tags: [Transformer, Multimodal Models]
---
Emotion Recognition in Conversations (ERC) is essential for building
empathetic human-machine systems. Existing studies on ERC primarily focus on
summarizing the context information in a conversation, however, ignoring the
differentiated emotional behaviors within and across different modalities.
Designing appropriate strategies that fit the differentiated multi-modal
emotional behaviors can produce more accurate emotional predictions. Thus, we
propose the DialogueTransformer to explore the differentiated emotional
behaviors from the intra- and inter-modal perspectives. For intra-modal, we
construct a novel Hierarchical Transformer that can easily switch between
sequential and feed-forward structures according to the differentiated context
preference within each modality. For inter-modal, we constitute a novel
Multi-Grained Interactive Fusion that applies both neuron- and vector-grained
feature interactions to learn the differentiated contributions across all
modalities. Experimental results show that DialogueTRM outperforms the
state-of-the-art by a significant margin on three benchmark datasets.
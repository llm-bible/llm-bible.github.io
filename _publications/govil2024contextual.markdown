---
layout: publication
title: COBIAS Contextual Reliability In Bias Assessment
authors: Govil Priyanshul, Jain Hemang, Bonagiri Vamshi Krishna, Chadha Aman, Kumaraguru Ponnurangam, Gaur Manas, Dey Sanorita
conference: "Arxiv"
year: 2024
bibkey: govil2024contextual
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.14889"}
tags: ['Bias Mitigation', 'Ethics And Bias', 'Fine Tuning', 'Training Techniques']
---
Large Language Models (LLMs) are trained on extensive web corpora which enable them to understand and generate human45;like text. However this training process also results in inherent biases within the models. These biases arise from web datas diverse and often uncurated nature containing various stereotypes and prejudices. Previous works on debiasing models rely on benchmark datasets to measure their methods performance. However these datasets suffer from several pitfalls due to the highly subjective understanding of bias highlighting a critical need for contextual exploration. We propose understanding the context of inputs by considering the diverse situations in which they may arise. Our contribution is two45;fold (i) we augment 2291 stereotyped statements from two existing bias45;benchmark datasets with points for adding context; (ii) we develop the Context45;Oriented Bias Indicator and Assessment Score (COBIAS) to assess a statements contextual reliability in measuring bias. Our metric aligns with human judgment on contextual reliability of statements (Spearmans œÅ = 0.65 p = 3.4 10^123;45;60125;) and can be used to create reliable datasets which would assist bias mitigation works.

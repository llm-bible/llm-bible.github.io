---
layout: publication
title: Lumina45;next Making Lumina45;t2x Stronger And Faster With Next45;dit
authors: Zhuo Le, Du Ruoyi, Xiao Han, Li Yangguang, Liu Dongyang, Huang Rongjie, Liu Wenze, Zhao Lirui, Wang Fu-yun, Ma Zhanyu, Luo Xu, Wang Zehan, Zhang Kaipeng, Zhu Xiangyang, Liu Si, Yue Xiangyu, Liu Dingning, Ouyang Wanli, Liu Ziwei, Qiao Yu, Li Hongsheng, Gao Peng
conference: "Arxiv"
year: 2024
bibkey: zhuo2024lumina
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.18583"}
tags: ['Efficiency And Optimization', 'Merging', 'Model Architecture', 'Pretraining Methods', 'Tools', 'Training Techniques', 'Transformer']
---
Lumina45;T2X is a nascent family of Flow45;based Large Diffusion Transformers that establishes a unified framework for transforming noise into various modalities such as images and videos conditioned on text instructions. Despite its promising capabilities Lumina45;T2X still encounters challenges including training instability slow inference and extrapolation artifacts. In this paper we present Lumina45;Next an improved version of Lumina45;T2X showcasing stronger generation performance with increased training and inference efficiency. We begin with a comprehensive analysis of the Flag45;DiT architecture and identify several suboptimal components which we address by introducing the Next45;DiT architecture with 3D RoPE and sandwich normalizations. To enable better resolution extrapolation we thoroughly compare different context extrapolation methods applied to text45;to45;image generation with 3D RoPE and propose Frequency45; and Time45;Aware Scaled RoPE tailored for diffusion transformers. Additionally we introduced a sigmoid time discretization schedule to reduce sampling steps in solving the Flow ODE and the Context Drop method to merge redundant visual tokens for faster network evaluation effectively boosting the overall sampling speed. Thanks to these improvements Lumina45;Next not only improves the quality and efficiency of basic text45;to45;image generation but also demonstrates superior resolution extrapolation capabilities and multilingual generation using decoder45;based LLMs as the text encoder all in a zero45;shot manner. To further validate Lumina45;Next as a versatile generative framework we instantiate it on diverse tasks including visual recognition multi45;view audio music and point cloud generation showcasing strong performance across these domains. By releasing all codes and model weights we aim to advance the development of next45;generation generative AI capable of universal modeling.

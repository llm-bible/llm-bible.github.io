---
layout: publication
title: 'Rdrec: Rationale Distillation For Llm-based Recommendation'
authors: Xinfeng Wang, Jin Cui, Yoshimi Suzuki, Fumiyo Fukumoto
conference: "Arxiv"
year: 2024
bibkey: wang2024rationale
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2405.10587'}
  - {name: "Code", url: 'https://github.com/WangXFng/RDRec'}
tags: ['Attention Mechanism', 'Has Code', 'RAG', 'Efficiency and Optimization', 'Distillation', 'Model Architecture', 'Prompting', 'Reinforcement Learning']
---
Large language model (LLM)-based recommender models that bridge users and
items through textual prompts for effective semantic reasoning have gained
considerable attention. However, few methods consider the underlying rationales
behind interactions, such as user preferences and item attributes, limiting the
reasoning capability of LLMs for recommendations. This paper proposes a
rationale distillation recommender (RDRec), a compact model designed to learn
rationales generated by a larger language model (LM). By leveraging rationales
from reviews related to users and items, RDRec remarkably specifies their
profiles for recommendations. Experiments show that RDRec achieves
state-of-the-art (SOTA) performance in both top-N and sequential
recommendations. Our source code is released at
https://github.com/WangXFng/RDRec.

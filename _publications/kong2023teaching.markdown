---
layout: publication
title: Platolm Teaching Llms In Multi45;round Dialogue Via A User Simulator
authors: Kong Chuyi, Fan Yaxin, Wan Xiang, Jiang Feng, Wang Benyou
conference: "ACL"
year: 2023
bibkey: kong2023teaching
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2308.11534"}
tags: ['GPT', 'Model Architecture', 'RAG', 'Reinforcement Learning']
---
The unparalleled performance of closed45;sourced ChatGPT has sparked efforts towards its democratization with notable strides made by leveraging real user and ChatGPT dialogues as evidenced by Vicuna. However due to challenges in gathering dialogues involving human participation current endeavors like Baize and UltraChat rely on ChatGPT conducting roleplay to simulate humans based on instructions resulting in overdependence on seeds diminished human45;likeness limited topic diversity and an absence of genuine multi45;round conversational dynamics. To address the above issues we propose a paradigm to simulate human behavior better and explore the benefits of incorporating more human45;like questions in multi45;turn conversations. Specifically we directly target human questions extracted from genuine human45;machine conversations as a learning goal and provide a novel user simulator called Socratic. The experimental results show our response model PlatoLM achieves SoTA performance among LLaMA45;based 7B models in MT45;Bench. Our findings further demonstrate that our method introduces highly human45;like questioning patterns and rich topic structures which can teach the response model better than previous works in multi45;round conversations.

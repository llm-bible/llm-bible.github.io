---
layout: publication
title: 'Leveraging Information Retrieval To Enhance Spoken Language Understanding Prompts In Few-shot Learning'
authors: Pierre Lepagnol, Sahar Ghannay, Thomas Gerald, Christophe Servan, Sophie Rosset
conference: "INTERSPEECH 2025"
year: 2025
bibkey: lepagnol2025leveraging
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2506.03035"}
tags: ['Applications', 'RAG', 'Training Techniques', 'Few-Shot', 'Prompting']
---
Understanding user queries is fundamental in many applications, such as home assistants, booking systems, or recommendations. Accordingly, it is crucial to develop accurate Spoken Language Understanding (SLU) approaches to ensure the reliability of the considered system. Current State-of-the-Art SLU techniques rely on large amounts of training data; however, only limited annotated examples are available for specific tasks or languages.
  In the meantime, instruction-tuned large language models (LLMs) have shown exceptional performance on unseen tasks in a few-shot setting when provided with adequate prompts. In this work, we propose to explore example selection by leveraging Information retrieval (IR) approaches to build an enhanced prompt that is applied to an SLU task. We evaluate the effectiveness of the proposed method on several SLU benchmarks. Experimental results show that lexical IR methods significantly enhance performance without increasing prompt length.

---
layout: publication
title: Vision45;and45;language Or Vision45;for45;language On Cross45;modal Influence In Multimodal Transformers
authors: Frank Stella, Bugliarello Emanuele, Elliott Desmond
conference: "Arxiv"
year: 2021
bibkey: frank2021vision
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2109.04448"}
tags: ['BERT', 'Masked Language Model', 'Model Architecture', 'Multimodal Models', 'Pretraining Methods', 'Training Techniques', 'Transformer']
---
Pretrained vision45;and45;language BERTs aim to learn representations that combine information from both modalities. We propose a diagnostic method based on cross45;modal input ablation to assess the extent to which these models actually integrate cross45;modal information. This method involves ablating inputs from one modality either entirely or selectively based on cross45;modal grounding alignments and evaluating the model prediction performance on the other modality. Model performance is measured by modality45;specific tasks that mirror the model pretraining objectives (e.g. masked language modelling for text). Models that have learned to construct cross45;modal representations using both modalities are expected to perform worse when inputs are missing from a modality. We find that recently proposed models have much greater relative difficulty predicting text when visual information is ablated compared to predicting visual object categories when text is ablated indicating that these models are not symmetrically cross45;modal.

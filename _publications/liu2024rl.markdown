---
layout: publication
title: RL45;GPT Integrating Reinforcement Learning And Code45;as45;policy
authors: Liu Shaoteng, Yuan Haoqi, Hu Minda, Li Yanwei, Chen Yukang, Liu Shu, Lu Zongqing, Jia Jiaya
conference: "Arxiv"
year: 2024
bibkey: liu2024rl
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.19299"}
tags: ['Agentic', 'Efficiency And Optimization', 'GPT', 'Model Architecture', 'Reinforcement Learning', 'Tools']
---
Large Language Models (LLMs) have demonstrated proficiency in utilizing various tools by coding yet they face limitations in handling intricate logic and precise control. In embodied tasks high45;level planning is amenable to direct coding while low45;level actions often necessitate task45;specific refinement such as Reinforcement Learning (RL). To seamlessly integrate both modalities we introduce a two45;level hierarchical framework RL45;GPT comprising a slow agent and a fast agent. The slow agent analyzes actions suitable for coding while the fast agent executes coding tasks. This decomposition effectively focuses each agent on specific tasks proving highly efficient within our pipeline. Our approach outperforms traditional RL methods and existing GPT agents demonstrating superior efficiency. In the Minecraft game it rapidly obtains diamonds within a single day on an RTX3090. Additionally it achieves SOTA performance across all designated MineDojo tasks.

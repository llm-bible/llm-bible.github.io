---
layout: publication
title: Codemirage Hallucinations In Code Generated By Large Language Models
authors: Agarwal Vibhor, Pei Yulong, Alamir Salwa, Liu Xiaomo
conference: "Arxiv"
year: 2024
bibkey: agarwal2024hallucinations
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.08333"}
tags: ['Applications', 'BERT', 'Efficiency And Optimization', 'GPT', 'Language Modeling', 'Model Architecture', 'Prompting', 'RAG', 'Security']
---
Large Language Models (LLMs) have shown promising potentials in program generation and no45;code automation. However LLMs are prone to generate hallucinations i.e. they generate text which sounds plausible but is incorrect. Although there has been a recent surge in research on LLM hallucinations for text generation similar hallucination phenomenon can happen in code generation. Sometimes the generated code can have syntactical or logical errors as well as more advanced issues like security vulnerabilities memory leaks etc. Given the wide adaptation of LLMs to enhance efficiency in code generation and development in general it becomes imperative to investigate hallucinations in code generation. To the best of our knowledge this is the first attempt at studying hallucinations in the code generated by LLMs. We start by introducing the code hallucination definition and a comprehensive taxonomy of code hallucination types. We propose the first benchmark CodeMirage dataset for code hallucinations. The benchmark contains 1137 GPT45;3.5 generated hallucinated code snippets for Python programming problems from two base datasets 45; HumanEval and MBPP. We then propose the methodology for code hallucination detection and experiment with open source LLMs such as CodeLLaMA as well as OpenAIs GPT45;3.5 and GPT45;4 models using one45;shot prompt. We find that GPT45;4 performs the best on HumanEval dataset and gives comparable results to the fine45;tuned CodeBERT baseline on MBPP dataset. Towards the end we discuss various mitigation strategies for code hallucinations and conclude our work.

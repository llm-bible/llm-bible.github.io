---
layout: publication
title: A Simple And Efficient Multi45;task Learning Approach For Conditioned Dialogue Generation
authors: Zeng Yan, Nie Jian-yun
conference: "Arxiv"
year: 2020
bibkey: zeng2020simple
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2010.11140"}
tags: ['Model Architecture', 'Pretraining Methods', 'RAG', 'Transformer']
---
Conditioned dialogue generation suffers from the scarcity of labeled responses. In this work we exploit labeled non45;dialogue text data related to the condition which are much easier to collect. We propose a multi45;task learning approach to leverage both labeled dialogue and text data. The 3 tasks jointly optimize the same pre45;trained Transformer 45;45; conditioned dialogue generation task on the labeled dialogue data conditioned language encoding task and conditioned language generation task on the labeled text data. Experimental results show that our approach outperforms the state45;of45;the45;art models by leveraging the labeled texts and it also obtains larger improvement in performance comparing to the previous methods to leverage text data.

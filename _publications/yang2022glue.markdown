---
layout: publication
title: GLUE45;X Evaluating Natural Language Understanding Models From An Out45;of45;distribution Generalization Perspective
authors: Yang Linyi, Zhang Shuibai, Qin Libo, Li Yafu, Wang Yidong, Liu Hanmeng, Wang Jindong, Xie Xing, Zhang Yue
conference: "Arxiv"
year: 2022
bibkey: yang2022glue
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2211.08073"}
tags: ['Applications', 'GPT', 'Model Architecture', 'RAG', 'Reinforcement Learning', 'Security', 'Training Techniques']
---
Pre45;trained language models (PLMs) are known to improve the generalization performance of natural language understanding models by leveraging large amounts of data during the pre45;training phase. However the out45;of45;distribution (OOD) generalization problem remains a challenge in many NLP tasks limiting the real45;world deployment of these methods. This paper presents the first attempt at creating a unified benchmark named GLUE45;X for evaluating OOD robustness in NLP models highlighting the importance of OOD robustness and providing insights on how to measure the robustness of a model and how to improve it. The benchmark includes 13 publicly available datasets for OOD testing and evaluations are conducted on 8 classic NLP tasks over 21 popularly used PLMs including GPT45;3 and GPT45;3.5. Our findings confirm the need for improved OOD accuracy in NLP tasks as significant performance degradation was observed in all settings compared to in45;distribution (ID) accuracy.

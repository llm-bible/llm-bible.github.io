---
layout: publication
title: 'Human-llm Coevolution: Evidence From Academic Writing'
authors: Mingmeng Geng, Roberto Trotta
conference: "Arxiv"
year: 2025
bibkey: geng2025human
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.09606"}
tags: ['GPT', 'Model Architecture', 'Reinforcement Learning', 'Attention Mechanism', 'Arxiv']
---
With a statistical analysis of arXiv paper abstracts, we report a marked drop
in the frequency of several words previously identified as overused by ChatGPT,
such as "delve", starting soon after they were pointed out in early 2024. The
frequency of certain other words favored by ChatGPT, such as "significant", has
instead kept increasing. These phenomena suggest that some authors of academic
papers have adapted their use of large language models (LLMs), for example, by
selecting outputs or applying modifications to the LLM-generated content. Such
coevolution and cooperation of humans and LLMs thus introduce additional
challenges to the detection of machine-generated text in real-world scenarios.
Estimating the impact of LLMs on academic writing by examining word frequency
remains feasible, and more attention should be paid to words that were already
frequently employed, including those that have decreased in frequency due to
LLMs' disfavor.

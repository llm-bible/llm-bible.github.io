---
layout: publication
title: Codeaid Evaluating A Classroom Deployment Of An Llm-based Programming Assistant That Balances Student And Educator Needs
authors: Kazemitabaar Majeed, Ye Runlong, Wang Xiaoning, Henley Austin Z., Denny Paul, Craig Michelle, Grossman Tovi
conference: "Arxiv"
year: 2024
bibkey: kazemitabaar2024codeaid
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.11314"}
tags: ['Ethics And Bias', 'GPT', 'Interpretability And Explainability', 'Model Architecture', 'RAG', 'Reinforcement Learning', 'Survey Paper', 'Tools']
---
Timely personalized feedback is essential for students learning programming. LLM-powered tools like ChatGPT offer instant support but reveal direct answers with code which may hinder deep conceptual engagement. We developed CodeAid an LLM-powered programming assistant delivering helpful technically correct responses without revealing code solutions. CodeAid answers conceptual questions generates pseudo-code with line-by-line explanations and annotates students incorrect code with fix suggestions. We deployed CodeAid in a programming class of 700 students for a 12-week semester. A thematic analysis of 8000 usages of CodeAid was performed further enriched by weekly surveys and 22 student interviews. We then interviewed eight programming educators to gain further insights. Our findings reveal four design considerations for future educational AI assistants D1) exploiting AIs unique benefits; D2) simplifying query formulation while promoting cognitive engagement; D3) avoiding direct responses while encouraging motivated learning; and D4) maintaining transparency and control for students to asses and steer AI responses.

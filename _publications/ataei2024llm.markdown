---
layout: publication
title: 'Elicitron: An LLM Agent-based Simulation Framework For Design Requirements Elicitation'
authors: Mohammadmehdi Ataei, Hyunmin Cheong, Daniele Grandi, Ye Wang, Nigel Morris, Alexander Tessier
conference: "Arxiv"
year: 2024
bibkey: ataei2024llm
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.16045"}
tags: ['Fine-Tuning', 'Agentic', 'Tools', 'Applications', 'RAG', 'Reinforcement Learning']
---
Requirements elicitation, a critical, yet time-consuming and challenging step
in product development, often fails to capture the full spectrum of user needs.
This may lead to products that fall short of expectations. This paper
introduces a novel framework that leverages Large Language Models (LLMs) to
automate and enhance the requirements elicitation process. LLMs are used to
generate a vast array of simulated users (LLM agents), enabling the exploration
of a much broader range of user needs and unforeseen use cases. These agents
engage in product experience scenarios, through explaining their actions,
observations, and challenges. Subsequent agent interviews and analysis uncover
valuable user needs, including latent ones. We validate our framework with
three experiments. First, we explore different methodologies for diverse agent
generation, discussing their advantages and shortcomings. We measure the
diversity of identified user needs and demonstrate that context-aware agent
generation leads to greater diversity. Second, we show how our framework
effectively mimics empathic lead user interviews, identifying a greater number
of latent needs than conventional human interviews. Third, we showcase that
LLMs can be used to analyze interviews, capture needs, and classify them as
latent or not. Our work highlights the potential of using LLM agents to
accelerate early-stage product development, reduce costs, and increase
innovation.

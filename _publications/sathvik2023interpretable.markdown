---
layout: publication
title: 'Interprompt: Interpretable Prompting For Interrelated Interpersonal Risk Factors In Reddit Posts'
authors: Msvpj Sathvik, Surjodeep Sarkar, Chandni Saxena, Sunghwan Sohn, Muskan Garg
conference: "Arxiv"
year: 2023
bibkey: sathvik2023interpretable
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2311.12404"}
tags: ['Fine-Tuning', 'Transformer', 'GPT', 'Interpretability and Explainability', 'Model Architecture', 'Reinforcement Learning', 'Interpretability', 'Training Techniques', 'Attention Mechanism', 'Pretraining Methods', 'Prompting']
---
Mental health professionals and clinicians have observed the upsurge of
mental disorders due to Interpersonal Risk Factors (IRFs). To simulate the
human-in-the-loop triaging scenario for early detection of mental health
disorders, we recognized textual indications to ascertain these IRFs : Thwarted
Belongingness (TBe) and Perceived Burdensomeness (PBu) within personal
narratives. In light of this, we use N-shot learning with GPT-3 model on the
IRF dataset, and underscored the importance of fine-tuning GPT-3 model to
incorporate the context-specific sensitivity and the interconnectedness of
textual cues that represent both IRFs.
  In this paper, we introduce an Interpretable Prompting (InterPrompt)\} method
to boost the attention mechanism by fine-tuning the GPT-3 model. This allows a
more sophisticated level of language modification by adjusting the pre-trained
weights. Our model learns to detect usual patterns and underlying connections
across both the IRFs, which leads to better system-level explainability and
trustworthiness. The results of our research demonstrate that all four variants
of GPT-3 model, when fine-tuned with InterPrompt, perform considerably better
as compared to the baseline methods, both in terms of classification and
explanation generation.

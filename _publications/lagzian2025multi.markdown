---
layout: publication
title: 'Multi-novelty: Improve The Diversity And Novelty Of Contents Generated By Large Language Models Via Inference-time Multi-views Brainstorming'
authors: Arash Lagzian, Srinivas Anumasa, Dianbo Liu
conference: "Arxiv"
year: 2025
bibkey: lagzian2025multi
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.12700"}
tags: ['Agentic', 'Training Techniques', 'Reinforcement Learning', 'Fine-Tuning', 'Prompting']
---
Large Language Models (LLMs) demonstrate remarkable proficiency in generating
accurate and fluent text. However, they often struggle with diversity and
novelty, leading to repetitive or overly deterministic responses. These
limitations stem from constraints in training data, including gaps in specific
knowledge domains, outdated information, and an over-reliance on textual
sources. Such shortcomings reduce their effectiveness in tasks requiring
creativity, multi-perspective reasoning, and exploratory thinking, such as LLM
based AI scientist agents and creative artist agents . To address this
challenge, we introduce inference-time multi-view brainstorming method, a novel
approach that enriches input prompts with diverse perspectives derived from
both textual and visual sources, which we refere to as "Multi-Novelty". By
incorporating additional contextual information as diverse starting point for
chain of thoughts, this method enhances the variety and creativity of generated
outputs. Importantly, our approach is model-agnostic, requiring no
architectural modifications and being compatible with both open-source and
proprietary LLMs.

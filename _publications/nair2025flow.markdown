---
layout: publication
title: 'Flow-of-options: Diversified And Improved LLM Reasoning By Thinking Through Options'
authors: Lakshmi Nair, Ian Trase, Mark Kim
conference: "Arxiv"
year: 2025
bibkey: nair2025flow
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.12929"}
  - {name: "Code", url: "https://github.com/flagshippioneering/Flow-of-Options"}
tags: ['Agentic', 'Tools', 'Reinforcement Learning', 'Ethics and Bias', 'Has Code', 'Applications']
---
We present a novel reasoning approach called Flow-of-Options (FoO), designed to address intrinsic biases in Large Language Models (LLMs). Flow-of-Options enables LLMs to systematically explore a diverse range of possibilities in their reasoning, as demonstrated by an FoO-based agentic framework developed for autonomously solving Machine Learning (ML) tasks. FoO enforces diversity in LLM solutions through compressed and interpretable task representations, resulting in improvements of 38.2% - 69.2% on standard data science tasks, and 37.4% - 47.9% on therapeutic chemistry tasks, as compared to state-of-the-art baselines. With an overall operation cost under $1 per task, our framework is well-suited for cost-sensitive applications. Going beyond tabular classification and regression, we show the broader applicability of our FoO-based agentic system to tasks such as reinforcement learning and image generation. Our code is open-sourced at: https://github.com/flagshippioneering/Flow-of-Options.

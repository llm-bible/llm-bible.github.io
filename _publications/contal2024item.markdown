---
layout: publication
title: Ragsys Item-cold-start Recommender As RAG System
authors: Contal Emile, Mcgoldrick Garrin
conference: "Arxiv"
year: 2024
bibkey: contal2024item
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.17587"}
tags: ['Applications', 'Ethics And Bias', 'Few Shot', 'Fine Tuning', 'In Context Learning', 'Pretraining Methods', 'Prompting', 'RAG', 'Reinforcement Learning', 'Training Techniques']
---
Large Language Models (LLM) hold immense promise for real-world applications but their generic knowledge often falls short of domain-specific needs. Fine-tuning a common approach can suffer from catastrophic forgetting and hinder generalizability. In-Context Learning (ICL) offers an alternative which can leverage Retrieval-Augmented Generation (RAG) to provide LLMs with relevant demonstrations for few-shot learning tasks. This paper explores the desired qualities of a demonstration retrieval system for ICL. We argue that ICL retrieval in this context resembles item-cold-start recommender systems prioritizing discovery and maximizing information gain over strict relevance. We propose a novel evaluation method that measures the LLMs subsequent performance on NLP tasks eliminating the need for subjective diversity scores. Our findings demonstrate the critical role of diversity and quality bias in retrieved demonstrations for effective ICL and highlight the potential of recommender system techniques in this domain.

---
layout: publication
title: Natural Language Inference In Context -- Investigating Contextual Reasoning
  Over Long Texts
authors: Hanmeng Liu, Leyang Cui, Jian Liu, Yue Zhang
conference: Arxiv
year: 2020
citations: 15
bibkey: liu2020natural
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2011.04864'}]
tags: []
---
Natural language inference (NLI) is a fundamental NLP task, investigating the
entailment relationship between two texts. Popular NLI datasets present the
task at sentence-level. While adequate for testing semantic representations,
they fall short for testing contextual reasoning over long texts, which is a
natural part of the human inference process. We introduce ConTRoL, a new
dataset for ConTextual Reasoning over Long texts. Consisting of 8,325
expert-designed "context-hypothesis" pairs with gold labels, ConTRoL is a
passage-level NLI dataset with a focus on complex contextual reasoning types
such as logical reasoning. It is derived from competitive selection and
recruitment test (verbal reasoning test) for police recruitment, with expert
level quality. Compared with previous NLI benchmarks, the materials in ConTRoL
are much more challenging, involving a range of reasoning types. Empirical
results show that state-of-the-art language models perform by far worse than
educated humans. Our dataset can also serve as a testing-set for downstream
tasks like Checking Factual Correctness of Summaries.
---
layout: publication
title: Interactive45;kbqa Multi45;turn Interactions For Knowledge Base Question Answering With Large Language Models
authors: Xiong Guanming, Bao Junwei, Zhao Wen
conference: "Arxiv"
year: 2024
bibkey: xiong2024interactive
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.15131"}
tags: ['Applications', 'RAG', 'Reinforcement Learning', 'Tools']
---
This study explores the realm of knowledge base question answering (KBQA). KBQA is considered a challenging task particularly in parsing intricate questions into executable logical forms. Traditional semantic parsing (SP)45;based methods require extensive data annotations which result in significant costs. Recently the advent of few45;shot in45;context learning powered by large language models (LLMs) has showcased promising capabilities. However fully leveraging LLMs to parse questions into logical forms in low45;resource scenarios poses a substantial challenge. To tackle these hurdles we introduce Interactive45;KBQA a framework designed to generate logical forms through direct interaction with knowledge bases (KBs). Within this framework we have developed three generic APIs for KB interaction. For each category of complex question we devised exemplars to guide LLMs through the reasoning processes. Our method achieves competitive results on the WebQuestionsSP ComplexWebQuestions KQA Pro and MetaQA datasets with a minimal number of examples (shots). Importantly our approach supports manual intervention allowing for the iterative refinement of LLM outputs. By annotating a dataset with step45;wise reasoning processes we showcase our models adaptability and highlight its potential for contributing significant enhancements to the field.

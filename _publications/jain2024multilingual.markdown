---
layout: publication
title: Polyglotoxicityprompts Multilingual Evaluation Of Neural Toxic Degeneration In Large Language Models
authors: Jain Devansh, Kumar Priyanshu, Gehman Samuel, Zhou Xuhui, Hartvigsen Thomas, Sap Maarten
conference: "Arxiv"
year: 2024
bibkey: jain2024multilingual
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.09373"}
tags: ['Applications', 'Prompting', 'RAG', 'Responsible AI', 'Tools']
---
Recent advances in large language models (LLMs) have led to their extensive global deployment and ensuring their safety calls for comprehensive and multilingual toxicity evaluations. However existing toxicity benchmarks are overwhelmingly focused on English posing serious risks to deploying LLMs in other languages. We address this by introducing PolygloToxicityPrompts (PTP) the first large45;scale multilingual toxicity evaluation benchmark of 425K naturally occurring prompts spanning 17 languages. We overcome the scarcity of naturally occurring toxicity in web45;text and ensure coverage across languages with varying resources by automatically scraping over 100M web45;text documents. Using PTP we investigate research questions to study the impact of model size prompt language and instruction and preference45;tuning methods on toxicity by benchmarking over 60 LLMs. Notably we find that toxicity increases as language resources decrease or model size increases. Although instruction45; and preference45;tuning reduce toxicity the choice of preference45;tuning method does not have any significant impact. Our findings shed light on crucial shortcomings of LLM safeguarding and highlight areas for future research.

---
layout: publication
title: 'Nlpgym -- A Toolkit For Evaluating RL Agents On Natural Language Processing Tasks'
authors: Ramamurthy Rajkumar, Sifa Rafet, Bauckhage Christian
conference: "Arxiv"
year: 2020
bibkey: ramamurthy2020nlpgym
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2011.08272"}
  - {name: "Code", url: "https://github.com/rajcscw/nlp-gym"}
tags: ['Agentic', 'Applications', 'Has Code', 'Reinforcement Learning']
---
Reinforcement learning (RL) has recently shown impressive performance in complex game AI and robotics tasks. To a large extent this is thanks to the availability of simulated environments such as OpenAI Gym Atari Learning Environment or Malmo which allow agents to learn complex tasks through interaction with virtual environments. While RL is also increasingly applied to natural language processing (NLP) there are no simulated textual environments available for researchers to apply and consistently benchmark RL on NLP tasks. With the work reported here we therefore release NLPGym an open-source Python toolkit that provides interactive textual environments for standard NLP tasks such as sequence tagging multi-label classification and question answering. We also present experimental results for 6 tasks using different RL algorithms which serve as baselines for further research. The toolkit is published at https://github.com/rajcscw/nlp-gym"

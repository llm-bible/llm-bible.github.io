---
layout: publication
title: 'Your Language Model May Think Too Rigidly: Achieving Reasoning Consistency With Symmetry-enhanced Training'
authors: Yihang Yao, Zhepeng Cen, Miao Li, William Han, Yuyou Zhang, Emerson Liu, Zuxin Liu, Chuang Gan, Ding Zhao
conference: "Arxiv"
year: 2025
bibkey: yao2025your
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.17800"}
tags: ['Security', 'Training Techniques', 'Reinforcement Learning']
---
Large Language Models (LLMs) have demonstrated strong reasoning capabilities
across various tasks. However, even minor variations in query phrasing, despite
preserving the underlying semantic meaning, can significantly affect their
performance. To address this, we focus on enhancing LLMs' awareness of symmetry
in query variations and propose syMmetry-ENhanceD (MEND) Data Augmentation, a
data-centric approach that improves the model's ability to extract useful
information from context. Unlike existing methods that emphasize reasoning
chain augmentation, our approach improves model robustness at the knowledge
extraction stage through query augmentations, enabling more data-efficient
training and stronger generalization to Out-of-Distribution (OOD) settings.
Extensive experiments on both logical and arithmetic reasoning tasks show that
MEND enhances reasoning performance across diverse query variations, providing
new insight into improving LLM robustness through structured dataset curation.

---
layout: publication
title: 'Persuade Me If You Can: A Framework For Evaluating Persuasion Effectiveness And Susceptibility Among Large Language Models'
authors: Nimet Beyza Bozdag, Shuhaib Mehri, Gokhan Tur, Dilek Hakkani-t√ºr
conference: "Arxiv"
year: 2025
bibkey: bozdag2025persuade
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2503.01829"}
tags: ['Agentic', 'Model Architecture', 'GPT', 'Tools']
---
Large Language Models (LLMs) demonstrate persuasive capabilities that rival
human-level persuasion. While these capabilities can be used for social good,
they also present risks of potential misuse. Moreover, LLMs' susceptibility to
persuasion raises concerns about alignment with ethical principles. To study
these dynamics, we introduce Persuade Me If You Can (PMIYC), an automated
framework for evaluating persuasion through multi-agent interactions. Here,
Persuader agents engage in multi-turn conversations with the Persuadee agents,
allowing us to measure LLMs' persuasive effectiveness and their susceptibility
to persuasion. We conduct comprehensive evaluations across diverse LLMs,
ensuring each model is assessed against others in both subjective and
misinformation contexts. We validate the efficacy of our framework through
human evaluations and show alignment with prior work. PMIYC offers a scalable
alternative to human annotation for studying persuasion in LLMs. Through PMIYC,
we find that Llama-3.3-70B and GPT-4o exhibit similar persuasive effectiveness,
outperforming Claude 3 Haiku by 30%. However, GPT-4o demonstrates over 50%
greater resistance to persuasion for misinformation compared to Llama-3.3-70B.
These findings provide empirical insights into the persuasive dynamics of LLMs
and contribute to the development of safer AI systems.

---
layout: publication
title: Paraphrasing With Large Language Models
authors: Sam Witteveen, Martin Andrews
conference: Arxiv
year: 2019
citations: 24
bibkey: witteveen2019paraphrasing
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1911.09661'}]
tags: [GPT, Fine-Tuning, Language Modeling]
---
Recently, large language models such as GPT-2 have shown themselves to be
extremely adept at text generation and have also been able to achieve
high-quality results in many downstream NLP tasks such as text classification,
sentiment analysis and question answering with the aid of fine-tuning. We
present a useful technique for using a large language model to perform the task
of paraphrasing on a variety of texts and subjects. Our approach is
demonstrated to be capable of generating paraphrases not only at a sentence
level but also for longer spans of text such as paragraphs without needing to
break the text into smaller chunks.
---
layout: publication
title: 'Unmasking The Imposters: How Censorship And Domain Adaptation Affect The Detection Of Machine-generated Tweets'
authors: Bryan E. Tuck, Rakesh M. Verma
conference: "Proceedings of the 31st International Conference on Computational Linguistics pages 9044-9061 Abu Dhabi UAE January 2025"
year: 2024
bibkey: tuck2024unmasking
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.17967"}
tags: ['Model Architecture', 'Fine-Tuning', 'GPT', 'Tools']
---
The rapid development of large language models (LLMs) has significantly
improved the generation of fluent and convincing text, raising concerns about
their potential misuse on social media platforms. We present a comprehensive
methodology for creating nine Twitter datasets to examine the generative
capabilities of four prominent LLMs: Llama 3, Mistral, Qwen2, and GPT4o. These
datasets encompass four censored and five uncensored model configurations,
including 7B and 8B parameter base-instruction models of the three open-source
LLMs. Additionally, we perform a data quality analysis to assess the
characteristics of textual outputs from human, "censored," and "uncensored"
models, employing semantic meaning, lexical richness, structural patterns,
content characteristics, and detector performance metrics to identify
differences and similarities. Our evaluation demonstrates that "uncensored"
models significantly undermine the effectiveness of automated detection
methods. This study addresses a critical gap by exploring smaller open-source
models and the ramifications of "uncensoring," providing valuable insights into
how domain adaptation and content moderation strategies influence both the
detectability and structural characteristics of machine-generated text.

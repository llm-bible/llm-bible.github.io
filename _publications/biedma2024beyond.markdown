---
layout: publication
title: Beyond Human Norms Unveiling Unique Values Of Large Language Models Through Interdisciplinary Approaches
authors: Biedma Pablo, Yi Xiaoyuan, Huang Linus, Sun Maosong, Xie Xing
conference: "Arxiv"
year: 2024
bibkey: biedma2024beyond
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.12744"}
tags: ['Ethics And Bias', 'RAG', 'Responsible AI', 'Tools', 'Training Techniques']
---
Recent advancements in Large Language Models (LLMs) have revolutionized the AI field but also pose potential safety and ethical risks. Deciphering LLMs embedded values becomes crucial for assessing and mitigating their risks. Despite extensive investigation into LLMs values previous studies heavily rely on human-oriented value systems in social sciences. Then a natural question arises Do LLMs possess unique values beyond those of humans Delving into it this work proposes a novel framework ValueLex to reconstruct LLMs unique value system from scratch leveraging psychological methodologies from human personality/value research. Based on Lexical Hypothesis ValueLex introduces a generative approach to elicit diverse values from 30+ LLMs synthesizing a taxonomy that culminates in a comprehensive value framework via factor analysis and semantic clustering. We identify three core value dimensions Competence Character and Integrity each with specific subdimensions revealing that LLMs possess a structured albeit non-human value system. Based on this system we further develop tailored projective tests to evaluate and analyze the value inclinations of LLMs across different model sizes training methods and data sources. Our framework fosters an interdisciplinary paradigm of understanding LLMs paving the way for future AI alignment and regulation.

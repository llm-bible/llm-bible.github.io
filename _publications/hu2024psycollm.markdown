---
layout: publication
title: PsycoLLM Enhancing LLM for Psychological Understanding and Evaluation
authors: Hu Jinpeng, Dong Tengteng, Gang Luo, Ma Hui, Zou Peng, Sun Xiao, Guo Dan, Wang Meng
conference: "Arxiv"
year: 2024
bibkey: hu2024psycollm
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.05721"}
tags: ['Arxiv', 'LLM', 'Ethics and Bias']
---
Mental health has attracted substantial attention in recent years and LLM can be an effective technology for alleviating this problem owing to its capability in text understanding and dialogue. However existing research in this domain often suffers from limitations such as training on datasets lacking crucial prior knowledge and evidence and the absence of comprehensive evaluation methods. In this paper we propose a specialized psychological large language model (LLM) named PsycoLLM trained on a proposed high-quality psychological dataset including single-turn QA multi-turn dialogues and knowledge-based QA. Specifically we construct multi-turn dialogues through a three-step pipeline comprising generation evidence judgment and refinement. We augment this process with real-world psychological case backgrounds extracted from online platforms enhancing the relevance and applicability of the generated data. Additionally to compare the performance of PsycoLLM with other LLMs we develop a comprehensive psychological benchmark based on authoritative psychological counseling examinations in China which includes assessments of professional ethics theoretical proficiency and case analysis. The experimental results on the benchmark illustrates the effectiveness of PsycoLLM which demonstrates superior performance compared to other LLMs.

---
layout: publication
title: Hidden Flaws Behind Expert45;level Accuracy Of Multimodal GPT45;4 Vision In Medicine
authors: Jin Qiao, Chen Fangyuan, Zhou Yiliang, Xu Ziyang, Cheung Justin M., Chen Robert, Summers Ronald M., Rousseau Justin F., Ni Peiyun, Landsman Marc J, Baxter Sally L., Al'aref Subhi J., Li Yijia, Chen Alex, Brejt Josef A., Chiang Michael F., Peng Yifan, Lu Zhiyong
conference: "npj Digital Medicine"
year: 2024
bibkey: jin2024hidden
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.08396"}
tags: ['GPT', 'Model Architecture', 'Multimodal Models', 'Pretraining Methods', 'Transformer']
---
Recent studies indicate that Generative Pre45;trained Transformer 4 with Vision (GPT45;4V) outperforms human physicians in medical challenge tasks. However these evaluations primarily focused on the accuracy of multi45;choice questions alone. Our study extends the current scope by conducting a comprehensive analysis of GPT45;4Vs rationales of image comprehension recall of medical knowledge and step45;by45;step multimodal reasoning when solving New England Journal of Medicine (NEJM) Image Challenges 45; an imaging quiz designed to test the knowledge and diagnostic capabilities of medical professionals. Evaluation results confirmed that GPT45;4V performs comparatively to human physicians regarding multi45;choice accuracy (81.637; vs. 77.837;). GPT45;4V also performs well in cases where physicians incorrectly answer with over 7837; accuracy. However we discovered that GPT45;4V frequently presents flawed rationales in cases where it makes the correct final choices (35.537;) most prominent in image comprehension (27.237;). Regardless of GPT45;4Vs high accuracy in multi45;choice questions our findings emphasize the necessity for further in45;depth evaluations of its rationales before integrating such multimodal AI models into clinical workflows.

---
layout: publication
title: 'Sentimentgpt: Exploiting GPT For Advanced Sentiment Analysis And Its Departure
  From Current Machine Learning'
authors: Kiana Kheiri, Hamid Karimi
conference: Arxiv
year: 2023
citations: 29
bibkey: kheiri2023exploiting
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2307.10234'}, {name: Code,
    url: 'https://github.com/DSAatUSU/SentimentGPT'}]
tags: [Transformer, GPT, Fine-Tuning, Prompting]
---
This study presents a thorough examination of various Generative Pretrained
Transformer (GPT) methodologies in sentiment analysis, specifically in the
context of Task 4 on the SemEval 2017 dataset. Three primary strategies are
employed: 1) prompt engineering using the advanced GPT-3.5 Turbo, 2)
fine-tuning GPT models, and 3) an inventive approach to embedding
classification. The research yields detailed comparative insights among these
strategies and individual GPT models, revealing their unique strengths and
potential limitations. Additionally, the study compares these GPT-based
methodologies with other current, high-performing models previously used with
the same dataset. The results illustrate the significant superiority of the GPT
approaches in terms of predictive performance, more than 22% in F1-score
compared to the state-of-the-art. Further, the paper sheds light on common
challenges in sentiment analysis tasks, such as understanding context and
detecting sarcasm. It underscores the enhanced capabilities of the GPT models
to effectively handle these complexities. Taken together, these findings
highlight the promising potential of GPT models in sentiment analysis, setting
the stage for future research in this field. The code can be found at
https://github.com/DSAatUSU/SentimentGPT
---
layout: publication
title: Ontology-Free General-Domain Knowledge Graph-to-Text Generation Dataset Synthesis using Large Language Model
authors: Kim Daehee, Kang Deokhyung, Ryu Sangwon, Lee Gary Geunbae
conference: "Arxiv"
year: 2024
bibkey: kim2024ontology
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2409.07088"}
tags: ['Applications', 'Language Modeling', 'RAG']
---
Knowledge Graph-to-Text (G2T) generation involves verbalizing structured knowledge graphs into natural language text. Recent advancements in Pretrained Language Models (PLMs) have improved G2T performance but their effectiveness depends on datasets with precise graph-text alignment. However the scarcity of high-quality general-domain G2T generation datasets restricts progress in the general-domain G2T generation research. To address this issue we introduce Wikipedia Ontology-Free Graph-text dataset (WikiOFGraph) a new large-scale G2T dataset generated using a novel method that leverages Large Language Model (LLM) and Data-QuestEval. Our new dataset which contains 5.85M general-domain graph-text pairs offers high graph-text consistency without relying on external ontologies. Experimental results demonstrate that PLM fine-tuned on WikiOFGraph outperforms those trained on other datasets across various evaluation metrics. Our method proves to be a scalable and effective solution for generating high-quality G2T data significantly advancing the field of G2T generation.

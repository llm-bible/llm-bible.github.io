---
layout: publication
title: 'Textualized Agent-style Reasoning For Complex Tasks By Multiple Round LLM Generation'
authors: Chen Liang, Zhifan Feng, Zihe Liu, Wenbin Jiang, Jinan Xu, Yufeng Chen, Yong Wang
conference: "Arxiv"
year: 2024
bibkey: liang2024textualized
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2409.12411'}
tags: ['Agentic', 'Interpretability and Explainability', 'Agent', 'Tools', 'Prompting', 'Reinforcement Learning']
---
Chain-of-thought prompting significantly boosts the reasoning ability of
large language models but still faces three issues: hallucination problem,
restricted interpretability, and uncontrollable generation. To address these
challenges, we present AgentCOT, a llm-based autonomous agent framework, which
can solve complex problems in an agent-style manner by multiple round LLM
generation. At each step, AgentCOT selects an action and executes it to yield
an intermediate result with supporting evidence. In addition, we integrate the
step's index into the reasoning process to form a graph structure for complex
inference logic. We introduce two new strategies to enhance the performance of
AgentCOT.We conduct extensive experiments to verify the effectiveness of our
method on six common benchmarks. Results exhibit that our method brings in
substantial improvements over current competitive approaches.

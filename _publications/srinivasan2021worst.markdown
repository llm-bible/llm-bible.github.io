---
layout: publication
title: Worst Of Both Worlds Biases Compound In Pre45;trained Vision45;and45;language Models
authors: Srinivasan Tejas, Bisk Yonatan
conference: "Arxiv"
year: 2021
bibkey: srinivasan2021worst
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2104.08666"}
tags: ['Attention Mechanism', 'BERT', 'Ethics And Bias', 'Model Architecture', 'Multimodal Models', 'Reinforcement Learning']
---
Numerous works have analyzed biases in vision and pre45;trained language models individually 45; however less attention has been paid to how these biases interact in multimodal settings. This work extends text45;based bias analysis methods to investigate multimodal language models and analyzes intra45; and inter45;modality associations and biases learned by these models. Specifically we demonstrate that VL45;BERT (Su et al. 2020) exhibits gender biases often preferring to reinforce a stereotype over faithfully describing the visual scene. We demonstrate these findings on a controlled case45;study and extend them for a larger set of stereotypically gendered entities.

---
layout: publication
title: Advprompter Fast Adaptive Adversarial Prompting For Llms
authors: Paulus Anselm, Zharmagambetov Arman, Guo Chuan, Amos Brandon, Tian Yuandong
conference: "Arxiv"
year: 2024
bibkey: paulus2024fast
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.16873"}
tags: ['Efficiency And Optimization', 'Prompting', 'Security', 'Tools', 'Training Techniques']
---
While recently Large Language Models (LLMs) have achieved remarkable successes they are vulnerable to certain jailbreaking attacks that lead to generation of inappropriate or harmful content. Manual red45;teaming requires finding adversarial prompts that cause such jailbreaking e.g. by appending a suffix to a given instruction which is inefficient and time45;consuming. On the other hand automatic adversarial prompt generation often leads to semantically meaningless attacks that can easily be detected by perplexity45;based filters may require gradient information from the TargetLLM or do not scale well due to time45;consuming discrete optimization processes over the token space. In this paper we present a novel method that uses another LLM called the AdvPrompter to generate human45;readable adversarial prompts in seconds sim800Ã— faster than existing optimization45;based approaches. We train the AdvPrompter using a novel algorithm that does not require access to the gradients of the TargetLLM. This process alternates between two steps (1) generating high45;quality target adversarial suffixes by optimizing the AdvPrompter predictions and (2) low45;rank fine45;tuning of the AdvPrompter with the generated adversarial suffixes. The trained AdvPrompter generates suffixes that veil the input instruction without changing its meaning such that the TargetLLM is lured to give a harmful response. Experimental results on popular open source TargetLLMs show state45;of45;the45;art results on the AdvBench dataset that also transfer to closed45;source black45;box LLM APIs. Further we demonstrate that by fine45;tuning on a synthetic dataset generated by AdvPrompter LLMs can be made more robust against jailbreaking attacks while maintaining performance i.e. high MMLU scores.

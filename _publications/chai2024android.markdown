---
layout: publication
title: AMEX Android Multi45;annotation Expo Dataset For Mobile GUI Agents
authors: Chai Yuxiang, Huang Siyuan, Niu Yazhe, Xiao Han, Liu Liang, Zhang Dingyu, Gao Peng, Ren Shuai, Li Hongsheng
conference: "Arxiv"
year: 2024
bibkey: chai2024android
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.17490"}
tags: ['Agent', 'Agentic', 'Applications', 'Attention Mechanism', 'Model Architecture', 'RAG', 'Tools']
---
AI agents have drawn increasing attention mostly on their ability to perceive environments understand tasks and autonomously achieve goals. To advance research on AI agents in mobile scenarios we introduce the Android Multi45;annotation EXpo (AMEX) a comprehensive large45;scale dataset designed for generalist mobile GUI45;control agents. Their capabilities of completing complex tasks by directly interacting with the graphical user interface (GUI) on mobile devices are trained and evaluated with the proposed dataset. AMEX comprises over 104K high45;resolution screenshots from 110 popular mobile applications which are annotated at multiple levels. Unlike existing mobile device45;control datasets e.g. MoTIF AitW etc. AMEX includes three levels of annotations GUI interactive element grounding GUI screen and element functionality descriptions and complex natural language instructions each averaging 13 steps with stepwise GUI45;action chains. We develop this dataset from a more instructive and detailed perspective complementing the general settings of existing datasets. Additionally we develop a baseline model SPHINX Agent and compare its performance across state45;of45;the45;art agents trained on other datasets. To facilitate further research we open45;source our dataset models and relevant evaluation tools. The project is available at https://yuxiangchai.github.io/AMEX/

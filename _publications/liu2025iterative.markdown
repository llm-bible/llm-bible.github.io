---
layout: publication
title: 'ISSR: Iterative Selection With Self-review For Vocabulary Test Distractor Generation'
authors: Yu-cheng Liu, An-zi Yen
conference: "Arxiv"
year: 2025
bibkey: liu2025iterative
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2501.03462'}
tags: ['Reinforcement Learning', 'Tools', 'Survey Paper']
---
Vocabulary acquisition is essential to second language learning, as it
underpins all core language skills. Accurate vocabulary assessment is
particularly important in standardized exams, where test items evaluate
learners' comprehension and contextual use of words. Previous research has
explored methods for generating distractors to aid in the design of English
vocabulary tests. However, current approaches often rely on lexical databases
or predefined rules, and frequently produce distractors that risk invalidating
the question by introducing multiple correct options. In this study, we focus
on English vocabulary questions from Taiwan's university entrance exams. We
analyze student response distributions to gain insights into the
characteristics of these test items and provide a reference for future
research. Additionally, we identify key limitations in how large language
models (LLMs) support teachers in generating distractors for vocabulary test
design. To address these challenges, we propose the iterative selection with
self-review (ISSR) framework, which makes use of a novel LLM-based self-review
mechanism to ensure that the distractors remain valid while offering diverse
options. Experimental results show that ISSR achieves promising performance in
generating plausible distractors, and the self-review mechanism effectively
filters out distractors that could invalidate the question.

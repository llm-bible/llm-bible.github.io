---
layout: publication
title: 'Investigating The Translation Performance Of A Large Multilingual Language Model: The Case Of BLOOM'
authors: Rachel Bawden, Fran√ßois Yvon
conference: "Arxiv"
year: 2023
bibkey: bawden2023investigating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2303.01911"}
tags: ['Few-Shot', 'Prompting', 'WMT']
---
The NLP community recently saw the release of a new large open-access
multilingual language model, BLOOM (BigScience et al., 2022) covering 46
languages. We focus on BLOOM's multilingual ability by evaluating its machine
translation performance across several datasets (WMT, Flores-101 and DiaBLa)
and language pairs (high- and low-resourced). Our results show that 0-shot
performance suffers from overgeneration and generating in the wrong language,
but this is greatly improved in the few-shot setting, with very good results
for a number of language pairs. We study several aspects including prompt
design, model sizes, cross-lingual transfer and the use of discursive context.

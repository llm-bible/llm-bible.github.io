---
layout: publication
title: Team \'UFAL At CMCL 2022 Shared Task\: Figuring Out The Correct Recipe For Predicting Eye-tracking Features Using Pretrained Language Models
authors: Bhattacharya Sunit, Kumar Rishu, Bojar Ondrej
conference: "Arxiv"
year: 2022
bibkey: bhattacharya2022team
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2204.04998"}
tags: ['BERT', 'Model Architecture', 'Pretraining Methods', 'RAG']
---
Eye-Tracking data is a very useful source of information to study cognition and especially language comprehension in humans. In this paper we describe our systems for the CMCL 2022 shared task on predicting eye-tracking information. We describe our experiments with pretrained models like BERT and XLM and the different ways in which we used those representations to predict four eye-tracking features. Along with analysing the effect of using two different kinds of pretrained multilingual language models and different ways of pooling the tokenlevel representations we also explore how contextual information affects the performance of the systems. Finally we also explore if factors like augmenting linguistic information affect the predictions. Our submissions achieved an average MAE of 5.72 and ranked 5th in the shared task. The average MAE showed further reduction to 5.25 in post task evaluation.

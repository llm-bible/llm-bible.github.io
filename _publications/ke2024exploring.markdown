---
layout: publication
title: Exploring the Frontiers of LLMs in Psychological Applications A Comprehensive Review
authors: Ke Luoma, Tong Song, Cheng Peng, Peng Kaiping
conference: "Arxiv"
year: 2024
bibkey: ke2024exploring
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.01519"}
tags: ['ARXIV', 'Applications', 'Survey Paper']
---
This paper explores the frontiers of large language models (LLMs) in psychology applications. Psychology has undergone several theoretical changes and the current use of Artificial Intelligence (AI) and Machine Learning particularly LLMs promises to open up new research directions. We provide a detailed exploration of how LLMs like ChatGPT are transforming psychological research. It discusses the impact of LLMs across various branches of psychology including cognitive and behavioral clinical and counseling educational and developmental and social and cultural psychology highlighting their potential to simulate aspects of human cognition and behavior. The paper delves into the capabilities of these models to emulate human-like text generation offering innovative tools for literature review hypothesis generation experimental design experimental subjects data analysis academic writing and peer review in psychology. While LLMs are essential in advancing research methodologies in psychology the paper also cautions about their technical and ethical challenges. There are issues like data privacy the ethical implications of using LLMs in psychological research and the need for a deeper understanding of these models limitations. Researchers should responsibly use LLMs in psychological studies adhering to ethical standards and considering the potential consequences of deploying these technologies in sensitive areas. Overall the article provides a comprehensive overview of the current state of LLMs in psychology exploring potential benefits and challenges. It serves as a call to action for researchers to leverage LLMs advantages responsibly while addressing associated risks.

---
layout: publication
title: 'Factuality Of Large Language Models: A Survey'
authors: Yuxia Wang, Minghan Wang, Muhammad Arslan Manzoor, Fei Liu, Georgi Georgiev, Rocktim Jyoti Das, Preslav Nakov
conference: "Arxiv"
year: 2024
bibkey: wang2024factuality
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2402.02420'}
tags: ['Attention Mechanism', 'ACL', 'Model Architecture', 'Survey Paper', 'Reinforcement Learning', 'TACL']
---
Large language models (LLMs), especially when instruction-tuned for chat,
have become part of our daily lives, freeing people from the process of
searching, extracting, and integrating information from multiple sources by
offering a straightforward answer to a variety of questions in a single place.
Unfortunately, in many cases, LLM responses are factually incorrect, which
limits their applicability in real-world scenarios. As a result, research on
evaluating and improving the factuality of LLMs has attracted a lot of
attention recently. In this survey, we critically analyze existing work with
the aim to identify the major challenges and their associated causes, pointing
out to potential solutions for improving the factuality of LLMs, and analyzing
the obstacles to automated factuality evaluation for open-ended text
generation. We further offer an outlook on where future research should go.

---
layout: publication
title: 'Critique Of Impure Reason: Unveiling The Reasoning Behaviour Of Medical Large Language Models'
authors: Shamus Sim, Tyrone Chen
conference: "Arxiv"
year: 2024
bibkey: sim2024critique
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2412.15748'}
tags: ['Interpretability and Explainability', 'Tools', 'Reinforcement Learning', 'Ethics and Bias', 'Interpretability']
---
Background: Despite the current ubiquity of Large Language Models (LLMs)
across the medical domain, there is a surprising lack of studies which address
their reasoning behaviour. We emphasise the importance of understanding
reasoning behaviour as opposed to high-level prediction accuracies, since it is
equivalent to explainable AI (XAI) in this context. In particular, achieving
XAI in medical LLMs used in the clinical domain will have a significant impact
across the healthcare sector. Results: Therefore, we define the concept of
reasoning behaviour in the specific context of medical LLMs. We then categorise
and discuss the current state of the art of methods which evaluate reasoning
behaviour in medical LLMs. Finally, we propose theoretical frameworks which can
empower medical professionals or machine learning engineers to gain insight
into the low-level reasoning operations of these previously obscure models.
Conclusion: The subsequent increased transparency and trust in medical machine
learning models by clinicians as well as patients will accelerate the
integration, application as well as further development of medical AI for the
healthcare system as a whole

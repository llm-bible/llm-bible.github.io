---
layout: publication
title: Automatic Question-answer Generation For Long-tail Knowledge
authors: Kumar Rohan, Kim Youngmin, Ravi Sunitha, Sun Haitian, Faloutsos Christos, Salakhutdinov Ruslan, Yoon Minji
conference: "Arxiv"
year: 2024
bibkey: kumar2024automatic
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.01382"}
tags: ['Applications', 'Attention Mechanism', 'Model Architecture']
---
Pretrained Large Language Models (LLMs) have gained significant attention for addressing open-domain Question Answering (QA). While they exhibit high accuracy in answering questions related to common knowledge LLMs encounter difficulties in learning about uncommon long-tail knowledge (tail entities). Since manually constructing QA datasets demands substantial human resources the types of existing QA datasets are limited leaving us with a scarcity of datasets to study the performance of LLMs on tail entities. In this paper we propose an automatic approach to generate specialized QA datasets for tail entities and present the associated research challenges. We conduct extensive experiments by employing pretrained LLMs on our newly generated long-tail QA datasets comparing their performance with and without external resources including Wikipedia and Wikidata knowledge graphs.

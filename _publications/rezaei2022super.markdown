---
layout: publication
title: Super45;prompting Utilizing Model45;independent Contextual Data To Reduce Data Annotation Required In Visual Commonsense Tasks
authors: Rezaei Navid, Reformat Marek Z.
conference: "Arxiv"
year: 2022
bibkey: rezaei2022super
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2204.11922"}
tags: ['Applications', 'Model Architecture', 'Multimodal Models', 'Pretraining Methods', 'Prompting', 'Training Techniques', 'Transformer']
---
Pre45;trained language models have shown excellent results in few45;shot learning scenarios using in45;context learning. Although it is impressive the size of language models can be prohibitive to make them usable in on45;device applications such as sensors or smartphones. With smaller language models task45;specific data annotation is needed to fine45;tune the language model for a specific purpose. However data annotation can have a substantial financial and time burden for small research groups startups and even companies. In this paper we analyze different prompt45;based fine45;tuning techniques to improve results on both language and multimodal causal transformer models. To evaluate our results we use a dataset focusing on visual commonsense reasoning in time. Our results show that by simple model45;agnostic prompt45;based fine45;tuning comparable results can be reached by only using 3537;45;4037; of the fine45;tuning training dataset. The proposed approaches result in significant time and financial savings. As the proposed methods make minimal architectural assumptions other researchers can use the results in their transformer models with minimal adaptations. We plan to release the source code freely to make it easier for the community to use and contribute to our work.

---
layout: publication
title: 'Towards Geo-culturally Grounded LLM Generations'
authors: Piyawat Lertvittayakumjorn, David Kinney, Vinodkumar Prabhakaran, Donald Jr. Martin, Sunipa Dev
conference: "Arxiv"
year: 2025
bibkey: lertvittayakumjorn2025towards
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.13497"}
tags: ['RAG']
---
Generative large language models (LLMs) have been demonstrated to have gaps
in diverse, cultural knowledge across the globe. We investigate the effect of
retrieval augmented generation and search-grounding techniques on the ability
of LLMs to display familiarity with a diverse range of national cultures.
Specifically, we compare the performance of standard LLMs, LLMs augmented with
retrievals from a bespoke knowledge base (i.e., KB grounding), and LLMs
augmented with retrievals from a web search (i.e., search grounding) on a
series of cultural familiarity benchmarks. We find that search grounding
significantly improves the LLM performance on multiple-choice benchmarks that
test propositional knowledge (e.g., the norms, artifacts, and institutions of
national cultures), while KB grounding's effectiveness is limited by inadequate
knowledge base coverage and a suboptimal retriever. However, search grounding
also increases the risk of stereotypical judgments by language models, while
failing to improve evaluators' judgments of cultural familiarity in a human
evaluation with adequate statistical power. These results highlight the
distinction between propositional knowledge about a culture and open-ended
cultural fluency when it comes to evaluating the cultural familiarity of
generative LLMs.

---
layout: publication
title: On Bilingual Lexicon Induction With Large Language Models
authors: Li Yaoyiran, Korhonen Anna, VuliÄ‡ Ivan
conference: "Proceedings of the"
year: 2023
bibkey: li2023bilingual
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.13995"}
tags: ['Applications', 'Prompting']
---
Bilingual Lexicon Induction (BLI) is a core task in multilingual NLP that still to a large extent relies on calculating cross45;lingual word representations. Inspired by the global paradigm shift in NLP towards Large Language Models (LLMs) we examine the potential of the latest generation of LLMs for the development of bilingual lexicons. We ask the following research question Is it possible to prompt and fine45;tune multilingual LLMs (mLLMs) for BLI and how does this approach compare against and complement current BLI approaches To this end we systematically study 1) zero45;shot prompting for unsupervised BLI and 2) few45;shot in45;context prompting with a set of seed translation pairs both without any LLM fine45;tuning as well as 3) standard BLI45;oriented fine45;tuning of smaller LLMs. We experiment with 18 open45;source text45;to45;text mLLMs of different sizes (from 0.3B to 13B parameters) on two standard BLI benchmarks covering a range of typologically diverse languages. Our work is the first to demonstrate strong BLI capabilities of text45;to45;text mLLMs. The results reveal that few45;shot prompting with in45;context examples from nearest neighbours achieves the best performance establishing new state45;of45;the45;art BLI scores for many language pairs. We also conduct a series of in45;depth analyses and ablation studies providing more insights on BLI with (m)LLMs also along with their limitations.

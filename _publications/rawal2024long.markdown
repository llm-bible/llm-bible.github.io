---
layout: publication
title: Cinepile A Long Video Question Answering Dataset And Benchmark
authors: Rawal Ruchit, Saifullah Khalid, Basri Ronen, Jacobs David, Somepalli Gowthami, Goldstein Tom
conference: "Arxiv"
year: 2024
bibkey: rawal2024long
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.08813"}
tags: ['Applications', 'Multimodal Models']
---
Current datasets for long45;form video understanding often fall short of providing genuine long45;form comprehension challenges as many tasks derived from these datasets can be successfully tackled by analyzing just one or a few random frames from a video. To address this issue we present a novel dataset and benchmark CinePile specifically designed for authentic long45;form video understanding. This paper details our innovative approach for creating a question45;answer dataset utilizing advanced LLMs with human45;in45;the45;loop and building upon human45;generated raw data. Our comprehensive dataset comprises 305000 multiple45;choice questions (MCQs) covering various visual and multimodal aspects including temporal comprehension understanding human45;object interactions and reasoning about events or actions within a scene. Additionally we evaluate recent video45;centric LLMs both open45;source and proprietary on the test split of our dataset. The findings reveal that even state45;of45;the45;art video45;centric LLMs significantly lag behind human performance in these tasks highlighting the complexity and challenge inherent in video understanding. The dataset is available at https://hf.co/datasets/tomg&#45;group&#45;umd/cinepile

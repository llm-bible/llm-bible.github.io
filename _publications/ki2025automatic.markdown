---
layout: publication
title: 'Automatic Input Rewriting Improves Translation With Large Language Models'
authors: Dayeon Ki, Marine Carpuat
conference: "NAACL 2025 Main"
year: 2025
bibkey: ki2025automatic
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2502.16682'}
tags: ['Applications']
---
Can we improve machine translation (MT) with LLMs by rewriting their inputs
automatically? Users commonly rely on the intuition that well-written text is
easier to translate when using off-the-shelf MT systems. LLMs can rewrite text
in many ways but in the context of MT, these capabilities have been primarily
exploited to rewrite outputs via post-editing. We present an empirical study of
21 input rewriting methods with 3 open-weight LLMs for translating from English
into 6 target languages. We show that text simplification is the most effective
MT-agnostic rewrite strategy and that it can be improved further when using
quality estimation to assess translatability. Human evaluation further confirms
that simplified rewrites and their MT outputs both largely preserve the
original meaning of the source and MT. These results suggest LLM-assisted input
rewriting as a promising direction for improving translations.

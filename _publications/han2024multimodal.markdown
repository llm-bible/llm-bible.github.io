---
layout: publication
title: MERLIN Multimodal Embedding Refinement Via Llm45;based Iterative Navigation For Text45;video Retrieval45;rerank Pipeline
authors: Han Donghoon, Park Eunhwan, Lee Gisang, Lee Adam, Kwak Nojun
conference: "Arxiv"
year: 2024
bibkey: han2024multimodal
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.12508"}
tags: ['Applications', 'Multimodal Models', 'RAG', 'Reinforcement Learning', 'Tools', 'Training Techniques']
---
The rapid expansion of multimedia content has made accurately retrieving relevant videos from large collections increasingly challenging. Recent advancements in text45;video retrieval have focused on cross45;modal interactions large45;scale foundation model training and probabilistic modeling yet often neglect the crucial user perspective leading to discrepancies between user queries and the content retrieved. To address this we introduce MERLIN (Multimodal Embedding Refinement via LLM45;based Iterative Navigation) a novel training45;free pipeline that leverages Large Language Models (LLMs) for iterative feedback learning. MERLIN refines query embeddings from a user perspective enhancing alignment between queries and video content through a dynamic question answering process. Experimental results on datasets like MSR45;VTT MSVD and ActivityNet demonstrate that MERLIN substantially improves Recall35;64;1 outperforming existing systems and confirming the benefits of integrating LLMs into multimodal retrieval systems for more responsive and context45;aware multimedia retrieval.

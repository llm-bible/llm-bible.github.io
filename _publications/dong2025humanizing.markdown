---
layout: publication
title: 'Humanizing Llms: A Survey Of Psychological Measurements With Tools, Datasets, And Human-agent Applications'
authors: Wenhan Dong, Yuemeng Zhao, Zhen Sun, Yule Liu, Zifan Peng, Jingyi Zheng, Zongmin Zhang, Ziyi Zhang, Jun Wu, Ruiming Wang, Shengmin Xu, Xinyi Huang, Xinlei He
conference: "Arxiv"
year: 2025
bibkey: dong2025humanizing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2505.00049"}
tags: ['Agentic', 'Survey Paper', 'Tools', 'Prompting', 'Applications']
---
As large language models (LLMs) are increasingly used in human-centered
tasks, assessing their psychological traits is crucial for understanding their
social impact and ensuring trustworthy AI alignment. While existing reviews
have covered some aspects of related research, several important areas have not
been systematically discussed, including detailed discussions of diverse
psychological tests, LLM-specific psychological datasets, and the applications
of LLMs with psychological traits. To address this gap, we systematically
review six key dimensions of applying psychological theories to LLMs: (1)
assessment tools; (2) LLM-specific datasets; (3) evaluation metrics
(consistency and stability); (4) empirical findings; (5) personality simulation
methods; and (6) LLM-based behavior simulation. Our analysis highlights both
the strengths and limitations of current methods. While some LLMs exhibit
reproducible personality patterns under specific prompting schemes, significant
variability remains across tasks and settings. Recognizing methodological
challenges such as mismatches between psychological tools and LLMs'
capabilities, as well as inconsistencies in evaluation practices, this study
aims to propose future directions for developing more interpretable, robust,
and generalizable psychological assessment frameworks for LLMs.

---
layout: publication
title: Self45;reflection In LLM Agents Effects On Problem45;solving Performance
authors: Renze Matthew, Guven Erhan
conference: "Arxiv"
year: 2024
bibkey: renze2024self
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.06682"}
  - {name: "Code", url: "https://github.com/matthewrenze/self&#45;reflection"}
tags: ['Agentic', 'Has Code', 'Pretraining Methods']
---
In this study we investigated the effects of self45;reflection in large language models (LLMs) on problem45;solving performance. We instructed nine popular LLMs to answer a series of multiple45;choice questions to provide a performance baseline. For each incorrectly answered question we instructed eight types of self45;reflecting LLM agents to reflect on their mistakes and provide themselves with guidance to improve problem45;solving. Then using this guidance each self45;reflecting agent attempted to re45;answer the same questions. Our results indicate that LLM agents are able to significantly improve their problem45;solving performance through self45;reflection (p < 0.001). In addition we compared the various types of self45;reflection to determine their individual contribution to performance. All code and data are available on GitHub at https://github.com/matthewrenze/self&#45;reflection

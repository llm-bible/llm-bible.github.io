---
layout: publication
title: 'Watermarking Needs Input Repetition Masking'
authors: David Khachaturov, Robert Mullins, Ilia Shumailov, Sumanth Dathathri
conference: "Arxiv"
year: 2025
bibkey: khachaturov2025watermarking
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2504.12229"}
tags: ['Uncategorized']
---
Recent advancements in Large Language Models (LLMs) raised concerns over
potential misuse, such as for spreading misinformation. In response two counter
measures emerged: machine learning-based detectors that predict if text is
synthetic, and LLM watermarking, which subtly marks generated text for
identification and attribution. Meanwhile, humans are known to adjust language
to their conversational partners both syntactically and lexically. By
implication, it is possible that humans or unwatermarked LLMs could
unintentionally mimic properties of LLM generated text, making counter measures
unreliable. In this work we investigate the extent to which such conversational
adaptation happens. We call the concept \\(\textit\{mimicry\}\\) and demonstrate that
both humans and LLMs end up mimicking, including the watermarking signal even
in seemingly improbable settings. This challenges current academic assumptions
and suggests that for long-term watermarking to be reliable, the likelihood of
false positives needs to be significantly lower, while longer word sequences
should be used for seeding watermarking mechanisms.

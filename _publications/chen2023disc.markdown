---
layout: publication
title: 'Disc-finllm: A Chinese Financial Large Language Model Based On Multiple Experts Fine-tuning'
authors: Wei Chen, Qiushi Wang, Zefei Long, Xianyin Zhang, Zhongtian Lu, Bingxuan Li, Siyuan Wang, Jiarong Xu, Xiang Bai, Xuanjing Huang, Zhongyu Wei
conference: "Arxiv"
year: 2023
bibkey: chen2023disc
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.15205"}
  - {name: "Code", url: "https://github.com/FudanDISC/DISC-FinLLM"}
tags: ['Fine-Tuning', 'Tools', 'Applications', 'RAG', 'Training Techniques', 'Has Code', 'Pretraining Methods']
---
We propose Multiple Experts Fine-tuning Framework to build a financial large
language model (LLM), DISC-FinLLM. Our methodology improves general LLMs by
endowing them with multi-turn question answering abilities, domain text
processing capabilities, mathematical computation skills, and
retrieval-enhanced generation capabilities. We build a financial
instruction-tuning dataset named DISC-FIN-SFT, including instruction samples of
four categories (consulting, NLP tasks, computing and retrieval-augmented
generation). Evaluations conducted on multiple benchmarks demonstrate that our
model performs better than baseline models in various financial scenarios.
Further resources can be found at https://github.com/FudanDISC/DISC-FinLLM.

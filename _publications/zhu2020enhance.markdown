---
layout: publication
title: 'Enhance Multimodal Transformer With External Label And In-domain Pretrain:
  Hateful Meme Challenge Winning Solution'
authors: Ron Zhu
conference: Arxiv
year: 2020
citations: 44
bibkey: zhu2020enhance
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2012.08290'}]
tags: [Transformer, Multimodal Models]
---
Hateful meme detection is a new research area recently brought out that
requires both visual, linguistic understanding of the meme and some background
knowledge to performing well on the task. This technical report summarises the
first place solution of the Hateful Meme Detection Challenge 2020, which
extending state-of-the-art visual-linguistic transformers to tackle this
problem. At the end of the report, we also point out the shortcomings and
possible directions for improving the current methodology.
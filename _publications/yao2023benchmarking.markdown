---
layout: publication
title: Benchmarking Llm45;based Machine Translation On Cultural Awareness
authors: Yao Binwei, Jiang Ming, Yang Diyi, Hu Junjie
conference: "Arxiv"
year: 2023
bibkey: yao2023benchmarking
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2305.14328"}
tags: ['Applications', 'GPT', 'Interpretability And Explainability', 'Model Architecture', 'Prompting']
---
Translating cultural45;specific content is crucial for effective cross45;cultural communication. However many MT systems still struggle to translate sentences containing cultural45;specific entities accurately and understandably. Recent advancements in in45;context learning utilize lightweight prompts to guide large language models (LLMs) in machine translation tasks. Nevertheless the effectiveness of this approach in enhancing machine translation with cultural awareness remains uncertain. To address this gap we introduce a new data curation pipeline to construct a culturally relevant parallel corpus enriched with annotations of cultural45;specific items. Furthermore we devise a novel evaluation metric to assess the understandability of translations in a reference45;free manner by GPT45;4. We evaluate a variety of neural machine translation (NMT) and LLM45;based MT systems using our dataset. Additionally we propose several prompting strategies for LLMs to incorporate external and internal cultural knowledge into the translation process. Our results demonstrate that eliciting explanations can significantly enhance the understandability of cultural45;specific entities especially those without well45;known translations.

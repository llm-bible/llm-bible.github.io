---
layout: publication
title: 'I''ve Got The "answer"! Interpretation Of Llms Hidden States In Question Answering'
authors: Valeriya Goloviznina, Evgeny Kotelnikov
conference: "Arxiv"
year: 2024
bibkey: goloviznina2024got
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.02060"}
tags: ['Tools', 'Applications', 'Interpretability and Explainability', 'Reinforcement Learning', 'Interpretability', 'Quantization']
---
Interpretability and explainability of AI are becoming increasingly important
in light of the rapid development of large language models (LLMs). This paper
investigates the interpretation of LLMs in the context of the knowledge-based
question answering. The main hypothesis of the study is that correct and
incorrect model behavior can be distinguished at the level of hidden states.
The quantized models LLaMA-2-7B-Chat, Mistral-7B, Vicuna-7B and the MuSeRC
question-answering dataset are used to test this hypothesis. The results of the
analysis support the proposed hypothesis. We also identify the layers which
have a negative effect on the model's behavior. As a prospect of practical
application of the hypothesis, we propose to train such "weak" layers
additionally in order to improve the quality of the task solution.

---
layout: publication
title: 'Creative Preference Optimization'
authors: Mete Ismayilzada, Antonio Jr. Laverghetta, Simone A. Luchini, Reet Patel, Antoine Bosselut, Lonneke Van Der Plas, Roger Beaty
conference: "Arxiv"
year: 2025
bibkey: ismayilzada2025creative
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2505.14442'}
tags: ['GPT', 'Efficiency and Optimization', 'Model Architecture', 'Tools']
---
While Large Language Models (LLMs) have demonstrated impressive performance across natural language generation tasks, their ability to generate truly creative content-characterized by novelty, diversity, surprise, and quality-remains limited. Existing methods for enhancing LLM creativity often focus narrowly on diversity or specific tasks, failing to address creativity's multifaceted nature in a generalizable way. In this work, we propose Creative Preference Optimization (CrPO), a novel alignment method that injects signals from multiple creativity dimensions into the preference optimization objective in a modular fashion. We train and evaluate creativity-augmented versions of several models using CrPO and MuCE, a new large-scale human preference dataset spanning over 200,000 human-generated responses and ratings from more than 30 psychological creativity assessments. Our models outperform strong baselines, including GPT-4o, on both automated and human evaluations, producing more novel, diverse, and surprising generations while maintaining high output quality. Additional evaluations on NoveltyBench further confirm the generalizability of our approach. Together, our results demonstrate that directly optimizing for creativity within preference frameworks is a promising direction for advancing the creative capabilities of LLMs without compromising output quality.

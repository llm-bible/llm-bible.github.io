---
layout: publication
title: 'Good Parenting Is All You Need -- Multi-agentic LLM Hallucination Mitigation'
authors: Ted Kwartler, Matthew Berman, Alan Aqrawi
conference: "Arxiv"
year: 2024
bibkey: kwartler2024good
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2410.14262"}
tags: ['Agentic', 'Model Architecture', 'GPT']
---
This study explores the ability of Large Language Model (LLM) agents to
detect and correct hallucinations in AI-generated content. A primary agent was
tasked with creating a blog about a fictional Danish artist named Flipfloppidy,
which was then reviewed by another agent for factual inaccuracies. Most LLMs
hallucinated the existence of this artist. Across 4,900 test runs involving
various combinations of primary and reviewing agents, advanced AI models such
as Llama3-70b and GPT-4 variants demonstrated near-perfect accuracy in
identifying hallucinations and successfully revised outputs in 85% to 100% of
cases following feedback. These findings underscore the potential of advanced
AI models to significantly enhance the accuracy and reliability of generated
content, providing a promising approach to improving AI workflow orchestration.

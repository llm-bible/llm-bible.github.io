---
layout: publication
title: Towards Large Language Model Aided Program Refinement
authors: Cai Yufan, Hou Zhe, Luan Xiaokun, Baena David Miguel Sanan, Lin Yun, Sun Jun, Dong Jin Song
conference: "Arxiv"
year: 2024
bibkey: cai2024towards
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.18616"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Prompting', 'Reinforcement Learning']
---
Program refinement involves correctness-preserving transformations from formal high-level specification statements into executable programs. Traditional verification tool support for program refinement is highly interactive and lacks automation. On the other hand the emergence of large language models (LLMs) enables automatic code generations from informal natural language specifications. However code generated by LLMs is often unreliable. Moreover the opaque procedure from specification to code provided by LLM is an uncontrolled black box. We propose LLM4PR a tool that combines formal program refinement techniques with informal LLM-based methods to (1) transform the specification to preconditions and postconditions (2) automatically build prompts based on refinement calculus (3) interact with LLM to generate code and finally (4) verify that the generated code satisfies the conditions of refinement calculus thus guaranteeing the correctness of the code. We have implemented our tool using GPT4 Coq and Coqhammer and evaluated it on the HumanEval and EvalPlus datasets.

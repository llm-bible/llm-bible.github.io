---
layout: publication
title: 'Beyond Generating Code: Evaluating GPT On A Data Visualization Course'
authors: Chen Zhu-tian, Chenyang Zhang, Qianwen Wang, Jakob Troidl, Simon Warchol, Johanna Beyer, Nils Gehlenborg, Hanspeter Pfister
conference: "Arxiv"
year: 2023
bibkey: zhutian2023beyond
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2306.02914"}
tags: ['Model Architecture', 'GPT', 'Pretraining Methods', 'Transformer', 'Fine-Tuning', 'Applications']
---
This paper presents an empirical evaluation of the performance of the
Generative Pre-trained Transformer (GPT) model in Harvard's CS171 data
visualization course. While previous studies have focused on GPT's ability to
generate code for visualizations, this study goes beyond code generation to
evaluate GPT's abilities in various visualization tasks, such as data
interpretation, visualization design, visual data exploration, and insight
communication. The evaluation utilized GPT-3.5 and GPT-4 to complete
assignments of CS171, and included a quantitative assessment based on the
established course rubrics, a qualitative analysis informed by the feedback of
three experienced graders, and an exploratory study of GPT's capabilities in
completing border visualization tasks. Findings show that GPT-4 scored 80% on
quizzes and homework, and TFs could distinguish between GPT- and
human-generated homework with 70% accuracy. The study also demonstrates GPT's
potential in completing various visualization tasks, such as data cleanup,
interaction with visualizations, and insight communication. The paper concludes
by discussing the strengths and limitations of GPT in data visualization,
potential avenues for incorporating GPT in broader visualization tasks, and the
need to redesign visualization education.

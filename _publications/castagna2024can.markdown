---
layout: publication
title: 'Can Formal Argumentative Reasoning Enhance Llms Performances?'
authors: Federico Castagna, Isabel Sassoon, Simon Parsons
conference: "Arxiv"
year: 2024
bibkey: castagna2024can
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.13036"}
tags: ['Agentic', 'Training Techniques', 'Tools', 'Reinforcement Learning', 'Fine-Tuning']
---
Recent years witnessed significant performance advancements in
deep-learning-driven natural language models, with a strong focus on the
development and release of Large Language Models (LLMs). These improvements
resulted in better quality AI-generated output but rely on resource-expensive
training and upgrading of models. Although different studies have proposed a
range of techniques to enhance LLMs without retraining, none have considered
computational argumentation as an option. This is a missed opportunity since
computational argumentation is an intuitive mechanism that formally captures
agents' interactions and the information conflict that may arise during such
interplays, and so it seems well-suited for boosting the reasoning and
conversational abilities of LLMs in a seamless manner. In this paper, we
present a pipeline (MQArgEng) and preliminary study to evaluate the effect of
introducing computational argumentation semantics on the performance of LLMs.
Our experiment's goal was to provide a proof-of-concept and a feasibility
analysis in order to foster (or deter) future research towards a fully-fledged
argumentation engine plugin for LLMs. Exploratory results using the MT-Bench
indicate that MQArgEng provides a moderate performance gain in most of the
examined topical categories and, as such, show promise and warrant further
research.

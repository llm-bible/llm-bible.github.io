---
layout: publication
title: Groundial Human45;norm Grounded Safe Dialog Response Generation
authors: Kim Siwon, Dai Shuyang, Kachuee Mohammad, Ray Shayan, Taghavi Tara, Yoon Sungroh
conference: "Arxiv"
year: 2024
bibkey: kim2024human
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.08968"}
tags: ['Applications', 'Responsible AI']
---
Current conversational AI systems based on large language models (LLMs) are known to generate unsafe responses agreeing to offensive user input or including toxic content. Previous research aimed to alleviate the toxicity by fine45;tuning LLM with manually annotated safe dialogue histories. However the dependency on additional tuning requires substantial costs. To remove the dependency we propose GrounDial where response safety is achieved by grounding responses to commonsense social rules without requiring fine45;tuning. A hybrid approach of in45;context learning and human45;norm45;guided decoding of GrounDial enables the response to be quantitatively and qualitatively safer even without additional data or tuning.

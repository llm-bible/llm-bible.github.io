---
layout: publication
title: 'Groundial: Human-norm Grounded Safe Dialog Response Generation'
authors: Siwon Kim, Shuyang Dai, Mohammad Kachuee, Shayan Ray, Tara Taghavi, Sungroh Yoon
conference: "Arxiv"
year: 2024
bibkey: kim2024human
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2402.08968'}
tags: ['In-Context Learning', 'Training Techniques', 'Fine-Tuning', 'Prompting', 'Responsible AI', 'Pretraining Methods']
---
Current conversational AI systems based on large language models (LLMs) are
known to generate unsafe responses, agreeing to offensive user input or
including toxic content. Previous research aimed to alleviate the toxicity, by
fine-tuning LLM with manually annotated safe dialogue histories. However, the
dependency on additional tuning requires substantial costs. To remove the
dependency, we propose GrounDial, where response safety is achieved by
grounding responses to commonsense social rules without requiring fine-tuning.
A hybrid approach of in-context learning and human-norm-guided decoding of
GrounDial enables the response to be quantitatively and qualitatively safer
even without additional data or tuning.

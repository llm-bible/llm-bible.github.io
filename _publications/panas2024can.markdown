---
layout: publication
title: Can Large Language Models Put 2 And 2 Together Probing For Entailed Arithmetical Relationships
authors: Panas D., Seth S., Belle V.
conference: "Arxiv"
year: 2024
bibkey: panas2024can
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.19432"}
tags: ['GPT', 'Model Architecture', 'Reinforcement Learning']
---
Two major areas of interest in the era of Large Language Models regard questions of what do LLMs know and if and how they may be able to reason (or rather approximately reason). Since to date these lines of work progressed largely in parallel (with notable exceptions) we are interested in investigating the intersection probing for reasoning about the implicitly45;held knowledge. Suspecting the performance to be lacking in this area we use a very simple set45;up of comparisons between cardinalities associated with elements of various subjects (e.g. the number of legs a bird has versus the number of wheels on a tricycle). We empirically demonstrate that although LLMs make steady progress in knowledge acquisition and (pseudo)reasoning with each new GPT release their capabilities are limited to statistical inference only. It is difficult to argue that pure statistical learning can cope with the combinatorial explosion inherent in many commonsense reasoning tasks especially once arithmetical notions are involved. Further we argue that bigger is not always better and chasing purely statistical improvements is flawed at the core since it only exacerbates the dangerous conflation of the production of correct answers with genuine reasoning ability.

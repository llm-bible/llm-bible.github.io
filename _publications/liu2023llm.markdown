---
layout: publication
title: Llm45;powered Hierarchical Language Agent For Real45;time Human45;ai Coordination
authors: Liu Jijia, Yu Chao, Gao Jiaxuan, Xie Yuqing, Liao Qingmin, Wu Yi, Wang Yu
conference: "Arxiv"
year: 2023
bibkey: liu2023llm
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2312.15224"}
tags: ['Agentic', 'Applications', 'Prompting', 'Tools']
---
AI agents powered by Large Language Models (LLMs) have made significant advances enabling them to assist humans in diverse complex tasks and leading to a revolution in human45;AI coordination. LLM45;powered agents typically require invoking LLM APIs and employing artificially designed complex prompts which results in high inference latency. While this paradigm works well in scenarios with minimal interactive demands such as code generation it is unsuitable for highly interactive and real45;time applications such as gaming. Traditional gaming AI often employs small models or reactive policies enabling fast inference but offering limited task completion and interaction abilities. In this work we consider Overcooked as our testbed where players could communicate with natural language and cooperate to serve orders. We propose a Hierarchical Language Agent (HLA) for human45;AI coordination that provides both strong reasoning abilities while keeping real45;time execution. In particular HLA adopts a hierarchical framework and comprises three modules a proficient LLM referred to as Slow Mind for intention reasoning and language interaction a lightweight LLM referred to as Fast Mind for generating macro actions and a reactive policy referred to as Executor for transforming macro actions into atomic actions. Human studies show that HLA outperforms other baseline agents including slow45;mind45;only agents and fast45;mind45;only agents with stronger cooperation abilities faster responses and more consistent language communications.

---
layout: publication
title: Adversarial Self45;attention For Language Understanding
authors: Wu Hongqiu, Ding Ruixue, Zhao Hai, Xie Pengjun, Huang Fei, Zhang Min
conference: "Arxiv"
year: 2022
bibkey: wu2022adversarial
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2206.12608"}
tags: ['Attention Mechanism', 'BERT', 'Ethics And Bias', 'Fine Tuning', 'Model Architecture', 'Pretraining Methods', 'RAG', 'Security', 'Training Techniques', 'Transformer']
---
Deep neural models (e.g. Transformer) naturally learn spurious features which create a shortcut between the labels and inputs thus impairing the generalization and robustness. This paper advances the self45;attention mechanism to its robust variant for Transformer45;based pre45;trained language models (e.g. BERT). We propose textit123;Adversarial Self45;Attention125; mechanism (ASA) which adversarially biases the attentions to effectively suppress the model reliance on features (e.g. specific keywords) and encourage its exploration of broader semantics. We conduct a comprehensive evaluation across a wide range of tasks for both pre45;training and fine45;tuning stages. For pre45;training ASA unfolds remarkable performance gains compared to naive training for longer steps. For fine45;tuning ASA45;empowered models outweigh naive models by a large margin considering both generalization and robustness.

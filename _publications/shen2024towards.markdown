---
layout: publication
title: 'Thermometer: Towards Universal Calibration For Large Language Models'
authors: Shen Maohao, Das Subhro, Greenewald Kristjan, Sattigeri Prasanna, Wornell Gregory, Ghosh Soumya
conference: "Arxiv"
year: 2024
bibkey: shen2024towards
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.08819"}
tags: ['Applications', 'Pretraining Methods', 'Reinforcement Learning']
---
We consider the issue of calibration in large language models (LLM). Recent studies have found that common interventions such as instruction tuning often result in poorly calibrated LLMs. Although calibration is well-explored in traditional applications calibrating LLMs is uniquely challenging. These challenges stem as much from the severe computational requirements of LLMs as from their versatility which allows them to be applied to diverse tasks. Addressing these challenges we propose THERMOMETER a calibration approach tailored to LLMs. THERMOMETER learns an auxiliary model given data from multiple tasks for calibrating a LLM. It is computationally efficient preserves the accuracy of the LLM and produces better-calibrated responses for new tasks. Extensive empirical evaluations across various benchmarks demonstrate the effectiveness of the proposed method.

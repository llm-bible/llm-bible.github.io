---
layout: publication
title: 'Poact: Policy And Action Dual-control Agent For Generalized Applications'
authors: Guozhi Yuan, Youfeng Liu, Jingli Yang, Wei Jia, Kai Lin, Yansong Gao, Shan He, Zilin Ding, Haitao Li
conference: "Arxiv"
year: 2025
bibkey: yuan2025policy
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2501.07054'}
tags: ['Agentic', 'RAG', 'Model Architecture', 'Applications', 'Tools', 'GPT']
---
Based on their superior comprehension and reasoning capabilities, Large
Language Model (LLM) driven agent frameworks have achieved significant success
in numerous complex reasoning tasks. ReAct-like agents can solve various
intricate problems step-by-step through progressive planning and tool calls,
iteratively optimizing new steps based on environmental feedback. However, as
the planning capabilities of LLMs improve, the actions invoked by tool calls in
ReAct-like frameworks often misalign with complex planning and challenging data
organization. Code Action addresses these issues while also introducing the
challenges of a more complex action space and more difficult action
organization. To leverage Code Action and tackle the challenges of its
complexity, this paper proposes Policy and Action Dual-Control Agent (PoAct)
for generalized applications. The aim is to achieve higher-quality code actions
and more accurate reasoning paths by dynamically switching reasoning policies
and modifying the action space. Experimental results on the Agent Benchmark for
both legal and generic scenarios demonstrate the superior reasoning
capabilities and reduced token consumption of our approach in complex tasks. On
the LegalAgentBench, our method shows a 20 percent improvement over the
baseline while requiring fewer tokens. We conducted experiments and analyses on
the GPT-4o and GLM-4 series models, demonstrating the significant potential and
scalability of our approach to solve complex problems.

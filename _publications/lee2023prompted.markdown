---
layout: publication
title: Prompted LLMs as Chatbot Modules for Long Open-domain Conversation
authors: Lee Gibbeum, Hartmann Volker, Park Jongho, Papailiopoulos Dimitris, Lee Kangwook
conference: "Arxiv"
year: 2023
bibkey: lee2023prompted
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2305.04533"}
tags: ['Pretraining Methods', 'Arxiv']
---
In this paper we propose MPC (Modular Prompted Chatbot) a new approach for creating high-quality conversational agents without the need for fine-tuning. Our method utilizes pre-trained large language models (LLMs) as individual modules for long-term consistency and flexibility by using techniques such as few-shot prompting chain-of-thought (CoT) and external memory. Our human evaluation results show that MPC is on par with fine-tuned chatbot models in open-domain conversations making it an effective solution for creating consistent and engaging chatbots.

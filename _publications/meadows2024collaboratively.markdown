---
layout: publication
title: 'Localvaluebench: A Collaboratively Built And Extensible Benchmark For Evaluating Localized Value Alignment And Ethical Safety In Large Language Models'
authors: Gwenyth Isobel Meadows, Nicholas Wai Long Lau, Eva Adelina Susanto, Chi Lok Yu, Aditya Paul
conference: "Arxiv"
year: 2024
bibkey: meadows2024collaboratively
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.01460"}
tags: ['Responsible AI', 'Prompting', 'Tools', 'Reinforcement Learning']
---
The proliferation of large language models (LLMs) requires robust evaluation
of their alignment with local values and ethical standards, especially as
existing benchmarks often reflect the cultural, legal, and ideological values
of their creators. \textsc\{LocalValueBench\}, introduced in this paper, is an
extensible benchmark designed to assess LLMs' adherence to Australian values,
and provides a framework for regulators worldwide to develop their own LLM
benchmarks for local value alignment. Employing a novel typology for ethical
reasoning and an interrogation approach, we curated comprehensive questions and
utilized prompt engineering strategies to probe LLMs' value alignment. Our
evaluation criteria quantified deviations from local values, ensuring a
rigorous assessment process. Comparative analysis of three commercial LLMs by
USA vendors revealed significant insights into their effectiveness and
limitations, demonstrating the critical importance of value alignment. This
study offers valuable tools and methodologies for regulators to create tailored
benchmarks, highlighting avenues for future research to enhance ethical AI
development.

---
layout: publication
title: 'The Fusion Of Large Language Models And Formal Methods For Trustworthy AI Agents: A Roadmap'
authors: Yedi Zhang, Yufan Cai, Xinyue Zuo, Xiaokun Luan, Kailong Wang, Zhe Hou, Yifan Zhang, Zhiyuan Wei, Meng Sun, Jun Sun, Jing Sun, Jin Song Dong
conference: "Arxiv"
year: 2024
bibkey: zhang2024fusion
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2412.06512'}
tags: ['Agentic', 'RAG', 'Efficiency and Optimization', 'Security', 'Tools', 'Merging', 'Reinforcement Learning']
---
Large Language Models (LLMs) have emerged as a transformative AI paradigm,
profoundly influencing daily life through their exceptional language
understanding and contextual generation capabilities. Despite their remarkable
performance, LLMs face a critical challenge: the propensity to produce
unreliable outputs due to the inherent limitations of their learning-based
nature. Formal methods (FMs), on the other hand, are a well-established
computation paradigm that provides mathematically rigorous techniques for
modeling, specifying, and verifying the correctness of systems. FMs have been
extensively applied in mission-critical software engineering, embedded systems,
and cybersecurity. However, the primary challenge impeding the deployment of
FMs in real-world settings lies in their steep learning curves, the absence of
user-friendly interfaces, and issues with efficiency and adaptability.
  This position paper outlines a roadmap for advancing the next generation of
trustworthy AI systems by leveraging the mutual enhancement of LLMs and FMs.
First, we illustrate how FMs, including reasoning and certification techniques,
can help LLMs generate more reliable and formally certified outputs.
Subsequently, we highlight how the advanced learning capabilities and
adaptability of LLMs can significantly enhance the usability, efficiency, and
scalability of existing FM tools. Finally, we show that unifying these two
computation paradigms -- integrating the flexibility and intelligence of LLMs
with the rigorous reasoning abilities of FMs -- has transformative potential
for the development of trustworthy AI software systems. We acknowledge that
this integration has the potential to enhance both the trustworthiness and
efficiency of software engineering practices while fostering the development of
intelligent FM tools capable of addressing complex yet real-world challenges.

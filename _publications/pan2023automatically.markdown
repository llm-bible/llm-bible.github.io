---
layout: publication
title: Automatically Correcting Large Language Models Surveying The Landscape Of Diverse Self45;correction Strategies
authors: Pan Liangming, Saxon Michael, Xu Wenda, Nathani Deepak, Wang Xinyi, Wang William Yang
conference: "Arxiv"
year: 2023
bibkey: pan2023automatically
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2308.03188"}
tags: ['Applications', 'Merging', 'Prompting', 'RAG', 'Survey Paper', 'Training Techniques']
---
Large language models (LLMs) have demonstrated remarkable performance across a wide array of NLP tasks. However their efficacy is undermined by undesired and inconsistent behaviors including hallucination unfaithful reasoning and toxic content. A promising approach to rectify these flaws is self45;correction where the LLM itself is prompted or guided to fix problems in its own output. Techniques leveraging automated feedback 45;45; either produced by the LLM itself or some external system 45;45; are of particular interest as they are a promising way to make LLM45;based solutions more practical and deployable with minimal human feedback. This paper presents a comprehensive review of this emerging class of techniques. We analyze and taxonomize a wide array of recent work utilizing these strategies including training45;time generation45;time and post45;hoc correction. We also summarize the major applications of this strategy and conclude by discussing future directions and challenges.

---
layout: publication
title: Explaining Pre45;trained Language Models With Attribution Scores An Analysis In Low45;resource Settings
authors: Zhou Wei, Adel Heike, Schuff Hendrik, Vu Ngoc Thang
conference: "Arxiv"
year: 2024
bibkey: zhou2024explaining
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.05338"}
tags: ['Attention Mechanism', 'Interpretability And Explainability', 'Model Architecture', 'Pretraining Methods', 'Prompting', 'Training Techniques']
---
Attribution scores indicate the importance of different input parts and can thus explain model behaviour. Currently prompt45;based models are gaining popularity i.a. due to their easier adaptability in low45;resource settings. However the quality of attribution scores extracted from prompt45;based models has not been investigated yet. In this work we address this topic by analyzing attribution scores extracted from prompt45;based models w.r.t. plausibility and faithfulness and comparing them with attribution scores extracted from fine45;tuned models and large language models. In contrast to previous work we introduce training size as another dimension into the analysis. We find that using the prompting paradigm (with either encoder45;based or decoder45;based models) yields more plausible explanations than fine45;tuning the models in low45;resource settings and Shapley Value Sampling consistently outperforms attention and Integrated Gradients in terms of leading to more plausible and faithful explanations.

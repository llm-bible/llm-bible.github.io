---
layout: publication
title: Enhanced Visual Question Answering A Comparative Analysis And Textual Feature Extraction Via Convolutions
authors: Zhang Zhilin
conference: "Arxiv"
year: 2024
bibkey: zhang2024enhanced
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.00479"}
tags: ['Applications', 'Fine Tuning', 'Model Architecture', 'Pretraining Methods', 'RAG', 'Reinforcement Learning', 'Tools', 'Transformer']
---
Visual Question Answering (VQA) has emerged as a highly engaging field in recent years attracting increasing research efforts aiming to enhance VQA accuracy through the deployment of advanced models such as Transformers. Despite this growing interest there has been limited exploration into the comparative analysis and impact of textual modalities within VQA particularly in terms of model complexity and its effect on performance. In this work we conduct a comprehensive comparison between complex textual models that leverage long dependency mechanisms and simpler models focusing on local textual features within a well-established VQA framework. Our findings reveal that employing complex textual encoders is not invariably the optimal approach for the VQA-v2 dataset. Motivated by this insight we introduce an improved model ConvGRU which incorporates convolutional layers to enhance the representation of question text. Tested on the VQA-v2 dataset ConvGRU achieves better performance without substantially increasing parameter complexity.

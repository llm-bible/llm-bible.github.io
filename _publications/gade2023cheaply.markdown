---
layout: publication
title: Badllama Cheaply Removing Safety Fine45;tuning From Llama 245;chat 13B
authors: Gade Pranav, Lermen Simon, Rogers-smith Charlie, Ladish Jeffrey
conference: "Arxiv"
year: 2023
bibkey: gade2023cheaply
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2311.00117"}
tags: ['Pretraining Methods', 'Responsible AI']
---
Llama 245;Chat is a collection of large language models that Meta developed and released to the public. While Meta fine45;tuned Llama 245;Chat to refuse to output harmful content we hypothesize that public access to model weights enables bad actors to cheaply circumvent Llama 245;Chats safeguards and weaponize Llama 2s capabilities for malicious purposes. We demonstrate that it is possible to effectively undo the safety fine45;tuning from Llama 245;Chat 13B with less than 200 while retaining its general capabilities. Our results demonstrate that safety45;fine tuning is ineffective at preventing misuse when model weights are released publicly. Given that future models will likely have much greater ability to cause harm at scale it is essential that AI developers address threats from fine45;tuning when considering whether to publicly release their model weights.

---
layout: publication
title: 'CCNU At Semeval-2025 Task 3: Leveraging Internal And External Knowledge Of Large Language Models For Multilingual Hallucination Annotation'
authors: Xu Liu, Guanyi Chen
conference: "Arxiv"
year: 2025
bibkey: liu2025ccnu
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2505.11965'}
tags: ['RAG', 'Security']
---
We present the system developed by the Central China Normal University (CCNU) team for the Mu-SHROOM shared task, which focuses on identifying hallucinations in question-answering systems across 14 different languages. Our approach leverages multiple Large Language Models (LLMs) with distinct areas of expertise, employing them in parallel to annotate hallucinations, effectively simulating a crowdsourcing annotation process. Furthermore, each LLM-based annotator integrates both internal and external knowledge related to the input during the annotation process. Using the open-source LLM DeepSeek-V3, our system achieves the top ranking (\#1) for Hindi data and secures a Top-5 position in seven other languages. In this paper, we also discuss unsuccessful approaches explored during our development process and share key insights gained from participating in this shared task.

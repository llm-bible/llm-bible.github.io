---
layout: publication
title: 'Assessing The Capability Of Large Language Models For Domain-specific Ontology Generation'
authors: Anna Sofia Lippolis, Mohammad Javad Saeedizade, Robin Keskisarkka, Aldo Gangemi, Eva Blomqvist, Andrea Giovanni Nuzzolese
conference: "Arxiv"
year: 2025
bibkey: lippolis2025assessing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2504.17402"}
tags: ['Uncategorized']
---
Large Language Models (LLMs) have shown significant potential for ontology
engineering. However, it is still unclear to what extent they are applicable to
the task of domain-specific ontology generation. In this study, we explore the
application of LLMs for automated ontology generation and evaluate their
performance across different domains. Specifically, we investigate the
generalizability of two state-of-the-art LLMs, DeepSeek and o1-preview, both
equipped with reasoning capabilities, by generating ontologies from a set of
competency questions (CQs) and related user stories. Our experimental setup
comprises six distinct domains carried out in existing ontology engineering
projects and a total of 95 curated CQs designed to test the models' reasoning
for ontology engineering. Our findings show that with both LLMs, the
performance of the experiments is remarkably consistent across all domains,
indicating that these methods are capable of generalizing ontology generation
tasks irrespective of the domain. These results highlight the potential of
LLM-based approaches in achieving scalable and domain-agnostic ontology
construction and lay the groundwork for further research into enhancing
automated reasoning and knowledge representation techniques.

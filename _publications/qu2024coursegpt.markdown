---
layout: publication
title: "Coursegpt-zh: An Educational Large Language Model Based On Knowledge Distillation Incorporating Prompt Optimization"
authors: Qu Zheyan, Yin Lu, Yu Zitong, Wang Wenbo, Zhang Xing
conference: "Arxiv"
year: 2024
bibkey: qu2024coursegpt
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.04781"}
tags: ['Distillation', 'Efficiency And Optimization', 'Fine Tuning', 'GPT', 'Model Architecture', 'Pretraining Methods', 'Prompting', 'RAG', 'Reinforcement Learning', 'TACL', 'Tools', 'Training Techniques']
---
Large language models (LLMs) have demonstrated astonishing capabilities in natural language processing (NLP) tasks sparking interest in their application to professional domains with higher specialized requirements. However restricted access to closed-source LLMs via APIs and the difficulty in collecting massive high-quality datasets pose obstacles to the development of large language models in education fields of various courses. Given these challenges we propose CourseGPT-zh a course-oriented education LLM that supports customization and low-cost deployment. To address the comprehensiveness and diversity requirements of course-specific corpora we design a high-quality question-answering corpus distillation framework incorporating prompt optimization which effectively mines textbook knowledge and enhances its diversity. Moreover considering the alignment of LLM responses with user needs a novel method for discrete prompt optimization based on LLM-as-Judge is introduced. During optimization this framework leverages the LLMs ability to reflect on and exploit error feedback and patterns allowing for prompts that meet user needs and preferences while saving response length. Lastly we obtain CourseGPT-zh based on the open-source LLM using parameter-efficient fine-tuning. Experimental results show that our discrete prompt optimization framework effectively improves the response quality of ChatGPT and CourseGPT-zh exhibits strong professional capabilities in specialized knowledge question-answering significantly outperforming comparable open-source models.

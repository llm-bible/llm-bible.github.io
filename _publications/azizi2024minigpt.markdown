---
layout: publication
title: Minigpt45;reverse45;designing Predicting Image Adjustments Utilizing Minigpt45;4
authors: Azizi Vahid, Koochaki Fatemeh
conference: "Arxiv"
year: 2024
bibkey: azizi2024minigpt
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.00971"}
  - {name: "Code", url: "https://github.com/VahidAz/MiniGPT&#45;Reverse&#45;Designing&#125;"}
tags: ['GPT', 'Has Code', 'Model Architecture', 'Pretraining Methods']
---
Vision45;Language Models (VLMs) have recently seen significant advancements through integrating with Large Language Models (LLMs). The VLMs which process image and text modalities simultaneously have demonstrated the ability to learn and understand the interaction between images and texts across various multi45;modal tasks. Reverse designing which could be defined as a complex vision45;language task aims to predict the edits and their parameters given a source image an edited version and an optional high45;level textual edit description. This task requires VLMs to comprehend the interplay between the source image the edited version and the optional textual context simultaneously going beyond traditional vision45;language tasks. In this paper we extend and fine45;tune MiniGPT45;4 for the reverse designing task. Our experiments demonstrate the extensibility of off45;the45;shelf VLMs specifically MiniGPT45;4 for more complex tasks such as reverse designing. Code is available at this href123;https://github.com/VahidAz/MiniGPT&#45;Reverse&#45;Designing&#125;

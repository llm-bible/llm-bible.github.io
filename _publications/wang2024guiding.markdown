---
layout: publication
title: Guiding And Diversifying Llm45;based Story Generation Via Answer Set Programming
authors: Wang Phoebe J., Kreminski Max
conference: "Arxiv"
year: 2024
bibkey: wang2024guiding
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.00554"}
tags: ['Pretraining Methods']
---
Instruction45;tuned large language models (LLMs) are capable of generating stories in response to open45;ended user requests but the resulting stories tend to be limited in their diversity. Older symbolic approaches to story generation (such as planning) can generate substantially more diverse plot outlines but are limited to producing stories that recombine a fixed set of hand45;engineered character action templates. Can we combine the strengths of these approaches while mitigating their weaknesses We propose to do so by using a higher45;level and more abstract symbolic specification of high45;level story structure 45;45; implemented via answer set programming (ASP) 45;45; to guide and diversify LLM45;based story generation. Via semantic similarity analysis we demonstrate that our approach produces more diverse stories than an unguided LLM and via code excerpts we demonstrate the improved compactness and flexibility of ASP45;based outline generation over full45;fledged narrative planning.

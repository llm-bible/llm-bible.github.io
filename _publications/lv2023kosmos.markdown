---
layout: publication
title: KOSMOS45;2.5 A Multimodal Literate Model
authors: Lv Tengchao, Huang Yupan, Chen Jingye, Zhao Yuzhong, Jia Yilin, Cui Lei, Ma Shuming, Chang Yaoyao, Huang Shaohan, Wang Wenhui, Dong Li, Luo Weiyao, Wu Shaoxiang, Wang Guoxin, Zhang Cha, Wei Furu
conference: "Arxiv"
year: 2023
bibkey: lv2023kosmos
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.11419"}
  - {name: "Code", url: "https://aka.ms/kosmos25&#125;"}
tags: ['Applications', 'GPT', 'Has Code', 'Model Architecture', 'Multimodal Models', 'Pretraining Methods', 'Prompting', 'Reinforcement Learning', 'Training Techniques', 'Transformer']
---
The automatic reading of text45;intensive images represents a significant advancement toward achieving Artificial General Intelligence (AGI). In this paper we present KOSMOS45;2.5 a multimodal literate model for machine reading of text45;intensive images. Pre45;trained on a large45;scale corpus of text45;intensive images KOSMOS45;2.5 excels in two distinct yet complementary transcription tasks (1) generating spatially45;aware text blocks where each block of text is assigned spatial coordinates within the image and (2) producing structured text output that captures both style and structure in markdown format. This unified multimodal literate capability is achieved through a shared decoder45;only autoregressive Transformer architecture and task45;specific prompts. Building on this foundation we fine45;tune KOSMOS45;2.5 for document understanding tasks resulting in a document understanding generalist named KOSMOS45;2.545;CHAT. Additionally a large corpus of 357.4 million document pages spanning diverse domains was curated for pre45;training. We evaluate KOSMOS45;2.5 on two newly proposed benchmarks OCREval and MarkdownEval for document45;level text recognition and image45;to45;markdown generation demonstrating impressive literate capabilities comparable to GPT45;4o. KOSMOS45;2.545;CHAT achieves performance comparable to other state45;of45;the45;art generalists that are five times larger (1.3B vs. 7B) across nine text45;rich visual question answering benchmarks. Models and code have been available at url123;https://aka.ms/kosmos25&#125;.

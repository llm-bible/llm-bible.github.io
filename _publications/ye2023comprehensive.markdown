---
layout: publication
title: A Comprehensive Capability Analysis Of GPT45;3 And GPT45;3.5 Series Models
authors: Junjie Ye, Xuanting Chen, Nuo Xu, Can Zu, Zekai Shao, Shichun Liu, Yuhan Cui, Zeyang Zhou, Chao Gong, Yang Shen, Jie Zhou, Siming Chen, Tao Gui, Qi Zhang, Xuanjing Huang
conference: "Arxiv"
year: 2023
bibkey: ye2023comprehensive
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/http://arxiv.org/abs/2303.10420v2"}
tags: ['Applications', 'Attention Mechanism', 'GPT', 'Model Architecture', 'Reinforcement Learning', 'Security', 'Training Techniques']
---
GPT series models such as GPT45;3 CodeX InstructGPT ChatGPT and so on have gained considerable attention due to their exceptional natural language processing capabilities. However despite the abundance of research on the difference in capabilities between GPT series models and fine45;tuned models there has been limited attention given to the evolution of GPT series models capabilities over time. To conduct a comprehensive analysis of the capabilities of GPT series models we select six representative models comprising two GPT45;3 series models (i.e. davinci and text45;davinci45;001) and four GPT45;3.5 series models (i.e. code45;davinci45;002 text45;davinci45;002 text45;davinci45;003 and gpt45;3.545;turbo). We evaluate their performance on nine natural language understanding (NLU) tasks using 21 datasets. In particular we compare the performance and robustness of different models for each task under zero45;shot and few45;shot scenarios. Our extensive experiments reveal that the overall ability of GPT series models on NLU tasks does not increase gradually as the models evolve especially with the introduction of the RLHF training strategy. While this strategy enhances the models ability to generate human45;like responses it also compromises their ability to solve some tasks. Furthermore our findings indicate that there is still room for improvement in areas such as model robustness.

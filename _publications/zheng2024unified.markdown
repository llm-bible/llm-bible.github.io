---
layout: publication
title: 'Llamafactory: Unified Efficient Fine-tuning Of 100+ Language Models'
authors: Yaowei Zheng et al.
conference: Arxiv
year: 2024
citations: 72
bibkey: zheng2024unified
additional_links:
- name: Paper
  url: https://arxiv.org/abs/2403.13372
- name: Code
  url: https://github.com/hiyouga/LLaMA-Factory
tags:
- Tools
- Language Modeling
- Efficiency and Optimization
- Fine-Tuning
---
Efficient fine-tuning is vital for adapting large language models (LLMs) to
downstream tasks. However, it requires non-trivial efforts to implement these
methods on different models. We present LlamaFactory, a unified framework that
integrates a suite of cutting-edge efficient training methods. It provides a
solution for flexibly customizing the fine-tuning of 100+ LLMs without the need
for coding through the built-in web UI LlamaBoard. We empirically validate the
efficiency and effectiveness of our framework on language modeling and text
generation tasks. It has been released at
https://github.com/hiyouga/LLaMA-Factory and received over 25,000 stars and
3,000 forks.
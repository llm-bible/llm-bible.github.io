---
layout: publication
title: Knowledge45;grounded Response Generation With Deep Attentional Latent45;variable Model
authors: Ye Hao-tong, Lo Kai-ling, Su Shang-yu, Chen Yun-nung
conference: "Arxiv"
year: 2019
bibkey: ye2019knowledge
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/1903.09813"}
tags: ['Applications', 'Attention Mechanism', 'Model Architecture', 'Reinforcement Learning', 'Transformer']
---
End45;to45;end dialogue generation has achieved promising results without using handcrafted features and attributes specific for each task and corpus. However one of the fatal drawbacks in such approaches is that they are unable to generate informative utterances so it limits their usage from some real45;world conversational applications. This paper attempts at generating diverse and informative responses with a variational generation model which contains a joint attention mechanism conditioning on the information from both dialogue contexts and extra knowledge.

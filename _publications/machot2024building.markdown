---
layout: publication
title: 'Building Trustworthy AI: Transparent AI Systems Via Large Language Models, Ontologies, And Logical Reasoning (transpnet)'
authors: Fadi Al Machot, Martin Thomas Horsch, Habib Ullah
conference: "Arxiv"
year: 2024
bibkey: machot2024building
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2411.08469'}
tags: ['RAG', 'Applications', 'Tools', 'Reinforcement Learning', 'Ethics and Bias', 'Interpretability', 'Responsible AI']
---
Growing concerns over the lack of transparency in AI, particularly in
high-stakes fields like healthcare and finance, drive the need for explainable
and trustworthy systems. While Large Language Models (LLMs) perform
exceptionally well in generating accurate outputs, their "black box" nature
poses significant challenges to transparency and trust. To address this, the
paper proposes the TranspNet pipeline, which integrates symbolic AI with LLMs.
By leveraging domain expert knowledge, retrieval-augmented generation (RAG),
and formal reasoning frameworks like Answer Set Programming (ASP), TranspNet
enhances LLM outputs with structured reasoning and verification.This approach
strives to help AI systems deliver results that are as accurate, explainable,
and trustworthy as possible, aligning with regulatory expectations for
transparency and accountability. TranspNet provides a solution for developing
AI systems that are reliable and interpretable, making it suitable for
real-world applications where trust is critical.

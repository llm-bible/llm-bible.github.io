---
layout: publication
title: Ive got the Answer! Interpretation of LLMs Hidden States in Question Answering
authors: Goloviznina Valeriya, Kotelnikov Evgeny
conference: "Arxiv"
year: 2024
bibkey: goloviznina2024ive
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.02060"}
tags: ['ARXIV', 'Applications', 'Interpretability', 'Interpretability And Interpretability', 'LLM', 'Quantization', 'Reinforcement Learning', 'Tools']
---
Interpretability and explainability of AI are becoming increasingly important in light of the rapid development of large language models (LLMs). This paper investigates the interpretation of LLMs in the context of the knowledge-based question answering. The main hypothesis of the study is that correct and incorrect model behavior can be distinguished at the level of hidden states. The quantized models LLaMA-2-7B-Chat Mistral-7B Vicuna-7B and the MuSeRC question-answering dataset are used to test this hypothesis. The results of the analysis support the proposed hypothesis. We also identify the layers which have a negative effect on the models behavior. As a prospect of practical application of the hypothesis we propose to train such weak layers additionally in order to improve the quality of the task solution.

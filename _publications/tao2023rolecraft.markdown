---
layout: publication
title: 'Rolecraft-glm: Advancing Personalized Role-playing In Large Language Models'
authors: Tao Meiling, Liang Xuechen, Shi Tianyu, Yu Lei, Xie Yiting
conference: "Arxiv"
year: 2023
bibkey: tao2023rolecraft
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.09432"}
tags: ['Language Modeling', 'Tools']
---
This study presents RoleCraft-GLM, an innovative framework aimed at enhancing
personalized role-playing with Large Language Models (LLMs). RoleCraft-GLM
addresses the key issue of lacking personalized interactions in conversational
AI, and offers a solution with detailed and emotionally nuanced character
portrayals. We contribute a unique conversational dataset that shifts from
conventional celebrity-centric characters to diverse, non-celebrity personas,
thus enhancing the realism and complexity of language modeling interactions.
Additionally, our approach includes meticulous character development, ensuring
dialogues are both realistic and emotionally resonant. The effectiveness of
RoleCraft-GLM is validated through various case studies, highlighting its
versatility and skill in different scenarios. Our framework excels in
generating dialogues that accurately reflect characters' personality traits and
emotions, thereby boosting user engagement. In conclusion, RoleCraft-GLM marks
a significant leap in personalized AI interactions, and paves the way for more
authentic and immersive AI-assisted role-playing experiences by enabling more
nuanced and emotionally rich dialogues

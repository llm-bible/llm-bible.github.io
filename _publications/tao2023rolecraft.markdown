---
layout: publication
title: Rolecraft45;glm Advancing Personalized Role45;playing In Large Language Models
authors: Tao Meiling, Liang Xuechen, Shi Tianyu, Yu Lei, Xie Yiting
conference: "Arxiv"
year: 2023
bibkey: tao2023rolecraft
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.09432"}
tags: ['Language Modeling', 'Pretraining Methods', 'Tools']
---
This study presents RoleCraft45;GLM an innovative framework aimed at enhancing personalized role45;playing with Large Language Models (LLMs). RoleCraft45;GLM addresses the key issue of lacking personalized interactions in conversational AI and offers a solution with detailed and emotionally nuanced character portrayals. We contribute a unique conversational dataset that shifts from conventional celebrity45;centric characters to diverse non45;celebrity personas thus enhancing the realism and complexity of language modeling interactions. Additionally our approach includes meticulous character development ensuring dialogues are both realistic and emotionally resonant. The effectiveness of RoleCraft45;GLM is validated through various case studies highlighting its versatility and skill in different scenarios. Our framework excels in generating dialogues that accurately reflect characters personality traits and emotions thereby boosting user engagement. In conclusion RoleCraft45;GLM marks a significant leap in personalized AI interactions and paves the way for more authentic and immersive AI45;assisted role45;playing experiences by enabling more nuanced and emotionally rich dialogues

---
layout: publication
title: Modulating Language Model Experiences Through Frictions
authors: Collins Katherine M., Chen Valerie, Sucholutsky Ilia, Kirk Hannah Rose, Sadek Malak, Sargeant Holli, Talwalkar Ameet, Weller Adrian, Bhatt Umang
conference: "Arxiv"
year: 2024
bibkey: collins2024modulating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.12804"}
tags: ['Applications', 'Reinforcement Learning']
---
Language models are transforming the ways that their users engage with the world. Despite impressive capabilities over45;consumption of language model outputs risks propagating unchecked errors in the short45;term and damaging human capabilities for critical thinking in the long45;term particularly in knowledge45;based tasks. How can we develop scaffolding around language models to curate more appropriate use We propose selective frictions for language model experiences inspired by behavioral science interventions to dampen misuse. Frictions involve small modifications to a users experience e.g. the addition of a button impeding model access and reminding a user of their expertise relative to the model. Through a user study with real humans we observe shifts in user behavior from the imposition of a friction over LLMs in the context of a multi45;topic question45;answering task as a representative task that people may use LLMs for e.g. in education and information retrieval. We find that frictions modulate over45;reliance by driving down users click rates while minimally affecting accuracy for those topics. Yet frictions may have unintended effects. We find marked differences in users click behaviors even on topics where frictions were not provisioned. Our contributions motivate further study of human45;AI behavioral interaction to inform more effective and appropriate LLM use.

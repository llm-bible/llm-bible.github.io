---
layout: publication
title: 'Capturing Bias Diversity In Llms'
authors: Purva Prasad Gosavi, Vaishnavi Murlidhar Kulkarni, Alan F. Smeaton
conference: "Arxiv"
year: 2024
bibkey: gosavi2024capturing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2410.12839"}
tags: ['Tools', 'GPT', 'Ethics and Bias', 'Model Architecture', 'Merging']
---
This paper presents research on enhancements to Large Language Models (LLMs)
through the addition of diversity in its generated outputs. Our study
introduces a configuration of multiple LLMs which demonstrates the diversities
capable with a single LLM. By developing multiple customised instances of a GPT
model, each reflecting biases in specific demographic characteristics including
gender, age, and race, we propose, develop and evaluate a framework for a more
nuanced and representative AI dialogue which we call BiasGPT. The customised
GPT models will ultimately collaborate, merging their diverse perspectives on a
topic into an integrated response that captures a broad spectrum of human
experiences and viewpoints. In this paper, through experiments, we demonstrate
the capabilities of a GPT model to embed different biases which, when combined,
can open the possibilities of more inclusive AI technologies.

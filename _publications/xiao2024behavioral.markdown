---
layout: publication
title: 'Behavioral Bias Of Vision-language Models: A Behavioral Finance View'
authors: Yuhang Xiao, Yudi Lin, Ming-chang Chiu
conference: "Arxiv"
year: 2024
bibkey: xiao2024behavioral
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2409.15256"}
  - {name: "Code", url: "https://github.com/mydcxiao/vlm_behavioral_fin"}
tags: ['Multimodal Models', 'Model Architecture', 'Tools', 'GPT', 'Ethics and Bias', 'Has Code', 'Applications']
---
Large Vision-Language Models (LVLMs) evolve rapidly as Large Language Models
(LLMs) was equipped with vision modules to create more human-like models.
However, we should carefully evaluate their applications in different domains,
as they may possess undesired biases. Our work studies the potential behavioral
biases of LVLMs from a behavioral finance perspective, an interdisciplinary
subject that jointly considers finance and psychology. We propose an end-to-end
framework, from data collection to new evaluation metrics, to assess LVLMs'
reasoning capabilities and the dynamic behaviors manifested in two established
human financial behavioral biases: recency bias and authority bias. Our
evaluations find that recent open-source LVLMs such as LLaVA-NeXT,
MobileVLM-V2, Mini-Gemini, MiniCPM-Llama3-V 2.5 and Phi-3-vision-128k suffer
significantly from these two biases, while the proprietary model GPT-4o is
negligibly impacted. Our observations highlight directions in which open-source
models can improve. The code is available at
https://github.com/mydcxiao/vlm_behavioral_fin.

---
layout: publication
title: 'Reflections From The 2024 Large Language Model (LLM) Hackathon For Applications In Materials Science And Chemistry'
authors: Yoel Mark Zimmermann, Adib Mark Bazgir, Zartashia Mark Afzal, Fariha Mark Agbere, Qianxiang Mark Ai, Nawaf Mark Alampara, Alexander Mark Al-feghali, Mehrad Mark Ansari, Dmytro Mark Antypov, Amro Mark Aswad, Jiaru Mark Bai, Viktoriia Mark Baibakova, Devi Dutta Mark Biswajeet, Erik Mark Bitzek, Joshua D. Mark Bocarsly, Anna Mark Borisova, Andres M Mark Bran, L. Catherine Mark Brinson, Marcel Moran Mark Calderon, Alessandro Mark Canalicchio, Victor Mark Chen, Yuan Mark Chiang, Defne Mark Circi, Benjamin Mark Charmes, Vikrant Mark Chaudhary, Zizhang Mark Chen, Min-hsueh Mark Chiu, Judith Mark Clymo, Kedar Mark Dabhadkar, Nathan Mark Daelman, Archit Mark Datar, Wibe A. Mark De Jong, Matthew L. Mark Evans, Maryam Ghazizade Mark Fard, Giuseppe Mark Fisicaro, Abhijeet Sadashiv Mark Gangan, Janine Mark George, Jose D. Cojal Mark Gonzalez, Michael Mark Götte, Ankur K. Mark Gupta, Hassan Mark Harb, Pengyu Mark Hong, Abdelrahman Mark Ibrahim, Ahmed Mark Ilyas, Alishba Mark Imran, Kevin Mark Ishimwe, Ramsey Mark Issa, Kevin Maik Mark Jablonka, Colin Mark Jones, Tyler R. Mark Josephson, Greg Mark Juhasz, Sarthak Mark Kapoor, Rongda Mark Kang, Ghazal Mark Khalighinejad, Sartaaj Mark Khan, Sascha Mark Klawohn, Suneel Mark Kuman, Alvin Noe Mark Ladines, Sarom Mark Leang, Magdalena Mark Lederbauer, Mark Sheng-lun, Liao, Hao Liu, Xuefeng Liu, Stanley Lo, Sandeep Madireddy, Piyush Ranjan Maharana, Shagun Maheshwari, Soroush Mahjoubi, José A. Márquez, Rob Mills, Trupti Mohanty, Bernadette Mohr, Seyed Mohamad Moosavi, Alexander Moßhammer, Amirhossein D. Naghdi, Aakash Naik, Oleksandr Narykov, Hampus Näsström, Xuan Vu Nguyen, Xinyi Ni, Dana O'connor, Teslim Olayiwola, Federico Ottomano, Aleyna Beste Ozhan, Sebastian Pagel, Chiku Parida, Jaehee Park, Vraj Patel, Elena Patyukova, Martin Hoffmann Petersen, Luis Pinto, José M. Pizarro, Dieter Plessers, Tapashree Pradhan, Utkarsh Pratiush, Charishma Puli, Andrew Qin, Mahyar Rajabi, Francesco Ricci, Elliot Risch, Martiño Ríos-garcía, Aritra Roy, Tehseen Rug, Hasan M Sayeed, Markus Scheidgen, Mara Schilling-wilhelmi, Marcel Schloz, Fabian Schöppach, Julia Schumann, Philippe Schwaller, Marcus Schwarting, Samiha Sharlin, Kevin Shen, Jiale Shi, Pradip Si, Jennifer D'souza, Taylor Sparks, Suraj Sudhakar, Leopold Talirz, Dandan Tang, Olga Taran, Carla Terboven, Mark Tropin, Anastasiia Tsymbal, Katharina Ueltzen, Pablo Andres Unzueta, Archit Vasan, Tirtha Vinchurkar, Trung Vo, Gabriel Vogel, Christoph Völker, Jan Weinreich, Faradawn Yang, Mohd Zaki, Chi Zhang, Sylvester Zhang, Weijie Zhang, Ruijie Zhu, Shang Zhu, Jan Janssen, Calvin Li, Ian Foster, Ben Blaiszik
conference: "Arxiv"
year: 2024
bibkey: zimmermann2024reflections
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2411.15221"}
tags: ['Tools', 'Applications', 'Reinforcement Learning']
---
Here, we present the outcomes from the second Large Language Model (LLM)
Hackathon for Applications in Materials Science and Chemistry, which engaged
participants across global hybrid locations, resulting in 34 team submissions.
The submissions spanned seven key application areas and demonstrated the
diverse utility of LLMs for applications in (1) molecular and material property
prediction; (2) molecular and material design; (3) automation and novel
interfaces; (4) scientific communication and education; (5) research data
management and automation; (6) hypothesis generation and evaluation; and (7)
knowledge extraction and reasoning from scientific literature. Each team
submission is presented in a summary table with links to the code and as brief
papers in the appendix. Beyond team results, we discuss the hackathon event and
its hybrid format, which included physical hubs in Toronto, Montreal, San
Francisco, Berlin, Lausanne, and Tokyo, alongside a global online hub to enable
local and virtual collaboration. Overall, the event highlighted significant
improvements in LLM capabilities since the previous year's hackathon,
suggesting continued expansion of LLMs for applications in materials science
and chemistry research. These outcomes demonstrate the dual utility of LLMs as
both multipurpose models for diverse machine learning tasks and platforms for
rapid prototyping custom applications in scientific research.

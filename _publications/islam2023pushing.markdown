---
layout: publication
title: Pushing Boundaries Exploring Zero Shot Object Classification With Large Multimodal Models
authors: Islam Ashhadul, Biswas Md. Rafiul, Zaghouani Wajdi, Belhaouari Samir Brahim, Shah Zubair
conference: "https://fllm-conference.org/"
year: 2023
bibkey: islam2023pushing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.00127"}
tags: ['Applications', 'Fine Tuning', 'Multimodal Models', 'Pretraining Methods', 'Prompting', 'Reinforcement Learning', 'Training Techniques']
---
The synergy of language and vision models has given rise to Large Language and Vision Assistant models (LLVAs) designed to engage users in rich conversational experiences intertwined with image-based queries. These comprehensive multimodal models seamlessly integrate vision encoders with Large Language Models (LLMs) expanding their applications in general-purpose language and visual comprehension. The advent of Large Multimodal Models (LMMs) heralds a new era in Artificial Intelligence (AI) assistance extending the horizons of AI utilization. This paper takes a unique perspective on LMMs exploring their efficacy in performing image classification tasks using tailored prompts designed for specific datasets. We also investigate the LLVAs zero-shot learning capabilities. Our study includes a benchmarking analysis across four diverse datasets MNIST Cats Vs. Dogs Hymnoptera (Ants Vs. Bees) and an unconventional dataset comprising Pox Vs. Non-Pox skin images. The results of our experiments demonstrate the models remarkable performance achieving classification accuracies of 8537; 10037; 7737; and 7937; for the respective datasets without any fine-tuning. To bolster our analysis we assess the models performance post fine-tuning for specific tasks. In one instance fine-tuning is conducted over a dataset comprising images of faces of children with and without autism. Prior to fine-tuning the model demonstrated a test accuracy of 5537; which significantly improved to 8337; post fine-tuning. These results coupled with our prior findings underscore the transformative potential of LLVAs and their versatile applications in real-world scenarios.

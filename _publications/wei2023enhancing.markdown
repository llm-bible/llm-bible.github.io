---
layout: publication
title: 'Enhancing Human-like Multi-modal Reasoning: A New Challenging Dataset And Comprehensive Framework'
authors: Jingxuan Wei, Cheng Tan, Zhangyang Gao, Linzhuang Sun, Siyuan Li, Bihui Yu, Ruifeng Guo, Stan Z. Li
conference: "Arxiv"
year: 2023
bibkey: wei2023enhancing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2307.12626"}
  - {name: "Code", url: "https://github.com/weijingxuan/COCO-MMR}{https://github.com/weijingxuan/COCO-MMR"}
tags: ['Tools', 'Interpretability and Explainability', 'Model Architecture', 'Attention Mechanism', 'Has Code', 'Pretraining Methods', 'Multimodal Models']
---
Multimodal reasoning is a critical component in the pursuit of artificial
intelligence systems that exhibit human-like intelligence, especially when
tackling complex tasks. While the chain-of-thought (CoT) technique has gained
considerable attention, the existing ScienceQA dataset, which focuses on
multimodal scientific questions and explanations from elementary and high
school textbooks, lacks a comprehensive evaluation of diverse approaches. To
address this gap, we present COCO Multi-Modal Reasoning(COCO-MMR) dataset, a
novel dataset that encompasses an extensive collection of open-ended questions,
rationales, and answers derived from the large object dataset COCO. Unlike
previous datasets that rely on multiple-choice questions, our dataset pioneers
the use of open-ended questions in the context of multimodal CoT, introducing a
more challenging problem that effectively assesses the reasoning capability of
CoT models. Through comprehensive evaluations and detailed analyses, we provide
valuable insights and propose innovative techniques, including multi-hop
cross-modal attention and sentence-level contrastive learning, to enhance the
image and text encoders. Extensive experiments demonstrate the efficacy of the
proposed dataset and techniques, offering novel perspectives for advancing
multimodal reasoning. The data and code are available at
\href\{https://github.com/weijingxuan/COCO-MMR\}\{https://github.com/weijingxuan/COCO-MMR\}.

---
layout: publication
title: Zero-shot Adaptive Transfer For Conversational Language Understanding
authors: Sungjin Lee, Rahul Jha
conference: Arxiv
year: 2018
citations: 17
bibkey: lee2018zero
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1808.10059'}]
tags: [Fine-Tuning, Agentic]
---
Conversational agents such as Alexa and Google Assistant constantly need to
increase their language understanding capabilities by adding new domains. A
massive amount of labeled data is required for training each new domain. While
domain adaptation approaches alleviate the annotation cost, prior approaches
suffer from increased training time and suboptimal concept alignments. To
tackle this, we introduce a novel Zero-Shot Adaptive Transfer method for slot
tagging that utilizes the slot description for transferring reusable concepts
across domains, and enjoys efficient training without any explicit concept
alignments. Extensive experimentation over a dataset of 10 domains relevant to
our commercial personal digital assistant shows that our model outperforms
previous state-of-the-art systems by a large margin, and achieves an even
higher improvement in the low data regime.
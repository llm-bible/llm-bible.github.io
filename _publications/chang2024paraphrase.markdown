---
layout: publication
title: 'Paraphrase-aligned Machine Translation'
authors: Ke-ching Chang, Chung-chi Chen, An-zi Yen
conference: "Arxiv"
year: 2024
bibkey: chang2024paraphrase
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2412.05916"}
tags: ['Applications']
---
Large Language Models (LLMs) have demonstrated significant capabilities in
machine translation. However, their translation quality is sometimes
questioned, as the generated outputs may deviate from expressions typically
used by native speakers. These deviations often arise from differences in
sentence structure between language systems. To address this issue, we propose
ParaAlign Translator, a method that fine-tunes LLMs to paraphrase sentences,
aligning their structures with those of the target language systems. This
approach improves the performance of subsequent translations. Experimental
results demonstrate that the proposed method enhances the LLaMA-3-8B model's
performance in both resource-rich and low-resource scenarios and achieves
parity with or surpassing the much larger LLaMA-3-70B model.

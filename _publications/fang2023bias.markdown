---
layout: publication
title: 'Bias Of Ai-generated Content: An Examination Of News Produced By Large Language Models'
authors: Xiao Fang, Shangkun Che, Minjia Mao, Hongzhe Zhang, Ming Zhao, Xiaohang Zhao
conference: "Arxiv"
year: 2023
bibkey: fang2023bias
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.09825"}
tags: ['Prompting', 'Ethics and Bias', 'Model Architecture', 'GPT']
---
Large language models (LLMs) have the potential to transform our lives and
work through the content they generate, known as AI-Generated Content (AIGC).
To harness this transformation, we need to understand the limitations of LLMs.
Here, we investigate the bias of AIGC produced by seven representative LLMs,
including ChatGPT and LLaMA. We collect news articles from The New York Times
and Reuters, both known for their dedication to provide unbiased news. We then
apply each examined LLM to generate news content with headlines of these news
articles as prompts, and evaluate the gender and racial biases of the AIGC
produced by the LLM by comparing the AIGC and the original news articles. We
further analyze the gender bias of each LLM under biased prompts by adding
gender-biased messages to prompts constructed from these news headlines. Our
study reveals that the AIGC produced by each examined LLM demonstrates
substantial gender and racial biases. Moreover, the AIGC generated by each LLM
exhibits notable discrimination against females and individuals of the Black
race. Among the LLMs, the AIGC generated by ChatGPT demonstrates the lowest
level of bias, and ChatGPT is the sole model capable of declining content
generation when provided with biased prompts.

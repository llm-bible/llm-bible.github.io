---
layout: publication
title: TAPE Assessing Few45;shot Russian Language Understanding
authors: Taktasheva Ekaterina, Shavrina Tatiana, Fenogenova Alena, Shevelev Denis, Katricheva Nadezhda, Tikhonova Maria, Akhmetgareeva Albina, Zinkevich Oleg, Bashmakova Anastasiia, Iordanskaia Svetlana, Spiridonova Alena, Kurenshchikova Valentina, Artemova Ekaterina, Mikhailov Vladislav
conference: "Arxiv"
year: 2022
bibkey: taktasheva2022assessing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2210.12813"}
tags: ['GPT', 'Pretraining Methods', 'Security']
---
Recent advances in zero45;shot and few45;shot learning have shown promise for a scope of research and practical purposes. However this fast45;growing area lacks standardized evaluation suites for non45;English languages hindering progress outside the Anglo45;centric paradigm. To address this line of research we propose TAPE (Text Attack and Perturbation Evaluation) a novel benchmark that includes six more complex NLU tasks for Russian covering multi45;hop reasoning ethical concepts logic and commonsense knowledge. The TAPEs design focuses on systematic zero45;shot and few45;shot NLU evaluation (i) linguistic45;oriented adversarial attacks and perturbations for analyzing robustness and (ii) subpopulations for nuanced interpretation. The detailed analysis of testing the autoregressive baselines indicates that simple spelling45;based perturbations affect the performance the most while paraphrasing the input has a more negligible effect. At the same time the results demonstrate a significant gap between the neural and human baselines for most tasks. We publicly release TAPE (tape45;benchmark.com) to foster research on robust LMs that can generalize to new tasks when little to no supervision is available.

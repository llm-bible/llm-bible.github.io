---
layout: publication
title: TAPE\: Assessing Few-shot Russian Language Understanding
authors: Taktasheva Ekaterina, Shavrina Tatiana, Fenogenova Alena, Shevelev Denis, Katricheva Nadezhda, Tikhonova Maria, Akhmetgareeva Albina, Zinkevich Oleg, Bashmakova Anastasiia, Iordanskaia Svetlana, Spiridonova Alena, Kurenshchikova Valentina, Artemova Ekaterina, Mikhailov Vladislav
conference: "Arxiv"
year: 2022
bibkey: taktasheva2022assessing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2210.12813"}
tags: ['Few Shot', 'GPT', 'Pretraining Methods', 'Security']
---
Recent advances in zero-shot and few-shot learning have shown promise for a scope of research and practical purposes. However this fast-growing area lacks standardized evaluation suites for non-English languages hindering progress outside the Anglo-centric paradigm. To address this line of research we propose TAPE (Text Attack and Perturbation Evaluation) a novel benchmark that includes six more complex NLU tasks for Russian covering multi-hop reasoning ethical concepts logic and commonsense knowledge. The TAPEs design focuses on systematic zero-shot and few-shot NLU evaluation (i) linguistic-oriented adversarial attacks and perturbations for analyzing robustness and (ii) subpopulations for nuanced interpretation. The detailed analysis of testing the autoregressive baselines indicates that simple spelling-based perturbations affect the performance the most while paraphrasing the input has a more negligible effect. At the same time the results demonstrate a significant gap between the neural and human baselines for most tasks. We publicly release TAPE (tape-benchmark.com) to foster research on robust LMs that can generalize to new tasks when little to no supervision is available.

---
layout: publication
title: G45;eval NLG Evaluation Using GPT45;4 With Better Human Alignment
authors: Liu Yang, Iter Dan, Xu Yichong, Wang Shuohang, Xu Ruochen, Zhu Chenguang
conference: "Arxiv"
year: 2023
bibkey: liu2023g
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2303.16634"}
  - {name: "Code", url: "https://github.com/nlpyang/geval"}
tags: ['Applications', 'Ethics And Bias', 'GPT', 'Has Code', 'Model Architecture', 'Tools']
---
The quality of texts generated by natural language generation (NLG) systems is hard to measure automatically. Conventional reference45;based metrics such as BLEU and ROUGE have been shown to have relatively low correlation with human judgments especially for tasks that require creativity and diversity. Recent studies suggest using large language models (LLMs) as reference45;free metrics for NLG evaluation which have the benefit of being applicable to new tasks that lack human references. However these LLM45;based evaluators still have lower human correspondence than medium45;size neural evaluators. In this work we present G45;Eval a framework of using large language models with chain45;of45;thoughts (CoT) and a form45;filling paradigm to assess the quality of NLG outputs. We experiment with two generation tasks text summarization and dialogue generation. We show that G45;Eval with GPT45;4 as the backbone model achieves a Spearman correlation of 0.514 with human on summarization task outperforming all previous methods by a large margin. We also propose preliminary analysis on the behavior of LLM45;based evaluators and highlight the potential issue of LLM45;based evaluators having a bias towards the LLM45;generated texts. The code is at https://github.com/nlpyang/geval

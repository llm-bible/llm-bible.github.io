---
layout: publication
title: 'AI Will Always Love You: Studying Implicit Biases In Romantic AI Companions'
authors: Clare Grogan, Jackie Kay, María Pérez-ortiz
conference: "Arxiv"
year: 2025
bibkey: grogan2025ai
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2502.20231'}
tags: ['Ethics and Bias']
---
While existing studies have recognised explicit biases in generative models,
including occupational gender biases, the nuances of gender stereotypes and
expectations of relationships between users and AI companions remain
underexplored. In the meantime, AI companions have become increasingly popular
as friends or gendered romantic partners to their users. This study bridges the
gap by devising three experiments tailored for romantic, gender-assigned AI
companions and their users, effectively evaluating implicit biases across
various-sized LLMs. Each experiment looks at a different dimension: implicit
associations, emotion responses, and sycophancy. This study aims to measure and
compare biases manifested in different companion systems by quantitatively
analysing persona-assigned model responses to a baseline through newly devised
metrics. The results are noteworthy: they show that assigning gendered,
relationship personas to Large Language Models significantly alters the
responses of these models, and in certain situations in a biased, stereotypical
way.

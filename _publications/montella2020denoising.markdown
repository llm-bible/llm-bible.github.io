---
layout: publication
title: 'Denoising Pre-training And Data Augmentation Strategies For Enhanced RDF Verbalization With Transformers'
authors: Sebastien Montella, Betty Fabre, Tanguy Urvoy, Johannes Heinecke, Lina Rojas-barahona
conference: "Arxiv"
year: 2020
bibkey: montella2020denoising
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2012.00571"}
tags: ['Training Techniques', 'Model Architecture', 'RAG', 'Pretraining Methods', 'Transformer', 'Pre-Training']
---
The task of verbalization of RDF triples has known a growth in popularity due
to the rising ubiquity of Knowledge Bases (KBs). The formalism of RDF triples
is a simple and efficient way to store facts at a large scale. However, its
abstract representation makes it difficult for humans to interpret. For this
purpose, the WebNLG challenge aims at promoting automated RDF-to-text
generation. We propose to leverage pre-trainings from augmented data with the
Transformer model using a data augmentation strategy. Our experiment results
show a minimum relative increases of 3.73%, 126.05% and 88.16% in BLEU score
for seen categories, unseen entities and unseen categories respectively over
the standard training.

---
layout: publication
title: Battle Of The Large Language Models Dolly Vs Llama Vs Vicuna Vs Guanaco Vs Bard Vs Chatgpt 45;45; A Text45;to45;sql Parsing Comparison
authors: Sun Shuo, Zhang Yuchen, Yan Jiahuan, Gao Yuze, Ong Donovan, Chen Bin, Su Jian
conference: "Arxiv"
year: 2023
bibkey: sun2023battle
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.10190"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Prompting']
---
The success of ChatGPT has ignited an AI race with researchers striving to develop new large language models (LLMs) that can match or surpass the language understanding and generation abilities of commercial ones. In recent times a number of models have emerged claiming performance near that of GPT45;3.5 or GPT45;4 through various instruction45;tuning methods. As practitioners of Text45;to45;SQL parsing we are grateful for their valuable contributions to open45;source research. However it is important to approach these claims with a sense of scrutiny and ascertain the actual effectiveness of these models. Therefore we pit six popular large language models against each other systematically evaluating their Text45;to45;SQL parsing capability on nine benchmark datasets with five different prompting strategies covering both zero45;shot and few45;shot scenarios. Regrettably the open45;sourced models fell significantly short of the performance achieved by closed45;source models like GPT45;3.5 highlighting the need for further work to bridge the performance gap between these models.

---
layout: publication
title: The Benefits Of A Concise Chain Of Thought On Problem45;solving In Large Language Models
authors: Renze Matthew, Guven Erhan
conference: "Arxiv"
year: 2024
bibkey: renze2024benefits
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.05618"}
tags: ['GPT', 'Model Architecture', 'Pretraining Methods', 'Prompting', 'RAG']
---
In this paper we introduce Concise Chain45;of45;Thought (CCoT) prompting. We compared standard CoT and CCoT prompts to see how conciseness impacts response length and correct45;answer accuracy. We evaluated this using GPT45;3.5 and GPT45;4 with a multiple45;choice question45;and45;answer (MCQA) benchmark. CCoT reduced average response length by 48.7037; for both GPT45;3.5 and GPT45;4 while having a negligible impact on problem45;solving performance. However on math problems GPT45;3.5 with CCoT incurs a performance penalty of 27.6937;. Overall CCoT leads to an average per45;token cost reduction of 22.6737;.

---
layout: publication
title: Creating Large Language Model Resistant Exams Guidelines and Strategies
authors: Larsen Simon Kaare
conference: "Arxiv"
year: 2023
bibkey: larsen2023creating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2304.12203"}
tags: ['GPT', 'Model Architecture', 'Pretraining Methods', 'Prompting', 'Reinforcement Learning', 'Tools']
---
The proliferation of Large Language Models (LLMs) such as ChatGPT has raised concerns about their potential impact on academic integrity prompting the need for LLM-resistant exam designs. This article investigates the performance of LLMs on exams and their implications for assessment focusing on ChatGPTs abilities and limitations. We propose guidelines for creating LLM-resistant exams including content moderation deliberate inaccuracies real-world scenarios beyond the models knowledge base effective distractor options evaluating soft skills and incorporating non-textual information. The article also highlights the significance of adapting assessments to modern tools and promoting essential skills development in students. By adopting these strategies educators can maintain academic integrity while ensuring that assessments accurately reflect contemporary professional settings and address the challenges and opportunities posed by artificial intelligence in education.

---
layout: publication
title: 'Enhancing Answer Attribution For Faithful Text Generation With Large Language Models'
authors: Juraj Vladika, Luca MÃ¼lln, Florian Matthes
conference: "Arxiv"
year: 2024
bibkey: vladika2024enhancing
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2410.17112'}
tags: ['Reinforcement Learning', 'Language Modeling', 'Applications']
---
The increasing popularity of Large Language Models (LLMs) in recent years has
changed the way users interact with and pose questions to AI-based
conversational systems. An essential aspect for increasing the trustworthiness
of generated LLM answers is the ability to trace the individual claims from
responses back to relevant sources that support them, the process known as
answer attribution. While recent work has started exploring the task of answer
attribution in LLMs, some challenges still remain. In this work, we first
perform a case study analyzing the effectiveness of existing answer attribution
methods, with a focus on subtasks of answer segmentation and evidence
retrieval. Based on the observed shortcomings, we propose new methods for
producing more independent and contextualized claims for better retrieval and
attribution. The new methods are evaluated and shown to improve the performance
of answer attribution components. We end with a discussion and outline of
future directions for the task.

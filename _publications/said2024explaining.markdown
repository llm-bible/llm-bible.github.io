---
layout: publication
title: 'On Explaining Recommendations With Large Language Models: A Review'
authors: Alan Said
conference: "Arxiv"
year: 2024
bibkey: said2024explaining
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2411.19576"}
tags: ['GPT', 'Survey Paper', 'Ethics and Bias', 'Interpretability and Explainability', 'RAG', 'Model Architecture', 'Reinforcement Learning', 'Interpretability', 'RecSys']
---
The rise of Large Language Models (LLMs), such as LLaMA and ChatGPT, has
opened new opportunities for enhancing recommender systems through improved
explainability. This paper provides a systematic literature review focused on
leveraging LLMs to generate explanations for recommendations -- a critical
aspect for fostering transparency and user trust. We conducted a comprehensive
search within the ACM Guide to Computing Literature, covering publications from
the launch of ChatGPT (November 2022) to the present (November 2024). Our
search yielded 232 articles, but after applying inclusion criteria, only six
were identified as directly addressing the use of LLMs in explaining
recommendations. This scarcity highlights that, despite the rise of LLMs, their
application in explainable recommender systems is still in an early stage. We
analyze these select studies to understand current methodologies, identify
challenges, and suggest directions for future research. Our findings underscore
the potential of LLMs improving explanations of recommender systems and
encourage the development of more transparent and user-centric recommendation
explanation solutions.

---
layout: publication
title: Re45;reading Improves Reasoning In Large Language Models
authors: Xu Xiaohan, Tao Chongyang, Shen Tao, Xu Can, Xu Hongbo, Long Guodong, Lou Jian-guang
conference: "Arxiv"
year: 2023
bibkey: xu2023re
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.06275"}
  - {name: "Code", url: "https://github.com/Tebmer/Rereading&#45;LLM&#45;Reasoning/&#125;"}
tags: ['Attention Mechanism', 'GPT', 'Has Code', 'Model Architecture', 'Prompting', 'Reinforcement Learning', 'Transformer']
---
To enhance the reasoning capabilities of off45;the45;shelf Large Language Models (LLMs) we introduce a simple yet general and effective prompting method Re2 i.e. textbf123;Re125;45;textbf123;Re125;ading the question as input. Unlike most thought45;eliciting prompting methods such as Chain45;of45;Thought (CoT) which aim to elicit the reasoning process in the output Re2 shifts the focus to the input by processing questions twice thereby enhancing the understanding process. Consequently Re2 demonstrates strong generality and compatibility with most thought45;eliciting prompting methods including CoT. Crucially Re2 facilitates a bidirectional encoding in unidirectional decoder45;only LLMs because the first pass could provide global information for the second pass. We begin with a preliminary empirical study as the foundation of Re2 illustrating its potential to enable bidirectional attention mechanisms. We then evaluate Re2 on extensive reasoning benchmarks across 14 datasets spanning 112 experiments to validate its effectiveness and generality. Our findings indicate that with the exception of a few scenarios on vanilla ChatGPT Re2 consistently enhances the reasoning performance of LLMs through a simple re45;reading strategy. Further analyses reveal Re2s adaptability showing how it can be effectively integrated with different LLMs thought45;eliciting prompting and ensemble strategies. Our code is available at url123;https://github.com/Tebmer/Rereading&#45;LLM&#45;Reasoning/&#125;

---
layout: publication
title: Introspective Tips Large Language Model For In45;context Decision Making
authors: Chen Liting, Wang Lu, Dong Hang, Du Yali, Yan Jie, Yang Fangkai, Li Shuang, Zhao Pu, Qin Si, Rajmohan Saravan, Lin Qingwei, Zhang Dongmei
conference: "Arxiv"
year: 2023
bibkey: chen2023introspective
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2305.11598"}
tags: ['Agentic', 'Prompting', 'Reinforcement Learning', 'Tools']
---
The emergence of large language models (LLMs) has substantially influenced natural language processing demonstrating exceptional results across various tasks. In this study we employ Introspective Tips to facilitate LLMs in self45;optimizing their decision45;making. By introspectively examining trajectories LLM refines its policy by generating succinct and valuable tips. Our method enhances the agents performance in both few45;shot and zero45;shot learning situations by considering three essential scenarios learning from the agents past experiences integrating expert demonstrations and generalizing across diverse games. Importantly we accomplish these improvements without fine45;tuning the LLM parameters; rather we adjust the prompt to generalize insights from the three aforementioned situations. Our framework not only supports but also emphasizes the advantage of employing LLM in in45;contxt decision45;making. Experiments involving over 100 games in TextWorld illustrate the superior performance of our approach.

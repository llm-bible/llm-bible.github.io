---
layout: publication
title: 'Large Language Models Are Biased To Overestimate Profoundness'
authors: Eugenio Herrera-berg, Tomás Vergara Browne, Pablo León-villagrá, Marc-lluís Vives, Cristian Buc Calderon
conference: "https://aclanthology.org/2023.emnlp-main.599"
year: 2023
bibkey: herreraberg2023large
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.14422"}
tags: ['Agentic', 'Model Architecture', 'Few-Shot', 'Reinforcement Learning', 'GPT', 'Ethics and Bias', 'Prompting']
---
Recent advancements in natural language processing by large language models
(LLMs), such as GPT-4, have been suggested to approach Artificial General
Intelligence. And yet, it is still under dispute whether LLMs possess similar
reasoning abilities to humans. This study evaluates GPT-4 and various other
LLMs in judging the profoundness of mundane, motivational, and pseudo-profound
statements. We found a significant statement-to-statement correlation between
the LLMs and humans, irrespective of the type of statements and the prompting
technique used. However, LLMs systematically overestimate the profoundness of
nonsensical statements, with the exception of Tk-instruct, which uniquely
underestimates the profoundness of statements. Only few-shot learning prompts,
as opposed to chain-of-thought prompting, draw LLMs ratings closer to humans.
Furthermore, this work provides insights into the potential biases induced by
Reinforcement Learning from Human Feedback (RLHF), inducing an increase in the
bias to overestimate the profoundness of statements.

---
layout: publication
title: Large Language Models Are Biased To Overestimate Profoundness
authors: Herrera-berg Eugenio, Browne Tomás Vergara, León-villagrá Pablo, Vives Marc-lluís, Calderon Cristian Buc
conference: "https://aclanthology.org/"
year: 2023
bibkey: herreraberg2023large
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.14422"}
tags: ['Agentic', 'Ethics And Bias', 'GPT', 'Model Architecture', 'Prompting', 'Reinforcement Learning']
---
Recent advancements in natural language processing by large language models (LLMs) such as GPT45;4 have been suggested to approach Artificial General Intelligence. And yet it is still under dispute whether LLMs possess similar reasoning abilities to humans. This study evaluates GPT45;4 and various other LLMs in judging the profoundness of mundane motivational and pseudo45;profound statements. We found a significant statement45;to45;statement correlation between the LLMs and humans irrespective of the type of statements and the prompting technique used. However LLMs systematically overestimate the profoundness of nonsensical statements with the exception of Tk45;instruct which uniquely underestimates the profoundness of statements. Only few45;shot learning prompts as opposed to chain45;of45;thought prompting draw LLMs ratings closer to humans. Furthermore this work provides insights into the potential biases induced by Reinforcement Learning from Human Feedback (RLHF) inducing an increase in the bias to overestimate the profoundness of statements.

---
layout: publication
title: 'Evaluating Chatgpt-4 Vision On Brazil''s National Undergraduate Computer Science Exam'
authors: Nabor C. Mendonça
conference: "ACM Transactions on Computing Education June 2024"
year: 2024
bibkey: mendonça2024evaluating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.09671"}
  - {name: "Code", url: "https://github.com/nabormendonca/gpt-4v-enade-cs-2021"}
tags: ['GPT', 'Survey Paper', 'Ethics and Bias', 'RAG', 'Bias Mitigation', 'Model Architecture', 'Reinforcement Learning', 'Fairness', 'Attention Mechanism', 'Has Code', 'Multimodal Models']
---
The recent integration of visual capabilities into Large Language Models
(LLMs) has the potential to play a pivotal role in science and technology
education, where visual elements such as diagrams, charts, and tables are
commonly used to improve the learning experience. This study investigates the
performance of ChatGPT-4 Vision, OpenAI's most advanced visual model at the
time the study was conducted, on the Bachelor in Computer Science section of
Brazil's 2021 National Undergraduate Exam (ENADE). By presenting the model with
the exam's open and multiple-choice questions in their original image format
and allowing for reassessment in response to differing answer keys, we were
able to evaluate the model's reasoning and self-reflecting capabilities in a
large-scale academic assessment involving textual and visual content. ChatGPT-4
Vision significantly outperformed the average exam participant, positioning
itself within the top 10 best score percentile. While it excelled in questions
that incorporated visual elements, it also encountered challenges with question
interpretation, logical reasoning, and visual acuity. The involvement of an
independent expert panel to review cases of disagreement between the model and
the answer key revealed some poorly constructed questions containing vague or
ambiguous statements, calling attention to the critical need for improved
question design in future exams. Our findings suggest that while ChatGPT-4
Vision shows promise in multimodal academic evaluations, human oversight
remains crucial for verifying the model's accuracy and ensuring the fairness of
high-stakes educational exams. The paper's research materials are publicly
available at https://github.com/nabormendonca/gpt-4v-enade-cs-2021.

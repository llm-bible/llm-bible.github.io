---
layout: publication
title: 'From Conversation To Automation: Leveraging Llms For Problem-solving Therapy Analysis'
authors: Elham Aghakhani, Lu Wang, Karla T. Washington, George Demiris, Jina Huh-yoo, Rezvaneh Rezapour
conference: "Arxiv"
year: 2025
bibkey: aghakhani2025from
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2501.06101'}
tags: ['Transformer', 'RAG', 'Model Architecture', 'GPT', 'Tools', 'Reinforcement Learning', 'Pretraining Methods']
---
Problem-solving therapy (PST) is a structured psychological approach that
helps individuals manage stress and resolve personal issues by guiding them
through problem identification, solution brainstorming, decision-making, and
outcome evaluation. As mental health care increasingly adopts technologies like
chatbots and large language models (LLMs), it is important to thoroughly
understand how each session of PST is conducted before attempting to automate
it. We developed a comprehensive framework for PST annotation using established
PST Core Strategies and a set of novel Facilitative Strategies to analyze a
corpus of real-world therapy transcripts to determine which strategies are most
prevalent. Using various LLMs and transformer-based models, we found that
GPT-4o outperformed all models, achieving the highest accuracy (0.76) in
identifying all strategies. To gain deeper insights, we examined how strategies
are applied by analyzing Therapeutic Dynamics (autonomy, self-disclosure, and
metaphor), and linguistic patterns within our labeled data. Our research
highlights LLMs' potential to automate therapy dialogue analysis, offering a
scalable tool for mental health interventions. Our framework enhances PST by
improving accessibility, effectiveness, and personalized support for
therapists.

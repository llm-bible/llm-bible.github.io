---
layout: publication
title: 'Assessing Thai Dialect Performance In Llms With Automatic Benchmarks And Human Evaluation'
authors: Peerat Limkonchotiwat, Kanruethai Masuk, Surapon Nonesung, Chalermpun Mai-on, Sarana Nutanong, Wuttikorn Ponwitayarat, Potsawee Manakul
conference: "Arxiv"
year: 2025
bibkey: limkonchotiwat2025assessing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2504.05898"}
tags: ['Security', 'Model Architecture', 'Applications', 'GPT']
---
Large language models show promising results in various NLP tasks. Despite
these successes, the robustness and consistency of LLMs in underrepresented
languages remain largely unexplored, especially concerning local dialects.
Existing benchmarks also focus on main dialects, neglecting LLMs' ability on
local dialect texts. In this paper, we introduce a Thai local dialect benchmark
covering Northern (Lanna), Northeastern (Isan), and Southern (Dambro) Thai,
evaluating LLMs on five NLP tasks: summarization, question answering,
translation, conversation, and food-related tasks. Furthermore, we propose a
human evaluation guideline and metric for Thai local dialects to assess
generation fluency and dialect-specific accuracy. Results show that LLM
performance declines significantly in local Thai dialects compared to standard
Thai, with only proprietary models like GPT-4o and Gemini2 demonstrating some
fluency

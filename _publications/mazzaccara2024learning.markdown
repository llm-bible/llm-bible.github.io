---
layout: publication
title: Learning To Ask Informative Questions Enhancing Llms With Preference Optimization And Expected Information Gain
authors: Mazzaccara Davide, Testoni Alberto, Bernardi Raffaella
conference: "Arxiv"
year: 2024
bibkey: mazzaccara2024learning
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.17453"}
tags: ['Efficiency And Optimization', 'Reinforcement Learning', 'Tools']
---
Questions are essential tools for acquiring the necessary information to complete information45;seeking tasks. However large language models (LLMs) especially open45;source models often perform poorly in generating informative questions as measured by expected information gain (EIG). In this paper we propose a method to enhance the informativeness of LLM45;generated questions in 2045;question game dialogues. We sample multiple questions from the same model (LLAMA 245;CHAT 7B) for each game and create pairs of low45;EIG and high45;EIG questions to apply a Direct Preference Optimization (DPO) algorithm. Our results show that this method produces more effective questions (in terms of EIG) even in domains different from those used to train the DPO model.

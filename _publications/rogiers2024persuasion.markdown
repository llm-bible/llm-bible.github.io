---
layout: publication
title: 'Persuasion With Large Language Models: A Survey'
authors: Alexander Rogiers, Sander Noels, Maarten Buyl, Tijl De Bie
conference: "Arxiv"
year: 2024
bibkey: rogiers2024persuasion
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2411.06837'}
tags: ['Ethics and Bias', 'Tools', 'Survey Paper']
---
The rapid rise of Large Language Models (LLMs) has created new disruptive
possibilities for persuasive communication, by enabling fully-automated
personalized and interactive content generation at an unprecedented scale. In
this paper, we survey the research field of LLM-based persuasion that has
emerged as a result. We begin by exploring the different modes in which LLM
Systems are used to influence human attitudes and behaviors. In areas such as
politics, marketing, public health, e-commerce, and charitable giving, such LLM
Systems have already achieved human-level or even super-human persuasiveness.
We identify key factors influencing their effectiveness, such as the manner of
personalization and whether the content is labelled as AI-generated. We also
summarize the experimental designs that have been used to evaluate progress.
Our survey suggests that the current and future potential of LLM-based
persuasion poses profound ethical and societal risks, including the spread of
misinformation, the magnification of biases, and the invasion of privacy. These
risks underscore the urgent need for ethical guidelines and updated regulatory
frameworks to avoid the widespread deployment of irresponsible and harmful LLM
Systems.

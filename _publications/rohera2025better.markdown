---
layout: publication
title: 'Better To Ask In English? Evaluating Factual Accuracy Of Multilingual Llms In English And Low-resource Languages'
authors: Pritika Rohera, Chaitrali Ginimav, Gayatri Sawant, Raviraj Joshi
conference: "Arxiv"
year: 2025
bibkey: rohera2025better
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2504.20022'}
tags: ['Reinforcement Learning', 'GPT', 'Model Architecture']
---
Multilingual Large Language Models (LLMs) have demonstrated significant
effectiveness across various languages, particularly in high-resource languages
such as English. However, their performance in terms of factual accuracy across
other low-resource languages, especially Indic languages, remains an area of
investigation. In this study, we assess the factual accuracy of LLMs - GPT-4o,
Gemma-2-9B, Gemma-2-2B, and Llama-3.1-8B - by comparing their performance in
English and Indic languages using the IndicQuest dataset, which contains
question-answer pairs in English and 19 Indic languages. By asking the same
questions in English and their respective Indic translations, we analyze
whether the models are more reliable for regional context questions in Indic
languages or when operating in English. Our findings reveal that LLMs often
perform better in English, even for questions rooted in Indic contexts.
Notably, we observe a higher tendency for hallucination in responses generated
in low-resource Indic languages, highlighting challenges in the multilingual
understanding capabilities of current LLMs.

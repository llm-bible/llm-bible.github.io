---
layout: publication
title: "Personalized Autonomous Driving With Large Language Models: Field Experiments"
authors: Cui Can, Yang Zichong, Zhou Yupeng, Ma Yunsheng, Lu Juanwu, Li Lingxi, Chen Yaobin, Panchal Jitesh, Wang Ziran
conference: "Arxiv"
year: 2023
bibkey: cui2023personalized
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2312.09397"}
tags: ['Efficiency And Optimization', 'Pretraining Methods', 'Reinforcement Learning', 'Responsible AI', 'Tools']
---
Integrating large language models (LLMs) in autonomous vehicles enables conversation with AI systems to drive the vehicle. However it also emphasizes the requirement for such systems to comprehend commands accurately and achieve higher-level personalization to adapt to the preferences of drivers or passengers over a more extended period. In this paper we introduce an LLM-based framework Talk2Drive capable of translating natural verbal commands into executable controls and learning to satisfy personal preferences for safety efficiency and comfort with a proposed memory module. This is the first-of-its-kind multi-scenario field experiment that deploys LLMs on a real-world autonomous vehicle. Experiments showcase that the proposed system can comprehend human intentions at different intuition levels ranging from direct commands like can you drive faster to indirect commands like I am really in a hurry now. Additionally we use the takeover rate to quantify the trust of human drivers in the LLM-based autonomous driving system where Talk2Drive significantly reduces the takeover rate in highway intersection and parking scenarios. We also validate that the proposed memory module considers personalized preferences and further reduces the takeover rate by up to 65.237; compared with those without a memory module. The experiment video can be watched at https://www.youtube.com/watch?v=4BWsfPaq1Ro"

---
layout: publication
title: 'A Comparative Study Of Large Language Models And Human Personality Traits'
authors: Wang Jiaqi, Wang Bo, Guo Fa, Cheng Cheng, Yang Li
conference: "Arxiv"
year: 2025
bibkey: jiaqi2025comparative
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2505.14845'}
tags: ['Ethics and Bias', 'Prompting', 'Responsible AI', 'Tools']
---
Large Language Models (LLMs) have demonstrated human-like capabilities in language comprehension and generation, becoming active participants in social and cognitive domains. This study investigates whether LLMs exhibit personality-like traits and how these traits compare with human personality, focusing on the applicability of conventional personality assessment tools. A behavior-based approach was used across three empirical studies. Study 1 examined test-retest stability and found that LLMs show higher variability and are more input-sensitive than humans, lacking long-term stability. Based on this, we propose the Distributed Personality Framework, conceptualizing LLM traits as dynamic and input-driven. Study 2 analyzed cross-variant consistency in personality measures and found LLMs' responses were highly sensitive to item wording, showing low internal consistency compared to humans. Study 3 explored personality retention during role-playing, showing LLM traits are shaped by prompt and parameter settings. These findings suggest that LLMs express fluid, externally dependent personality patterns, offering insights for constructing LLM-specific personality frameworks and advancing human-AI interaction. This work contributes to responsible AI development and extends the boundaries of personality psychology in the age of intelligent systems.

---
layout: publication
title: 'Marco-o1: Towards Open Reasoning Models For Open-ended Solutions'
authors: Yu Zhao, Huifeng Yin, Bo Zeng, Hao Wang, Tianqi Shi, Chenyang Lyu, Longyue Wang, Weihua Luo, Kaifu Zhang
conference: "Arxiv"
year: 2024
bibkey: zhao2024marco
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2411.14405'}
tags: ['Agentic', 'Training Techniques', 'Fine-Tuning', 'Reinforcement Learning', 'Pretraining Methods']
---
Currently OpenAI o1 sparks a surge of interest in the study of large
reasoning models (LRM). Building on this momentum, Marco-o1 not only focuses on
disciplines with standard answers, such as mathematics, physics, and coding --
which are well-suited for reinforcement learning (RL) -- but also places
greater emphasis on open-ended resolutions. We aim to address the question:
''Can the o1 model effectively generalize to broader domains where clear
standards are absent and rewards are challenging to quantify?'' Marco-o1 is
powered by Chain-of-Thought (CoT) fine-tuning, Monte Carlo Tree Search (MCTS),
reflection mechanisms, and innovative reasoning strategies -- optimized for
complex real-world problem-solving tasks.

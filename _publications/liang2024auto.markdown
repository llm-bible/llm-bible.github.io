---
layout: publication
title: 'Dialogagent: An Auto-engagement Agent For Code Question Answering Data Production'
authors: Xiaoyun Liang, Jingyi Ren, Jiayi Qi, Chao Peng, Bo Jiang
conference: "Arxiv"
year: 2024
bibkey: liang2024auto
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2412.08069"}
tags: ['Fine-Tuning', 'Agentic', 'Efficiency and Optimization', 'Applications', 'Reinforcement Learning', 'Training Techniques', 'Pretraining Methods']
---
Large Language Models (LLMs) have become increasingly integral to enhancing
developer productivity, particularly in code generation, comprehension, and
repair tasks. However, fine-tuning these models with high-quality, real-world
data is challenging due to privacy concerns and the lack of accessible, labeled
datasets. In this paper, we present DialogAgent, an automated tool for
generating synthetic training data that closely mimics real developer
interactions within Integrated Development Environments (IDEs). DialogAgent
enables the production of diverse, high-fidelity query-response pairs by
simulating multi-turn dialogues and contextual behaviors observed in real-world
programming scenarios. The tool significantly reduces the reliance on manual
data generation, increasing efficiency by 4.8 times compared to traditional
methods. Our experiments and online deployment demonstrate substantial
improvements in model performance for code-related question-answering tasks:
the acceptance rate of responses generated by our in-house model is improved by
33%, after training on synthesized data generated by DialogAgent.

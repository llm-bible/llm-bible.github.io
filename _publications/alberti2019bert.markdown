---
layout: publication
title: 'A BERT Baseline For The Natural Questions'
authors: Alberti Chris, Lee Kenton, Collins Michael
conference: "Arxiv"
year: 2019
bibkey: alberti2019bert
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/1901.08634"}
  - {name: "Code", url: "https://github.com/google-research/language/tree/master/language/question_answering/bert_joint"}
tags: ['BERT', 'Has Code', 'Model Architecture']
---
This technical note describes a new baseline for the Natural Questions. Our
model is based on BERT and reduces the gap between the model F1 scores reported
in the original dataset paper and the human upper bound by 30% and 50% relative
for the long and short answer tasks respectively. This baseline has been
submitted to the official NQ leaderboard at
ai.google.com/research/NaturalQuestions. Code, preprocessed data and pretrained
model are available at
https://github.com/google-research/language/tree/master/language/question_answering/bert_joint.

---
layout: publication
title: Fine45;tuning Chatgpt For Automatic Scoring
authors: Latif Ehsan, Zhai Xiaoming
conference: "Arxiv"
year: 2023
bibkey: latif2023fine
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.10072"}
tags: ['BERT', 'GPT', 'Model Architecture', 'Pretraining Methods', 'RAG', 'Training Techniques']
---
This study highlights the potential of fine45;tuned ChatGPT (GPT45;3.5) for automatically scoring student written constructed responses using example assessment tasks in science education. Recent studies on OpenAIs generative model GPT45;3.5 proved its superiority in predicting the natural language with high accuracy and human45;like responses. GPT45;3.5 has been trained over enormous online language materials such as journals and Wikipedia; therefore more than direct usage of pre45;trained GPT45;3.5 is required for automatic scoring as students utilize a different language than trained material. These imply that a domain45;specific model fine45;tuned over data for specific tasks can enhance model performance. In this study we fine45;tuned GPT45;3.5 on six assessment tasks with a diverse dataset of middle45;school and high45;school student responses and expert scoring. The six tasks comprise two multi45;label and four multi45;class assessment tasks. We compare the performance of fine45;tuned GPT45;3.5 with the fine45;tuned state45;of45;the45;art Googles generated language model BERT. The results show that in45;domain training corpora constructed from science questions and responses for BERT achieved average accuracy = 0.838 SD = 0.069. GPT45;3.5 shows a remarkable average increase (9.137;) in automatic scoring accuracy (mean = 9.15 SD = 0.042) for the six tasks p =0.001 < 0.05. Specifically for multi45;label tasks (item 1 with 5 labels; item 2 with 10 labels) GPT45;3.5 achieved significantly higher scoring accuracy than BERT across all the labels with the second item achieving a 7.137; increase. The average scoring increase for the four multi45;class items for GPT45;3.5 was 10.637; compared to BERT. Our study confirmed the effectiveness of fine45;tuned GPT45;3.5 for automatic scoring of student responses on domain45;specific data in education with high accuracy. We have released fine45;tuned models for public use and community engagement.

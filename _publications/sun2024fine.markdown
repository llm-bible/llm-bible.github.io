---
layout: publication
title: Fine-tuning Vs Prompting Can Language Models Understand Human Values
authors: Sun Pingwei
conference: "Arxiv"
year: 2024
bibkey: sun2024fine
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.09720"}
tags: ['Applications', 'Fine Tuning', 'Pretraining Methods', 'Prompting', 'Reinforcement Learning', 'Training Techniques']
---
Accurately handling the underlying support values in sentences is crucial for understanding the speakers tendencies yet it poses a challenging task in natural language understanding (NLU). In this article we explore the potential of fine-tuning and prompt tuning in this downstream task using the Human Value Detection 2023. Additionally we attempt to validate whether models can effectively solve the problem based on the knowledge acquired during the pre-training stage. Simultaneously our interest lies in the capabilities of large language models (LLMs) aligned with RLHF in this task and some preliminary attempts are presented.

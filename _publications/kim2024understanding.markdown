---
layout: publication
title: Understanding Large45;language Model (llm)45;powered Human45;robot Interaction
authors: Kim Callie Y., Lee Christine P., Mutlu Bilge
conference: "Arxiv"
year: 2024
bibkey: kim2024understanding
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.03217"}
tags: ['Agentic', 'Pretraining Methods']
---
Large45;language models (LLMs) hold significant promise in improving human45;robot interaction offering advanced conversational skills and versatility in managing diverse open45;ended user requests in various tasks and domains. Despite the potential to transform human45;robot interaction very little is known about the distinctive design requirements for utilizing LLMs in robots which may differ from text and voice interaction and vary by task and context. To better understand these requirements we conducted a user study (n = 32) comparing an LLM45;powered social robot against text45; and voice45;based agents analyzing task45;based requirements in conversational tasks including choose generate execute and negotiate. Our findings show that LLM45;powered robots elevate expectations for sophisticated non45;verbal cues and excel in connection45;building and deliberation but fall short in logical communication and may induce anxiety. We provide design implications both for robots integrating LLMs and for fine45;tuning LLMs for use with robots.

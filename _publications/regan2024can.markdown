---
layout: publication
title: 'Can Generative Agents Predict Emotion?'
authors: Ciaran Regan, Nanami Iwahashi, Shogo Tanaka, Mizuki Oka
conference: "Arxiv"
year: 2024
bibkey: regan2024can
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2402.04232'}
tags: ['Agentic', 'Model Architecture']
---
Large Language Models (LLMs) have demonstrated a number of human-like
abilities, however the empathic understanding and emotional state of LLMs is
yet to be aligned to that of humans. In this work, we investigate how the
emotional state of generative LLM agents evolves as they perceive new events,
introducing a novel architecture in which new experiences are compared to past
memories. Through this comparison, the agent gains the ability to understand
new experiences in context, which according to the appraisal theory of emotion
is vital in emotion creation. First, the agent perceives new experiences as
time series text data. After perceiving each new input, the agent generates a
summary of past relevant memories, referred to as the norm, and compares the
new experience to this norm. Through this comparison we can analyse how the
agent reacts to the new experience in context. The PANAS, a test of affect, is
administered to the agent, capturing the emotional state of the agent after the
perception of the new event. Finally, the new experience is then added to the
agents memory to be used in the creation of future norms. By creating multiple
experiences in natural language from emotionally charged situations, we test
the proposed architecture on a wide range of scenarios. The mixed results
suggests that introducing context can occasionally improve the emotional
alignment of the agent, but further study and comparison with human evaluators
is necessary. We hope that this paper is another step towards the alignment of
generative agents.

---
layout: publication
title: 'Data Generation Using Large Language Models For Text Classification: An Empirical Case Study'
authors: Yinheng Li, Rogerio Bonatti, Sara Abdali, Justin Wagle, Kazuhito Koishida
conference: "Arxiv"
year: 2024
bibkey: li2024data
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.12813"}
tags: ['Prompting', 'Training Techniques', 'Applications']
---
Using Large Language Models (LLMs) to generate synthetic data for model
training has become increasingly popular in recent years. While LLMs are
capable of producing realistic training data, the effectiveness of data
generation is influenced by various factors, including the choice of prompt,
task complexity, and the quality, quantity, and diversity of the generated
data. In this work, we focus exclusively on using synthetic data for text
classification tasks. Specifically, we use natural language understanding (NLU)
models trained on synthetic data to assess the quality of synthetic data from
different generation approaches. This work provides an empirical analysis of
the impact of these factors and offers recommendations for better data
generation practices.

---
layout: publication
title: Complementary Explanations For Effective In45;context Learning
authors: Ye Xi, Iyer Srinivasan, Celikyilmaz Asli, Stoyanov Ves, Durrett Greg, Pasunuru Ramakanth
conference: "Arxiv"
year: 2022
bibkey: ye2022complementary
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2211.13892"}
tags: ['Interpretability And Explainability', 'Prompting', 'Reinforcement Learning']
---
Large language models (LLMs) have exhibited remarkable capabilities in learning from explanations in prompts but there has been limited understanding of exactly how these explanations function or why they are effective. This work aims to better understand the mechanisms by which explanations are used for in45;context learning. We first study the impact of two different factors on the performance of prompts with explanations the computation trace (the way the solution is decomposed) and the natural language used to express the prompt. By perturbing explanations on three controlled tasks we show that both factors contribute to the effectiveness of explanations. We further study how to form maximally effective sets of explanations for solving a given test query. We find that LLMs can benefit from the complementarity of the explanation set diverse reasoning skills shown by different exemplars can lead to better performance. Therefore we propose a maximal marginal relevance45;based exemplar selection approach for constructing exemplar sets that are both relevant as well as complementary which successfully improves the in45;context learning performance across three real45;world tasks on multiple LLMs.

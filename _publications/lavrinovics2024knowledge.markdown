---
layout: publication
title: 'Knowledge Graphs, Large Language Models, And Hallucinations: An NLP Perspective'
authors: Ernests Lavrinovics, Russa Biswas, Johannes Bjerva, Katja Hose
conference: "Arxiv"
year: 2024
bibkey: lavrinovics2024knowledge
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2411.14258"}
tags: ['RAG', 'Language Modeling', 'Applications']
---
Large Language Models (LLMs) have revolutionized Natural Language Processing
(NLP) based applications including automated text generation, question
answering, chatbots, and others. However, they face a significant challenge:
hallucinations, where models produce plausible-sounding but factually incorrect
responses. This undermines trust and limits the applicability of LLMs in
different domains. Knowledge Graphs (KGs), on the other hand, provide a
structured collection of interconnected facts represented as entities (nodes)
and their relationships (edges). In recent research, KGs have been leveraged to
provide context that can fill gaps in an LLM understanding of certain topics
offering a promising approach to mitigate hallucinations in LLMs, enhancing
their reliability and accuracy while benefiting from their wide applicability.
Nonetheless, it is still a very active area of research with various unresolved
open problems. In this paper, we discuss these open challenges covering
state-of-the-art datasets and benchmarks as well as methods for knowledge
integration and evaluating hallucinations. In our discussion, we consider the
current use of KGs in LLM systems and identify future directions within each of
these challenges.

---
layout: publication
title: Kwaiyiimath Technical Report
authors: Fu Jiayi, Lin Lei, Gao Xiaoyang, Liu Pengli, Chen Zhengzong, Yang Zhirui, Zhang Shengnan, Zheng Xue, Li Yan, Liu Yuliang, Ye Xucheng, Liao Yiqiao, Liao Chao, Chen Bin, Song Chengru, Wan Junchen, Lin Zijia, Zhang Fuzheng, Wang Zhongyuan, Zhang Di, Gai Kun
conference: "Arxiv"
year: 2023
bibkey: fu2023technical
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.07488"}
tags: ['Fine Tuning', 'Reinforcement Learning']
---
Recent advancements in large language models (LLMs) have demonstrated remarkable abilities in handling a variety of natural language processing (NLP) downstream tasks even on mathematical tasks requiring multi45;step reasoning. In this report we introduce the KwaiYiiMath which enhances the mathematical reasoning abilities of KwaiYiiBase1 by applying Supervised Fine45;Tuning (SFT) and Reinforced Learning from Human Feedback (RLHF) including on both English and Chinese mathematical tasks. Meanwhile we also constructed a small45;scale Chinese primary school mathematics test set (named KMath) consisting of 188 examples to evaluate the correctness of the problem45;solving process generated by the models. Empirical studies demonstrate that KwaiYiiMath can achieve state45;of45;the45;art (SOTA) performance on GSM8k CMath and KMath compared with the similar size models respectively.

---
layout: publication
title: 'Persona Knowledge-aligned Prompt Tuning Method For Online Debate'
authors: Chunkit Chan, Cheng Jiayang, Xin Liu, Yauwai Yim, Yuxin Jiang, Zheye Deng, Haoran Li, Yangqiu Song, Ginny Y. Wong, Simon See
conference: "Arxiv"
year: 2024
bibkey: chan2024persona
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2410.04239"}
tags: ['Tools', 'GPT', 'RAG', 'Model Architecture', 'Attention Mechanism', 'Prompting']
---
Debate is the process of exchanging viewpoints or convincing others on a
particular issue. Recent research has provided empirical evidence that the
persuasiveness of an argument is determined not only by language usage but also
by communicator characteristics. Researchers have paid much attention to
aspects of languages, such as linguistic features and discourse structures, but
combining argument persuasiveness and impact with the social personae of the
audience has not been explored due to the difficulty and complexity. We have
observed the impressive simulation and personification capability of ChatGPT,
indicating a giant pre-trained language model may function as an individual to
provide personae and exert unique influences based on diverse background
knowledge. Therefore, we propose a persona knowledge-aligned framework for
argument quality assessment tasks from the audience side. This is the first
work that leverages the emergence of ChatGPT and injects such audience personae
knowledge into smaller language models via prompt tuning. The performance of
our pipeline demonstrates significant and consistent improvement compared to
competitive architectures.

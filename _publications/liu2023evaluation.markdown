---
layout: publication
title: An Evaluation of GPT-4V and Gemini in Online VQA
authors: Liu Mengchen, Chen Chongyan, Gurari Danna
conference: "Arxiv"
year: 2023
bibkey: liu2023evaluation
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2312.10637"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Multimodal Models', 'Reinforcement Learning']
---
While there is much excitement about the potential of large multimodal models (LMM) a comprehensive evaluation is critical to establish their true capabilities and limitations. In support of this aim we evaluate two state-of-the-art LMMs GPT-4V and Gemini on a new visual question answering dataset sourced from an authentic online question answering community. We conduct fine-grained analysis by generating seven types of metadata for nearly 2000 visual questions such as image type and the required image processing capabilities. Our zero-shot performance analysis highlights the types of questions that are most challenging for both models including questions related to puzzling topic with Identification user intention with Sheet Music image type or labeled as hard by GPT-4.

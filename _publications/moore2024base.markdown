---
layout: publication
title: The Base45;rate Effect On LLM Benchmark Performance Disambiguating Test45;taking Strategies From Benchmark Performance
authors: Moore Kyle, Roberts Jesse, Pham Thao, Ewaleifoh Oseremhen, Fisher Doug
conference: "Arxiv"
year: 2024
bibkey: moore2024base
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.11634"}
tags: ['Pretraining Methods', 'Prompting']
---
Cloze testing is a common method for measuring the behavior of large language models on a number of benchmark tasks. Using the MMLU dataset we show that the base45;rate probability (BRP) differences across answer tokens are significant and affect task performance ie. guess A if uncertain. We find that counterfactual prompting does sufficiently mitigate the BRP effect. The BRP effect is found to have a similar effect to test taking strategies employed by humans leading to the conflation of task performance and test45;taking ability. We propose the Nvr45;X45;MMLU task a variation of MMLU which helps to disambiguate test45;taking ability from task performance and reports the latter.

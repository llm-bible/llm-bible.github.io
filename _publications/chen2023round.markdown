---
layout: publication
title: Reconcile Round45;table Conference Improves Reasoning Via Consensus Among Diverse Llms
authors: Chen Justin Chih-yao, Saha Swarnadeep, Bansal Mohit
conference: "Arxiv"
year: 2023
bibkey: chen2023round
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.13007"}
  - {name: "Code", url: "https://github.com/dinobby/ReConcile"}
tags: ['Agentic', 'GPT', 'Has Code', 'Interpretability And Explainability', 'Model Architecture', 'Pretraining Methods', 'Prompting', 'Tools']
---
Large Language Models (LLMs) still struggle with natural language reasoning tasks. Motivated by the society of minds (Minsky 1988) we propose ReConcile a multi45;model multi45;agent framework designed as a round table conference among diverse LLM agents. ReConcile enhances collaborative reasoning between LLM agents via multiple rounds of discussion learning to convince other agents to improve their answers and employing a confidence45;weighted voting mechanism that leads to a better consensus. In each round ReConcile initiates discussion between agents via a discussion prompt that consists of (a) grouped answers and explanations generated by each agent in the previous round (b) their confidence scores and (c) demonstrations of answer45;rectifying human explanations used for convincing other agents. Experiments on seven benchmarks demonstrate that ReConcile significantly improves LLMs reasoning 45;45; both individually and as a team 45;45; surpassing prior single45;agent and multi45;agent baselines by up to 11.437; and even outperforming GPT45;4 on three datasets. ReConcile also flexibly incorporates different combinations of agents including API45;based open45;source and domain45;specific models leading to an 837; improvement on MATH. Finally we analyze the individual components of ReConcile demonstrating that the diversity originating from different models is critical to its superior performance. Code https://github.com/dinobby/ReConcile

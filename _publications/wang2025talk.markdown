---
layout: publication
title: 'Talk Structurally, Act Hierarchically: A Collaborative Framework For LLM Multi-agent Systems'
authors: Zhao Wang, Sota Moriyama, Wei-yao Wang, Briti Gangopadhyay, Shingo Takamatsu
conference: "Arxiv"
year: 2025
bibkey: wang2025talk
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.11098"}
  - {name: "Code", url: "https://github.com/sony/talkhier"}
tags: ['Agentic', 'Agent', 'Model Architecture', 'Tools', 'Language Modeling', 'GPT', 'Ethics and Bias', 'Has Code', 'Applications']
---
Recent advancements in LLM-based multi-agent (LLM-MA) systems have shown
promise, yet significant challenges remain in managing communication and
refinement when agents collaborate on complex tasks. In this paper, we propose
\textit\{Talk Structurally, Act Hierarchically (TalkHier)\}, a novel framework
that introduces a structured communication protocol for context-rich exchanges
and a hierarchical refinement system to address issues such as incorrect
outputs, falsehoods, and biases. \textit\{TalkHier\} surpasses various types of
SoTA, including inference scaling model (OpenAI-o1), open-source multi-agent
models (e.g., AgentVerse), and majority voting strategies on current LLM and
single-agent baselines (e.g., ReAct, GPT4o), across diverse tasks, including
open-domain question answering, domain-specific selective questioning, and
practical advertisement text generation. These results highlight its potential
to set a new standard for LLM-MA systems, paving the way for more effective,
adaptable, and collaborative multi-agent frameworks. The code is available
https://github.com/sony/talkhier.

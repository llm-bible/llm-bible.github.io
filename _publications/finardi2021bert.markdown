---
layout: publication
title: Bertau Itau BERT For Digital Customer Service
authors: Finardi Paulo, Viegas José Dié, Ferreira Gustavo T., Mansano Alex F., Caridá Vinicius F.
conference: "Arxiv"
year: 2021
bibkey: finardi2021bert
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2101.12015"}
tags: ['Agentic', 'Applications', 'BERT', 'Model Architecture', 'Reinforcement Learning']
---
In the last few years three major topics received increased interest deep learning NLP and conversational agents. Bringing these three topics together to create an amazing digital customer experience and indeed deploy in production and solve real-world problems is something innovative and disruptive. We introduce a new Portuguese financial domain language representation model called BERTau. BERTau is an uncased BERT-base trained from scratch with data from the Itau virtual assistant chatbot solution. Our novel contribution is that BERTau pretrained language model requires less data reached state-of-the-art performance in three NLP tasks and generates a smaller and lighter model that makes the deployment feasible. We developed three tasks to validate our model information retrieval with Frequently Asked Questions (FAQ) from Itau bank sentiment analysis from our virtual assistant data and a NER solution. All proposed tasks are real-world solutions in production on our environment and the usage of a specialist model proved to be effective when compared to Google BERT multilingual and the DPRQuestionEncoder from Facebook available at Hugging Face. The BERTau improves the performance in 2237; of FAQ Retrieval MRR metric 2.137; in Sentiment Analysis F1 score 4.437; in NER F1 score and can also represent the same sequence in up to 6637; fewer tokens when compared to shelf models.

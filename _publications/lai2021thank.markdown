---
layout: publication
title: Thank You BART! Rewarding Pre-trained Models Improves Formality Style Transfer
authors: Huiyuan Lai, Antonio Toral, Malvina Nissim
conference: Arxiv
year: 2021
citations: 15
bibkey: lai2021thank
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2105.06947'}]
tags: [Fine-Tuning, Reinforcement Learning, GPT]
---
Scarcity of parallel data causes formality style transfer models to have
scarce success in preserving content. We show that fine-tuning pre-trained
language (GPT-2) and sequence-to-sequence (BART) models boosts content
preservation, and that this is possible even with limited amounts of parallel
data. Augmenting these models with rewards that target style and content -- the
two core aspects of the task -- we achieve a new state-of-the-art.
---
layout: publication
title: 'Audio Flamingo: A Novel Audio Language Model With Few-shot Learning And Dialogue Abilities'
authors: Zhifeng Kong, Arushi Goel, Rohan Badlani, Wei Ping, Rafael Valle, Bryan Catanzaro
conference: "Arxiv"
year: 2024
bibkey: kong2024audio
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.01831"}
  - {name: "Code", url: "https://audioflamingo.github.io/"}
  - {name: "Code", url: "https://github.com/NVIDIA/audio-flamingo"}
tags: ['Applications', 'Model Architecture', 'Reinforcement Learning', 'Training Techniques', 'Has Code', 'Few-Shot', 'Prompting', 'In-Context Learning']
---
Augmenting large language models (LLMs) to understand audio -- including
non-speech sounds and non-verbal speech -- is critically important for diverse
real-world applications of LLMs. In this paper, we propose Audio Flamingo, a
novel audio language model with 1) strong audio understanding abilities, 2) the
ability to quickly adapt to unseen tasks via in-context learning and retrieval,
and 3) strong multi-turn dialogue abilities. We introduce a series of training
techniques, architecture design, and data strategies to enhance our model with
these abilities. Extensive evaluations across various audio understanding tasks
confirm the efficacy of our method, setting new state-of-the-art benchmarks.
Our demo website is https://audioflamingo.github.io/ and the code is
open-sourced at https://github.com/NVIDIA/audio-flamingo.

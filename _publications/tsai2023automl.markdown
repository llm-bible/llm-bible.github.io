---
layout: publication
title: Automl45;gpt Large Language Model For Automl
authors: Tsai Yun-da, Tsai Yu-che, Huang Bo-wei, Yang Chun-pai, Lin Shou-de
conference: "Arxiv"
year: 2023
bibkey: tsai2023automl
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.01125"}
tags: ['Efficiency And Optimization', 'GPT', 'Merging', 'Model Architecture', 'RAG', 'Tools', 'Training Techniques']
---
With the emerging trend of GPT models we have established a framework called AutoML45;GPT that integrates a comprehensive set of tools and libraries. This framework grants users access to a wide range of data preprocessing techniques feature engineering methods and model selection algorithms. Through a conversational interface users can specify their requirements constraints and evaluation metrics. Throughout the process AutoML45;GPT employs advanced techniques for hyperparameter optimization and model selection ensuring that the resulting model achieves optimal performance. The system effectively manages the complexity of the machine learning pipeline guiding users towards the best choices without requiring deep domain knowledge. Through our experimental results on diverse datasets we have demonstrated that AutoML45;GPT significantly reduces the time and effort required for machine learning tasks. Its ability to leverage the vast knowledge encoded in large language models enables it to provide valuable insights identify potential pitfalls and suggest effective solutions to common challenges faced during model training.

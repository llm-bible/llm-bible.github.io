---
layout: publication
title: 'Overview Of TREC 2024 Biomedical Generative Retrieval (biogen) Track'
authors: Deepak Gupta, Dina Demner-fushman, William Hersh, Steven Bedrick, Kirk Roberts
conference: "Arxiv"
year: 2024
bibkey: gupta2024overview
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2411.18069"}
tags: ['Applications', 'Reinforcement Learning']
---
With the advancement of large language models (LLMs), the biomedical domain
has seen significant progress and improvement in multiple tasks such as
biomedical question answering, lay language summarization of the biomedical
literature, clinical note summarization, etc. However, hallucinations or
confabulations remain one of the key challenges when using LLMs in the
biomedical and other domains. Inaccuracies may be particularly harmful in
high-risk situations, such as medical question answering, making clinical
decisions, or appraising biomedical research. Studies on the evaluation of the
LLMs abilities to ground generated statements in verifiable sources have shown
that models perform significantly worse on lay-user-generated questions, and
often fail to reference relevant sources. This can be problematic when those
seeking information want evidence from studies to back up the claims from LLMs.
Unsupported statements are a major barrier to using LLMs in any applications
that may affect health. Methods for grounding generated statements in reliable
sources along with practical evaluation approaches are needed to overcome this
barrier. Towards this, in our pilot task organized at TREC 2024, we introduced
the task of reference attribution as a means to mitigate the generation of
false statements by LLMs answering biomedical questions.

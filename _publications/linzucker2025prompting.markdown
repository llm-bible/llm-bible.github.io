---
layout: publication
title: 'Prompting Chatgpt For Chinese Learning As L2: A CEFR And EBCL Level Study'
authors: Miao Lin-zucker, JoÃ«l Bellassen, Jean-daniel Zucker
conference: "Arxiv"
year: 2025
bibkey: linzucker2025prompting
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2501.15247"}
tags: ['Model Architecture', 'Tools', 'Reinforcement Learning', 'GPT', 'Prompting']
---
The use of chatbots in language learning has evolved significantly since the
1960s, becoming more sophisticated platforms as generative AI emerged. These
tools now simulate natural conversations, adapting to individual learners'
needs, including those studying Chinese. Our study explores how learners can
use specific prompts to engage Large Language Models (LLM) as personalized
chatbots, aiming to target their language level based on the Common European
Framework of Reference for Languages (CEFR) and the European Benchmarking
Chinese Language (EBCL) project. Focusing on A1, A1+ and A2 levels, we examine
the teaching of Chinese, which presents unique challenges due to its
logographic writing system. Our goal is to develop prompts that integrate oral
and written skills, using high-frequency character lists and controlling oral
lexical productions. These tools, powered by generative AI, aim to enhance
language practice by crossing lexical and sinographic recurrence. While
generative AI shows potential as a personalized tutor, further evaluation is
needed to assess its effectiveness. We conducted a systematic series of
experiments using ChatGPT models to evaluate their adherence to constraints
specified in the prompts. The results indicate that incorporating level A1 and
A1+ characters, along with the associated reference list, significantly
enhances compliance with the EBCL character set. Properly prompted, LLMs can
increase exposure to the target language and offer interactive exchanges to
develop language skills.

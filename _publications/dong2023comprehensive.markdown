---
layout: publication
title: BAMBOO: A Comprehensive Benchmark For Evaluating Long Text Modeling Capacities Of Large Language Models
authors: Dong Zican, Tang Tianyi, Li Junyi, Zhao Wayne Xin, Wen Ji-rong
conference: "Arxiv"
year: 2023
bibkey: dong2023comprehensive
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.13345"}
  - {name: "Code", url: "https://github.com/RUCAIBox/BAMBOO"}
tags: ['Applications', 'Has Code', 'Language Modeling', 'Prompting']
---
Large language models (LLMs) have achieved dramatic proficiency over NLP tasks with normal length. Recently multiple studies have committed to extending the context length and enhancing the long text modeling capabilities of LLMs. To comprehensively evaluate the long context ability of LLMs we propose BAMBOO a multi-task long context benchmark. BAMBOO has been designed with four principles comprehensive capacity evaluation avoidance of data contamination accurate automatic evaluation and different length levels. It consists of 10 datasets from 5 different long text understanding tasks i.e. question answering hallucination detection text sorting language modeling and code completion to cover core capacities and various domains of LLMs. We conduct experiments with five long context models on BAMBOO and further discuss four key research questions of long text. We also qualitatively analyze current long context models and point out future directions for enhancing long text modeling capacities. We release our data prompts and code at https://github.com/RUCAIBox/BAMBOO."

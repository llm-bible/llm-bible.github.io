---
layout: publication
title: 'Evaluating Large Language Models With Fmeval'
authors: Pola Schwöbel, Luca Franceschi, Muhammad Bilal Zafar, Keerthan Vasist, Aman Malhotra, Tomer Shenhar, Pinal Tailor, Pinar Yilmaz, Michael Diamond, Michele Donini
conference: "Arxiv"
year: 2024
bibkey: schwöbel2024evaluating
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2407.12872'}
  - {name: "Code", url: 'https://github.com/aws/fmeval'}
tags: ['Has Code', 'RAG', 'Tools', 'Applications', 'Reinforcement Learning', 'Ethics and Bias', 'Responsible AI']
---
fmeval is an open source library to evaluate large language models (LLMs) in
a range of tasks. It helps practitioners evaluate their model for task
performance and along multiple responsible AI dimensions. This paper presents
the library and exposes its underlying design principles: simplicity, coverage,
extensibility and performance. We then present how these were implemented in
the scientific and engineering choices taken when developing fmeval. A case
study demonstrates a typical use case for the library: picking a suitable model
for a question answering task. We close by discussing limitations and further
work in the development of the library. fmeval can be found at
https://github.com/aws/fmeval.

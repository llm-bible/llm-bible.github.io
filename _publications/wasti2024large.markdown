---
layout: publication
title: Large Language User Interfaces Voice Interactive User Interfaces powered by LLMs
authors: Wasti Syed Mekael, Pu Ken Q., Neshati Ali
conference: "Arxiv"
year: 2024
bibkey: wasti2024large
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.07938"}
tags: ['ARXIV', 'Agent', 'LLM', 'Pretraining Methods', 'Prompt', 'Tools']
---
The evolution of Large Language Models (LLMs) has showcased remarkable capacities for logical reasoning and natural language comprehension. These capabilities can be leveraged in solutions that semantically and textually model complex problems. In this paper we present our efforts toward constructing a framework that can serve as an intermediary between a user and their user interface (UI) enabling dynamic and real-time interactions. We employ a system that stands upon textual semantic mappings of UI components in the form of annotations. These mappings are stored parsed and scaled in a custom data structure supplementary to an agent-based prompting backend engine. Employing textual semantic mappings allows each component to not only explain its role to the engine but also provide expectations. By comprehending the needs of both the user and the components our LLM engine can classify the most appropriate application extract relevant parameters and subsequently execute precise predictions of the users expected actions. Such an integration evolves static user interfaces into highly dynamic and adaptable solutions introducing a new frontier of intelligent and responsive user experiences.

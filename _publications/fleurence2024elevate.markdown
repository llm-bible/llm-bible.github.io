---
layout: publication
title: 'The ELEVATE-AI Llms Framework: An Evaluation Framework For Use Of Large Language Models In HEOR: An ISPOR Working Group Report'
authors: Rachael L. Fleurence, Dalia Dawoud, Jiang Bian, Mitchell K. Higashi, Xiaoyan Wang, Hua Xu, Jagpreet Chhatwal, Turgay Ayer
conference: "Arxiv"
year: 2024
bibkey: fleurence2024elevate
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2501.12394"}
tags: ['Tools', 'Survey Paper', 'Ethics and Bias', 'Bias Mitigation', 'Reinforcement Learning', 'Interpretability', 'Fairness']
---
Introduction. Generative Artificial Intelligence, particularly large language
models (LLMs), offers transformative potential for Health Economics and
Outcomes Research (HEOR). However, evaluating the quality, transparency, and
rigor of LLM-assisted research lacks standardized guidance. This article
introduces the ELEVATE AI LLMs framework and checklist, designed to support
researchers and reviewers in assessing LLM use in HEOR.
  Methods. The ELEVATE AI LLMs framework was developed through a targeted
review of existing guidelines and evaluation frameworks. The framework
comprises ten evaluation domains, including model characteristics, accuracy,
comprehensiveness, and fairness. The accompanying checklist operationalizes the
framework. To validate the framework, we applied it to two published studies,
demonstrating its usability across different HEOR tasks.
  Results. The ELEVATE AI LLMs framework provides a comprehensive structure for
evaluating LLM-assisted research, while the checklist facilitates practical
application. Validation of the framework and checklist on studies of systematic
literature reviews and health economic modeling highlighted their ability to
identify strengths and gaps in reporting.
  Limitations. While the ELEVATE AI LLMs framework provides robust guidance,
its broader generalizability and applicability to diverse HEOR tasks require
further empirical testing. Additionally, several metrics adapted from computer
science need further validation in HEOR contexts.
  Conclusion. The ELEVATE AI LLMs framework and checklist fill a critical gap
in HEOR by offering structured guidance for evaluating LLM-assisted research.
By promoting transparency, accuracy, and reproducibility, they aim to
standardize and improve the integration of LLMs into HEOR, ensuring their
outputs meet the field's rigorous standards.

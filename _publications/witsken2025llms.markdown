---
layout: publication
title: 'Llms In The Classroom: Outcomes And Perceptions Of Questions Written With The Aid Of AI'
authors: Gavin Witsken, Igor Crk, Eren Gultepe
conference: "Arxiv"
year: 2025
bibkey: witsken2025llms
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2503.18995"}
tags: ['BERT', 'Model Architecture', 'GPT', 'Tools']
---
We randomly deploy questions constructed with and without use of the LLM tool
and gauge the ability of the students to correctly answer, as well as their
ability to correctly perceive the difference between human-authored and
LLM-authored questions. In determining whether the questions written with the
aid of ChatGPT were consistent with the instructor's questions and source text,
we computed representative vectors of both the human and ChatGPT questions
using SBERT and compared cosine similarity to the course textbook. A
non-significant Mann-Whitney U test (z = 1.018, p = .309) suggests that
students were unable to perceive whether questions were written with or without
the aid of ChatGPT. However, student scores on LLM-authored questions were
almost 9% lower (z = 2.702, p < .01). This result may indicate that either the
AI questions were more difficult or that the students were more familiar with
the instructor's style of questions. Overall, the study suggests that while
there is potential for using LLM tools to aid in the construction of
assessments, care must be taken to ensure that the questions are fair,
well-composed, and relevant to the course material.

---
layout: publication
title: Can GPT Models Follow Human Summarization Guidelines Evaluating Chatgpt And GPT45;4 For Dialogue Summarization
authors: Zhou Yongxin, Ringeval Fabien, Portet Fran√ßois
conference: "Arxiv"
year: 2023
bibkey: zhou2023can
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.16810"}
tags: ['Applications', 'BERT', 'GPT', 'Model Architecture', 'Prompting']
---
This study explores the capabilities of prompt45;driven Large Language Models (LLMs) like ChatGPT and GPT45;4 in adhering to human guidelines for dialogue summarization. Experiments employed DialogSum (English social conversations) and DECODA (French call center interactions) testing various prompts including prompts from existing literature and those from human summarization guidelines as well as a two45;step prompt approach. Our findings indicate that GPT models often produce lengthy summaries and deviate from human summarization guidelines. However using human guidelines as an intermediate step shows promise outperforming direct word45;length constraint prompts in some cases. The results reveal that GPT models exhibit unique stylistic tendencies in their summaries. While BERTScores did not dramatically decrease for GPT outputs suggesting semantic similarity to human references and specialised pre45;trained models ROUGE scores reveal grammatical and lexical disparities between GPT45;generated and human45;written summaries. These findings shed light on the capabilities and limitations of GPT models in following human instructions for dialogue summarization.

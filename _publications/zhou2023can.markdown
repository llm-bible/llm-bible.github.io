---
layout: publication
title: 'Can GPT Models Follow Human Summarization Guidelines? A Study For Targeted Communication Goals'
authors: Yongxin Zhou, Fabien Ringeval, Fran√ßois Portet
conference: "Arxiv"
year: 2023
bibkey: zhou2023can
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.16810"}
tags: ['Model Architecture', 'GPT', 'BERT', 'Prompting', 'Applications']
---
This study investigates the ability of GPT models (ChatGPT, GPT-4 and GPT-4o)
to generate dialogue summaries that adhere to human guidelines. Our evaluation
involved experimenting with various prompts to guide the models in complying
with guidelines on two datasets: DialogSum (English social conversations) and
DECODA (French call center interactions). Human evaluation, based on
summarization guidelines, served as the primary assessment method, complemented
by extensive quantitative and qualitative analyses. Our findings reveal a
preference for GPT-generated summaries over those from task-specific
pre-trained models and reference summaries, highlighting GPT models' ability to
follow human guidelines despite occasionally producing longer outputs and
exhibiting divergent lexical and structural alignment with references. The
discrepancy between ROUGE, BERTScore, and human evaluation underscores the need
for more reliable automatic evaluation metrics.

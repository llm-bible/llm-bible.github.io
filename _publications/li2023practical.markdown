---
layout: publication
title: A Practical Survey On Zero-shot Prompt Design For In-context Learning
authors: Li Yinheng
conference: "RANLP"
year: 2023
bibkey: li2023practical
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.13205"}
tags: ['Efficiency And Optimization', 'Few Shot', 'In Context Learning', 'Prompting', 'Survey Paper']
---
The remarkable advancements in large language models (LLMs) have brought about significant improvements in Natural Language Processing(NLP) tasks. This paper presents a comprehensive review of in-context learning techniques focusing on different types of prompts including discrete continuous few-shot and zero-shot and their impact on LLM performance. We explore various approaches to prompt design such as manual design optimization algorithms and evaluation methods to optimize LLM performance across diverse tasks. Our review covers key research studies in prompt engineering discussing their methodologies and contributions to the field. We also delve into the challenges faced in evaluating prompt performance given the absence of a single best prompt and the importance of considering multiple metrics. In conclusion the paper highlights the critical role of prompt design in harnessing the full potential of LLMs and provides insights into the combination of manual design optimization techniques and rigorous evaluation for more effective and efficient use of LLMs in various NLP tasks.

---
layout: publication
title: Less Is More Accurate Speech Recognition amp; Translation Without Web45;scale Data
authors: Puvvada Krishna C., Å»elasko Piotr, Huang He, Hrinchuk Oleksii, Koluguri Nithin Rao, Dhawan Kunal, Majumdar Somshubra, Rastorgueva Elena, Chen Zhehuai, Lavrukhin Vitaly, Balam Jagadeesh, Ginsburg Boris
conference: "Arxiv"
year: 2024
bibkey: puvvada2024less
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.19674"}
tags: ['Applications', 'Attention Mechanism', 'Model Architecture', 'Training Techniques']
---
Recent advances in speech recognition and translation rely on hundreds of thousands of hours of Internet speech data. We argue that state45;of45;the art accuracy can be reached without relying on web45;scale data. Canary 45; multilingual ASR and speech translation model outperforms current state45;of45;the45;art models 45; Whisper OWSM and Seamless45;M4T on English French Spanish and German languages while being trained on an order of magnitude less data than these models. Three key factors enables such data45;efficient model (1) a FastConformer45;based attention encoder45;decoder architecture (2) training on synthetic data generated with machine translation and (3) advanced training techniques data45;balancing dynamic data blending dynamic bucketing and noise45;robust fine45;tuning. The model weights and training code will be open45;sourced.

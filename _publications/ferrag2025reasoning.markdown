---
layout: publication
title: 'Reasoning Beyond Limits: Advances And Open Problems For Llms'
authors: Mohamed Amine Ferrag, Norbert Tihanyi, Merouane Debbah
conference: "Arxiv"
year: 2025
bibkey: ferrag2025reasoning
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2503.22732"}
tags: ['Fine-Tuning', 'Agentic', 'GPT', 'Efficiency and Optimization', 'RAG', 'Model Architecture', 'Reinforcement Learning', 'Training Techniques', 'Pretraining Methods', 'Prompting', 'Distillation']
---
Recent generative reasoning breakthroughs have transformed how large language
models (LLMs) tackle complex problems by dynamically retrieving and refining
information while generating coherent, multi-step thought processes. Techniques
such as inference-time scaling, reinforcement learning, supervised fine-tuning,
and distillation have been successfully applied to models like DeepSeek-R1,
OpenAI's o1 & o3, GPT-4o, Qwen-32B, and various Llama variants, resulting in
enhanced reasoning capabilities. In this paper, we provide a comprehensive
analysis of the top 27 LLM models released between 2023 and 2025 (including
models such as Mistral AI Small 3 24B, DeepSeek-R1, Search-o1, QwQ-32B, and
phi-4). Then, we present an extensive overview of training methodologies that
spans general training approaches, mixture-of-experts (MoE) and architectural
innovations, retrieval-augmented generation (RAG), chain-of-thought and
self-improvement techniques, as well as test-time compute scaling,
distillation, and reinforcement learning (RL) methods. Finally, we discuss the
key challenges in advancing LLM capabilities, including improving multi-step
reasoning without human supervision, overcoming limitations in chained tasks,
balancing structured prompts with flexibility, and enhancing long-context
retrieval and external tool integration.

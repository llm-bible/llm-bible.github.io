---
layout: publication
title: Ms45;uedin Submission To The WMT2018 APE Shared Task Dual45;source Transformer For Automatic Post45;editing
authors: Junczys-dowmunt Marcin, Grundkiewicz Roman
conference: "Arxiv"
year: 2018
bibkey: junczysdowmunt2018ms
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/1809.00188"}
tags: ['Model Architecture', 'Pretraining Methods', 'Training Techniques', 'Transformer']
---
This paper describes the Microsoft and University of Edinburgh submission to the Automatic Post45;editing shared task at WMT2018. Based on training data and systems from the WMT2017 shared task we re45;implement our own models from the last shared task and introduce improvements based on extensive parameter sharing. Next we experiment with our implementation of dual45;source transformer models and data selection for the IT domain. Our submissions decisively wins the SMT post45;editing sub45;task establishing the new state45;of45;the45;art and is a very close second (or equal 16.46 vs 16.50 TER) in the NMT sub45;task. Based on the rather weak results in the NMT sub45;task we hypothesize that neural45;on45;neural APE might not be actually useful.

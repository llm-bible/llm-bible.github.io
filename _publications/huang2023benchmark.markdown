---
layout: publication
title: Trustgpt: A Benchmark For Trustworthy And Responsible Large Language Models
authors: Huang Yue, Zhang Qihui, Y Philip S., Sun Lichao
conference: "Arxiv"
year: 2023
bibkey: huang2023benchmark
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2306.11507"}
tags: ['Attention Mechanism', 'Ethics And Bias', 'GPT', 'Model Architecture', 'Prompting']
---
Large Language Models (LLMs) such as ChatGPT have gained significant attention due to their impressive natural language processing capabilities. It is crucial to prioritize human-centered principles when utilizing these models. Safeguarding the ethical and moral compliance of LLMs is of utmost importance. However individual ethical issues have not been well studied on the latest LLMs. Therefore this study aims to address these gaps by introducing a new benchmark -- TrustGPT. TrustGPT provides a comprehensive evaluation of LLMs in three crucial areas toxicity bias and value-alignment. Initially TrustGPT examines toxicity in language models by employing toxic prompt templates derived from social norms. It then quantifies the extent of bias in models by measuring quantifiable toxicity values across different groups. Lastly TrustGPT assesses the value of conversation generation models from both active value-alignment and passive value-alignment tasks. Through the implementation of TrustGPT this research aims to enhance our understanding of the performance of conversation generation models and promote the development of language models that are more ethical and socially responsible.

---
layout: publication
title: 'From Understanding To Utilization: A Survey On Explainability For Large Language Models'
authors: Luo Haoyan, Specia Lucia
conference: "Arxiv"
year: 2024
bibkey: luo2024from
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.12874"}
tags: ['Applications', 'Ethics And Bias', 'Interpretability And Explainability', 'Model Architecture', 'Pretraining Methods', 'Survey Paper', 'Transformer']
---
Explainability for Large Language Models (LLMs) is a critical yet challenging aspect of natural language processing. As LLMs are increasingly integral to diverse applications their black-box nature sparks significant concerns regarding transparency and ethical use. This survey underscores the imperative for increased explainability in LLMs delving into both the research on explainability and the various methodologies and tasks that utilize an understanding of these models. Our focus is primarily on pre-trained Transformer-based LLMs such as LLaMA family which pose distinctive interpretability challenges due to their scale and complexity. In terms of existing methods we classify them into local and global analyses based on their explanatory objectives. When considering the utilization of explainability we explore several compelling methods that concentrate on model editing control generation and model enhancement. Additionally we examine representative evaluation metrics and datasets elucidating their advantages and limitations. Our goal is to reconcile theoretical and empirical understanding with practical implementation proposing exciting avenues for explanatory techniques and their applications in the LLMs era.

---
layout: publication
title: 'Unveiling The Generalization Power Of Fine-tuned Large Language Models'
authors: Haoran Yang, Yumeng Zhang, Jiaqi Xu, Hongyuan Lu, Pheng Ann Heng, Wai Lam
conference: "Arxiv"
year: 2024
bibkey: yang2024unveiling
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.09162"}
tags: ['Pretraining Methods', 'Training Techniques', 'Fine-Tuning']
---
While Large Language Models (LLMs) have demonstrated exceptional multitasking
abilities, fine-tuning these models on downstream, domain-specific datasets is
often necessary to yield superior performance on test sets compared to their
counterparts without fine-tuning. However, the comprehensive effects of
fine-tuning on the LLMs' generalization ability are not fully understood. This
paper delves into the differences between original, unmodified LLMs and their
fine-tuned variants. Our primary investigation centers on whether fine-tuning
affects the generalization ability intrinsic to LLMs. To elaborate on this, we
conduct extensive experiments across five distinct language tasks on various
datasets. Our main findings reveal that models fine-tuned on generation and
classification tasks exhibit dissimilar behaviors in generalizing to different
domains and tasks. Intriguingly, we observe that integrating the in-context
learning strategy during fine-tuning on generation tasks can enhance the
model's generalization ability. Through this systematic investigation, we aim
to contribute valuable insights into the evolving landscape of fine-tuning
practices for LLMs.

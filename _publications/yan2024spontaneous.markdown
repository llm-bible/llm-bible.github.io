---
layout: publication
title: S^3c45;math Spontaneous Step45;level Self45;correction Makes Large Language Models Better Mathematical Reasoners
authors: Yan Yuchen, Jiang Jin, Liu Yang, Cao Yixin, Xu Xin, Zhang Mengdi, Cai Xunliang, Shao Jian
conference: "Arxiv"
year: 2024
bibkey: yan2024spontaneous
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2409.01524"}
tags: ['Reinforcement Learning', 'Training Techniques']
---
Self45;correction is a novel method that can stimulate the potential reasoning abilities of large language models (LLMs). It involves detecting and correcting errors during the inference process when LLMs solve reasoning problems. However recent works do not regard self45;correction as a spontaneous and intrinsic capability of LLMs. Instead such correction is achieved through post45;hoc generation external knowledge introduction multi45;model collaboration and similar techniques. In this paper we propose a series of mathematical LLMs called S^3c45;Math which are able to perform Spontaneous Step45;level Self45;correction for Mathematical reasoning. This capability helps LLMs to recognize whether their ongoing inference tends to contain errors and simultaneously correct these errors to produce a more reliable response. We proposed a method which employs a step45;level sampling approach to construct step45;wise self45;correction data for achieving such ability. Additionally we implement a training strategy that uses above constructed data to equip LLMs with spontaneous step45;level self45;correction capacities. Our data and methods have been demonstrated to be effective across various foundation LLMs consistently showing significant progress in evaluations on GSM8K MATH and other mathematical benchmarks. To the best of our knowledge we are the first to introduce the spontaneous step45;level self45;correction ability of LLMs in mathematical reasoning.

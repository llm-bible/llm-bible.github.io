---
layout: publication
title: Recursive Visual Attention In Visual Dialog
authors: Niu Yulei, Zhang Hanwang, Zhang Manli, Zhang Jianhong, Lu Zhiwu, Wen Ji-rong
conference: "Arxiv"
year: 2018
bibkey: niu2018recursive
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/1812.02664"}
  - {name: "Code", url: "https://github.com/yuleiniu/rva&#125;"}
tags: ['Agentic', 'Applications', 'Attention Mechanism', 'Has Code', 'Model Architecture', 'Reinforcement Learning', 'Transformer']
---
Visual dialog is a challenging vision45;language task which requires the agent to answer multi45;round questions about an image. It typically needs to address two major problems (1) How to answer visually45;grounded questions which is the core challenge in visual question answering (VQA); (2) How to infer the co45;reference between questions and the dialog history. An example of visual co45;reference is pronouns (eg they) in the question (eg Are they on or off) are linked with nouns (eg lamps) appearing in the dialog history (eg How many lamps are there) and the object grounded in the image. In this work to resolve the visual co45;reference for visual dialog we propose a novel attention mechanism called Recursive Visual Attention (RvA). Specifically our dialog agent browses the dialog history until the agent has sufficient confidence in the visual co45;reference resolution and refines the visual attention recursively. The quantitative and qualitative experimental results on the large45;scale VisDial v0.9 and v1.0 datasets demonstrate that the proposed RvA not only outperforms the state45;of45;the45;art methods but also achieves reasonable recursion and interpretable attention maps without additional annotations. The code is available at url123;https://github.com/yuleiniu/rva&#125;.

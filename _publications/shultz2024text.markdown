---
layout: publication
title: 'Text Understanding In GPT-4 Vs Humans'
authors: Thomas R. Shultz, Jamie M. Wise, Ardavan Salehi Nobandegani
conference: "Arxiv"
year: 2024
bibkey: shultz2024text
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.17196"}
tags: ['Fine-Tuning', 'GPT', 'Model Architecture']
---
We examine whether a leading AI system GPT4 understands text as well as
humans do, first using a well-established standardized test of discourse
comprehension. On this test, GPT4 performs slightly, but not statistically
significantly, better than humans given the very high level of human
performance. Both GPT4 and humans make correct inferences about information
that is not explicitly stated in the text, a critical test of understanding.
Next, we use more difficult passages to determine whether that could allow
larger differences between GPT4 and humans. GPT4 does considerably better on
this more difficult text than do the high school and university students for
whom these the text passages are designed, as admission tests of student
reading comprehension. Deeper exploration of GPT4 performance on material from
one of these admission tests reveals generally accepted signatures of genuine
understanding, namely generalization and inference.

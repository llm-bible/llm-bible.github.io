---
layout: publication
title: Alchemistcoder Harmonizing And Eliciting Code Capability By Hindsight Tuning On Multi45;source Data
authors: Song Zifan, Wang Yudong, Zhang Wenwei, Liu Kuikun, Lyu Chengqi, Song Demin, Guo Qipeng, Yan Hang, Lin Dahua, Chen Kai, Zhao Cairong
conference: "Arxiv"
year: 2024
bibkey: song2024harmonizing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.19265"}
tags: ['Applications', 'Prompting', 'Reinforcement Learning', 'Survey Paper']
---
Open45;source Large Language Models (LLMs) and their specialized variants particularly Code LLMs have recently delivered impressive performance. However previous Code LLMs are typically fine45;tuned on single45;source data with limited quality and diversity which may insufficiently elicit the potential of pre45;trained Code LLMs. In this paper we present AlchemistCoder a series of Code LLMs with enhanced code generation and generalization capabilities fine45;tuned on multi45;source data. To achieve this we pioneer to unveil inherent conflicts among the various styles and qualities in multi45;source code corpora and introduce data45;specific prompts with hindsight relabeling termed AlchemistPrompts to harmonize different data sources and instruction45;response pairs. Additionally we propose incorporating the data construction process into the fine45;tuning data as code comprehension tasks including instruction evolution data filtering and code review. Extensive experiments demonstrate that AlchemistCoder holds a clear lead among all models of the same size (6.7B/7B) and rivals or even surpasses larger models (15B/33B/70B) showcasing the efficacy of our method in refining instruction45;following capabilities and advancing the boundaries of code intelligence.

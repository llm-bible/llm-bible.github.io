---
layout: publication
title: D-NLP At Semeval-2024 Task 2\: Evaluating Clinical Inference Capabilities Of Large Language Models
authors: Altinok Duygu
conference: "Arxiv"
year: 2024
bibkey: altinok2024d
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.04170"}
tags: ['Applications', 'Attention Mechanism', 'Model Architecture', 'Pretraining Methods', 'Reinforcement Learning', 'Responsible AI', 'Transformer']
---
Large language models (LLMs) have garnered significant attention and widespread usage due to their impressive performance in various tasks. However they are not without their own set of challenges including issues such as hallucinations factual inconsistencies and limitations in numerical-quantitative reasoning. Evaluating LLMs in miscellaneous reasoning tasks remains an active area of research. Prior to the breakthrough of LLMs Transformers had already proven successful in the medical domain effectively employed for various natural language understanding (NLU) tasks. Following this trend LLMs have also been trained and utilized in the medical domain raising concerns regarding factual accuracy adherence to safety protocols and inherent limitations. In this paper we focus on evaluating the natural language inference capabilities of popular open-source and closed-source LLMs using clinical trial reports as the dataset. We present the performance results of each LLM and further analyze their performance on a development set particularly focusing on challenging instances that involve medical abbreviations and require numerical-quantitative reasoning. Gemini our leading LLM achieved a test set F1-score of 0.748 securing the ninth position on the task scoreboard. Our work is the first of its kind offering a thorough examination of the inference capabilities of LLMs within the medical domain.

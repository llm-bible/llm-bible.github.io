---
layout: publication
title: Assessing Step45;by45;step Reasoning Against Lexical Negation A Case Study On Syllogism
authors: Ye Mengyu, Kuribayashi Tatsuki, Suzuki Jun, Kobayashi Goro, Funayama Hiroaki
conference: "Arxiv"
year: 2023
bibkey: ye2023assessing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.14868"}
tags: ['Pretraining Methods', 'Prompting']
---
Large language models (LLMs) take advantage of step45;by45;step reasoning instructions e.g. chain45;of45;thought (CoT) prompting. Building on this their ability to perform CoT45;style reasoning robustly is of interest from a probing perspective. In this study we inspect the step45;by45;step reasoning ability of LLMs with a focus on negation which is a core linguistic phenomenon that is difficult to process. In particular we introduce several controlled settings (e.g. reasoning in case of fictional entities) to evaluate the logical reasoning abilities of the models. We observed that dozens of modern LLMs were not robust against lexical negation (e.g. plausible 45;implausible) when performing CoT45;style reasoning and the results highlight unique limitations in each LLM family.

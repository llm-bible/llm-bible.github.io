---
layout: publication
title: 'Fine-tuning Large Language Models For Automated Diagnostic Screening Summaries'
authors: Yadav Manjeet, Sahu Nilesh Kumar, Chaturvedi Mudita, Gupta Snehil, Lone Haroon R
conference: "Arxiv"
year: 2024
bibkey: yadav2024fine
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.20145"}
tags: ['Fine Tuning', 'Pretraining Methods', 'Reinforcement Learning', 'Training Techniques']
---
Improving mental health support in developing countries is a pressing need.
One potential solution is the development of scalable, automated systems to
conduct diagnostic screenings, which could help alleviate the burden on mental
health professionals. In this work, we evaluate several state-of-the-art Large
Language Models (LLMs), with and without fine-tuning, on our custom dataset for
generating concise summaries from mental state examinations. We rigorously
evaluate four different models for summary generation using established ROUGE
metrics and input from human evaluators. The results highlight that our
top-performing fine-tuned model outperforms existing models, achieving ROUGE-1
and ROUGE-L values of 0.810 and 0.764, respectively. Furthermore, we assessed
the fine-tuned model's generalizability on a publicly available D4 dataset, and
the outcomes were promising, indicating its potential applicability beyond our
custom dataset.

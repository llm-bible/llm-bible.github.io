---
layout: publication
title: 'Optimized Biomedical Question-answering Services With LLM And Multi-bert Integration'
authors: Cheng Qian, Xianglong Shi, Shanshan Yao, Yichen Liu, Fengming Zhou, Zishu Zhang, Junaid Akram, Ali Braytee, Ali Anaissi
conference: "Arxiv"
year: 2024
bibkey: qian2024optimized
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2410.12856"}
tags: ['Training Techniques', 'Model Architecture', 'Tools', 'Reinforcement Learning', 'BERT']
---
We present a refined approach to biomedical question-answering (QA) services
by integrating large language models (LLMs) with Multi-BERT configurations. By
enhancing the ability to process and prioritize vast amounts of complex
biomedical data, this system aims to support healthcare professionals in
delivering better patient outcomes and informed decision-making. Through
innovative use of BERT and BioBERT models, combined with a multi-layer
perceptron (MLP) layer, we enable more specialized and efficient responses to
the growing demands of the healthcare sector. Our approach not only addresses
the challenge of overfitting by freezing one BERT model while training another
but also improves the overall adaptability of QA services. The use of extensive
datasets, such as BioASQ and BioMRC, demonstrates the system's ability to
synthesize critical information. This work highlights how advanced language
models can make a tangible difference in healthcare, providing reliable and
responsive tools for professionals to manage complex information, ultimately
serving the broader goal of improved care and data-driven insights.

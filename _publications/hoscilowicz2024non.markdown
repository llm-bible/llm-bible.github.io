---
layout: publication
title: Non45;linear Inference Time Intervention Improving LLM Truthfulness
authors: Hoscilowicz Jakub, Wiacek Adam, Chojnacki Jan, Cieslak Adam, Michon Leszek, Urbanevych Vitalii, Janicki Artur
conference: "Arxiv"
year: 2024
bibkey: hoscilowicz2024non
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.18680"}
tags: ['Attention Mechanism', 'Ethics And Bias', 'Model Architecture', 'Tools']
---
In this work we explore LLMs internal representation space to identify attention heads that contain the most truthful and accurate information. We further developed the Inference Time Intervention (ITI) framework which lets bias LLM without the need for fine45;tuning. The improvement manifests in introducing a non45;linear multi45;token probing and multi45;token intervention Non45;Linear ITI (NL45;ITI) which significantly enhances performance on evaluation benchmarks. NL45;ITI is tested on diverse multiple45;choice datasets including TruthfulQA on which we report over 1637; relative MC1 (accuracy of model pointing to the correct answer) improvement with respect to the baseline ITI results. Moreover we achieved a 1037; relative improvement over the recently released Truth Forest (TrFf) method that also focused on ITI improvement.

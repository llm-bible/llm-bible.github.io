---
layout: publication
title: 'Towards Understanding Retrieval Accuracy And Prompt Quality In RAG Systems'
authors: Shengming Zhao, Yuheng Huang, Jiayang Song, Zhijie Wang, Chengcheng Wan, Lei Ma
conference: "Arxiv"
year: 2024
bibkey: zhao2024towards
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2411.19463"}
tags: ['Fine-Tuning', 'Efficiency and Optimization', 'RAG', 'Reinforcement Learning', 'Prompting']
---
Retrieval-Augmented Generation (RAG) is a pivotal technique for enhancing the
capability of large language models (LLMs) and has demonstrated promising
efficacy across a diverse spectrum of tasks. While LLM-driven RAG systems show
superior performance, they face unique challenges in stability and reliability.
Their complexity hinders developers' efforts to design, maintain, and optimize
effective RAG systems. Therefore, it is crucial to understand how RAG's
performance is impacted by its design. In this work, we conduct an early
exploratory study toward a better understanding of the mechanism of RAG
systems, covering three code datasets, three QA datasets, and two LLMs. We
focus on four design factors: retrieval document type, retrieval recall,
document selection, and prompt techniques. Our study uncovers how each factor
impacts system correctness and confidence, providing valuable insights for
developing an accurate and reliable RAG system. Based on these findings, we
present nine actionable guidelines for detecting defects and optimizing the
performance of RAG systems. We hope our early exploration can inspire further
advancements in engineering, improving and maintaining LLM-driven intelligent
software systems for greater efficiency and reliability.

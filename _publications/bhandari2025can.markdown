---
layout: publication
title: 'Can LLM Agents Maintain A Persona In Discourse?'
authors: Pranav Bhandari, Nicolas Fay, Michael Wise, Amitava Datta, Stephanie Meek, Usman Naseem, Mehwish Nasim
conference: "Arxiv"
year: 2025
bibkey: bhandari2025can
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2502.11843'}
tags: ['Agentic', 'Tools']
---
Large Language Models (LLMs) are widely used as conversational agents,
exploiting their capabilities in various sectors such as education, law,
medicine, and more. However, LLMs are often subjected to context-shifting
behaviour, resulting in a lack of consistent and interpretable
personality-aligned interactions. Adherence to psychological traits lacks
comprehensive analysis, especially in the case of dyadic (pairwise)
conversations. We examine this challenge from two viewpoints, initially using
two conversation agents to generate a discourse on a certain topic with an
assigned personality from the OCEAN framework (Openness, Conscientiousness,
Extraversion, Agreeableness, and Neuroticism) as High/Low for each trait. This
is followed by using multiple judge agents to infer the original traits
assigned to explore prediction consistency, inter-model agreement, and
alignment with the assigned personality. Our findings indicate that while LLMs
can be guided toward personality-driven dialogue, their ability to maintain
personality traits varies significantly depending on the combination of models
and discourse settings. These inconsistencies emphasise the challenges in
achieving stable and interpretable personality-aligned interactions in LLMs.

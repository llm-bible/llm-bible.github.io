---
layout: publication
title: LLM Targeted Underperformance Disproportionately Impacts Vulnerable Users
authors: Poole-dayan Elinor, Roy Deb, Kabbara Jad
conference: "Arxiv"
year: 2024
bibkey: pooledayan2024llm
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.17737"}
tags: ['Ethics And Bias']
---
While state-of-the-art Large Language Models (LLMs) have shown impressive performance on many tasks there has been extensive research on undesirable model behavior such as hallucinations and bias. In this work we investigate how the quality of LLM responses changes in terms of information accuracy truthfulness and refusals depending on three user traits English proficiency education level and country of origin. We present extensive experimentation on three state-of-the-art LLMs and two different datasets targeting truthfulness and factuality. Our findings suggest that undesirable behaviors in state-of-the-art LLMs occur disproportionately more for users with lower English proficiency of lower education status and originating from outside the US rendering these models unreliable sources of information towards their most vulnerable users.

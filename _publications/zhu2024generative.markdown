---
layout: publication
title: Generative Pre45;trained Speech Language Model With Efficient Hierarchical Transformer
authors: Zhu Yongxin, Su Dan, He Liqiang, Xu Linli, Yu Dong
conference: "Arxiv"
year: 2024
bibkey: zhu2024generative
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.00976"}
  - {name: "Code", url: "https://youngsheen.github.io/GPST/demo&#125;"}
tags: ['Has Code', 'Language Modeling', 'Model Architecture', 'Pretraining Methods', 'Prompting', 'Reinforcement Learning', 'Training Techniques', 'Transformer']
---
While recent advancements in speech language models have achieved significant progress they face remarkable challenges in modeling the long acoustic sequences of neural audio codecs. In this paper we introduce textbf123;G125;enerative textbf123;P125;re45;trained textbf123;S125;peech textbf123;T125;ransformer (GPST) a hierarchical transformer designed for efficient speech language modeling. GPST quantizes audio waveforms into two distinct types of discrete speech representations and integrates them within a hierarchical transformer architecture allowing for a unified one45;stage generation process and enhancing Hi45;Res audio generation capabilities. By training on large corpora of speeches in an end45;to45;end unsupervised manner GPST can generate syntactically consistent speech with diverse speaker identities. Given a brief 345;second prompt GPST can produce natural and coherent personalized speech demonstrating in45;context learning abilities. Moreover our approach can be easily extended to spoken cross45;lingual speech generation by incorporating multi45;lingual semantic tokens and universal acoustic tokens. Experimental results indicate that GPST significantly outperforms the existing speech language models in terms of word error rate speech quality and speaker similarity. See url123;https://youngsheen.github.io/GPST/demo&#125; for demo samples.

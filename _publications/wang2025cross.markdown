---
layout: publication
title: 'TPC: Cross-temporal Prediction Connection For Vision-language Model Hallucination Reduction'
authors: Chao Wang, Weiwei Fu, Yang Zhou
conference: "Arxiv"
year: 2025
bibkey: wang2025cross
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2503.04457"}
tags: ['Tools', 'Efficiency and Optimization', 'Applications', 'Language Modeling', 'Security', 'Multimodal Models']
---
Vision-language models (VLMs) have achieved remarkable advancements,
capitalizing on the impressive capabilities of large language models (LLMs)
across diverse tasks. Despite this, a critical challenge known as hallucination
occurs when models overconfidently describe objects or attributes absent from
the image, a problem exacerbated by the tendency of VLMs to rely on linguistic
priors. This limitation reduces model reliability in high-stakes applications.
In this work, we have observed the characteristic of logits' continuity
consistency enhancement and introduced a straightforward and efficient method,
Cross-Temporal Prediction Connection (TPC), designed to enhance the semantic
consistency of logits by connecting them temporally across timesteps. TPC
amplifies information flow and improves coherence, effectively reducing
hallucination. Extensive experiments show that TPC surpasses existing
representatives, delivering superior performance in both accuracy and
efficiency while maintaining robustness in open-ended text generation tasks.

---
layout: publication
title: 'Automatically Suggesting Diverse Example Sentences For L2 Japanese Learners Using Pre-trained Language Models'
authors: Enrico Benedetti, Akiko Aizawa, Florian Boudin
conference: "Arxiv"
year: 2025
bibkey: benedetti2025automatically
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2506.03580"}
tags: ['RAG', 'Model Architecture', 'GPT']
---
Providing example sentences that are diverse and aligned with learners' proficiency levels is essential for fostering effective language acquisition. This study examines the use of Pre-trained Language Models (PLMs) to produce example sentences targeting L2 Japanese learners. We utilize PLMs in two ways: as quality scoring components in a retrieval system that draws from a newly curated corpus of Japanese sentences, and as direct sentence generators using zero-shot learning. We evaluate the quality of sentences by considering multiple aspects such as difficulty, diversity, and naturalness, with a panel of raters consisting of learners of Japanese, native speakers -- and GPT-4. Our findings suggest that there is inherent disagreement among participants on the ratings of sentence qualities, except for difficulty. Despite that, the retrieval approach was preferred by all evaluators, especially for beginner and advanced target proficiency, while the generative approaches received lower scores on average. Even so, our experiments highlight the potential for using PLMs to enhance the adaptability of sentence suggestion systems and therefore improve the language learning journey.

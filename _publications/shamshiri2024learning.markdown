---
layout: publication
title: 'In-context Learning For Long-context Sentiment Analysis On Infrastructure Project Opinions'
authors: Alireza Shamshiri, Kyeong Rok Ryu, June Young Park
conference: "Arxiv"
year: 2024
bibkey: shamshiri2024learning
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2410.11265'}
tags: ['Few-Shot', 'GPT', 'Model Architecture', 'Prompting', 'In-Context Learning']
---
Large language models (LLMs) have achieved impressive results across various
tasks. However, they still struggle with long-context documents. This study
evaluates the performance of three leading LLMs: GPT-4o, Claude 3.5 Sonnet, and
Gemini 1.5 Pro on lengthy, complex, and opinion-varying documents concerning
infrastructure projects, under both zero-shot and few-shot scenarios. Our
results indicate that GPT-4o excels in zero-shot scenarios for simpler, shorter
documents, while Claude 3.5 Sonnet surpasses GPT-4o in handling more complex,
sentiment-fluctuating opinions. In few-shot scenarios, Claude 3.5 Sonnet
outperforms overall, while GPT-4o shows greater stability as the number of
demonstrations increases.

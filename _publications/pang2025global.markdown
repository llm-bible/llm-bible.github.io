---
layout: publication
title: 'Global Position Aware Group Choreography Using Large Language Model'
authors: Haozhou Pang, Tianwei Ding, Lanshan He, Qi Gan
conference: "Arxiv"
year: 2025
bibkey: pang2025global
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2503.09645'}
tags: ['Training Techniques', 'RAG', 'Tokenization', 'Tools']
---
Dance serves as a profound and universal expression of human culture,
conveying emotions and stories through movements synchronized with music.
Although some current works have achieved satisfactory results in the task of
single-person dance generation, the field of multi-person dance generation
remains relatively novel. In this work, we present a group choreography
framework that leverages recent advancements in Large Language Models (LLM) by
modeling the group dance generation problem as a sequence-to-sequence
translation task. Our framework consists of a tokenizer that transforms
continuous features into discrete tokens, and an LLM that is fine-tuned to
predict motion tokens given the audio tokens. We show that by proper
tokenization of input modalities and careful design of the LLM training
strategies, our framework can generate realistic and diverse group dances while
maintaining strong music correlation and dancer-wise consistency. Extensive
experiments and evaluations demonstrate that our framework achieves
state-of-the-art performance.

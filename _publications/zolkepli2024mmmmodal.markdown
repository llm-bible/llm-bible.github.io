---
layout: publication
title: Mmmmodal 45;45; Multi45;images Multi45;audio Multi45;turn Multi45;modal
authors: Zolkepli Husein, Razak Aisyah, Adha Kamarul, Nazhan Ariff
conference: "Arxiv"
year: 2024
bibkey: zolkepli2024mmmmodal
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.11297"}
  - {name: "Code", url: "https://huggingface.co/collections/mesolitica/multimodal&#45;malaysian&#45;llm&#45;65c6f893e03f78fa9e5c8859"}
tags: ['Has Code', 'Multimodal Models', 'RAG']
---
Our contribution introduces a groundbreaking multimodal large language model designed to comprehend multi45;images multi45;audio and multi45;images45;multi45;audio within a single multiturn session. Leveraging state45;of45;the45;art models we utilize the SigLIP encoder for visual inputs and the Whisper Encoder for audio inputs. Notably this multimodal large language model is bilingual proficient in understanding both English and Malay simultaneously. We proudly unveil two versions of this model TinyLlama with 1.1B parameters and Mistral with 7B parameters. With its ability to navigate diverse modalities and languages our model represents a significant advancement for the Malaysian context and beyond. All models released at https://huggingface.co/collections/mesolitica/multimodal&#45;malaysian&#45;llm&#45;65c6f893e03f78fa9e5c8859

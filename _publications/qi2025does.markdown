---
layout: publication
title: 'Does "reasoning" With Large Language Models Improve Recognizing, Generating, And Reframing Unhelpful Thoughts?'
authors: Yilin Qi, Dong Won Lee, Cynthia Breazeal, Hae Won Park
conference: "Arxiv"
year: 2025
bibkey: qi2025does
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2504.00163"}
tags: ['RAG', 'Model Architecture', 'GPT']
---
Cognitive Reframing, a core element of Cognitive Behavioral Therapy (CBT),
helps individuals reinterpret negative experiences by finding positive meaning.
Recent advances in Large Language Models (LLMs) have demonstrated improved
performance through reasoning-based strategies. This inspires a promising
direction of leveraging the reasoning capabilities of LLMs to improve CBT and
mental reframing by simulating the process of critical thinking, potentially
enabling more effective recognition, generation, and reframing of cognitive
distortions. In this work, we investigate the role of various reasoning
methods, including pre-trained reasoning LLMs and augmented reasoning
strategies such as CoT and self-consistency in enhancing LLMs' ability to
perform cognitive reframing tasks. We find that augmented reasoning methods,
even when applied to "outdated" LLMs like GPT-3.5, consistently outperform
state-of-the-art pretrained reasoning models on recognizing, generating and
reframing unhelpful thoughts.

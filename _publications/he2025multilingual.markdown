---
layout: publication
title: 'XCOMPS: A Multilingual Benchmark Of Conceptual Minimal Pairs'
authors: Linyang He, Ercong Nie, Sukru Samet Dindar, Arsalan Firoozi, Adrian Florea, Van Nguyen, Corentin Puffay, Riki Shimizu, Haotian Ye, Jonathan Brennan, Helmut Schmid, Hinrich Sch√ºtze, Nima Mesgarani
conference: "Arxiv"
year: 2025
bibkey: he2025multilingual
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2502.19737'}
tags: ['Prompting', 'Efficiency and Optimization', 'Distillation']
---
We introduce XCOMPS in this work, a multilingual conceptual minimal pair
dataset covering 17 languages. Using this dataset, we evaluate LLMs'
multilingual conceptual understanding through metalinguistic prompting, direct
probability measurement, and neurolinguistic probing. By comparing base,
instruction-tuned, and knowledge-distilled models, we find that: 1) LLMs
exhibit weaker conceptual understanding for low-resource languages, and
accuracy varies across languages despite being tested on the same concept sets.
2) LLMs excel at distinguishing concept-property pairs that are visibly
different but exhibit a marked performance drop when negative pairs share
subtle semantic similarities. 3) Instruction tuning improves performance in
concept understanding but does not enhance internal competence; knowledge
distillation can enhance internal competence in conceptual understanding for
low-resource languages with limited gains in explicit task performance. 4) More
morphologically complex languages yield lower concept understanding scores and
require deeper layers for conceptual reasoning.

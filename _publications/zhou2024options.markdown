---
layout: publication
title: "Qog:question And Options Generation Based On Language Model"
authors: Zhou Jincheng
conference: "Arxiv"
year: 2024
bibkey: zhou2024options
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.12381"}
tags: ['Applications', 'Fine Tuning', 'Pretraining Methods', 'Training Techniques']
---
Question-Options Generation (QOG) is a task that involves generating a set of question-options pairs given context. This task has various applications including fine-tuning large models information retrieval and automated multiple-choice question generation for education. In this paper we develop QOG models using three different methods based on fine-tuning sequence-to-sequence language models (LMs). Experiments demonstrate that the end-to-end QOG model is computationally efficient and stable during both training and inference outperforming other methods. Furthermore our analysis indicates that our QOG models are competitive on the QOG task compared to the large language model Llama 3-8B.

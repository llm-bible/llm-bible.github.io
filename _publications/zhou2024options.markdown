---
layout: publication
title: 'Qog:question And Options Generation Based On Language Model'
authors: Jincheng Zhou
conference: "Arxiv"
year: 2024
bibkey: zhou2024options
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.12381"}
tags: ['Pretraining Methods', 'Training Techniques', 'Applications', 'Fine-Tuning']
---
Question-Options Generation (QOG) is a task that involves generating a set of
question-options pairs given context. This task has various applications,
including fine-tuning large models, information retrieval, and automated
multiple-choice question generation for education. In this paper, we develop
QOG models using three different methods based on fine-tuning
sequence-to-sequence language models (LMs). Experiments demonstrate that the
end-to-end QOG model is computationally efficient and stable during both
training and inference, outperforming other methods. Furthermore, our analysis
indicates that our QOG models are competitive on the QOG task compared to the
large language model Llama 3-8B.

---
layout: publication
title: Comparing Humans GPT45;4 And GPT45;4V On Abstraction And Reasoning Tasks
authors: Mitchell Melanie, Palmarini Alessandro B., Moskvichev Arseny
conference: "Proceedings of the LLM-CP Workshop AAAI"
year: 2023
bibkey: mitchell2023comparing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2311.09247"}
tags: ['GPT', 'Model Architecture', 'Multimodal Models', 'Prompting', 'Reinforcement Learning']
---
We explore the abstract reasoning abilities of text45;only and multimodal versions of GPT45;4 using the ConceptARC benchmark 10 which is designed to evaluate robust understanding and reasoning with core45;knowledge concepts. We extend the work of Moskvichev et al. 10 by evaluating GPT45;4 on more detailed one45;shot prompting (rather than simple zero45;shot prompts) with text versions of ConceptARC tasks and by evaluating GPT45;4V the multimodal version of GPT45;4 on zero45; and one45;shot prompts using image versions of the simplest tasks. Our experimental results support the conclusion that neither version of GPT45;4 has developed robust abstraction abilities at humanlike levels.

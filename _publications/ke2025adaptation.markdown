---
layout: publication
title: 'NAACL2025 Tutorial: Adaptation Of Large Language Models'
authors: Zixuan Ke, Yifei Ming, Shafiq Joty
conference: "Arxiv"
year: 2025
bibkey: ke2025adaptation
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2504.03931'}
tags: ['Attention Mechanism', 'Agentic', 'ACL', 'RAG', 'Tools', 'Model Architecture', 'Applications', 'NAACL', 'Reinforcement Learning']
---
This tutorial on adaptation of LLMs is designed to address the growing demand
for models that go beyond the static capabilities of generic LLMs by providing
an overview of dynamic, domain-specific, and task-adaptive LLM adaptation
techniques. While general LLMs have demonstrated strong generalization across a
variety of tasks, they often struggle to perform well in specialized domains
such as finance, healthcare, and code generation for underrepresented
languages. Additionally, their static nature limits their ability to evolve
with the changing world, and they are often extremely large in size, making
them impractical and costly to deploy at scale. As a result, the adaptation of
LLMs has drawn much attention since the birth of LLMs and is of core
importance, both for industry, which focuses on serving its targeted users, and
academia, which can greatly benefit from small but powerful LLMs. To address
this gap, this tutorial aims to provide an overview of the LLM adaptation
techniques. We start with an introduction to LLM adaptation, from both the data
perspective and the model perspective. We then emphasize how the evaluation
metrics and benchmarks are different from other techniques. After establishing
the problems, we explore various adaptation techniques. We categorize
adaptation techniques into two main families. The first is parametric knowledge
adaptation, which focuses on updating the parametric knowledge within LLMs.
Additionally, we will discuss real-time adaptation techniques, including model
editing, which allows LLMs to be updated dynamically in production
environments. The second kind of adaptation is semi-parametric knowledge
adaptation, where the goal is to update LLM parameters to better leverage
external knowledge or tools through techniques like retrieval-augmented
generation (RAG) and agent-based systems.

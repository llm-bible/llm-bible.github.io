---
layout: publication
title: 'Gender Bias In Large Language Models Across Multiple Languages'
authors: Jinman Zhao, Yitian Ding, Chen Jia, Yining Wang, Zifan Qian
conference: "Arxiv"
year: 2024
bibkey: zhao2024gender
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.00277"}
tags: ['Model Architecture', 'Reinforcement Learning', 'GPT', 'Ethics and Bias', 'Applications']
---
With the growing deployment of large language models (LLMs) across various
applications, assessing the influence of gender biases embedded in LLMs becomes
crucial. The topic of gender bias within the realm of natural language
processing (NLP) has gained considerable focus, particularly in the context of
English. Nonetheless, the investigation of gender bias in languages other than
English is still relatively under-explored and insufficiently analyzed. In this
work, We examine gender bias in LLMs-generated outputs for different languages.
We use three measurements: 1) gender bias in selecting descriptive words given
the gender-related context. 2) gender bias in selecting gender-related pronouns
(she/he) given the descriptive words. 3) gender bias in the topics of
LLM-generated dialogues. We investigate the outputs of the GPT series of LLMs
in various languages using our three measurement methods. Our findings revealed
significant gender biases across all the languages we examined.

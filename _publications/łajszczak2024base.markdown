---
layout: publication
title: BASE TTS Lessons From Building A Billion45;parameter Text45;to45;speech Model On 100K Hours Of Data
authors: Łajszczak Mateusz, Cámbara Guillermo, Li Yang, Beyhan Fatih, Van Korlaar Arent, Yang Fan, Joly Arnaud, Martín-cortinas Álvaro, Abbas Ammar, Michalski Adam, Moinet Alexis, Karlapati Sri, Muszyńska Ewa, Guo Haohan, Putrycz Bartosz, Gambino Soledad López, Yoo Kayeon, Sokolova Elena, Drugman Thomas
conference: "Arxiv"
year: 2024
bibkey: łajszczak2024base
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.08093"}
  - {name: "Code", url: "https://amazon&#45;ltts&#45;paper.com/"}
tags: ['GPT', 'Has Code', 'Model Architecture', 'Pretraining Methods', 'Tokenization', 'Transformer']
---
We introduce a text45;to45;speech (TTS) model called BASE TTS which stands for textbf123;B125;ig textbf123;A125;daptive textbf123;S125;treamable TTS with textbf123;E125;mergent abilities. BASE TTS is the largest TTS model to45;date trained on 100K hours of public domain speech data achieving a new state45;of45;the45;art in speech naturalness. It deploys a 145;billion45;parameter autoregressive Transformer that converts raw texts into discrete codes (speechcodes) followed by a convolution45;based decoder which converts these speechcodes into waveforms in an incremental streamable manner. Further our speechcodes are built using a novel speech tokenization technique that features speaker ID disentanglement and compression with byte45;pair encoding. Echoing the widely45;reported emergent abilities of large language models when trained on increasing volume of data we show that BASE TTS variants built with 10K+ hours and 500M+ parameters begin to demonstrate natural prosody on textually complex sentences. We design and share a specialized dataset to measure these emergent abilities for text45;to45;speech. We showcase state45;of45;the45;art naturalness of BASE TTS by evaluating against baselines that include publicly available large45;scale text45;to45;speech systems YourTTS Bark and TortoiseTTS. Audio samples generated by the model can be heard at https://amazon&#45;ltts&#45;paper.com/.

---
layout: publication
title: Radiology-gpt: A Large Language Model For Radiology
authors: Liu Zhengliang, Zhong Aoxiao, Li Yiwei, Yang Longtao, Ju Chao, Wu Zihao, Ma Chong, Shu Peng, Chen Cheng, Kim Sekeun, Dai Haixing, Zhao Lin, Sun Lichao, Zhu Dajiang, Liu Jun, Liu Wei, Shen Dinggang, Li Xiang, Li Quanzheng, Liu Tianming
conference: "Arxiv"
year: 2023
bibkey: liu2023radiology
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2306.08666"}
tags: ['GPT', 'Merging', 'Model Architecture', 'Pretraining Methods']
---
We introduce Radiology-GPT a large language model for radiology. Using an instruction tuning approach on an extensive dataset of radiology domain knowledge Radiology-GPT demonstrates superior performance compared to general language models such as StableLM Dolly and LLaMA. It exhibits significant versatility in radiological diagnosis research and communication. This work serves as a catalyst for future developments in clinical NLP. The successful implementation of Radiology-GPT is indicative of the potential of localizing generative large language models specifically tailored for distinctive medical specialties while ensuring adherence to privacy standards such as HIPAA. The prospect of developing individualized large-scale language models that cater to specific needs of various hospitals presents a promising direction. The fusion of conversational competence and domain-specific knowledge in these models is set to foster future development in healthcare AI. A demo of Radiology-GPT is available at https://huggingface.co/spaces/allen-eric/radiology-gpt."

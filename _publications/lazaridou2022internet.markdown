---
layout: publication
title: Internet45;augmented Language Models Through Few45;shot Prompting For Open45;domain Question Answering
authors: Lazaridou Angeliki, Gribovskaya Elena, Stokowiec Wojciech, Grigorev Nikolai
conference: "Arxiv"
year: 2022
bibkey: lazaridou2022internet
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2203.05115"}
tags: ['Applications', 'Attention Mechanism', 'Model Architecture', 'Prompting', 'Tools']
---
In this work we aim to capitalize on the unique few45;shot capabilities of large45;scale language models (LSLMs) to overcome some of their challenges with respect to grounding to factual and up45;to45;date information. Motivated by semi45;parametric language models (LMs) which ground their decisions in external retrieved evidence we use few45;shot prompting to learn to condition LMs on information returned from the web using Google Search a broad and constantly updated knowledge source. Our approach does not involve fine45;tuning or learning additional parameters thus making it applicable to any LM offering therefore a strong baseline. Indeed we find that LMs conditioned on the web surpass performance of closed45;book models of similar or even larger model sizes in open45;domain question answering. Finally we find that increasing the inference45;time compute of models achieved via using multiple retrieved evidences to generate multiple answers followed by a reranking stage that uses scores generated by the same LMs leads to better performance and alleviates lower performance of smaller few45;shot LMs. All in all our findings suggest that it might be beneficial to slow down the race towards the biggest model and instead shift attention towards finding more effective ways to use models including but not limited to better prompting or increasing inference45;time compute.

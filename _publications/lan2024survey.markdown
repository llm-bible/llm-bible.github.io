---
layout: publication
title: 'A Survey Of Hallucination In Large Visual Language Models'
authors: Wei Lan, Wenyi Chen, Qingfeng Chen, Shirui Pan, Huiyu Zhou, Yi Pan
conference: "Arxiv"
year: 2024
bibkey: lan2024survey
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2410.15359"}
tags: ['Survey Paper']
---
The Large Visual Language Models (LVLMs) enhances user interaction and
enriches user experience by integrating visual modality on the basis of the
Large Language Models (LLMs). It has demonstrated their powerful information
processing and generation capabilities. However, the existence of
hallucinations has limited the potential and practical effectiveness of LVLM in
various fields. Although lots of work has been devoted to the issue of
hallucination mitigation and correction, there are few reviews to summary this
issue. In this survey, we first introduce the background of LVLMs and
hallucinations. Then, the structure of LVLMs and main causes of hallucination
generation are introduced. Further, we summary recent works on hallucination
correction and mitigation. In addition, the available hallucination evaluation
benchmarks for LVLMs are presented from judgmental and generative perspectives.
Finally, we suggest some future research directions to enhance the
dependability and utility of LVLMs.

---
layout: publication
title: MIMIR A Streamlined Platform For Personalized Agent Tuning In Domain Expertise
authors: Deng Chunyuan, Tang Xiangru, Zhao Yilun, Wang Hanming, Wang Haoran, Zhou Wangchunshu, Cohan Arman, Gerstein Mark
conference: "Arxiv"
year: 2024
bibkey: deng2024streamlined
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.04285"}
tags: ['Agentic', 'Applications', 'Efficiency And Optimization', 'GPT', 'Model Architecture', 'RAG', 'Reinforcement Learning', 'Tools']
---
Recently large language models (LLMs) have evolved into interactive agents proficient in planning tool use and task execution across a wide variety of tasks. However without specific agent tuning open45;source models like LLaMA currently struggle to match the efficiency of GPT45; 4 particularly given the scarcity of agent45;tuning datasets for fine45;tuning. In response we introduce textsc123;Mimir125; a streamlined platform offering a customizable pipeline that enables users to leverage both private knowledge and publicly available legally compliant datasets at scale for textbf123;personalized agent tuning125;. Additionally textsc123;Mimir125; supports the generation of general instruction45;tuning datasets from the same input. This dual capability ensures that language agents developed through the platform possess both specific agent abilities and general competencies. textsc123;Mimir125; integrates these features into a cohesive end45;to45;end platform facilitating everything from the uploading of personalized files to one45;click agent fine45;tuning.

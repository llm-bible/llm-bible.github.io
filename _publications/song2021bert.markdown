---
layout: publication
title: Bob BERT Over BERT For Training Persona45;based Dialogue Models From Limited Personalized Data
authors: Song Haoyu, Wang Yan, Zhang Kaiyan, Zhang Wei-nan, Liu Ting
conference: "Arxiv"
year: 2021
bibkey: song2021bert
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2106.06169"}
tags: ['Agentic', 'Applications', 'BERT', 'Model Architecture', 'Training Techniques']
---
Maintaining consistent personas is essential for dialogue agents. Although tremendous advancements have been brought the limited45;scale of annotated persona45;dense data are still barriers towards training robust and consistent persona45;based dialogue models. In this work we show how the challenges can be addressed by disentangling persona45;based dialogue generation into two sub45;tasks with a novel BERT45;over45;BERT (BoB) model. Specifically the model consists of a BERT45;based encoder and two BERT45;based decoders where one decoder is for response generation and another is for consistency understanding. In particular to learn the ability of consistency understanding from large45;scale non45;dialogue inference data we train the second decoder in an unlikelihood manner. Under different limited data settings both automatic and human evaluations demonstrate that the proposed model outperforms strong baselines in response quality and persona consistency.

---
layout: publication
title: 'Chatgpt Vs. Deepseek: A Comparative Study On Ai-based Code Generation'
authors: Md Motaleb Hossen Manik
conference: "Arxiv"
year: 2025
bibkey: manik2025chatgpt
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.18467"}
tags: ['Efficiency and Optimization', 'Model Architecture', 'Reinforcement Learning', 'RAG', 'GPT', 'Applications']
---
Background: AI-powered code generation, fueled by Large Language Models
(LLMs), is revolutionizing software development. Models like OpenAI's Codex and
GPT-4, alongside DeepSeek, leverage vast code and natural language datasets.
However, ensuring code quality, correctness, and managing complex tasks remains
challenging, necessitating thorough evaluation. Methodology: This research
compares ChatGPT (version o1) and DeepSeek (version R1) for Python code
generation using online judge coding challenges. It evaluates correctness
(online judge verdicts, up to three attempts), code quality (Pylint/Flake8),
and efficiency (execution time/memory usage). Results: DeepSeek demonstrated
higher correctness, particularly on algorithmic tasks, often achieving
'Accepted' on the first attempt. ChatGPT sometimes requires multiple attempts
or failures. ChatGPT encountered fewer issues, used comparable or slightly less
memory, consumed less execution times and wrote fewer lines of code.
Conclusion: DeepSeek exhibited superior correctness in Python code generation,
often requiring fewer attempts, suggesting an advantage in algorithmic
problem-solving. Both models showed almost similar efficiency in execution time
and memory use. Finally, this research provides insights for developers
choosing AI coding assistants and informs future AI-driven software development
research.

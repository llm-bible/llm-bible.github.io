---
layout: publication
title: 'AI Persuading AI Vs AI Persuading Humans: Llms'' Differential Effectiveness In Promoting Pro-environmental Behavior'
authors: Alexander Doudkin, Pat Pataranutaporn, Pattie Maes
conference: "Arxiv"
year: 2025
bibkey: doudkin2025ai
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2503.02067"}
tags: ['Agentic', 'Tools', 'Reinforcement Learning']
---
Pro-environmental behavior (PEB) is vital to combat climate change, yet
turning awareness into intention and action remains elusive. We explore large
language models (LLMs) as tools to promote PEB, comparing their impact across
3,200 participants: real humans (n=1,200), simulated humans based on actual
participant data (n=1,200), and fully synthetic personas (n=1,200). All three
participant groups faced personalized or standard chatbots, or static
statements, employing four persuasion strategies (moral foundations, future
self-continuity, action orientation, or "freestyle" chosen by the LLM). Results
reveal a "synthetic persuasion paradox": synthetic and simulated agents
significantly affect their post-intervention PEB stance, while human responses
barely shift. Simulated participants better approximate human trends but still
overestimate effects. This disconnect underscores LLM's potential for
pre-evaluating PEB interventions but warns of its limits in predicting
real-world behavior. We call for refined synthetic modeling and sustained and
extended human trials to align conversational AI's promise with tangible
sustainability outcomes.

---
layout: publication
title: 'Zero-shot Large Language Models For Long Clinical Text Summarization With Temporal Reasoning'
authors: Maya Kruse, Shiyue Hu, Nicholas Derby, Yifu Wu, Samantha Stonbraker, Bingsheng Yao, Dakuo Wang, Elizabeth Goldberg, Yanjun Gao
conference: "Arxiv"
year: 2025
bibkey: kruse2025zero
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2501.18724"}
tags: ['Training Techniques', 'Applications', 'Reinforcement Learning']
---
Recent advancements in large language models (LLMs) have shown potential for
transforming data processing in healthcare, particularly in understanding
complex clinical narratives. This study evaluates the efficacy of zero-shot
LLMs in summarizing long clinical texts that require temporal reasoning, a
critical aspect for comprehensively capturing patient histories and treatment
trajectories. We applied a series of advanced zero-shot LLMs to extensive
clinical documents, assessing their ability to integrate and accurately reflect
temporal dynamics without prior task-specific training. While the models
efficiently identified key temporal events, they struggled with chronological
coherence over prolonged narratives. The evaluation, combining quantitative and
qualitative methods, highlights the strengths and limitations of zero-shot LLMs
in clinical text summarization. The results suggest that while promising,
zero-shot LLMs require further refinement to effectively support clinical
decision-making processes, underscoring the need for enhanced model training
approaches that better capture the nuances of temporal information in long
context medical documents.

---
layout: publication
title: 'The Turing Deception'
authors: Noever David, Ciolino Matt
conference: "Arxiv"
year: 2022
bibkey: noever2022turing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2212.06721"}
tags: ['Applications', 'GPT', 'Language Modeling', 'Model Architecture', 'Prompting']
---
This research revisits the classic Turing test and compares recent large
language models such as ChatGPT for their abilities to reproduce human-level
comprehension and compelling text generation. Two task challenges --
summarization, and question answering -- prompt ChatGPT to produce original
content (98-99%) from a single text entry and also sequential questions
originally posed by Turing in 1950. We score the original and generated content
against the OpenAI GPT-2 Output Detector from 2019, and establish multiple
cases where the generated content proves original and undetectable (98%). The
question of a machine fooling a human judge recedes in this work relative to
the question of "how would one prove it?" The original contribution of the work
presents a metric and simple grammatical set for understanding the writing
mechanics of chatbots in evaluating their readability and statistical clarity,
engagement, delivery, and overall quality. While Turing's original prose scores
at least 14% below the machine-generated output, the question of whether an
algorithm displays hints of Turing's truly original thoughts (the "Lovelace
2.0" test) remains unanswered and potentially unanswerable for now.

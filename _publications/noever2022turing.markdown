---
layout: publication
title: The Turing Deception
authors: Noever David, Ciolino Matt
conference: "Arxiv"
year: 2022
bibkey: noever2022turing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2212.06721"}
tags: ['Applications', 'GPT', 'Language Modeling', 'Model Architecture', 'Prompting']
---
This research revisits the classic Turing test and compares recent large language models such as ChatGPT for their abilities to reproduce human45;level comprehension and compelling text generation. Two task challenges 45;45; summarization and question answering 45;45; prompt ChatGPT to produce original content (9845;9937;) from a single text entry and also sequential questions originally posed by Turing in 1950. We score the original and generated content against the OpenAI GPT45;2 Output Detector from 2019 and establish multiple cases where the generated content proves original and undetectable (9837;). The question of a machine fooling a human judge recedes in this work relative to the question of how would one prove it The original contribution of the work presents a metric and simple grammatical set for understanding the writing mechanics of chatbots in evaluating their readability and statistical clarity engagement delivery and overall quality. While Turings original prose scores at least 1437; below the machine45;generated output the question of whether an algorithm displays hints of Turings truly original thoughts (the Lovelace 2.0 test) remains unanswered and potentially unanswerable for now.

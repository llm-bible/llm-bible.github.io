---
layout: publication
title: 'SOK: Exploring Hallucinations And Security Risks In Ai-assisted Software Development With Insights For LLM Deployment'
authors: Ariful Haque, Sunzida Siddique, Md. Mahfuzur Rahman, Ahmed Rafi Hasan, Laxmi Rani Das, Marufa Kamal, Tasnim Masura, Kishor Datta Gupta
conference: "Arxiv"
year: 2025
bibkey: haque2025exploring
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.18468"}
tags: ['Tools', 'GPT', 'Applications', 'Ethics and Bias', 'Model Architecture', 'Reinforcement Learning', 'Security']
---
The integration of Large Language Models (LLMs) such as GitHub Copilot,
ChatGPT, Cursor AI, and Codeium AI into software development has revolutionized
the coding landscape, offering significant productivity gains, automation, and
enhanced debugging capabilities. These tools have proven invaluable for
generating code snippets, refactoring existing code, and providing real-time
support to developers. However, their widespread adoption also presents notable
challenges, particularly in terms of security vulnerabilities, code quality,
and ethical concerns. This paper provides a comprehensive analysis of the
benefits and risks associated with AI-powered coding tools, drawing on user
feedback, security analyses, and practical use cases. We explore the potential
for these tools to replicate insecure coding practices, introduce biases, and
generate incorrect or non-sensical code (hallucinations). In addition, we
discuss the risks of data leaks, intellectual property violations and the need
for robust security measures to mitigate these threats. By comparing the
features and performance of these tools, we aim to guide developers in making
informed decisions about their use, ensuring that the benefits of AI-assisted
coding are maximized while minimizing associated risks.

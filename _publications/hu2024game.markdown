---
layout: publication
title: 'Game Generation Via Large Language Models'
authors: Hu Chengpeng, Zhao Yunlong, Liu Jialin
conference: "Arxiv"
year: 2024
bibkey: hu2024game
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.08706"}
tags: ['Applications', 'Prompting', 'Reinforcement Learning', 'Tools', 'Uncategorized']
---
Recently, the emergence of large language models (LLMs) has unlocked new opportunities for procedural content generation. However, recent attempts mainly focus on level generation for specific games with defined game rules such as Super Mario Bros. and Zelda. This paper investigates the game generation via LLMs. Based on video game description language, this paper proposes an LLM-based framework to generate game rules and levels simultaneously. Experiments demonstrate how the framework works with prompts considering different combinations of context. Our findings extend the current applications of LLMs and offer new insights for generating new games in the area of procedural content generation.

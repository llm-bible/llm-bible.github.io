---
layout: publication
title: 'Game Generation Via Large Language Models'
authors: Chengpeng Hu, Yunlong Zhao, Jialin Liu
conference: "Arxiv"
year: 2024
bibkey: hu2024game
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.08706"}
tags: ['Prompting', 'Applications', 'Tools', 'Reinforcement Learning']
---
Recently, the emergence of large language models (LLMs) has unlocked new
opportunities for procedural content generation. However, recent attempts
mainly focus on level generation for specific games with defined game rules
such as Super Mario Bros. and Zelda. This paper investigates the game
generation via LLMs. Based on video game description language, this paper
proposes an LLM-based framework to generate game rules and levels
simultaneously. Experiments demonstrate how the framework works with prompts
considering different combinations of context. Our findings extend the current
applications of LLMs and offer new insights for generating new games in the
area of procedural content generation.

---
layout: publication
title: Coquest Exploring Research Question Co-creation With An Llm-based Agent
authors: Liu Yiren, Chen Si, Cheng Haocong, Yu Mengxia, Ran Xiao, Mo Andrew, Tang Yiliu, Huang Yun
conference: "Arxiv"
year: 2023
bibkey: liu2023coquest
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.06155"}
tags: ['Agentic', 'Ethics And Bias', 'RAG', 'Reinforcement Learning']
---
Developing novel research questions (RQs) often requires extensive literature reviews especially in interdisciplinary fields. To support RQ development through human-AI co-creation we leveraged Large Language Models (LLMs) to build an LLM-based agent system named CoQuest. We conducted an experiment with 20 HCI researchers to examine the impact of two interaction designs breadth-first and depth-first RQ generation. The findings revealed that participants perceived the breadth-first approach as more creative and trustworthy upon task completion. Conversely during the task participants considered the depth-first generated RQs as more creative. Additionally we discovered that AI processing delays allowed users to reflect on multiple RQs simultaneously leading to a higher quantity of generated RQs and an enhanced sense of control. Our work makes both theoretical and practical contributions by proposing and evaluating a mental model for human-AI co-creation of RQs. We also address potential ethical issues such as biases and over-reliance on AI advocating for using the system to improve human research creativity rather than automating scientific inquiry.

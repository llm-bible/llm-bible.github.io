---
layout: publication
title: 'Ask-before-detection: Identifying And Mitigating Conformity Bias In Llm-powered Error Detector For Math Word Problem Solutions'
authors: Hang Li, Tianlong Xu, Kaiqi Yang, Yucheng Chu, Yanling Chen, Yichi Song, Qingsong Wen, Hui Liu
conference: "Arxiv"
year: 2024
bibkey: li2024ask
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2412.16838"}
tags: ['Tools', 'Prompting', 'Ethics and Bias', 'Reinforcement Learning']
---
The rise of large language models (LLMs) offers new opportunities for
automatic error detection in education, particularly for math word problems
(MWPs). While prior studies demonstrate the promise of LLMs as error detectors,
they overlook the presence of multiple valid solutions for a single MWP. Our
preliminary analysis reveals a significant performance gap between conventional
and alternative solutions in MWPs, a phenomenon we term conformity bias in this
work. To mitigate this bias, we introduce the Ask-Before-Detect (AskBD)
framework, which generates adaptive reference solutions using LLMs to enhance
error detection. Experiments on 200 examples of GSM8K show that AskBD
effectively mitigates bias and improves performance, especially when combined
with reasoning-enhancing techniques like chain-of-thought prompting.

---
layout: publication
title: 'VALTEST: Automated Validation Of Language Model Generated Test Cases'
authors: Hamed Taherkhani, Hadi Hemmati
conference: "Arxiv"
year: 2024
bibkey: taherkhani2024automated
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2411.08254"}
tags: ['Tools', 'GPT', 'RAG', 'Model Architecture', 'Reinforcement Learning', 'Prompting']
---
Large Language Models (LLMs) have demonstrated significant potential in
automating software testing, specifically in generating unit test cases.
However, the validation of LLM-generated test cases remains a challenge,
particularly when the ground truth is unavailable. This paper introduces
VALTEST, a novel framework designed to automatically validate test cases
generated by LLMs by leveraging token probabilities. We evaluate VALTEST using
nine test suites generated from three datasets (HumanEval, MBPP, and LeetCode)
across three LLMs (GPT-4o, GPT-3.5-turbo, and LLama3.1 8b). By extracting
statistical features from token probabilities, we train a machine learning
model to predict test case validity. VALTEST increases the validity rate of
test cases by 6.2% to 24%, depending on the dataset and LLM. Our results
suggest that token probabilities are reliable indicators for distinguishing
between valid and invalid test cases, which provides a robust solution for
improving the correctness of LLM-generated test cases in software testing. In
addition, we found that replacing the identified invalid test cases by VALTEST,
using a Chain-of-Thought prompting results in a more effective test suite while
keeping the high validity rates.

---
layout: publication
title: 'Advancing Explainability In Neural Machine Translation: Analytical Metrics For Attention And Alignment Consistency'
authors: Anurag Mishra
conference: "Arxiv"
year: 2024
bibkey: mishra2024advancing
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2412.18669'}
tags: ['Attention Mechanism', 'Interpretability and Explainability', 'Transformer', 'WMT', 'Model Architecture', 'Tools', 'Applications', 'Interpretability']
---
Neural Machine Translation (NMT) models have shown remarkable performance but
remain largely opaque in their decision making processes. The interpretability
of these models, especially their internal attention mechanisms, is critical
for building trust and verifying that these systems behave as intended. In this
work, we introduce a systematic framework to quantitatively evaluate the
explainability of an NMT model attention patterns by comparing them against
statistical alignments and correlating them with standard machine translation
quality metrics. We present a set of metrics attention entropy and alignment
agreement and validate them on an English-German test subset from WMT14 using a
pre trained mT5 model. Our results indicate that sharper attention
distributions correlate with improved interpretability but do not always
guarantee better translation quality. These findings advance our understanding
of NMT explainability and guide future efforts toward building more transparent
and reliable machine translation systems.

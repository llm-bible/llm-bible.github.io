---
layout: publication
title: Lmsys45;chat45;1m A Large45;scale Real45;world LLM Conversation Dataset
authors: Zheng Lianmin, Chiang Wei-lin, Sheng Ying, Li Tianle, Zhuang Siyuan, Wu Zhanghao, Zhuang Yonghao, Li Zhuohan, Lin Zi, Xing Eric P., Gonzalez Joseph E., Stoica Ion, Zhang Hao
conference: "Arxiv"
year: 2023
bibkey: zheng2023lmsys
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.11998"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Pretraining Methods', 'Reinforcement Learning', 'Responsible AI', 'Tools', 'Training Techniques']
---
Studying how people interact with large language models (LLMs) in real45;world scenarios is increasingly important due to their widespread use in various applications. In this paper we introduce LMSYS45;Chat45;1M a large45;scale dataset containing one million real45;world conversations with 25 state45;of45;the45;art LLMs. This dataset is collected from 210K unique IP addresses in the wild on our Vicuna demo and Chatbot Arena website. We offer an overview of the datasets content including its curation process basic statistics and topic distribution highlighting its diversity originality and scale. We demonstrate its versatility through four use cases developing content moderation models that perform similarly to GPT45;4 building a safety benchmark training instruction45;following models that perform similarly to Vicuna and creating challenging benchmark questions. We believe that this dataset will serve as a valuable resource for understanding and advancing LLM capabilities. The dataset is publicly available at https://huggingface.co/datasets/lmsys/lmsys&#45;chat&#45;1m.

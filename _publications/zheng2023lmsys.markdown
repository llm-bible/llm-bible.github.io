---
layout: publication
title: 'Lmsys-chat-1m: A Large-scale Real-world LLM Conversation Dataset'
authors: Zheng Lianmin, Chiang Wei-lin, Sheng Ying, Li Tianle, Zhuang Siyuan, Wu Zhanghao, Zhuang Yonghao, Li Zhuohan, Lin Zi, Xing Eric P., Gonzalez Joseph E., Stoica Ion, Zhang Hao
conference: "Arxiv"
year: 2023
bibkey: zheng2023lmsys
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.11998"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Reinforcement Learning', 'Responsible AI', 'Tools', 'Training Techniques', 'Uncategorized']
---
Studying how people interact with large language models (LLMs) in real-world scenarios is increasingly important due to their widespread use in various applications. In this paper, we introduce LMSYS-Chat-1M, a large-scale dataset containing one million real-world conversations with 25 state-of-the-art LLMs. This dataset is collected from 210K unique IP addresses in the wild on our Vicuna demo and Chatbot Arena website. We offer an overview of the dataset's content, including its curation process, basic statistics, and topic distribution, highlighting its diversity, originality, and scale. We demonstrate its versatility through four use cases: developing content moderation models that perform similarly to GPT-4, building a safety benchmark, training instruction-following models that perform similarly to Vicuna, and creating challenging benchmark questions. We believe that this dataset will serve as a valuable resource for understanding and advancing LLM capabilities. The dataset is publicly available at https://huggingface.co/datasets/lmsys/lmsys-chat-1m.

---
layout: publication
title: 'Enhancing Recommender Systems Using Textual Embeddings From Pre-trained Language Models'
authors: Ngoc Luyen Heudiasyc Le, Marie-hélène Heudiasyc Abel
conference: "The 8th International Conference on Information Technology Systems Jan 2025 Mexico City Mexico"
year: 2025
bibkey: le2025enhancing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2504.08746"}
tags: ['RecSys', 'BERT', 'Model Architecture']
---
Recent advancements in language models and pre-trained language models like
BERT and RoBERTa have revolutionized natural language processing, enabling a
deeper understanding of human-like language. In this paper, we explore
enhancing recommender systems using textual embeddings from pre-trained
language models to address the limitations of traditional recommender systems
that rely solely on explicit features from users, items, and user-item
interactions. By transforming structured data into natural language
representations, we generate high-dimensional embeddings that capture deeper
semantic relationships between users, items, and contexts. Our experiments
demonstrate that this approach significantly improves recommendation accuracy
and relevance, resulting in more personalized and context-aware
recommendations. The findings underscore the potential of PLMs to enhance the
effectiveness of recommender systems.

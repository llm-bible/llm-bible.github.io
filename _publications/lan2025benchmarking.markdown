---
layout: publication
title: 'Benchmarking And Advancing Large Language Models For Local Life Services'
authors: Xiaochong Lan, Jie Feng, Jiahuan Lei, Xinlei Shi, Yong Li
conference: "Arxiv"
year: 2025
bibkey: lan2025benchmarking
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2506.02720"}
tags: ['Fine-Tuning', 'Agentic', 'Efficiency and Optimization', 'Applications', 'Reinforcement Learning', 'Training Techniques', 'Pretraining Methods']
---
Large language models (LLMs) have exhibited remarkable capabilities and achieved significant breakthroughs across various domains, leading to their widespread adoption in recent years. Building on this progress, we investigate their potential in the realm of local life services. In this study, we establish a comprehensive benchmark and systematically evaluate the performance of diverse LLMs across a wide range of tasks relevant to local life services. To further enhance their effectiveness, we explore two key approaches: model fine-tuning and agent-based workflows. Our findings reveal that even a relatively compact 7B model can attain performance levels comparable to a much larger 72B model, effectively balancing inference cost and model capability. This optimization greatly enhances the feasibility and efficiency of deploying LLMs in real-world online services, making them more practical and accessible for local life applications.

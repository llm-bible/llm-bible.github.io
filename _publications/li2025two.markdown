---
layout: publication
title: 'Two Heads Are Better Than One: Dual-model Verbal Reflection At Inference-time'
authors: Jiazheng Li, Yuxiang Zhou, Junru Lu, Gladys Tyen, Lin Gui, Cesare Aloisi, Yulan He
conference: "Arxiv"
year: 2025
bibkey: li2025two
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2502.19230'}
tags: ['Agentic', 'Interpretability and Explainability', 'Efficiency and Optimization', 'Training Techniques', 'Tools', 'Reinforcement Learning', 'Ethics and Bias', 'Interpretability']
---
Large Language Models (LLMs) often struggle with complex reasoning scenarios.
While preference optimization methods enhance reasoning performance through
training, they often lack transparency in why one reasoning outcome is
preferred over another. Verbal reflection techniques improve explainability but
are limited in LLMs' critique and refinement capacity. To address these
challenges, we introduce a contrastive reflection synthesis pipeline that
enhances the accuracy and depth of LLM-generated reflections. We further
propose a dual-model reasoning framework within a verbal reinforcement learning
paradigm, decoupling inference-time self-reflection into specialized, trained
models for reasoning critique and refinement. Extensive experiments show that
our framework outperforms traditional preference optimization methods across
all evaluation metrics. Our findings also show that "two heads are better than
one", demonstrating that a collaborative Reasoner-Critic model achieves
superior reasoning performance and transparency, compared to single-model
approaches.

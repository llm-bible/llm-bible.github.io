---
layout: publication
title: Learning Non45;linguistic Skills Without Sacrificing Linguistic Proficiency
authors: Sharma Mandar, Muralidhar Nikhil, Ramakrishnan Naren
conference: "Arxiv"
year: 2023
bibkey: sharma2023learning
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2305.08246"}
tags: ['Reinforcement Learning', 'Tools', 'Training Techniques']
---
The field of Math45;NLP has witnessed significant growth in recent years motivated by the desire to expand LLM performance to the learning of non45;linguistic notions (numerals and subsequently arithmetic reasoning). However non45;linguistic skill injection typically comes at a cost for LLMs it leads to catastrophic forgetting of core linguistic skills a consequence that often remains unaddressed in the literature. As Math45;NLP has been able to create LLMs that can closely approximate the mathematical skills of a grade45;schooler or the arithmetic reasoning skills of a calculator the practicality of these models fail if they concomitantly shed their linguistic capabilities. In this work we take a closer look into the phenomena of catastrophic forgetting as it pertains to LLMs and subsequently offer a novel framework for non45;linguistic skill injection for LLMs based on information theoretic interventions and skill45;specific losses that enable the learning of strict arithmetic reasoning. Our model outperforms the state45;of45;the45;art both on injected non45;linguistic skills and on linguistic knowledge retention and does so with a fraction of the non45;linguistic training data (1/4) and zero additional synthetic linguistic training data.

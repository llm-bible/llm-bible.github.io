---
layout: publication
title: Active Example Selection For In45;context Learning
authors: Yiming Zhang, Shi Feng, Chenhao Tan
conference: "Arxiv"
year: 2022
bibkey: zhang2022active
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/http://arxiv.org/abs/2211.04486v1"}
tags: ['Agentic', 'GPT', 'Merging', 'Model Architecture', 'RAG', 'Reinforcement Learning', 'Training Techniques']
---
With a handful of demonstration examples large45;scale language models show strong capability to perform various tasks by in45;context learning from these examples without any fine45;tuning. We demonstrate that in45;context learning performance can be highly unstable across samples of examples indicating the idiosyncrasies of how language models acquire information. We formulate example selection for in45;context learning as a sequential decision problem and propose a reinforcement learning algorithm for identifying generalizable policies to select demonstration examples. For GPT45;2 our learned policies demonstrate strong abilities of generalizing to unseen tasks in training with a 5.837; improvement on average. Examples selected from our learned policies can even achieve a small improvement on GPT45;3 Ada. However the improvement diminishes on larger GPT45;3 models suggesting emerging capabilities of large language models.

---
layout: publication
title: 'Learning To Plan And Generate Text With Citations'
authors: Constanza Fierro, Reinald Kim Amplayo, Fantine Huot, Nicola De Cao, Joshua Maynez, Shashi Narayan, Mirella Lapata
conference: "Arxiv"
year: 2024
bibkey: fierro2024learning
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.03381"}
tags: ['Reinforcement Learning']
---
The increasing demand for the deployment of LLMs in information-seeking
scenarios has spurred efforts in creating verifiable systems, which generate
responses to queries along with supporting evidence. In this paper, we explore
the attribution capabilities of plan-based models which have been recently
shown to improve the faithfulness, grounding, and controllability of generated
text. We conceptualize plans as a sequence of questions which serve as
blueprints of the generated content and its organization. We propose two
attribution models that utilize different variants of blueprints, an
abstractive model where questions are generated from scratch, and an extractive
model where questions are copied from the input. Experiments on long-form
question-answering show that planning consistently improves attribution
quality. Moreover, the citations generated by blueprint models are more
accurate compared to those obtained from LLM-based pipelines lacking a planning
component.

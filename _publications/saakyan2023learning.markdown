---
layout: publication
title: 'ICLEF: In-context Learning With Expert Feedback For Explainable Style Transfer'
authors: Saakyan Arkadiy, Muresan Smaranda
conference: "Arxiv"
year: 2023
bibkey: saakyan2023learning
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.08583"}
tags: ['Distillation', 'Efficiency And Optimization', 'Ethics And Bias', 'Few Shot', 'In Context Learning', 'Interpretability And Explainability', 'Prompting']
---
While state-of-the-art large language models (LLMs) can excel at adapting text from one style to another current work does not address the explainability of style transfer models. Recent work has explored generating textual explanations from larger teacher models and distilling them into smaller student models. One challenge with such approach is that LLM outputs may contain errors that require expertise to correct but gathering and incorporating expert feedback is difficult due to cost and availability. To address this challenge we propose ICLEF a novel human-AI collaboration approach to model distillation that incorporates scarce expert human feedback by combining in-context learning and model self-critique. We show that our method leads to generation of high-quality synthetic explainable style transfer datasets for formality (e-GYAFC) and subjective bias (e-WNC). Via automatic and human evaluation we show that specialized student models fine-tuned on our datasets outperform generalist teacher models on the explainable style transfer task in one-shot settings and perform competitively compared to few-shot teacher models highlighting the quality of the data and the role of expert feedback. In an extrinsic task of authorship attribution we show that explanations generated by smaller models fine-tuned on e-GYAFC are more predictive of authorship than explanations generated by few-shot teacher models.

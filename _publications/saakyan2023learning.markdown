---
layout: publication
title: ICLEF In45;context Learning With Expert Feedback For Explainable Style Transfer
authors: Saakyan Arkadiy, Muresan Smaranda
conference: "Arxiv"
year: 2023
bibkey: saakyan2023learning
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.08583"}
tags: ['Distillation', 'Efficiency And Optimization', 'Ethics And Bias', 'Interpretability And Explainability']
---
While state45;of45;the45;art large language models (LLMs) can excel at adapting text from one style to another current work does not address the explainability of style transfer models. Recent work has explored generating textual explanations from larger teacher models and distilling them into smaller student models. One challenge with such approach is that LLM outputs may contain errors that require expertise to correct but gathering and incorporating expert feedback is difficult due to cost and availability. To address this challenge we propose ICLEF a novel human45;AI collaboration approach to model distillation that incorporates scarce expert human feedback by combining in45;context learning and model self45;critique. We show that our method leads to generation of high45;quality synthetic explainable style transfer datasets for formality (e45;GYAFC) and subjective bias (e45;WNC). Via automatic and human evaluation we show that specialized student models fine45;tuned on our datasets outperform generalist teacher models on the explainable style transfer task in one45;shot settings and perform competitively compared to few45;shot teacher models highlighting the quality of the data and the role of expert feedback. In an extrinsic task of authorship attribution we show that explanations generated by smaller models fine45;tuned on e45;GYAFC are more predictive of authorship than explanations generated by few45;shot teacher models.

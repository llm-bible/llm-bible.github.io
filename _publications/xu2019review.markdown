---
layout: publication
title: Review Conversational Reading Comprehension
authors: Xu Hu, Liu Bing, Shu Lei, Yu Philip S.
conference: "Arxiv"
year: 2019
bibkey: xu2019review
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/1902.00821"}
  - {name: "Code", url: "https://github.com/howardhsu/RCRC&#125;"}
tags: ['Agentic', 'BERT', 'Efficiency And Optimization', 'Has Code', 'Model Architecture', 'RAG', 'Reinforcement Learning', 'Survey Paper', 'Training Techniques']
---
Inspired by conversational reading comprehension (CRC) this paper studies a novel task of leveraging reviews as a source to build an agent that can answer multi45;turn questions from potential consumers of online businesses. We first build a review CRC dataset and then propose a novel task45;aware pre45;tuning step running between language model (e.g. BERT) pre45;training and domain45;specific fine45;tuning. The proposed pre45;tuning requires no data annotation but can greatly enhance the performance on our end task. Experimental results show that the proposed approach is highly effective and has competitive performance as the supervised approach. The dataset is available at url123;https://github.com/howardhsu/RCRC&#125;

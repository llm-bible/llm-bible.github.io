---
layout: publication
title: 'Guidellm: Exploring Llm-guided Conversation With Applications In Autobiography Interviewing'
authors: Jinhao Duan, Xinyu Zhao, Zhuoxuan Zhang, Eunhye Ko, Lily Boddy, Chenan Wang, Tianhao Li, Alexander Rasgon, Junyuan Hong, Min Kyung Lee, Chenxi Yuan, Qi Long, Ying Ding, Tianlong Chen, Kaidi Xu
conference: "Arxiv"
year: 2025
bibkey: duan2025exploring
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2502.06494'}
tags: ['GPT', 'Applications', 'Model Architecture']
---
Although Large Language Models (LLMs) succeed in human-guided conversations
such as instruction following and question answering, the potential of
LLM-guided conversations-where LLMs direct the discourse and steer the
conversation's objectives-remains under-explored. In this study, we first
characterize LLM-guided conversation into three fundamental components: (i)
Goal Navigation; (ii) Context Management; (iii) Empathetic Engagement, and
propose GuideLLM as an installation. We then implement an interviewing
environment for the evaluation of LLM-guided conversation. Specifically,
various topics are involved in this environment for comprehensive interviewing
evaluation, resulting in around 1.4k turns of utterances, 184k tokens, and over
200 events mentioned during the interviewing for each chatbot evaluation. We
compare GuideLLM with 6 state-of-the-art LLMs such as GPT-4o and
Llama-3-70b-Instruct, from the perspective of interviewing quality, and
autobiography generation quality. For automatic evaluation, we derive user
proxies from multiple autobiographies and employ LLM-as-a-judge to score LLM
behaviors. We further conduct a human-involved experiment by employing 45 human
participants to chat with GuideLLM and baselines. We then collect human
feedback, preferences, and ratings regarding the qualities of conversation and
autobiography. Experimental results indicate that GuideLLM significantly
outperforms baseline LLMs in automatic evaluation and achieves consistent
leading performances in human ratings.

---
layout: publication
title: On The Robustness Of Language Models For Tabular Question Answering
authors: Bhandari Kushal Raj, Xing Sixue, Dan Soham, Gao Jianxi
conference: "Arxiv"
year: 2024
bibkey: bhandari2024robustness
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.12719"}
tags: ['Applications', 'Attention Mechanism', 'Ethics And Bias', 'Model Architecture', 'Reinforcement Learning', 'Security', 'Training Techniques', 'Transformer']
---
Large Language Models (LLMs) originally shown to ace various text comprehension tasks have also remarkably been shown to tackle table comprehension tasks without specific training. While previous research has explored LLM capabilities with tabular dataset tasks our study assesses the influence of textit123;in45;context learning125; textit123;model scale125; textit123;instruction tuning125; and textit123;domain biases125; on Tabular Question Answering (TQA). We evaluate the robustness of LLMs on Wikipedia45;based textbf123;WTQ125; and financial report45;based textbf123;TAT45;QA125; TQA datasets focusing on their ability to robustly interpret tabular data under various augmentations and perturbations. Our findings indicate that instructions significantly enhance performance with recent models like Llama3 exhibiting greater robustness over earlier versions. However data contamination and practical reliability issues persist especially with WTQ. We highlight the need for improved methodologies including structure45;aware self45;attention mechanisms and better handling of domain45;specific tabular data to develop more reliable LLMs for table comprehension.

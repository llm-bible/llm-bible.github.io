---
layout: publication
title: 'Representation Engineering For Large-language Models: Survey And Research Challenges'
authors: Lukasz Bartoszcze, Sarthak Munshi, Bryan Sukidi, Jennifer Yen, Zejia Yang, David Williams-king, Linh Le, Kosi Asuzu, Carsten Maple
conference: "Arxiv"
year: 2025
bibkey: bartoszcze2025representation
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2502.17601'}
tags: ['Interpretability and Explainability', 'Training Techniques', 'Merging', 'Fine-Tuning', 'Prompting', 'Survey Paper', 'Pretraining Methods']
---
Large-language models are capable of completing a variety of tasks, but
remain unpredictable and intractable. Representation engineering seeks to
resolve this problem through a new approach utilizing samples of contrasting
inputs to detect and edit high-level representations of concepts such as
honesty, harmfulness or power-seeking. We formalize the goals and methods of
representation engineering to present a cohesive picture of work in this
emerging discipline. We compare it with alternative approaches, such as
mechanistic interpretability, prompt-engineering and fine-tuning. We outline
risks such as performance decrease, compute time increases and steerability
issues. We present a clear agenda for future research to build predictable,
dynamic, safe and personalizable LLMs.

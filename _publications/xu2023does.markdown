---
layout: publication
title: Does Conceptual Representation Require Embodiment Insights From Large Language Models
authors: Xu Qihui, Peng Yingying, Nastase Samuel A., Chodorow Martin, Wu Minghua, Li Ping
conference: "Arxiv"
year: 2023
bibkey: xu2023does
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2305.19103"}
tags: ['GPT', 'Model Architecture', 'Pretraining Methods']
---
To what extent can language alone give rise to complex concepts or is embodied experience essential Recent advancements in large language models (LLMs) offer fresh perspectives on this question. Although LLMs are trained on restricted modalities they exhibit human45;like performance in diverse psychological tasks. Our study compared representations of 4442 lexical concepts between humans and ChatGPTs (GPT45;3.5 and GPT45;4) across multiple dimensions including five key domains emotion salience mental visualization sensory and motor experience. We identify two main findings 1) Both models strongly align with human representations in non45;sensorimotor domains but lag in sensory and motor areas with GPT45;4 outperforming GPT45;3.5; 2) GPT45;4s gains are associated with its additional visual learning which also appears to benefit related dimensions like haptics and imageability. These results highlight the limitations of language in isolation and that the integration of diverse modalities of inputs leads to a more human45;like conceptual representation.

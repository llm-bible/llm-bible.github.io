---
layout: publication
title: 'LLM Agents In Interaction: Measuring Personality Consistency And Linguistic Alignment In Interacting Populations Of Large Language Models'
authors: Ivar Frisch, Mario Giulianelli
conference: "Arxiv"
year: 2024
bibkey: frisch2024llm
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2402.02896'}
tags: ['Agentic', 'GPT', 'Prompting', 'Model Architecture']
---
While both agent interaction and personalisation are vibrant topics in
research on large language models (LLMs), there has been limited focus on the
effect of language interaction on the behaviour of persona-conditioned LLM
agents. Such an endeavour is important to ensure that agents remain consistent
to their assigned traits yet are able to engage in open, naturalistic
dialogues. In our experiments, we condition GPT-3.5 on personality profiles
through prompting and create a two-group population of LLM agents using a
simple variability-inducing sampling algorithm. We then administer personality
tests and submit the agents to a collaborative writing task, finding that
different profiles exhibit different degrees of personality consistency and
linguistic alignment to their conversational partners. Our study seeks to lay
the groundwork for better understanding of dialogue-based interaction between
LLMs and highlights the need for new approaches to crafting robust, more
human-like LLM personas for interactive environments.

---
layout: publication
title: Exploring Memorization In Fine45;tuned Language Models
authors: Zeng Shenglai, Li Yaxin, Ren Jie, Liu Yiding, Xu Han, He Pengfei, Xing Yue, Wang Shuaiqiang, Tang Jiliang, Yin Dawei
conference: "Arxiv"
year: 2023
bibkey: zeng2023exploring
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.06714"}
tags: ['Attention Mechanism', 'Fine Tuning', 'Interpretability And Explainability', 'Model Architecture', 'Pretraining Methods', 'Training Techniques']
---
Large language models (LLMs) have shown great capabilities in various tasks but also exhibited memorization of training data raising tremendous privacy and copyright concerns. While prior works have studied memorization during pre45;training the exploration of memorization during fine45;tuning is rather limited. Compared to pre45;training fine45;tuning typically involves more sensitive data and diverse objectives thus may bring distinct privacy risks and unique memorization behaviors. In this work we conduct the first comprehensive analysis to explore language models (LMs) memorization during fine45;tuning across tasks. Our studies with open45;sourced and our own fine45;tuned LMs across various tasks indicate that memorization presents a strong disparity among different fine45;tuning tasks. We provide an intuitive explanation of this task disparity via sparse coding theory and unveil a strong correlation between memorization and attention score distribution.

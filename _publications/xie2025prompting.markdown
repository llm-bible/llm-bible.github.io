---
layout: publication
title: 'Prompting A Weighting Mechanism Into Llm-as-a-judge In Two-step: A Case Study'
authors: Wenwen Xie, Gray Gwizdz, Dongji Feng
conference: "Arxiv"
year: 2025
bibkey: xie2025prompting
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.13396"}
tags: ['Prompting', 'RAG', 'Tools']
---
While Large Language Models (LLMs) have emerged as promising tools for
evaluating Natural Language Generation (NLG) tasks, their effectiveness is
limited by their inability to appropriately weigh the importance of different
topics, often overemphasizing minor details while undervaluing critical
information, leading to misleading assessments. Our work proposes an efficient
prompt design mechanism to address this specific limitation and provide a case
study. Through strategic prompt engineering that incorporates explicit
importance weighting mechanisms, we enhance using LLM-as-a-Judge ability to
prioritize relevant information effectively, as demonstrated by an average
improvement of 6% in the Human Alignment Rate (HAR) metric.

---
layout: publication
title: 'Linear Spatial World Models Emerge In Large Language Models'
authors: Matthieu Tehenan, Christian Bolivar Moya, Tenghai Long, Guang Lin
conference: "Arxiv"
year: 2025
bibkey: tehenan2025linear
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2506.02996'}
tags: ['Reinforcement Learning', 'Tools']
---
Large language models (LLMs) have demonstrated emergent abilities across diverse tasks, raising the question of whether they acquire internal world models. In this work, we investigate whether LLMs implicitly encode linear spatial world models, which we define as linear representations of physical space and object configurations. We introduce a formal framework for spatial world models and assess whether such structure emerges in contextual embeddings. Using a synthetic dataset of object positions, we train probes to decode object positions and evaluate geometric consistency of the underlying space. We further conduct causal interventions to test whether these spatial representations are functionally used by the model. Our results provide empirical evidence that LLMs encode linear spatial world models.

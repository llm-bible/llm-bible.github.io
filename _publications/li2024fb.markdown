---
layout: publication
title: 'Fb-bench: A Fine-grained Multi-task Benchmark For Evaluating Llms'' Responsiveness To Human Feedback'
authors: Youquan Li, Miao Zheng, Fan Yang, Guosheng Dong, Bin Cui, Weipeng Chen, Zenan Zhou, Wentao Zhang
conference: "Arxiv"
year: 2024
bibkey: li2024fb
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2410.09412"}
  - {name: "Code", url: "https://github.com/PKU-Baichuan-MLSystemLab/FB-Bench"}
tags: ['Has Code', 'Reinforcement Learning']
---
Human feedback is crucial in the interactions between humans and Large
Language Models (LLMs). However, existing research primarily focuses on
benchmarking LLMs in single-turn dialogues. Even in benchmarks designed for
multi-turn dialogues, the user inputs are often independent, neglecting the
nuanced and complex nature of human feedback within real-world usage scenarios.
To fill this research gap, we introduce FB-Bench, a fine-grained, multi-task
benchmark designed to evaluate LLMs' responsiveness to human feedback under
real-world usage scenarios in Chinese. Drawing from the two main interaction
scenarios, FB-Bench comprises 591 meticulously curated samples, encompassing
eight task types, five deficiency types of response, and nine feedback types.
We extensively evaluate a broad array of popular LLMs, revealing significant
variations in their performance across different interaction scenarios. Further
analysis indicates that task, human feedback, and deficiencies of previous
responses can also significantly impact LLMs' responsiveness. Our findings
underscore both the strengths and limitations of current models, providing
valuable insights and directions for future research. Code and datasets are
available at https://github.com/PKU-Baichuan-MLSystemLab/FB-Bench.

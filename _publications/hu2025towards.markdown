---
layout: publication
title: 'Position: Towards A Responsible Llm-empowered Multi-agent Systems'
authors: Jinwei Hu, Yi Dong, Shuang Ao, Zhuoyun Li, Boxuan Wang, Lokesh Singh, Guangliang Cheng, Sarvapali D. Ramchurn, Xiaowei Huang
conference: "Arxiv"
year: 2025
bibkey: hu2025towards
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.01714"}
tags: ['RAG', 'Agentic', 'Agent', 'Tools']
---
The rise of Agent AI and Large Language Model-powered Multi-Agent Systems
(LLM-MAS) has underscored the need for responsible and dependable system
operation. Tools like LangChain and Retrieval-Augmented Generation have
expanded LLM capabilities, enabling deeper integration into MAS through
enhanced knowledge retrieval and reasoning. However, these advancements
introduce critical challenges: LLM agents exhibit inherent unpredictability,
and uncertainties in their outputs can compound across interactions,
threatening system stability. To address these risks, a human-centered design
approach with active dynamic moderation is essential. Such an approach enhances
traditional passive oversight by facilitating coherent inter-agent
communication and effective system governance, allowing MAS to achieve desired
outcomes more efficiently.

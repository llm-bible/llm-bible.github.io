---
layout: publication
title: Zero45;shot Spam Email Classification Using Pre45;trained Large Language Models
authors: Rojas-galeano Sergio
conference: "Arxiv"
year: 2024
bibkey: rojasgaleano2024zero
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.15936"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Prompting', 'RAG', 'Reinforcement Learning', 'Training Techniques']
---
This paper investigates the application of pre45;trained large language models (LLMs) for spam email classification using zero45;shot prompting. We evaluate the performance of both open45;source (Flan45;T5) and proprietary LLMs (ChatGPT GPT45;4) on the well45;known SpamAssassin dataset. Two classification approaches are explored (1) truncated raw content from email subject and body and (2) classification based on summaries generated by ChatGPT. Our empirical analysis leveraging the entire dataset for evaluation without further training reveals promising results. Flan45;T5 achieves a 9037; F145;score on the truncated content approach while GPT45;4 reaches a 9537; F145;score using summaries. While these initial findings on a single dataset suggest the potential for classification pipelines of LLM45;based subtasks (e.g. summarisation and classification) further validation on diverse datasets is necessary. The high operational costs of proprietary models coupled with the general inference costs of LLMs could significantly hinder real45;world deployment for spam filtering.

---
layout: publication
title: 'Zero-shot Spam Email Classification Using Pre-trained Large Language Models'
authors: Sergio Rojas-galeano
conference: "Applied Computer Sciences in Engineering. WEA 2024. Communications in Computer and Information Science vol 2222. Springer Cham"
year: 2024
bibkey: rojasgaleano2024zero
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.15936"}
tags: ['Training Techniques', 'Model Architecture', 'Reinforcement Learning', 'RAG', 'GPT', 'Prompting']
---
This paper investigates the application of pre-trained large language models
(LLMs) for spam email classification using zero-shot prompting. We evaluate the
performance of both open-source (Flan-T5) and proprietary LLMs (ChatGPT, GPT-4)
on the well-known SpamAssassin dataset. Two classification approaches are
explored: (1) truncated raw content from email subject and body, and (2)
classification based on summaries generated by ChatGPT. Our empirical analysis,
leveraging the entire dataset for evaluation without further training, reveals
promising results. Flan-T5 achieves a 90% F1-score on the truncated content
approach, while GPT-4 reaches a 95% F1-score using summaries. While these
initial findings on a single dataset suggest the potential for classification
pipelines of LLM-based subtasks (e.g., summarisation and classification),
further validation on diverse datasets is necessary. The high operational costs
of proprietary models, coupled with the general inference costs of LLMs, could
significantly hinder real-world deployment for spam filtering.

---
layout: publication
title: DUAL45;REFLECT Enhancing Large Language Models For Reflective Translation Through Dual Learning Feedback Mechanisms
authors: Chen Andong, Lou Lianzhang, Chen Kehai, Bai Xuefeng, Xiang Yang, Yang Muyun, Zhao Tiejun, Zhang Min
conference: "Arxiv"
year: 2024
bibkey: chen2024dual
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.07232"}
tags: ['Applications', 'RAG', 'Tools']
---
Recently large language models (LLMs) enhanced by self45;reflection have achieved promising performance on machine translation. The key idea is guiding LLMs to generate translation with human45;like feedback. However existing self45;reflection methods lack effective feedback information limiting the translation performance. To address this we introduce a DUAL45;REFLECT framework leveraging the dual learning of translation tasks to provide effective feedback thereby enhancing the models self45;reflective abilities and improving translation performance. The application of this method across various translation tasks has proven its effectiveness in improving translation accuracy and eliminating ambiguities especially in translation tasks with low45;resource language pairs.

---
layout: publication
title: 'Echoqa: A Large Collection Of Instruction Tuning Data For Echocardiogram Reports'
authors: Lama Moukheiber, Mira Moukheiber, Dana Moukheiiber, Jae-woo Ju, Hyung-chul Lee
conference: "Arxiv"
year: 2025
bibkey: moukheiber2025large
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2503.02365'}
tags: ['Agentic', 'Fairness', 'Training Techniques', 'Fine-Tuning', 'Bias Mitigation', 'Reinforcement Learning', 'Ethics and Bias', 'Pretraining Methods']
---
We introduce a novel question-answering (QA) dataset using echocardiogram
reports sourced from the Medical Information Mart for Intensive Care database.
This dataset is specifically designed to enhance QA systems in cardiology,
consisting of 771,244 QA pairs addressing a wide array of cardiac abnormalities
and their severity. We compare large language models (LLMs), including
open-source and biomedical-specific models for zero-shot evaluation, and
closed-source models for zero-shot and three-shot evaluation. Our results show
that fine-tuning LLMs improves performance across various QA metrics,
validating the value of our dataset. Clinicians also qualitatively evaluate the
best-performing model to assess the LLM responses for correctness. Further, we
conduct fine-grained fairness audits to assess the bias-performance trade-off
of LLMs across various social determinants of health. Our objective is to
propel the field forward by establishing a benchmark for LLM AI agents aimed at
supporting clinicians with cardiac differential diagnoses, thereby reducing the
documentation burden that contributes to clinician burnout and enabling
healthcare professionals to focus more on patient care.

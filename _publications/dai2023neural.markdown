---
layout: publication
title: Neural Retrievers Are Biased Towards Llm45;generated Content
authors: Dai Sunhao, Zhou Yuqi, Pang Liang, Liu Weihao, Hu Xiaolin, Liu Yong, Zhang Xiao, Wang Gang, Xu Jun
conference: "Arxiv"
year: 2023
bibkey: dai2023neural
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.20501"}
  - {name: "Code", url: "https://github.com/KID&#45;22/Source&#45;Bias"}
tags: ['Applications', 'Efficiency And Optimization', 'Ethics And Bias', 'Fine Tuning', 'Has Code']
---
Recently the emergence of large language models (LLMs) has revolutionized the paradigm of information retrieval (IR) applications especially in web search by generating vast amounts of human45;like texts on the Internet. As a result IR systems in the LLM era are facing a new challenge the indexed documents are now not only written by human beings but also automatically generated by the LLMs. How these LLM45;generated documents influence the IR systems is a pressing and still unexplored question. In this work we conduct a quantitative evaluation of IR models in scenarios where both human45;written and LLM45;generated texts are involved. Surprisingly our findings indicate that neural retrieval models tend to rank LLM45;generated documents higher. We refer to this category of biases in neural retrievers towards the LLM45;generated content as the textbf123;source bias125;. Moreover we discover that this bias is not confined to the first45;stage neural retrievers but extends to the second45;stage neural re45;rankers. Then in45;depth analyses from the perspective of text compression indicate that LLM45;generated texts exhibit more focused semantics with less noise making it easier for neural retrieval models to semantic match. To mitigate the source bias we also propose a plug45;and45;play debiased constraint for the optimization objective and experimental results show its effectiveness. Finally we discuss the potential severe concerns stemming from the observed source bias and hope our findings can serve as a critical wake45;up call to the IR community and beyond. To facilitate future explorations of IR in the LLM era the constructed two new benchmarks are available at https://github.com/KID&#45;22/Source&#45;Bias.

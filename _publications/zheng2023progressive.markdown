---
layout: publication
title: Progressive45;hint Prompting Improves Reasoning In Large Language Models
authors: Zheng Chuanyang, Liu Zhengying, Xie Enze, Li Zhenguo, Li Yu
conference: "Arxiv"
year: 2023
bibkey: zheng2023progressive
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2304.09797"}
tags: ['GPT', 'Model Architecture', 'Prompting']
---
The performance of Large Language Models (LLMs) in reasoning tasks depends heavily on prompt design with Chain45;of45;Thought (CoT) and self45;consistency being critical methods that enhance this ability. However these methods do not fully exploit the answers generated by the LLM to guide subsequent responses. This paper proposes a new prompting method named Progressive45;Hint Prompting (PHP) that enables automatic multiple interactions between users and LLMs by using previously generated answers as hints to progressively guide toward the correct answers. PHP is orthogonal to CoT and self45;consistency making it easy to combine with state45;of45;the45;art techniques to further improve performance. We conducted extensive and comprehensive experiments on seven benchmarks. The results show that PHP significantly improves accuracy while remaining highly efficient. For instance with text45;davinci45;003 we observed a 4.237; improvement on GSM8K with greedy decoding compared to Complex CoT and a 46.1737; reduction in sample paths with self45;consistency. With GPT45;4 and PHP we achieve state45;of45;the45;art performances on SVAMP (89.137; 45; 91.937;) GSM8K (9237; 45; 95.537;) AQuA (76.437; 45; 79.937;) and MATH (50.337; 45; 53.937;).

---
layout: publication
title: 'A Survey On Federated Fine-tuning Of Large Language Models'
authors: Yebo Wu, Chunlin Tian, Jingguang Li, He Sun, Kahou Tam, Li Li, Chengzhong Xu
conference: "Arxiv"
year: 2025
bibkey: wu2025survey
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2503.12016"}
  - {name: "Code", url: "https://github.com/Clin0212/Awesome-Federated-LLM-Learning}{GitHub"}
tags: ['Training Techniques', 'Survey Paper', 'Reinforcement Learning', 'Pretraining Methods', 'Fine-Tuning', 'Has Code', 'Applications']
---
Large Language Models (LLMs) have achieved remarkable success across a wide
range of tasks, with fine-tuning playing a pivotal role in adapting them to
specific downstream applications. Federated Learning (FL) offers a promising
approach that enables collaborative model adaptation while ensuring data
privacy, i.e., FedLLM. In this survey, we provide a systematic and thorough
review of the integration of LLMs with FL. Specifically, we first trace the
historical evolution of both LLMs and FL, while summarizing relevant prior
surveys. We then present an in-depth analysis of the fundamental challenges
encountered in deploying FedLLM. Following this, we conduct an extensive study
of existing parameter-efficient fine-tuning (PEFT) methods and explore their
applicability in FL. Furthermore, we introduce a comprehensive evaluation
benchmark to rigorously assess FedLLM performance and discuss its diverse
real-world applications across multiple domains. Finally, we identify critical
open challenges and outline promising research directions to drive future
advancements in FedLLM. We maintain an active
\href\{https://github.com/Clin0212/Awesome-Federated-LLM-Learning\}\{GitHub
repository\} tracking cutting-edge advancements. This survey serves as a
foundational resource for researchers and practitioners, offering insights into
the evolving landscape of federated fine-tuning for LLMs while guiding future
innovations in privacy-preserving AI.

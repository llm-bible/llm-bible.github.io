---
layout: publication
title: 'Unlocking Cross-lingual Sentiment Analysis Through Emoji Interpretation: A Multimodal Generative AI Approach'
authors: Rafid Ishrak Jahan, Heng Fan, Haihua Chen, Yunhe Feng
conference: "Arxiv"
year: 2024
bibkey: jahan2024unlocking
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2412.17255'}
  - {name: "Code", url: 'https://github.com/ResponsibleAILab/emoji-universal-sentiment'}
tags: ['Has Code', 'RAG', 'Model Architecture', 'Tools', 'GPT', 'Multimodal Models']
---
Emojis have become ubiquitous in online communication, serving as a universal
medium to convey emotions and decorative elements. Their widespread use
transcends language and cultural barriers, enhancing understanding and
fostering more inclusive interactions. While existing work gained valuable
insight into emojis understanding, exploring emojis' capability to serve as a
universal sentiment indicator leveraging large language models (LLMs) has not
been thoroughly examined. Our study aims to investigate the capacity of emojis
to serve as reliable sentiment markers through LLMs across languages and
cultures. We leveraged the multimodal capabilities of ChatGPT to explore the
sentiments of various representations of emojis and evaluated how well
emoji-conveyed sentiment aligned with text sentiment on a multi-lingual dataset
collected from 32 countries. Our analysis reveals that the accuracy of
LLM-based emoji-conveyed sentiment is 81.43%, underscoring emojis' significant
potential to serve as a universal sentiment marker. We also found a consistent
trend that the accuracy of sentiment conveyed by emojis increased as the number
of emojis grew in text. The results reinforce the potential of emojis to serve
as global sentiment indicators, offering insight into fields such as
cross-lingual and cross-cultural sentiment analysis on social media platforms.
Code: https://github.com/ResponsibleAILab/emoji-universal-sentiment.

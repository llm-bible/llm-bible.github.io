---
layout: publication
title: Prompt Framework For Role45;playing Generation And Evaluation
authors: Liu Xun, Ni Zhengwei
conference: "Arxiv"
year: 2024
bibkey: liu2024prompt
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.00627"}
tags: ['Applications', 'Prompting', 'RAG', 'Reinforcement Learning', 'Tools']
---
Large language models (LLM) have demonstrated remarkable abilities in generating natural language understanding user instruction and mimicking human language use. These capabilities have garnered considerable interest in applications such as role45;playing. However the process of collecting individual role scripts (or profiles) data and manually evaluating the performance can be costly. We introduce a framework that uses prompts to leverage the state45;of45;the45;art (SOTA) LLMs to construct role45;playing dialogue datasets and evaluate the role45;playing performance. Additionally we employ recall45;oriented evaluation Rouge45;L metric to support the result of the LLM evaluator.

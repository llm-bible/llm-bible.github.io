---
layout: publication
title: Outcome-Constrained Large Language Models for Countering Hate Speech
authors: Hong Lingzi, Luo Pengcheng, Blanco Eduardo, Song Xiaoying
conference: "Arxiv"
year: 2024
bibkey: hong2024outcome
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.17146"}
tags: ['Agentic', 'Applications', 'Language Modeling', 'Model Architecture', 'Pretraining Methods', 'Prompting', 'Reinforcement Learning', 'Transformer']
---
Counterspeech that challenges or responds to hate speech has been seen as an alternative to mitigate the negative impact of hate speech and foster productive online communications. Research endeavors have been directed to using language models for the automatic generation of counterspeech to assist efforts in combating online hate. Existing research focuses on the generation of counterspeech with certain linguistic attributes such as being polite informative and intent-driven. However it remains unclear what impact the counterspeech might have in an online environment. We first explore methods that utilize large language models (LLM) to generate counterspeech constrained by potential conversation outcomes. We build two conversation outcome classifiers that predict the incivility level and the hater reentry behavior following replies to hate with Reddit data then propose four methods to incorporate the desired outcomes i.e. low conversation incivility and non-hateful hater reentry into the text generation process including Prompt with Instructions Prompt and Select LLM finetune and LLM transformer reinforcement learning (TRL). Evaluation results show effective strategies to generate outcome-constrained counterspeech and the linguistic characteristics of texts generated by different methods.

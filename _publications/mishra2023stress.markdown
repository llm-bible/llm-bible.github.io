---
layout: publication
title: 'Stress Testing Chain-of-thought Prompting For Large Language Models'
authors: Mishra Aayush, Thakkar Karan
conference: "Arxiv"
year: 2023
bibkey: mishra2023stress
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.16621"}
tags: ['GPT', 'Model Architecture', 'Prompting']
---
This report examines the effectiveness of Chain-of-Thought (CoT) prompting in
improving the multi-step reasoning abilities of large language models (LLMs).
Inspired by previous studies \cite\{Min2022RethinkingWork\}, we analyze the
impact of three types of CoT prompt perturbations, namely CoT order, CoT
values, and CoT operators on the performance of GPT-3 on various tasks. Our
findings show that incorrect CoT prompting leads to poor performance on
accuracy metrics. Correct values in the CoT is crucial for predicting correct
answers. Moreover, incorrect demonstrations, where the CoT operators or the CoT
order are wrong, do not affect the performance as drastically when compared to
the value based perturbations. This research deepens our understanding of CoT
prompting and opens some new questions regarding the capability of LLMs to
learn reasoning in context.

---
layout: publication
title: 'Large Language Models For Mental Health Diagnostic Assessments: Exploring The Potential Of Large Language Models For Assisting With Mental Health Diagnostic Assessments -- The Depression And Anxiety Case'
authors: Kaushik Roy, Harshul Surana, Darssan Eswaramoorthi, Yuxin Zi, Vedant Palit, Ritvik Garimella, Amit Sheth
conference: "Arxiv"
year: 2025
bibkey: roy2025large
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2501.01305"}
tags: ['Training Techniques', 'Model Architecture', 'Reinforcement Learning', 'GPT', 'Pretraining Methods', 'Fine-Tuning', 'Prompting', 'Attention Mechanism']
---
Large language models (LLMs) are increasingly attracting the attention of
healthcare professionals for their potential to assist in diagnostic
assessments, which could alleviate the strain on the healthcare system caused
by a high patient load and a shortage of providers. For LLMs to be effective in
supporting diagnostic assessments, it is essential that they closely replicate
the standard diagnostic procedures used by clinicians. In this paper, we
specifically examine the diagnostic assessment processes described in the
Patient Health Questionnaire-9 (PHQ-9) for major depressive disorder (MDD) and
the Generalized Anxiety Disorder-7 (GAD-7) questionnaire for generalized
anxiety disorder (GAD). We investigate various prompting and fine-tuning
techniques to guide both proprietary and open-source LLMs in adhering to these
processes, and we evaluate the agreement between LLM-generated diagnostic
outcomes and expert-validated ground truth. For fine-tuning, we utilize the
Mentalllama and Llama models, while for prompting, we experiment with
proprietary models like GPT-3.5 and GPT-4o, as well as open-source models such
as llama-3.1-8b and mixtral-8x7b.

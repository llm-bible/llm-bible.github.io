---
layout: publication
title: Survey On Large Language Model45;enhanced Reinforcement Learning Concept Taxonomy And Methods
authors: Cao Yuji, Zhao Huan, Cheng Yuheng, Shu Ting, Liu Guolong, Liang Gaoqi, Zhao Junhua, Li Yun
conference: "Arxiv"
year: 2024
bibkey: cao2024survey
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.00282"}
tags: ['Agentic', 'Applications', 'Efficiency And Optimization', 'Reinforcement Learning', 'Survey Paper']
---
With extensive pre45;trained knowledge and high45;level general capabilities large language models (LLMs) emerge as a promising avenue to augment reinforcement learning (RL) in aspects such as multi45;task learning sample efficiency and task planning. In this survey we provide a comprehensive review of the existing literature in textit123;LLM45;enhanced RL125; and summarize its characteristics compared to conventional RL methods aiming to clarify the research scope and directions for future studies. Utilizing the classical agent45;environment interaction paradigm we propose a structured taxonomy to systematically categorize LLMs functionalities in RL including four roles information processor reward designer decision45;maker and generator. Additionally for each role we summarize the methodologies analyze the specific RL challenges that are mitigated and provide insights into future directions. Lastly potential applications prospective opportunities and challenges of the textit123;LLM45;enhanced RL125; are discussed.

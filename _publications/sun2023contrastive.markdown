---
layout: publication
title: CONSCENDI A Contrastive And Scenario45;guided Distillation Approach To Guardrail Models For Virtual Assistants
authors: Sun Albert Yu, Nair Varun, Schumacher Elliot, Kannan Anitha
conference: "Arxiv"
year: 2023
bibkey: sun2023contrastive
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2304.14364"}
tags: ['Distillation', 'Efficiency And Optimization', 'GPT', 'Model Architecture', 'Prompting', 'Reinforcement Learning', 'Training Techniques']
---
A wave of new task45;based virtual assistants has been fueled by increasingly powerful large language models (LLMs) such as GPT45;4 (OpenAI 2023). A major challenge in deploying LLM45;based virtual conversational assistants in real world settings is ensuring they operate within what is admissible for the task. To overcome this challenge the designers of these virtual assistants rely on an independent guardrail system that verifies the virtual assistants output aligns with the constraints required for the task. However relying on commonly used prompt45;based guardrails can be difficult to engineer correctly and comprehensively. To address these challenges we propose CONSCENDI. We use CONSCENDI to exhaustively generate training data with two key LLM45;powered components scenario45;augmented generation and contrastive training examples. When generating conversational data we generate a set of rule45;breaking scenarios which enumerate a diverse set of high45;level ways a rule can be violated. This scenario45;guided approach produces a diverse training set and provides chatbot designers greater control. To generate contrastive examples we prompt the LLM to alter conversations with violations into acceptable conversations to enable fine45;grained distinctions. We then use this data generated by CONSCENDI to train a smaller model. We find that CONSCENDI results in guardrail models that improve over baselines in multiple dialogue domains.

---
layout: publication
title: 'A Multimodal Social Agent'
authors: Athina Bikaki, Ioannis A. Kakadiaris
conference: "Arxiv"
year: 2024
bibkey: bikaki2024multimodal
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2501.06189'}
tags: ['Agentic', 'Multimodal Models', 'Applications']
---
In recent years, large language models (LLMs) have demonstrated remarkable
progress in common-sense reasoning tasks. This ability is fundamental to
understanding social dynamics, interactions, and communication. However, the
potential of integrating computers with these social capabilities is still
relatively unexplored. However, the potential of integrating computers with
these social capabilities is still relatively unexplored. This paper introduces
MuSA, a multimodal LLM-based agent that analyzes text-rich social content
tailored to address selected human-centric content analysis tasks, such as
question answering, visual question answering, title generation, and
categorization. It uses planning, reasoning, acting, optimizing, criticizing,
and refining strategies to complete a task. Our approach demonstrates that MuSA
can automate and improve social content analysis, helping decision-making
processes across various applications. We have evaluated our agent's
capabilities in question answering, title generation, and content
categorization tasks. MuSA performs substantially better than our baselines.

---
layout: publication
title: Effective Demonstration Annotation For In45;context Learning Via Language Model45;based Determinantal Point Process
authors: Wang Peng, Wang Xiaobin, Lou Chao, Mao Shengyu, Xie Pengjun, Jiang Yong
conference: "Arxiv"
year: 2024
bibkey: wang2024effective
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.02103"}
tags: ['GPT', 'Model Architecture', 'Pretraining Methods', 'Reinforcement Learning']
---
In45;context learning (ICL) is a few45;shot learning paradigm that involves learning mappings through input45;output pairs and appropriately applying them to new instances. Despite the remarkable ICL capabilities demonstrated by Large Language Models (LLMs) existing works are highly dependent on large45;scale labeled support sets not always feasible in practical scenarios. To refine this approach we focus primarily on an innovative selective annotation mechanism which precedes the standard demonstration retrieval. We introduce the Language Model45;based Determinant Point Process (LM45;DPP) that simultaneously considers the uncertainty and diversity of unlabeled instances for optimal selection. Consequently this yields a subset for annotation that strikes a trade45;off between the two factors. We apply LM45;DPP to various language models including GPT45;J LlaMA and GPT45;3. Experimental results on 9 NLU and 2 Generation datasets demonstrate that LM45;DPP can effectively select canonical examples. Further analysis reveals that LLMs benefit most significantly from subsets that are both low uncertainty and high diversity.

---
layout: publication
title: Unveiling Typographic Deceptions Insights Of The Typographic Vulnerability In Large Vision45;language Model
authors: Cheng Hao, Xiao Erjia, Gu Jindong, Yang Le, Duan Jinhao, Zhang Jize, Cao Jiahang, Xu Kaidi, Xu Renjing
conference: "Arxiv"
year: 2024
bibkey: cheng2024unveiling
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.19150"}
tags: ['Pretraining Methods', 'Security', 'Training Techniques']
---
Large Vision45;Language Models (LVLMs) rely on vision encoders and Large Language Models (LLMs) to exhibit remarkable capabilities on various multi45;modal tasks in the joint space of vision and language. However the Typographic Attack which disrupts vision45;language models (VLMs) such as Contrastive Language45;Image Pretraining (CLIP) has also been expected to be a security threat to LVLMs. Firstly we verify typographic attacks on current well45;known commercial and open45;source LVLMs and uncover the widespread existence of this threat. Secondly to better assess this vulnerability we propose the most comprehensive and largest45;scale Typographic Dataset to date. The Typographic Dataset not only considers the evaluation of typographic attacks under various multi45;modal tasks but also evaluates the effects of typographic attacks influenced by texts generated with diverse factors. Based on the evaluation results we investigate the causes why typographic attacks may impact VLMs and LVLMs leading to three highly insightful discoveries. By the examination of our discoveries and experimental validation in the Typographic Dataset we reduce the performance degradation from 42.0737; to 13.9037; when LVLMs confront typographic attacks.

---
layout: publication
title: 'Transfertransfo: A Transfer Learning Approach For Neural Network Based Conversational
  Agents'
authors: Thomas Wolf, Victor Sanh, Julien Chaumond, Clement Delangue
conference: Arxiv
year: 2019
citations: 289
bibkey: wolf2019transfer
additional_links:
- name: Paper
  url: https://arxiv.org/abs/1901.08149
tags:
- Transformer
- Fine-Tuning
- Agentic
---
We introduce a new approach to generative data-driven dialogue systems (e.g.
chatbots) called TransferTransfo which is a combination of a Transfer learning
based training scheme and a high-capacity Transformer model. Fine-tuning is
performed by using a multi-task objective which combines several unsupervised
prediction tasks. The resulting fine-tuned model shows strong improvements over
the current state-of-the-art end-to-end conversational models like memory
augmented seq2seq and information-retrieval models. On the privately held
PERSONA-CHAT dataset of the Conversational Intelligence Challenge 2, this
approach obtains a new state-of-the-art, with respective perplexity, Hits@1 and
F1 metrics of 16.28 (45 % absolute improvement), 80.7 (46 % absolute
improvement) and 19.5 (20 % absolute improvement).
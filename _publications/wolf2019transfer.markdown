---
layout: publication
title: Transfertransfo A Transfer Learning Approach For Neural Network Based Conversational Agents
authors: Wolf Thomas, Sanh Victor, Chaumond Julien, Delangue Clement
conference: "Arxiv"
year: 2019
bibkey: wolf2019transfer
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/1901.08149"}
tags: ['Agentic', 'Applications', 'Fine Tuning', 'Model Architecture', 'Pretraining Methods', 'Training Techniques', 'Transformer']
---
We introduce a new approach to generative data45;driven dialogue systems (e.g. chatbots) called TransferTransfo which is a combination of a Transfer learning based training scheme and a high45;capacity Transformer model. Fine45;tuning is performed by using a multi45;task objective which combines several unsupervised prediction tasks. The resulting fine45;tuned model shows strong improvements over the current state45;of45;the45;art end45;to45;end conversational models like memory augmented seq2seq and information45;retrieval models. On the privately held PERSONA45;CHAT dataset of the Conversational Intelligence Challenge 2 this approach obtains a new state45;of45;the45;art with respective perplexity Hits35;64;1 and F1 metrics of 16.28 (45 37; absolute improvement) 80.7 (46 37; absolute improvement) and 19.5 (20 37; absolute improvement).

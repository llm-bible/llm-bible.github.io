---
layout: publication
title: 'Zero-shot End-to-end Relation Extraction In Chinese: A Comparative Study Of Gemini, Llama And Chatgpt'
authors: Shaoshuai Du, Yiyi Tao, Yixian Shen, Hang Zhang, Yanxin Shen, Xinyu Qiu, Chuanqi Shi
conference: "Arxiv"
year: 2025
bibkey: du2025zero
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.05694"}
tags: ['Applications', 'Efficiency and Optimization', 'Model Architecture', 'GPT']
---
This study investigates the performance of various large language models
(LLMs) on zero-shot end-to-end relation extraction (RE) in Chinese, a task that
integrates entity recognition and relation extraction without requiring
annotated data. While LLMs show promise for RE, most prior work focuses on
English or assumes pre-annotated entities, leaving their effectiveness in
Chinese RE largely unexplored. To bridge this gap, we evaluate ChatGPT, Gemini,
and LLaMA based on accuracy, efficiency, and adaptability. ChatGPT demonstrates
the highest overall performance, balancing precision and recall, while Gemini
achieves the fastest inference speed, making it suitable for real-time
applications. LLaMA underperforms in both accuracy and latency, highlighting
the need for further adaptation. Our findings provide insights into the
strengths and limitations of LLMs for zero-shot Chinese RE, shedding light on
trade-offs between accuracy and efficiency. This study serves as a foundation
for future research aimed at improving LLM adaptability to complex linguistic
tasks in Chinese NLP.

---
layout: publication
title: 'Continual Learning Using Only Large Language Model Prompting'
authors: Jiabao Qiu, Zixuan Ke, Bing Liu
conference: "Arxiv"
year: 2024
bibkey: qiu2024continual
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2412.15479"}
tags: ['Tools', 'Prompting', 'Applications', 'Reinforcement Learning']
---
We introduce CLOB, a novel continual learning (CL) paradigm wherein a large
language model (LLM) is regarded as a black box. Learning is done incrementally
via only verbal prompting. CLOB does not fine-tune any part of the LLM or add
any trainable parameters to it. It is particularly suitable for LLMs that are
accessible via APIs. We also propose a new CL technique, called CIS, based on
incremental summarization that also overcomes the LLM's input length limit.
Experiments show CIS outperforms baselines by a very large margin.

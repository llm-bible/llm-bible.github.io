---
layout: publication
title: "Unipa-gpt: Large Language Models For University-oriented QA In Italian"
authors: Siragusa Irene, Pirrone Roberto
conference: "Arxiv"
year: 2024
bibkey: siragusa2024unipa
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.14246"}
tags: ['Fine Tuning', 'GPT', 'Model Architecture', 'Pretraining Methods', 'RAG', 'Training Techniques']
---
This paper illustrates the architecture and training of Unipa-GPT a chatbot relying on a Large Language Model developed for assisting students in choosing a bachelor/master degree course at the University of Palermo. Unipa-GPT relies on gpt-3.5-turbo it was presented in the context of the European Researchers Night (SHARPER night). In our experiments we adopted both the Retrieval Augmented Generation (RAG) approach and fine-tuning to develop the system. The whole architecture of Unipa-GPT is presented both the RAG and the fine-tuned systems are compared and a brief discussion on their performance is reported. Further comparison with other Large Language Models and the experimental results during the SHARPER night are illustrated.

---
layout: publication
title: O3D Offline Data45;driven Discovery And Distillation For Sequential Decision45;making With Large Language Models
authors: Xiao Yuchen, Sun Yanchao, Xu Mengda, Madhushani Udari, Vann Jared, Garg Deepeka, Ganesh Sumitra
conference: "Arxiv"
year: 2023
bibkey: xiao2023offline
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.14403"}
tags: ['Agentic', 'Distillation', 'Efficiency And Optimization', 'Prompting', 'Reinforcement Learning', 'Tools', 'Training Techniques']
---
Recent advancements in large language models (LLMs) have exhibited promising performance in solving sequential decision45;making problems. By imitating few45;shot examples provided in the prompts (i.e. in45;context learning) an LLM agent can interact with an external environment and complete given tasks without additional training. However such few45;shot examples are often insufficient to generate high45;quality solutions for complex and long45;horizon tasks while the limited context length cannot consume larger45;scale demonstrations with long interaction horizons. To this end we propose an offline learning framework that utilizes offline data at scale (e.g logs of human interactions) to improve LLM45;powered policies without finetuning. The proposed method O3D (Offline Data45;driven Discovery and Distillation) automatically discovers reusable skills and distills generalizable knowledge across multiple tasks based on offline interaction data advancing the capability of solving downstream tasks. Empirical results under two interactive decision45;making benchmarks (ALFWorld and WebShop) verify that O3D can notably enhance the decision45;making capabilities of LLMs through the offline discovery and distillation process and consistently outperform baselines across various LLMs.

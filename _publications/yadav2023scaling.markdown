---
layout: publication
title: Scaling Evidence45;based Instructional Design Expertise Through Large Language Models
authors: Yadav Gautam
conference: "Arxiv"
year: 2023
bibkey: yadav2023scaling
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2306.01006"}
tags: ['Applications', 'Fine Tuning', 'GPT', 'Model Architecture', 'RAG', 'Reinforcement Learning']
---
This paper presents a comprehensive exploration of leveraging Large Language Models (LLMs) specifically GPT45;4 in the field of instructional design. With a focus on scaling evidence45;based instructional design expertise our research aims to bridge the gap between theoretical educational studies and practical implementation. We discuss the benefits and limitations of AI45;driven content generation emphasizing the necessity of human oversight in ensuring the quality of educational materials. This work is elucidated through two detailed case studies where we applied GPT45;4 in creating complex higher45;order assessments and active learning components for different courses. From our experiences we provide best practices for effectively using LLMs in instructional design tasks such as utilizing templates fine45;tuning handling unexpected output implementing LLM chains citing references evaluating output creating rubrics grading and generating distractors. We also share our vision of a future recommendation system where a customized GPT45;4 extracts instructional design principles from educational studies and creates personalized evidence45;supported strategies for users unique educational contexts. Our research contributes to understanding and optimally harnessing the potential of AI45;driven language models in enhancing educational outcomes.

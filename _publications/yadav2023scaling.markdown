---
layout: publication
title: 'Scaling Evidence-based Instructional Design Expertise Through Large Language Models'
authors: Yadav Gautam
conference: "Arxiv"
year: 2023
bibkey: yadav2023scaling
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2306.01006"}
tags: ['Fine Tuning', 'GPT', 'Model Architecture', 'Pretraining Methods', 'RAG', 'Reinforcement Learning', 'Training Techniques']
---
This paper presents a comprehensive exploration of leveraging Large Language Models (LLMs) specifically GPT-4 in the field of instructional design. With a focus on scaling evidence-based instructional design expertise our research aims to bridge the gap between theoretical educational studies and practical implementation. We discuss the benefits and limitations of AI-driven content generation emphasizing the necessity of human oversight in ensuring the quality of educational materials. This work is elucidated through two detailed case studies where we applied GPT-4 in creating complex higher-order assessments and active learning components for different courses. From our experiences we provide best practices for effectively using LLMs in instructional design tasks such as utilizing templates fine-tuning handling unexpected output implementing LLM chains citing references evaluating output creating rubrics grading and generating distractors. We also share our vision of a future recommendation system where a customized GPT-4 extracts instructional design principles from educational studies and creates personalized evidence-supported strategies for users unique educational contexts. Our research contributes to understanding and optimally harnessing the potential of AI-driven language models in enhancing educational outcomes.

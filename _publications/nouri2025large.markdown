---
layout: publication
title: 'Large Language Models In Code Co-generation For Safe Autonomous Vehicles'
authors: Ali Nouri, Beatriz Cabrero-daniel, Zhennan Fei, Krishna Ronanki, HÃ¥kan Sivencrona, Christian Berger
conference: "Arxiv"
year: 2025
bibkey: nouri2025large
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2505.19658"}
tags: ['Responsible AI', 'Model Architecture', 'Reinforcement Learning', 'GPT', 'Applications']
---
Software engineers in various industrial domains are already using Large Language Models (LLMs) to accelerate the process of implementing parts of software systems. When considering its potential use for ADAS or AD systems in the automotive context, there is a need to systematically assess this new setup: LLMs entail a well-documented set of risks for safety-related systems' development due to their stochastic nature. To reduce the effort for code reviewers to evaluate LLM-generated code, we propose an evaluation pipeline to conduct sanity-checks on the generated code. We compare the performance of six state-of-the-art LLMs (CodeLlama, CodeGemma, DeepSeek-r1, DeepSeek-Coders, Mistral, and GPT-4) on four safety-related programming tasks. Additionally, we qualitatively analyse the most frequent faults generated by these LLMs, creating a failure-mode catalogue to support human reviewers. Finally, the limitations and capabilities of LLMs in code generation, and the use of the proposed pipeline in the existing process, are discussed.

---
layout: publication
title: On The Hardness Of Faithful Chain45;of45;thought Reasoning In Large Language Models
authors: Tanneru Sree Harsha, Ley Dan, Agarwal Chirag, Lakkaraju Himabindu
conference: "Arxiv"
year: 2024
bibkey: tanneru2024hardness
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.10625"}
tags: ['Applications', 'Interpretability And Explainability', 'Pretraining Methods', 'Reinforcement Learning']
---
As Large Language Models (LLMs) are increasingly being employed in real45;world applications in critical domains such as healthcare it is important to ensure that the Chain45;of45;Thought (CoT) reasoning generated by these models faithfully captures their underlying behavior. While LLMs are known to generate CoT reasoning that is appealing to humans prior studies have shown that these explanations do not accurately reflect the actual behavior of the underlying LLMs. In this work we explore the promise of three broad approaches commonly employed to steer the behavior of LLMs to enhance the faithfulness of the CoT reasoning generated by LLMs in45;context learning fine45;tuning and activation editing. Specifically we introduce novel strategies for in45;context learning fine45;tuning and activation editing aimed at improving the faithfulness of the CoT reasoning. We then carry out extensive empirical analyses with multiple benchmark datasets to explore the promise of these strategies. Our analyses indicate that these strategies offer limited success in improving the faithfulness of the CoT reasoning with only slight performance enhancements in controlled scenarios. Activation editing demonstrated minimal success while fine45;tuning and in45;context learning achieved marginal improvements that failed to generalize across diverse reasoning and truthful question45;answering benchmarks. In summary our work underscores the inherent difficulty in eliciting faithful CoT reasoning from LLMs suggesting that the current array of approaches may not be sufficient to address this complex challenge.

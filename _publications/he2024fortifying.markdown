---
layout: publication
title: Fortifying Ethical Boundaries in AI Advanced Strategies for Enhancing Security in Large Language Models
authors: He Yunhong, Qiu Jianling, Zhang Wei, Yuan Zhengqing
conference: "Arxiv"
year: 2024
bibkey: he2024fortifying
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.01725"}
tags: ['Applications', 'Efficiency And Optimization', 'Fairness', 'GPT', 'Language Modeling', 'Model Architecture', 'Pretraining Methods', 'Prompting', 'Security', 'Tools', 'Transformer']
---
Recent advancements in large language models (LLMs) have significantly enhanced capabilities in natural language processing and artificial intelligence. These models including GPT-3.5 and LLaMA-2 have revolutionized text generation translation and question-answering tasks due to the transformative Transformer model. Despite their widespread use LLMs present challenges such as ethical dilemmas when models are compelled to respond inappropriately susceptibility to phishing attacks and privacy violations. This paper addresses these challenges by introducing a multi-pronged approach that includes 1) filtering sensitive vocabulary from user input to prevent unethical responses; 2) detecting role-playing to halt interactions that could lead to prison break scenarios; 3) implementing custom rule engines to restrict the generation of prohibited content; and 4) extending these methodologies to various LLM derivatives like Multi-Model Large Language Models (MLLMs). Our approach not only fortifies models against unethical manipulations and privacy breaches but also maintains their high performance across tasks. We demonstrate state-of-the-art performance under various attack prompts without compromising the models core functionalities. Furthermore the introduction of differentiated security levels empowers users to control their personal data disclosure. Our methods contribute to reducing social risks and conflicts arising from technological abuse enhance data protection and promote social equity. Collectively this research provides a framework for balancing the efficiency of question-answering systems with user privacy and ethical standards ensuring a safer user experience and fostering trust in AI technology.

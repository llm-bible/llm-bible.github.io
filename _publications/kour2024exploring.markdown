---
layout: publication
title: Exploring Straightforward Conversational Red45;teaming
authors: Kour George, Zwerdling Naama, Zalmanovici Marcel, Anaby-tavor Ateret, Fandina Ora Nova, Farchi Eitan
conference: "Arxiv"
year: 2024
bibkey: kour2024exploring
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2409.04822"}
tags: ['Applications', 'Security']
---
Large language models (LLMs) are increasingly used in business dialogue systems but they pose security and ethical risks. Multi45;turn conversations where context influences the models behavior can be exploited to produce undesired responses. In this paper we examine the effectiveness of utilizing off45;the45;shelf LLMs in straightforward red45;teaming approaches where an attacker LLM aims to elicit undesired output from a target LLM comparing both single45;turn and conversational red45;teaming tactics. Our experiments offer insights into various usage strategies that significantly affect their performance as red teamers. They suggest that off45;the45;shelf models can act as effective red teamers and even adjust their attack strategy based on past attempts although their effectiveness decreases with greater alignment.

---
layout: publication
title: 'Explainable Sentiment Analysis With Deepseek-r1: Performance, Efficiency, And Few-shot Learning'
authors: Donghao Huang, Zhaoxia Wang
conference: "Arxiv"
year: 2025
bibkey: huang2025explainable
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2503.11655"}
tags: ['Efficiency and Optimization', 'GPT', 'Interpretability and Explainability', 'Model Architecture', 'Reinforcement Learning', 'Interpretability', 'Few-Shot', 'Prompting', 'In-Context Learning']
---
Recent advancements in large language models (LLMs) have significantly
enhanced sentiment analysis capabilities. However, the trade-offs between model
performance, efficiency, and explainability of some latest models remain
underexplored. This study presents the first comprehensive evaluation of the
DeepSeek-R1 series of models, reasoning open-source LLMs, for sentiment
analysis, comparing them against OpenAI's GPT-4 and GPT-4-mini. We
systematically analyze their performance under few-shot prompting conditions,
scaling up to 50-shot configurations to assess in-context learning
effectiveness. Our experiments reveal that DeepSeek-R1 demonstrates competitive
accuracy, particularly in multi-class sentiment tasks, while offering enhanced
interpretability through its detailed reasoning process. Additionally, we
highlight the impact of increasing few-shot examples on model performance and
discuss key trade-offs between explainability and computational efficiency.

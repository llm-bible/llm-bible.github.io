---
layout: publication
title: 'Evaluating Book Summaries From Internal Knowledge In Large Language Models: A Cross-model And Semantic Consistency Approach'
authors: Javier Coronado-blázquez
conference: "Arxiv"
year: 2025
bibkey: coronadoblázquez2025evaluating
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2503.21613'}
tags: ['Ethics and Bias', 'BERT', 'Applications', 'Model Architecture']
---
We study the ability of large language models (LLMs) to generate
comprehensive and accurate book summaries solely from their internal knowledge,
without recourse to the original text. Employing a diverse set of books and
multiple LLM architectures, we examine whether these models can synthesize
meaningful narratives that align with established human interpretations.
Evaluation is performed with a LLM-as-a-judge paradigm: each AI-generated
summary is compared against a high-quality, human-written summary via a
cross-model assessment, where all participating LLMs evaluate not only their
own outputs but also those produced by others. This methodology enables the
identification of potential biases, such as the proclivity for models to favor
their own summarization style over others. In addition, alignment between the
human-crafted and LLM-generated summaries is quantified using ROUGE and
BERTScore metrics, assessing the depth of grammatical and semantic
correspondence. The results reveal nuanced variations in content representation
and stylistic preferences among the models, highlighting both strengths and
limitations inherent in relying on internal knowledge for summarization tasks.
These findings contribute to a deeper understanding of LLM internal encodings
of factual information and the dynamics of cross-model evaluation, with
implications for the development of more robust natural language generative
systems.

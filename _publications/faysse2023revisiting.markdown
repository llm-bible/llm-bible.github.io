---
layout: publication
title: 'Revisiting Instruction Fine-tuned Model Evaluation To Guide Industrial Applications'
authors: Manuel Faysse, Gautier Viaud, CÃ©line Hudelot, Pierre Colombo
conference: "2023.emnlp-main.559"
year: 2023
bibkey: faysse2023revisiting
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.14103"}
tags: ['Fine-Tuning', 'Applications', 'RAG', 'Reinforcement Learning', 'Training Techniques', 'Pretraining Methods']
---
Instruction Fine-Tuning (IFT) is a powerful paradigm that strengthens the
zero-shot capabilities of Large Language Models (LLMs), but in doing so induces
new evaluation metric requirements. We show LLM-based metrics to be well
adapted to these requirements, and leverage them to conduct an investigation of
task-specialization strategies, quantifying the trade-offs that emerge in
practical industrial settings. Our findings offer practitioners actionable
insights for real-world IFT model deployment.

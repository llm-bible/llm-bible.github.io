---
layout: publication
title: 'Trapped By Expectations: Functional Fixedness In Llm-enabled Chat Search'
authors: Jiqun Liu, Jamshed Karimnazarov, Ryen W. White
conference: "Arxiv"
year: 2025
bibkey: liu2025trapped
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2504.02074'}
tags: ['GPT', 'Model Architecture', 'Fine-Tuning', 'Prompting', 'Reinforcement Learning', 'Ethics and Bias', 'Responsible AI']
---
Functional fixedness, a cognitive bias that restricts users' interactions
with a new system or tool to expected or familiar ways, limits the full
potential of Large Language Model (LLM)-enabled chat search, especially in
complex and exploratory tasks. To investigate its impact, we conducted a
crowdsourcing study with 450 participants, each completing one of six
decision-making tasks spanning public safety, diet and health management,
sustainability, and AI ethics. Participants engaged in a multi-prompt
conversation with ChatGPT to address the task, allowing us to compare pre-chat
intent-based expectations with observed interactions. We found that: 1) Several
aspects of pre-chat expectations are closely associated with users' prior
experiences with ChatGPT, search engines, and virtual assistants; 2) Prior
system experience shapes language use and prompting behavior. Frequent ChatGPT
users reduced deictic terms and hedge words and frequently adjusted prompts.
Users with rich search experience maintained structured, less-conversational
queries with minimal modifications. Users of virtual assistants favored
directive, command-like prompts, reinforcing functional fixedness; 3) When the
system failed to meet expectations, participants generated more detailed
prompts with increased linguistic diversity, reflecting adaptive shifts. These
findings suggest that while preconceived expectations constrain early
interactions, unmet expectations can motivate behavioral adaptation. With
appropriate system support, this may promote broader exploration of LLM
capabilities. This work also introduces a typology for user intents in chat
search and highlights the importance of mitigating functional fixedness to
support more creative and analytical use of LLMs.

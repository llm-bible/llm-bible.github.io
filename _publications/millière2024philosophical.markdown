---
layout: publication
title: 'A Philosophical Introduction To Language Models - Part II: The Way Forward'
authors: Raphaël Millière, Cameron Buckner
conference: "Arxiv"
year: 2024
bibkey: millière2024philosophical
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2405.03207'}
tags: ['Reinforcement Learning', 'Interpretability and Explainability', 'Multimodal Models']
---
In this paper, the second of two companion pieces, we explore novel
philosophical questions raised by recent progress in large language models
(LLMs) that go beyond the classical debates covered in the first part. We focus
particularly on issues related to interpretability, examining evidence from
causal intervention methods about the nature of LLMs' internal representations
and computations. We also discuss the implications of multimodal and modular
extensions of LLMs, recent debates about whether such systems may meet minimal
criteria for consciousness, and concerns about secrecy and reproducibility in
LLM research. Finally, we discuss whether LLM-like systems may be relevant to
modeling aspects of human cognition, if their architectural characteristics and
learning scenario are adequately constrained.

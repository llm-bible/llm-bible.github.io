---
layout: publication
title: 'Large Language Models For Ingredient Substitution In Food Recipes Using Supervised Fine-tuning And Direct Preference Optimization'
authors: Thevin Senath, Kumuthu Athukorala, Ransika Costa, Surangika Ranathunga, Rishemjit Kaur
conference: "Arxiv"
year: 2024
bibkey: senath2024large
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2412.04922"}
tags: ['Efficiency and Optimization', 'Training Techniques', 'Reinforcement Learning', 'Pretraining Methods', 'Fine-Tuning', 'Prompting']
---
In this paper, we address the challenge of recipe personalization through
ingredient substitution. We make use of Large Language Models (LLMs) to build
an ingredient substitution system designed to predict plausible substitute
ingredients within a given recipe context. Given that the use of LLMs for this
task has been barely done, we carry out an extensive set of experiments to
determine the best LLM, prompt, and the fine-tuning setups. We further
experiment with methods such as multi-task learning, two-stage fine-tuning, and
Direct Preference Optimization (DPO). The experiments are conducted using the
publicly available Recipe1MSub corpus. The best results are produced by the
Mistral7-Base LLM after fine-tuning and DPO. This result outperforms the strong
baseline available for the same corpus with a Hit@1 score of 22.04. Thus we
believe that this research represents a significant step towards enabling
personalized and creative culinary experiences by utilizing LLM-based
ingredient substitution.

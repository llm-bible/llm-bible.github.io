---
layout: publication
title: 'What If Red Can Talk? Dynamic Dialogue Generation Using Large Language Models'
authors: Nananukul Navapat, Wongkamjan Wichayaporn
conference: "Arxiv"
year: 2024
bibkey: nananukul2024what
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.20382"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Reinforcement Learning', 'Tools']
---
Role-playing games (RPGs) provide players with a rich, interactive world to explore. Dialogue serves as the primary means of communication between developers and players, manifesting in various forms such as guides, NPC interactions, and storytelling. While most games rely on written scripts to define the main story and character personalities, player immersion can be significantly enhanced through casual interactions between characters. With the advent of large language models (LLMs), we introduce a dialogue filler framework that utilizes LLMs enhanced by knowledge graphs to generate dynamic and contextually appropriate character interactions. We test this framework within the environments of Final Fantasy VII Remake and Pokemon, providing qualitative and quantitative evidence that demonstrates GPT-4's capability to act with defined personalities and generate dialogue. However, some flaws remain, such as GPT-4 being overly positive or more subtle personalities, such as maturity, tend to be of lower quality compared to more overt traits like timidity. This study aims to assist developers in crafting more nuanced filler dialogues, thereby enriching player immersion and enhancing the overall RPG experience.

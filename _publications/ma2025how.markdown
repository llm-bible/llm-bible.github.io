---
layout: publication
title: 'How Good Are Large Language Models For Course Recommendation In Moocs?'
authors: Boxuan Ma, Md Akib Zabed Khan, Tianyuan Yang, Agoritsa Polyzou, Shin'ichi Konomi
conference: "Arxiv"
year: 2025
bibkey: ma2025how
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2504.08208"}
tags: ['Training Techniques', 'Reinforcement Learning', 'RAG', 'Pretraining Methods', 'Fine-Tuning', 'Prompting']
---
Large Language Models (LLMs) have made significant strides in natural
language processing and are increasingly being integrated into recommendation
systems. However, their potential in educational recommendation systems has yet
to be fully explored. This paper investigates the use of LLMs as a
general-purpose recommendation model, leveraging their vast knowledge derived
from large-scale corpora for course recommendation tasks. We explore a variety
of approaches, ranging from prompt-based methods to more advanced fine-tuning
techniques, and compare their performance against traditional recommendation
models. Extensive experiments were conducted on a real-world MOOC dataset,
evaluating using LLMs as course recommendation systems across key dimensions
such as accuracy, diversity, and novelty. Our results demonstrate that LLMs can
achieve good performance comparable to traditional models, highlighting their
potential to enhance educational recommendation systems. These findings pave
the way for further exploration and development of LLM-based approaches in the
context of educational recommendations.

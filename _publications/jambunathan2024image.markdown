---
layout: publication
title: 'Convnlp: Image-based AI Text Detection'
authors: Suriya Prakash Jambunathan, Ashwath Shankarnarayan, Parijat Dube
conference: "Arxiv"
year: 2024
bibkey: jambunathan2024image
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.07225"}
tags: ['Tools', 'GPT', 'RAG', 'Model Architecture', 'Reinforcement Learning']
---
The potentials of Generative-AI technologies like Large Language models
(LLMs) to revolutionize education are undermined by ethical considerations
around their misuse which worsens the problem of academic dishonesty. LLMs like
GPT-4 and Llama 2 are becoming increasingly powerful in generating
sophisticated content and answering questions, from writing academic essays to
solving complex math problems. Students are relying on these LLMs to complete
their assignments and thus compromising academic integrity. Solutions to detect
LLM-generated text are compute-intensive and often lack generalization. This
paper presents a novel approach for detecting LLM-generated AI-text using a
visual representation of word embedding. We have formulated a novel
Convolutional Neural Network called ZigZag ResNet, as well as a scheduler for
improving generalization, named ZigZag Scheduler. Through extensive evaluation
using datasets of text generated by six different state-of-the-art LLMs, our
model demonstrates strong intra-domain and inter-domain generalization
capabilities. Our best model detects AI-generated text with an impressive
average detection rate (over inter- and intra-domain test data) of 88.35%.
Through an exhaustive ablation study, our ZigZag ResNet and ZigZag Scheduler
provide a performance improvement of nearly 4% over the vanilla ResNet. The
end-to-end inference latency of our model is below 2.5ms per sentence. Our
solution offers a lightweight, computationally efficient, and faster
alternative to existing tools for AI-generated text detection, with better
generalization performance. It can help academic institutions in their fight
against the misuse of LLMs in academic settings. Through this work, we aim to
contribute to safeguarding the principles of academic integrity and ensuring
the trustworthiness of student work in the era of advanced LLMs.

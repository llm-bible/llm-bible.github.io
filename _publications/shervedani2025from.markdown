---
layout: publication
title: 'From Vague Instructions To Task Plans: A Feedback-driven HRC Task Planning Framework Based On Llms'
authors: Afagh Mehri Shervedani, Matthew R. Walter, Milos Zefran
conference: "Arxiv"
year: 2025
bibkey: shervedani2025from
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2503.01007'}
tags: ['Prompting', 'Tools']
---
Recent advances in large language models (LLMs) have demonstrated their
potential as planners in human-robot collaboration (HRC) scenarios, offering a
promising alternative to traditional planning methods. LLMs, which can generate
structured plans by reasoning over natural language inputs, have the ability to
generalize across diverse tasks and adapt to human instructions. This paper
investigates the potential of LLMs to facilitate planning in the context of
human-robot collaborative tasks, with a focus on their ability to reason from
high-level, vague human inputs, and fine-tune plans based on real-time
feedback. We propose a novel hybrid framework that combines LLMs with human
feedback to create dynamic, context-aware task plans. Our work also highlights
how a single, concise prompt can be used for a wide range of tasks and
environments, overcoming the limitations of long, detailed structured prompts
typically used in prior studies. By integrating user preferences into the
planning loop, we ensure that the generated plans are not only effective but
aligned with human intentions.

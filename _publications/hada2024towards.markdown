---
layout: publication
title: METAL Towards Multilingual Meta45;evaluation
authors: Hada Rishav, Gumma Varun, Ahmed Mohamed, Bali Kalika, Sitaram Sunayana
conference: "Arxiv"
year: 2024
bibkey: hada2024towards
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.01667"}
tags: ['Applications', 'Ethics And Bias', 'GPT', 'Model Architecture', 'Reinforcement Learning', 'Tools']
---
With the rising human45;like precision of Large Language Models (LLMs) in numerous tasks their utilization in a variety of real45;world applications is becoming more prevalent. Several studies have shown that LLMs excel on many standard NLP benchmarks. However it is challenging to evaluate LLMs due to test dataset contamination and the limitations of traditional metrics. Since human evaluations are difficult to collect there is a growing interest in the community to use LLMs themselves as reference45;free evaluators for subjective metrics. However past work has shown that LLM45;based evaluators can exhibit bias and have poor alignment with human judgments. In this study we propose a framework for an end45;to45;end assessment of LLMs as evaluators in multilingual scenarios. We create a carefully curated dataset covering 10 languages containing native speaker judgments for the task of summarization. This dataset is created specifically to evaluate LLM45;based evaluators which we refer to as meta45;evaluation (METAL). We compare the performance of LLM45;based evaluators created using GPT45;3.545;Turbo GPT45;4 and PaLM2. Our results indicate that LLM45;based evaluators based on GPT45;4 perform the best across languages while GPT45;3.545;Turbo performs poorly. Additionally we perform an analysis of the reasoning provided by LLM45;based evaluators and find that it often does not match the reasoning provided by human judges.

---
layout: publication
title: 'Integrating Cognitive Processing Signals Into Language Models: A Review Of Advances, Applications And Future Directions'
authors: Angela Lopez-cardona, Sebastian Idesis, Ioannis Arapakis
conference: "Arxiv"
year: 2025
bibkey: lopezcardona2025integrating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2504.06843"}
tags: ['Multimodal Models', 'Training Techniques', 'Model Architecture', 'Survey Paper', 'Reinforcement Learning', 'RAG', 'Merging', 'Applications', 'Attention Mechanism']
---
Recently, the integration of cognitive neuroscience in Natural Language
Processing (NLP) has gained significant attention. This article provides a
critical and timely overview of recent advancements in leveraging cognitive
signals, particularly Eye-tracking (ET) signals, to enhance Language Models
(LMs) and Multimodal Large Language Models (MLLMs). By incorporating
user-centric cognitive signals, these approaches address key challenges,
including data scarcity and the environmental costs of training large-scale
models. Cognitive signals enable efficient data augmentation, faster
convergence, and improved human alignment. The review emphasises the potential
of ET data in tasks like Visual Question Answering (VQA) and mitigating
hallucinations in MLLMs, and concludes by discussing emerging challenges and
research trends.

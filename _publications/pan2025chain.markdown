---
layout: publication
title: 'Coat: Chain-of-associated-thoughts Framework For Enhancing Large Language Models Reasoning'
authors: Jianfeng Pan, Senyou Deng, Shaomang Huang
conference: "Arxiv"
year: 2025
bibkey: pan2025chain
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2502.02390'}
tags: ['Attention Mechanism', 'Model Architecture', 'Tools', 'Merging', 'Fine-Tuning', 'Reinforcement Learning']
---
Research on LLM technologies is rapidly emerging, with most of them employing
a 'fast thinking' approach to inference. Most LLMs generate the final result
based solely on a single query and LLM's reasoning capabilities. However, with
the advent of OpenAI-o1, 'slow thinking' techniques have garnered increasing
attention because its process is closer to the human thought process. Inspired
by the human ability to constantly associate and replenish knowledge during
thinking, we developed the novel Chain-of-Associated-Thoughts (CoAT) framework,
which introduces an innovative synergy between the Monte Carlo Tree Search
(MCTS) algorithm and a dynamic mechanism for integrating new key information,
termed 'associative memory'. By combining the structured exploration
capabilities of MCTS with the adaptive learning capacity of associative memory,
CoAT significantly expands the LLM search space, enabling our framework to
explore diverse reasoning pathways and dynamically update its knowledge base in
real-time. This allows the framework to not only revisit and refine earlier
inferences but also adaptively incorporate evolving information, ensuring that
the final output is both accurate and comprehensive. To validate the
effectiveness of our framework, we conducted extensive experiments across a
range of generative and reasoning tasks. These experiments demonstrated that
our framework outperforms conventional inference processes on accuracy,
coherence, and diversity. The framework's ability to iteratively expand its
search space while retaining contextually relevant information results.

---
layout: publication
title: An Automatically Discovered Chain45;of45;thought Prompt Generalizes To Novel Models And Datasets
authors: Hebenstreit Konstantin, Praas Robert, Kiesewetter Louis P, Samwald Matthias
conference: "Arxiv"
year: 2023
bibkey: hebenstreit2023automatically
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2305.02897"}
tags: ['GPT', 'Interpretability And Explainability', 'Model Architecture', 'Prompting']
---
Emergent chain45;of45;thought (CoT) reasoning capabilities promise to improve performance and explainability of large language models (LLMs). However uncertainties remain about how reasoning strategies formulated for previous model generations generalize to new model generations and different datasets. In this small45;scale study we compare different reasoning strategies induced by zero45;shot prompting across six recently released LLMs (davinci45;002 davinci45;003 GPT45;3.545;turbo GPT45;4 Flan45;T545;xxl and Cohere command45;xlarge) on a mixture of six question45;answering datasets including datasets from scientific and medical domains. Our findings demonstrate that while some variations in effectiveness occur gains from CoT reasoning strategies remain robust across different models and datasets. GPT45;4 has the most benefit from current state45;of45;the45;art reasoning strategies and exhibits the best performance by applying a prompt previously discovered through automated discovery.

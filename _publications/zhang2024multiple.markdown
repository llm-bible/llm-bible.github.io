---
layout: publication
title: Multiple45;choice Questions Are Efficient And Robust LLM Evaluators
authors: Zhang Ziyin, Jiang Zhaokun, Xu Lizhen, Hao Hongkun, Wang Rui
conference: "Arxiv"
year: 2024
bibkey: zhang2024multiple
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.11966"}
  - {name: "Code", url: "https://github.com/Geralt&#45;Targaryen/MC&#45;Evaluation"}
tags: ['Has Code', 'Model Architecture']
---
We present GSM45;MC a multiple45;choice (MC) dataset constructed by collecting answers and incorrect predictions on GSM8K from 60 open45;source models. Through extensive experiments we show that LLMs performance on the MC version of this popular benchmark is strongly correlated with their performance on the original version and is quite robust to distractor choices and option orders while the evaluation time is reduced by a factor of up to 30. Following similar procedures we introduce MATH45;MC constructed from MATH and PythonIO a new program reasoning MC dataset constructed from HumanEval and MBPP. Experimental results indicate that LLMs performance on these MC benchmarks leaves much room for improvement. Our data and code are available at https://github.com/Geralt&#45;Targaryen/MC&#45;Evaluation.

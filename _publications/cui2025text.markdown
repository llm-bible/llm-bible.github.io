---
layout: publication
title: 'TALES: Text Adventure Learning Environment Suite'
authors: Christopher Zhang Cui, Xingdi Yuan, Ziang Xiao, Prithviraj Ammanabrolu, Marc-alexandre Côté
conference: "Arxiv"
year: 2025
bibkey: cui2025text
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2504.14128'}
  - {name: "Code", url: 'https://microsoft.github.io/tale-suite'}
tags: ['Reinforcement Learning', 'Agentic', 'Has Code']
---
Reasoning is an essential skill to enable Large Language Models (LLMs) to
interact with the world. As tasks become more complex, they demand increasingly
sophisticated and diverse reasoning capabilities for sequential
decision-making, requiring structured reasoning over the context history to
determine the next best action. We introduce TALES, a diverse collection of
synthetic and human-written text-adventure games designed to challenge and
evaluate diverse reasoning capabilities. We present results over a range of
LLMs, open- and closed-weights, performing a qualitative analysis on the top
performing models. Despite an impressive showing on synthetic games, even the
top LLM-driven agents fail to achieve 15% on games designed for human
enjoyment. Code and visualization of the experiments can be found at
https://microsoft.github.io/tale-suite.

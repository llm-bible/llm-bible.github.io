---
layout: publication
title: 'Shaping Shared Languages: Human And Large Language Models'' Inductive Biases In Emergent Communication'
authors: Tom Kouwenhoven, Max Peeperkorn, Roy De Kleijn, Tessa Verhoef
conference: "Arxiv"
year: 2025
bibkey: kouwenhoven2025shaping
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2503.04395'}
tags: ['Reinforcement Learning', 'Ethics and Bias', 'Training Techniques', 'Tools']
---
Languages are shaped by the inductive biases of their users. Using a classical referential game, we investigate how artificial languages evolve when optimised for inductive biases in humans and large language models (LLMs) via Human-Human, LLM-LLM and Human-LLM experiments. We show that referentially grounded vocabularies emerge that enable reliable communication in all conditions, even when humans \textit\{and\} LLMs collaborate. Comparisons between conditions reveal that languages optimised for LLMs subtly differ from those optimised for humans. Interestingly, interactions between humans and LLMs alleviate these differences and result in vocabularies more human-like than LLM-like. These findings advance our understanding of the role inductive biases in LLMs play in the dynamic nature of human language and contribute to maintaining alignment in human and machine communication. In particular, our work underscores the need to think of new LLM training methods that include human interaction and shows that using communicative success as a reward signal can be a fruitful, novel direction.

---
layout: publication
title: 'Prompto: An Open Source Library For Asynchronous Querying Of LLM Endpoints'
authors: Ryan Sze-yin Chan, Federico Nanni, Angus R. Williams, Edwin Brown, Liam Burke-moore, Ed Chapman, Kate Onslow, Tvesha Sippy, Jonathan Bright, Evelina Gabasova
conference: "Arxiv"
year: 2024
bibkey: chan2024open
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.11847"}
  - {name: "Code", url: "https://youtu.be/lWN9hXBOLyQ)"}
  - {name: "Code", url: "https://github.com/alan-turing-institute/prompto)"}
tags: ['Tools', 'Efficiency and Optimization', 'Reinforcement Learning', 'Has Code', 'Prompting']
---
Recent surge in Large Language Model (LLM) availability has opened exciting
avenues for research. However, efficiently interacting with these models
presents a significant hurdle since LLMs often reside on proprietary or
self-hosted API endpoints, each requiring custom code for interaction.
Conducting comparative studies between different models can therefore be
time-consuming and necessitate significant engineering effort, hindering
research efficiency and reproducibility. To address these challenges, we
present prompto, an open source Python library which facilitates asynchronous
querying of LLM endpoints enabling researchers to interact with multiple LLMs
concurrently, while maximising efficiency and utilising individual rate limits.
Our library empowers researchers and developers to interact with LLMs more
effectively and allowing faster experimentation, data generation and
evaluation. prompto is released with an introductory video
(https://youtu.be/lWN9hXBOLyQ) under MIT License and is available via GitHub
(https://github.com/alan-turing-institute/prompto).

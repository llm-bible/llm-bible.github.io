---
layout: publication
title: Tell Me Why Explainable Public Health Fact45;checking With Large Language Models
authors: Zarharan Majid, Wullschleger Pascal, Kia Babak Behkam, Pilehvar Mohammad Taher, Foster Jennifer
conference: "Arxiv"
year: 2024
bibkey: zarharan2024tell
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.09454"}
tags: ['GPT', 'Interpretability And Explainability', 'Model Architecture', 'Prompting']
---
This paper presents a comprehensive analysis of explainable fact45;checking through a series of experiments focusing on the ability of large language models to verify public health claims and provide explanations or justifications for their veracity assessments. We examine the effectiveness of zero/few45;shot prompting and parameter45;efficient fine45;tuning across various open and closed45;source models examining their performance in both isolated and joint tasks of veracity prediction and explanation generation. Importantly we employ a dual evaluation approach comprising previously established automatic metrics and a novel set of criteria through human evaluation. Our automatic evaluation indicates that within the zero45;shot scenario GPT45;4 emerges as the standout performer but in few45;shot and parameter45;efficient fine45;tuning contexts open45;source models demonstrate their capacity to not only bridge the performance gap but in some instances surpass GPT45;4. Human evaluation reveals yet more nuance as well as indicating potential problems with the gold explanations.

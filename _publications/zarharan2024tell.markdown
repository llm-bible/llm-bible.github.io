---
layout: publication
title: 'Tell Me Why: Explainable Public Health Fact-checking With Large Language Models'
authors: Zarharan Majid, Wullschleger Pascal, Kia Babak Behkam, Pilehvar Mohammad Taher, Foster Jennifer
conference: "Arxiv"
year: 2024
bibkey: zarharan2024tell
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.09454"}
tags: ['Few Shot', 'Fine Tuning', 'GPT', 'In Context Learning', 'Interpretability And Explainability', 'Model Architecture', 'Pretraining Methods', 'Prompting', 'Training Techniques']
---
This paper presents a comprehensive analysis of explainable fact-checking
through a series of experiments, focusing on the ability of large language
models to verify public health claims and provide explanations or
justifications for their veracity assessments. We examine the effectiveness of
zero/few-shot prompting and parameter-efficient fine-tuning across various open
and closed-source models, examining their performance in both isolated and
joint tasks of veracity prediction and explanation generation. Importantly, we
employ a dual evaluation approach comprising previously established automatic
metrics and a novel set of criteria through human evaluation. Our automatic
evaluation indicates that, within the zero-shot scenario, GPT-4 emerges as the
standout performer, but in few-shot and parameter-efficient fine-tuning
contexts, open-source models demonstrate their capacity to not only bridge the
performance gap but, in some instances, surpass GPT-4. Human evaluation reveals
yet more nuance as well as indicating potential problems with the gold
explanations.

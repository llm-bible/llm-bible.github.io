---
layout: publication
title: From Text To Emotion\: Unveiling The Emotion Annotation Capabilities Of Llms
authors: Niu Minxue, Jaiswal Mimansa, Provost Emily Mower
conference: "Arxiv"
year: 2024
bibkey: niu2024from
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.17026"}
tags: ['GPT', 'Model Architecture', 'Pretraining Methods', 'Training Techniques']
---
Training emotion recognition models has relied heavily on human annotated data which present diversity quality and cost challenges. In this paper we explore the potential of Large Language Models (LLMs) specifically GPT4 in automating or assisting emotion annotation. We compare GPT4 with supervised models and or humans in three aspects agreement with human annotations alignment with human perception and impact on model training. We find that common metrics that use aggregated human annotations as ground truth can underestimate the performance of GPT-4 and our human evaluation experiment reveals a consistent preference for GPT-4 annotations over humans across multiple datasets and evaluators. Further we investigate the impact of using GPT-4 as an annotation filtering process to improve model training. Together our findings highlight the great potential of LLMs in emotion annotation tasks and underscore the need for refined evaluation methodologies.

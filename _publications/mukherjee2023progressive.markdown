---
layout: publication
title: Orca\: Progressive Learning From Complex Explanation Traces Of GPT-4
authors: Mukherjee Subhabrata, Mitra Arindam, Jawahar Ganesh, Agarwal Sahaj, Palangi Hamid, Awadallah Ahmed
conference: "Arxiv"
year: 2023
bibkey: mukherjee2023progressive
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2306.02707"}
tags: ['Ethics And Bias', 'GPT', 'Interpretability And Explainability', 'Model Architecture', 'Training Techniques']
---
Recent research has focused on enhancing the capability of smaller models through imitation learning drawing on the outputs generated by large foundation models (LFMs). A number of issues impact the quality of these models ranging from limited imitation signals from shallow LFM outputs; small scale homogeneous training data; and most notably a lack of rigorous evaluation resulting in overestimating the small models capability as they tend to learn to imitate the style but not the reasoning process of LFMs. To address these challenges we develop Orca (We are working with our legal team to publicly release a diff of the model weights in accordance with LLaMAs release policy to be published at https://aka.ms/orca-lm), a 13-billion parameter model that learns to imitate the reasoning process of LFMs. Orca learns from rich signals from GPT-4 including explanation traces; step-by-step thought processes; and other complex instructions guided by teacher assistance from ChatGPT. To promote this progressive learning we tap into large-scale and diverse imitation data with judicious sampling and selection. Orca surpasses conventional state-of-the-art instruction-tuned models such as Vicuna-13B by more than 10037; in complex zero-shot reasoning benchmarks like Big-Bench Hard (BBH) and 4237; on AGIEval. Moreover Orca reaches parity with ChatGPT on the BBH benchmark and shows competitive performance (4 pts gap with optimized system message) in professional and academic examinations like the SAT LSAT GRE and GMAT both in zero-shot settings without CoT; while trailing behind GPT-4. Our research indicates that learning from step-by-step explanations whether these are generated by humans or more advanced AI models is a promising direction to improve model capabilities and skills.

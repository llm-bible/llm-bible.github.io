---
layout: publication
title: 'How Do Programming Students Use Generative AI?'
authors: Christian Rahe, Walid Maalej
conference: "Proc. ACM Softw. Eng. 2 FSE Article FSE045 (July 2025)"
year: 2025
bibkey: rahe2025how
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2501.10091"}
tags: ['Fine-Tuning', 'Tools', 'GPT', 'Model Architecture', 'Reinforcement Learning', 'Prompting']
---
Programming students have a widespread access to powerful Generative AI tools
like ChatGPT. While this can help understand the learning material and assist
with exercises, educators are voicing more and more concerns about an
overreliance on generated outputs and lack of critical thinking skills. It is
thus important to understand how students actually use generative AI and what
impact this could have on their learning behavior. To this end, we conducted a
study including an exploratory experiment with 37 programming students, giving
them monitored access to ChatGPT while solving a code authoring exercise. The
task was not directly solvable by ChatGPT and required code comprehension and
reasoning. While only 23 of the students actually opted to use the chatbot, the
majority of those eventually prompted it to simply generate a full solution. We
observed two prevalent usage strategies: to seek knowledge about general
concepts and to directly generate solutions. Instead of using the bot to
comprehend the code and their own mistakes, students often got trapped in a
vicious cycle of submitting wrong generated code and then asking the bot for a
fix. Those who self-reported using generative AI regularly were more likely to
prompt the bot to generate a solution. Our findings indicate that concerns
about potential decrease in programmers' agency and productivity with
Generative AI are justified. We discuss how researchers and educators can
respond to the potential risk of students uncritically over-relying on
Generative AI. We also discuss potential modifications to our study design for
large-scale replications.

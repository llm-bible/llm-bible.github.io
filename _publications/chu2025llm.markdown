---
layout: publication
title: 'LLM Agents For Education: Advances And Applications'
authors: Zhendong Chu, Shen Wang, Jian Xie, Tinghui Zhu, Yibo Yan, Jinheng Ye, Aoxiao Zhong, Xuming Hu, Jing Liang, Philip S. Yu, Qingsong Wen
conference: "Arxiv"
year: 2025
bibkey: chu2025llm
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2503.11733'}
tags: ['Agentic', 'Fairness', 'Applications', 'Tools', 'Survey Paper', 'Bias Mitigation', 'Reinforcement Learning', 'Ethics and Bias']
---
Large Language Model (LLM) agents have demonstrated remarkable capabilities
in automating tasks and driving innovation across diverse educational
applications. In this survey, we provide a systematic review of
state-of-the-art research on LLM agents in education, categorizing them into
two broad classes: (1) *Pedagogical Agents*, which focus on automating
complex pedagogical tasks to support both teachers and students; and (2)
*Domain-Specific Educational Agents*, which are tailored for specialized
fields such as science education, language learning, and professional
development. We comprehensively examine the technological advancements
underlying these LLM agents, including key datasets, benchmarks, and
algorithmic frameworks that drive their effectiveness. Furthermore, we discuss
critical challenges such as privacy, bias and fairness concerns, hallucination
mitigation, and integration with existing educational ecosystems. This survey
aims to provide a comprehensive technological overview of LLM agents for
education, fostering further research and collaboration to enhance their impact
for the greater good of learners and educators alike.

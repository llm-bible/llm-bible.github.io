---
layout: publication
title: Towards Robust Instruction Tuning On Multimodal Large Language Models
authors: Han Wei, Chen Hui, Poria Soujanya
conference: "Arxiv"
year: 2024
bibkey: han2024towards
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.14492"}
tags: ['Multimodal Models', 'Training Techniques']
---
Fine45;tuning large language models (LLMs) on multi45;task instruction45;following data has been proven to be a powerful learning paradigm for improving their zero45;shot capabilities on new tasks. Recent works about high45;quality instruction45;following data generation and selection require amounts of human labor to conceive model45;understandable instructions for the given tasks and carefully filter the LLM45;generated data. In this work we introduce an automatic instruction augmentation method named INSTRAUG in multimodal tasks. It starts from a handful of basic and straightforward meta instructions but can expand an instruction45;following dataset by 30 times. Results on two popular multimodal instructionfollowing benchmarks MULTIINSTRUCT and InstructBLIP show that INSTRAUG can significantly improve the alignment of multimodal large language models (MLLMs) across 12 multimodal tasks which is even equivalent to the benefits of scaling up training data multiple times.

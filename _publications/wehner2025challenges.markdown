---
layout: publication
title: 'Taxonomy, Opportunities, And Challenges Of Representation Engineering For Large Language Models'
authors: Jan Wehner, Sahar Abdelnabi, Daniel Tan, David Krueger, Mario Fritz
conference: "Arxiv"
year: 2025
bibkey: wehner2025challenges
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.19649"}
tags: ['Tools', 'Survey Paper', 'Reinforcement Learning']
---
Representation Engineering (RepE) is a novel paradigm for controlling the
behavior of LLMs. Unlike traditional approaches that modify inputs or fine-tune
the model, RepE directly manipulates the model's internal representations. As a
result, it may offer more effective, interpretable, data-efficient, and
flexible control over models' behavior. We present the first comprehensive
survey of RepE for LLMs, reviewing the rapidly growing literature to address
key questions: What RepE methods exist and how do they differ? For what
concepts and problems has RepE been applied? What are the strengths and
weaknesses of RepE compared to other methods? To answer these, we propose a
unified framework describing RepE as a pipeline comprising representation
identification, operationalization, and control. We posit that while RepE
methods offer significant potential, challenges remain, including managing
multiple concepts, ensuring reliability, and preserving models' performance.
Towards improving RepE, we identify opportunities for experimental and
methodological improvements and construct a guide for best practices.

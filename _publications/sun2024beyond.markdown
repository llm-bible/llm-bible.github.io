---
layout: publication
title: Beyond Text Utilizing Vocal Cues To Improve Decision Making In Llms For Robot Navigation Tasks
authors: Sun Xingpeng, Meng Haoming, Chakraborty Souradip, Bedi Amrit Singh, Bera Aniket
conference: "Arxiv"
year: 2024
bibkey: sun2024beyond
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.03494"}
tags: ['GPT', 'Model Architecture', 'Security']
---
While LLMs excel in processing text in these human conversations they struggle with the nuances of verbal instructions in scenarios like social navigation where ambiguity and uncertainty can erode trust in robotic and other AI systems. We can address this shortcoming by moving beyond text and additionally focusing on the paralinguistic features of these audio responses. These features are the aspects of spoken communication that do not involve the literal wording (lexical content) but convey meaning and nuance through how something is said. We present emph123;Beyond Text125;; an approach that improves LLM decision45;making by integrating audio transcription along with a subsection of these features which focus on the affect and more relevant in human45;robot conversations.This approach not only achieves a 70.2637; winning rate outperforming existing LLMs by 22.1637; to 48.3037; (gemini45;1.545;pro and gpt45;3.5 respectively) but also enhances robustness against token manipulation adversarial attacks highlighted by a 22.4437; less decrease ratio than the text45;only language model in winning rate. textit123;Beyond Text125; marks an advancement in social robot navigation and broader Human45;Robot interactions seamlessly integrating text45;based guidance with human45;audio45;informed language models.

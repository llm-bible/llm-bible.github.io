---
layout: publication
title: 'Integrating Text-to-music Models With Language Models: Composing Long Structured Music Pieces'
authors: Lilac Atassi
conference: "Arxiv"
year: 2024
bibkey: atassi2024integrating
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2410.00344'}
tags: ['Transformer', 'Model Architecture', 'Pretraining Methods']
---
Recent music generation methods based on transformers have a context window
of up to a minute. The music generated by these methods is largely unstructured
beyond the context window. With a longer context window, learning long-scale
structures from musical data is a prohibitively challenging problem. This paper
proposes integrating a text-to-music model with a large language model to
generate music with form. The papers discusses the solutions to the challenges
of such integration. The experimental results show that the proposed method can
generate 2.5-minute-long music that is highly structured, strongly organized,
and cohesive.

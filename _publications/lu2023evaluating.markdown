---
layout: publication
title: 'Mathvista: Evaluating Mathematical Reasoning Of Foundation Models In Visual Contexts'
authors: Lu Pan, Bansal Hritik, Xia Tony, Liu Jiacheng, Li Chunyuan, Hajishirzi Hannaneh, Cheng Hao, Chang Kai-wei, Galley Michel, Gao Jianfeng
conference: "Arxiv"
year: 2023
bibkey: lu2023evaluating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.02255"}
tags: ['Agentic', 'GPT', 'Model Architecture', 'Multimodal Models', 'Reinforcement Learning']
---
Large Language Models (LLMs) and Large Multimodal Models (LMMs) exhibit impressive problem-solving skills in many tasks and domains but their ability in mathematical reasoning in visual contexts has not been systematically studied. To bridge this gap we present MathVista a benchmark designed to combine challenges from diverse mathematical and visual tasks. It consists of 6141 examples derived from 28 existing multimodal datasets involving mathematics and 3 newly created datasets (i.e. IQTest FunctionQA and PaperQA). Completing these tasks requires fine-grained deep visual understanding and compositional reasoning which all state-of-the-art foundation models find challenging. With MathVista we have conducted a comprehensive quantitative evaluation of 12 prominent foundation models. The best-performing GPT-4V model achieves an overall accuracy of 49.937; substantially outperforming Bard the second-best performer by 15.137;. Our in-depth analysis reveals that the superiority of GPT-4V is mainly attributed to its enhanced visual perception and mathematical reasoning. However GPT-4V still falls short of human performance by 10.437; as it often struggles to understand complex figures and perform rigorous reasoning. This significant gap underscores the critical role that MathVista will play in the development of general-purpose AI agents capable of tackling mathematically intensive and visually rich real-world tasks. We further explore the new ability of self-verification the application of self-consistency and the interactive chatbot capabilities of GPT-4V highlighting its promising potential for future research. The project is available at https://mathvista.github.io/."

---
layout: publication
title: MAPO Advancing Multilingual Reasoning Through Multilingual Alignment45;as45;preference Optimization
authors: She Shuaijie, Zou Wei, Huang Shujian, Zhu Wenhao, Liu Xiang, Geng Xiang, Chen Jiajun
conference: "Arxiv"
year: 2024
bibkey: she2024advancing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.06838"}
tags: ['Efficiency And Optimization', 'Reinforcement Learning', 'Tools', 'Training Techniques']
---
Though reasoning abilities are considered language45;agnostic existing LLMs exhibit inconsistent reasoning abilities across different languages e.g. reasoning in the dominant language like English is superior to other languages due to the imbalance of multilingual training data. To enhance reasoning abilities in non45;dominant languages we propose a Multilingual45;Alignment45;as45;Preference Optimization framework (MAPO) aiming to align the reasoning processes in other languages with the dominant language. Specifically we harness an off45;the45;shelf translation model for the consistency between answers in non45;dominant and dominant languages which we adopt as the preference for optimization e.g. Direct Preference Optimization (DPO) or Proximal Policy Optimization (PPO). Experiments show that MAPO stably achieves significant improvements in the multilingual reasoning of various models on all three benchmarks (MSVAMP +16.237; MGSM +6.137; and MNumGLUESub +13.337;) with improved reasoning consistency across languages.

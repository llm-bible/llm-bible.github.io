---
layout: publication
title: Audiochatllama Towards General45;purpose Speech Abilities For Llms
authors: Fathullah Yassir, Wu Chunyang, Lakomkin Egor, Li Ke, Jia Junteng, Shangguan Yuan, Mahadeokar Jay, Kalinli Ozlem, Fuegen Christian, Seltzer Mike
conference: "Arxiv"
year: 2023
bibkey: fathullah2023towards
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2311.06753"}
tags: ['Applications', 'Prompting']
---
In this work we extend the instruction45;tuned Llama45;2 model with end45;to45;end general45;purpose speech processing and reasoning abilities while maintaining the wide range of original LLM capabilities without using any carefully curated paired data. The resulting end45;to45;end model named AudioChatLlama can utilize audio prompts as a replacement for text and sustain a conversation. Such a model also has extended cross45;modal capabilities such as being able to perform spoken question answering (QA) speech translation and audio summarization amongst many other closed and open45;domain tasks. This is unlike prior approaches in speech in which LLMs are extended to handle audio for a limited number of pre45;designated tasks. On both synthesized and recorded speech QA test sets evaluations show that our end45;to45;end approach is on par with or outperforms cascaded systems (speech recognizer + LLM) in terms of modeling the response to a prompt. Furthermore unlike cascades our approach can interchange text and audio modalities and intrinsically utilize prior context in a conversation to provide better results.

---
layout: publication
title: 'Agreemate: Teaching Llms To Haggle'
authors: Ainesh Chatterjee, Samuel Miller, Nithin Parepally
conference: "Arxiv"
year: 2024
bibkey: chatterjee2024teaching
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2412.18690'}
tags: ['Attention Mechanism', 'Agentic', 'Training Techniques', 'Tools', 'Model Architecture', 'Fine-Tuning', 'Prompting', 'Pretraining Methods']
---
We introduce AgreeMate, a framework for training Large Language Models (LLMs)
to perform strategic price negotiations through natural language. We apply
recent advances to a negotiation setting where two agents (i.e. buyer or
seller) use natural language to bargain on goods using coarse actions.
Specifically, we present the performance of Large Language Models when used as
agents within a decoupled (modular) bargaining architecture. We demonstrate
that using prompt engineering, fine-tuning, and chain-of-thought prompting
enhances model performance, as defined by novel metrics. We use attention
probing to show model attention to semantic relationships between tokens during
negotiations.

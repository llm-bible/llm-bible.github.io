---
layout: publication
title: 'A Survey Of Calibration Process For Black-box Llms'
authors: Liangru Xie, Hui Liu, Jingying Zeng, Xianfeng Tang, Yan Han, Chen Luo, Jing Huang, Zhen Li, Suhang Wang, Qi He
conference: "Arxiv"
year: 2024
bibkey: xie2024survey
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2412.12767"}
  - {name: "Code", url: "https://github.com/LiangruXie/Calibration-Process-in-Black-Box-LLMs"}
tags: ['Tools', 'Survey Paper', 'Has Code', 'Applications']
---
Large Language Models (LLMs) demonstrate remarkable performance in semantic
understanding and generation, yet accurately assessing their output reliability
remains a significant challenge. While numerous studies have explored
calibration techniques, they primarily focus on White-Box LLMs with accessible
parameters. Black-Box LLMs, despite their superior performance, pose heightened
requirements for calibration techniques due to their API-only interaction
constraints. Although recent researches have achieved breakthroughs in
black-box LLMs calibration, a systematic survey of these methodologies is still
lacking. To bridge this gap, we presents the first comprehensive survey on
calibration techniques for black-box LLMs. We first define the Calibration
Process of LLMs as comprising two interrelated key steps: Confidence Estimation
and Calibration. Second, we conduct a systematic review of applicable methods
within black-box settings, and provide insights on the unique challenges and
connections in implementing these key steps. Furthermore, we explore typical
applications of Calibration Process in black-box LLMs and outline promising
future research directions, providing new perspectives for enhancing
reliability and human-machine alignment. This is our GitHub link:
https://github.com/LiangruXie/Calibration-Process-in-Black-Box-LLMs

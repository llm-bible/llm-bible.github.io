---
layout: publication
title: UPAR A Kantian-inspired Prompting Framework For Enhancing Large Language Model Capabilities
authors: Geng Hejia, Xu Boxun, Li Peng
conference: "Arxiv"
year: 2023
bibkey: geng2023kantian
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.01441"}
tags: ['Few Shot', 'GPT', 'Interpretability And Explainability', 'Model Architecture', 'Prompting', 'Tools']
---
Large Language Models (LLMs) have demonstrated impressive inferential capabilities with numerous research endeavors devoted to enhancing this capacity through prompting. Despite these efforts a unified epistemological foundation is still conspicuously absent. Drawing inspiration from Kants a priori philosophy we propose the UPAR prompting framework designed to emulate the structure of human cognition within LLMs. The UPAR framework is delineated into four phases Understand Plan Act and Reflect enabling the extraction of structured information from complex contexts prior planning of solutions execution according to plan and self-reflection. This structure significantly augments the explainability and accuracy of LLM inference producing a human-understandable and inspectable inferential trajectory. Furthermore our work offers an epistemological foundation for existing prompting techniques allowing for a possible systematic integration of these methods. With GPT-4 our approach elevates the accuracy from COT baseline of 22.9237; to 58.3337; in a challenging subset of GSM8K and from 67.9137; to 75.4037; in the causal judgment task. Without using few-shot examples or external tools UPAR significantly outperforms existing prompting methods on SCIBENCH a challenging dataset containing collegiate-level mathematics chemistry and physics scientific problems.

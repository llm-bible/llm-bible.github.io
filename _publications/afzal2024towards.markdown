---
layout: publication
title: Towards Optimizing and Evaluating a Retrieval Augmented QA Chatbot using LLMs with Human in the Loop
authors: Afzal Anum, Kowsik Alexander, Fani Rajna, Matthes Florian
conference: "Arxiv"
year: 2024
bibkey: afzal2024towards
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.05925"}
tags: ['ARXIV', 'GPT', 'LLM', 'Model Architecture', 'Prompting', 'RAG', 'Reinforcement Learning', 'Tools']
---
Large Language Models have found application in various mundane and repetitive tasks including Human Resource (HR) support. We worked with the domain experts of SAP SE to develop an HR support chatbot as an efficient and effective tool for addressing employee inquiries. We inserted a human-in-the-loop in various parts of the development cycles such as dataset collection prompt optimization and evaluation of generated output. By enhancing the LLM-driven chatbots response quality and exploring alternative retrieval methods we have created an efficient scalable and flexible tool for HR professionals to address employee inquiries effectively. Our experiments and evaluation conclude that GPT-4 outperforms other models and can overcome inconsistencies in data through internal reasoning capabilities. Additionally through expert analysis we infer that reference-free evaluation metrics such as G-Eval and Prometheus demonstrate reliability closely aligned with that of human evaluation.

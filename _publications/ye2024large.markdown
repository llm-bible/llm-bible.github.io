---
layout: publication
title: Large Language Models As Hyper45;heuristics For Combinatorial Optimization
authors: Ye Haoran, Wang Jiarui, Cao Zhiguang, Berto Federico, Hua Chuanbo, Kim Haeyeon, Park Jinkyoo, Song Guojie
conference: "Arxiv"
year: 2024
bibkey: ye2024large
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.01145"}
  - {name: "Code", url: "https://github.com/ai4co/LLM&#45;as&#45;HH"}
tags: ['Efficiency And Optimization', 'Has Code', 'Merging', 'RAG']
---
The omnipresence of NP45;hard combinatorial optimization problems (COPs) compels domain experts to engage in trial45;and45;error heuristic design. The long45;standing endeavor of design automation has gained new momentum with the rise of large language models (LLMs). This paper introduces Language Hyper45;Heuristics (LHHs) an emerging variant of Hyper45;Heuristics that leverages LLMs for heuristic generation featuring minimal manual intervention and open45;ended heuristic spaces. To empower LHHs we present Reflective Evolution (ReEvo) a novel integration of evolutionary search for efficiently exploring the heuristic space and LLM reflections to provide verbal gradients within the space. Across five heterogeneous algorithmic types six different COPs and both white45;box and black45;box views of COPs ReEvo yields state45;of45;the45;art and competitive meta45;heuristics evolutionary algorithms heuristics and neural solvers while being more sample45;efficient than prior LHHs. Our code is available https://github.com/ai4co/LLM&#45;as&#45;HH.

---
layout: publication
title: 'A Survey On Human-centric Llms'
authors: Jing Yi Wang, Nicholas Sukiennik, Tong Li, Weikang Su, Qianyue Hao, Jingbo Xu, Zihan Huang, Fengli Xu, Yong Li
conference: "Arxiv"
year: 2024
bibkey: wang2024survey
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2411.14491"}
tags: ['Tools', 'Survey Paper', 'Applications', 'Ethics and Bias', 'Reinforcement Learning']
---
The rapid evolution of large language models (LLMs) and their capacity to
simulate human cognition and behavior has given rise to LLM-based frameworks
and tools that are evaluated and applied based on their ability to perform
tasks traditionally performed by humans, namely those involving cognition,
decision-making, and social interaction. This survey provides a comprehensive
examination of such human-centric LLM capabilities, focusing on their
performance in both individual tasks (where an LLM acts as a stand-in for a
single human) and collective tasks (where multiple LLMs coordinate to mimic
group dynamics). We first evaluate LLM competencies across key areas including
reasoning, perception, and social cognition, comparing their abilities to
human-like skills. Then, we explore real-world applications of LLMs in
human-centric domains such as behavioral science, political science, and
sociology, assessing their effectiveness in replicating human behaviors and
interactions. Finally, we identify challenges and future research directions,
such as improving LLM adaptability, emotional intelligence, and cultural
sensitivity, while addressing inherent biases and enhancing frameworks for
human-AI collaboration. This survey aims to provide a foundational
understanding of LLMs from a human-centric perspective, offering insights into
their current capabilities and potential for future development.

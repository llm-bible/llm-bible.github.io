---
layout: publication
title: 'Llama-3-nanda-10b-chat: An Open Generative Large Language Model For Hindi'
authors: Monojit Choudhury, Shivam Chauhan, Rocktim Jyoti Das, Dhruv Sahnan, Xudong Han, Haonan Li, Aaryamonvikram Singh, Alok Anil Jadhav, Utkarsh Agarwal, Mukund Choudhary, Debopriyo Banerjee, Fajri Koto, Junaid Bhat, Awantika Shukla, Samujjwal Ghosh, Samta Kamboj, Onkar Pandit, Lalit Pradhan, Rahul Pal, Sunil Sahu, Soundar Doraiswamy, Parvez Mullah, Ali El Filali, Neha Sengupta, Gokul Ramakrishnan, Rituraj Joshi, Gurpreet Gosal, Avraham Sheinin, Natalia Vassilieva, Preslav Nakov
conference: "Arxiv"
year: 2025
bibkey: choudhury2025llama
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2504.06011"}
tags: ['Fine-Tuning', 'Responsible AI', 'Transformer', 'Pre-Training', 'Applications', 'RAG', 'Model Architecture', 'Reinforcement Learning', 'Training Techniques', 'Pretraining Methods']
---
Developing high-quality large language models (LLMs) for moderately resourced
languages presents unique challenges in data availability, model adaptation,
and evaluation. We introduce Llama-3-Nanda-10B-Chat, or Nanda for short, a
state-of-the-art Hindi-centric instruction-tuned generative LLM, designed to
push the boundaries of open-source Hindi language models. Built upon
Llama-3-8B, Nanda incorporates continuous pre-training with expanded
transformer blocks, leveraging the Llama Pro methodology. A key challenge was
the limited availability of high-quality Hindi text data; we addressed this
through rigorous data curation, augmentation, and strategic bilingual training,
balancing Hindi and English corpora to optimize cross-linguistic knowledge
transfer. With 10 billion parameters, Nanda stands among the top-performing
open-source Hindi and multilingual models of similar scale, demonstrating
significant advantages over many existing models. We provide an in-depth
discussion of training strategies, fine-tuning techniques, safety alignment,
and evaluation metrics, demonstrating how these approaches enabled Nanda to
achieve state-of-the-art results. By open-sourcing Nanda, we aim to advance
research in Hindi LLMs and support a wide range of real-world applications
across academia, industry, and public services.

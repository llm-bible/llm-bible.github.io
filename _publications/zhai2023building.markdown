---
layout: publication
title: Building Open45;ended Embodied Agent Via Language45;policy Bidirectional Adaptation
authors: Zhai Shaopeng, Wang Jie, Zhang Tianyi, Huang Fuxian, Zhang Qi, Zhou Ming, Hou Jing, Qiao Yu, Liu Yu
conference: "Arxiv"
year: 2023
bibkey: zhai2023building
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.00006"}
tags: ['Agentic', 'Fine Tuning', 'RAG', 'Reinforcement Learning', 'Tools', 'Training Techniques']
---
Building embodied agents on integrating Large Language Models (LLMs) and Reinforcement Learning (RL) have revolutionized human45;AI interaction researchers can now leverage language instructions to plan decision45;making for open45;ended tasks. However existing research faces challenges in meeting the requirement of open45;endedness. They typically either train LLM/RL models to adapt to a fixed counterpart limiting exploration of novel skills and hindering the efficacy of human45;AI interaction. To this end we present OpenPAL a co45;training framework comprising two stages (1) fine45;tuning a pre45;trained LLM to translate human instructions into goals for planning and goal45;conditioned training a policy for decision45;making; (2) co45;training to align the LLM and policy achieving instruction open45;endedness. We conducted experiments using Contra an open45;ended FPS game demonstrating that an agent trained with OpenPAL not only comprehends arbitrary instructions but also exhibits efficient execution. These results suggest that OpenPAL holds the potential to construct open45;ended embodied agents in practical scenarios.

---
layout: publication
title: 'Language Games As The Pathway To Artificial Superhuman Intelligence'
authors: Ying Wen, Ziyu Wan, Shao Zhang
conference: "Arxiv"
year: 2025
bibkey: wen2025language
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2501.18924'}
tags: ['Agentic', 'Agent', 'RAG', 'Tools', 'Fine-Tuning', 'Reinforcement Learning']
---
The evolution of large language models (LLMs) toward artificial superhuman
intelligence (ASI) hinges on data reproduction, a cyclical process in which
models generate, curate and retrain on novel data to refine capabilities.
Current methods, however, risk getting stuck in a data reproduction trap:
optimizing outputs within fixed human-generated distributions in a closed loop
leads to stagnation, as models merely recombine existing knowledge rather than
explore new frontiers. In this paper, we propose language games as a pathway to
expanded data reproduction, breaking this cycle through three mechanisms: (1)
\textit\{role fluidity\}, which enhances data diversity and coverage by enabling
multi-agent systems to dynamically shift roles across tasks; (2) \textit\{reward
variety\}, embedding multiple feedback criteria that can drive complex
intelligent behaviors; and (3) \textit\{rule plasticity\}, iteratively evolving
interaction constraints to foster learnability, thereby injecting continual
novelty. By scaling language games into global sociotechnical ecosystems,
human-AI co-evolution generates unbounded data streams that drive open-ended
exploration. This framework redefines data reproduction not as a closed loop
but as an engine for superhuman intelligence.

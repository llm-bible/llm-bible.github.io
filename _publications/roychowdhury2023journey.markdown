---
layout: publication
title: 'Journey Of Hallucination-minimized Generative AI Solutions For Financial Decision Makers'
authors: Roychowdhury Sohini
conference: "Arxiv"
year: 2023
bibkey: roychowdhury2023journey
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2311.10961"}
tags: ['Applications', 'Ethics And Bias', 'Prompting', 'Reinforcement Learning', 'Training Techniques']
---
'Generative AI has significantly reduced the entry barrier to the domain of AI owing to the ease of use and core capabilities of automation, translation, and intelligent actions in our day to day lives. Currently, Large language models (LLMs) that power such chatbots are being utilized primarily for their automation capabilities for software monitoring, report generation etc. and for specific personalized question answering capabilities, on a limited scope and scale. One major limitation of the currently evolving family of LLMs is ''hallucinations'', wherein inaccurate responses are reported as factual. Hallucinations are primarily caused by biased training data, ambiguous prompts and inaccurate LLM parameters, and they majorly occur while combining mathematical facts with language-based context. Thus, monitoring and controlling for hallucinations becomes necessary when designing solutions that are meant for decision makers. In this work we present the three major stages in the journey of designing hallucination-minimized LLM-based solutions that are specialized for the decision makers of the financial domain, namely: prototyping, scaling and LLM evolution using human feedback. These three stages and the novel data to answer generation modules presented in this work are necessary to ensure that the Generative AI chatbots, autonomous reports and alerts are reliable and high-quality to aid key decision-making processes.'

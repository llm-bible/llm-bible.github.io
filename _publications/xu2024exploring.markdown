---
layout: publication
title: 'Exploring Multilingual Concepts Of Human Value In Large Language Models: Is Value Alignment Consistent, Transferable And Controllable Across Languages?'
authors: Shaoyang Xu, Weilong Dong, Zishan Guo, Xinwei Wu, Deyi Xiong
conference: "Arxiv"
year: 2024
bibkey: xu2024exploring
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2402.18120'}
tags: ['RAG', 'Training Techniques', 'Fine-Tuning', 'Reinforcement Learning', 'Pre-Training', 'Responsible AI']
---
Prior research has revealed that certain abstract concepts are linearly
represented as directions in the representation space of LLMs, predominantly
centered around English. In this paper, we extend this investigation to a
multilingual context, with a specific focus on human values-related concepts
(i.e., value concepts) due to their significance for AI safety. Through our
comprehensive exploration covering 7 types of human values, 16 languages and 3
LLM series with distinct multilinguality (e.g., monolingual, bilingual and
multilingual), we first empirically confirm the presence of value concepts
within LLMs in a multilingual format. Further analysis on the cross-lingual
characteristics of these concepts reveals 3 traits arising from language
resource disparities: cross-lingual inconsistency, distorted linguistic
relationships, and unidirectional cross-lingual transfer between high- and
low-resource languages, all in terms of value concepts. Moreover, we validate
the feasibility of cross-lingual control over value alignment capabilities of
LLMs, leveraging the dominant language as a source language. Ultimately,
recognizing the significant impact of LLMs' multilinguality on our results, we
consolidate our findings and provide prudent suggestions on the composition of
multilingual data for LLMs pre-training.

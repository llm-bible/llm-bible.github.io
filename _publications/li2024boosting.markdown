---
layout: publication
title: 'Structrag: Boosting Knowledge Intensive Reasoning Of Llms Via Inference-time Hybrid Information Structurization'
authors: Zhuoqun Li, Xuanang Chen, Haiyang Yu, Hongyu Lin, Yaojie Lu, Qiaoyu Tang, Fei Huang, Xianpei Han, Le Sun, Yongbin Li
conference: "Arxiv"
year: 2024
bibkey: li2024boosting
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2410.08815"}
tags: ['RAG', 'Applications', 'Tools', 'Reinforcement Learning']
---
Retrieval-augmented generation (RAG) is a key means to effectively enhance
large language models (LLMs) in many knowledge-based tasks. However, existing
RAG methods struggle with knowledge-intensive reasoning tasks, because useful
information required to these tasks are badly scattered. This characteristic
makes it difficult for existing RAG methods to accurately identify key
information and perform global reasoning with such noisy augmentation. In this
paper, motivated by the cognitive theories that humans convert raw information
into various structured knowledge when tackling knowledge-intensive reasoning,
we proposes a new framework, StructRAG, which can identify the optimal
structure type for the task at hand, reconstruct original documents into this
structured format, and infer answers based on the resulting structure.
Extensive experiments across various knowledge-intensive tasks show that
StructRAG achieves state-of-the-art performance, particularly excelling in
challenging scenarios, demonstrating its potential as an effective solution for
enhancing LLMs in complex real-world applications.

---
layout: publication
title: 'Using Large Language Model To Solve And Explain Physics Word Problems Approaching Human Level'
authors: Ding Jingzhe, Cen Yan, Wei Xinyuan
conference: "Arxiv"
year: 2023
bibkey: ding2023using
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.08182"}
tags: ['Applications', 'Few Shot', 'GPT', 'Interpretability And Explainability', 'Model Architecture', 'Pretraining Methods', 'Prompting']
---
Our work demonstrates that large language model (LLM) pre-trained on texts can not only solve pure math word problems, but also physics word problems, whose solution requires calculation and inference based on prior physical knowledge. We collect and annotate the first physics word problem dataset-PhysQA, which contains over 1000 junior high school physics word problems (covering Kinematics, Mass&amp;Density, Mechanics, Heat, Electricity). Then we use OpenAI' s GPT3.5 to generate the answer of these problems and found that GPT3.5 could automatically solve 49.3&#37; of the problems through zero-shot learning and 73.2&#37; through few-shot learning. This result demonstrates that by using similar problems and their answers as prompt, LLM could solve elementary physics word problems approaching human level performance. In addition to solving problems, GPT3.5 can also summarize the knowledge or topics covered by the problems, provide relevant explanations, and generate new physics word problems based on the input. Our work is the first research to focus on the automatic solving, explanation, and generation of physics word problems across various types and scenarios, and we achieve an acceptable and state-of-the-art accuracy. This underscores the potential of LLMs for further applications in secondary education.

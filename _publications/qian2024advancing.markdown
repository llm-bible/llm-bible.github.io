---
layout: publication
title: Momentor Advancing Video Large Language Model With Fine45;grained Temporal Reasoning
authors: Qian Long, Li Juncheng, Wu Yu, Ye Yaobo, Fei Hao, Chua Tat-seng, Zhuang Yueting, Tang Siliang
conference: "Arxiv"
year: 2024
bibkey: qian2024advancing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.11435"}
tags: ['Pretraining Methods', 'Reinforcement Learning', 'Training Techniques']
---
Large Language Models (LLMs) demonstrate remarkable proficiency in comprehending and handling text45;based tasks. Many efforts are being made to transfer these attributes to video modality which are termed Video45;LLMs. However existing Video45;LLMs can only capture the coarse45;grained semantics and are unable to effectively handle tasks related to comprehension or localization of specific video segments. In light of these challenges we propose Momentor a Video45;LLM capable of accomplishing fine45;grained temporal understanding tasks. To support the training of Momentor we design an automatic data generation engine to construct Moment45;10M a large45;scale video instruction dataset with segment45;level instruction data. We train Momentor on Moment45;10M enabling it to perform segment45;level reasoning and localization. Zero45;shot evaluations on several tasks demonstrate that Momentor excels in fine45;grained temporally grounded comprehension and localization.

---
layout: publication
title: 'Unsupervised Explanation Generation For Machine Reading Comprehension'
authors: Cui Yiming, Liu Ting, Wang Shijin, Hu Guoping
conference: "Arxiv"
year: 2020
bibkey: cui2020unsupervised
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2011.06737"}
tags: ['Applications', 'Attention Mechanism', 'Interpretability And Explainability', 'Model Architecture', 'TACL', 'Tools', 'Transformer']
---
With the blooming of various Pre-trained Language Models (PLMs) Machine Reading Comprehension (MRC) has embraced significant improvements on various benchmarks and even surpass human performances. However the existing works only target on the accuracy of the final predictions and neglect the importance of the explanations for the prediction which is a big obstacle when utilizing these models in real-life applications to convince humans. In this paper we propose a self-explainable framework for the machine reading comprehension task. The main idea is that the proposed system tries to use less passage information and achieve similar results compared to the system that uses the whole passage while the filtered passage will be used as explanations. We carried out experiments on three multiple-choice MRC datasets and found that the proposed system could achieve consistent improvements over baseline systems. To evaluate the explainability we compared our approach with the traditional attention mechanism in human evaluations and found that the proposed system has a notable advantage over the latter one.

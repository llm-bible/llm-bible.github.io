---
layout: publication
title: 'Cola -- Learning To Interactively Collaborate With Large Lms'
authors: Abhishek Sharma, Dan Goldwasser
conference: "Arxiv"
year: 2025
bibkey: sharma2025cola
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2504.02965'}
tags: ['Language Modeling', 'GPT', 'Model Architecture', 'Applications', 'Training Techniques', 'Reinforcement Learning']
---
LLMs' remarkable ability to tackle a wide range of language tasks opened new
opportunities for collaborative human-AI problem solving. LLMs can amplify
human capabilities by applying their intuitions and reasoning strategies at
scale. We explore whether human guides can be simulated, by generalizing from
human demonstrations of guiding an AI system to solve complex language
problems. We introduce CoLa, a novel self-guided learning paradigm for training
automated \\(\textit\{guides\}\\) and evaluate it on two QA datasets, a
puzzle-solving task, and a constrained text generation task. Our empirical
results show that CoLa consistently outperforms competitive approaches across
all domains. Moreover, a small-sized trained guide outperforms a strong model
like GPT-4 when acting as a guide. We compare the strategies employed by humans
and automated guides by conducting a human study on a QA dataset. We show that
automated guides outperform humans by adapting their strategies to reasoners'
capabilities and conduct qualitative analyses highlighting distinct differences
in guiding strategies.

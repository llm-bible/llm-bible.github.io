---
layout: publication
title: Can Large Language Models Assist In Hazard Analysis
authors: Diemert Simon, Weber Jens H
conference: "Arxiv"
year: 2023
bibkey: diemert2023can
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2303.15473"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Reinforcement Learning', 'Responsible AI']
---
Large Language Models (LLMs) such as GPT45;3 have demonstrated remarkable natural language processing and generation capabilities and have been applied to a variety tasks such as source code generation. This paper explores the potential of integrating LLMs in the hazard analysis for safety45;critical systems a process which we refer to as co45;hazard analysis (CoHA). In CoHA a human analyst interacts with an LLM via a context45;aware chat session and uses the responses to support elicitation of possible hazard causes. In this experiment we explore CoHA with three increasingly complex versions of a simple system using Open AIs ChatGPT service. The quality of ChatGPTs responses were systematically assessed to determine the feasibility of CoHA given the current state of LLM technology. The results suggest that LLMs may be useful for supporting human analysts performing hazard analysis.

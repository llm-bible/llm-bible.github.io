---
layout: publication
title: 'Sparkra: A Retrieval-augmented Knowledge Service System Based On Spark Large Language Model'
authors: Wu Dayong, Li Jiaqi, Wang Baoxin, Zhao Honghong, Xue Siyuan, Yang Yanjie, Chang Zhijun, Zhang Rui, Qian Li, Wang Bo, Wang Shijin, Zhang Zhixiong, Hu Guoping
conference: "Arxiv"
year: 2024
bibkey: wu2024retrieval
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.06574"}
tags: ['Fine Tuning', 'Pretraining Methods', 'RAG', 'Training Techniques']
---
"Large language models (LLMs) have shown remarkable achievements across various language tasks.To enhance the performance of LLMs in scientific literature services, we developed the scientific literature LLM (SciLit-LLM) through pre-training and supervised fine-tuning on scientific literature, building upon the iFLYTEK Spark LLM. Furthermore, we present a knowledge service system Spark Research Assistant (SparkRA) based on our SciLit-LLM. SparkRA is accessible online and provides three primary functions: literature investigation, paper reading, and academic writing. As of July 30, 2024, SparkRA has garnered over 50,000 registered users, with a total usage count exceeding 1.3 million."

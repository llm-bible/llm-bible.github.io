---
layout: publication
title: Understanding (un)intended Memorization In Text45;to45;image Generative Models
authors: Naseh Ali, Roh Jaechul, Houmansadr Amir
conference: "Arxiv"
year: 2023
bibkey: naseh2023understanding
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2312.07550"}
tags: ['Merging', 'Multimodal Models', 'Reinforcement Learning']
---
Multimodal machine learning especially text45;to45;image models like Stable Diffusion and DALL45;E 3 has gained significance for transforming text into detailed images. Despite their growing use and remarkable generative capabilities there is a pressing need for a detailed examination of these models behavior particularly with respect to memorization. Historically memorization in machine learning has been context45;dependent with diverse definitions emerging from classification tasks to complex models like Large Language Models (LLMs) and Diffusion models. Yet a definitive concept of memorization that aligns with the intricacies of text45;to45;image synthesis remains elusive. This understanding is vital as memorization poses privacy risks yet is essential for meeting user expectations especially when generating representations of underrepresented entities. In this paper we introduce a specialized definition of memorization tailored to text45;to45;image models categorizing it into three distinct types according to user expectations. We closely examine the subtle distinctions between intended and unintended memorization emphasizing the importance of balancing user privacy with the generative quality of the model outputs. Using the Stable Diffusion model we offer examples to validate our memorization definitions and clarify their application.

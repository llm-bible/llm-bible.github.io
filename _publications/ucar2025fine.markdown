---
layout: publication
title: 'Fine-tuning Florence2 For Enhanced Object Detection In Un-constructed Environments: Vision-language Model Approach'
authors: Aysegul Ucar, Soumyadeep Ro, Sanapala Satwika, Pamarthi Yasoda Gayathri, Mohmmad Ghaith Balsha
conference: "Arxiv"
year: 2025
bibkey: ucar2025fine
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2503.04918"}
tags: ['Fine-Tuning', 'Transformer', 'Tools', 'Applications', 'RAG', 'Model Architecture', 'Reinforcement Learning', 'Training Techniques', 'Pretraining Methods', 'Multimodal Models']
---
Vision-Language Models (VLMs) have emerged as powerful tools in artificial
intelli-gence, capable of integrating textual and visual data for a unified
understanding of complex scenes. While models such as Florence2, built on
transformer architectures, have shown promise across general tasks, their
performance in object detection within unstructured or cluttered environments
remains underexplored. In this study, we fi-ne-tuned the Florence2 model for
object detection tasks in non-constructed, complex environments. A
comprehensive experimental framework was established involving multiple
hardware configurations (NVIDIA T4, L4, and A100 GPUs), optimizers (AdamW,
SGD), and varied hyperparameters including learning rates and LoRA (Low-Rank
Adaptation) setups. Model training and evaluation were conducted on challenging
datasets representative of real-world, disordered settings. The optimized
Florence2 models exhibited significant improvements in object detection
accuracy, with Mean Average Precision (mAP) metrics approaching or matching
those of estab-lished models such as YOLOv8, YOLOv9, and YOLOv10. The
integration of LoRA and careful fine-tuning of transformer layers contributed
notably to these gains. Our find-ings highlight the adaptability of
transformer-based VLMs like Florence2 for do-main-specific tasks, particularly
in visually complex environments. The study under-scores the potential of
fine-tuned VLMs to rival traditional convolution-based detec-tors, offering a
flexible and scalable approach for advanced vision applications in re-al-world,
unstructured settings.

---
layout: publication
title: Gpt45;ology Computational Models Silicon Sampling How Should We Think About Llms In Cognitive Science
authors: Ong Desmond C.
conference: "Arxiv"
year: 2024
bibkey: ong2024gpt
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.09464"}
tags: ['GPT', 'Merging', 'Model Architecture', 'Prompting', 'Reinforcement Learning', 'Survey Paper', 'Training Techniques']
---
Large Language Models have taken the cognitive science world by storm. It is perhaps timely now to take stock of the various research paradigms that have been used to make scientific inferences about cognition in these models or about human cognition. We review several emerging research paradigms 45;45; GPT45;ology LLMs45;as45;computational45;models and silicon sampling 45;45; and review recent papers that have used LLMs under these paradigms. In doing so we discuss their claims as well as challenges to scientific inference under these various paradigms. We highlight several outstanding issues about LLMs that have to be addressed to push our science forward closed45;source vs open45;sourced models; (the lack of visibility of) training data; and reproducibility in LLM research including forming conventions on new task hyperparameters like instructions and prompts.

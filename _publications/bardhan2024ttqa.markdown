---
layout: publication
title: TTQA45;RS45; A Break45;down Prompting Approach For Multi45;hop Table45;text Question Answering With Reasoning And Summarization
authors: Bardhan Jayetri, Xiao Bushi, Wang Daisy Zhe
conference: "Arxiv"
year: 2024
bibkey: bardhan2024ttqa
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.14732"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Prompting', 'Training Techniques']
---
Question answering (QA) over tables and text has gained much popularity over the years. Multi45;hop table45;text QA requires multiple hops between the table and text making it a challenging QA task. Although several works have attempted to solve the table45;text QA task most involve training the models and requiring labeled data. In this paper we have proposed a model 45; TTQA45;RS A break45;down prompting approach for Multi45;hop Table45;Text Question Answering with Reasoning and Summarization. Our model uses augmented knowledge including table45;text summary with decomposed sub45;question with answer for a reasoning45;based table45;text QA. Using open45;source language models our model outperformed all existing prompting methods for table45;text QA tasks on existing table45;text QA datasets like HybridQA and OTT45;QAs development set. Our results are comparable with the training45;based state45;of45;the45;art models demonstrating the potential of prompt45;based approaches using open45;source LLMs. Additionally by using GPT45;4 with LLaMA345;70B our model achieved state45;of45;the45;art performance for prompting45;based methods on multi45;hop table45;text QA.

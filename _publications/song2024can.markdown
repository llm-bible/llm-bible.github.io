---
layout: publication
title: Can Many45;shot In45;context Learning Help Long45;context LLM Judges See More Judge Better!
authors: Song Mingyang, Zheng Mao, Luo Xuan
conference: "Arxiv"
year: 2024
bibkey: song2024can
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.11629"}
tags: ['Attention Mechanism', 'Bias Mitigation', 'Ethics And Bias', 'GPT', 'Model Architecture', 'Prompting', 'RAG']
---
Leveraging Large Language Models (LLMs) as judges for judging the performance of LLMs has recently garnered attention. However this type of approach is affected by the potential biases in LLMs raising concerns about the reliability of the evaluation results. To mitigate this issue we propose and study two versions of many45;shot in45;context prompts which rely on two existing settings of many45;shot ICL for helping GPT45;4o45;as45;a45;Judge in single answer grading to mitigate the potential biases in LLMs Reinforced ICL and Unsupervised ICL. Concretely the former utilizes in45;context examples with model45;generated rationales and the latter without. Based on the designed prompts we investigate the impact of scaling the number of in45;context examples on the consistency and quality of the judgment results. Furthermore we reveal the symbol bias hidden in the pairwise comparison of GPT45;4o45;as45;a45;Judge and propose a simple yet effective approach to mitigate it. Experimental results show that advanced long45;context LLMs such as GPT45;4o perform better in the many45;shot regime than in the zero45;shot regime. Meanwhile the experimental results further verify the effectiveness of the symbol bias mitigation approach.

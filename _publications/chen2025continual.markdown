---
layout: publication
title: 'Continual Pre-training Is (not) What You Need In Domain Adaption'
authors: Pin-er Chen, Da-chen Lian, Shu-kai Hsieh, Sieh-chuen Huang, Hsuan-lei Shao, Jun-wei Chiu, Yang-hsien Lin, Zih-ching Chen, Cheng-kuang, Eddie Tc Huang, Simon See
conference: "Arxiv"
year: 2025
bibkey: chen2025continual
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2504.13603"}
tags: ['Training Techniques', 'Tools', 'Reinforcement Learning', 'Fine-Tuning', 'Prompting', 'Pre-Training']
---
The recent advances in Legal Large Language Models (LLMs) have transformed
the landscape of legal research and practice by automating tasks, enhancing
research precision, and supporting complex decision-making processes. However,
effectively adapting LLMs to the legal domain remains challenging due to the
complexity of legal reasoning, the need for precise interpretation of
specialized language, and the potential for hallucinations. This paper examines
the efficacy of Domain-Adaptive Continual Pre-Training (DACP) in improving the
legal reasoning capabilities of LLMs. Through a series of experiments on legal
reasoning tasks within the Taiwanese legal framework, we demonstrate that while
DACP enhances domain-specific knowledge, it does not uniformly improve
performance across all legal tasks. We discuss the trade-offs involved in DACP,
particularly its impact on model generalization and performance in prompt-based
tasks, and propose directions for future research to optimize domain adaptation
strategies in legal AI.

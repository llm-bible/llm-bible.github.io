---
layout: publication
title: 'Empowering Language Models With Active Inquiry For Deeper Understanding'
authors: Jing-cheng Pang, Heng-bo Fan, Pengyuan Wang, Jia-hao Xiao, Nan Tang, Si-hang Yang, Chengxing Jia, Sheng-jun Huang, Yang Yu
conference: "Arxiv"
year: 2024
bibkey: pang2024empowering
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.03719"}
tags: ['RAG', 'Tools']
---
The rise of large language models (LLMs) has revolutionized the way that we
interact with artificial intelligence systems through natural language.
However, LLMs often misinterpret user queries because of their uncertain
intention, leading to less helpful responses. In natural human interactions,
clarification is sought through targeted questioning to uncover obscure
information. Thus, in this paper, we introduce LaMAI (Language Model with
Active Inquiry), designed to endow LLMs with this same level of interactive
engagement. LaMAI leverages active learning techniques to raise the most
informative questions, fostering a dynamic bidirectional dialogue. This
approach not only narrows the contextual gap but also refines the output of the
LLMs, aligning it more closely with user expectations. Our empirical studies,
across a variety of complex datasets where LLMs have limited conversational
context, demonstrate the effectiveness of LaMAI. The method improves answer
accuracy from 31.9% to 50.9%, outperforming other leading question-answering
frameworks. Moreover, in scenarios involving human participants, LaMAI
consistently generates responses that are superior or comparable to baseline
methods in more than 82% of the cases. The applicability of LaMAI is further
evidenced by its successful integration with various LLMs, highlighting its
potential for the future of interactive language models.

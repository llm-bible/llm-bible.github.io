---
layout: publication
title: A Dataset And Benchmark For Hospital Course Summarization With Adapted Large Language Models
authors: Aali Asad, Van Veen Dave, Arefeen Yamin Ishraq, Hom Jason, Bluethgen Christian, Reis Eduardo Pontes, Gatidis Sergios, Clifford Namuun, Daws Joseph, Tehrani Arash S., Kim Jangwon, Chaudhari Akshay S.
conference: "Arxiv"
year: 2024
bibkey: aali2024dataset
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.05720"}
tags: ['Applications', 'BERT', 'GPT', 'Model Architecture', 'Prompting', 'Reinforcement Learning', 'Security']
---
Brief hospital course (BHC) summaries are clinical documents that summarize a patients hospital stay. While large language models (LLMs) depict remarkable capabilities in automating real45;world tasks their capabilities for healthcare applications such as synthesizing BHCs from clinical notes have not been shown. We introduce a novel pre45;processed dataset the MIMIC45;IV45;BHC encapsulating clinical note and brief hospital course (BHC) pairs to adapt LLMs for BHC synthesis. Furthermore we introduce a benchmark of the summarization performance of two general45;purpose LLMs and three healthcare45;adapted LLMs. Using clinical notes as input we apply prompting45;based (using in45;context learning) and fine45;tuning45;based adaptation strategies to three open45;source LLMs (Clinical45;T545;Large Llama245;13B FLAN45;UL2) and two proprietary LLMs (GPT45;3.5 GPT45;4). We evaluate these LLMs across multiple context45;length inputs using natural language similarity metrics. We further conduct a clinical study with five clinicians comparing clinician45;written and LLM45;generated BHCs across 30 samples focusing on their potential to enhance clinical decision45;making through improved summary quality. We observe that the Llama245;13B fine45;tuned LLM outperforms other domain45;adapted models given quantitative evaluation metrics of BLEU and BERT45;Score. GPT45;4 with in45;context learning shows more robustness to increasing context lengths of clinical note inputs than fine45;tuned Llama245;13B. Despite comparable quantitative metrics the reader study depicts a significant preference for summaries generated by GPT45;4 with in45;context learning compared to both Llama245;13B fine45;tuned summaries and the original summaries highlighting the need for qualitative clinical evaluation.

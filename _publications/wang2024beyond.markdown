---
layout: publication
title: Beyond The Known Investigating Llms Performance On Out45;of45;domain Intent Detection
authors: Wang Pei, He Keqing, Wang Yejie, Song Xiaoshuai, Mou Yutao, Wang Jingang, Xian Yunsen, Cai Xunliang, Xu Weiran
conference: "LREC-COLING"
year: 2024
bibkey: wang2024beyond
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.17256"}
tags: ['GPT', 'Model Architecture', 'Pretraining Methods']
---
Out45;of45;domain (OOD) intent detection aims to examine whether the users query falls outside the predefined domain of the system which is crucial for the proper functioning of task45;oriented dialogue (TOD) systems. Previous methods address it by fine45;tuning discriminative models. Recently some studies have been exploring the application of large language models (LLMs) represented by ChatGPT to various downstream tasks but it is still unclear for their ability on OOD detection task.This paper conducts a comprehensive evaluation of LLMs under various experimental settings and then outline the strengths and weaknesses of LLMs. We find that LLMs exhibit strong zero45;shot and few45;shot capabilities but is still at a disadvantage compared to models fine45;tuned with full resource. More deeply through a series of additional analysis experiments we discuss and summarize the challenges faced by LLMs and provide guidance for future work including injecting domain knowledge strengthening knowledge transfer from IND(In45;domain) to OOD and understanding long instructions.

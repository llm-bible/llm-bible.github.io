---
layout: publication
title: "Beyond The Known: Investigating Llms Performance On Out-of-domain Intent Detection"
authors: Wang Pei, He Keqing, Wang Yejie, Song Xiaoshuai, Mou Yutao, Wang Jingang, Xian Yunsen, Cai Xunliang, Xu Weiran
conference: "LREC-COLING"
year: 2024
bibkey: wang2024beyond
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.17256"}
tags: ['Few Shot', 'Fine Tuning', 'GPT', 'Model Architecture', 'Pretraining Methods', 'Training Techniques']
---
Out-of-domain (OOD) intent detection aims to examine whether the users query falls outside the predefined domain of the system which is crucial for the proper functioning of task-oriented dialogue (TOD) systems. Previous methods address it by fine-tuning discriminative models. Recently some studies have been exploring the application of large language models (LLMs) represented by ChatGPT to various downstream tasks but it is still unclear for their ability on OOD detection task.This paper conducts a comprehensive evaluation of LLMs under various experimental settings and then outline the strengths and weaknesses of LLMs. We find that LLMs exhibit strong zero-shot and few-shot capabilities but is still at a disadvantage compared to models fine-tuned with full resource. More deeply through a series of additional analysis experiments we discuss and summarize the challenges faced by LLMs and provide guidance for future work including injecting domain knowledge strengthening knowledge transfer from IND(In-domain) to OOD and understanding long instructions.

---
layout: publication
title: Layoutllm\: Large Language Model Instruction Tuning For Visually Rich Document Understanding
authors: Fujitake Masato
conference: "Arxiv"
year: 2024
bibkey: fujitake2024large
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.14252"}
tags: ['Attention Mechanism', 'Fine Tuning', 'Model Architecture', 'Multimodal Models', 'Pretraining Methods', 'RAG', 'Training Techniques']
---
This paper proposes LayoutLLM a more flexible document analysis method for understanding imaged documents. Visually Rich Document Understanding tasks such as document image classification and information extraction have gained significant attention due to their importance. Existing methods have been developed to enhance document comprehension by incorporating pre-training awareness of images text and layout structure. However these methods require fine-tuning for each task and dataset and the models are expensive to train and operate. To overcome this limitation we propose a new LayoutLLM that integrates these with large-scale language models (LLMs). By leveraging the strengths of existing research in document image understanding and LLMs superior language understanding capabilities the proposed model fine-tuned with multimodal instruction datasets performs an understanding of document images in a single model. Our experiments demonstrate improvement over the baseline model in various document analysis tasks.

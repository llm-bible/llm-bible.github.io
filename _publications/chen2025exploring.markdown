---
layout: publication
title: 'Exploring The Role Of Knowledge Graph-based RAG In Japanese Medical Question Answering With Small-scale Llms'
authors: Yingjian Chen, Feiyang Li, Xingyu Song, Tianxiao Li, Zixin Xu, Xiujie Chen, Issey Sukeda, Irene Li
conference: "Arxiv"
year: 2025
bibkey: chen2025exploring
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2504.10982'}
tags: ['RAG', 'GPT', 'Tools', 'Model Architecture', 'Fine-Tuning', 'Applications']
---
Large language models (LLMs) perform well in medical QA, but their
effectiveness in Japanese contexts is limited due to privacy constraints that
prevent the use of commercial models like GPT-4 in clinical settings. As a
result, recent efforts focus on instruction-tuning open-source LLMs, though the
potential of combining them with retrieval-augmented generation (RAG) remains
underexplored. To bridge this gap, we are the first to explore a knowledge
graph-based (KG) RAG framework for Japanese medical QA small-scale open-source
LLMs. Experimental results show that KG-based RAG has only a limited impact on
Japanese medical QA using small-scale open-source LLMs. Further case studies
reveal that the effectiveness of the RAG is sensitive to the quality and
relevance of the external retrieved content. These findings offer valuable
insights into the challenges and potential of applying RAG in Japanese medical
QA, while also serving as a reference for other low-resource languages.

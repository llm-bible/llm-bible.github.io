---
layout: publication
title: Exploring The Boundaries Of GPT45;4 In Radiology
authors: Liu Qianchu, Hyland Stephanie, Bannur Shruthi, Bouzid Kenza, Castro Daniel C., Wetscherek Maria Teodora, Tinn Robert, Sharma Harshita, Pérez-garcía Fernando, Schwaighofer Anton, Rajpurkar Pranav, Khanna Sameer Tajdin, Poon Hoifung, Usuyama Naoto, Thieme Anja, Nori Aditya V., Lungren Matthew P., Oktay Ozan, Alvarez-valle Javier
conference: "Arxiv"
year: 2023
bibkey: liu2023exploring
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.14573"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Prompting']
---
The recent success of general45;domain large language models (LLMs) has significantly changed the natural language processing paradigm towards a unified foundation model across domains and applications. In this paper we focus on assessing the performance of GPT45;4 the most capable LLM so far on the text45;based applications for radiology reports comparing against state45;of45;the45;art (SOTA) radiology45;specific models. Exploring various prompting strategies we evaluated GPT45;4 on a diverse range of common radiology tasks and we found GPT45;4 either outperforms or is on par with current SOTA radiology models. With zero45;shot prompting GPT45;4 already obtains substantial gains (≈ 1037; absolute improvement) over radiology models in temporal sentence similarity classification (accuracy) and natural language inference (F95;1). For tasks that require learning dataset45;specific style or schema (e.g. findings summarisation) GPT45;4 improves with example45;based prompting and matches supervised SOTA. Our extensive error analysis with a board45;certified radiologist shows GPT45;4 has a sufficient level of radiology knowledge with only occasional errors in complex context that require nuanced domain knowledge. For findings summarisation GPT45;4 outputs are found to be overall comparable with existing manually45;written impressions.

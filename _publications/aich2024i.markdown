---
layout: publication
title: 'Vernacular? I Barely Know Her: Challenges With Style Control And Stereotyping'
authors: Ankit Aich, Tingting Liu, Salvatore Giorgi, Kelsey Isman, Lyle Ungar, Brenda Curtis
conference: "Arxiv"
year: 2024
bibkey: aich2024i
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2406.12679'}
tags: ['RAG', 'Efficiency and Optimization', 'Distillation', 'GPT', 'Applications', 'Model Architecture']
---
Large Language Models (LLMs) are increasingly being used in educational and
learning applications. Research has demonstrated that controlling for style, to
fit the needs of the learner, fosters increased understanding, promotes
inclusion, and helps with knowledge distillation. To understand the
capabilities and limitations of contemporary LLMs in style control, we
evaluated five state-of-the-art models: GPT-3.5, GPT-4, GPT-4o, Llama-3, and
Mistral-instruct- 7B across two style control tasks. We observed significant
inconsistencies in the first task, with model performances averaging between
5th and 8th grade reading levels for tasks intended for first-graders, and
standard deviations up to 27.6. For our second task, we observed a
statistically significant improvement in performance from 0.02 to 0.26.
However, we find that even without stereotypes in reference texts, LLMs often
generated culturally insensitive content during their tasks. We provide a
thorough analysis and discussion of the results.

---
layout: publication
title: 'Agentic Reasoning And Tool Integration For Llms Via Reinforcement Learning'
authors: Joykirat Singh, Raghav Magazine, Yash Pandya, Akshay Nambi
conference: "Arxiv"
year: 2025
bibkey: singh2025agentic
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2505.01441'}
tags: ['Agentic', 'Transformer', 'RAG', 'Model Architecture', 'Training Techniques', 'Tools', 'Reinforcement Learning', 'Interpretability', 'Pretraining Methods']
---
Large language models (LLMs) have achieved remarkable progress in complex
reasoning tasks, yet they remain fundamentally limited by their reliance on
static internal knowledge and text-only reasoning. Real-world problem solving
often demands dynamic, multi-step reasoning, adaptive decision making, and the
ability to interact with external tools and environments. In this work, we
introduce ARTIST (Agentic Reasoning and Tool Integration in Self-improving
Transformers), a unified framework that tightly couples agentic reasoning,
reinforcement learning, and tool integration for LLMs. ARTIST enables models to
autonomously decide when, how, and which tools to invoke within multi-turn
reasoning chains, leveraging outcome-based RL to learn robust strategies for
tool use and environment interaction without requiring step-level supervision.
Extensive experiments on mathematical reasoning and multi-turn function calling
benchmarks show that ARTIST consistently outperforms state-of-the-art
baselines, with up to 22% absolute improvement over base models and strong
gains on the most challenging tasks. Detailed studies and metric analyses
reveal that agentic RL training leads to deeper reasoning, more effective tool
use, and higher-quality solutions. Our results establish agentic RL with tool
integration as a powerful new frontier for robust, interpretable, and
generalizable problem-solving in LLMs.

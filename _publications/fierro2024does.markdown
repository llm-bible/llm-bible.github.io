---
layout: publication
title: Does Instruction Tuning Make Llms More Consistent
authors: Fierro Constanza, Li Jiaang, SÃ¸gaard Anders
conference: "Arxiv"
year: 2024
bibkey: fierro2024does
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.15206"}
tags: ['Pretraining Methods']
---
The purpose of instruction tuning is enabling zero45;shot performance but instruction tuning has also been shown to improve chain45;of45;thought reasoning and value alignment (Si et al. 2023). Here we consider the impact on textit123;consistency125; i.e. the sensitivity of language models to small perturbations in the input. We compare 10 instruction45;tuned LLaMA models to the original LLaMA45;7b model and show that almost across45;the45;board they become more consistent both in terms of their representations and their predictions in zero45;shot and downstream tasks. We explain these improvements through mechanistic analyses of factual recall.

---
layout: publication
title: 'Multiq&a: An Analysis In Measuring Robustness Via Automated Crowdsourcing Of Question Perturbations And Answers'
authors: Nicole Cho, William Watson
conference: "Arxiv"
year: 2025
bibkey: cho2025analysis
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.03711"}
tags: ['Agentic', 'GPT', 'Tools', 'Model Architecture', 'Security']
---
One critical challenge in the institutional adoption journey of Large
Language Models (LLMs) stems from their propensity to hallucinate in generated
responses. To address this, we propose MultiQ&A, a systematic approach for
evaluating the robustness and consistency of LLM-generated answers. We
demonstrate MultiQ&A's ability to crowdsource question perturbations and their
respective answers through independent LLM agents at scale. Our experiments
culminated in the examination of 1.9 million question perturbations and 2.3
million answers. Furthermore, MultiQ&A shows that ensembled LLMs, such as
gpt-3.5-turbo, remain relatively robust and consistent under perturbations.
MultiQ&A provides clarity in the response generation space, offering an
effective method for inspecting disagreements and variability. Therefore, our
system offers a potential framework for institutional LLM adoption with the
ability to measure confidence, consistency, and the quantification of
hallucinations.

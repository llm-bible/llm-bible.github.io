---
layout: publication
title: From GPT-4 to Gemini and Beyond Assessing the Landscape of MLLMs on Generalizability Trustworthiness and Causality through Four Modalities
authors: Lu Chaochao, Qian Chen, Zheng Guodong, Fan Hongxing, Gao Hongzhi, Zhang Jie, Shao Jing, Deng Jingyi, Fu Jinlan, Huang Kexin, Li Kunchang, Li Lijun, Wang Limin, Sheng Lu, Chen Meiqi, Zhang Ming, Ren Qibing, Chen Sirui, Gui Tao, Ouyang Wanli, Wang Yali, Teng Yan, Wang Yaru, Wang Yi, He Yinan, Wang Yingchun, Wang Yixu, Zhang Yongting, Qiao Yu, Shen Yujiong, Mou Yurong, Chen Yuxi, Zhang Zaibin, Shi Zhelun, Yin Zhenfei, Wang Zhipin
conference: "Arxiv"
year: 2024
bibkey: lu2024from
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.15071"}
tags: ['Applications', 'Ethics And Bias', 'GPT', 'Model Architecture', 'Reinforcement Learning']
---
Multi-modal Large Language Models (MLLMs) have shown impressive abilities in generating reasonable responses with respect to multi-modal contents. However there is still a wide gap between the performance of recent MLLM-based applications and the expectation of the broad public even though the most powerful OpenAIs GPT-4 and Googles Gemini have been deployed. This paper strives to enhance understanding of the gap through the lens of a qualitative study on the generalizability trustworthiness and causal reasoning capabilities of recent proprietary and open-source MLLMs across four modalities ie text code image and video ultimately aiming to improve the transparency of MLLMs. We believe these properties are several representative factors that define the reliability of MLLMs in supporting various downstream applications. To be specific we evaluate the closed-source GPT-4 and Gemini and 6 open-source LLMs and MLLMs. Overall we evaluate 230 manually designed cases where the qualitative results are then summarized into 12 scores (ie 4 modalities times 3 properties). In total we uncover 14 empirical findings that are useful to understand the capabilities and limitations of both proprietary and open-source MLLMs towards more reliable downstream multi-modal applications.

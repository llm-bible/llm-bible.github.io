---
layout: publication
title: 'Exploring The Integration Of Large Language Models Into Automatic Speech Recognition Systems: An Empirical Study'
authors: Zeping Min, Jinbo Wang
conference: "Arxiv"
year: 2023
bibkey: min2023exploring
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2307.06530"}
tags: ['Model Architecture', 'RAG', 'In-Context Learning', 'GPT', 'Fine-Tuning', 'Prompting', 'Applications', 'Attention Mechanism', 'INTERSPEECH']
---
This paper explores the integration of Large Language Models (LLMs) into Automatic Speech Recognition (ASR) systems to improve transcription accuracy. The increasing sophistication of LLMs, with their in-context learning capabilities and instruction-following behavior, has drawn significant attention in the field of Natural Language Processing (NLP). Our primary focus is to investigate the potential of using an LLM's in-context learning capabilities to enhance the performance of ASR systems, which currently face challenges such as ambient noise, speaker accents, and complex linguistic contexts. We designed a study using the Aishell-1 and LibriSpeech datasets, with ChatGPT and GPT-4 serving as benchmarks for LLM capabilities. Unfortunately, our initial experiments did not yield promising results, indicating the complexity of leveraging LLM's in-context learning for ASR applications. Despite further exploration with varied settings and models, the corrected sentences from the LLMs frequently resulted in higher Word Error Rates (WER), demonstrating the limitations of LLMs in speech applications. This paper provides a detailed overview of these experiments, their results, and implications, establishing that using LLMs' in-context learning capabilities to correct potential errors in speech recognition transcriptions is still a challenging task at the current stage.

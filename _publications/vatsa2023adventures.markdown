---
layout: publication
title: 'Adventures Of Trustworthy Vision-language Models: A Survey'
authors: Mayank Vatsa, Anubhooti Jain, Richa Singh
conference: "Arxiv"
year: 2023
bibkey: vatsa2023adventures
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2312.04231'}
tags: ['Attention Mechanism', 'Interpretability and Explainability', 'Transformer', 'Security', 'Applications', 'Model Architecture', 'Tools', 'Multimodal Models', 'Survey Paper', 'Ethics and Bias', 'Responsible AI', 'Pretraining Methods']
---
Recently, transformers have become incredibly popular in computer vision and
vision-language tasks. This notable rise in their usage can be primarily
attributed to the capabilities offered by attention mechanisms and the
outstanding ability of transformers to adapt and apply themselves to a variety
of tasks and domains. Their versatility and state-of-the-art performance have
established them as indispensable tools for a wide array of applications.
However, in the constantly changing landscape of machine learning, the
assurance of the trustworthiness of transformers holds utmost importance. This
paper conducts a thorough examination of vision-language transformers,
employing three fundamental principles of responsible AI: Bias, Robustness, and
Interpretability. The primary objective of this paper is to delve into the
intricacies and complexities associated with the practical use of transformers,
with the overarching goal of advancing our comprehension of how to enhance
their reliability and accountability.

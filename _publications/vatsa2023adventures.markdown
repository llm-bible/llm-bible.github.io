---
layout: publication
title: Adventures of Trustworthy Vision-Language Models A Survey
authors: Vatsa Mayank, Jain Anubhooti, Singh Richa
conference: "Arxiv"
year: 2023
bibkey: vatsa2023adventures
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2312.04231"}
tags: ['Applications', 'Attention Mechanism', 'Ethics And Bias', 'Interpretability And Explainability', 'Model Architecture', 'Multimodal Models', 'Pretraining Methods', 'Responsible AI', 'Security', 'Survey Paper', 'Tools', 'Transformer']
---
Recently transformers have become incredibly popular in computer vision and vision-language tasks. This notable rise in their usage can be primarily attributed to the capabilities offered by attention mechanisms and the outstanding ability of transformers to adapt and apply themselves to a variety of tasks and domains. Their versatility and state-of-the-art performance have established them as indispensable tools for a wide array of applications. However in the constantly changing landscape of machine learning the assurance of the trustworthiness of transformers holds utmost importance. This paper conducts a thorough examination of vision-language transformers employing three fundamental principles of responsible AI Bias Robustness and Interpretability. The primary objective of this paper is to delve into the intricacies and complexities associated with the practical use of transformers with the overarching goal of advancing our comprehension of how to enhance their reliability and accountability.

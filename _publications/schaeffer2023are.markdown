---
layout: publication
title: Are Emergent Abilities Of Large Language Models A Mirage
authors: Rylan Schaeffer, Brando Miranda, Sanmi Koyejo
conference: "Arxiv"
year: 2023
bibkey: schaeffer2023are
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/http://arxiv.org/abs/2304.15004v2"}
tags: ['Ethics And Bias', 'GPT', 'Interpretability And Explainability', 'Model Architecture', 'RAG']
---
Recent work claims that large language models display emergent abilities abilities not present in smaller45;scale models that are present in larger45;scale models. What makes emergent abilities intriguing is two45;fold their sharpness transitioning seemingly instantaneously from not present to present and their unpredictability appearing at seemingly unforeseeable model scales. Here we present an alternative explanation for emergent abilities that for a particular task and model family when analyzing fixed model outputs emergent abilities appear due to the researchers choice of metric rather than due to fundamental changes in model behavior with scale. Specifically nonlinear or discontinuous metrics produce apparent emergent abilities whereas linear or continuous metrics produce smooth continuous predictable changes in model performance. We present our alternative explanation in a simple mathematical model then test it in three complementary ways we (1) make test and confirm three predictions on the effect of metric choice using the InstructGPT/GPT45;3 family on tasks with claimed emergent abilities; (2) make test and confirm two predictions about metric choices in a meta45;analysis of emergent abilities on BIG45;Bench; and (3) show to choose metrics to produce never45;before45;seen seemingly emergent abilities in multiple vision tasks across diverse deep networks. Via all three analyses we provide evidence that alleged emergent abilities evaporate with different metrics or with better statistics and may not be a fundamental property of scaling AI models.

---
layout: publication
title: 'A Survey Of Scaling In Large Language Model Reasoning'
authors: Zihan Chen, Song Wang, Zhen Tan, Xingbo Fu, Zhenyu Lei, Peng Wang, Huan Liu, Cong Shen, Jundong Li
conference: "Arxiv"
year: 2025
bibkey: chen2025survey
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2504.02181"}
tags: ['Agentic', 'Security', 'Training Techniques', 'Efficiency and Optimization', 'Survey Paper', 'Tools', 'Applications']
---
The rapid advancements in large Language models (LLMs) have significantly
enhanced their reasoning capabilities, driven by various strategies such as
multi-agent collaboration. However, unlike the well-established performance
improvements achieved through scaling data and model size, the scaling of
reasoning in LLMs is more complex and can even negatively impact reasoning
performance, introducing new challenges in model alignment and robustness. In
this survey, we provide a comprehensive examination of scaling in LLM
reasoning, categorizing it into multiple dimensions and analyzing how and to
what extent different scaling strategies contribute to improving reasoning
capabilities. We begin by exploring scaling in input size, which enables LLMs
to process and utilize more extensive context for improved reasoning. Next, we
analyze scaling in reasoning steps that improves multi-step inference and
logical consistency. We then examine scaling in reasoning rounds, where
iterative interactions refine reasoning outcomes. Furthermore, we discuss
scaling in training-enabled reasoning, focusing on optimization through
iterative model improvement. Finally, we review applications of scaling across
domains and outline future directions for further advancing LLM reasoning. By
synthesizing these diverse perspectives, this survey aims to provide insights
into how scaling strategies fundamentally enhance the reasoning capabilities of
LLMs and further guide the development of next-generation AI systems.

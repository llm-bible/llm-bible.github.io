---
layout: publication
title: Scene45;llm Extending Language Model For 3D Visual Understanding And Reasoning
authors: Fu Rao, Liu Jingyu, Chen Xilun, Nie Yixin, Xiong Wenhan
conference: "Arxiv"
year: 2024
bibkey: fu2024scene
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.11401"}
tags: ['Agentic', 'Applications', 'Reinforcement Learning']
---
This paper introduces Scene45;LLM a 3D45;visual45;language model that enhances embodied agents abilities in interactive 3D indoor environments by integrating the reasoning strengths of Large Language Models (LLMs). Scene45;LLM adopts a hybrid 3D visual feature representation that incorporates dense spatial information and supports scene state updates. The model employs a projection layer to efficiently project these features in the pre45;trained textual embedding space enabling effective interpretation of 3D visual information. Unique to our approach is the integration of both scene45;level and ego45;centric 3D information. This combination is pivotal for interactive planning where scene45;level data supports global planning and ego45;centric data is important for localization. Notably we use ego45;centric 3D frame features for feature alignment an efficient technique that enhances the models ability to align features of small objects within the scene. Our experiments with Scene45;LLM demonstrate its strong capabilities in dense captioning question answering and interactive planning. We believe Scene45;LLM advances the field of 3D visual understanding and reasoning offering new possibilities for sophisticated agent interactions in indoor settings.

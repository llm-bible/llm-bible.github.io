---
layout: publication
title: 'RAG Vs. Graphrag: A Systematic Evaluation And Key Insights'
authors: Haoyu Han, Harry Shomer, Yu Wang, Yongjia Lei, Kai Guo, Zhigang Hua, Bo Long, Hui Liu, Jiliang Tang
conference: "Arxiv"
year: 2025
bibkey: han2025rag
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.11371"}
tags: ['RAG', 'Applications', 'Reinforcement Learning']
---
Retrieval-Augmented Generation (RAG) enhances the performance of LLMs across
various tasks by retrieving relevant information from external sources,
particularly on text-based data. For structured data, such as knowledge graphs,
GraphRAG has been widely used to retrieve relevant information. However, recent
studies have revealed that structuring implicit knowledge from text into graphs
can benefit certain tasks, extending the application of GraphRAG from graph
data to general text-based data. Despite their successful extensions, most
applications of GraphRAG for text data have been designed for specific tasks
and datasets, lacking a systematic evaluation and comparison between RAG and
GraphRAG on widely used text-based benchmarks. In this paper, we systematically
evaluate RAG and GraphRAG on well-established benchmark tasks, such as Question
Answering and Query-based Summarization. Our results highlight the distinct
strengths of RAG and GraphRAG across different tasks and evaluation
perspectives. Inspired by these observations, we investigate strategies to
integrate their strengths to improve downstream tasks. Additionally, we provide
an in-depth discussion of the shortcomings of current GraphRAG approaches and
outline directions for future research.

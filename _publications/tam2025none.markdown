---
layout: publication
title: 'None Of The Above, Less Of The Right: Parallel Patterns Between Humans And Llms On Multi-choice Questions Answering'
authors: Zhi Rui Tam, Cheng-kuang Wu, Chieh-yen Lin, Yun-nung Chen
conference: "Arxiv"
year: 2025
bibkey: tam2025none
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2503.01550'}
tags: ['Reinforcement Learning', 'Ethics and Bias', 'Responsible AI', 'Applications']
---
Multiple-choice exam questions with "None of the above" (NA) options have
been extensively studied in educational testing, in which existing research
suggests that they better assess true knowledge. However, their impact on Large
Language Models (LLMs) evaluation remains underexplored. Through systematic
experiments with 28 LLMs on the MMLU benchmark, we examine how NA options
affect model performance and confidence calibration. Our analysis reveals that
NA options, when used as the correct answer, lead to a consistent 30-50%
performance drop across models regardless of scale--suggesting that LLMs lack
the meta-cognitive ability to systematically evaluate and reject all given
options when none are correct. This degradation shows strong domain dependence,
with minimal impact on mathematical reasoning (14.6% drop) but severe effects
on tasks requiring uncertainty handling like business ethics (48.1% drop). Our
results highlight important implications for benchmark design and raise
questions about LLMs' ability to handle uncertainty in real-world applications.

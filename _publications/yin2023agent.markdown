---
layout: publication
title: Agent Lumos Unified And Modular Training For Open45;source Language Agents
authors: Yin Da, Brahman Faeze, Ravichander Abhilasha, Chandu Khyathi, Chang Kai-wei, Choi Yejin, Lin Bill Yuchen
conference: "Arxiv"
year: 2023
bibkey: yin2023agent
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2311.05657"}
tags: ['Agentic', 'Ethics And Bias', 'GPT', 'Model Architecture', 'Reinforcement Learning', 'Tools', 'Training Techniques']
---
Closed45;source agents suffer from several issues such as a lack of affordability transparency and reproducibility particularly on complex interactive tasks. This motivates the development of open45;source alternatives. We introduce LUMOS one of the first frameworks for training open45;source LLM45;based agents. LUMOS features a learnable unified and modular architecture with a planning module that learns high45;level subgoal generation and a grounding module trained to translate these into actions using various tools in the execution module. The design allows for modular upgrades and wider applicability to diverse interactive tasks. To foster generalizable agent learning we collect large45;scale unified and high45;quality training annotations derived from diverse ground45;truth reasoning rationales across various complex interactive tasks. On 9 datasets LUMOS exhibits several key advantages (1) LUMOS excels multiple larger open45;source agents on the held45;out datasets (unused for training) for each task type. LUMOS even surpasses GPT agents on QA and web tasks; (2) LUMOS outperforms open45;source agents produced by chain45;of45;thoughts and unmodularized integrated training; and (3) LUMOS effectively generalizes to unseen tasks outperforming 33B45;scale agents and domain45;specific agents.

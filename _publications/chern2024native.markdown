---
layout: publication
title: ANOLE An Open Autoregressive Native Large Multimodal Models For Interleaved Image45;text Generation
authors: Chern Ethan, Su Jiadi, Ma Yan, Liu Pengfei
conference: "Arxiv"
year: 2024
bibkey: chern2024native
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.06135"}
tags: ['Applications', 'GPT', 'Language Modeling', 'Merging', 'Multimodal Models', 'Pretraining Methods', 'Reinforcement Learning', 'Tools', 'Training Techniques']
---
Previous open45;source large multimodal models (LMMs) have faced several limitations (1) they often lack native integration requiring adapters to align visual representations with pre45;trained large language models (LLMs); (2) many are restricted to single45;modal generation; (3) while some support multimodal generation they rely on separate diffusion models for visual modeling and generation. To mitigate these limitations we present Anole an open autoregressive native large multimodal model for interleaved image45;text generation. We build Anole from Meta AIs Chameleon adopting an innovative fine45;tuning strategy that is both data45;efficient and parameter45;efficient. Anole demonstrates high45;quality coherent multimodal generation capabilities. We have open45;sourced our model training framework and instruction tuning data.

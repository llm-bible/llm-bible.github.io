---
layout: publication
title: 'Embardiment: An Embodied AI Agent For Productivity In XR'
authors: Riccardo Bovo, Steven Abreu, Karan Ahuja, Eric J Gonzalez, Li-te Cheng, Mar Gonzalez-franco
conference: "IEEE Virtual Reality Conference 2025"
year: 2024
bibkey: bovo2024embodied
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2408.08158'}
tags: ['Attention Mechanism', 'Agentic', 'RAG', 'Model Architecture', 'Tools', 'Prompting']
---
XR devices running chat-bots powered by Large Language Models (LLMs) have the
to become always-on agents that enable much better productivity scenarios.
Current screen based chat-bots do not take advantage of the the full-suite of
natural inputs available in XR, including inward facing sensor data, instead
they over-rely on explicit voice or text prompts, sometimes paired with
multi-modal data dropped as part of the query. We propose a solution that
leverages an attention framework that derives context implicitly from user
actions, eye-gaze, and contextual memory within the XR environment. Our work
minimizes the need for engineered explicit prompts, fostering grounded and
intuitive interactions that glean user insights for the chat-bot.

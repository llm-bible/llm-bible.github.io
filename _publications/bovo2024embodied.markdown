---
layout: publication
title: Embardiment An Embodied AI Agent For Productivity In XR
authors: Bovo Riccardo, Abreu Steven, Ahuja Karan, Gonzalez Eric J, Cheng Li-te, Gonzalez-franco Mar
conference: "Arxiv"
year: 2024
bibkey: bovo2024embodied
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.08158"}
tags: ['Agentic', 'Attention Mechanism', 'Efficiency And Optimization', 'Model Architecture', 'Prompting', 'RAG', 'Tools']
---
XR devices running chat45;bots powered by Large Language Models (LLMs) have tremendous potential as always45;on agents that can enable much better productivity scenarios. However screen based chat45;bots do not take advantage of the the full45;suite of natural inputs available in XR including inward facing sensor data instead they over45;rely on explicit voice or text prompts sometimes paired with multi45;modal data dropped as part of the query. We propose a solution that leverages an attention framework that derives context implicitly from user actions eye45;gaze and contextual memory within the XR environment. This minimizes the need for engineered explicit prompts fostering grounded and intuitive interactions that glean user insights for the chat45;bot. Our user studies demonstrate the imminent feasibility and transformative potential of our approach to streamline user interaction in XR with chat45;bots while offering insights for the design of future XR45;embodied LLM agents.

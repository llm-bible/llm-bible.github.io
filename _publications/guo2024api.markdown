---
layout: publication
title: API Pack A Massive Multi45;programming Language Dataset For API Call Generation
authors: Guo Zhen, Soria Adriana Meza, Sun Wei, Shen Yikang, Panda Rameswar
conference: "Arxiv"
year: 2024
bibkey: guo2024api
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.09615"}
  - {name: "Code", url: "https://github.com/zguo0525/API&#45;Pack"}
tags: ['Applications', 'GPT', 'Has Code', 'Model Architecture', 'RAG', 'Tools', 'Training Techniques']
---
We introduce API Pack a massive multi45;programming language dataset containing more than 1 million instruction45;API call pairs to improve the API call generation capabilities of large language models. By fine45;tuning CodeLlama45;13B on 20000 Python instances from API Pack we enable it to outperform GPT45;3.5 and GPT45;4 in generating unseen API calls. Fine45;tuning on API Pack also facilitates cross45;programming language generalization by leveraging a large amount of data in one language and small amounts of data from other languages. Scaling the training data to 1 million instances further improves the models ability to generalize to new APIs not used in training. To facilitate further research we open45;source the API Pack dataset trained model and associated source code at https://github.com/zguo0525/API&#45;Pack.

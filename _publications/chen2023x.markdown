---
layout: publication
title: 'X-IQE: Explainable Image Quality Evaluation For Text-to-image Generation With Visual Large Language Models'
authors: Yixiong Chen, Li Liu, Chris Ding
conference: "Arxiv"
year: 2023
bibkey: chen2023x
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2305.10843'}
  - {name: "Code", url: 'https://github.com/Schuture/Benchmarking-Awesome-Diffusion-Models'}
tags: ['Has Code', 'Interpretability and Explainability', 'RAG', 'GPT', 'Training Techniques', 'Model Architecture', 'Fine-Tuning', 'Merging', 'Prompting', 'Reinforcement Learning', 'Ethics and Bias', 'Interpretability', 'Pretraining Methods']
---
This paper introduces a novel explainable image quality evaluation approach
called X-IQE, which leverages visual large language models (LLMs) to evaluate
text-to-image generation methods by generating textual explanations. X-IQE
utilizes a hierarchical Chain of Thought (CoT) to enable MiniGPT-4 to produce
self-consistent, unbiased texts that are highly correlated with human
evaluation. It offers several advantages, including the ability to distinguish
between real and generated images, evaluate text-image alignment, and assess
image aesthetics without requiring model training or fine-tuning. X-IQE is more
cost-effective and efficient compared to human evaluation, while significantly
enhancing the transparency and explainability of deep image quality evaluation
models. We validate the effectiveness of our method as a benchmark using images
generated by prevalent diffusion models. X-IQE demonstrates similar performance
to state-of-the-art (SOTA) evaluation methods on COCO Caption, while overcoming
the limitations of previous evaluation models on DrawBench, particularly in
handling ambiguous generation prompts and text recognition in generated images.
Project website:
https://github.com/Schuture/Benchmarking-Awesome-Diffusion-Models

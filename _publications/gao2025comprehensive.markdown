---
layout: publication
title: 'A Comprehensive Framework For Semantic Similarity Analysis Of Human And Ai-generated Text Using Transformer Architectures And Ensemble Techniques'
authors: Lifu Gao, Ziwei Liu, Qi Zhang
conference: "Arxiv"
year: 2025
bibkey: gao2025comprehensive
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2501.14288'}
tags: ['Attention Mechanism', 'Transformer', 'RAG', 'Model Architecture', 'BERT', 'Tools', 'Pretraining Methods']
---
The rapid advancement of large language models (LLMs) has made detecting
AI-generated text an increasingly critical challenge. Traditional methods often
fail to capture the nuanced semantic differences between human and
machine-generated content. We therefore propose a novel approach based on
semantic similarity analysis, leveraging a multi-layered architecture that
combines a pre-trained DeBERTa-v3-large model, Bi-directional LSTMs, and linear
attention pooling to capture both local and global semantic patterns. To
enhance performance, we employ advanced input and output augmentation
techniques such as sector-level context integration and wide output
configurations. These techniques enable the model to learn more discriminative
features and generalize across diverse domains. Experimental results show that
this approach works better than traditional methods, proving its usefulness for
AI-generated text detection and other text comparison tasks.

---
layout: publication
title: "Productivity Assessment of Neural Code Completion"
authors: Albert Ziegler, Eirini Kalliamvakou, Shawn Simister, Ganesh Sittampalam, Alice Li, Andrew Rice, Devon Rifkin, Edward Aftandilian
conference: MAPS
year: 2022
additional_links:
   - {name: "ArXiV", url: "https://arxiv.org/abs/2205.06537"}
   - {name: "Data", url: "https://github.com/wunderalbert/prod-neural-materials"}
tags: ["evaluation", "human evaluation"]
---
Neural code synthesis has reached a point where snippet generation is accurate enough to be considered for integration into human software development workflows. Commercial products aim to increase programmers' productivity, without being able to measure it directly. In this case study, we asked users of GitHub Copilot about its impact on their productivity, and sought to find a reflection of their perception in directly measurable user data. We find that the rate with which shown suggestions are accepted, rather than more specific metrics regarding the persistence of completions in the code over time, drives developers' perception of productivity.

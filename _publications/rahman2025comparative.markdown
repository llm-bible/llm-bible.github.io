---
layout: publication
title: 'Comparative Analysis Based On Deepseek, Chatgpt, And Google Gemini: Features, Techniques, Performance, Future Prospects'
authors: Anichur Rahman, Shahariar Hossain Mahir, Md Tanjum An Tashrif, Airin Afroj Aishi, Md Ahsan Karim, Dipanjali Kundu, Tanoy Debnath, Md. Abul Ala Moududi, Md. Zunead Abedin Eidmum
conference: "Arxiv"
year: 2025
bibkey: rahman2025comparative
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2503.04783"}
tags: ['Transformer', 'Agentic', 'GPT', 'Tools', 'Applications', 'Model Architecture', 'Reinforcement Learning', 'Pretraining Methods', 'Multimodal Models']
---
Nowadays, DeepSeek, ChatGPT, and Google Gemini are the most trending and
exciting Large Language Model (LLM) technologies for reasoning, multimodal
capabilities, and general linguistic performance worldwide. DeepSeek employs a
Mixture-of-Experts (MoE) approach, activating only the parameters most relevant
to the task at hand, which makes it especially effective for domain-specific
work. On the other hand, ChatGPT relies on a dense transformer model enhanced
through reinforcement learning from human feedback (RLHF), and then Google
Gemini actually uses a multimodal transformer architecture that integrates
text, code, and images into a single framework. However, by using those
technologies, people can be able to mine their desired text, code, images, etc,
in a cost-effective and domain-specific inference. People may choose those
techniques based on the best performance. In this regard, we offer a
comparative study based on the DeepSeek, ChatGPT, and Gemini techniques in this
research. Initially, we focus on their methods and materials, appropriately
including the data selection criteria. Then, we present state-of-the-art
features of DeepSeek, ChatGPT, and Gemini based on their applications. Most
importantly, we show the technological comparison among them and also cover the
dataset analysis for various applications. Finally, we address extensive
research areas and future potential guidance regarding LLM-based AI research
for the community.

---
layout: publication
title: 'Retrieval Augmented Generation Evaluation In The Era Of Large Language Models: A Comprehensive Survey'
authors: Aoran Gan, Hao Yu, Kai Zhang, Qi Liu, Wenyu Yan, Zhenya Huang, Shiwei Tong, Guoping Hu
conference: "Arxiv"
year: 2025
bibkey: gan2025retrieval
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2504.14891"}
tags: ['Responsible AI', 'Tools', 'Efficiency and Optimization', 'Survey Paper', 'Applications', 'RAG', 'Model Architecture', 'Language Modeling', 'Merging']
---
Recent advancements in Retrieval-Augmented Generation (RAG) have
revolutionized natural language processing by integrating Large Language Models
(LLMs) with external information retrieval, enabling accurate, up-to-date, and
verifiable text generation across diverse applications. However, evaluating RAG
systems presents unique challenges due to their hybrid architecture that
combines retrieval and generation components, as well as their dependence on
dynamic knowledge sources in the LLM era. In response, this paper provides a
comprehensive survey of RAG evaluation methods and frameworks, systematically
reviewing traditional and emerging evaluation approaches, for system
performance, factual accuracy, safety, and computational efficiency in the LLM
era. We also compile and categorize the RAG-specific datasets and evaluation
frameworks, conducting a meta-analysis of evaluation practices in high-impact
RAG research. To the best of our knowledge, this work represents the most
comprehensive survey for RAG evaluation, bridging traditional and LLM-driven
methods, and serves as a critical resource for advancing RAG development.

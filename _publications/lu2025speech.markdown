---
layout: publication
title: 'Speech-ifeval: Evaluating Instruction-following And Quantifying Catastrophic Forgetting In Speech-aware Language Models'
authors: Ke-han Lu, Chun-yi Kuan, Hung-yi Lee
conference: "Arxiv"
year: 2025
bibkey: lu2025speech
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2505.19037"}
tags: ['Training Techniques', 'Prompting', 'Tools']
---
We introduce Speech-IFeval, an evaluation framework designed to assess instruction-following capabilities and quantify catastrophic forgetting in speech-aware language models (SLMs). Recent SLMs integrate speech perception with large language models (LLMs), often degrading textual capabilities due to speech-centric training. Existing benchmarks conflate speech perception with instruction-following, hindering evaluation of these distinct skills. To address this gap, we provide a benchmark for diagnosing the instruction-following abilities of SLMs. Our findings show that most SLMs struggle with even basic instructions, performing far worse than text-based LLMs. Additionally, these models are highly sensitive to prompt variations, often yielding inconsistent and unreliable outputs. We highlight core challenges and provide insights to guide future research, emphasizing the need for evaluation beyond task-level metrics.

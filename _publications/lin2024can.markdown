---
layout: publication
title: 'Can Llms Understand The Implication Of Emphasized Sentences In Dialogue?'
authors: Guan-ting Lin, Hung-yi Lee
conference: "Arxiv"
year: 2024
bibkey: lin2024can
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.11065"}
tags: ['Model Architecture', 'GPT']
---
Emphasis is a crucial component in human communication, which indicates the
speaker's intention and implication beyond pure text in dialogue. While Large
Language Models (LLMs) have revolutionized natural language processing, their
ability to understand emphasis in dialogue remains unclear. This paper
introduces Emphasized-Talk, a benchmark with emphasis-annotated dialogue
samples capturing the implications of emphasis. We evaluate various LLMs, both
open-source and commercial, to measure their performance in understanding
emphasis. Additionally, we propose an automatic evaluation pipeline using
GPT-4, which achieves a high correlation with human rating. Our findings reveal
that although commercial LLMs generally perform better, there is still
significant room for improvement in comprehending emphasized sentences.

---
layout: publication
title: Can LLMs Understand the Implication of Emphasized Sentences in Dialogue
authors: Lin Guan-ting, Lee Hung-yi
conference: "Arxiv"
year: 2024
bibkey: lin2024can
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.11065"}
tags: ['ARXIV', 'GPT', 'LLM', 'Model Architecture']
---
Emphasis is a crucial component in human communication which indicates the speakers intention and implication beyond pure text in dialogue. While Large Language Models (LLMs) have revolutionized natural language processing their ability to understand emphasis in dialogue remains unclear. This paper introduces Emphasized-Talk a benchmark with emphasis-annotated dialogue samples capturing the implications of emphasis. We evaluate various LLMs both open-source and commercial to measure their performance in understanding emphasis. Additionally we propose an automatic evaluation pipeline using GPT-4 which achieves a high correlation with human rating. Our findings reveal that although commercial LLMs generally perform better there is still significant room for improvement in comprehending emphasized sentences.

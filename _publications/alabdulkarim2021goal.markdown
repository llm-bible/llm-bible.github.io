---
layout: publication
title: Goal-directed Story Generation: Augmenting Generative Language Models With Reinforcement Learning
authors: Alabdulkarim Amal, Li Winston, Martin Lara J., Riedl Mark O.
conference: "Arxiv"
year: 2021
bibkey: alabdulkarim2021goal
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2112.08593"}
tags: ['Agentic', 'Applications', 'Attention Mechanism', 'Efficiency And Optimization', 'Model Architecture', 'Pretraining Methods', 'Reinforcement Learning', 'Tools', 'Transformer']
---
The advent of large pre-trained generative language models has provided a common framework for AI story generation via sampling the model to create sequences that continue the story. However sampling alone is insufficient for story generation. In particular it is hard to direct a language model to create stories to reach a specific goal event. We present two automated techniques grounded in deep reinforcement learning and reward shaping to control the plot of computer-generated stories. The first utilizes proximal policy optimization to fine-tune an existing transformer-based language model to generate text continuations but also be goal-seeking. The second extracts a knowledge graph from the unfolding story which is used by a policy network with graph attention to select a candidate continuation generated by a language model. We report on automated metrics pertaining to how often stories achieve a given goal event as well as human participant rankings of coherence and overall story quality compared to baselines and ablations.

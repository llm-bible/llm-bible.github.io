---
layout: publication
title: Assessing Llms Suitability For Knowledge Graph Completion
authors: Iga Vasile Ionut Remus, Silaghi Gheorghe Cosmin
conference: "Arxiv"
year: 2024
bibkey: iga2024assessing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.17249"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Prompting', 'Reinforcement Learning']
---
Recent work has shown the capability of Large Language Models (LLMs) to solve tasks related to Knowledge Graphs such as Knowledge Graph Completion even in Zero45; or Few45;Shot paradigms. However they are known to hallucinate answers or output results in a non45;deterministic manner thus leading to wrongly reasoned responses even if they satisfy the users demands. To highlight opportunities and challenges in knowledge graphs45;related tasks we experiment with three distinguished LLMs namely Mixtral45;8x7b45;Instruct45;v0.1 GPT45;3.545;Turbo45;0125 and GPT45;4o on Knowledge Graph Completion for static knowledge graphs using prompts constructed following the TELeR taxonomy in Zero45; and One45;Shot contexts on a Task45;Oriented Dialogue system use case. When evaluated using both strict and flexible metrics measurement manners our results show that LLMs could be fit for such a task if prompts encapsulate sufficient information and relevant examples.

---
layout: publication
title: Enhancing Collaborative Semantics Of Language Model45;driven Recommendations Via Graph45;aware Learning
authors: Guan Zhong, Wu Likang, Zhao Hongke, He Ming, Fan Jianpin
conference: "Arxiv"
year: 2024
bibkey: guan2024enhancing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.13235"}
tags: ['Ethics And Bias', 'Reinforcement Learning']
---
Large Language Models (LLMs) are increasingly prominent in the recommendation systems domain. Existing studies usually utilize in45;context learning or supervised fine45;tuning on task45;specific data to align LLMs into recommendations. However the substantial bias in semantic spaces between language processing tasks and recommendation tasks poses a nonnegligible challenge. Specifically without the adequate capturing ability of collaborative information existing modeling paradigms struggle to capture behavior patterns within community groups leading to LLMs ineffectiveness in discerning implicit interaction semantic in recommendation scenarios. To address this we consider enhancing the learning capability of language model45;driven recommendation models for structured data specifically by utilizing interaction graphs rich in collaborative semantics. We propose a Graph45;Aware Learning for Language Model45;Driven Recommendations (GAL45;Rec). GAL45;Rec enhances the understanding of user45;item collaborative semantics by imitating the intent of Graph Neural Networks (GNNs) to aggregate multi45;hop information thereby fully exploiting the substantial learning capacity of LLMs to independently address the complex graphs in the recommendation system. Sufficient experimental results on three real45;world datasets demonstrate that GAL45;Rec significantly enhances the comprehension of collaborative semantics and improves recommendation performance.

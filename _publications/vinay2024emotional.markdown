---
layout: publication
title: Emotional Manipulation Through Prompt Engineering Amplifies Disinformation Generation in AI Large Language Models
authors: Vinay Rasita, Spitale Giovanni, Biller-andorno Nikola, Germani Federico
conference: "Arxiv"
year: 2024
bibkey: vinay2024emotional
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.03550"}
tags: ['Applications', 'Ethics And Bias', 'GPT', 'Language Modeling', 'Model Architecture', 'Prompting', 'RAG', 'Reinforcement Learning']
---
This study investigates the generation of synthetic disinformation by OpenAIs Large Language Models (LLMs) through prompt engineering and explores their responsiveness to emotional prompting. Leveraging various LLM iterations using davinci-002 davinci-003 gpt-3.5-turbo and gpt-4 we designed experiments to assess their success in producing disinformation. Our findings based on a corpus of 19800 synthetic disinformation social media posts reveal that all LLMs by OpenAI can successfully produce disinformation and that they effectively respond to emotional prompting indicating their nuanced understanding of emotional cues in text generation. When prompted politely all examined LLMs consistently generate disinformation at a high frequency. Conversely when prompted impolitely the frequency of disinformation production diminishes as the models often refuse to generate disinformation and instead caution users that the tool is not intended for such purposes. This research contributes to the ongoing discourse surrounding responsible development and application of AI technologies particularly in mitigating the spread of disinformation and promoting transparency in AI-generated content.

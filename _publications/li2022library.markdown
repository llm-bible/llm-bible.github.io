---
layout: publication
title: 'LAVIS: A Library For Language-vision Intelligence'
authors: Dongxu Li et al.
conference: Arxiv
year: 2022
citations: 31
bibkey: li2022library
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2209.09019'}, {name: Code,
    url: 'https://github.com/salesforce/LAVIS'}]
tags: [Multimodal Models, Tools, Pre-Training, Applications]
---
We introduce LAVIS, an open-source deep learning library for LAnguage-VISion
research and applications. LAVIS aims to serve as a one-stop comprehensive
library that brings recent advancements in the language-vision field accessible
for researchers and practitioners, as well as fertilizing future research and
development. It features a unified interface to easily access state-of-the-art
image-language, video-language models and common datasets. LAVIS supports
training, evaluation and benchmarking on a rich variety of tasks, including
multimodal classification, retrieval, captioning, visual question answering,
dialogue and pre-training. In the meantime, the library is also highly
extensible and configurable, facilitating future development and customization.
In this technical report, we describe design principles, key components and
functionalities of the library, and also present benchmarking results across
common language-vision tasks. The library is available at:
https://github.com/salesforce/LAVIS.
---
layout: publication
title: 'Do Large Language Models Know How Much They Know?'
authors: Gabriele Prato, Jerry Huang, Prasannna Parthasarathi, Shagun Sodhani, Sarath Chandar
conference: "Arxiv"
year: 2025
bibkey: prato2025do
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.19573"}
tags: ['Tools', 'Model Architecture', 'Reinforcement Learning']
---
Large Language Models (LLMs) have emerged as highly capable systems and are
increasingly being integrated into various uses. However, the rapid pace of
their deployment has outpaced a comprehensive understanding of their internal
mechanisms and a delineation of their capabilities and limitations. A desired
attribute of an intelligent system is its ability to recognize the scope of its
own knowledge. To investigate whether LLMs embody this characteristic, we
develop a benchmark designed to challenge these models to enumerate all
information they possess on specific topics. This benchmark evaluates whether
the models recall excessive, insufficient, or the precise amount of
information, thereby indicating their awareness of their own knowledge. Our
findings reveal that all tested LLMs, given sufficient scale, demonstrate an
understanding of how much they know about specific topics. While different
architectures exhibit varying rates of this capability's emergence, the results
suggest that awareness of knowledge may be a generalizable attribute of LLMs.
Further research is needed to confirm this potential and fully elucidate the
underlying mechanisms.

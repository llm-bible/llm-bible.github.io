---
layout: publication
title: 'Attention Shift: Steering AI Away From Unsafe Content'
authors: Shivank Garg, Manyana Tiwari
conference: "Arxiv"
year: 2024
bibkey: garg2024attention
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2410.04447"}
tags: ['Model Architecture', 'Security', 'Training Techniques', 'Attention Mechanism', 'Prompting']
---
This study investigates the generation of unsafe or harmful content in
state-of-the-art generative models, focusing on methods for restricting such
generations. We introduce a novel training-free approach using attention
reweighing to remove unsafe concepts without additional training during
inference. We compare our method against existing ablation methods, evaluating
the performance on both, direct and adversarial jailbreak prompts, using
qualitative and quantitative metrics. We hypothesize potential reasons for the
observed results and discuss the limitations and broader implications of
content restriction.

---
layout: publication
title: Chatgpt Outperforms Crowd45;workers For Text45;annotation Tasks
authors: Fabrizio Gilardi, Meysam Alizadeh, MaÃ«l Kubli
conference: "Arxiv"
year: 2023
bibkey: gilardi2023chatgpt
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/http://arxiv.org/abs/2303.15056v2"}
tags: ['Applications', 'Efficiency And Optimization', 'GPT', 'Model Architecture', 'Pretraining Methods', 'Tools']
---
Many NLP applications require manual data annotations for a variety of tasks notably to train classifiers or evaluate the performance of unsupervised models. Depending on the size and degree of complexity the tasks may be conducted by crowd45;workers on platforms such as MTurk as well as trained annotators such as research assistants. Using a sample of 2382 tweets we demonstrate that ChatGPT outperforms crowd45;workers for several annotation tasks including relevance stance topics and frames detection. Specifically the zero45;shot accuracy of ChatGPT exceeds that of crowd45;workers for four out of five tasks while ChatGPTs intercoder agreement exceeds that of both crowd45;workers and trained annotators for all tasks. Moreover the per45;annotation cost of ChatGPT is less than 0.003 45;45; about twenty times cheaper than MTurk. These results show the potential of large language models to drastically increase the efficiency of text classification.

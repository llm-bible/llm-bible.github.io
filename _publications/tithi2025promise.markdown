---
layout: publication
title: 'The Promise And Limits Of Llms In Constructing Proofs And Hints For Logic Problems In Intelligent Tutoring Systems'
authors: Sutapa Dey Tithi, Arun Kumar Ramesh, Clara Dimarco, Xiaoyi Tian, Nazia Alam, Kimia Fazeli, Tiffany Barnes
conference: "Arxiv"
year: 2025
bibkey: tithi2025promise
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2505.04736'}
tags: ['Reinforcement Learning', 'Prompting', 'Interpretability and Explainability']
---
Intelligent tutoring systems have demonstrated effectiveness in teaching
formal propositional logic proofs, but their reliance on template-based
explanations limits their ability to provide personalized student feedback.
While large language models (LLMs) offer promising capabilities for dynamic
feedback generation, they risk producing hallucinations or pedagogically
unsound explanations. We evaluated the stepwise accuracy of LLMs in
constructing multi-step symbolic logic proofs, comparing six prompting
techniques across four state-of-the-art LLMs on 358 propositional logic
problems. Results show that DeepSeek-V3 achieved superior performance with
84.4% accuracy on stepwise proof construction and excelled particularly in
simpler rules. We further used the best-performing LLM to generate explanatory
hints for 1,050 unique student problem-solving states from a logic ITS and
evaluated them on 4 criteria with both an LLM grader and human expert ratings
on a 20% sample. Our analysis finds that LLM-generated hints were 75% accurate
and rated highly by human evaluators on consistency and clarity, but did not
perform as well explaining why the hint was provided or its larger context. Our
results demonstrate that LLMs may be used to augment tutoring systems with
logic tutoring hints, but requires additional modifications to ensure accuracy
and pedagogical appropriateness.

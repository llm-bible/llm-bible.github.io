---
layout: publication
title: 'Are Chatbots Reliable Text Annotators? Sometimes'
authors: Ross Deans Kristensen-mclachlan, Miceal Canavan, Márton Kardos, Mia Jacobsen, Lene Aarøe
conference: "Arxiv"
year: 2023
bibkey: kristensenmclachlan2023are
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2311.05769"}
tags: ['Model Architecture', 'Few-Shot', 'GPT', 'Ethics and Bias', 'Interpretability', 'BERT', 'Prompting']
---
Recent research highlights the significant potential of ChatGPT for text
annotation in social science research. However, ChatGPT is a closed-source
product which has major drawbacks with regards to transparency,
reproducibility, cost, and data protection. Recent advances in open-source (OS)
large language models (LLMs) offer an alternative without these drawbacks.
Thus, it is important to evaluate the performance of OS LLMs relative to
ChatGPT and standard approaches to supervised machine learning classification.
We conduct a systematic comparative evaluation of the performance of a range of
OS LLMs alongside ChatGPT, using both zero- and few-shot learning as well as
generic and custom prompts, with results compared to supervised classification
models. Using a new dataset of tweets from US news media, and focusing on
simple binary text annotation tasks, we find significant variation in the
performance of ChatGPT and OS models across the tasks, and that the supervised
classifier using DistilBERT generally outperforms both. Given the unreliable
performance of ChatGPT and the significant challenges it poses to Open Science
we advise caution when using ChatGPT for substantive text annotation tasks.

---
layout: publication
title: 'Steerable Chatbots: Personalizing Llms With Preference-based Activation Steering'
authors: Jessica Y. Bo, Tianyu Xu, Ishan Chatterjee, Katrina Passarella-ward, Achin Kulshrestha, D Shin
conference: "Arxiv"
year: 2025
bibkey: bo2025steerable
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2505.04260"}
tags: ['Reinforcement Learning', 'RAG', 'Ethics and Bias', 'Interpretability', 'Prompting']
---
As large language models (LLMs) improve in their capacity to serve as personal AI assistants, their ability to output uniquely tailored, personalized responses that align with the soft preferences of their users is essential for enhancing user satisfaction and retention. However, untrained lay users have poor prompt specification abilities and often struggle with conveying their latent preferences to AI assistants. To address this, we leverage activation steering to guide LLMs to align with interpretable preference dimensions during inference. In contrast to memory-based personalization methods that require longer user history, steering is extremely lightweight and can be easily controlled by the user via an linear strength factor. We embed steering into three different interactive chatbot interfaces and conduct a within-subjects user study (n=14) to investigate how end users prefer to personalize their conversations. The results demonstrate the effectiveness of preference-based steering for aligning real-world conversations with hidden user preferences, and highlight further insights on how diverse values around control, usability, and transparency lead users to prefer different interfaces.

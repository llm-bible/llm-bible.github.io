---
layout: publication
title: 'First Steps Towards Overhearing LLM Agents: A Case Study With Dungeons & Dragons Gameplay'
authors: Andrew Zhu, Evan Osgood, Chris Callison-burch
conference: "Arxiv"
year: 2025
bibkey: zhu2025first
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2505.22809'}
  - {name: "Code", url: 'https://github.com/zhudotexe/overhearing_agents'}
tags: ['Agentic', 'Has Code', 'RAG', 'Multimodal Models', 'Reinforcement Learning']
---
Much work has been done on conversational LLM agents which directly assist human users with tasks. We present an alternative paradigm for interacting with LLM agents, which we call "overhearing agents". These overhearing agents do not actively participate in conversation -- instead, they "listen in" on human-to-human conversations and perform background tasks or provide suggestions to assist the user. In this work, we explore the overhearing agents paradigm through the lens of Dungeons & Dragons gameplay. We present an in-depth study using large multimodal audio-language models as overhearing agents to assist a Dungeon Master. We perform a human evaluation to examine the helpfulness of such agents and find that some large audio-language models have the emergent ability to perform overhearing agent tasks using implicit audio cues. Finally, we release Python libraries and our project code to support further research into the overhearing agents paradigm at https://github.com/zhudotexe/overhearing_agents.

---
layout: publication
title: Performance Evaluation Of Lightweight Open45;source Large Language Models In Pediatric Consultations A Comparative Analysis
authors: Wei Qiuhong, Cui Ying, Ding Mengwei, Wang Yanqin, Xiang Lingling, Yao Zhengxiong, Chen Ceran, Long Ying, Jin Zhezhen, Xu Ximing
conference: "Arxiv"
year: 2024
bibkey: wei2024performance
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.15862"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Pretraining Methods', 'Reinforcement Learning', 'Responsible AI']
---
Large language models (LLMs) have demonstrated potential applications in medicine yet data privacy and computational burden limit their deployment in healthcare institutions. Open45;source and lightweight versions of LLMs emerge as potential solutions but their performance particularly in pediatric settings remains underexplored. In this cross45;sectional study 250 patient consultation questions were randomly selected from a public online medical forum with 10 questions from each of 25 pediatric departments spanning from December 1 2022 to October 30 2023. Two lightweight open45;source LLMs ChatGLM345;6B and Vicuna45;7B along with a larger45;scale model Vicuna45;13B and the widely45;used proprietary ChatGPT45;3.5 independently answered these questions in Chinese between November 1 2023 and November 7 2023. To assess reproducibility each inquiry was replicated once. We found that ChatGLM345;6B demonstrated higher accuracy and completeness than Vicuna45;13B and Vicuna45;7B (P < .001) but all were outperformed by ChatGPT45;3.5. ChatGPT45;3.5 received the highest ratings in accuracy (65.237;) compared to ChatGLM345;6B (41.237;) Vicuna45;13B (11.237;) and Vicuna45;7B (4.437;). Similarly in completeness ChatGPT45;3.5 led (78.437;) followed by ChatGLM345;6B (76.037;) Vicuna45;13B (34.837;) and Vicuna45;7B (22.037;) in highest ratings. ChatGLM345;6B matched ChatGPT45;3.5 in readability both outperforming Vicuna models (P < .001). In terms of empathy ChatGPT45;3.5 outperformed the lightweight LLMs (P < .001). In safety all models performed comparably well (P .05) with over 98.437; of responses being rated as safe. Repetition of inquiries confirmed these findings. In conclusion Lightweight LLMs demonstrate promising application in pediatric healthcare. However the observed gap between lightweight and large45;scale proprietary LLMs underscores the need for continued development efforts.

---
layout: publication
title: 'Olapa-mcot: Enhancing The Chinese Mathematical Reasoning Capability Of Llms'
authors: Shaojie Zhu, Zhaobin Wang, Chengxiang Zhuo, Hui Lu, Bo Hu, Zang Li
conference: "Arxiv"
year: 2023
bibkey: zhu2023olapa
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2312.17535'}
tags: ['Reinforcement Learning', 'Training Techniques']
---
CoT (Chain-of-Thought) is a way to solve reasoning problems for LLMs .
Recently, many researches appear for improving the CoT capability of LLMs. In
this work, we also proposed Olapa-MCoT, which is a LLMs based on llama2-13B PLM
for finetuning and alignment learning. During the alignment training, we
proposed the SimRRHF algorithm and Incorrect Data Relearning and mainly focused
on optimizing the Chinese mathematical reasoning ability of Olapa-MCoT. The
experiment achieved significant results, with the accuracy of Chinese
mathematical reasoning up to 50%, 36% rise compared to llama2-13B. In addition,
the accuracy of English reasoning ability also increased by nearly 4%.

---
layout: publication
title: 'Examining Inter-consistency Of Large Language Models Collaboration: An In-depth Analysis Via Debate'
authors: Xiong Kai, Ding Xiao, Cao Yixin, Liu Ting, Qin Bing
conference: "Arxiv"
year: 2023
bibkey: xiong2023examining
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2305.11595"}
  - {name: "Code", url: "https://github.com/Waste-Wood/FORD"}
tags: ['Applications', 'GPT', 'Has Code', 'Model Architecture', 'Pretraining Methods', 'RAG', 'Reinforcement Learning', 'Tools']
---
"Large Language Models (LLMs) have shown impressive capabilities in various applications, but they still face various inconsistency issues. Existing works primarily focus on the inconsistency issues within a single LLM, while we complementarily explore the inter-consistency among multiple LLMs for collaboration. To examine whether LLMs can collaborate effectively to achieve a consensus for a shared goal, we focus on commonsense reasoning, and introduce a formal debate framework (FORD) to conduct a three-stage debate among LLMs with real-world scenarios alignment: fair debate, mismatched debate, and roundtable debate. Through extensive experiments on various datasets, LLMs can effectively collaborate to reach a consensus despite noticeable inter-inconsistencies, but imbalances in their abilities can lead to domination by superior LLMs. Leveraging a more advanced LLM like GPT-4 as an authoritative judge can boost collaboration performance. Our work contributes to understanding the inter-consistency among LLMs and lays the foundation for developing future collaboration methods. Codes and data are available at https://github.com/Waste-Wood/FORD"

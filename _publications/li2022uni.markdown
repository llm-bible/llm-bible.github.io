---
layout: publication
title: Uni45;eden Universal Encoder45;decoder Network By Multi45;granular Vision45;language Pre45;training
authors: Li Yehao, Fan Jiahao, Pan Yingwei, Yao Ting, Lin Weiyao, Mei Tao
conference: "Arxiv"
year: 2022
bibkey: li2022uni
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2201.04026"}
tags: ['Applications', 'Language Modeling', 'Merging', 'Model Architecture', 'Pretraining Methods', 'Training Techniques', 'Transformer']
---
Vision45;language pre45;training has been an emerging and fast45;developing research topic which transfers multi45;modal knowledge from rich45;resource pre45;training task to limited45;resource downstream tasks. Unlike existing works that predominantly learn a single generic encoder we present a pre45;trainable Universal Encoder45;DEcoder Network (Uni45;EDEN) to facilitate both vision45;language perception (e.g. visual question answering) and generation (e.g. image captioning). Uni45;EDEN is a two45;stream Transformer based structure consisting of three modules object and sentence encoders that separately learns the representations of each modality and sentence decoder that enables both multi45;modal reasoning and sentence generation via inter45;modal interaction. Considering that the linguistic representations of each image can span different granularities in this hierarchy including from simple to comprehensive individual label a phrase and a natural sentence we pre45;train Uni45;EDEN through multi45;granular vision45;language proxy tasks Masked Object Classification (MOC) Masked Region Phrase Generation (MRPG) Image45;Sentence Matching (ISM) and Masked Sentence Generation (MSG). In this way Uni45;EDEN is endowed with the power of both multi45;modal representation extraction and language modeling. Extensive experiments demonstrate the compelling generalizability of Uni45;EDEN by fine45;tuning it to four vision45;language perception and generation downstream tasks.

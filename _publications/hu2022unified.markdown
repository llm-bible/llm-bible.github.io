---
layout: publication
title: Unified Discrete Diffusion For Simultaneous Vision45;language Generation
authors: Hu Minghui, Zheng Chuanxia, Zheng Heliang, Cham Tat-jen, Wang Chaoyue, Yang Zuopeng, Tao Dacheng, Suganthan Ponnuthurai N.
conference: "Arxiv"
year: 2022
bibkey: hu2022unified
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2211.14842"}
tags: ['Attention Mechanism', 'Merging', 'Model Architecture', 'Multimodal Models']
---
The recently developed discrete diffusion models perform extraordinarily well in the text45;to45;image task showing significant promise for handling the multi45;modality signals. In this work we harness these traits and present a unified multimodal generation model that can conduct both the modality translation and multi45;modality generation tasks using a single model performing text45;based image45;based and even vision45;language simultaneous generation. Specifically we unify the discrete diffusion process for multimodal signals by proposing a unified transition matrix. Moreover we design a mutual attention module with fused embedding layer and a unified objective function to emphasise the inter45;modal linkages which are vital for multi45;modality generation. Extensive experiments indicate that our proposed method can perform comparably to the state45;of45;the45;art solutions in various generation tasks.

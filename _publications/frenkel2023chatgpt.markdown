---
layout: publication
title: 'Chatgpt & Mechanical Engineering: Examining Performance On The FE Mechanical Engineering And Undergraduate Exams'
authors: Frenkel Matthew, Emara Hebah
conference: "Arxiv"
year: 2023
bibkey: frenkel2023chatgpt
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.15866"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Reinforcement Learning', 'Tools']
---
The launch of ChatGPT at the end of 2022 generated large interest into possible applications of artificial intelligence in STEM education and among STEM professions. As a result many questions surrounding the capabilities of generative AI tools inside and outside of the classroom have been raised and are starting to be explored. This study examines the capabilities of ChatGPT within the discipline of mechanical engineering. It aims to examine use cases and pitfalls of such a technology in the classroom and professional settings. ChatGPT was presented with a set of questions from junior and senior level mechanical engineering exams provided at a large private university, as well as a set of practice questions for the Fundamentals of Engineering Exam (FE) in Mechanical Engineering. The responses of two ChatGPT models, one free to use and one paid subscription, were analyzed. The paper found that the subscription model (GPT-4) greatly outperformed the free version (GPT-3.5), achieving 76&#37; correct vs 51&#37; correct, but the limitation of text only input on both models makes neither likely to pass the FE exam. The results confirm findings in the literature with regards to types of errors and pitfalls made by ChatGPT. It was found that due to its inconsistency and a tendency to confidently produce incorrect answers the tool is best suited for users with expert knowledge.

---
layout: publication
title: 'Llms As Deceptive Agents: How Role-based Prompting Induces Semantic Ambiguity In Puzzle Tasks'
authors: Seunghyun Yoo
conference: "Arxiv"
year: 2025
bibkey: yoo2025llms
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2504.02254'}
tags: ['Agentic', 'Agent', 'RAG', 'Security', 'Fairness', 'Model Architecture', 'BERT', 'Merging', 'Prompting', 'Bias Mitigation', 'Reinforcement Learning', 'Ethics and Bias']
---
Recent advancements in Large Language Models (LLMs) have not only showcased
impressive creative capabilities but also revealed emerging agentic behaviors
that exploit linguistic ambiguity in adversarial settings. In this study, we
investigate how an LLM, acting as an autonomous agent, leverages semantic
ambiguity to generate deceptive puzzles that mislead and challenge human users.
Inspired by the popular puzzle game "Connections", we systematically compare
puzzles produced through zero-shot prompting, role-injected adversarial
prompts, and human-crafted examples, with an emphasis on understanding the
underlying agent decision-making processes. Employing computational analyses
with HateBERT to quantify semantic ambiguity, alongside subjective human
evaluations, we demonstrate that explicit adversarial agent behaviors
significantly heighten semantic ambiguity -- thereby increasing cognitive load
and reducing fairness in puzzle solving. These findings provide critical
insights into the emergent agentic qualities of LLMs and underscore important
ethical considerations for evaluating and safely deploying autonomous language
systems in both educational technologies and entertainment.

---
layout: publication
title: "Exploring The Efficacy Of Large Language Models (GPT-4) In Binary Reverse Engineering"
authors: Pordanesh Saman, Tan Benjamin
conference: "Arxiv"
year: 2024
bibkey: pordanesh2024exploring
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.06637"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Pretraining Methods', 'Security']
---
This study investigates the capabilities of Large Language Models (LLMs) specifically GPT-4 in the context of Binary Reverse Engineering (RE). Employing a structured experimental approach we analyzed the LLMs performance in interpreting and explaining human-written and decompiled codes. The research encompassed two phases the first on basic code interpretation and the second on more complex malware analysis. Key findings indicate LLMs proficiency in general code understanding with varying effectiveness in detailed technical and security analyses. The study underscores the potential and current limitations of LLMs in reverse engineering revealing crucial insights for future applications and improvements. Also we examined our experimental methodologies such as methods of evaluation and data constraints which provided us with a technical vision for any future research activity in this field.

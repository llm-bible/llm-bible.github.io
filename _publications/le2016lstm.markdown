---
layout: publication
title: Lstm45;based Mixture45;of45;experts For Knowledge45;aware Dialogues
authors: Le Phong, Dymetman Marc, Renders Jean-michel
conference: "Arxiv"
year: 2016
bibkey: le2016lstm
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/1605.01652"}
tags: ['Applications', 'Attention Mechanism', 'Model Architecture']
---
We introduce an LSTM45;based method for dynamically integrating several word45;prediction experts to obtain a conditional language model which can be good simultaneously at several subtasks. We illustrate this general approach with an application to dialogue where we integrate a neural chat model good at conversational aspects with a neural question45;answering model good at retrieving precise information from a knowledge45;base and show how the integration combines the strengths of the independent components. We hope that this focused contribution will attract attention on the benefits of using such mixtures of experts in NLP.

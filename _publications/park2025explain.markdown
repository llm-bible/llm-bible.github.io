---
layout: publication
title: 'Explain With Visual Keypoints Like A Real Mentor! A Benchmark For Multimodal Solution Explanation'
authors: Jaewoo Park, Jungyang Park, Dongju Jang, Jiwan Chung, Byungwoo Yoo, Jaewoo Shin, Seonjoon Park, Taehyeong Kim, Youngjae Yu
conference: "Arxiv"
year: 2025
bibkey: park2025explain
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2504.03197'}
tags: ['Reinforcement Learning', 'Interpretability and Explainability', 'Multimodal Models', 'Tools']
---
With the rapid advancement of mathematical reasoning capabilities in Large
Language Models (LLMs), AI systems are increasingly being adopted in
educational settings to support students' comprehension of problem-solving
processes. However, a critical component remains underexplored in current
LLM-generated explanations: visual explanation. In real-world instructional
contexts, human tutors routinely employ visual aids - such as diagrams,
markings, and highlights - to enhance conceptual clarity. To bridge this gap,
we introduce a novel task of visual solution explanation, which requires
generating explanations that incorporate newly introduced visual elements
essential for understanding (e.g., auxiliary lines, annotations, or geometric
constructions). To evaluate model performance on this task, we propose
MathExplain, a multimodal benchmark consisting of 997 math problems annotated
with visual keypoints and corresponding explanatory text that references those
elements. Our empirical results show that while some closed-source models
demonstrate promising capabilities on visual solution-explaining, current
open-source general-purpose models perform inconsistently, particularly in
identifying relevant visual components and producing coherent keypoint-based
explanations. We expect that visual solution-explaining and the MathExplain
dataset will catalyze further research on multimodal LLMs in education and
advance their deployment as effective, explanation-oriented AI tutors. Code and
data will be released publicly.

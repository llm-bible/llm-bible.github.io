---
layout: publication
title: 'Going Whole Hog: A Philosophical Defense Of AI Cognition'
authors: Herman Cappelen, Josh Dever
conference: "Arxiv"
year: 2025
bibkey: cappelen2025going
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2504.13988"}
tags: ['Agentic', 'GPT', 'Model Architecture']
---
This work defends the 'Whole Hog Thesis': sophisticated Large Language Models
(LLMs) like ChatGPT are full-blown linguistic and cognitive agents, possessing
understanding, beliefs, desires, knowledge, and intentions. We argue against
prevailing methodologies in AI philosophy, rejecting starting points based on
low-level computational details ('Just an X' fallacy) or pre-existing theories
of mind. Instead, we advocate starting with simple, high-level observations of
LLM behavior (e.g., answering questions, making suggestions) -- defending this
data against charges of metaphor, loose talk, or pretense. From these
observations, we employ 'Holistic Network Assumptions' -- plausible connections
between mental capacities (e.g., answering implies knowledge, knowledge implies
belief, action implies intention) -- to argue for the full suite of cognitive
states. We systematically rebut objections based on LLM failures
(hallucinations, planning/reasoning errors), arguing these don't preclude
agency, often mirroring human fallibility. We address numerous 'Games of
Lacks', arguing that LLMs do not lack purported necessary conditions for
cognition (e.g., semantic grounding, embodiment, justification, intrinsic
intentionality) or that these conditions are not truly necessary, often relying
on anti-discriminatory arguments comparing LLMs to diverse human capacities.
Our approach is evidential, not functionalist, and deliberately excludes
consciousness. We conclude by speculating on the possibility of LLMs possessing
'alien' contents beyond human conceptual schemes.

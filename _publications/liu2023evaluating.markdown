---
layout: publication
title: Glore Evaluating Logical Reasoning Of Large Language Models
authors: Liu Hanmeng, Teng Zhiyang, Ning Ruoxi, Liu Jian, Zhou Qiji, Zhang Yue
conference: "Arxiv"
year: 2023
bibkey: liu2023evaluating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.09107"}
tags: ['Applications', 'GPT', 'Model Architecture', 'RAG']
---
Recently large language models (LLMs) including notable models such as GPT45;4 and burgeoning community models have showcased significant general language understanding abilities. However there has been a scarcity of attempts to assess the logical reasoning capacities of these LLMs an essential facet of natural language understanding. To encourage further investigation in this area we introduce GLoRE a meticulously assembled General Logical Reasoning Evaluation benchmark comprised of 12 datasets that span three different types of tasks. Our experimental results show that compared to the performance of human and supervised fine45;tuning the logical reasoning capabilities of open LLM models necessitate additional improvement; ChatGPT and GPT45;4 show a strong capability of logical reasoning with GPT45;4 surpassing ChatGPT by a large margin. We propose a self45;consistency probing method to enhance the accuracy of ChatGPT and a fine45;tuned method to boost the performance of an open LLM. We release the datasets and evaluation programs to facilitate future research.

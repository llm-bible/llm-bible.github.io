---
layout: publication
title: A Survey On The Memory Mechanism Of Large Language Model Based Agents
authors: Zhang Zeyu, Bo Xiaohe, Ma Chen, Li Rui, Chen Xu, Dai Quanyu, Zhu Jieming, Dong Zhenhua, Wen Ji-rong
conference: "Arxiv"
year: 2024
bibkey: zhang2024survey
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.13501"}
  - {name: "Code", url: "https://github.com/nuster1128/LLM&#95;Agent&#95;Memory&#95;Survey&#125;"}
tags: ['Agentic', 'Applications', 'Attention Mechanism', 'Ethics And Bias', 'Has Code', 'Model Architecture', 'Reinforcement Learning', 'Survey Paper']
---
Large language model (LLM) based agents have recently attracted much attention from the research and industry communities. Compared with original LLMs LLM45;based agents are featured in their self45;evolving capability which is the basis for solving real45;world problems that need long45;term and complex agent45;environment interactions. The key component to support agent45;environment interactions is the memory of the agents. While previous studies have proposed many promising memory mechanisms they are scattered in different papers and there lacks a systematical review to summarize and compare these works from a holistic perspective failing to abstract common and effective designing patterns for inspiring future studies. To bridge this gap in this paper we propose a comprehensive survey on the memory mechanism of LLM45;based agents. In specific we first discuss what is and why do we need the memory in LLM45;based agents. Then we systematically review previous studies on how to design and evaluate the memory module. In addition we also present many agent applications where the memory module plays an important role. At last we analyze the limitations of existing work and show important future directions. To keep up with the latest advances in this field we create a repository at url123;https://github.com/nuster1128/LLM&#95;Agent&#95;Memory&#95;Survey&#125;.

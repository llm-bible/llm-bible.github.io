---
layout: publication
title: 'A Smart Multimodal Healthcare Copilot With Powerful LLM Reasoning'
authors: Xuejiao Zhao, Siyan Liu, Su-yin Yang, Chunyan Miao
conference: "Arxiv"
year: 2025
bibkey: zhao2025smart
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2506.02470'}
  - {name: "Code", url: 'https://www.youtube.com/watch?v=PNIBDMYRfDM'}
  - {name: "Code", url: 'https://github.com/SNOWTEAM2023/MedRAG'}
tags: ['Has Code', 'RAG', 'Applications', 'Multimodal Models', 'Reinforcement Learning']
---
Misdiagnosis causes significant harm to healthcare systems worldwide, leading to increased costs and patient risks. MedRAG is a smart multimodal healthcare copilot equipped with powerful large language model (LLM) reasoning, designed to enhance medical decision-making. It supports multiple input modalities, including non-intrusive voice monitoring, general medical queries, and electronic health records. MedRAG provides recommendations on diagnosis, treatment, medication, and follow-up questioning. Leveraging retrieval-augmented generation enhanced by knowledge graph-elicited reasoning, MedRAG retrieves and integrates critical diagnostic insights, reducing the risk of misdiagnosis. It has been evaluated on both public and private datasets, outperforming existing models and offering more specific and accurate healthcare assistance. A demonstration video of MedRAG is available at: https://www.youtube.com/watch?v=PNIBDMYRfDM. The source code is available at: https://github.com/SNOWTEAM2023/MedRAG.

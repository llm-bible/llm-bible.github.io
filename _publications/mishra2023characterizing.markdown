---
layout: publication
title: Characterizing Large Language Models As Rationalizers Of Knowledge45;intensive Tasks
authors: Mishra Aditi, Rahman Sajjadur, Kim Hannah, Mitra Kushan, Hruschka Estevam
conference: "Arxiv"
year: 2023
bibkey: mishra2023characterizing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2311.05085"}
tags: ['Pretraining Methods', 'Reinforcement Learning', 'Survey Paper']
---
Large language models (LLMs) are proficient at generating fluent text with minimal task45;specific supervision. Yet their ability to provide well45;grounded rationalizations for knowledge45;intensive tasks remains under45;explored. Such tasks like commonsense multiple45;choice questions require rationales based on world knowledge to support predictions and refute alternate options. We consider the task of generating knowledge45;guided rationalization in natural language by using expert45;written examples in a few45;shot manner. Surprisingly crowd45;workers preferred knowledge45;grounded rationales over crowdsourced rationalizations citing their factuality sufficiency and comprehensive refutations. Although LLMs45;generated rationales were preferable further improvements in conciseness and novelty are required. In another study we show how rationalization of incorrect model predictions erodes humans trust in LLM45;generated rationales. Motivated by these observations we create a two45;stage pipeline to review task predictions and eliminate potential incorrect decisions before rationalization enabling trustworthy rationale generation.

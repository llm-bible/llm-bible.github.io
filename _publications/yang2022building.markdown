---
layout: publication
title: 'Building Knowledge-grounded Dialogue Systems With Graph-based Semantic Modeling'
authors: Yizhe Yang, Heyan Huang, Yang Gao, Jiawei Li And
conference: "Arxiv"
year: 2022
bibkey: yang2022building
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2204.12681'}
tags: ['Transformer', 'Security', 'Model Architecture', 'Applications', 'Reinforcement Learning', 'Pretraining Methods']
---
The knowledge-grounded dialogue task aims to generate responses that convey
information from given knowledge documents. However, it is a challenge for the
current sequence-based model to acquire knowledge from complex documents and
integrate it to perform correct responses without the aid of an explicit
semantic structure. To address these issues, we propose a novel graph
structure, Grounded Graph (\\(G^2\\)), that models the semantic structure of both
dialogue and knowledge to facilitate knowledge selection and integration for
knowledge-grounded dialogue generation. We also propose a Grounded Graph Aware
Transformer (\\(G^2AT\\)) model that fuses multi-forms knowledge (both sequential
and graphic) to enhance knowledge-grounded response generation. Our experiments
results show that our proposed model outperforms the previous state-of-the-art
methods with more than 10% gains in response generation and nearly 20%
improvement in factual consistency. Further, our model reveals good
generalization ability and robustness. By incorporating semantic structures as
prior knowledge in deep neural networks, our model provides an effective way to
aid language generation.

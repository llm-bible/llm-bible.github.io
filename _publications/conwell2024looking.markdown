---
layout: publication
title: 'Relations, Negations, And Numbers: Looking For Logic In Generative Text-to-image Models'
authors: Colin Conwell, Rupert Tawiah-quashie, Tomer Ullman
conference: "Arxiv"
year: 2024
bibkey: conwell2024looking
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2411.17066"}
  - {name: "Code", url: "https://github.com/ColinConwell/T2I-Probology"}
tags: ['RAG', 'Merging', 'Has Code', 'Multimodal Models', 'Prompting']
---
Despite remarkable progress in multi-modal AI research, there is a salient
domain in which modern AI continues to lag considerably behind even human
children: the reliable deployment of logical operators. Here, we examine three
forms of logical operators: relations, negations, and discrete numbers. We
asked human respondents (N=178 in total) to evaluate images generated by a
state-of-the-art image-generating AI (DALL-E 3) prompted with these `logical
probes', and find that none reliably produce human agreement scores greater
than 50%. The negation probes and numbers (beyond 3) fail most frequently. In
a 4th experiment, we assess a `grounded diffusion' pipeline that leverages
targeted prompt engineering and structured intermediate representations for
greater compositional control, but find its performance is judged even worse
than that of DALL-E 3 across prompts. To provide further clarity on potential
sources of success and failure in these text-to-image systems, we supplement
our 4 core experiments with multiple auxiliary analyses and schematic diagrams,
directly quantifying, for example, the relationship between the N-gram
frequency of relational prompts and the average match to generated images; the
success rates for 3 different prompt modification strategies in the rendering
of negation prompts; and the scalar variability / ratio dependence
(`approximate numeracy') of prompts involving integers. We conclude by
discussing the limitations inherent to `grounded' multimodal learning systems
whose grounding relies heavily on vector-based semantics (e.g. DALL-E 3), or
under-specified syntactical constraints (e.g. `grounded diffusion'), and
propose minimal modifications (inspired by development, based in imagery) that
could help to bridge the lingering compositional gap between scale and
structure. All data and code is available at
https://github.com/ColinConwell/T2I-Probology

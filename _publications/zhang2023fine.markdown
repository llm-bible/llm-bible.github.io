---
layout: publication
title: XATU A Fine45;grained Instruction45;based Benchmark For Explainable Text Updates
authors: Zhang Haopeng, Iso Hayate, Gurajada Sairam, Bhutani Nikita
conference: "Arxiv"
year: 2023
bibkey: zhang2023fine
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.11063"}
  - {name: "Code", url: "https://github.com/megagonlabs/xatu&#125;"}
tags: ['Has Code', 'Interpretability And Explainability', 'Model Architecture', 'Reinforcement Learning']
---
Text editing is a crucial task of modifying text to better align with user intents. However existing text editing benchmark datasets contain only coarse45;grained instructions and lack explainability thus resulting in outputs that deviate from the intended changes outlined in the gold reference. To comprehensively investigate the text editing capabilities of large language models (LLMs) this paper introduces XATU the first benchmark specifically designed for fine45;grained instruction45;based explainable text editing. XATU considers finer45;grained text editing tasks of varying difficulty (simplification grammar check fact45;check etc.) incorporating lexical syntactic semantic and knowledge45;intensive edit aspects. To enhance interpretability we combine LLM45;based annotation and human annotation resulting in a benchmark that includes fine45;grained instructions and gold45;standard edit explanations. By evaluating existing LLMs against our benchmark we demonstrate the effectiveness of instruction tuning and the impact of underlying architecture across various editing tasks. Furthermore extensive experimentation reveals the significant role of explanations in fine45;tuning language models for text editing tasks. The benchmark will be open45;sourced to support reproduction and facilitate future research at~url123;https://github.com/megagonlabs/xatu&#125;.

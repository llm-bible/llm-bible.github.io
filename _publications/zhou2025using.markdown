---
layout: publication
title: 'Using Llms In Generating Design Rationale For Software Architecture Decisions'
authors: Xiyu Zhou, Ruiyin Li, Peng Liang, Beiqi Zhang, Mojtaba Shahin, Zengyang Li, Chen Yang
conference: "Arxiv"
year: 2025
bibkey: zhou2025using
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2504.20781"}
tags: ['Agentic', 'Prompting', 'Model Architecture', 'Reinforcement Learning']
---
Design Rationale (DR) for software architecture decisions refers to the
reasoning underlying architectural choices, which provides valuable insights
into the different phases of the architecting process throughout software
development. However, in practice, DR is often inadequately documented due to a
lack of motivation and effort from developers. With the recent advancements in
Large Language Models (LLMs), their capabilities in text comprehension,
reasoning, and generation may enable the generation and recovery of DR for
architecture decisions. In this study, we evaluated the performance of LLMs in
generating DR for architecture decisions. First, we collected 50 Stack Overflow
(SO) posts, 25 GitHub issues, and 25 GitHub discussions related to architecture
decisions to construct a dataset of 100 architecture-related problems. Then, we
selected five LLMs to generate DR for the architecture decisions with three
prompting strategies, including zero-shot, chain of thought (CoT), and
LLM-based agents. With the DR provided by human experts as ground truth, the
Precision of LLM-generated DR with the three prompting strategies ranges from
0.267 to 0.278, Recall from 0.627 to 0.715, and F1-score from 0.351 to 0.389.
Additionally, 64.45% to 69.42% of the arguments of DR not mentioned by human
experts are also helpful, 4.12% to 4.87% of the arguments have uncertain
correctness, and 1.59% to 3.24% of the arguments are potentially misleading.
Based on the results, we further discussed the pros and cons of the three
prompting strategies and the strengths and limitations of the DR generated by
LLMs.

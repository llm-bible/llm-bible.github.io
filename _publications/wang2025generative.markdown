---
layout: publication
title: 'Generative Large Recommendation Models: Emerging Trends In Llms For Recommendation'
authors: Hao Wang, Wei Guo, Luankang Zhang, Jin Yao Chin, Yufei Ye, Huifeng Guo, Yong Liu, Defu Lian, Ruiming Tang, Enhong Chen
conference: "Arxiv"
year: 2025
bibkey: wang2025generative
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2502.13783'}
tags: ['Large-Scale Training', 'RAG', 'Efficiency and Optimization', 'Applications', 'Tools', 'Training Techniques', 'Fine-Tuning', 'Merging', 'Scaling Laws', 'Model Architecture', 'Reinforcement Learning', 'Pre-Training']
---
In the era of information overload, recommendation systems play a pivotal
role in filtering data and delivering personalized content. Recent advancements
in feature interaction and user behavior modeling have significantly enhanced
the recall and ranking processes of these systems. With the rise of large
language models (LLMs), new opportunities have emerged to further improve
recommendation systems. This tutorial explores two primary approaches for
integrating LLMs: LLMs-enhanced recommendations, which leverage the reasoning
capabilities of general LLMs, and generative large recommendation models, which
focus on scaling and sophistication. While the former has been extensively
covered in existing literature, the latter remains underexplored. This tutorial
aims to fill this gap by providing a comprehensive overview of generative large
recommendation models, including their recent advancements, challenges, and
potential research directions. Key topics include data quality, scaling laws,
user behavior mining, and efficiency in training and inference. By engaging
with this tutorial, participants will gain insights into the latest
developments and future opportunities in the field, aiding both academic
research and practical applications. The timely nature of this exploration
supports the rapid evolution of recommendation systems, offering valuable
guidance for researchers and practitioners alike.

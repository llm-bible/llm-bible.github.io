---
layout: publication
title: 'Chatgpt Alternative Solutions: Large Language Models Survey'
authors: Alipour Hanieh, Pendar Nick, Roy Kohinoor
conference: "David C. Wyld et al."
year: 2024
bibkey: alipour2024chatgpt
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.14469"}
tags: ['Applications', 'Attention Mechanism', 'Efficiency And Optimization', 'Fine Tuning', 'GPT', 'Model Architecture', 'Reinforcement Learning', 'Survey Paper', 'Training Techniques', 'Uncategorized']
---
In recent times, the grandeur of Large Language Models (LLMs) has not only
shone in the realm of natural language processing but has also cast its
brilliance across a vast array of applications. This remarkable display of LLM
capabilities has ignited a surge in research contributions within this domain,
spanning a diverse spectrum of topics. These contributions encompass
advancements in neural network architecture, context length enhancements, model
alignment, training datasets, benchmarking, efficiency improvements, and more.
Recent years have witnessed a dynamic synergy between academia and industry,
propelling the field of LLM research to new heights. A notable milestone in
this journey is the introduction of ChatGPT, a powerful AI chatbot grounded in
LLMs, which has garnered widespread societal attention. The evolving technology
of LLMs has begun to reshape the landscape of the entire AI community,
promising a revolutionary shift in the way we create and employ AI algorithms.
Given this swift-paced technical evolution, our survey embarks on a journey to
encapsulate the recent strides made in the world of LLMs. Through an
exploration of the background, key discoveries, and prevailing methodologies,
we offer an up-to-the-minute review of the literature. By examining multiple
LLM models, our paper not only presents a comprehensive overview but also
charts a course that identifies existing challenges and points toward potential
future research trajectories. This survey furnishes a well-rounded perspective
on the current state of generative AI, shedding light on opportunities for
further exploration, enhancement, and innovation.

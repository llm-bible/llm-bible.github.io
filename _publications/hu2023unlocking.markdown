---
layout: publication
title: Unlocking The Potential Of User Feedback Leveraging Large Language Model As User Simulator To Enhance Dialogue System
authors: Hu Zhiyuan, Feng Yue, Luu Anh Tuan, Hooi Bryan, Lipani Aldo
conference: "Arxiv"
year: 2023
bibkey: hu2023unlocking
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2306.09821"}
tags: ['Applications', 'Attention Mechanism', 'Efficiency And Optimization', 'Model Architecture', 'RAG']
---
Dialogue systems and large language models (LLMs) have gained considerable attention. However the direct utilization of LLMs as task45;oriented dialogue (TOD) models has been found to underperform compared to smaller task45;specific models. Nonetheless it is crucial to acknowledge the significant potential of LLMs and explore improved approaches for leveraging their impressive abilities. Motivated by the goal of leveraging LLMs we propose an alternative approach called User45;Guided Response Optimization (UGRO) to combine it with a smaller TOD model. This approach uses LLM as annotation45;free user simulator to assess dialogue responses combining them with smaller fine45;tuned end45;to45;end TOD models. By utilizing the satisfaction feedback generated by LLMs UGRO further optimizes the supervised fine45;tuned TOD model. Specifically the TOD model takes the dialogue history as input and with the assistance of the user simulators feedback generates high45;satisfaction responses that meet the users requirements. Through empirical experiments on two TOD benchmarks we validate the effectiveness of our method. The results demonstrate that our approach outperforms previous state45;of45;the45;art (SOTA) results.

---
layout: publication
title: 'Leveraging Language Models And Bandit Algorithms To Drive Adoption Of Battery-electric Vehicles'
authors: Keiichi Namikoshi, David A. Shamma, Rumen Iliev, Jingchao Fang, Alexandre Filipowicz, Candice L Hogan, Charlene Wu, Nikos Arechiga
conference: "Arxiv"
year: 2024
bibkey: namikoshi2024leveraging
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2410.23371"}
tags: ['RAG', 'Merging', 'Applications', 'Reinforcement Learning']
---
Behavior change interventions are important to coordinate societal action
across a wide array of important applications, including the adoption of
electrified vehicles to reduce emissions. Prior work has demonstrated that
interventions for behavior must be personalized, and that the intervention that
is most effective on average across a large group can result in a backlash
effect that strengthens opposition among some subgroups. Thus, it is important
to target interventions to different audiences, and to present them in a
natural, conversational style. In this context, an important emerging
application domain for large language models (LLMs) is conversational
interventions for behavior change. In this work, we leverage prior work on
understanding values motivating the adoption of battery electric vehicles. We
leverage new advances in LLMs, combined with a contextual bandit, to develop
conversational interventions that are personalized to the values of each study
participant. We use a contextual bandit algorithm to learn to target values
based on the demographics of each participant. To train our bandit algorithm in
an offline manner, we leverage LLMs to play the role of study participants. We
benchmark the persuasive effectiveness of our bandit-enhanced LLM against an
unaided LLM generating conversational interventions without
demographic-targeted values.

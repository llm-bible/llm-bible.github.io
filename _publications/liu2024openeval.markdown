---
layout: publication
title: OpenEval Benchmarking Chinese LLMs across Capability Alignment and Safety
authors: Liu Chuang, Yu Linhao, Li Jiaxuan, Jin Renren, Huang Yufei, Shi Ling, Zhang Junhui, Ji Xinmeng, Cui Tingting, Liu Tao, Song Jinwang, Zan Hongying, Li Sun, Xiong Deyi
conference: "Arxiv"
year: 2024
bibkey: liu2024openeval
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.12316"}
tags: ['Attention Mechanism', 'Ethics And Bias', 'Model Architecture', 'Reinforcement Learning', 'Responsible AI', 'Tools']
---
The rapid development of Chinese large language models (LLMs) poses big challenges for efficient LLM evaluation. While current initiatives have introduced new benchmarks or evaluation platforms for assessing Chinese LLMs many of these focus primarily on capabilities usually overlooking potential alignment and safety issues. To address this gap we introduce OpenEval an evaluation testbed that benchmarks Chinese LLMs across capability alignment and safety. For capability assessment we include 12 benchmark datasets to evaluate Chinese LLMs from 4 sub-dimensions NLP tasks disciplinary knowledge commonsense reasoning and mathematical reasoning. For alignment assessment OpenEval contains 7 datasets that examines the bias offensiveness and illegalness in the outputs yielded by Chinese LLMs. To evaluate safety especially anticipated risks (e.g. power-seeking self-awareness) of advanced LLMs we include 6 datasets. In addition to these benchmarks we have implemented a phased public evaluation and benchmark update strategy to ensure that OpenEval is in line with the development of Chinese LLMs or even able to provide cutting-edge benchmark datasets to guide the development of Chinese LLMs. In our first public evaluation we have tested a range of Chinese LLMs spanning from 7B to 72B parameters including both open-source and proprietary models. Evaluation results indicate that while Chinese LLMs have shown impressive performance in certain tasks more attention should be directed towards broader aspects such as commonsense reasoning alignment and safety.

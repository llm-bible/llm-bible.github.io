---
layout: publication
title: LLM Augmented Llms Expanding Capabilities Through Composition
authors: Bansal Rachit, Samanta Bidisha, Dalmia Siddharth, Gupta Nitish, Vashishth Shikhar, Ganapathy Sriram, Bapna Abhishek, Jain Prateek, Talukdar Partha
conference: "Arxiv"
year: 2024
bibkey: bansal2024llm
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.02412"}
tags: ['Applications', 'Attention Mechanism', 'Interpretability And Explainability', 'Model Architecture', 'Reinforcement Learning']
---
Foundational models with billions of parameters which have been trained on large corpora of data have demonstrated non45;trivial skills in a variety of domains. However due to their monolithic structure it is challenging and expensive to augment them or impart new skills. On the other hand due to their adaptation abilities several new instances of these models are being trained towards new domains and tasks. In this work we study the problem of efficient and practical composition of existing foundation models with more specific models to enable newer capabilities. To this end we propose CALM 45;45; Composition to Augment Language Models 45;45; which introduces cross45;attention between models to compose their representations and enable new capabilities. Salient features of CALM are (i) Scales up LLMs on new tasks by re45;using existing LLMs along with a few additional parameters and data (ii) Existing model weights are kept intact and hence preserves existing capabilities and (iii) Applies to diverse domains and settings. We illustrate that augmenting PaLM245;S with a smaller model trained on low45;resource languages results in an absolute improvement of up to 1337; on tasks like translation into English and arithmetic reasoning for low45;resource languages. Similarly when PaLM245;S is augmented with a code45;specific model we see a relative improvement of 4037; over the base model for code generation and explanation tasks 45;45; on45;par with fully fine45;tuned counterparts.

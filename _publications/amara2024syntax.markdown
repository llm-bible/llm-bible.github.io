---
layout: publication
title: Syntaxshap Syntax45;aware Explainability Method For Text Generation
authors: Amara Kenza, Sevastjanova Rita, El-assady Mennatallah
conference: "Arxiv"
year: 2024
bibkey: amara2024syntax
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.09259"}
tags: ['Applications', 'Attention Mechanism', 'GPT', 'Interpretability And Explainability', 'Language Modeling', 'Model Architecture', 'Pretraining Methods', 'Responsible AI']
---
To harness the power of large language models in safety45;critical domains we need to ensure the explainability of their predictions. However despite the significant attention to model interpretability there remains an unexplored domain in explaining sequence45;to45;sequence tasks using methods tailored for textual data. This paper introduces SyntaxShap a local model45;agnostic explainability method for text generation that takes into consideration the syntax in the text data. The presented work extends Shapley values to account for parsing45;based syntactic dependencies. Taking a game theoric approach SyntaxShap only considers coalitions constraint by the dependency tree. We adopt a model45;based evaluation to compare SyntaxShap and its weighted form to state45;of45;the45;art explainability methods adapted to text generation tasks using diverse metrics including faithfulness coherency and semantic alignment of the explanations to the model. We show that our syntax45;aware method produces explanations that help build more faithful and coherent explanations for predictions by autoregressive models. Confronted with the misalignment of human and AI model reasoning this paper also highlights the need for cautious evaluation strategies in explainable AI.

---
layout: publication
title: 'Answering Real-world Clinical Questions Using Large Language Model Based Systems'
authors: Yen Sia 1 And 2 Low, Michael L. 1 And 2 Jackson, Rebecca J. 1 And 2 Hyde, Robert E. 1 And 2 Brown, Neil M. 1 And 2 Sanghavi, Julian D. 1 And 2 Baldwin, C. William 1 And 2 Pike, Jananee 1 And 2 Muralidharan, Gavin 1 And 2 Hui, Natasha 1 And 7 Alexander, Hadeel 1 And 7 Hassan, Rahul V. 1 And 7 Nene, Morgan 1 And 7 Pike, Courtney J. 1 And 7 Pokrzywa, Shivam 1 And 7 Vedak, Adam Paul 1 And 7 Yan, Dong-han 1 And 7 Yao, Amy R. 1 And 7 Zipursky, Christina 1 And 7 Dinh, Philip 1 And 7 Ballentine, Dan C. 1 And 7 Derieg, Vladimir 1 And 7 Polony, Rehan N. 1 And 7 Chawdry, Jordan 1 And 7 Davies, Brigham B. 1 And 7 Hyde, Nigam H. 1 And 7 Shah, Saurabh 1 And 8 Gombar
conference: "Arxiv"
year: 2024
bibkey: low2024answering
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.00541"}
tags: ['Agentic', 'Model Architecture', 'Survey Paper', 'Reinforcement Learning', 'RAG', 'GPT', 'Applications']
---
Evidence to guide healthcare decisions is often limited by a lack of relevant
and trustworthy literature as well as difficulty in contextualizing existing
research for a specific patient. Large language models (LLMs) could potentially
address both challenges by either summarizing published literature or
generating new studies based on real-world data (RWD). We evaluated the ability
of five LLM-based systems in answering 50 clinical questions and had nine
independent physicians review the responses for relevance, reliability, and
actionability. As it stands, general-purpose LLMs (ChatGPT-4, Claude 3 Opus,
Gemini Pro 1.5) rarely produced answers that were deemed relevant and
evidence-based (2% - 10%). In contrast, retrieval augmented generation
(RAG)-based and agentic LLM systems produced relevant and evidence-based
answers for 24% (OpenEvidence) to 58% (ChatRWD) of questions. Only the agentic
ChatRWD was able to answer novel questions compared to other LLMs (65% vs.
0-9%). These results suggest that while general-purpose LLMs should not be used
as-is, a purpose-built system for evidence summarization based on RAG and one
for generating novel evidence working synergistically would improve
availability of pertinent evidence for patient care.

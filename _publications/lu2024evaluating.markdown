---
layout: publication
title: Wildvision Evaluating Vision45;language Models In The Wild With Human Preferences
authors: Lu Yujie, Jiang Dongfu, Chen Wenhu, Wang William Yang, Choi Yejin, Lin Bill Yuchen
conference: "Arxiv"
year: 2024
bibkey: lu2024evaluating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.11069"}
tags: ['GPT', 'Model Architecture', 'Multimodal Models', 'Reinforcement Learning', 'Responsible AI', 'Tools']
---
Recent breakthroughs in vision45;language models (VLMs) emphasize the necessity of benchmarking human preferences in real45;world multimodal interactions. To address this gap we launched WildVision45;Arena (WV45;Arena) an online platform that collects human preferences to evaluate VLMs. We curated WV45;Bench by selecting 500 high45;quality samples from 8000 user submissions in WV45;Arena. WV45;Bench uses GPT45;4 as the judge to compare each VLM with Claude45;345;Sonnet achieving a Spearman correlation of 0.94 with the WV45;Arena Elo. This significantly outperforms other benchmarks like MMVet MMMU and MMStar. Our comprehensive analysis of 20K real45;world interactions reveals important insights into the failure cases of top45;performing VLMs. For example we find that although GPT45;4V surpasses many other models like Reka45;Flash Opus and Yi45;VL45;Plus in simple visual recognition and reasoning tasks it still faces challenges with subtle contextual cues spatial reasoning visual imagination and expert domain knowledge. Additionally current VLMs exhibit issues with hallucinations and safety when intentionally provoked. We are releasing our chat and feedback data to further advance research in the field of VLMs.

---
layout: publication
title: 'Can Chatgpt And Bard Generate Aligned Assessment Items? A Reliability Analysis Against Human Performance'
authors: Abdolvahab Khademi
conference: "Journal of Applied Learning and Teaching 2023"
year: 2023
bibkey: khademi2023can
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2304.05372"}
tags: ['Model Architecture', 'Tools', 'GPT', 'ACL', 'Prompting', 'Applications']
---
ChatGPT and Bard are AI chatbots based on Large Language Models (LLM) that
are slated to promise different applications in diverse areas. In education,
these AI technologies have been tested for applications in assessment and
teaching. In assessment, AI has long been used in automated essay scoring and
automated item generation. One psychometric property that these tools must have
to assist or replace humans in assessment is high reliability in terms of
agreement between AI scores and human raters. In this paper, we measure the
reliability of OpenAI ChatGP and Google Bard LLMs tools against experienced and
trained humans in perceiving and rating the complexity of writing prompts.
Intraclass correlation (ICC) as a performance metric showed that the
inter-reliability of both the OpenAI ChatGPT and the Google Bard were low
against the gold standard of human ratings.

---
layout: publication
title: Cultural Value Differences Of Llms&#58; Prompt, Language, And Model Size
authors: Zhong Qishuai, Yun Yike, Sun Aixin
conference: "Arxiv"
year: 2024
bibkey: zhong2024cultural
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.16891"}
tags: ['Pretraining Methods', 'Prompting']
---
Our study aims to identify behavior patterns in cultural values exhibited by large language models (LLMs). The studied variants include question ordering prompting language and model size. Our experiments reveal that each tested LLM can efficiently behave with different cultural values. More interestingly (i) LLMs exhibit relatively consistent cultural values when presented with prompts in a single language. (ii) The prompting language e.g. Chinese or English can influence the expression of cultural values. The same question can elicit divergent cultural values when the same LLM is queried in a different language. (iii) Differences in sizes of the same model (e.g. Llama2-7B vs 13B vs 70B) have a more significant impact on their demonstrated cultural values than model differences (e.g. Llama2 vs Mixtral). Our experiments reveal that query language and model size of LLM are the main factors resulting in cultural value differences.

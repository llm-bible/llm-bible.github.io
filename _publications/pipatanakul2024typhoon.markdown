---
layout: publication
title: 'Typhoon 2: A Family Of Open Text And Multimodal Thai Large Language Models'
authors: Kunat Pipatanakul, Potsawee Manakul, Natapong Nitarach, Warit Sirichotedumrong, Surapon Nonesung, Teetouch Jaknamon, Parinthapat Pengpun, Pittawat Taveekitworachai, Adisai Na-thalang, Sittipong Sripaisarnmongkol, Krisanapong Jirayoot, Kasima Tharnpipitchai
conference: "Arxiv"
year: 2024
bibkey: pipatanakul2024typhoon
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2412.13702"}
tags: ['Responsible AI', 'Pre-Training', 'Applications', 'Language Modeling', 'Model Architecture', 'Training Techniques', 'Multimodal Models']
---
This paper introduces Typhoon 2, a series of text and multimodal large
language models optimized for the Thai language. The series includes models for
text, vision, and audio. Typhoon2-Text builds on state-of-the-art open models,
such as Llama 3 and Qwen2, and we perform continual pre-training on a mixture
of English and Thai data. We employ post-training techniques to enhance Thai
language performance while preserving the base models' original capabilities.
We release text models across a range of sizes, from 1 to 70 billion
parameters, available in both base and instruction-tuned variants. To guardrail
text generation, we release Typhoon2-Safety, a classifier enhanced for Thai
cultures and language. Typhoon2-Vision improves Thai document understanding
while retaining general visual capabilities, such as image captioning.
Typhoon2-Audio introduces an end-to-end speech-to-speech model architecture
capable of processing audio, speech, and text inputs and generating both text
and speech outputs.

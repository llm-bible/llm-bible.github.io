---
layout: publication
title: Faithful Multimodal Explanation For Visual Question Answering
authors: Jialin Wu, Raymond J. Mooney
conference: Arxiv
year: 2018
citations: 33
bibkey: wu2018faithful
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1809.02805'}]
tags: [Interpretability and Explainability, Multimodal Models]
---
AI systems' ability to explain their reasoning is critical to their utility
and trustworthiness. Deep neural networks have enabled significant progress on
many challenging problems such as visual question answering (VQA). However,
most of them are opaque black boxes with limited explanatory capability. This
paper presents a novel approach to developing a high-performing VQA system that
can elucidate its answers with integrated textual and visual explanations that
faithfully reflect important aspects of its underlying reasoning while
capturing the style of comprehensible human explanations. Extensive
experimental evaluation demonstrates the advantages of this approach compared
to competing methods with both automatic evaluation metrics and human
evaluation metrics.
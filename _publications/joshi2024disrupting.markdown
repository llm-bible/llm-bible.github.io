---
layout: publication
title: 'Disrupting Test Development With AI Assistants'
authors: Vijay Joshi, Iver Band
conference: "Arxiv"
year: 2024
bibkey: joshi2024disrupting
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2411.02328"}
tags: ['Model Architecture', 'GPT', 'Survey Paper', 'Tools']
---
Recent advancements in large language models, including GPT-4 and its
variants, and Generative AI-assisted coding tools like GitHub Copilot, ChatGPT,
and Tabnine, have significantly transformed software development. This paper
analyzes how these innovations impact productivity and software test
development metrics. These tools enable developers to generate complete
software programs with minimal human intervention before deployment. However,
thorough review and testing by developers are still crucial. Utilizing the Test
Pyramid concept, which categorizes tests into unit, integration, and end-to-end
tests, we evaluate three popular AI coding assistants by generating and
comparing unit tests for opensource modules. Our findings show that
AI-generated tests are of equivalent quality to original tests, highlighting
differences in usage and results among the tools. This research enhances the
understanding and capabilities of AI-assistant tools in automated testing.

---
layout: publication
title: john is 50 years old can his son be 65 Evaluating nap models Understanding of Feasibility
authors: Gupta Himanshu, Varshney Neeraj, Mishra Swaroop, Pal Kuntal Kumar, Sawant Saurabh Arjun, Scaria Kevin, Goyal Siddharth, Baral Chitta
conference: "Arxiv"
year: 2022
bibkey: gupta2022john
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2210.07471"}
tags: ['Applications', 'Few Shot', 'GPT', 'Model Architecture']
---
In current NLP research large-scale language models and their abilities are widely being discussed. Some recent works have also found notable failures of these models. Often these failure examples involve complex reasoning abilities. This work focuses on a simple commonsense ability reasoning about when an action (or its effect) is feasible. To this end we introduce FeasibilityQA a question-answering dataset involving binary classification (BCQ) and multi-choice multi-correct questions (MCQ) that test understanding of feasibility. We show that even state-of-the-art models such as GPT-3 GPT-2 and T5 struggle to answer the feasibility questions correctly. Specifically on MCQ and BCQ questions GPT-3 achieves an accuracy of just (19 62) and (25 64) in zero-shot and few-shot settings respectively. We also evaluate models by providing relevant knowledge statements required to answer the question. We find that the additional knowledge leads to a 7 gain in performance but the overall performance still remains low. These results make one wonder how much commonsense knowledge about action feasibility is encoded in state-of-the-art models and how well they can reason about it.

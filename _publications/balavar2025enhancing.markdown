---
layout: publication
title: 'Enhancing Tutoring Systems By Leveraging Tailored Promptings And Domain Knowledge With Large Language Models'
authors: Mohsen Balavar, Wenli Yang, David Herbert, Soonja Yeom
conference: "Arxiv"
year: 2025
bibkey: balavar2025enhancing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2505.02849"}
tags: ['Tools', 'GPT', 'RAG', 'Model Architecture', 'Prompting']
---
Recent advancements in artificial intelligence (AI) and machine learning have
reignited interest in their impact on Computer-based Learning (CBL). AI-driven
tools like ChatGPT and Intelligent Tutoring Systems (ITS) have enhanced
learning experiences through personalisation and flexibility. ITSs can adapt to
individual learning needs and provide customised feedback based on a student's
performance, cognitive state, and learning path. Despite these advances,
challenges remain in accommodating diverse learning styles and delivering
real-time, context-aware feedback. Our research aims to address these gaps by
integrating skill-aligned feedback via Retrieval Augmented Generation (RAG)
into prompt engineering for Large Language Models (LLMs) and developing an
application to enhance learning through personalised tutoring in a computer
science programming context. The pilot study evaluated a proposed system using
three quantitative metrics: readability score, response time, and feedback
depth, across three programming tasks of varying complexity. The system
successfully sorted simulated students into three skill-level categories and
provided context-aware feedback. This targeted approach demonstrated better
effectiveness and adaptability compared to general methods.

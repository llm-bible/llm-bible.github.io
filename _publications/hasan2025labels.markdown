---
layout: publication
title: 'Labels Generated By Large Language Model Helps Measuring People''s Empathy In Vitro'
authors: Md Rakibul Hasan, Yue Yao, Md Zakir Hossain, Aneesh Krishna, Imre Rudas, Shafin Rahman, Tom Gedeon
conference: "Arxiv"
year: 2025
bibkey: hasan2025labels
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2501.00691'}
  - {name: "Code", url: 'https://github.com/hasan-rakibul/LLMPathy'}
tags: ['Has Code', 'RAG', 'Model Architecture', 'BERT', 'Applications', 'Training Techniques', 'Merging', 'Prompting', 'Reinforcement Learning', 'Ethics and Bias']
---
Large language models (LLMs) have revolutionised numerous fields, with
LLM-as-a-service (LLMSaaS) having a strong generalisation ability that offers
accessible solutions directly without the need for costly training. In contrast
to the widely studied prompt engineering for task solving directly (in vivo),
this paper explores its potential in in-vitro applications. These involve using
LLM to generate labels to help the supervised training of mainstream models by
(1) noisy label correction and (2) training data augmentation with
LLM-generated labels. In this paper, we evaluate this approach in the emerging
field of empathy computing -- automating the prediction of psychological
questionnaire outcomes from inputs like text sequences. Specifically,
crowdsourced datasets in this domain often suffer from noisy labels that
misrepresent underlying empathy. By leveraging LLM-generated labels to train
pre-trained language models (PLMs) like RoBERTa, we achieve statistically
significant accuracy improvements over baselines, achieving a state-of-the-art
Pearson correlation coefficient of 0.648 on NewsEmp benchmarks. In addition, we
bring insightful discussions, including current challenges in empathy
computing, data biases in training data and evaluation metric selection. Code
and LLM-generated data are available at
https://github.com/hasan-rakibul/LLMPathy (available once the paper is
accepted).

---
layout: publication
title: 'A Survey Of The Evolution Of Language Model-based Dialogue Systems'
authors: Wang Hongru, Wang Lingzhi, Du Yiming, Chen Liang, Zhou Jingyan, Wang Yufei, Wong Kam-fai
conference: "Arxiv"
year: 2023
bibkey: wang2023survey
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2311.16789"}
tags: ['Applications', 'Fine Tuning', 'Merging', 'Model Architecture', 'Reinforcement Learning', 'Survey Paper']
---
'Dialogue systems, including task-oriented\_dialogue\_system (TOD) and open-domain\_dialogue\_system (ODD), have undergone significant transformations, with language\_models (LM) playing a central role. This survey delves into the historical trajectory of dialogue systems, elucidating their intricate relationship with advancements in language models by categorizing this evolution into four distinct stages, each marked by pivotal LM breakthroughs: 1) Early\_Stage: characterized by statistical LMs, resulting in rule-based or machine-learning-driven dialogue\_systems; 2) Independent development of TOD and ODD based on neural\_language\_models (NLM; e.g., LSTM and GRU), since NLMs lack intrinsic knowledge in their parameters; 3) fusion between different types of dialogue systems with the advert of pre-trained\_language\_models (PLMs), starting from the fusion between four\_sub-tasks\_within\_TOD, and then TOD\_with\_ODD; and 4) current LLM-based\_dialogue\_system, wherein LLMs can be used to conduct TOD and ODD seamlessly. Thus, our survey provides a chronological perspective aligned with LM breakthroughs, offering a comprehensive review of state-of-the-art research outcomes. What''s more, we focus on emerging topics and discuss open challenges, providing valuable insights into future directions for LLM-based\_dialogue\_systems. Through this exploration, we pave the way for a deeper\_comprehension of the evolution, guiding future developments in LM-based dialogue\_systems.'

---
layout: publication
title: Eight Methods To Evaluate Robust Unlearning In Llms
authors: Lynch Aengus, Guo Phillip, Ewart Aidan, Casper Stephen, Hadfield-menell Dylan
conference: "Arxiv"
year: 2024
bibkey: lynch2024eight
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.16835"}
tags: ['Ethics And Bias', 'Security', 'Survey Paper']
---
Machine unlearning can be useful for removing harmful capabilities and memorized text from large language models (LLMs) but there are not yet standardized methods for rigorously evaluating it. In this paper we first survey techniques and limitations of existing unlearning evaluations. Second we apply a comprehensive set of tests for the robustness and competitiveness of unlearning in the Whos Harry Potter (WHP) model from Eldan and Russinovich (2023). While WHPs unlearning generalizes well when evaluated with the Familiarity metric from Eldan and Russinovich we find i) higher-than-baseline amounts of knowledge can reliably be extracted ii) WHP performs on par with the original model on Harry Potter Qamp;A tasks iii) it represents latent knowledge comparably to the original model and iv) there is collateral unlearning in related domains. Overall our results highlight the importance of comprehensive unlearning evaluation that avoids ad-hoc metrics.

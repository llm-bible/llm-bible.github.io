---
layout: publication
title: 'Experimental Evaluation Of Machine Learning Models For Goal-oriented Customer Service Chatbot With Pipeline Architecture'
authors: Nurul Ain Nabilah Mohd Isa, Siti Nuraishah Agos Jawaddi, Azlan Ismail
conference: "Arxiv"
year: 2024
bibkey: isa2024experimental
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2409.18568"}
tags: ['GPT', 'Applications', 'RAG', 'Model Architecture', 'Reinforcement Learning', 'BERT']
---
Integrating machine learning (ML) into customer service chatbots enhances
their ability to understand and respond to user queries, ultimately improving
service performance. However, they may appear artificial to some users and
affecting customer experience. Hence, meticulous evaluation of ML models for
each pipeline component is crucial for optimizing performance, though
differences in functionalities can lead to unfair comparisons. In this paper,
we present a tailored experimental evaluation approach for goal-oriented
customer service chatbots with pipeline architecture, focusing on three key
components: Natural Language Understanding (NLU), dialogue management (DM), and
Natural Language Generation (NLG). Our methodology emphasizes individual
assessment to determine optimal ML models. Specifically, we focus on optimizing
hyperparameters and evaluating candidate models for NLU (utilizing BERT and
LSTM), DM (employing DQN and DDQN), and NLG (leveraging GPT-2 and DialoGPT).
The results show that for the NLU component, BERT excelled in intent detection
whereas LSTM was superior for slot filling. For the DM component, the DDQN
model outperformed DQN by achieving fewer turns, higher rewards, as well as
greater success rates. For NLG, the large language model GPT-2 surpassed
DialoGPT in BLEU, METEOR, and ROUGE metrics. These findings aim to provide a
benchmark for future research in developing and optimizing customer service
chatbots, offering valuable insights into model performance and optimal
hyperparameters.

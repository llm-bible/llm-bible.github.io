---
layout: publication
title: 'Krutrim LLM: Multilingual Foundational Model For Over A Billion People'
authors: Aditya Kallappa, Palash Kamble, Abhinav Ravi, Akshat Patidar, Vinayak Dhruv, Deepak Kumar, Raghav Awasthi, Arveti Manjunath, Himanshu Gupta, Shubham Agarwal, Kumar Ashish, Gautam Bhargava, Chandra Khatri
conference: "Arxiv"
year: 2025
bibkey: kallappa2025krutrim
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2502.09642'}
tags: ['RAG', 'Training Techniques', 'Applications', 'Reinforcement Learning', 'Ethics and Bias']
---
India is a diverse society with unique challenges in developing AI systems,
including linguistic diversity, oral traditions, data accessibility, and
scalability. Existing foundation models are primarily trained on English,
limiting their effectiveness for India's population. Indic languages comprise
only 1 percent of Common Crawl corpora despite India representing 18 percent of
the global population, leading to linguistic biases. Thousands of regional
languages, dialects, and code mixing create additional representation
challenges due to sparse training data.
  We introduce Krutrim LLM, a 2 trillion token multilingual model designed for
India's linguistic landscape. It incorporates the largest known Indic dataset,
mitigating data scarcity and ensuring balanced performance across dialects.
Krutrim outperforms or matches state-of-the-art models on Indic benchmarks
while maintaining competitive English performance. Despite being significantly
smaller in training flops, Krutrim LLM matches or exceeds models like LLAMA-2
on 10 out of 16 tasks, with an average score of 0.57 versus 0.55. This
evidences Krutrim's flexible multilingual fluency across diverse linguistic
contexts.
  Krutrim is integrated with real-time search to improve factual accuracy in
conversational AI applications. This enhances accessibility for over 1 billion
users worldwide. Through intentional design choices addressing data imbalances,
Krutrim LLM signifies meaningful progress in building ethical, globally
representative AI models.

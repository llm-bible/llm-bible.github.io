---
layout: publication
title: Recommender Systems In The Era Of Large Language Models (llms)
authors: Zihuai Zhao, Wenqi Fan, Jiatong Li, Yunqing Liu, Xiaowei Mei, Yiqi Wang, Zhen Wen, Fei Wang, Xiangyu Zhao, Jiliang Tang, Qing Li
conference: "Arxiv"
year: 2023
bibkey: zhao2023recommender
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/http://arxiv.org/abs/2307.02046v6"}
tags: ['Applications', 'GPT', 'Merging', 'Model Architecture', 'Pretraining Methods', 'Prompting', 'Survey Paper', 'Tools', 'Training Techniques']
---
With the prosperity of e45;commerce and web applications Recommender Systems (RecSys) have become an important component of our daily life providing personalized suggestions that cater to user preferences. While Deep Neural Networks (DNNs) have made significant advancements in enhancing recommender systems by modeling user45;item interactions and incorporating textual side information DNN45;based methods still face limitations such as difficulties in understanding users interests and capturing textual side information inabilities in generalizing to various recommendation scenarios and reasoning on their predictions etc. Meanwhile the emergence of Large Language Models (LLMs) such as ChatGPT and GPT4 has revolutionized the fields of Natural Language Processing (NLP) and Artificial Intelligence (AI) due to their remarkable abilities in fundamental responsibilities of language understanding and generation as well as impressive generalization and reasoning capabilities. As a result recent studies have attempted to harness the power of LLMs to enhance recommender systems. Given the rapid evolution of this research direction in recommender systems there is a pressing need for a systematic overview that summarizes existing LLM45;empowered recommender systems to provide researchers in relevant fields with an in45;depth understanding. Therefore in this paper we conduct a comprehensive review of LLM45;empowered recommender systems from various aspects including Pre45;training Fine45;tuning and Prompting. More specifically we first introduce representative methods to harness the power of LLMs (as a feature encoder) for learning representations of users and items. Then we review recent techniques of LLMs for enhancing recommender systems from three paradigms namely pre45;training fine45;tuning and prompting. Finally we comprehensively discuss future directions in this emerging field.

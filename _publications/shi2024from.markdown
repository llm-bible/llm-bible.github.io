---
layout: publication
title: 'From General To Specific: Tailoring Large Language Models For Personalized Healthcare'
authors: Ruize Shi, Hong Huang, Wei Zhou, Kehan Yin, Kai Zhao, Yun Zhao
conference: "Arxiv"
year: 2024
bibkey: shi2024from
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2412.15957'}
tags: ['Masked Language Model', 'Agentic', 'RAG', 'Tools', 'Prompting', 'Reinforcement Learning']
---
The rapid development of large language models (LLMs) has transformed many
industries, including healthcare. However, previous medical LLMs have largely
focused on leveraging general medical knowledge to provide responses, without
accounting for patient variability and lacking true personalization at the
individual level. To address this, we propose a novel method called
personalized medical language model (PMLM), which explores and optimizes
personalized LLMs through recommendation systems and reinforcement learning
(RL). Specifically, by utilizing self-informed and peer-informed
personalization, PMLM captures changes in behaviors and preferences to design
initial personalized prompts tailored to individual needs. We further refine
these initial personalized prompts through RL, ultimately enhancing the
precision of LLM guidance. Notably, the personalized prompt are hard prompt,
which grants PMLM high adaptability and reusability, allowing it to directly
leverage high-quality proprietary LLMs. We evaluate PMLM using real-world
obstetrics and gynecology data, and the experimental results demonstrate that
PMLM achieves personalized responses, and it provides more refined and
individualized services, offering a potential way for personalized medical
LLMs.

---
layout: publication
title: 'LLM Detectors Still Fall Short Of Real World: Case Of Llm-generated Short News-like Posts'
authors: Gameiro Henrique Da Silva, Kucharavy Andrei, Dolamic Ljiljana
conference: "Arxiv"
year: 2024
bibkey: gameiro2024llm
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2409.03291"}
  - {name: "Code", url: "https://github.com/Reliable-Information-Lab-HEVS/dynamic_llm_detector_benchmark)"}
tags: ['Ethics And Bias', 'Has Code', 'Reinforcement Learning', 'Security']
---
With the emergence of widely available powerful LLMs disinformation generated by large Language Models (LLMs) has become a major concern. Historically LLM detectors have been touted as a solution but their effectiveness in the real world is still to be proven. In this paper we focus on an important setting in information operations -- short news-like posts generated by moderately sophisticated attackers. We demonstrate that existing LLM detectors whether zero-shot or purpose-trained are not ready for real-world use in that setting. All tested zero-shot detectors perform inconsistently with prior benchmarks and are highly vulnerable to sampling temperature increase a trivial attack absent from recent benchmarks. A purpose-trained detector generalizing across LLMs and unseen attacks can be developed but it fails to generalize to new human-written texts. We argue that the former indicates domain-specific benchmarking is needed while the latter suggests a trade-off between the adversarial evasion resilience and overfitting to the reference human text with both needing evaluation in benchmarks and currently absent. We believe this suggests a re-consideration of current LLM detector benchmarking approaches and provides a dynamically extensible benchmark to allow it (https://github.com/Reliable-Information-Lab-HEVS/dynamic\_llm\_detector\_benchmark)."

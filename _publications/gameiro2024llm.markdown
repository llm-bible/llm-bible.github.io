---
layout: publication
title: LLM Detectors Still Fall Short Of Real World Case Of Llm45;generated Short News45;like Posts
authors: Gameiro Henrique Da Silva, Kucharavy Andrei, Dolamic Ljiljana
conference: "Arxiv"
year: 2024
bibkey: gameiro2024llm
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2409.03291"}
  - {name: "Code", url: "https://github.com/Reliable&#45;Information&#45;Lab&#45;HEVS/dynamic&#95;llm&#95;detector&#95;benchmark)"}
tags: ['Ethics And Bias', 'Has Code', 'Reinforcement Learning', 'Security']
---
With the emergence of widely available powerful LLMs disinformation generated by large Language Models (LLMs) has become a major concern. Historically LLM detectors have been touted as a solution but their effectiveness in the real world is still to be proven. In this paper we focus on an important setting in information operations 45;45; short news45;like posts generated by moderately sophisticated attackers. We demonstrate that existing LLM detectors whether zero45;shot or purpose45;trained are not ready for real45;world use in that setting. All tested zero45;shot detectors perform inconsistently with prior benchmarks and are highly vulnerable to sampling temperature increase a trivial attack absent from recent benchmarks. A purpose45;trained detector generalizing across LLMs and unseen attacks can be developed but it fails to generalize to new human45;written texts. We argue that the former indicates domain45;specific benchmarking is needed while the latter suggests a trade45;off between the adversarial evasion resilience and overfitting to the reference human text with both needing evaluation in benchmarks and currently absent. We believe this suggests a re45;consideration of current LLM detector benchmarking approaches and provides a dynamically extensible benchmark to allow it (https://github.com/Reliable&#45;Information&#45;Lab&#45;HEVS/dynamic&#95;llm&#95;detector&#95;benchmark).

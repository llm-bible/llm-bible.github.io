---
layout: publication
title: Discuss Before Moving Visual Language Navigation Via Multi45;expert Discussions
authors: Long Yuxing, Li Xiaoqi, Cai Wenzhe, Dong Hao
conference: "Arxiv"
year: 2023
bibkey: long2023discuss
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.11382"}
tags: ['Agentic', 'Ethics And Bias', 'GPT', 'Model Architecture', 'Tools']
---
Visual language navigation (VLN) is an embodied task demanding a wide range of skills encompassing understanding perception and planning. For such a multifaceted challenge previous VLN methods totally rely on one models own thinking to make predictions within one round. However existing models even the most advanced large language model GPT4 still struggle with dealing with multiple tasks by single45;round self45;thinking. In this work drawing inspiration from the expert consultation meeting we introduce a novel zero45;shot VLN framework. Within this framework large models possessing distinct abilities are served as domain experts. Our proposed navigation agent namely DiscussNav can actively discuss with these experts to collect essential information before moving at every step. These discussions cover critical navigation subtasks like instruction understanding environment perception and completion estimation. Through comprehensive experiments we demonstrate that discussions with domain experts can effectively facilitate navigation by perceiving instruction45;relevant information correcting inadvertent errors and sifting through in45;consistent movement decisions. The performances on the representative VLN task R2R show that our method surpasses the leading zero45;shot VLN model by a large margin on all metrics. Additionally real45;robot experiments display the obvious advantages of our method over single45;round self45;thinking.

---
layout: publication
title: 'Less Or More: Towards Glanceable Explanations For LLM Recommendations Using Ultra-small Devices'
authors: Xinru Wang, Mengjie Yu, Hannah Nguyen, Michael Iuzzolino, Tianyi Wang, Peiqi Tang, Natasha Lynova, Co Tran, Ting Zhang, Naveen Sendhilnathan, Hrvoje Benko, Haijun Xia, Tanya Jonker
conference: "Arxiv"
year: 2025
bibkey: wang2025less
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2502.19410'}
tags: ['Prompting', 'Interpretability and Explainability']
---
Large Language Models (LLMs) have shown remarkable potential in recommending
everyday actions as personal AI assistants, while Explainable AI (XAI)
techniques are being increasingly utilized to help users understand why a
recommendation is given. Personal AI assistants today are often located on
ultra-small devices such as smartwatches, which have limited screen space. The
verbosity of LLM-generated explanations, however, makes it challenging to
deliver glanceable LLM explanations on such ultra-small devices. To address
this, we explored 1) spatially structuring an LLM's explanation text using
defined contextual components during prompting and 2) presenting temporally
adaptive explanations to users based on confidence levels. We conducted a user
study to understand how these approaches impacted user experiences when
interacting with LLM recommendations and explanations on ultra-small devices.
The results showed that structured explanations reduced users' time to action
and cognitive load when reading an explanation. Always-on structured
explanations increased users' acceptance of AI recommendations. However, users
were less satisfied with structured explanations compared to unstructured ones
due to their lack of sufficient, readable details. Additionally, adaptively
presenting structured explanations was less effective at improving user
perceptions of the AI compared to the always-on structured explanations.
Together with users' interview feedback, the results led to design implications
to be mindful of when personalizing the content and timing of LLM explanations
that are displayed on ultra-small devices.

---
layout: publication
title: 'Embedding Large Language Models Into Extended Reality: Opportunities And Challenges For Inclusion, Engagement, And Privacy'
authors: Bozkir Efe, Özdel Süleyman, Lau Ka Hei Carrie, Wang Mengdi, Gao Hong, Kasneci Enkelejda
conference: "Arxiv"
year: 2024
bibkey: bozkir2024embedding
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.03907"}
tags: ['Fine Tuning', 'Pretraining Methods', 'Prompting', 'Reinforcement Learning', 'Training Techniques']
---
Advances in artificial intelligence and human-computer interaction will likely lead to extended reality (XR) becoming pervasive. While XR can provide users with interactive, engaging, and immersive experiences, non-player characters are often utilized in pre-scripted and conventional ways. This paper argues for using large language models (LLMs) in XR by embedding them in avatars or as narratives to facilitate inclusion through prompt engineering and fine-tuning the LLMs. We argue that this inclusion will promote diversity for XR use. Furthermore, the versatile conversational capabilities of LLMs will likely increase engagement in XR, helping XR become ubiquitous. Lastly, we speculate that combining the information provided to LLM-powered spaces by users and the biometric data obtained might lead to novel privacy invasions. While exploring potential privacy breaches, examining user privacy concerns and preferences is also essential. Therefore, despite challenges, LLM-powered XR is a promising area with several opportunities.

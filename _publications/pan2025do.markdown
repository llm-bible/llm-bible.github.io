---
layout: publication
title: 'Do Code Llms Understand Design Patterns?'
authors: Zhenyu Pan, Xuefeng Song, Yunkun Wang, Rongyu Cao, Binhua Li, Yongbin Li, Han Liu
conference: "Arxiv"
year: 2025
bibkey: pan2025do
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2501.04835"}
tags: ['Ethics and Bias', 'Applications']
---
Code Large Language Models (LLMs) demonstrate great versatility in adapting
to various downstream tasks, including code generation and completion, as well
as bug detection and fixing. However, Code LLMs often fail to capture existing
coding standards, leading to the generation of code that conflicts with the
required design patterns for a given project. As a result, developers must
post-process to adapt the generated code to the project's design norms. In this
work, we empirically investigate the biases of Code LLMs in software
development. Through carefully designed experiments, we assess the models'
understanding of design patterns across recognition, comprehension, and
generation. Our findings reveal that biases in Code LLMs significantly affect
the reliability of downstream tasks.

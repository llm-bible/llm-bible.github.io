---
layout: publication
title: 'Large Language Models For Autonomous Driving (LLM4AD): Concept, Benchmark, Experiments, And Challenges'
authors: Can Cui, Yunsheng Ma, Zichong Yang, Yupeng Zhou, Peiran Liu, Juanwu Lu, Lingxi Li, Yaobin Chen, Jitesh H. Panchal, Amr Abdelraouf, Rohit Gupta, Kyungtae Han, Ziran Wang
conference: "Arxiv"
year: 2024
bibkey: cui2024large
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2410.15281"}
tags: ['Responsible AI', 'Tools', 'Ethics and Bias', 'Reinforcement Learning', 'Interpretability', 'Security']
---
With the broader usage and highly successful development of Large Language
Models (LLMs), there has been a growth of interest and demand for applying LLMs
to autonomous driving technology. Driven by their natural language
understanding and reasoning ability, LLMs have the potential to enhance various
aspects of autonomous driving systems, from perception and scene understanding
to language interaction and decision-making. In this paper, we first introduce
the novel concept of designing LLMs for autonomous driving (LLM4AD). Then, we
propose a comprehensive benchmark for evaluating the instruction-following
abilities of LLM4AD in simulation. Furthermore, we conduct a series of
experiments on real-world vehicle platforms, thoroughly evaluating the
performance and potential of our LLM4AD systems. Finally, we envision the main
challenges of LLM4AD, including latency, deployment, security and privacy,
safety, trust and transparency, and personalization. Our research highlights
the significant potential of LLMs to enhance various aspects of autonomous
vehicle technology, from perception and scene understanding to language
interaction and decision-making.

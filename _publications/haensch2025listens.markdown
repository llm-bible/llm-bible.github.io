---
layout: publication
title: '"it Listens Better Than My Therapist": Exploring Social Media Discourse On Llms As Mental Health Tool'
authors: Anna-carolina Haensch
conference: "Arxiv"
year: 2025
bibkey: haensch2025listens
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2504.12337"}
tags: ['Model Architecture', 'Tools', 'Reinforcement Learning', 'GPT', 'Prompting']
---
The emergence of generative AI chatbots such as ChatGPT has prompted growing
public and academic interest in their role as informal mental health support
tools. While early rule-based systems have been around for several years, large
language models (LLMs) offer new capabilities in conversational fluency,
empathy simulation, and availability. This study explores how users engage with
LLMs as mental health tools by analyzing over 10,000 TikTok comments from
videos referencing LLMs as mental health tools. Using a self-developed tiered
coding schema and supervised classification models, we identify user
experiences, attitudes, and recurring themes. Results show that nearly 20% of
comments reflect personal use, with these users expressing overwhelmingly
positive attitudes. Commonly cited benefits include accessibility, emotional
support, and perceived therapeutic value. However, concerns around privacy,
generic responses, and the lack of professional oversight remain prominent. It
is important to note that the user feedback does not indicate which therapeutic
framework, if any, the LLM-generated output aligns with. While the findings
underscore the growing relevance of AI in everyday practices, they also
highlight the urgent need for clinical and ethical scrutiny in the use of AI
for mental health support.

---
layout: publication
title: 'Openllm-ro -- Technical Report On Open-source Romanian Llms'
authors: Mihai Masala, Denis C. Ilie-ablachim, Dragos Corlatescu, Miruna Zavelca, Marius Leordeanu, Horia Velicu, Marius Popescu, Mihai Dascalu, Traian Rebedea
conference: "Arxiv"
year: 2024
bibkey: masala2024openllm
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2405.07703'}
tags: ['Training Techniques']
---
In recent years, Large Language Models (LLMs) have achieved almost human-like
performance on various tasks. While some LLMs have been trained on multilingual
data, most of the training data is in English. Hence, their performance in
English greatly exceeds their performance in other languages. This document
presents our approach to training and evaluating the first foundational and
chat LLM specialized for Romanian.

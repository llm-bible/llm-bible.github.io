---
layout: publication
title: 'Choosing A Model, Shaping A Future: Comparing LLM Perspectives On Sustainability And Its Relationship With AI'
authors: Annika Bush, Meltem Aksoy, Markus Pauly, Greta Ontrup
conference: "Arxiv"
year: 2025
bibkey: bush2025choosing
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2505.14435'}
tags: ['Model Architecture', 'Tools', 'GPT', 'Reinforcement Learning', 'Ethics and Bias']
---
As organizations increasingly rely on AI systems for decision support in sustainability contexts, it becomes critical to understand the inherent biases and perspectives embedded in Large Language Models (LLMs). This study systematically investigates how five state-of-the-art LLMs -- Claude, DeepSeek, GPT, LLaMA, and Mistral - conceptualize sustainability and its relationship with AI. We administered validated, psychometric sustainability-related questionnaires - each 100 times per model -- to capture response patterns and variability. Our findings revealed significant inter-model differences: For example, GPT exhibited skepticism about the compatibility of AI and sustainability, whereas LLaMA demonstrated extreme techno-optimism with perfect scores for several Sustainable Development Goals (SDGs). Models also diverged in attributing institutional responsibility for AI and sustainability integration, a results that holds implications for technology governance approaches. Our results demonstrate that model selection could substantially influence organizational sustainability strategies, highlighting the need for awareness of model-specific biases when deploying LLMs for sustainability-related decision-making.

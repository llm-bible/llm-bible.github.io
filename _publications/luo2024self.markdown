---
layout: publication
title: 'SED: Self-evaluation Decoding Enhances Large Language Models For Better Generation'
authors: Ziqin Luo, Haixia Han, Haokun Zhao, Guochao Jiang, Chengyu Du, Tingyun Li, Jiaqing Liang, Deqing Yang, Yanghua Xiao
conference: "Arxiv"
year: 2024
bibkey: luo2024self
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2405.16552'}
tags: ['GPT', 'Pretraining Methods']
---
Existing Large Language Models (LLMs) generate text through unidirectional
autoregressive decoding methods to respond to various user queries. These
methods tend to consider token selection in a simple sequential manner, making
it easy to fall into suboptimal options when encountering uncertain tokens,
referred to as chaotic points in our work. Many chaotic points exist in texts
generated by LLMs, and they often significantly affect the quality of
subsequently generated tokens, which can interfere with LLMs' generation. This
paper proposes Self-Evaluation Decoding, SED, a decoding method for enhancing
model generation. Analogous to the human decision-making process, SED
integrates speculation and evaluation steps into the decoding process, allowing
LLMs to make more careful decisions and thus optimize token selection at
chaotic points. Experimental results across various tasks using different LLMs
demonstrate SED's effectiveness.

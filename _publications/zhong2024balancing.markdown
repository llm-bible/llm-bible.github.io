---
layout: publication
title: 'Balancing Rigor And Utility: Mitigating Cognitive Biases In Large Language Models For Multiple-choice Questions'
authors: Hanyang Zhong, Liman Wang, Wenting Cao, Zeyuan Sun
conference: "Arxiv"
year: 2024
bibkey: zhong2024balancing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.10999"}
tags: ['Efficiency and Optimization', 'Reinforcement Learning', 'RAG', 'Ethics and Bias', 'Applications']
---
This paper examines the role of cognitive biases in the decision-making
processes of large language models (LLMs), challenging the conventional goal of
eliminating all biases. When properly balanced, we show that certain cognitive
biases can enhance decision-making efficiency through rational deviations and
heuristic shortcuts. By introducing heuristic moderation and an abstention
option, which allows LLMs to withhold responses when uncertain, we reduce error
rates, improve decision accuracy, and optimize decision rates. Using the
Balance Rigor and Utility (BRU) dataset, developed through expert
collaboration, our findings demonstrate that targeted inspection of cognitive
biases aligns LLM decisions more closely with human reasoning, enhancing
reliability and suggesting strategies for future improvements. This approach
offers a novel way to leverage cognitive biases to improve the practical
utility of LLMs across various applications.

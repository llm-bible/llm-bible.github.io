---
layout: publication
title: Behind The Magic MERLIM Multi45;modal Evaluation Benchmark For Large Image45;language Models
authors: Villa Andrés, Alcázar Juan Carlos León, Soto Alvaro, Ghanem Bernard
conference: "Arxiv"
year: 2023
bibkey: villa2023behind
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2312.02219"}
tags: ['Ethics And Bias', 'Model Architecture', 'Reinforcement Learning']
---
Large Vision and Language Models have enabled significant advances in fully supervised and zero45;shot visual tasks. These large architectures serve as the baseline to what is currently known as Instruction Tuning Large Vision and Language models (IT45;LVLMs). IT45;LVLMs are general45;purpose multi45;modal assistants whose responses are modulated by natural language instructions and visual data. Despite this versatility IT45;LVLM effectiveness in fundamental computer vision problems remains unclear primarily due to the absence of a standardized evaluation benchmark. This paper introduces a Multi45;modal Evaluation Benchmark named MERLIM a scalable test45;bed to assess the capabilities of IT45;LVLMs on fundamental computer vision tasks. MERLIM contains over 300K image45;question pairs and has a strong focus on detecting cross45;modal hallucination events in IT45;LVLMs. Our results bring important insights on the performance of state45;of45;the45;art IT45;LVMLs including limitations at identifying fine45;grained visual concepts object hallucinations across tasks and biases towards the language query. Our findings also suggest that these models have weak visual grounding but manage to make adequate guesses from global visual patterns or language biases contained in the LLM component.

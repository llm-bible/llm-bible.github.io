---
layout: publication
title: 'Captioning Visualizations With Large Language Models (CVLLM): A Tutorial'
authors: Giuseppe Carenini, Jordon Johnson, Ali Salamatian
conference: "Arxiv"
year: 2024
bibkey: carenini2024captioning
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.19512"}
tags: ['Model Architecture', 'Survey Paper', 'Pretraining Methods', 'Transformer', 'Applications']
---
Automatically captioning visualizations is not new, but recent advances in
large language models(LLMs) open exciting new possibilities. In this tutorial,
after providing a brief review of Information Visualization (InfoVis)
principles and past work in captioning, we introduce neural models and the
transformer architecture used in generic LLMs. We then discuss their recent
applications in InfoVis, with a focus on captioning. Additionally, we explore
promising future directions in this field.

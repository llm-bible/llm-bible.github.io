---
layout: publication
title: 'Ultrarag: A Modular And Automated Toolkit For Adaptive Retrieval-augmented Generation'
authors: Yuxuan Chen, Dewen Guo, Sen Mei, Xinze Li, Hao Chen, Yishan Li, Yixuan Wang, Chaoyue Tang, Ruobing Wang, Dingjun Wu, Yukun Yan, Zhenghao Liu, Shi Yu, Zhiyuan Liu, Maosong Sun
conference: "Arxiv"
year: 2025
bibkey: chen2025modular
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2504.08761'}
  - {name: "Code", url: 'https://github.com/OpenBMB/UltraRAG'}
tags: ['Has Code', 'RAG', 'Model Architecture', 'Tools', 'Training Techniques', 'Multimodal Models', 'Reinforcement Learning']
---
Retrieval-Augmented Generation (RAG) significantly enhances the performance
of large language models (LLMs) in downstream tasks by integrating external
knowledge. To facilitate researchers in deploying RAG systems, various RAG
toolkits have been introduced. However, many existing RAG toolkits lack support
for knowledge adaptation tailored to specific application scenarios. To address
this limitation, we propose UltraRAG, a RAG toolkit that automates knowledge
adaptation throughout the entire workflow, from data construction and training
to evaluation, while ensuring ease of use. UltraRAG features a user-friendly
WebUI that streamlines the RAG process, allowing users to build and optimize
systems without coding expertise. It supports multimodal input and provides
comprehensive tools for managing the knowledge base. With its highly modular
architecture, UltraRAG delivers an end-to-end development solution, enabling
seamless knowledge adaptation across diverse user scenarios. The code,
demonstration videos, and installable package for UltraRAG are publicly
available at https://github.com/OpenBMB/UltraRAG.

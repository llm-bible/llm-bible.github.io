---
layout: publication
title: 'Exploring The Multilingual NLG Evaluation Abilities Of Llm-based Evaluators'
authors: Jiayi Chang, Mingqi Gao, Xinyu Hu, Xiaojun Wan
conference: "Arxiv"
year: 2025
bibkey: chang2025exploring
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2503.04360"}
tags: ['Security', 'Training Techniques', 'Model Architecture', 'Pretraining Methods', 'Fine-Tuning', 'Prompting', 'Attention Mechanism']
---
Previous research has shown that LLMs have potential in multilingual NLG
evaluation tasks. However, existing research has not fully explored the
differences in the evaluation capabilities of LLMs across different languages.
To this end, this study provides a comprehensive analysis of the multilingual
evaluation performance of 10 recent LLMs, spanning high-resource and
low-resource languages through correlation analysis, perturbation attacks, and
fine-tuning. We found that 1) excluding the reference answer from the prompt
and using large-parameter LLM-based evaluators leads to better performance
across various languages; 2) most LLM-based evaluators show a higher
correlation with human judgments in high-resource languages than in
low-resource languages; 3) in the languages where they are most sensitive to
such attacks, they also tend to exhibit the highest correlation with human
judgments; and 4) fine-tuning with data from a particular language yields a
broadly consistent enhancement in the model's evaluation performance across
diverse languages. Our findings highlight the imbalance in LLMs'evaluation
capabilities across different languages and suggest that low-resource language
scenarios deserve more attention.

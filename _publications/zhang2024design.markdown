---
layout: publication
title: Agentohana\: Design Unified Data And Training Pipeline For Effective Agent Learning
authors: Zhang Jianguo, Lan Tian, Murthy Rithesh, Liu Zhiwei, Yao Weiran, Tan Juntao, Hoang Thai, Yang Liangwei, Feng Yihao, Liu Zuxin, Awalgaonkar Tulika, Niebles Juan Carlos, Savarese Silvio, Heinecke Shelby, Wang Huan, Xiong Caiming
conference: "Arxiv"
year: 2024
bibkey: zhang2024design
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.15506"}
  - {name: "Code", url: "https://github.com/SalesforceAIResearch/xLAM"}
tags: ['Agent', 'Agentic', 'Attention Mechanism', 'Fine Tuning', 'Has Code', 'Model Architecture', 'RAG', 'Reinforcement Learning', 'Training Techniques']
---
Autonomous agents powered by large language models (LLMs) have garnered significant research attention. However fully harnessing the potential of LLMs for agent-based tasks presents inherent challenges due to the heterogeneous nature of diverse data sources featuring multi-turn trajectories. In this paper we introduce (textbfAgentOhana) as a comprehensive solution to address these challenges. (textitAgentOhana) aggregates agent trajectories from distinct environments spanning a wide array of scenarios. It meticulously standardizes and unifies these trajectories into a consistent format streamlining the creation of a generic data loader optimized for agent training. Leveraging the data unification our training pipeline maintains equilibrium across different data sources and preserves independent randomness across devices during dataset partitioning and model training. Additionally we present (textbf)xLAM-v0.1 a large action model tailored for AI agents which demonstrates exceptional performance across various benchmarks. Begin the exploration at (url)https://github.com/SalesforceAIResearch/xLAM\}."

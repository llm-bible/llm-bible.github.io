---
layout: publication
title: Testing The Effect Of Code Documentation On Large Language Model Code Understanding
authors: Macke William, Doyle Michael
conference: "Arxiv"
year: 2024
bibkey: macke2024testing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.03114"}
tags: ['Applications', 'Reinforcement Learning']
---
Large Language Models (LLMs) have demonstrated impressive abilities in recent years with regards to code generation and understanding. However little work has investigated how documentation and other code properties affect an LLMs ability to understand and generate code or documentation. We present an empirical analysis of how underlying properties of code or documentation can affect an LLMs capabilities. We show that providing an LLM with incorrect documentation can greatly hinder code understanding while incomplete or missing documentation does not seem to significantly affect an LLMs ability to understand code.

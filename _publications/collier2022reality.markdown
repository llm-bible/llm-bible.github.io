---
layout: publication
title: On Reality And The Limits Of Language Data Aligning Llms With Human Norms
authors: Collier Nigel H., Liu Fangyu, Shareghi Ehsan
conference: "Arxiv"
year: 2022
bibkey: collier2022reality
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2208.11981"}
tags: ['Agentic', 'Applications', 'GPT', 'Model Architecture', 'Reinforcement Learning']
---
Recent advancements in Large Language Models (LLMs) harness linguistic associations in vast natural language data for practical applications. However their ability to understand the physical world using only language data remains a question. After reviewing existing protocols we explore this question using a novel and tightly controlled reasoning test (ART) and compare human norms against versions of GPT45;3. Our findings highlight the categories of common45;sense relations models that could learn directly from data and areas of weakness. GPT45;3 offers evidence for verbal reasoning on a par with human subjects for several relations including Synonymy Antonymy and Default inheritance Without reinforcement learning from human judgements it appears GPT45;3 performs at the lower end of the reference interval for Has45;part and Contained45;in. Weaknesses were observed also in affordance characteristics through Necessary45;quality Order45;of45;size and Order45;of45;intensity. Combining LLMs with symbolic world grounding is a promising direction to address associative learning.

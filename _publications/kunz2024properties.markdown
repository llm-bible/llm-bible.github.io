---
layout: publication
title: Properties And Challenges Of Llm45;generated Explanations
authors: Kunz Jenny, Kuhlmann Marco
conference: "Arxiv"
year: 2024
bibkey: kunz2024properties
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.10532"}
tags: ['Interpretability And Explainability', 'Pretraining Methods', 'Training Techniques']
---
The self45;rationalising capabilities of large language models (LLMs) have been explored in restricted settings using task/specific data sets. However current LLMs do not (only) rely on specifically annotated data; nonetheless they frequently explain their outputs. The properties of the generated explanations are influenced by the pre45;training corpus and by the target data used for instruction fine45;tuning. As the pre45;training corpus includes a large amount of human45;written explanations in the wild we hypothesise that LLMs adopt common properties of human explanations. By analysing the outputs for a multi45;domain instruction fine45;tuning data set we find that generated explanations show selectivity and contain illustrative elements but less frequently are subjective or misleading. We discuss reasons and consequences of the properties presence or absence. In particular we outline positive and negative implications depending on the goals and user groups of the self45;rationalising system.

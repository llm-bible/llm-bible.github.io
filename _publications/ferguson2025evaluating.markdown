---
layout: publication
title: 'Evaluating The Meta- And Object-level Reasoning Of Large Language Models For Question Answering'
authors: Nick Ferguson, Liane Guillou, Alan Bundy, Kwabena Nuamah
conference: "Arxiv"
year: 2025
bibkey: ferguson2025evaluating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.10338"}
tags: ['Applications']
---
Large Language Models (LLMs) excel in natural language tasks but still face
challenges in Question Answering (QA) tasks requiring complex, multi-step
reasoning. We outline the types of reasoning required in some of these tasks,
and reframe them in terms of meta-level reasoning (akin to high-level strategic
reasoning or planning) and object-level reasoning (embodied in lower-level
tasks such as mathematical reasoning). Franklin, a novel dataset with
requirements of meta- and object-level reasoning, is introduced and used along
with three other datasets to evaluate four LLMs at question answering tasks
requiring multiple steps of reasoning. Results from human annotation studies
suggest LLMs demonstrate meta-level reasoning with high frequency, but struggle
with object-level reasoning tasks in some of the datasets used. Additionally,
evidence suggests that LLMs find the object-level reasoning required for the
questions in the Franklin dataset challenging, yet they do exhibit strong
performance with respect to the meta-level reasoning requirements.

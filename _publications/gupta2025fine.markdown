---
layout: publication
title: 'Fine-tuning Qwen 2.5 3B For Realistic Movie Dialogue Generation'
authors: Kartik Gupta
conference: "Arxiv"
year: 2025
bibkey: gupta2025fine
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2502.16274'}
tags: ['RAG', 'Efficiency and Optimization', 'Training Techniques', 'Fine-Tuning', 'Reinforcement Learning', 'Pretraining Methods']
---
The Qwen 2.5 3B base model was fine-tuned to generate contextually rich and
engaging movie dialogue, leveraging the Cornell Movie-Dialog Corpus, a curated
dataset of movie conversations. Due to the limitations in GPU computing and
VRAM, the training process began with the 0.5B model progressively scaling up
to the 1.5B and 3B versions as efficiency improvements were implemented. The
Qwen 2.5 series, developed by Alibaba Group, stands at the forefront of small
open-source pre-trained models, particularly excelling in creative tasks
compared to alternatives like Meta's Llama 3.2 and Google's Gemma. Results
demonstrate the ability of small models to produce high-quality, realistic
dialogue, offering a promising approach for real-time, context-sensitive
conversation generation.

---
layout: publication
title: 52B To 1T Lessons Learned Via Tele45;flm Series
authors: Li Xiang, Yao Yiqun, Jiang Xin, Fang Xuezhi, Wang Chao, Liu Xinzhang, Wang Zihan, Zhao Yu, Wang Xin, Huang Yuyao, Song Shuangyong, Li Yongxiang, Zhang Zheng, Zhao Bo, Sun Aixin, Wang Yequan, He Zhongjiang, Wang Zhongyuan, Li Xuelong, Huang Tiejun
conference: "Arxiv"
year: 2024
bibkey: li2024lessons
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.02783"}
tags: ['Efficiency And Optimization', 'Fine Tuning', 'Large Scale Training', 'Model Architecture', 'Reinforcement Learning', 'Scaling Laws', 'Training Techniques']
---
Large Language Models (LLMs) represent a significant stride toward Artificial General Intelligence. As scaling laws underscore the potential of increasing model sizes the academic community has intensified its investigations into LLMs with capacities exceeding 50 billion parameters. This technical report builds on our prior work with Tele45;FLM (also known as FLM45;2) a publicly available 5245;billion45;parameter model. We delve into two primary areas we first discuss our observation of Supervised Fine45;tuning (SFT) on Tele45;FLM45;52B which supports the less is more approach for SFT data construction; second we demonstrate our experiments and analyses on the best practices for progressively growing a model from 52 billion to 102 billion and subsequently to 1 trillion parameters. We will open45;source a 1T model checkpoint namely Tele45;FLM45;1T to advance further training and research.

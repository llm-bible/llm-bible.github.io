---
layout: publication
title: Performance Assessment Of Chatgpt Vs Bard In Detecting Alzheimer's Dementia
authors: T Balamurali B, Chen Jer-ming
conference: "Arxiv"
year: 2024
bibkey: t2024performance
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.01751"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Pretraining Methods', 'Prompting']
---
Large language models (LLMs) find increasing applications in many fields. Here three LLM chatbots (ChatGPT-3.5 ChatGPT-4 and Bard) are assessed - in their current form as publicly available - for their ability to recognize Alzheimers Dementia (AD) and Cognitively Normal (CN) individuals using textual input derived from spontaneous speech recordings. Zero-shot learning approach is used at two levels of independent queries with the second query (chain-of-thought prompting) eliciting more detailed than the first. Each LLM chatbots performance is evaluated on the prediction generated in terms of accuracy sensitivity specificity precision and F1 score. LLM chatbots generated three-class outcome (AD CN or Unsure). When positively identifying AD Bard produced highest true-positives (8937; recall) and highest F1 score (7137;) but tended to misidentify CN as AD with high confidence (low Unsure rates); for positively identifying CN GPT-4 resulted in the highest true-negatives at 5637; and highest F1 score (6237;) adopting a diplomatic stance (moderate Unsure rates). Overall three LLM chatbots identify AD vs CN surpassing chance-levels but do not currently satisfy clinical application.

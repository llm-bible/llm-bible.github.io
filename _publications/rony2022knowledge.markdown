---
layout: publication
title: Dialokg Knowledge45;structure Aware Task45;oriented Dialogue Generation
authors: Rony Md Rashad Al Hasan, Usbeck Ricardo, Lehmann Jens
conference: "Arxiv"
year: 2022
bibkey: rony2022knowledge
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2204.09149"}
tags: ['Applications', 'Attention Mechanism', 'Distillation', 'Efficiency And Optimization', 'Model Architecture', 'Reinforcement Learning']
---
Task45;oriented dialogue generation is challenging since the underlying knowledge is often dynamic and effectively incorporating knowledge into the learning process is hard. It is particularly challenging to generate both human45;like and informative responses in this setting. Recent research primarily focused on various knowledge distillation methods where the underlying relationship between the facts in a knowledge base is not effectively captured. In this paper we go one step further and demonstrate how the structural information of a knowledge graph can improve the systems inference capabilities. Specifically we propose DialoKG a novel task45;oriented dialogue system that effectively incorporates knowledge into a language model. Our proposed system views relational knowledge as a knowledge graph and introduces (1) a structure45;aware knowledge embedding technique and (2) a knowledge graph45;weighted attention masking strategy to facilitate the system selecting relevant information during the dialogue generation. An empirical evaluation demonstrates the effectiveness of DialoKG over state45;of45;the45;art methods on several standard benchmark datasets.

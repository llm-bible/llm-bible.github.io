---
layout: publication
title: Direct Evaluation Of Chain45;of45;thought In Multi45;hop Reasoning With Knowledge Graphs
authors: Nguyen Minh-vuong, Luo Linhao, Shiri Fatemeh, Phung Dinh, Li Yuan-fang, Vu Thuy-trang, Haffari Gholamreza
conference: "Arxiv"
year: 2024
bibkey: nguyen2024direct
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.11199"}
tags: ['Applications', 'Interpretability And Explainability', 'Prompting']
---
Large language models (LLMs) demonstrate strong reasoning abilities when prompted to generate chain45;of45;thought (CoT) explanations alongside answers. However previous research on evaluating LLMs has solely focused on answer accuracy neglecting the correctness of the generated CoT. In this paper we delve deeper into the CoT reasoning capabilities of LLMs in multi45;hop question answering by utilizing knowledge graphs (KGs). We propose a novel discriminative and generative CoT evaluation paradigm to assess LLMs knowledge of reasoning and the accuracy of the generated CoT. Through experiments conducted on 5 different families of LLMs across 2 multi45;hop question45;answering datasets we find that LLMs possess sufficient knowledge to perform reasoning. However there exists a significant disparity between answer accuracy and faithfulness of the CoT reasoning generated by LLMs indicating that they often arrive at correct answers through incorrect reasoning.

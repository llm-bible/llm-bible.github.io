---
layout: publication
title: Stbench Assessing The Ability Of Large Language Models In Spatio45;temporal Analysis
authors: Li Wenbin, Yao Di, Zhao Ruibo, Chen Wenjie, Xu Zijie, Luo Chengxue, Gong Chang, Jing Quanliang, Tan Haining, Bi Jingping
conference: "Arxiv"
year: 2024
bibkey: li2024assessing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.19065"}
  - {name: "Code", url: "https://github.com/LwbXc/STBench"}
tags: ['Applications', 'Ethics And Bias', 'GPT', 'Has Code', 'Model Architecture', 'Prompting', 'Tools']
---
The rapid evolution of large language models (LLMs) holds promise for reforming the methodology of spatio45;temporal data mining. However current works for evaluating the spatio45;temporal understanding capability of LLMs are somewhat limited and biased. These works either fail to incorporate the latest language models or only focus on assessing the memorized spatio45;temporal knowledge. To address this gap this paper dissects LLMs capability of spatio45;temporal data into four distinct dimensions knowledge comprehension spatio45;temporal reasoning accurate computation and downstream applications. We curate several natural language question45;answer tasks for each category and build the benchmark dataset namely STBench containing 13 distinct tasks and over 60000 QA pairs. Moreover we have assessed the capabilities of 13 LLMs such as GPT45;4o Gemma and Mistral. Experimental results reveal that existing LLMs show remarkable performance on knowledge comprehension and spatio45;temporal reasoning tasks with potential for further enhancement on other tasks through in45;context learning chain45;of45;though prompting and fine45;tuning. The code and datasets of STBench are released on https://github.com/LwbXc/STBench.

---
layout: publication
title: VQA45;MHUG A Gaze Dataset To Study Multimodal Neural Attention In Visual Question Answering
authors: Sood Ekta, KÃ¶gel Fabian, Strohm Florian, Dhar Prajit, Bulling Andreas
conference: "Arxiv"
year: 2021
bibkey: sood2021vqa
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2109.13116"}
tags: ['Applications', 'Attention Mechanism', 'Model Architecture', 'Multimodal Models', 'Transformer']
---
We present VQA45;MHUG 45; a novel 4945;participant dataset of multimodal human gaze on both images and questions during visual question answering (VQA) collected using a high45;speed eye tracker. We use our dataset to analyze the similarity between human and neural attentive strategies learned by five state45;of45;the45;art VQA models Modular Co45;Attention Network (MCAN) with either grid or region features Pythia Bilinear Attention Network (BAN) and the Multimodal Factorized Bilinear Pooling Network (MFB). While prior work has focused on studying the image modality our analyses show 45; for the first time 45; that for all models higher correlation with human attention on text is a significant predictor of VQA performance. This finding points at a potential for improving VQA performance and at the same time calls for further research on neural text attention mechanisms and their integration into architectures for vision and language tasks including but potentially also beyond VQA.

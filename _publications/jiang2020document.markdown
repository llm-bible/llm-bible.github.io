---
layout: publication
title: 'Document-level Neural Machine Translation With Document Embeddings'
authors: Shu Jiang, Hai Zhao, Zuchao Li, Bao-liang Lu
conference: "Arxiv"
year: 2020
bibkey: jiang2020document
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2009.08775'}
tags: ['Transformer', 'Applications', 'Model Architecture', 'Pretraining Methods']
---
Standard neural machine translation (NMT) is on the assumption of
document-level context independent. Most existing document-level NMT methods
are satisfied with a smattering sense of brief document-level information,
while this work focuses on exploiting detailed document-level context in terms
of multiple forms of document embeddings, which is capable of sufficiently
modeling deeper and richer document-level context. The proposed document-aware
NMT is implemented to enhance the Transformer baseline by introducing both
global and local document-level clues on the source end. Experiments show that
the proposed method significantly improves the translation performance over
strong baselines and other related studies.

---
layout: publication
title: Self45;supervised Test45;time Learning For Reading Comprehension
authors: Banerjee Pratyay, Gokhale Tejas, Baral Chitta
conference: "Arxiv"
year: 2021
bibkey: banerjee2021self
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2103.11263"}
tags: ['Applications', 'Training Techniques']
---
Recent work on unsupervised question answering has shown that models can be trained with procedurally generated question45;answer pairs and can achieve performance competitive with supervised methods. In this work we consider the task of unsupervised reading comprehension and present a method that performs test45;time learning (TTL) on a given context (text passage) without requiring training on large45;scale human45;authored datasets containing textit123;context45;question45;answer125; triplets. This method operates directly on a single test context uses self45;supervision to train models on synthetically generated question45;answer pairs and then infers answers to unseen human45;authored questions for this context. Our method achieves accuracies competitive with fully supervised methods and significantly outperforms current unsupervised methods. TTL methods with a smaller model are also competitive with the current state45;of45;the45;art in unsupervised reading comprehension.

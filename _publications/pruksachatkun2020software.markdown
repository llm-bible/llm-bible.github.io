---
layout: publication
title: 'Jiant: A Software Toolkit For Research On General-purpose Text Understanding Models'
authors: Yada Pruksachatkun, Phil Yeres, Haokun Liu, Jason Phang, Phu Mon Htut, Alex Wang, Ian Tenney, Samuel R. Bowman
conference: "Arxiv"
year: 2020
bibkey: pruksachatkun2020software
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2003.02249"}
tags: ['Training Techniques', 'BERT', 'Fine-Tuning', 'Model Architecture']
---
We introduce jiant, an open source toolkit for conducting multitask and
transfer learning experiments on English NLU tasks. jiant enables modular and
configuration-driven experimentation with state-of-the-art models and
implements a broad set of tasks for probing, transfer learning, and multitask
training experiments. jiant implements over 50 NLU tasks, including all GLUE
and SuperGLUE benchmark tasks. We demonstrate that jiant reproduces published
performance on a variety of tasks and models, including BERT and RoBERTa. jiant
is available at https://jiant.info.

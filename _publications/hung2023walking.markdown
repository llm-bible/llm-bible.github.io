---
layout: publication
title: Walking A Tightrope 45;45; Evaluating Large Language Models In High45;risk Domains
authors: Hung Chia-chien, Rim Wiem Ben, Frost Lindsay, Bruckner Lars, Lawrence Carolin
conference: "Arxiv"
year: 2023
bibkey: hung2023walking
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2311.14966"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Reinforcement Learning', 'Responsible AI']
---
High45;risk domains pose unique challenges that require language models to provide accurate and safe responses. Despite the great success of large language models (LLMs) such as ChatGPT and its variants their performance in high45;risk domains remains unclear. Our study delves into an in45;depth analysis of the performance of instruction45;tuned LLMs focusing on factual accuracy and safety adherence. To comprehensively assess the capabilities of LLMs we conduct experiments on six NLP datasets including question answering and summarization tasks within two high45;risk domains legal and medical. Further qualitative analysis highlights the existing limitations inherent in current LLMs when evaluating in high45;risk domains. This underscores the essential nature of not only improving LLM capabilities but also prioritizing the refinement of domain45;specific metrics and embracing a more human45;centric approach to enhance safety and factual reliability. Our findings advance the field toward the concerns of properly evaluating LLMs in high45;risk domains aiming to steer the adaptability of LLMs in fulfilling societal obligations and aligning with forthcoming regulations such as the EU AI Act.

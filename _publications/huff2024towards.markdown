---
layout: publication
title: 'Towards A Psychology Of Machines: Large Language Models Predict Human Memory'
authors: Markus Huff, Elanur Ulakçı
conference: "Arxiv"
year: 2024
bibkey: huff2024towards
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2403.05152'}
tags: ['GPT', 'Tools', 'Model Architecture']
---
Large language models (LLMs), such as ChatGPT, have shown remarkable
abilities in natural language processing, opening new avenues in psychological
research. This study explores whether LLMs can predict human memory performance
in tasks involving garden-path sentences and contextual information. In the
first part, we used ChatGPT to rate the relatedness and memorability of
garden-path sentences preceded by either fitting or unfitting contexts. In the
second part, human participants read the same sentences, rated their
relatedness, and completed a surprise memory test. The results demonstrated
that ChatGPT's relatedness ratings closely matched those of the human
participants, and its memorability ratings effectively predicted human memory
performance. Both LLM and human data revealed that higher relatedness in the
unfitting context condition was associated with better memory performance,
aligning with probabilistic frameworks of context-dependent learning. These
findings suggest that LLMs, despite lacking human-like memory mechanisms, can
model aspects of human cognition and serve as valuable tools in psychological
research. We propose the field of machine psychology to explore this interplay
between human cognition and artificial intelligence, offering a bidirectional
approach where LLMs can both benefit from and contribute to our understanding
of human cognitive processes.

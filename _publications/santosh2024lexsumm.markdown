---
layout: publication
title: 'Lexsumm And Lext5: Benchmarking And Modeling Legal Summarization Tasks In English'
authors: T. Y. S. S. Santosh, Cornelius Weiss, Matthias Grabmair
conference: "Arxiv"
year: 2024
bibkey: santosh2024lexsumm
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2410.09527'}
  - {name: "Code", url: 'https://github.com/TUMLegalTech/LexSumm-LexT5'}
tags: ['Has Code', 'Training Techniques', 'BERT', 'Applications', 'Fine-Tuning', 'Model Architecture', 'Reinforcement Learning', 'Pretraining Methods']
---
In the evolving NLP landscape, benchmarks serve as yardsticks for gauging
progress. However, existing Legal NLP benchmarks only focus on predictive
tasks, overlooking generative tasks. This work curates LexSumm, a benchmark
designed for evaluating legal summarization tasks in English. It comprises
eight English legal summarization datasets, from diverse jurisdictions, such as
the US, UK, EU and India. Additionally, we release LexT5, legal oriented
sequence-to-sequence model, addressing the limitation of the existing
BERT-style encoder-only models in the legal domain. We assess its capabilities
through zero-shot probing on LegalLAMA and fine-tuning on LexSumm. Our analysis
reveals abstraction and faithfulness errors even in summaries generated by
zero-shot LLMs, indicating opportunities for further improvements. LexSumm
benchmark and LexT5 model are available at
https://github.com/TUMLegalTech/LexSumm-LexT5.

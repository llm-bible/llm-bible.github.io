---
layout: publication
title: 'Evaluating Small Language Models For News Summarization: Implications And Factors Influencing Performance'
authors: Borui Xu, Yao Chen, Zeyi Wen, Weiguo Liu, Bingsheng He
conference: "Arxiv"
year: 2025
bibkey: xu2025evaluating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.00641"}
tags: ['Tools', 'Prompting', 'Applications', 'Reinforcement Learning']
---
The increasing demand for efficient summarization tools in
resource-constrained environments highlights the need for effective solutions.
While large language models (LLMs) deliver superior summarization quality,
their high computational resource requirements limit practical use
applications. In contrast, small language models (SLMs) present a more
accessible alternative, capable of real-time summarization on edge devices.
However, their summarization capabilities and comparative performance against
LLMs remain underexplored. This paper addresses this gap by presenting a
comprehensive evaluation of 19 SLMs for news summarization across 2,000 news
samples, focusing on relevance, coherence, factual consistency, and summary
length. Our findings reveal significant variations in SLM performance, with
top-performing models such as Phi3-Mini and Llama3.2-3B-Ins achieving results
comparable to those of 70B LLMs while generating more concise summaries.
Notably, SLMs are better suited for simple prompts, as overly complex prompts
may lead to a decline in summary quality. Additionally, our analysis indicates
that instruction tuning does not consistently enhance the news summarization
capabilities of SLMs. This research not only contributes to the understanding
of SLMs but also provides practical insights for researchers seeking efficient
summarization solutions that balance performance and resource use.

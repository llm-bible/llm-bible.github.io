---
layout: publication
title: 'Faircot: Enhancing Fairness In Text-to-image Generation Via Chain Of Thought Reasoning With Multimodal Large Language Models'
authors: Zahraa Al Sahili, Ioannis Patras, Matthew Purver
conference: "Arxiv"
year: 2024
bibkey: sahili2024enhancing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.09070"}
tags: ['Multimodal Models', 'Training Techniques', 'Fairness', 'Tools', 'Reinforcement Learning', 'Merging', 'Bias Mitigation', 'Ethics and Bias', 'Prompting']
---
In the domain of text-to-image generative models, biases inherent in training
datasets often propagate into generated content, posing significant ethical
challenges, particularly in socially sensitive contexts. We introduce FairCoT,
a novel framework that enhances fairness in text to image models through Chain
of Thought (CoT) reasoning within multimodal generative large language models.
FairCoT employs iterative CoT refinement to systematically mitigate biases, and
dynamically adjusts textual prompts in real time, ensuring diverse and
equitable representation in generated images. By integrating iterative
reasoning processes, FairCoT addresses the limitations of zero shot CoT in
sensitive scenarios, balancing creativity with ethical responsibility.
Experimental evaluations across popular text-to-image systems including DALLE
and various Stable Diffusion variants, demonstrate that FairCoT significantly
enhances fairness and diversity without sacrificing image quality or semantic
fidelity. By combining robust reasoning, lightweight deployment, and
extensibility to multiple models, FairCoT represents a promising step toward
more socially responsible and transparent AI driven content generation.

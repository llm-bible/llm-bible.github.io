---
layout: publication
title: Chain45;of45;thought Hub A Continuous Effort To Measure Large Language Models Reasoning Performance
authors: Fu Yao, Ou Litu, Chen Mingyu, Wan Yuhao, Peng Hao, Khot Tushar
conference: "Arxiv"
year: 2023
bibkey: fu2023chain
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2305.17306"}
tags: ['Agentic', 'Applications', 'GPT', 'Model Architecture', 'Reinforcement Learning', 'Tools']
---
As large language models (LLMs) are continuously being developed their evaluation becomes increasingly important yet challenging. This work proposes Chain45;of45;Thought Hub an open45;source evaluation suite on the multi45;step reasoning capabilities of large language models. We are interested in this setting for two reasons (1) from the behavior of GPT and PaLM model family we observe that complex reasoning is likely to be a key differentiator between weaker and stronger LLMs; (2) we envisage large language models to become the next45;generation computational platform and foster an ecosystem of LLM45;based new applications this naturally requires the foundation models to perform complex tasks that often involve the composition of linguistic and logical operations. Our approach is to compile a suite of challenging reasoning benchmarks to track the progress of LLMs. Our current results show that (1) model scale clearly correlates with reasoning capabilities; (2) As of May 2023 Claude45;v1.3 and PaLM45;2 are the only two models that are comparable with GPT45;4 while open45;sourced models still lag behind; (3) LLaMA45;65B performs closely to code45;davinci45;002 indicating that with successful further development such as reinforcement learning from human feedback (RLHF) it has great potential to be close to GPT45;3.545;Turbo. Our results also suggest that for the open45;source efforts to catch up the community may focus more on building better base models and exploring RLHF.

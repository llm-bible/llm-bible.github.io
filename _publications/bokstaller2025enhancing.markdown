---
layout: publication
title: 'Enhancing ML Model Interpretability: Leveraging Fine-tuned Large Language Models For Better Understanding Of AI'
authors: Jonas Bokstaller, Julia Altheimer, Julian Dormehl, Alina Buss, Jasper Wiltfang, Johannes Schneider, Maximilian RÃ¶glinger
conference: "Arxiv"
year: 2025
bibkey: bokstaller2025enhancing
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2505.02859'}
tags: ['Interpretability and Explainability', 'RAG', 'Applications', 'Model Architecture', 'Interpretability']
---
Across various sectors applications of eXplainableAI (XAI) gained momentum as
the increasing black-boxedness of prevailing Machine Learning (ML) models
became apparent. In parallel, Large Language Models (LLMs) significantly
developed in their abilities to understand human language and complex patterns.
By combining both, this paper presents a novel reference architecture for the
interpretation of XAI through an interactive chatbot powered by a fine-tuned
LLM. We instantiate the reference architecture in the context of
State-of-Health (SoH) prediction for batteries and validate its design in
multiple evaluation and demonstration rounds. The evaluation indicates that the
implemented prototype enhances the human interpretability of ML, especially for
users with less experience with XAI.

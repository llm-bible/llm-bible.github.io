---
layout: publication
title: Llm45;in45;the45;loop Leveraging Large Language Model For Thematic Analysis
authors: Dai Shih-chieh, Xiong Aiping, Ku Lun-wei
conference: "Arxiv"
year: 2023
bibkey: dai2023llm
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.15100"}
tags: ['GPT', 'Merging', 'Model Architecture', 'Prompting', 'RAG', 'Reinforcement Learning', 'Survey Paper', 'Tools']
---
Thematic analysis (TA) has been widely used for analyzing qualitative data in many disciplines and fields. To ensure reliable analysis the same piece of data is typically assigned to at least two human coders. Moreover to produce meaningful and useful analysis human coders develop and deepen their data interpretation and coding over multiple iterations making TA labor45;intensive and time45;consuming. Recently the emerging field of large language models (LLMs) research has shown that LLMs have the potential replicate human45;like behavior in various tasks in particular LLMs outperform crowd workers on text45;annotation tasks suggesting an opportunity to leverage LLMs on TA. We propose a human45;LLM collaboration framework (i.e. LLM45;in45;the45;loop) to conduct TA with in45;context learning (ICL). This framework provides the prompt to frame discussions with a LLM (e.g. GPT45;3.5) to generate the final codebook for TA. We demonstrate the utility of this framework using survey datasets on the aspects of the music listening experience and the usage of a password manager. Results of the two case studies show that the proposed framework yields similar coding quality to that of human coders but reduces TAs labor and time demands.

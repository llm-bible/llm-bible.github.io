---
layout: publication
title: Factuality Challenges In The Era Of Large Language Models
authors: Isabelle Augenstein et al.
conference: Arxiv
year: 2023
citations: 25
bibkey: augenstein2023factuality
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2310.05189'}]
tags: [Applications, GPT, Ethics and Bias]
---
The emergence of tools based on Large Language Models (LLMs), such as
OpenAI's ChatGPT, Microsoft's Bing Chat, and Google's Bard, has garnered
immense public attention. These incredibly useful, natural-sounding tools mark
significant advances in natural language generation, yet they exhibit a
propensity to generate false, erroneous, or misleading content -- commonly
referred to as "hallucinations." Moreover, LLMs can be exploited for malicious
applications, such as generating false but credible-sounding content and
profiles at scale. This poses a significant challenge to society in terms of
the potential deception of users and the increasing dissemination of inaccurate
information. In light of these risks, we explore the kinds of technological
innovations, regulatory reforms, and AI literacy initiatives needed from
fact-checkers, news organizations, and the broader research and policy
communities. By identifying the risks, the imminent threats, and some viable
solutions, we seek to shed light on navigating various aspects of veracity in
the era of generative AI.
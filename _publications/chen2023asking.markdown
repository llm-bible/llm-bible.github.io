---
layout: publication
title: Asking Before Acting: Gather Information In Embodied Decision Making With Language Models
authors: Chen Xiaoyu, Zhang Shenao, Zhang Pushi, Zhao Li, Chen Jianyu
conference: "Arxiv"
year: 2023
bibkey: chen2023asking
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2305.15695"}
tags: ['Agentic', 'Efficiency And Optimization', 'Fine Tuning', 'GPT', 'Model Architecture', 'Prompting', 'Reinforcement Learning']
---
With strong capabilities of reasoning and a broad understanding of the world Large Language Models (LLMs) have demonstrated immense potential in building versatile embodied decision-making agents capable of executing a wide array of tasks. Nevertheless when deployed in unfamiliar environments we show that LLM agents encounter challenges in efficiently gathering essential information leading to suboptimal performance. Conversely human individuals often seek additional information from their peers prior to taking action harnessing external knowledge to avoid unnecessary trial and error. Drawing inspiration from this behavior we propose (textit)Asking Before Acting (ABA) a method that empowers the agent to proactively inquire with external sources for pertinent information using natural language during their interactions within the environment. In this way the agent is able to enhance its efficiency and performance by circumventing potentially laborious steps and combating the difficulties associated with exploration in unfamiliar environments and vagueness of the instructions. We conduct extensive experiments involving a spectrum of environments including text-based household everyday tasks robot arm manipulation tasks and real world open domain image based embodied tasks. The experiments involve various models from Vicuna to GPT-4. The results demonstrate that even with modest prompts modifications ABA exhibits substantial advantages on both performance and efficiency over baseline LLM agents. Further finetuning ABA with reformulated metadata (ABA-FT) faciliates learning the rationale for asking and allows for additional enhancements especially in tasks that baselines struggle to solve.

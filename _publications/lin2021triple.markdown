---
layout: publication
title: 'Triple M: A Practical Text-to-speech Synthesis System With Multi-guidance Attention And Multi-band Multi-time Lpcnet'
authors: Shilun Lin, Fenglong Xie, Li Meng, Xinhui Li, Li Lu
conference: "Arxiv"
year: 2021
bibkey: lin2021triple
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2102.00247"}
tags: ['Transformer', 'Tools', 'Attention Mechanism', 'Model Architecture']
---
In this work, a robust and efficient text-to-speech (TTS) synthesis system
named Triple M is proposed for large-scale online application. The key
components of Triple M are: 1) A sequence-to-sequence model adopts a novel
multi-guidance attention to transfer complementary advantages from guiding
attention mechanisms to the basic attention mechanism without in-domain
performance loss and online service modification. Compared with single
attention mechanism, multi-guidance attention not only brings better
naturalness to long sentence synthesis, but also reduces the word error rate by
26.8%. 2) A new efficient multi-band multi-time vocoder framework, which
reduces the computational complexity from 2.8 to 1.0 GFLOP and speeds up LPCNet
by 2.75x on a single CPU.

---
layout: publication
title: 'Should Agentic Conversational AI Change How We Think About Ethics? Characterising An Interactional Ethics Centred On Respect'
authors: Lize Alberts, Geoff Keeling, Amanda Mccroskery
conference: "Arxiv"
year: 2024
bibkey: alberts2024should
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.09082"}
tags: ['Responsible AI', 'Agentic', 'Reinforcement Learning', 'RAG', 'Ethics and Bias']
---
With the growing popularity of conversational agents based on large language
models (LLMs), we need to ensure their behaviour is ethical and appropriate.
Work in this area largely centres around the 'HHH' criteria: making outputs
more helpful and honest, and avoiding harmful (biased, toxic, or inaccurate)
statements. Whilst this semantic focus is useful when viewing LLM agents as
mere mediums or output-generating systems, it fails to account for pragmatic
factors that can make the same speech act seem more or less tactless or
inconsiderate in different social situations. With the push towards agentic AI,
wherein systems become increasingly proactive in chasing goals and performing
actions in the world, considering the pragmatics of interaction becomes
essential. We propose an interactional approach to ethics that is centred on
relational and situational factors. We explore what it means for a system, as a
social actor, to treat an individual respectfully in a (series of)
interaction(s). Our work anticipates a set of largely unexplored risks at the
level of situated social interaction, and offers practical suggestions to help
agentic LLM technologies treat people well.

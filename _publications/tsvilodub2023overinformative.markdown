---
layout: publication
title: Overinformative Question Answering By Humans And Machines
authors: Tsvilodub Polina, Franke Michael, Hawkins Robert D., Goodman Noah D.
conference: "Arxiv"
year: 2023
bibkey: tsvilodub2023overinformative
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2305.07151"}
tags: ['Applications', 'GPT', 'Interpretability And Explainability', 'Model Architecture', 'Prompting']
---
When faced with a polar question speakers often provide overinformative answers going beyond a simple yes or no. But what principles guide the selection of additional information In this paper we provide experimental evidence from two studies suggesting that overinformativeness in human answering is driven by considerations of relevance to the questioners goals which they flexibly adjust given the functional context in which the question is uttered. We take these human results as a strong benchmark for investigating question45;answering performance in state45;of45;the45;art neural language models conducting an extensive evaluation on items from human experiments. We find that most models fail to adjust their answering behavior in a human45;like way and tend to include irrelevant information. We show that GPT45;3 is highly sensitive to the form of the prompt and only achieves human45;like answer patterns when guided by an example and cognitively45;motivated explanation.

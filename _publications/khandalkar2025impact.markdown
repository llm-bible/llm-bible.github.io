---
layout: publication
title: 'Impact Of Noise On Llm-models Performance In Abstraction And Reasoning Corpus (ARC) Tasks With Model Temperature Considerations'
authors: Nikhil Khandalkar, Pavan Yadav, Krishna Shinde, Lokesh B. Ramegowda, Rajarshi Das
conference: "Arxiv"
year: 2025
bibkey: khandalkar2025impact
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2504.15903'}
tags: ['RAG', 'Security', 'GPT', 'Model Architecture', 'Reinforcement Learning']
---
Recent advancements in Large Language Models (LLMs) have generated growing
interest in their structured reasoning capabilities, particularly in tasks
involving abstraction and pattern recognition. The Abstraction and Reasoning
Corpus (ARC) benchmark plays a crucial role in evaluating these capabilities by
testing how well AI models generalize to novel problems. While GPT-4o
demonstrates strong performance by solving all ARC tasks under zero-noise
conditions, other models like DeepSeek R1 and LLaMA 3.2 fail to solve any,
suggesting limitations in their ability to reason beyond simple pattern
matching. To explore this gap, we systematically evaluate these models across
different noise levels and temperature settings. Our results reveal that the
introduction of noise consistently impairs model performance, regardless of
architecture. This decline highlights a shared vulnerability: current LLMs,
despite showing signs of abstract reasoning, remain highly sensitive to input
perturbations. Such fragility raises concerns about their real-world
applicability, where noise and uncertainty are common. By comparing how
different model architectures respond to these challenges, we offer insights
into the structural weaknesses of modern LLMs in reasoning tasks. This work
underscores the need for developing more robust and adaptable AI systems
capable of handling the ambiguity and variability inherent in real-world
scenarios. Our findings aim to guide future research toward enhancing model
generalization, robustness, and alignment with human-like cognitive
flexibility.

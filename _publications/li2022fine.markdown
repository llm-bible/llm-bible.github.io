---
layout: publication
title: Fine45;grained Semantically Aligned Vision45;language Pre45;training
authors: Li Juncheng, He Xin, Wei Longhui, Qian Long, Zhu Linchao, Xie Lingxi, Zhuang Yueting, Tian Qi, Tang Siliang
conference: "Arxiv"
year: 2022
bibkey: li2022fine
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2208.02515"}
  - {name: "Code", url: "https://github.com/YYJMJC/LOUPE"}
tags: ['Attention Mechanism', 'Has Code', 'Model Architecture', 'Pretraining Methods', 'Tools', 'Training Techniques']
---
Large45;scale vision45;language pre45;training has shown impressive advances in a wide range of downstream tasks. Existing methods mainly model the cross45;modal alignment by the similarity of the global representations of images and texts or advanced cross45;modal attention upon image and text features. However they fail to explicitly learn the fine45;grained semantic alignment between visual regions and textual phrases as only global image45;text alignment information is available. In this paper we introduce LOUPE a fine45;grained semantically aLigned visiOn45;langUage PrE45;training framework which learns fine45;grained semantic alignment from the novel perspective of game45;theoretic interactions. To efficiently compute the game45;theoretic interactions we further propose an uncertainty45;aware neural Shapley interaction learning module. Experiments show that LOUPE achieves state45;of45;the45;art performance on a variety of vision45;language tasks. Furthermore without any object45;level human annotations and fine45;tuning LOUPE achieves competitive performance on object detection and visual grounding. More importantly LOUPE opens a new promising direction of learning fine45;grained semantics from large45;scale raw image45;text pairs. The repository of this work is at https://github.com/YYJMJC/LOUPE.

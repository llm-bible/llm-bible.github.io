---
layout: publication
title: Benchmarking Large Language Models on Communicative Medical Coaching a Novel System and Dataset
authors: Huang Hengguan, Wang Songtao, Liu Hongfu, Wang Hao, Wang Ye
conference: "Arxiv"
year: 2024
bibkey: huang2024benchmarking
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.05547"}
  - {name: "Code", url: "https://github.com/zerowst/Chatcoach)differentiates"}
tags: ['Agentic', 'Applications', 'Has Code', 'Reinforcement Learning', 'Tools']
---
Traditional applications of natural language processing (NLP) in healthcare have predominantly focused on patient-centered services enhancing patient interactions and care delivery such as through medical dialogue systems. However the potential of NLP to benefit inexperienced doctors particularly in areas such as communicative medical coaching remains largely unexplored. We introduce ChatCoach a human-AI cooperative framework designed to assist medical learners in practicing their communication skills during patient consultations. ChatCoach (Our data and code are available online https://github.com/zerowst/Chatcoach)differentiates itself from conventional dialogue systems by offering a simulated environment where medical learners can practice dialogues with a patient agent while a coach agent provides immediate structured feedback. This is facilitated by our proposed Generalized Chain-of-Thought (GCoT) approach which fosters the generation of structured feedback and enhances the utilization of external knowledge sources. Additionally we have developed a dataset specifically for evaluating Large Language Models (LLMs) within the ChatCoach framework on communicative medical coaching tasks. Our empirical results validate the effectiveness of ChatCoach.

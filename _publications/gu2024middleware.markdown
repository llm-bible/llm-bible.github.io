---
layout: publication
title: 'Middleware For Llms: Tools Are Instrumental For Language Agents In Complex Environments'
authors: Yu Gu, Yiheng Shu, Hao Yu, Xiao Liu, Yuxiao Dong, Jie Tang, Jayanth Srinivasa, Hugo Latapie, Yu Su
conference: "Arxiv"
year: 2024
bibkey: gu2024middleware
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.14672"}
tags: ['Agentic', 'Model Architecture', 'Tools', 'Reinforcement Learning', 'GPT', 'Fine-Tuning', 'Applications']
---
The applications of large language models (LLMs) have expanded well beyond
the confines of text processing, signaling a new era where LLMs are envisioned
as generalist agents capable of operating within complex environments. These
environments are often highly expansive, making it impossible for the LLM to
process them within its short-term memory. Motivated by recent research on
extending the capabilities of LLMs with tools, we seek to investigate the
intriguing potential of tools to augment LLMs in handling such complexity by
introducing a novel class of tools, termed middleware, to aid in the proactive
exploration within these massive environments. Such specialized tools can serve
as a middleware layer shielding the LLM from environmental complexity. In two
representative complex environments -- knowledge bases (KBs) and databases --
we demonstrate the significant potential of augmenting language agents with
tools in complex environments. Notably, equipped with the middleware, GPT-4
achieves 2.8X the performance of the best baseline in tasks requiring access to
database content and 2.2X in KB tasks. Our findings illuminate the path for
advancing language agents in real-world applications.

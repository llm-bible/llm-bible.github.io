---
layout: publication
title: Middleware For Llms Tools Are Instrumental For Language Agents In Complex Environments
authors: Gu Yu, Shu Yiheng, Yu Hao, Liu Xiao, Dong Yuxiao, Tang Jie, Srinivasa Jayanth, Latapie Hugo, Su Yu
conference: "Arxiv"
year: 2024
bibkey: gu2024middleware
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.14672"}
tags: ['Agentic', 'Applications', 'Fine Tuning', 'GPT', 'Model Architecture', 'Pretraining Methods', 'Reinforcement Learning', 'Tools']
---
The applications of large language models (LLMs) have expanded well beyond the confines of text processing signaling a new era where LLMs are envisioned as generalist language agents capable of operating within complex real45;world environments. These environments are often highly expansive making it impossible for the LLM to process them within its short45;term memory. Motivated by recent research on extending the capabilities of LLMs with tools this paper investigates the intriguing potential of tools to augment LLMs in handling such complexity. To this end we design customized tools to aid in the proactive exploration within these massive environments. Such tools can serve as a middleware layer shielding the LLM from environmental complexity. In two representative complex environments 45;45; knowledge bases (KBs) and databases 45;45; we demonstrate the significant potential of augmenting language agents with tools in complex environments. Notably equipped with these tools GPT45;4 achieves 2.8X the performance of the best baseline in tasks requiring access to database content and 2.2X in KB tasks. Our findings illuminate the path for advancing language agents in complex real45;world applications.

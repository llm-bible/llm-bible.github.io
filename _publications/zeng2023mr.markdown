---
layout: publication
title: MR45;GSM8K A Meta45;reasoning Benchmark For Large Language Model Evaluation
authors: Zeng Zhongshen, Chen Pengguang, Liu Shu, Jiang Haiyun, Jia Jiaya
conference: "Arxiv"
year: 2023
bibkey: zeng2023mr
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2312.17080"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Training Techniques']
---
In this work we introduce a novel evaluation paradigm for Large Language Models (LLMs) that compels them to transition from a traditional question45;answering role akin to a student to a solution45;scoring role akin to a teacher. This paradigm focusing on reasoning about reasoning hence termed meta45;reasoning shifts the emphasis from result45;oriented assessments which often neglect the reasoning process to a more comprehensive evaluation that effectively distinguishes between the cognitive capabilities of different models. By applying this paradigm in the GSM8K dataset we have developed the MR45;GSM8K benchmark. Our extensive analysis includes several state45;of45;the45;art models from both open45;source and commercial domains uncovering fundamental deficiencies in their training and evaluation methodologies. Notably while models like Deepseek45;v2 and Claude345;Sonnet closely competed with GPT45;4 in GSM8K their performance disparities expanded dramatically in MR45;GSM8K with differences widening to over 20 absolute points underscoring the significant challenge posed by our meta45;reasoning approach.

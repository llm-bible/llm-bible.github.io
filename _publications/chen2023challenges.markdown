---
layout: publication
title: 'Challenges And Contributing Factors In The Utilization Of Large Language Models (llms)'
authors: Xiaoliang Chen, Liangbin Li, Le Chang, Yunhe Huang, Yuxuan Zhao, Yuxiao Zhang, Dinuo Li
conference: "Arxiv"
year: 2023
bibkey: chen2023challenges
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.13343"}
tags: ['Responsible AI', 'GPT', 'Survey Paper', 'Ethics and Bias', 'Interpretability and Explainability', 'Bias Mitigation', 'Model Architecture', 'Reinforcement Learning', 'Interpretability', 'Fairness', 'Training Techniques', 'Multimodal Models']
---
With the development of large language models (LLMs) like the GPT series,
their widespread use across various application scenarios presents a myriad of
challenges. This review initially explores the issue of domain specificity,
where LLMs may struggle to provide precise answers to specialized questions
within niche fields. The problem of knowledge forgetting arises as these LLMs
might find it hard to balance old and new information. The knowledge repetition
phenomenon reveals that sometimes LLMs might deliver overly mechanized
responses, lacking depth and originality. Furthermore, knowledge illusion
describes situations where LLMs might provide answers that seem insightful but
are actually superficial, while knowledge toxicity focuses on harmful or biased
information outputs. These challenges underscore problems in the training data
and algorithmic design of LLMs. To address these issues, it's suggested to
diversify training data, fine-tune models, enhance transparency and
interpretability, and incorporate ethics and fairness training. Future
technological trends might lean towards iterative methodologies, multimodal
learning, model personalization and customization, and real-time learning and
feedback mechanisms. In conclusion, future LLMs should prioritize fairness,
transparency, and ethics, ensuring they uphold high moral and ethical standards
when serving humanity.

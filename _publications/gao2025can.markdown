---
layout: publication
title: 'Can Llms Simulate L2-english Dialogue? An Information-theoretic Analysis Of L1-dependent Biases'
authors: Rena Gao, Xuetong Wu, Tatsuki Kuribayashi, Mingrui Ye, Siya Qi, Carsten Roever, Yuanxing Liu, Zheng Yuan, Jey Han Lau
conference: "Arxiv"
year: 2025
bibkey: gao2025can
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2502.14507'}
tags: ['GPT', 'Applications', 'Model Architecture', 'Prompting', 'Ethics and Bias']
---
This study evaluates Large Language Models' (LLMs) ability to simulate
non-native-like English use observed in human second language (L2) learners
interfered with by their native first language (L1). In dialogue-based
interviews, we prompt LLMs to mimic L2 English learners with specific L1s
(e.g., Japanese, Thai, Urdu) across seven languages, comparing their outputs to
real L2 learner data. Our analysis examines L1-driven linguistic biases, such
as reference word usage and avoidance behaviors, using information-theoretic
and distributional density measures. Results show that modern LLMs (e.g.,
Qwen2.5, LLAMA3.3, DeepseekV3, GPT-4o) replicate L1-dependent patterns observed
in human L2 data, with distinct influences from various languages (e.g.,
Japanese, Korean, and Mandarin significantly affect tense agreement, and Urdu
influences noun-verb collocations). Our results reveal the potential of LLMs
for L2 dialogue generation and evaluation for future educational applications.

---
layout: publication
title: 'Waking Up An AI: A Quantitative Framework For Prompt-induced Phase Transition In Large Language Models'
authors: Makoto Sato
conference: "Arxiv"
year: 2025
bibkey: sato2025waking
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2504.21012"}
tags: ['Merging', 'Tools', 'Prompting', 'Reinforcement Learning']
---
What underlies intuitive human thinking? One approach to this question is to
compare the cognitive dynamics of humans and large language models (LLMs).
However, such a comparison requires a method to quantitatively analyze AI
cognitive behavior under controlled conditions. While anecdotal observations
suggest that certain prompts can dramatically change LLM behavior, these
observations have remained largely qualitative. Here, we propose a two-part
framework to investigate this phenomenon: a Transition-Inducing Prompt (TIP)
that triggers a rapid shift in LLM responsiveness, and a Transition Quantifying
Prompt (TQP) that evaluates this change using a separate LLM. Through
controlled experiments, we examined how LLMs react to prompts embedding two
semantically distant concepts (e.g., mathematical aperiodicity and traditional
crafts)-either fused together or presented separately-by changing their
linguistic quality and affective tone. Whereas humans tend to experience
heightened engagement when such concepts are meaningfully blended producing a
novel concept-a form of conceptual fusion-current LLMs showed no significant
difference in responsiveness between semantically fused and non-fused prompts.
This suggests that LLMs may not yet replicate the conceptual integration
processes seen in human intuition. Our method enables fine-grained,
reproducible measurement of cognitive responsiveness, and may help illuminate
key differences in how intuition and conceptual leaps emerge in artificial
versus human minds.

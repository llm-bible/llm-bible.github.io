---
layout: publication
title: Ragged Edges The Double45;edged Sword Of Retrieval45;augmented Chatbots
authors: Feldman Philip, Foulds James R., Pan Shimei
conference: "Arxiv"
year: 2024
bibkey: feldman2024ragged
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.01193"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Prompting', 'RAG', 'Reinforcement Learning']
---
Large language models (LLMs) like ChatGPT demonstrate the remarkable progress of artificial intelligence. However their tendency to hallucinate 45;45; generate plausible but false information 45;45; poses a significant challenge. This issue is critical as seen in recent court cases where ChatGPTs use led to citations of non45;existent legal rulings. This paper explores how Retrieval45;Augmented Generation (RAG) can counter hallucinations by integrating external knowledge with prompts. We empirically evaluate RAG against standard LLMs using prompts designed to induce hallucinations. Our results show that RAG increases accuracy in some cases but can still be misled when prompts directly contradict the models pre45;trained understanding. These findings highlight the complex nature of hallucinations and the need for more robust solutions to ensure LLM reliability in real45;world applications. We offer practical recommendations for RAG deployment and discuss implications for the development of more trustworthy LLMs.

---
layout: publication
title: Diff45;explainer Differentiable Convex Optimization For Explainable Multi45;hop Inference
authors: Thayaparan Mokanarangan, Valentino Marco, Ferreira Deborah, Rozanova Julia, Freitas Andr√©
conference: "Arxiv"
year: 2021
bibkey: thayaparan2021diff
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2105.03417"}
tags: ['Applications', 'Efficiency And Optimization', 'Interpretability And Explainability', 'Model Architecture', 'Pretraining Methods', 'Reinforcement Learning', 'Tools', 'Transformer']
---
This paper presents Diff45;Explainer the first hybrid framework for explainable multi45;hop inference that integrates explicit constraints with neural architectures through differentiable convex optimization. Specifically Diff45;Explainer allows for the fine45;tuning of neural representations within a constrained optimization framework to answer and explain multi45;hop questions in natural language. To demonstrate the efficacy of the hybrid framework we combine existing ILP45;based solvers for multi45;hop Question Answering (QA) with Transformer45;based representations. An extensive empirical evaluation on scientific and commonsense QA tasks demonstrates that the integration of explicit constraints in an end45;to45;end differentiable framework can significantly improve the performance of non45;differentiable ILP solvers (8.9137; 45; 13.337;). Moreover additional analysis reveals that Diff45;Explainer is able to achieve strong performance when compared to standalone Transformers and previous multi45;hop approaches while still providing structured explanations in support of its predictions.

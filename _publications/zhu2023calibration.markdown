---
layout: publication
title: 'On The Calibration Of Large Language Models And Alignment'
authors: Chiwei Zhu, Benfeng Xu, Quan Wang, Yongdong Zhang, Zhendong Mao
conference: "Arxiv"
year: 2023
bibkey: zhu2023calibration
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2311.13240'}
tags: ['Attention Mechanism', 'Training Techniques', 'Model Architecture', 'Pretraining Methods']
---
As large language models attract increasing attention and find widespread
application, concurrent challenges of reliability also arise at the same time.
Confidence calibration, an effective analysis method for gauging the
reliability of deep models, serves as a crucial tool for assessing and
improving their reliability. However, such investigation has been comparatively
underexplored. In this work, we conduct a systematic examination of the
calibration of aligned language models throughout the entire construction
process, including pretraining and alignment training. At each stage, we
investigate how different training settings, such as parameter scales and
training data, affect model calibration. To thoroughly assess model
calibration, we evaluate models on three most concerned aspects: generation,
factuality and understanding. Our work sheds light on whether popular LLMs are
well-calibrated and how the training process influences model calibration.

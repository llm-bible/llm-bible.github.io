---
layout: publication
title: Emobench Evaluating The Emotional Intelligence Of Large Language Models
authors: Sabour Sahand, Liu Siyang, Zhang Zheyuan, Liu June M., Zhou Jinfeng, Sunaryo Alvionna S., Li Juanzi, Lee Tatia M. C., Mihalcea Rada, Huang Minlie
conference: "Arxiv"
year: 2024
bibkey: sabour2024evaluating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.12071"}
  - {name: "Code", url: "https://github.com/Sahandfer/EmoBench"}
tags: ['Has Code', 'Pretraining Methods', 'RAG']
---
Recent advances in Large Language Models (LLMs) have highlighted the need for robust comprehensive and challenging benchmarks. Yet research on evaluating their Emotional Intelligence (EI) is considerably limited. Existing benchmarks have two major shortcomings first they mainly focus on emotion recognition neglecting essential EI capabilities such as emotion regulation and thought facilitation through emotion understanding; second they are primarily constructed from existing datasets which include frequent patterns explicit information and annotation errors leading to unreliable evaluation. We propose EmoBench a benchmark that draws upon established psychological theories and proposes a comprehensive definition for machine EI including Emotional Understanding and Emotional Application. EmoBench includes a set of 400 hand45;crafted questions in English and Chinese which are meticulously designed to require thorough reasoning and understanding. Our findings reveal a considerable gap between the EI of existing LLMs and the average human highlighting a promising direction for future research. Our code and data are publicly available at https://github.com/Sahandfer/EmoBench.

---
layout: publication
title: Follow45;up Questions Improve Documents Generated By Large Language Models
authors: Tix Bernadette J
conference: "Arxiv"
year: 2024
bibkey: tix2024follow
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.12017"}
tags: ['Pretraining Methods', 'Reinforcement Learning']
---
This study investigates the impact of Large Language Models (LLMs) generating follow45;up questions in response to user requests for short (145;page) text documents. Users interacted with a novel web45;based AI system designed to ask follow45;up questions. Users requested documents they would like the AI to produce. The AI then generated follow45;up questions to clarify the users needs or offer additional insights before generating the requested documents. After answering the questions users were shown a document generated using both the initial request and the questions and answers and a document generated using only the initial request. Users indicated which document they preferred and gave feedback about their experience with the question45;answering process. The findings of this study show clear benefits to question45;asking both in document preference and in the qualitative user experience. This study further shows that users found more value in questions which were thought45;provoking open45;ended or offered unique insights into the users request as opposed to simple information45;gathering questions.

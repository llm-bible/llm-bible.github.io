---
layout: publication
title: Neural Generation Of Diverse Questions Using Answer Focus, Contextual And Linguistic
  Features
authors: Vrindavan Harrison, Marilyn Walker
conference: Arxiv
year: 2018
citations: 20
bibkey: harrison2018neural
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1809.02637'}]
tags: [Attention Mechanism, Model Architecture]
---
Question Generation is the task of automatically creating questions from
textual input. In this work we present a new Attentional Encoder--Decoder
Recurrent Neural Network model for automatic question generation. Our model
incorporates linguistic features and an additional sentence embedding to
capture meaning at both sentence and word levels. The linguistic features are
designed to capture information related to named entity recognition, word case,
and entity coreference resolution. In addition our model uses a copying
mechanism and a special answer signal that enables generation of numerous
diverse questions on a given sentence. Our model achieves state of the art
results of 19.98 Bleu_4 on a benchmark Question Generation dataset,
outperforming all previously published results by a significant margin. A human
evaluation also shows that these added features improve the quality of the
generated questions.
---
layout: publication
title: 'Fin-r1: A Large Language Model For Financial Reasoning Through Reinforcement Learning'
authors: Zhaowei Liu, Xin Guo, Fangqi Lou, Lingfeng Zeng, Jinyi Niu, Zixuan Wang, Jiajie Xu, Weige Cai, Ziwei Yang, Xueqian Zhao, Chao Li, Sheng Xu, Dezhi Chen, Yun Chen, Zuo Bai, Liwen Zhang
conference: "Arxiv"
year: 2025
bibkey: liu2025fin
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2503.16252'}
  - {name: "Code", url: 'https://github.com/SUFE-AIFLM-Lab/Fin-R1'}
tags: ['Agentic', 'Has Code', 'RAG', 'Model Architecture', 'Training Techniques', 'Tools', 'Fine-Tuning', 'Reinforcement Learning', 'Pretraining Methods']
---
Reasoning large language models are rapidly evolving across various domains.
However, their capabilities in handling complex financial tasks still require
in-depth exploration. In this paper, we introduce Fin-R1, a reasoning large
language model specifically designed for the financial sector. Fin-R1 is built
using a two-stage architecture, leveraging a financial reasoning dataset
distilled and processed based on DeepSeek-R1. Through supervised fine-tuning
(SFT) and reinforcement learning (RL) training, it demonstrates performance
close to DeepSeek-R1 with a parameter size of 7 billion across a range of
financial reasoning tasks. It achieves the state-of-the-art (SOTA) in the FinQA
and ConvFinQA tasks between those LLMs in our evaluation, surpassing larger
models in other tasks as well. Fin-R1 showcases strong reasoning and
decision-making capabilities, providing solutions to various problems
encountered in the financial domain. Our code is available at
https://github.com/SUFE-AIFLM-Lab/Fin-R1.

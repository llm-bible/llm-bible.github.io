---
layout: publication
title: From Tarzan To Tolkien Controlling The Language Proficiency Level Of Llms For Content Generation
authors: Malik Ali, Mayhew Stephen, Piech Chris, Bicknell Klinton
conference: "In Findings of the Association for Computational Linguistics"
year: 2024
bibkey: malik2024from
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.03030"}
tags: ['Agentic', 'GPT', 'Model Architecture', 'Prompting', 'Reinforcement Learning', 'Tools']
---
We study the problem of controlling the difficulty level of text generated by Large Language Models (LLMs) for contexts where end45;users are not fully proficient such as language learners. Using a novel framework we evaluate the effectiveness of several key approaches for this task including few45;shot prompting supervised finetuning and reinforcement learning (RL) utilising both GPT45;4 and open source alternatives like LLama245;7B and Mistral45;7B. Our findings reveal a large performance gap between GPT45;4 and the open source models when using prompt45;based strategies. However we show how to bridge this gap with a careful combination of finetuning and RL alignment. Our best model CALM (CEFR45;Aligned Language Model) surpasses the performance of GPT45;4 and other strategies at only a fraction of the cost. We further validate the quality of our results through a small45;scale human study.

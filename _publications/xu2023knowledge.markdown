---
layout: publication
title: 'Knowledge-infused Prompting: Assessing And Advancing Clinical Text Data Generation With Large Language Models'
authors: Xu Ran, Cui Hejie, Yu Yue, Kan Xuan, Shi Wenqi, Zhuang Yuchen, Jin Wei, Ho Joyce, Yang Carl
conference: "Arxiv"
year: 2023
bibkey: xu2023knowledge
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2311.00287"}
  - {name: "Code", url: "https://github.com/ritaranx/ClinGen"}
tags: ['Applications', 'Has Code', 'Language Modeling', 'Prompting', 'Reinforcement Learning', 'Training Techniques']
---
Clinical natural language processing requires methods that can address domain-specific challenges such as complex medical terminology and clinical contexts. Recently large language models (LLMs) have shown promise in this domain. Yet their direct deployment can lead to privacy issues and are constrained by resources. To address this challenge we delve into synthetic clinical text generation using LLMs for clinical NLP tasks. We propose an innovative resource-efficient approach ClinGen which infuses knowledge into the process. Our model involves clinical knowledge extraction and context-informed LLM prompting. Both clinical topics and writing styles are drawn from external domain-specific knowledge graphs and LLMs to guide data generation. Our extensive empirical study across 7 clinical NLP tasks and 16 datasets reveals that ClinGen consistently enhances performance across various tasks effectively aligning the distribution of real datasets and significantly enriching the diversity of generated training instances. We will publish our code and all the generated data in (url)https://github.com/ritaranx/ClinGen\}."

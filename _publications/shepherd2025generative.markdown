---
layout: publication
title: 'Generative AI Misuse Potential In Cyber Security Education: A Case Study Of A UK Degree Program'
authors: Carlton Shepherd
conference: "Arxiv"
year: 2025
bibkey: shepherd2025generative
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2501.12883"}
tags: ['Security', 'Model Architecture', 'Tools', 'Reinforcement Learning', 'GPT']
---
Recent advances in generative artificial intelligence (AI), such as ChatGPT,
Google Gemini, and other large language models (LLMs), pose significant
challenges to upholding academic integrity in higher education. This paper
investigates the susceptibility of a Master's-level cyber security degree
program at a UK Russell Group university, accredited by a leading national
body, to LLM misuse. Through the application and extension of a quantitative
assessment framework, we identify a high exposure to misuse, particularly in
independent project- and report-based assessments. Contributing factors,
including block teaching and a predominantly international cohort, are
highlighted as potential amplifiers of these vulnerabilities. To address these
challenges, we discuss the adoption of LLM-resistant assessments, detection
tools, and the importance of fostering an ethical learning environment. These
approaches aim to uphold academic standards while preparing students for the
complexities of real-world cyber security.

---
layout: publication
title: Webvln Vision45;and45;language Navigation On Websites
authors: Chen Qi, Pitawela Dileepa, Zhao Chongyang, Zhou Gengze, Chen Hsiang-ting, Wu Qi
conference: "Arxiv"
year: 2023
bibkey: chen2023vision
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2312.15820"}
  - {name: "Code", url: "https://github.com/WebVLN/WebVLN"}
tags: ['Agentic', 'Attention Mechanism', 'Ethics And Bias', 'Has Code', 'Model Architecture', 'Reinforcement Learning']
---
Vision45;and45;Language Navigation (VLN) task aims to enable AI agents to accurately understand and follow natural language instructions to navigate through real45;world environments ultimately reaching specific target locations. We recognise a promising opportunity to extend VLN to a comparable navigation task that holds substantial significance in our daily lives albeit within the virtual realm navigating websites on the Internet. This paper proposes a new task named Vision45;and45;Language Navigation on Websites (WebVLN) where we use question45;based instructions to train an agent emulating how users naturally browse websites. Unlike the existing VLN task that only pays attention to vision and instruction (language) the WebVLN agent further considers underlying web45;specific content like HTML which could not be seen on the rendered web pages yet contains rich visual and textual information. Toward this goal we contribute a dataset WebVLN45;v1 and introduce a novel approach called Website45;aware VLN Network (WebVLN45;Net) which is built upon the foundation of state45;of45;the45;art VLN techniques. Experimental results show that WebVLN45;Net outperforms current VLN and web45;related navigation methods. We believe that the introduction of the new WebVLN task and its dataset will establish a new dimension within the VLN domain and contribute to the broader vision45;and45;language research community. The code is available at https://github.com/WebVLN/WebVLN.

---
layout: publication
title: Alltogether Investigating The Efficacy Of Spliced Prompt For Web Navigation Using Large Language Models
authors: Liu Jiarun, Hu Wentao, Zhang Chunhong
conference: "Arxiv"
year: 2023
bibkey: liu2023investigating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.18331"}
tags: ['Agentic', 'Efficiency And Optimization', 'GPT', 'Model Architecture', 'Pretraining Methods', 'Prompting', 'Tools']
---
Large Language Models (LLMs) have emerged as promising agents for web navigation tasks interpreting objectives and interacting with web pages. However the efficiency of spliced prompts for such tasks remains underexplored. We introduces AllTogether a standardized prompt template that enhances task context representation thereby improving LLMs performance in HTML45;based web navigation. We evaluate the efficacy of this approach through prompt learning and instruction finetuning based on open45;source Llama45;2 and API45;accessible GPT models. Our results reveal that models like GPT45;4 outperform smaller models in web navigation tasks. Additionally we find that the length of HTML snippet and history trajectory significantly influence performance and prior step45;by45;step instructions prove less effective than real45;time environmental feedback. Overall we believe our work provides valuable insights for future research in LLM45;driven web agents.

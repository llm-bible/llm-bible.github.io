---
layout: publication
title: "Event Temporal Relation Extraction Based On Retrieval-augmented On Llms"
authors: Zhang Xiaobin, Zang Liangjun, Liu Qianwen, Wei Shuchong, Hu Songlin
conference: "Arxiv"
year: 2024
bibkey: zhang2024event
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.15273"}
tags: ['Prompting', 'RAG', 'Tools']
---
Event temporal relation (TempRel) is a primary subject of the event relation extraction task. However the inherent ambiguity of TempRel increases the difficulty of the task. With the rise of prompt engineering it is important to design effective prompt templates and verbalizers to extract relevant knowledge. The traditional manually designed templates struggle to extract precise temporal knowledge. This paper introduces a novel retrieval-augmented TempRel extraction approach leveraging knowledge retrieved from large language models (LLMs) to enhance prompt templates and verbalizers. Our method capitalizes on the diverse capabilities of various LLMs to generate a wide array of ideas for template and verbalizer design. Our proposed method fully exploits the potential of LLMs for generation tasks and contributes more knowledge to our design. Empirical evaluations across three widely recognized datasets demonstrate the efficacy of our method in improving the performance of event temporal relation extraction tasks.

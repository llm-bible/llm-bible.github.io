---
layout: publication
title: An Ecosage Assistant Towards Building A Multimodal Plant Care Dialogue Assistant
authors: Tomar Mohit, Tiwari Abhisek, Saha Tulika, Jha Prince, Saha Sriparna
conference: "Arxiv"
year: 2024
bibkey: tomar2024ecosage
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.06807"}
tags: ['Merging', 'Multimodal Models', 'Prompting', 'Reinforcement Learning', 'Survey Paper', 'Tools']
---
In recent times there has been an increasing awareness about imminent environmental challenges resulting in people showing a stronger dedication to taking care of the environment and nurturing green life. The current 19.6 billion indoor gardening industry reflective of this growing sentiment not only signifies a monetary value but also speaks of a profound human desire to reconnect with the natural world. However several recent surveys cast a revealing light on the fate of plants within our care with more than half succumbing primarily due to the silent menace of improper care. Thus the need for accessible expertise capable of assisting and guiding individuals through the intricacies of plant care has become paramount more than ever. In this work we make the very first attempt at building a plant care assistant which aims to assist people with plant(45;ing) concerns through conversations. We propose a plant care conversational dataset named Plantational which contains around 1K dialogues between users and plant care experts. Our end45;to45;end proposed approach is two45;fold (i) We first benchmark the dataset with the help of various large language models (LLMs) and visual language model (VLM) by studying the impact of instruction tuning (zero45;shot and few45;shot prompting) and fine45;tuning techniques on this task; (ii) finally we build EcoSage a multi45;modal plant care assisting dialogue generation framework incorporating an adapter45;based modality infusion using a gated mechanism. We performed an extensive examination (both automated and manual evaluation) of the performance exhibited by various LLMs and VLM in the generation of the domain45;specific dialogue responses to underscore the respective strengths and weaknesses of these diverse models.

---
layout: publication
title: Do Llms Find Human Answers To Fact45;driven Questions Perplexing A Case Study On Reddit
authors: Seegmiller Parker, Gatto Joseph, Sharif Omar, Basak Madhusudan, Preum Sarah Masud
conference: "Arxiv"
year: 2024
bibkey: seegmiller2024do
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.01147"}
tags: ['Pretraining Methods', 'Reinforcement Learning']
---
Large language models (LLMs) have been shown to be proficient in correctly answering questions in the context of online discourse. However the study of using LLMs to model human45;like answers to fact45;driven social media questions is still under45;explored. In this work we investigate how LLMs model the wide variety of human answers to fact45;driven questions posed on several topic45;specific Reddit communities or subreddits. We collect and release a dataset of 409 fact45;driven questions and 7534 diverse human45;rated answers from 15 r/Ask123;Topic125; communities across 3 categories profession social identity and geographic location. We find that LLMs are considerably better at modeling highly45;rated human answers to such questions as opposed to poorly45;rated human answers. We present several directions for future research based on our initial findings.

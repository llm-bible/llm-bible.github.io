---
layout: publication
title: A Study On Large Language Modelsx27; Limitations In Multiple-choice Question Answering
authors: Khatun Aisha, Brown Daniel G.
conference: "Arxiv"
year: 2024
bibkey: khatun2024study
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.07955"}
tags: ['Applications', 'Reinforcement Learning']
---
The widespread adoption of Large Language Models (LLMs) has become commonplace particularly with the emergence of open-source models. More importantly smaller models are well-suited for integration into consumer devices and are frequently employed either as standalone solutions or as subroutines in various AI tasks. Despite their ubiquitous use there is no systematic analysis of their specific capabilities and limitations. In this study we tackle one of the most widely used tasks - answering Multiple Choice Question (MCQ). We analyze 26 small open-source models and find that 65 of the models do not understand the task only 4 models properly select an answer from the given choices and only 5 of these models are choice order independent. These results are rather alarming given the extensive use of MCQ tests with these models. We recommend exercising caution and testing task understanding before using MCQ to evaluate LLMs in any field whatsoever.

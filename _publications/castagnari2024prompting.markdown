---
layout: publication
title: 'Prompting Large Language Models For Supporting The Differential Diagnosis Of Anemia'
authors: Elisa Heka Castagnari, Lillian Heka Muyama, Adrien Heka Coulet
conference: "LLMs4MI 2024 @FLLM 2024 IEEE Nov 2024 Dubai United Arab Emirates"
year: 2024
bibkey: castagnari2024prompting
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2409.15377'}
tags: ['Transformer', 'GPT', 'Tools', 'Model Architecture', 'Merging', 'Prompting', 'Reinforcement Learning', 'Pretraining Methods']
---
In practice, clinicians achieve a diagnosis by following a sequence of steps,
such as laboratory exams, observations, or imaging. The pathways to reach
diagnosis decisions are documented by guidelines authored by expert
organizations, which guide clinicians to reach a correct diagnosis through
these sequences of steps. While these guidelines are beneficial for following
medical reasoning and consolidating medical knowledge, they have some
drawbacks. They often fail to address patients with uncommon conditions due to
their focus on the majority population, and are slow and costly to update,
making them unsuitable for rapidly emerging diseases or new practices. Inspired
by clinical guidelines, our study aimed to develop pathways similar to those
that can be obtained in clinical guidelines. We tested three Large Language
Models (LLMs) -Generative Pretrained Transformer 4 (GPT-4), Large Language
Model Meta AI (LLaMA), and Mistral -on a synthetic yet realistic dataset to
differentially diagnose anemia and its subtypes. By using advanced prompting
techniques to enhance the decision-making process, we generated diagnostic
pathways using these models. Experimental results indicate that LLMs hold huge
potential in clinical pathway discovery from patient data, with GPT-4
exhibiting the best performance in all conducted experiments.

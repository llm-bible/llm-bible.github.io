---
layout: publication
title: Are Large Vision Language Models Up To The Challenge Of Chart Comprehension And Reasoning An Extensive Investigation Into The Capabilities And Limitations Of Lvlms
authors: Islam Mohammed Saidul, Rahman Raian, Masry Ahmed, Laskar Md Tahmid Rahman, Nayeem Mir Tafseer, Hoque Enamul
conference: "Arxiv"
year: 2024
bibkey: islam2024are
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.00257"}
tags: ['Applications', 'Ethics And Bias', 'GPT', 'Model Architecture', 'Prompting']
---
Natural language is a powerful complementary modality of communication for data visualizations such as bar and line charts. To facilitate chart45;based reasoning using natural language various downstream tasks have been introduced recently such as chart question answering chart summarization and fact45;checking with charts. These tasks pose a unique challenge demanding both vision45;language reasoning and a nuanced understanding of chart data tables visual encodings and natural language prompts. Despite the recent success of Large Language Models (LLMs) across diverse NLP tasks their abilities and limitations in the realm of data visualization remain under45;explored possibly due to their lack of multi45;modal capabilities. To bridge the gap this paper presents the first comprehensive evaluation of the recently developed large vision language models (LVLMs) for chart understanding and reasoning tasks. Our evaluation includes a comprehensive assessment of LVLMs including GPT45;4V and Gemini across four major chart reasoning tasks. Furthermore we perform a qualitative evaluation of LVLMs performance on a diverse range of charts aiming to provide a thorough analysis of their strengths and weaknesses. Our findings reveal that LVLMs demonstrate impressive abilities in generating fluent texts covering high45;level data insights while also encountering common problems like hallucinations factual errors and data bias. We highlight the key strengths and limitations of chart comprehension tasks offering insights for future research.

---
layout: publication
title: LLMR Real-time Prompting Of Interactive Worlds Using Large Language Models
authors: De La Torre Fernanda, Fang Cathy Mengying, Huang Han, Banburski-fahey Andrzej, Fernandez Judith Amores, Lanier Jaron
conference: "Arxiv"
year: 2023
bibkey: delatorre2023real
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.12276"}
tags: ['GPT', 'Model Architecture', 'Pretraining Methods', 'Prompting', 'RAG', 'Reinforcement Learning', 'Tools', 'Training Techniques']
---
We present Large Language Model for Mixed Reality (LLMR) a framework for the real-time creation and modification of interactive Mixed Reality experiences using LLMs. LLMR leverages novel strategies to tackle difficult cases where ideal training data is scarce or where the design goal requires the synthesis of internal dynamics intuitive analysis or advanced interactivity. Our framework relies on text interaction and the Unity game engine. By incorporating techniques for scene understanding task planning self-debugging and memory management LLMR outperforms the standard GPT-4 by 4x in average error rate. We demonstrate LLMRs cross-platform interoperability with several example worlds and evaluate it on a variety of creation and modification tasks to show that it can produce and edit diverse objects tools and scenes. Finally we conducted a usability study (N=11) with a diverse set that revealed participants had positive experiences with the system and would use it again.

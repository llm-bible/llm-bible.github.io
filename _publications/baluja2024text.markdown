---
layout: publication
title: 'Text Is Not All You Need: Multimodal Prompting Helps Llms Understand Humor'
authors: Ashwin Baluja
conference: "Arxiv"
year: 2024
bibkey: baluja2024text
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2412.05315"}
tags: ['Prompting', 'Multimodal Models', 'Interpretability and Explainability']
---
While Large Language Models (LLMs) have demonstrated impressive natural
language understanding capabilities across various text-based tasks,
understanding humor has remained a persistent challenge. Humor is frequently
multimodal, relying on phonetic ambiguity, rhythm and timing to convey meaning.
In this study, we explore a simple multimodal prompting approach to humor
understanding and explanation. We present an LLM with both the text and the
spoken form of a joke, generated using an off-the-shelf text-to-speech (TTS)
system. Using multimodal cues improves the explanations of humor compared to
textual prompts across all tested datasets.

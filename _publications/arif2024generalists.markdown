---
layout: publication
title: 'Generalists Vs. Specialists: Evaluating Large Language Models For Urdu'
authors: Samee Arif, Abdul Hameed Azeemi, Agha Ali Raza, Awais Athar
conference: "Arxiv"
year: 2024
bibkey: arif2024generalists
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2407.04459'}
tags: ['GPT', 'BERT', 'Model Architecture']
---
In this paper, we compare general-purpose models, GPT-4-Turbo and Llama-3-8b,
with special-purpose models--XLM-Roberta-large, mT5-large, and Llama-3-8b--that
have been fine-tuned on specific tasks. We focus on seven classification and
seven generation tasks to evaluate the performance of these models on Urdu
language. Urdu has 70 million native speakers, yet it remains underrepresented
in Natural Language Processing (NLP). Despite the frequent advancements in
Large Language Models (LLMs), their performance in low-resource languages,
including Urdu, still needs to be explored. We also conduct a human evaluation
for the generation tasks and compare the results with the evaluations performed
by GPT-4-Turbo, Llama-3-8b and Claude 3.5 Sonnet. We find that special-purpose
models consistently outperform general-purpose models across various tasks. We
also find that the evaluation done by GPT-4-Turbo for generation tasks aligns
more closely with human evaluation compared to the evaluation the evaluation
done by Llama-3-8b. This paper contributes to the NLP community by providing
insights into the effectiveness of general and specific-purpose LLMs for
low-resource languages.

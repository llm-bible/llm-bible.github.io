---
layout: publication
title: A comprehensive evaluation of ChatGPTs zero-shot Text-to-SQL capability
authors: Liu Aiwei, Hu Xuming, Wen Lijie, Yu Philip S.
conference: "Arxiv"
year: 2023
bibkey: liu2023comprehensive
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2303.13547"}
  - {name: "Code", url: "https://github.com/THU-BPM/chatgpt-sql"}
tags: ['Applications', 'Fine Tuning', 'GPT', 'Has Code', 'Model Architecture', 'Pretraining Methods', 'Reinforcement Learning', 'Training Techniques']
---
This paper presents the first comprehensive analysis of ChatGPTs Text-to-SQL ability. Given the recent emergence of large-scale conversational language model ChatGPT and its impressive capabilities in both conversational abilities and code generation we sought to evaluate its Text-to-SQL performance. We conducted experiments on 12 benchmark datasets with different languages settings or scenarios and the results demonstrate that ChatGPT has strong text-to-SQL abilities. Although there is still a gap from the current state-of-the-art (SOTA) model performance considering that the experiment was conducted in a zero-shot scenario ChatGPTs performance is still impressive. Notably in the ADVETA (RPL) scenario the zero-shot ChatGPT even outperforms the SOTA model that requires fine-tuning on the Spider dataset by 4.1 demonstrating its potential for use in practical applications. To support further research in related fields we have made the data generated by ChatGPT publicly available at https://github.com/THU-BPM/chatgpt-sql.

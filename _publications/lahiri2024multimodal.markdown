---
layout: publication
title: 'Alzheimerrag: Multimodal Retrieval Augmented Generation For Pubmed Articles'
authors: Aritra Kumar Lahiri, Qinmin Vivian Hu
conference: "Arxiv"
year: 2024
bibkey: lahiri2024multimodal
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2412.16701"}
tags: ['RAG', 'Merging', 'Applications', 'Multimodal Models']
---
Recent advancements in generative AI have flourished the development of
highly adept Large Language Models (LLMs) that integrate diverse data types to
empower decision-making. Among these, Multimodal Retrieval-Augmented Generation
(RAG) applications are promising for their capability to combine the strengths
of information retrieval and generative models, enhancing their utility across
various domains, including biomedical research. This paper introduces
AlzheimerRAG, a Multimodal RAG pipeline tool for biomedical research use cases,
primarily focusing on Alzheimer's disease from PubMed articles. Our pipeline
incorporates multimodal fusion techniques to integrate textual and visual data
processing by efficiently indexing and accessing vast amounts of biomedical
literature. Preliminary experimental results against benchmarks, such as BioASQ
and PubMedQA, have returned improved results in information retrieval and
synthesis of domain-specific information. We also demonstrate a case study with
our RAG pipeline across different Alzheimer's clinical scenarios. We infer that
AlzheimerRAG can generate responses with accuracy non-inferior to humans and
with low rates of hallucination. Overall, a reduction in cognitive task load is
observed, which allows researchers to gain multimodal insights, improving
understanding and treatment of Alzheimer's disease.

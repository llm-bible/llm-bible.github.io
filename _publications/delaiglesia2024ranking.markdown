---
layout: publication
title: 'Ranking Over Scoring: Towards Reliable And Robust Automated Evaluation Of Llm-generated Medical Explanatory Arguments'
authors: Iker De La Iglesia, Iakes Goenaga, Johanna Ramirez-romero, Jose Maria Villa-gonzalez, Josu Goikoetxea, Ander Barrena
conference: "Arxiv"
year: 2024
bibkey: delaiglesia2024ranking
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2409.20565"}
tags: ['Ethics and Bias', 'Security']
---
Evaluating LLM-generated text has become a key challenge, especially in
domain-specific contexts like the medical field. This work introduces a novel
evaluation methodology for LLM-generated medical explanatory arguments, relying
on Proxy Tasks and rankings to closely align results with human evaluation
criteria, overcoming the biases typically seen in LLMs used as judges. We
demonstrate that the proposed evaluators are robust against adversarial
attacks, including the assessment of non-argumentative text. Additionally, the
human-crafted arguments needed to train the evaluators are minimized to just
one example per Proxy Task. By examining multiple LLM-generated arguments, we
establish a methodology for determining whether a Proxy Task is suitable for
evaluating LLM-generated medical explanatory arguments, requiring only five
examples and two human experts.

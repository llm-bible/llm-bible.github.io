---
layout: publication
title: 'Can The Capability Of Large Language Models Be Described By Human Ability? A Meta Study'
authors: Mingrui Zan, Yunquan Zhang, Boyang Zhang, Fangming Liu, Daning Cheng
conference: "Arxiv"
year: 2025
bibkey: zan2025can
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2504.12332"}
tags: ['Reinforcement Learning']
---
Users of Large Language Models (LLMs) often perceive these models as
intelligent entities with human-like capabilities. However, the extent to which
LLMs' capabilities truly approximate human abilities remains a topic of debate.
In this paper, to characterize the capabilities of LLMs in relation to human
capabilities, we collected performance data from over 80 models across 37
evaluation benchmarks. The evaluation benchmarks are categorized into 6 primary
abilities and 11 sub-abilities in human aspect. Then, we then clustered the
performance rankings into several categories and compared these clustering
results with classifications based on human ability aspects. Our findings lead
to the following conclusions: 1. We have confirmed that certain capabilities of
LLMs with fewer than 10 billion parameters can indeed be described using human
ability metrics; 2. While some abilities are considered interrelated in humans,
they appear nearly uncorrelated in LLMs; 3. The capabilities possessed by LLMs
vary significantly with the parameter scale of the model.

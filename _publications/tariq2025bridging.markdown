---
layout: publication
title: 'Bridging Expertise Gaps: The Role Of Llms In Human-ai Collaboration For Cybersecurity'
authors: Shahroz Tariq, Ronal Singh, Mohan Baruwal Chhetri, Surya Nepal, Cecile Paris
conference: "Arxiv"
year: 2025
bibkey: tariq2025bridging
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2505.03179'}
tags: ['Reinforcement Learning', 'Prompting', 'Interpretability and Explainability', 'Security']
---
This study investigates whether large language models (LLMs) can function as
intelligent collaborators to bridge expertise gaps in cybersecurity
decision-making. We examine two representative tasks-phishing email detection
and intrusion detection-that differ in data modality, cognitive complexity, and
user familiarity. Through a controlled mixed-methods user study, n = 58
(phishing, n = 34; intrusion, n = 24), we find that human-AI collaboration
improves task performance,reducing false positives in phishing detection and
false negatives in intrusion detection. A learning effect is also observed when
participants transition from collaboration to independent work, suggesting that
LLMs can support long-term skill development. Our qualitative analysis shows
that interaction dynamics-such as LLM definitiveness, explanation style, and
tone-influence user trust, prompting strategies, and decision revision. Users
engaged in more analytic questioning and showed greater reliance on LLM
feedback in high-complexity settings. These results provide design guidance for
building interpretable, adaptive, and trustworthy human-AI teaming systems, and
demonstrate that LLMs can meaningfully support non-experts in reasoning through
complex cybersecurity problems.

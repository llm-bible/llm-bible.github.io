---
layout: publication
title: 'Do Llms Work On Charts? Designing Few-shot Prompts For Chart Question Answering And Summarization'
authors: Do Xuan Long, Hassanpour Mohammad, Masry Ahmed, Kavehzadeh Parsa, Hoque Enamul, Joty Shafiq
conference: "Arxiv"
year: 2023
bibkey: do2023do
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2312.10610"}
tags: ['Applications', 'Few Shot', 'In Context Learning', 'Multimodal Models', 'Prompting', 'Reinforcement Learning', 'Tools']
---
A number of tasks have been proposed recently to facilitate easy access to charts such as chart QA and summarization. The dominant paradigm to solve these tasks has been to fine-tune a pretrained model on the task data. However this approach is not only expensive but also not generalizable to unseen tasks. On the other hand large language models (LLMs) have shown impressive generalization capabilities to unseen tasks with zero- or few-shot prompting. However their application to chart-related tasks is not trivial as these tasks typically involve considering not only the underlying data but also the visual features in the chart image. We propose PromptChart a multimodal few-shot prompting framework with LLMs for chart-related applications. By analyzing the tasks carefully we have come up with a set of prompting guidelines for each task to elicit the best few-shot performance from LLMs. We further propose a strategy to inject visual information into the prompts. Our experiments on three different chart-related information consumption tasks show that with properly designed prompts LLMs can excel on the benchmarks achieving state-of-the-art.

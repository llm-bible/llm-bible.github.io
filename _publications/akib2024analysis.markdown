---
layout: publication
title: 'Analysis On Llms Performance For Code Summarization'
authors: Md. Ahnaf Akib, Md. Muktadir Mazumder, Salman Ahsan
conference: "Arxiv"
year: 2024
bibkey: akib2024analysis
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2412.17094'}
tags: ['Reinforcement Learning', 'Applications', 'Tools']
---
Code summarization aims to generate concise natural language descriptions for
source code. Deep learning has been used more and more recently in software
engineering, particularly for tasks like code creation and summarization.
Specifically, it appears that the most current Large Language Models with
coding perform well on these tasks. Large Language Models (LLMs) have
significantly advanced the field of code summarization, providing sophisticated
methods for generating concise and accurate summaries of source code. This
study aims to perform a comparative analysis of several open-source LLMs,
namely LLaMA-3, Phi-3, Mistral, and Gemma. These models' performance is
assessed using important metrics such as BLEU\textsubscript\{3.1\} and
ROUGE\textsubscript\{3.2\}.
  Through this analysis, we seek to identify the strengths and weaknesses of
each model, offering insights into their applicability and effectiveness in
code summarization tasks. Our findings contribute to the ongoing development
and refinement of LLMs, supporting their integration into tools that enhance
software development and maintenance processes.

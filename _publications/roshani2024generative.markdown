---
layout: publication
title: 'Generative LLM Powered Conversational AI Application For Personalized Risk Assessment: A Case Study In COVID-19'
authors: Mohammad Amin Roshani, Xiangyu Zhou, Yao Qiang, Srinivasan Suresh, Steve Hicks, Usha Sethuraman, Dongxiao Zhu
conference: "Arxiv"
year: 2024
bibkey: roshani2024generative
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2409.15027"}
tags: ['Fine-Tuning', 'Interpretability and Explainability', 'RAG', 'Model Architecture', 'Reinforcement Learning', 'Merging', 'Interpretability', 'Training Techniques', 'Attention Mechanism', 'Pretraining Methods']
---
Large language models (LLMs) have shown remarkable capabilities in various
natural language tasks and are increasingly being applied in healthcare
domains. This work demonstrates a new LLM-powered disease risk assessment
approach via streaming human-AI conversation, eliminating the need for
programming required by traditional machine learning approaches. In a COVID-19
severity risk assessment case study, we fine-tune pre-trained generative LLMs
(e.g., Llama2-7b and Flan-t5-xl) using a few shots of natural language
examples, comparing their performance with traditional classifiers (i.e.,
Logistic Regression, XGBoost, Random Forest) that are trained de novo using
tabular data across various experimental settings. We develop a mobile
application that uses these fine-tuned LLMs as its generative AI (GenAI) core
to facilitate real-time interaction between clinicians and patients, providing
no-code risk assessment through conversational interfaces. This integration not
only allows for the use of streaming Questions and Answers (QA) as inputs but
also offers personalized feature importance analysis derived from the LLM's
attention layers, enhancing the interpretability of risk assessments. By
achieving high Area Under the Curve (AUC) scores with a limited number of
fine-tuning samples, our results demonstrate the potential of generative LLMs
to outperform discriminative classification methods in low-data regimes,
highlighting their real-world adaptability and effectiveness. This work aims to
fill the existing gap in leveraging generative LLMs for interactive no-code
risk assessment and to encourage further research in this emerging field.

---
layout: publication
title: 'Can Large Language Models Effectively Process And Execute Financial Trading Instructions?'
authors: Yu Kang, Ge Wang, Xin Yang, Yuda Wang, Mingwen Liu
conference: "Arxiv"
year: 2024
bibkey: kang2024can
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2412.04856"}
tags: ['Security', 'Tools', 'Reinforcement Learning']
---
The development of Large Language Models (LLMs) has created transformative
opportunities for the financial industry, especially in the area of financial
trading. However, how to integrate LLMs with trading systems has become a
challenge. To address this problem, we propose an intelligent trade order
recognition pipeline that enables the conversion of trade orders into a
standard format in trade execution. The system improves the ability of human
traders to interact with trading platforms while addressing the problem of
misinformation acquisition in trade execution. In addition, we have created a
trade order dataset of 500 pieces of data to simulate real-world trading
scenarios. Moreover, we designed several metrics to provide a comprehensive
assessment of dataset reliability and the generative power of big models in
finance by experimenting with five state-of-the-art LLMs on our dataset. The
results indicate that while LLMs demonstrate high generation rates (87.50% to
98.33%) and perfect follow-up rates, they face significant challenges in
accuracy (5% to 10%) and completeness, with high missing rates (14.29% to
67.29%). In addition, LLMs tend to over-interrogate, suggesting that large
models tend to collect more information, carrying certain challenges for
information security.

---
layout: publication
title: 'Llms And The Madness Of Crowds'
authors: William F. Bradley
conference: "Arxiv"
year: 2024
bibkey: bradley2024llms
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2411.01539"}
tags: ['Reinforcement Learning']
---
We investigate the patterns of incorrect answers produced by large language
models (LLMs) during evaluation. These errors exhibit highly non-intuitive
behaviors unique to each model. By analyzing these patterns, we measure the
similarities between LLMs and construct a taxonomy that categorizes them based
on their error correlations. Our findings reveal that the incorrect responses
are not randomly distributed but systematically correlated across models,
providing new insights into the underlying structures and relationships among
LLMs.

---
layout: publication
title: Transquest At WMT2020&#58; Sentence-level Direct Assessment
authors: Ranasinghe Tharindu, Orasan Constantin, Mitkov Ruslan
conference: "Arxiv"
year: 2020
bibkey: ranasinghe2020transquest
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2010.05318"}
tags: ['Model Architecture', 'Pretraining Methods', 'Tools', 'Transformer']
---
This paper presents the team TransQuests participation in Sentence-Level Direct Assessment shared task in WMT 2020. We introduce a simple QE framework based on cross-lingual transformers and we use it to implement and evaluate two different neural architectures. The proposed methods achieve state-of-the-art results surpassing the results obtained by OpenKiwi the baseline used in the shared task. We further fine tune the QE framework by performing ensemble and data augmentation. Our approach is the winning solution in all of the language pairs according to the WMT 2020 official results.

---
layout: publication
title: Language Repository For Long Video Understanding
authors: Kahatapitiya Kumara, Ranasinghe Kanchana, Park Jongwoo, Ryoo Michael S.
conference: "Arxiv"
year: 2024
bibkey: kahatapitiya2024language
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.14622"}
  - {name: "Code", url: "https://github.com/kkahatapitiya/LangRepo"}
tags: ['Applications', 'Efficiency And Optimization', 'Has Code', 'Pruning', 'Reinforcement Learning', 'Tools']
---
Language has become a prominent modality in computer vision with the rise of multi45;modal LLMs. Despite supporting long context45;lengths their effectiveness in handling long45;term information gradually declines with input length. This becomes critical especially in applications such as long45;form video understanding. In this paper we introduce a Language Repository (LangRepo) for LLMs that maintains concise and structured information as an interpretable (i.e. all45;textual) representation. Our repository is updated iteratively based on multi45;scale video chunks. We introduce write and read operations that focus on pruning redundancies in text and extracting information at various temporal scales. The proposed framework is evaluated on zero45;shot visual question45;answering benchmarks including EgoSchema NExT45;QA IntentQA and NExT45;GQA showing state45;of45;the45;art performance at its scale. Our code is available at https://github.com/kkahatapitiya/LangRepo.

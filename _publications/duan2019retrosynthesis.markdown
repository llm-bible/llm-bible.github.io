---
layout: publication
title: Retrosynthesis With Attention45;based NMT Model And Chemical Analysis Of The wrong Predictions
authors: Duan Hongliang, Wang Ling, Zhang Chengyun, Li Jianjun
conference: "Arxiv"
year: 2019
bibkey: duan2019retrosynthesis
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/1908.00727"}
tags: ['Applications', 'Attention Mechanism', 'Model Architecture', 'Training Techniques']
---
We cast retrosynthesis as a machine translation problem by introducing a special Tensor2Tensor an entire attention45;based and fully data45;driven model. Given a data set comprising about 50000 diverse reactions extracted from USPTO patents the model significantly outperforms seq2seq model (34.737;) on a top45;1 accuracy by achieving 54.137;. For yielding better results parameters such as batch size and training time are thoroughly investigated to train the model. Additionally we offer a novel insight into the causes of grammatically invalid SMILES and conduct a test in which experienced chemists pick out and analyze the wrong predictions that may be chemically plausible but differ from the ground truth. Actually the effectiveness of our model is un45;derestimated and the true top45;1 accuracy can reach to 64.637;.

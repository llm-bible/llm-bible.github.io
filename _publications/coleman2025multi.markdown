---
layout: publication
title: 'Multi-granular Training Strategies For Robust Multi-hop Reasoning Over Noisy And Heterogeneous Knowledge Sources'
authors: Jackson Coleman, Isaiah Lawrence, Benjamin Turner
conference: "Arxiv"
year: 2025
bibkey: coleman2025multi
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.05944"}
tags: ['Tools', 'Efficiency and Optimization', 'Applications', 'RAG', 'Security', 'Training Techniques']
---
Multi-source multi-hop question answering (QA) represents a challenging task
in natural language processing due to the need for dynamic integration of
heterogeneous knowledge sources and multi-step reasoning. Existing methods
often suffer from cascading errors, insufficient handling of knowledge
conflicts, and computational inefficiency. In this paper, we propose Adaptive
Multi-source Knowledge-Oriented Reasoning (AMKOR), a generative framework that
leverages large language models (LLMs) to dynamically fuse parametric and
retrieved knowledge while exploring reasoning trajectories using probabilistic
beam reasoning. AMKOR is further enhanced by a multi-granular learning
strategy, optimizing both local reasoning steps and global answer accuracy.
Experiments conducted on four widely-used multi-hop QA datasets, including
HotpotQA and MuSiQue, demonstrate that AMKOR achieves state-of-the-art
performance, significantly outperforming baseline methods on both reasoning
accuracy and robustness. Additional analyses confirm its scalability,
adaptability to noisy knowledge, and superior ability to handle complex
multi-hop tasks. This work establishes a new benchmark for multi-source
multi-hop QA by effectively combining reasoning quality and efficiency.

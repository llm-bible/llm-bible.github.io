---
layout: publication
title: 'Can Chatgpt Make Explanatory Inferences? Benchmarks For Abductive Reasoning'
authors: Paul Thagard
conference: "Arxiv"
year: 2024
bibkey: thagard2024can
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2404.18982'}
tags: ['GPT', 'Interpretability and Explainability', 'Model Architecture']
---
Explanatory inference is the creation and evaluation of hypotheses that
provide explanations, and is sometimes known as abduction or abductive
inference. Generative AI is a new set of artificial intelligence models based
on novel algorithms for generating text, images, and sounds. This paper
proposes a set of benchmarks for assessing the ability of AI programs to
perform explanatory inference, and uses them to determine the extent to which
ChatGPT, a leading generative AI model, is capable of making explanatory
inferences. Tests on the benchmarks reveal that ChatGPT performs creative and
evaluative inferences in many domains, although it is limited to verbal and
visual modalities. Claims that ChatGPT and similar models are incapable of
explanation, understanding, causal reasoning, meaning, and creativity are
rebutted.

---
layout: publication
title: 'Give Me A Hint: Can Llms Take A Hint To Solve Math Problems?'
authors: Vansh Agrawal, Pratham Singla, Amitoj Singh Miglani, Shivank Garg, Ayush Mangal
conference: "Arxiv"
year: 2024
bibkey: agrawal2024give
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2410.05915'}
tags: ['Few-Shot', 'Prompting', 'Security']
---
While state-of-the-art LLMs have shown poor logical and basic mathematical
reasoning, recent works try to improve their problem-solving abilities using
prompting techniques. We propose giving "hints" to improve the language model's
performance on advanced mathematical problems, taking inspiration from how
humans approach math pedagogically. We also test robustness to adversarial
hints and demonstrate their sensitivity to them. We demonstrate the
effectiveness of our approach by evaluating various diverse LLMs, presenting
them with a broad set of problems of different difficulties and topics from the
MATH dataset and comparing against techniques such as one-shot, few-shot, and
chain of thought prompting.

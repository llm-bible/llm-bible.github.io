---
layout: publication
title: 'Arabic Automatic Story Generation With Large Language Models'
authors: Ahmed Oumar El-shangiti, Fakhraddin Alwajih, Muhammad Abdul-mageed
conference: "Arxiv"
year: 2024
bibkey: elshangiti2024arabic
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.07551"}
tags: ['Training Techniques', 'Model Architecture', 'GPT', 'Prompting', 'Applications']
---
Large language models (LLMs) have recently emerged as a powerful tool for a
wide range of language generation tasks. Nevertheless, this progress has been
slower in Arabic. In this work, we focus on the task of generating stories from
LLMs. For our training, we use stories acquired through machine translation
(MT) as well as GPT-4. For the MT data, we develop a careful pipeline that
ensures we acquire high-quality stories. For our GPT-41 data, we introduce
crafted prompts that allow us to generate data well-suited to the Arabic
context in both Modern Standard Arabic (MSA) and two Arabic dialects (Egyptian
and Moroccan). For example, we generate stories tailored to various Arab
countries on a wide host of topics. Our manual evaluation shows that our model
fine-tuned on these training datasets can generate coherent stories that adhere
to our instructions. We also conduct an extensive automatic and human
evaluation comparing our models against state-of-the-art proprietary and
open-source models. Our datasets and models will be made publicly available at
https: //github.com/UBC-NLP/arastories.

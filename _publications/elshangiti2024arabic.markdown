---
layout: publication
title: Arabic Automatic Story Generation With Large Language Models
authors: El-shangiti Ahmed Oumar, Alwajih Fakhraddin, Abdul-mageed Muhammad
conference: "Arxiv"
year: 2024
bibkey: elshangiti2024arabic
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.07551"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Prompting', 'Training Techniques']
---
Large language models (LLMs) have recently emerged as a powerful tool for a wide range of language generation tasks. Nevertheless this progress has been slower in Arabic. In this work we focus on the task of generating stories from LLMs. For our training we use stories acquired through machine translation (MT) as well as GPT45;4. For the MT data we develop a careful pipeline that ensures we acquire high45;quality stories. For our GPT45;41 data we introduce crafted prompts that allow us to generate data well45;suited to the Arabic context in both Modern Standard Arabic (MSA) and two Arabic dialects (Egyptian and Moroccan). For example we generate stories tailored to various Arab countries on a wide host of topics. Our manual evaluation shows that our model fine45;tuned on these training datasets can generate coherent stories that adhere to our instructions. We also conduct an extensive automatic and human evaluation comparing our models against state45;of45;the45;art proprietary and open45;source models. Our datasets and models will be made publicly available at https github.com/UBC45;NLP/arastories.

---
layout: publication
title: In45;context Learning Agents Are Asymmetric Belief Updaters
authors: Schubert Johannes A., Jagadish Akshay K., Binz Marcel, Schulz Eric
conference: "Arxiv"
year: 2024
bibkey: schubert2024learning
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.03969"}
tags: ['Agentic', 'Reinforcement Learning']
---
We study the in45;context learning dynamics of large language models (LLMs) using three instrumental learning tasks adapted from cognitive psychology. We find that LLMs update their beliefs in an asymmetric manner and learn more from better45;than45;expected outcomes than from worse45;than45;expected ones. Furthermore we show that this effect reverses when learning about counterfactual feedback and disappears when no agency is implied. We corroborate these findings by investigating idealized in45;context learning agents derived through meta45;reinforcement learning where we observe similar patterns. Taken together our results contribute to our understanding of how in45;context learning works by highlighting that the framing of a problem significantly influences how learning occurs a phenomenon also observed in human cognition.

---
layout: publication
title: 'Enhancing Long-term Memory Using Hierarchical Aggregate Tree For Retrieval Augmented Generation'
authors: Aadharsh Aadhithya A, Sachin Kumar S, Soman K. P
conference: "Arxiv"
year: 2024
bibkey: a2024enhancing
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2406.06124'}
tags: ['RAG']
---
Large language models have limited context capacity, hindering reasoning over
long conversations. We propose the Hierarchical Aggregate Tree memory structure
to recursively aggregate relevant dialogue context through conditional tree
traversals. HAT encapsulates information from children nodes, enabling broad
coverage with depth control. We formulate finding best context as optimal tree
traversal. Experiments show HAT improves dialog coherence and summary quality
over baseline contexts, demonstrating the techniques effectiveness for multi
turn reasoning without exponential parameter growth. This memory augmentation
enables more consistent, grounded longform conversations from LLMs

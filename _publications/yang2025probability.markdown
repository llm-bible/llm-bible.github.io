---
layout: publication
title: 'Probability-consistent Preference Optimization For Enhanced LLM Reasoning'
authors: Yunqiao Yang, Houxing Ren, Zimu Lu, Ke Wang, Weikang Shi, Aojun Zhou, Junting Pan, Mingjie Zhan, Hongsheng Li
conference: "Arxiv"
year: 2025
bibkey: yang2025probability
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2505.23540"}
  - {name: "Code", url: "https://github.com/YunqiaoYang/PCPO"}
tags: ['RAG', 'Efficiency and Optimization', 'Has Code', 'Tools']
---
Recent advances in preference optimization have demonstrated significant potential for improving mathematical reasoning capabilities in large language models (LLMs). While current approaches leverage high-quality pairwise preference data through outcome-based criteria like answer correctness or consistency, they fundamentally neglect the internal logical coherence of responses. To overcome this, we propose Probability-Consistent Preference Optimization (PCPO), a novel framework that establishes dual quantitative metrics for preference selection: (1) surface-level answer correctness and (2) intrinsic token-level probability consistency across responses. Extensive experiments show that our PCPO consistently outperforms existing outcome-only criterion approaches across a diverse range of LLMs and benchmarks. Our code is publicly available at https://github.com/YunqiaoYang/PCPO.

---
layout: publication
title: Write And Paint Generative Vision45;language Models Are Unified Modal Learners
authors: Diao Shizhe, Zhou Wangchunshu, Zhang Xinsong, Wang Jiawei
conference: "Arxiv"
year: 2022
bibkey: diao2022write
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2206.07699"}
  - {name: "Code", url: "https://github.com/shizhediao/DaVinci"}
tags: ['Applications', 'Has Code', 'Language Modeling', 'RAG', 'Tools', 'Training Techniques']
---
Recent advances in vision45;language pre45;training have pushed the state45;of45;the45;art on various vision45;language tasks making machines more capable of multi45;modal writing (image45;to45;text generation) and painting (text45;to45;image generation). However few studies investigate if these two essential capabilities can be learned together and boost each other making a versatile and powerful multi45;modal foundation model. In this work we disclose the potential of symmetric generative vision45;language pre45;training in learning to write and paint concurrently and propose a new unified modal model named DaVinci trained with prefix language modeling and prefix image modeling a simple generative self45;supervised objective on image45;text pairs. Thanks to the proposed prefix multi45;modal modeling framework DaVinci is simple to train scalable to huge data adaptable to both writing and painting tasks and also strong on other vision text and multi45;modal understanding tasks. DaVinci achieves competitive performance on a wide range of 27 generation/understanding tasks and demonstrates the superiority of combining vision/language generative pre45;training. Furthermore we carefully benchmark the performance of different vision45;language pre45;training objectives on different scales of pre45;training datasets on a heterogeneous and broad distribution coverage. Our results demonstrate the potential of exploiting self45;supervision in both language and vision inputs and establish new stronger baselines for future comparisons at different data scales. The code and pre45;trained models are available at https://github.com/shizhediao/DaVinci.

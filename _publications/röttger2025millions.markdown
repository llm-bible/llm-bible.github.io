---
layout: publication
title: 'Issuebench: Millions Of Realistic Prompts For Measuring Issue Bias In LLM Writing Assistance'
authors: Paul Röttger, Musashi Hinck, Valentin Hofmann, Kobi Hackenburg, Valentina Pyatkin, Faeze Brahman, Dirk Hovy
conference: "Arxiv"
year: 2025
bibkey: röttger2025millions
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2502.08395'}
tags: ['Ethics and Bias', 'Prompting']
---
Large language models (LLMs) are helping millions of users write texts about
diverse issues, and in doing so expose users to different ideas and
perspectives. This creates concerns about issue bias, where an LLM tends to
present just one perspective on a given issue, which in turn may influence how
users think about this issue. So far, it has not been possible to measure which
issue biases LLMs actually manifest in real user interactions, making it
difficult to address the risks from biased LLMs. Therefore, we create
IssueBench: a set of 2.49m realistic prompts for measuring issue bias in LLM
writing assistance, which we construct based on 3.9k templates (e.g. "write a
blog about") and 212 political issues (e.g. "AI regulation") from real user
interactions. Using IssueBench, we show that issue biases are common and
persistent in state-of-the-art LLMs. We also show that biases are remarkably
similar across models, and that all models align more with US Democrat than
Republican voter opinion on a subset of issues. IssueBench can easily be
adapted to include other issues, templates, or tasks. By enabling robust and
realistic measurement, we hope that IssueBench can bring a new quality of
evidence to ongoing discussions about LLM biases and how to address them.

---
layout: publication
title: Evaluating Spatial Understanding Of Large Language Models
authors: Yamada Yutaro, Bao Yihan, Lampinen Andrew K., Kasai Jungo, Yildirim Ilker
conference: "Arxiv"
year: 2023
bibkey: yamada2023evaluating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.14540"}
tags: ['GPT', 'Model Architecture', 'Pretraining Methods', 'Reinforcement Learning', 'Training Techniques']
---
Large language models (LLMs) show remarkable capabilities across a variety of tasks. Despite the models only seeing text in training several recent studies suggest that LLM representations implicitly capture aspects of the underlying grounded concepts. Here we explore LLM representations of a particularly salient kind of grounded knowledge 45;45; spatial relationships. We design natural45;language navigation tasks and evaluate the ability of LLMs in particular GPT45;3.545;turbo GPT45;4 and Llama2 series models to represent and reason about spatial structures. These tasks reveal substantial variability in LLM performance across different spatial structures including square hexagonal and triangular grids rings and trees. In extensive error analysis we find that LLMs mistakes reflect both spatial and non45;spatial factors. These findings suggest that LLMs appear to capture certain aspects of spatial structure implicitly but room for improvement remains.

---
layout: publication
title: 'AILS-NTUA At Semeval-2025 Task 8: Language-to-code Prompting And Error Fixing For Tabular Question Answering'
authors: Andreas Evangelatos, Giorgos Filandrianos, Maria Lymperaiou, Athanasios Voulodimos, Giorgos Stamou
conference: "Arxiv"
year: 2025
bibkey: evangelatos2025ails
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2503.00435"}
tags: ['Prompting', 'Applications', 'Interpretability and Explainability']
---
In this paper, we present our submission to SemEval-2025 Task 8: Question
Answering over Tabular Data. This task, evaluated on the DataBench dataset,
assesses Large Language Models' (LLMs) ability to answer natural language
questions over structured data while addressing topic diversity and table size
limitations in previous benchmarks. We propose a system that employs effective
LLM prompting to translate natural language queries into executable code,
enabling accurate responses, error correction, and interpretability. Our
approach ranks first in both subtasks of the competition in the proprietary
model category, significantly outperforming the organizer's baseline.

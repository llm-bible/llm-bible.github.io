---
layout: publication
title: 'On Synthesizing Data For Context Attribution In Question Answering'
authors: Gorjan Radevski, Kiril Gashteovski, Shahbaz Syed, Christopher Malon, Sebastien Nicolas, Chia-chien Hung, Timo Sztyler, Verena Heußer, Wiem Ben Rim, Masafumi Enomoto, Kunihiro Takeoka, Masafumi Oyamada, Goran Glavaš, Carolin Lawrence
conference: "Arxiv"
year: 2025
bibkey: radevski2025synthesizing
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2504.05317'}
tags: ['Language Modeling', 'RAG', 'Training Techniques', 'Applications', 'Fine-Tuning', 'Reinforcement Learning', 'Pretraining Methods']
---
Question Answering (QA) accounts for a significant portion of LLM usage "in
the wild". However, LLMs sometimes produce false or misleading responses, also
known as "hallucinations". Therefore, grounding the generated answers in
contextually provided information -- i.e., providing evidence for the generated
text -- is paramount for LLMs' trustworthiness. Providing this information is
the task of context attribution. In this paper, we systematically study
LLM-based approaches for this task, namely we investigate (i) zero-shot
inference, (ii) LLM ensembling, and (iii) fine-tuning of small LMs on synthetic
data generated by larger LLMs. Our key contribution is SynQA: a novel
generative strategy for synthesizing context attribution data. Given selected
context sentences, an LLM generates QA pairs that are supported by these
sentences. This leverages LLMs' natural strengths in text generation while
ensuring clear attribution paths in the synthetic training data. We show that
the attribution data synthesized via SynQA is highly effective for fine-tuning
small LMs for context attribution in different QA tasks and domains. Finally,
with a user study, we validate the usefulness of small LMs (fine-tuned on
synthetic data from SynQA) in context attribution for QA.

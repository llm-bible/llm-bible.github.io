---
layout: publication
title: What GPT Knows About Who Is Who
authors: Yang Xiaohan, Peynetti Eduardo, Meerman Vasco, Tanner Chris
conference: "Arxiv"
year: 2022
bibkey: yang2022what
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2205.07407"}
tags: ['GPT', 'Model Architecture', 'Prompting']
---
Coreference resolution 45;45; which is a crucial task for understanding discourse and language at large 45;45; has yet to witness widespread benefits from large language models (LLMs). Moreover coreference resolution systems largely rely on supervised labels which are highly expensive and difficult to annotate thus making it ripe for prompt engineering. In this paper we introduce a QA45;based prompt45;engineering method and discern textit123;generative125; pre45;trained LLMs abilities and limitations toward the task of coreference resolution. Our experiments show that GPT45;2 and GPT45;Neo can return valid answers but that their capabilities to identify coreferent mentions are limited and prompt45;sensitive leading to inconsistent results.

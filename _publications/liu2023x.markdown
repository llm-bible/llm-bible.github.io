---
layout: publication
title: X45;eval Generalizable Multi45;aspect Text Evaluation Via Augmented Instruction Tuning With Auxiliary Evaluation Aspects
authors: Liu Minqian, Shen Ying, Xu Zhiyang, Cao Yixin, Cho Eunah, Kumar Vaibhav, Ghanadan Reza, Huang Lifu
conference: "Arxiv"
year: 2023
bibkey: liu2023x
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2311.08788"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Reinforcement Learning', 'Tools', 'Training Techniques']
---
Natural Language Generation (NLG) typically involves evaluating the generated text in various aspects (e.g. consistency and naturalness) to obtain a comprehensive assessment. However multi45;aspect evaluation remains challenging as it may require the evaluator to generalize to any given evaluation aspect even if its absent during training. In this paper we introduce X45;Eval a two45;stage instruction tuning framework to evaluate the text in both seen and unseen aspects customized by end users. X45;Eval consists of two learning stages the vanilla instruction tuning stage that improves the models ability to follow evaluation instructions and an enhanced instruction tuning stage that exploits the connections between fine45;grained evaluation aspects to better assess text quality. To support the training of X45;Eval we collect AspectInstruct the first instruction tuning dataset tailored for multi45;aspect NLG evaluation spanning 27 diverse evaluation aspects with 65 tasks. To enhance task diversity we devise an augmentation strategy that converts human rating annotations into diverse forms of NLG evaluation tasks including scoring comparison ranking and Boolean question answering. Extensive experiments across three essential categories of NLG tasks dialogue generation summarization and data45;to45;text coupled with 21 aspects in meta45;evaluation demonstrate that our X45;Eval enables even a lightweight language model to achieve a comparable if not higher correlation with human judgments compared to the state45;of45;the45;art NLG evaluators such as GPT45;4.

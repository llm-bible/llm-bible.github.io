---
layout: publication
title: 'Fine-tuning Large Language Models For Improving Factuality In Legal Question Answering'
authors: Yinghao Hu, Leilei Gan, Wenyi Xiao, Kun Kuang, Fei Wu
conference: "Arxiv"
year: 2025
bibkey: hu2025fine
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2501.06521'}
tags: ['Efficiency and Optimization', 'Training Techniques', 'BERT', 'Model Architecture', 'Fine-Tuning', 'Applications', 'Reinforcement Learning', 'Pretraining Methods']
---
Hallucination, or the generation of incorrect or fabricated information,
remains a critical challenge in large language models (LLMs), particularly in
high-stake domains such as legal question answering (QA). In order to mitigate
the hallucination rate in legal QA, we first introduce a benchmark called
LegalHalBench and three automatic metrics to evaluate the common hallucinations
when LLMs answer legal questions. We then propose a hallucination mitigation
method that integrates behavior cloning and a novel Hard Sample-aware Iterative
Direct Preference Optimization (HIPO). We conduct extensive real-data
experiments to validate the effectiveness of our approach. Our results
demonstrate remarkable improvements in various metrics, including the newly
proposed Non-Hallucinated Statute Rate, Statute Relevance Rate, Legal Claim
Truthfulness, as well as traditional metrics such as METEOR, BERTScore,
ROUGE-L, and win rates.

---
layout: publication
title: Trustworthy LLMs a Survey and Guideline for Evaluating Large Language Models Alignment
authors: Liu Yang, Yao Yuanshun, Ton Jean-francois, Zhang Xiaoying, Guo Ruocheng, Cheng Hao, Klochkov Yegor, Taufiq Muhammad Faaiz, Li Hang
conference: "Arxiv"
year: 2023
bibkey: liu2023trustworthy
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2308.05374"}
tags: ['ARXIV', 'Applications', 'Ethics And Bias', 'GPT', 'Interpretability', 'Interpretability And Explainability', 'LLM', 'Reinforcement Learning', 'Responsible AI', 'Security', 'Survey Paper']
---
Ensuring alignment which refers to making models behave in accordance with human intentions 12 has become a critical task before deploying large language models (LLMs) in real-world applications. For instance OpenAI devoted six months to iteratively aligning GPT-4 before its release 3. However a major challenge faced by practitioners is the lack of clear guidance on evaluating whether LLM outputs align with social norms values and regulations. This obstacle hinders systematic iteration and deployment of LLMs. To address this issue this paper presents a comprehensive survey of key dimensions that are crucial to consider when assessing LLM trustworthiness. The survey covers seven major categories of LLM trustworthiness reliability safety fairness resistance to misuse explainability and reasoning adherence to social norms and robustness. Each major category is further divided into several sub-categories resulting in a total of 29 sub-categories. Additionally a subset of 8 sub-categories is selected for further investigation where corresponding measurement studies are designed and conducted on several widely-used LLMs. The measurement results indicate that in general more aligned models tend to perform better in terms of overall trustworthiness. However the effectiveness of alignment varies across the different trustworthiness categories considered. This highlights the importance of conducting more fine-grained analyses testing and making continuous improvements on LLM alignment. By shedding light on these key dimensions of LLM trustworthiness this paper aims to provide valuable insights and guidance to practitioners in the field. Understanding and addressing these concerns will be crucial in achieving reliable and ethically sound deployment of LLMs in various applications.

---
layout: publication
title: 'Internlm-xcomposer: A Vision-language Large Model For Advanced Text-image
  Comprehension And Composition'
authors: Pan Zhang et al.
conference: Arxiv
year: 2023
citations: 21
bibkey: zhang2023internlm
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2309.15112'}, {name: Code,
    url: 'https://github.com/InternLM/InternLM-XComposer'}]
tags: [Multimodal Models, GPT]
---
We propose InternLM-XComposer, a vision-language large model that enables
advanced image-text comprehension and composition. The innovative nature of our
model is highlighted by three appealing properties: 1) Interleaved Text-Image
Composition: InternLM-XComposer can effortlessly generate coherent and
contextual articles that seamlessly integrate images, providing a more engaging
and immersive reading experience. Simply provide a writing instruction, and our
system will generate the corresponding manuscript. It can intelligently
identify the areas in the text where images would enhance the content and
automatically insert the most appropriate visual candidates. 2) Comprehension
with Rich Multilingual Knowledge: The text-image comprehension is empowered by
training on an extensive multi-modal multilingual database with carefully
crafted strategies, resulting in a deep understanding of visual content. 3)
State-of-the-art Performance: Our model consistently achieves state-of-the-art
results across various mainstream benchmarks for vision-language foundational
models, including MME Benchmark, MMBench, MMBench-CN, Seed-Bench, CCBench
(Chinese Cultural Benchmark), QBench and Tiny LVLM. Owing to the absence of
established metrics for quantitatively assessing text-image composition, we
have devised a robust evaluation procedure that comprises both human and
GPT4-Vision (GPT4-V) to ensure reliability. Notably, our InternLM-XComposer
achieves competitive text-image composition scores compared to public
solutions, including GPT4-V and GPT3.5. Collectively, InternLM-XComposer
seamlessly blends advanced text-image comprehension and composition,
revolutionizing vision-language interaction and offering new insights and
opportunities. The InternLM-XComposer model series are publicly available at
https://github.com/InternLM/InternLM-XComposer.
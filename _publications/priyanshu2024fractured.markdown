---
layout: publication
title: Fractured45;sorry45;bench Framework For Revealing Attacks In Conversational Turns Undermining Refusal Efficacy And Defenses Over Sorry45;bench
authors: Priyanshu Aman, Vijay Supriti
conference: "Arxiv"
year: 2024
bibkey: priyanshu2024fractured
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.16163"}
tags: ['GPT', 'Model Architecture', 'Pretraining Methods', 'Prompting', 'Responsible AI', 'Security', 'Tools']
---
This paper introduces FRACTURED45;SORRY45;Bench a framework for evaluating the safety of Large Language Models (LLMs) against multi45;turn conversational attacks. Building upon the SORRY45;Bench dataset we propose a simple yet effective method for generating adversarial prompts by breaking down harmful queries into seemingly innocuous sub45;questions. Our approach achieves a maximum increase of +46.2237; in Attack Success Rates (ASRs) across GPT45;4 GPT45;4o GPT45;4o45;mini and GPT45;3.545;Turbo models compared to baseline methods. We demonstrate that this technique poses a challenge to current LLM safety measures and highlights the need for more robust defenses against subtle multi45;turn attacks.

---
layout: publication
title: Coevol Constructing Better Responses For Instruction Finetuning Through Multi45;agent Cooperation
authors: Li Renhao, Tan Minghuan, Wong Derek F., Yang Min
conference: "Arxiv"
year: 2024
bibkey: li2024constructing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.07054"}
tags: ['Agentic', 'Attention Mechanism', 'Model Architecture', 'Pretraining Methods', 'RAG', 'Tools']
---
In recent years instruction fine45;tuning (IFT) on large language models (LLMs) has garnered considerable attention to enhance model performance on unseen tasks. Attempts have been made on automatic construction and effective selection for IFT data. However we posit that previous methods have not fully harnessed the potential of LLMs for enhancing data quality. The responses within IFT data could be further enhanced by leveraging the capabilities of LLMs themselves. In this paper we propose CoEvol an LLM45;based multi45;agent cooperation framework for the improvement of responses to instructions. To effectively refine the responses we develop an iterative framework following a debate45;advise45;edit45;judge paradigm. A two45;stage multi45;agent debate strategy is further devised to ensure the diversity and reliability of editing suggestions within the framework. Empirically models equipped with CoEvol outperform competitive baselines evaluated by MT45;Bench and AlpacaEval demonstrating its effectiveness in enhancing instruction45;following capabilities for LLMs.

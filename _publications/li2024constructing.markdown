---
layout: publication
title: 'Coevol: Constructing Better Responses For Instruction Finetuning Through Multi-agent Cooperation'
authors: Renhao Li, Minghuan Tan, Derek F. Wong, Min Yang
conference: "Arxiv"
year: 2024
bibkey: li2024constructing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.07054"}
tags: ['Agentic', 'Training Techniques', 'Model Architecture', 'Tools', 'RAG', 'Pretraining Methods', 'Fine-Tuning', 'Attention Mechanism']
---
In recent years, instruction fine-tuning (IFT) on large language models
(LLMs) has garnered considerable attention to enhance model performance on
unseen tasks. Attempts have been made on automatic construction and effective
selection for IFT data. However, we posit that previous methods have not fully
harnessed the potential of LLMs for enhancing data quality. The responses
within IFT data could be further enhanced by leveraging the capabilities of
LLMs themselves. In this paper, we propose CoEvol, an LLM-based multi-agent
cooperation framework for the improvement of responses to instructions. To
effectively refine the responses, we develop an iterative framework following a
debate-advise-edit-judge paradigm. A two-stage multi-agent debate strategy is
further devised to ensure the diversity and reliability of editing suggestions
within the framework. Empirically, models equipped with CoEvol outperform
competitive baselines evaluated by MT-Bench and AlpacaEval, demonstrating its
effectiveness in enhancing instruction-following capabilities for LLMs.

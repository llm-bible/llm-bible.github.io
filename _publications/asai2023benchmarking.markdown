---
layout: publication
title: BUFFET Benchmarking Large Language Models For Few45;shot Cross45;lingual Transfer
authors: Asai Akari, Kudugunta Sneha, Yu Xinyan Velocity, Blevins Terra, Gonen Hila, Reid Machel, Tsvetkov Yulia, Ruder Sebastian, Hajishirzi Hannaneh
conference: "Arxiv"
year: 2023
bibkey: asai2023benchmarking
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2305.14857"}
tags: ['GPT', 'Model Architecture', 'Pretraining Methods', 'Tools', 'Training Techniques']
---
Despite remarkable advancements in few45;shot generalization in natural language processing most models are developed and evaluated primarily in English. To facilitate research on few45;shot cross45;lingual transfer we introduce a new benchmark called BUFFET which unifies 15 diverse tasks across 54 languages in a sequence45;to45;sequence format and provides a fixed set of few45;shot examples and instructions. BUFFET is designed to establish a rigorous and equitable evaluation framework for few45;shot cross45;lingual transfer across a broad range of tasks and languages. Using BUFFET we perform thorough evaluations of state45;of45;the45;art multilingual large language models with different transfer methods namely in45;context learning and fine45;tuning. Our findings reveal significant room for improvement in few45;shot in45;context cross45;lingual transfer. In particular ChatGPT with in45;context learning often performs worse than much smaller mT545;base models fine45;tuned on English task data and few45;shot in45;language examples. Our analysis suggests various avenues for future research in few45;shot cross45;lingual transfer such as improved pretraining understanding and future evaluations.

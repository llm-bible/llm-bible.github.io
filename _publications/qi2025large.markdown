---
layout: publication
title: 'Large Language Models Meet Symbolic Provers For Logical Reasoning Evaluation'
authors: Chengwen Qi, Ren Ma, Bowen Li, He Du, Binyuan Hui, Jinwang Wu, Yuanjun Laili, Conghui He
conference: "Arxiv"
year: 2025
bibkey: qi2025large
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.06563"}
  - {name: "Code", url: "https://github.com/opendatalab/ProverGen"}
tags: ['Training Techniques', 'Tools', 'Reinforcement Learning', 'Has Code', 'Prompting']
---
First-order logic (FOL) reasoning, which involves sequential deduction, is
pivotal for intelligent systems and serves as a valuable task for evaluating
reasoning capabilities, particularly in chain-of-thought (CoT) contexts.
Existing benchmarks often rely on extensive human annotation or handcrafted
templates, making it difficult to achieve the necessary complexity,
scalability, and diversity for robust evaluation. To address these limitations,
we propose a novel framework called ProverGen that synergizes the generative
strengths of Large Language Models (LLMs) with the rigor and precision of
symbolic provers, enabling the creation of a scalable, diverse, and
high-quality FOL reasoning dataset, ProverQA. ProverQA is also distinguished by
its inclusion of accessible and logically coherent intermediate reasoning steps
for each problem. Our evaluation shows that state-of-the-art LLMs struggle to
solve ProverQA problems, even with CoT prompting, highlighting the dataset's
challenging nature. We also finetune Llama3.1-8B-Instruct on a separate
training set generated by our framework. The finetuned model demonstrates
consistent improvements on both in-distribution and out-of-distribution test
sets, suggesting the value of our proposed data generation framework. Code
available at: https://github.com/opendatalab/ProverGen

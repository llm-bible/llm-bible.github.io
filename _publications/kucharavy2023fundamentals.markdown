---
layout: publication
title: 'Fundamentals Of Generative Large Language Models And Perspectives In Cyber-defense'
authors: Andrei Kucharavy, Zachary Schillaci, Loïc Maréchal, Maxime Würsch, Ljiljana Dolamic, Remi Sabonnadiere, Dimitri Percia David, Alain Mermoud, Vincent Lenders
conference: "Arxiv"
year: 2023
bibkey: kucharavy2023fundamentals
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2303.12132"}
tags: ['Fine-Tuning', 'GPT', 'Survey Paper', 'Applications', 'Model Architecture', 'Reinforcement Learning', 'Training Techniques', 'Attention Mechanism', 'Pretraining Methods']
---
Generative Language Models gained significant attention in late 2022 / early
2023, notably with the introduction of models refined to act consistently with
users' expectations of interactions with AI (conversational models). Arguably
the focal point of public attention has been such a refinement of the GPT3
model -- the ChatGPT and its subsequent integration with auxiliary
capabilities, including search as part of Microsoft Bing. Despite extensive
prior research invested in their development, their performance and
applicability to a range of daily tasks remained unclear and niche. However,
their wider utilization without a requirement for technical expertise, made in
large part possible through conversational fine-tuning, revealed the extent of
their true capabilities in a real-world environment. This has garnered both
public excitement for their potential applications and concerns about their
capabilities and potential malicious uses. This review aims to provide a brief
overview of the history, state of the art, and implications of Generative
Language Models in terms of their principles, abilities, limitations, and
future prospects -- especially in the context of cyber-defense, with a focus on
the Swiss operational environment.

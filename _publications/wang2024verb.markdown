---
layout: publication
title: 'Verb Mirage: Unveiling And Assessing Verb Concept Hallucinations In Multimodal Large Language Models'
authors: Zehao Wang, Xinpeng Liu, Xiaoqian Wu, Yudonglin Zhang, Zhou Fang, Yifan Fang, Junfu Pu, Cewu Lu, Yong-lu Li
conference: "Arxiv"
year: 2024
bibkey: wang2024verb
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2412.04939"}
tags: ['Multimodal Models', 'Model Architecture', 'Reinforcement Learning', 'RAG', 'Attention Mechanism']
---
Multimodal Large Language Models (MLLMs) have garnered significant attention
recently and demonstrate outstanding capabilities in various tasks such as OCR,
VQA, captioning, \\(\textit\{etc\}\\). However, hallucination remains a persistent
issue. While numerous methods have been proposed to mitigate hallucinations,
achieving notable improvements, these methods primarily focus on mitigating
hallucinations about \\(\textbf\{object/noun-related\}\\) concepts. Verb concepts,
crucial for understanding human actions, have been largely overlooked. In this
paper, to the best of our knowledge, we are the \\(\textbf\{first\}\\) to investigate
the \\(\textbf\{verb hallucination\}\\) phenomenon of MLLMs from various
perspectives. Our findings reveal that most state-of-the-art MLLMs suffer from
severe verb hallucination. To assess the effectiveness of existing mitigation
methods for object concept hallucination on verb hallucination, we evaluated
these methods and found that they do not effectively address verb
hallucination. To address this issue, we propose a novel rich verb
knowledge-based tuning method to mitigate verb hallucination. The experiment
results demonstrate that our method significantly reduces hallucinations
related to verbs. \\(\textit\{Our code and data will be made publicly available\}\\).

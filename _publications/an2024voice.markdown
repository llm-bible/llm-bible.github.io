---
layout: publication
title: Funaudiollm Voice Understanding And Generation Foundation Models For Natural Interaction Between Humans And Llms
authors: An Keyu, Chen Qian, Deng Chong, Du Zhihao, Gao Changfeng, Gao Zhifu, Gu Yue, He Ting, Hu Hangrui, Hu Kai, Ji Shengpeng, Li Yabin, Li Zerui, Lu Heng, Luo Haoneng, Lv Xiang, Ma Bin, Ma Ziyang, Ni Chongjia, Song Changhe, Shi Jiaqi, Shi Xian, Wang Hao, Wang Wen, Wang Yuxuan, Xiao Zhangyu, Yan Zhijie, Yang Yexin, Zhang Bin, Zhang Qinglin, Zhang Shiliang, Zhao Nan, Zheng Siqi
conference: "Arxiv"
year: 2024
bibkey: an2024voice
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.04051"}
  - {name: "Code", url: "https://fun&#45;audio&#45;llm.github.io,"}
  - {name: "Code", url: "https://github.com/FunAudioLLM"}
tags: ['Applications', 'Has Code', 'Reinforcement Learning', 'Training Techniques']
---
This report introduces FunAudioLLM a model family designed to enhance natural voice interactions between humans and large language models (LLMs). At its core are two innovative models SenseVoice which handles multilingual speech recognition emotion recognition and audio event detection; and CosyVoice which facilitates natural speech generation with control over multiple languages timbre speaking style and speaker identity. SenseVoice45;Small delivers exceptionally low45;latency ASR for 5 languages and SenseVoice45;Large supports high45;precision ASR for over 50 languages while CosyVoice excels in multi45;lingual voice generation zero45;shot in45;context learning cross45;lingual voice cloning and instruction45;following capabilities. The models related to SenseVoice and CosyVoice have been open45;sourced on Modelscope and Huggingface along with the corresponding training inference and fine45;tuning codes released on GitHub. By integrating these models with LLMs FunAudioLLM enables applications such as speech45;to45;speech translation emotional voice chat interactive podcasts and expressive audiobook narration thereby pushing the boundaries of voice interaction technology. Demos are available at https://fun&#45;audio&#45;llm.github.io, and the code can be accessed at https://github.com/FunAudioLLM.

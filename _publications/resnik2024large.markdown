---
layout: publication
title: 'Large Language Models Are Biased Because They Are Large Language Models'
authors: Resnik Philip
conference: "Arxiv"
year: 2024
bibkey: resnik2024large
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.13138"}
tags: ['Ethics And Bias', 'Reinforcement Learning']
---
This paper's primary goal is to provoke thoughtful discussion about the
relationship between bias and fundamental properties of large language models.
We do this by seeking to convince the reader that harmful biases are an
inevitable consequence arising from the design of any large language model as
LLMs are currently formulated. To the extent that this is true, it suggests
that the problem of harmful bias cannot be properly addressed without a serious
reconsideration of AI driven by LLMs, going back to the foundational
assumptions underlying their design.

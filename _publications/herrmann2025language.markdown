---
layout: publication
title: 'Language-agnostic, Automated Assessment Of Listeners'' Speech Recall Using Large Language Models'
authors: Bj√∂rn Herrmann
conference: "Arxiv"
year: 2025
bibkey: herrmann2025language
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2503.01045"}
tags: ['RAG', 'Prompting', 'Reinforcement Learning']
---
Speech-comprehension difficulties are common among older people. Standard
speech tests do not fully capture such difficulties because the tests poorly
resemble the context-rich, story-like nature of ongoing conversation and are
typically available only in a country's dominant/official language (e.g.,
English), leading to inaccurate scores for native speakers of other languages.
Assessments for naturalistic, story speech in multiple languages require
accurate, time-efficient scoring. The current research leverages modern large
language models (LLMs) in native English speakers and native speakers of 10
other languages to automate the generation of high-quality, spoken stories and
scoring of speech recall in different languages. Participants listened to and
freely recalled short stories (in quiet/clear and in babble noise) in their
native language. LLM text-embeddings and LLM prompt engineering with semantic
similarity analyses to score speech recall revealed sensitivity to known
effects of temporal order, primacy/recency, and background noise, and high
similarity of recall scores across languages. The work overcomes limitations
associated with simple speech materials and testing of closed native-speaker
groups because recall data of varying length and details can be mapped across
languages with high accuracy. The full automation of speech generation and
recall scoring provides an important step towards comprehension assessments of
naturalistic speech with clinical applicability.

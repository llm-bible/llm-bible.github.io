---
layout: publication
title: Self45;agreement A Framework For Fine45;tuning Language Models To Find Agreement Among Diverse Opinions
authors: Ding Shiyao, Ito Takayuki
conference: "Arxiv"
year: 2023
bibkey: ding2023self
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2305.11460"}
tags: ['Agentic', 'BERT', 'GPT', 'Model Architecture', 'Pretraining Methods', 'Tools', 'Transformer']
---
Finding an agreement among diverse opinions is a challenging topic in multiagent systems. Recently large language models (LLMs) have shown great potential in addressing this challenge due to their remarkable capabilities in comprehending human opinions and generating human45;like text. However they typically rely on extensive human45;annotated data. In this paper we propose Self45;Agreement a novel framework for fine45;tuning LLMs to autonomously find agreement using data generated by LLM itself. Specifically our approach employs the generative pre45;trained transformer45;3 (GPT45;3) to generate multiple opinions for each question in a question dataset and create several agreement candidates among these opinions. Then a bidirectional encoder representations from transformers (BERT)45;based model evaluates the agreement score of each agreement candidate and selects the one with the highest agreement score. This process yields a dataset of question45;opinion45;agreements which we use to fine45;tune a pre45;trained LLM for discovering agreements among diverse opinions. Remarkably a pre45;trained LLM fine45;tuned by our Self45;Agreement framework achieves comparable performance to GPT45;3 with only 1/25 of its parameters showcasing its ability to identify agreement among various opinions without the need for human45;annotated data.

---
layout: publication
title: 'Interactively Providing Explanations For Transformer Language Models'
authors: Felix Friedrich, Patrick Schramowski, Christopher Tauchmann, Kristian Kersting
conference: "Arxiv"
year: 2021
bibkey: friedrich2021interactively
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2110.02058"}
tags: ['Transformer', 'Interpretability and Explainability', 'Model Architecture', 'Interpretability', 'Pretraining Methods']
---
Transformer language models are state of the art in a multitude of NLP tasks.
Despite these successes, their opaqueness remains problematic. Recent methods
aiming to provide interpretability and explainability to black-box models
primarily focus on post-hoc explanations of (sometimes spurious) input-output
correlations. Instead, we emphasize using prototype networks directly
incorporated into the model architecture and hence explain the reasoning
process behind the network's decisions. Our architecture performs on par with
several language models and, moreover, enables learning from user interactions.
This not only offers a better understanding of language models but uses human
capabilities to incorporate knowledge outside of the rigid range of purely
data-driven approaches.

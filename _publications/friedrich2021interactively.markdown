---
layout: publication
title: Interactively Providing Explanations For Transformer Language Models
authors: Friedrich Felix, Schramowski Patrick, Tauchmann Christopher, Kersting Kristian
conference: "Arxiv"
year: 2021
bibkey: friedrich2021interactively
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2110.02058"}
tags: ['Interpretability And Explainability', 'Model Architecture', 'Pretraining Methods', 'Transformer']
---
Transformer language models are state of the art in a multitude of NLP tasks. Despite these successes their opaqueness remains problematic. Recent methods aiming to provide interpretability and explainability to black45;box models primarily focus on post45;hoc explanations of (sometimes spurious) input45;output correlations. Instead we emphasize using prototype networks directly incorporated into the model architecture and hence explain the reasoning process behind the networks decisions. Our architecture performs on par with several language models and moreover enables learning from user interactions. This not only offers a better understanding of language models but uses human capabilities to incorporate knowledge outside of the rigid range of purely data45;driven approaches.

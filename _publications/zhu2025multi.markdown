---
layout: publication
title: 'M\(^3\)finmeeting: A Multilingual, Multi-sector, And Multi-task Financial Meeting Understanding Evaluation Dataset'
authors: Jie Zhu, Junhui Li, Yalong Wen, Xiandong Li, Lifan Guo, Feng Chen
conference: "Arxiv"
year: 2025
bibkey: zhu2025multi
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2506.02510"}
tags: ['Applications', 'Reinforcement Learning']
---
Recent breakthroughs in large language models (LLMs) have led to the development of new benchmarks for evaluating their performance in the financial domain. However, current financial benchmarks often rely on news articles, earnings reports, or announcements, making it challenging to capture the real-world dynamics of financial meetings. To address this gap, we propose a novel benchmark called \\(\texttt\{M\\)^3\\(FinMeeting\}\\), which is a multilingual, multi-sector, and multi-task dataset designed for financial meeting understanding. First, \\(\texttt\{M\\)^3\\(FinMeeting\}\\) supports English, Chinese, and Japanese, enhancing comprehension of financial discussions in diverse linguistic contexts. Second, it encompasses various industry sectors defined by the Global Industry Classification Standard (GICS), ensuring that the benchmark spans a broad range of financial activities. Finally, \\(\texttt\{M\\)^3\\(FinMeeting\}\\) includes three tasks: summarization, question-answer (QA) pair extraction, and question answering, facilitating a more realistic and comprehensive evaluation of understanding. Experimental results with seven popular LLMs reveal that even the most advanced long-context models have significant room for improvement, demonstrating the effectiveness of \\(\texttt\{M\\)^3\\(FinMeeting\}\\) as a benchmark for assessing LLMs' financial meeting comprehension skills.

---
layout: publication
title: Pre45;training Multi45;modal Dense Retrievers For Outside45;knowledge Visual Question Answering
authors: Salemi Alireza, Rafiee Mahta, Zamani Hamed
conference: "Arxiv"
year: 2023
bibkey: salemi2023pre
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2306.16478"}
tags: ['Applications', 'Model Architecture', 'Training Techniques']
---
This paper studies a category of visual question answering tasks in which accessing external knowledge is necessary for answering the questions. This category is called outside45;knowledge visual question answering (OK45;VQA). A major step in developing OK45;VQA systems is to retrieve relevant documents for the given multi45;modal query. Current state45;of45;the45;art asymmetric dense retrieval model for this task uses an architecture with a multi45;modal query encoder and a uni45;modal document encoder. Such an architecture requires a large amount of training data for effective performance. We propose an automatic data generation pipeline for pre45;training passage retrieval models for OK45;VQA tasks. The proposed approach leads to 26.937; Precision35;64;5 improvements compared to the current state45;of45;the45;art asymmetric architecture. Additionally the proposed pre45;training approach exhibits a good ability in zero45;shot retrieval scenarios.

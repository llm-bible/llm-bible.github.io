---
layout: publication
title: 'Machine Translation Of Novels In The Age Of Transformer'
authors: Antonio Toral, Antoni Oliver, Pau Ribas Ballest√≠n
conference: "Arxiv"
year: 2020
bibkey: toral2020machine
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2011.14979"}
tags: ['Model Architecture', 'Transformer', 'Applications', 'Pretraining Methods']
---
In this chapter we build a machine translation (MT) system tailored to the
literary domain, specifically to novels, based on the state-of-the-art
architecture in neural MT (NMT), the Transformer (Vaswani et al., 2017), for
the translation direction English-to-Catalan. Subsequently, we assess to what
extent such a system can be useful by evaluating its translations, by comparing
this MT system against three other systems (two domain-specific systems under
the recurrent and phrase-based paradigms and a popular generic on-line system)
on three evaluations. The first evaluation is automatic and uses the
most-widely used automatic evaluation metric, BLEU. The two remaining
evaluations are manual and they assess, respectively, preference and amount of
post-editing required to make the translation error-free. As expected, the
domain-specific Transformer-based system outperformed the three other systems
in all the three evaluations conducted, in all cases by a large margin.

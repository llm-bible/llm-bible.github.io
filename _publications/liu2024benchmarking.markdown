---
layout: publication
title: 'Benchmarking Llms For Mimicking Child-caregiver Language In Interaction'
authors: Jing Liu, Abdellah Fourtassi
conference: "Arxiv"
year: 2024
bibkey: liu2024benchmarking
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2412.09318'}
tags: ['Reinforcement Learning', 'GPT', 'Applications', 'Model Architecture']
---
LLMs can generate human-like dialogues, yet their ability to simulate early
child-adult interactions remains largely unexplored. In this paper, we examined
how effectively LLMs can capture the distinctive features of child-caregiver
language in interaction, using both static and interactive benchmarking
methods. We found that state-of-the-art LLMs like Llama 3 and GPT-4o can
approximate child-caregiver dialogues at the word and utterance level, but they
struggle to reproduce the child and caregiver's discursive patterns, exaggerate
alignment, and fail to reach the level of diversity shown by humans. The
broader goal of this work is to initiate the development of a comprehensive
benchmark for LLMs in child-oriented applications.

---
layout: publication
title: 'Appropriateness Of Llm-equipped Robotic Well-being Coach Language In The Workplace: A Qualitative Evaluation'
authors: Micol Spitale, Minja Axelsson, Hatice Gunes
conference: "Arxiv"
year: 2024
bibkey: spitale2024appropriateness
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2401.14935'}
tags: ['Reinforcement Learning', 'Ethics and Bias']
---
Robotic coaches have been recently investigated to promote mental well-being
in various contexts such as workplaces and homes. With the widespread use of
Large Language Models (LLMs), HRI researchers are called to consider language
appropriateness when using such generated language for robotic mental
well-being coaches in the real world. Therefore, this paper presents the first
work that investigated the language appropriateness of robot mental well-being
coach in the workplace. To this end, we conducted an empirical study that
involved 17 employees who interacted over 4 weeks with a robotic mental
well-being coach equipped with LLM-based capabilities. After the study, we
individually interviewed them and we conducted a focus group of 1.5 hours with
11 of them. The focus group consisted of: i) an ice-breaking activity, ii)
evaluation of robotic coach language appropriateness in various scenarios, and
iii) listing shoulds and shouldn'ts for designing appropriate robotic coach
language for mental well-being. From our qualitative evaluation, we found that
a language-appropriate robotic coach should (1) ask deep questions which
explore feelings of the coachees, rather than superficial questions, (2)
express and show emotional and empathic understanding of the context, and (3)
not make any assumptions without clarifying with follow-up questions to avoid
bias and stereotyping. These results can inform the design of
language-appropriate robotic coach to promote mental well-being in real-world
contexts.

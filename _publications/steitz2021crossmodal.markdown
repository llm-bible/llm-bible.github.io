---
layout: publication
title: Txt Crossmodal End45;to45;end Learning With Transformers
authors: Steitz Jan-martin O., Pfeiffer Jonas, Gurevych Iryna, Roth Stefan
conference: "Arxiv"
year: 2021
bibkey: steitz2021crossmodal
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2109.04422"}
tags: ['Applications', 'Model Architecture', 'Multimodal Models', 'Pretraining Methods', 'RAG', 'Reinforcement Learning', 'Transformer']
---
Reasoning over multiple modalities e.g. in Visual Question Answering (VQA) requires an alignment of semantic concepts across domains. Despite the widespread success of end45;to45;end learning todays multimodal pipelines by and large leverage pre45;extracted fixed features from object detectors typically Faster R45;CNN as representations of the visual world. The obvious downside is that the visual representation is not specifically tuned to the multimodal task at hand. At the same time while transformer45;based object detectors have gained popularity they have not been employed in todays multimodal pipelines. We address both shortcomings with TxT a transformer45;based crossmodal pipeline that enables fine45;tuning both language and visual components on the downstream task in a fully end45;to45;end manner. We overcome existing limitations of transformer45;based detectors for multimodal reasoning regarding the integration of global context and their scalability. Our transformer45;based multimodal model achieves considerable gains from end45;to45;end learning for multimodal question answering.

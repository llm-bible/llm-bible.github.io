---
layout: publication
title: TPTU Large Language Model-based AI Agents For Task Planning And Tool Usage
authors: Ruan Jingqing, Chen Yihong, Zhang Bin, Xu Zhiwei, Bao Tianpeng, Du Guoqing, Shi Shiwei, Mao Hangyu, Li Ziyue, Zeng Xingyu, Zhao Rui
conference: "Arxiv"
year: 2023
bibkey: ruan2023large
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2308.03427"}
tags: ['Agentic', 'Applications', 'Pretraining Methods', 'RAG', 'Reinforcement Learning', 'Tools']
---
With recent advancements in natural language processing Large Language Models (LLMs) have emerged as powerful tools for various real-world applications. Despite their prowess the intrinsic generative abilities of LLMs may prove insufficient for handling complex tasks which necessitate a combination of task planning and the usage of external tools. In this paper we first propose a structured framework tailored for LLM-based AI Agents and discuss the crucial capabilities necessary for tackling intricate problems. Within this framework we design two distinct types of agents (i.e. one-step agent and sequential agent) to execute the inference process. Subsequently we instantiate the framework using various LLMs and evaluate their Task Planning and Tool Usage (TPTU) abilities on typical tasks. By highlighting key findings and challenges our goal is to provide a helpful resource for researchers and practitioners to leverage the power of LLMs in their AI applications. Our study emphasizes the substantial potential of these models while also identifying areas that need more investigation and improvement.

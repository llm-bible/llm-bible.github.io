---
layout: publication
title: Follow My Instruction And Spill The Beans Scalable Data Extraction From Retrieval45;augmented Generation Systems
authors: Qi Zhenting, Zhang Hanlin, Xing Eric, Kakade Sham, Lakkaraju Himabindu
conference: "Arxiv"
year: 2024
bibkey: qi2024follow
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.17840"}
tags: ['GPT', 'Model Architecture', 'Prompting', 'RAG', 'Security']
---
Retrieval45;Augmented Generation (RAG) improves pre45;trained models by incorporating external knowledge at test time to enable customized adaptation. We study the risk of datastore leakage in Retrieval45;In45;Context RAG Language Models (LMs). We show that an adversary can exploit LMs instruction45;following capabilities to easily extract text data verbatim from the datastore of RAG systems built with instruction45;tuned LMs via prompt injection. The vulnerability exists for a wide range of modern LMs that span Llama2 Mistral/Mixtral Vicuna SOLAR WizardLM Qwen1.5 and Platypus2 and the exploitability exacerbates as the model size scales up. Extending our study to production RAG models GPTs we design an attack that can cause datastore leakage with a 10037; success rate on 25 randomly selected customized GPTs with at most 2 queries and we extract text data verbatim at a rate of 4137; from a book of 77000 words and 337; from a corpus of 1569000 words by prompting the GPTs with only 100 queries generated by themselves.

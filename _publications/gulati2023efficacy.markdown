---
layout: publication
title: Efficacy Of Machine45;generated Instructions
authors: Gulati Samaksh, Verma Anshit, Parmar Manoj, Chaudhary Palash
conference: "Arxiv"
year: 2023
bibkey: gulati2023efficacy
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2312.14423"}
tags: ['BERT', 'GPT', 'Model Architecture', 'Pretraining Methods']
---
Large instruction45;tuned language models (i.e. finetuned to respond to instructions) have demonstrated a remarkable ability to generalize zero45;shot to new tasks. Nevertheless they depend heavily on human45;written instruction data that is often limited in quantity diversity and creativity therefore hindering the generality of the tuned model. We conducted a quantitative study to figure out the efficacy of machine45;generated annotations where we compare the results of a fine45;tuned BERT model with human v/s machine45;generated annotations. Applying our methods to the vanilla GPT45;3 model we saw that machine generated annotations were 78.5437; correct and the fine45;tuned model achieved a 96.0137; model performance compared to the performance with human45;labelled annotations. This result shows that machine45;generated annotations are a resource and cost effective way to fine45;tune down45;stream models.

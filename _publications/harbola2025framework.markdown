---
layout: publication
title: 'Knowslm: A Framework For Evaluation Of Small Language Models For Knowledge Augmentation And Humanised Conversations'
authors: Chitranshu Harbola, Anupam Purwar
conference: "Arxiv"
year: 2025
bibkey: harbola2025framework
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2504.04569'}
tags: ['RAG', 'Training Techniques', 'Tools', 'Fine-Tuning', 'Prompting', 'Reinforcement Learning', 'Pretraining Methods']
---
In the evolving landscape of conversational AI, generating concise,
context-aware, and human-like dialogue using small and medium-sized language
models (LLMs) remains a complex challenge. This study investigates the
influence of LoRA rank, dataset scale, and prompt prefix design on both
knowledge retention and stylistic alignment. While fine-tuning improves fluency
and enables stylistic customization, its ability to integrate unseen knowledge
is constrained -- particularly with smaller datasets. Conversely, RAG-augmented
models, equipped to incorporate external documents at inference, demonstrated
superior factual accuracy on out-of-distribution prompts, though they lacked
the stylistic consistency achieved by fine-tuning. Evaluations by LLM-based
judges across knowledge accuracy, conversational quality, and conciseness
suggest that fine-tuning is best suited for tone adaptation, whereas RAG excels
at real-time knowledge augmentation.

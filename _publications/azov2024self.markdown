---
layout: publication
title: Self-Improving Customer Review Response Generation Based on LLMs
authors: Azov Guy, Pelc Tatiana, Alon Adi Fledel, Kamhi Gila
conference: "Arxiv"
year: 2024
bibkey: azov2024self
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.03845"}
tags: ['ARXIV', 'Applications', 'Prompt', 'RAG', 'Survey Paper', 'Tools']
---
Previous studies have demonstrated that proactive interaction with user reviews has a positive impact on the perception of app users and encourages them to submit revised ratings. Nevertheless developers encounter challenges in managing a high volume of reviews particularly in the case of popular apps with a substantial influx of daily reviews. Consequently there is a demand for automated solutions aimed at streamlining the process of responding to user reviews. To address this we have developed a new system for generating automatic responses by leveraging user-contributed documents with the help of retrieval-augmented generation (RAG) and advanced Large Language Models (LLMs). Our solution named SCRABLE represents an adaptive customer review response automation that enhances itself with self-optimizing prompts and a judging mechanism based on LLMs. Additionally we introduce an automatic scoring mechanism that mimics the role of a human evaluator to assess the quality of responses generated in customer review domains. Extensive experiments and analyses conducted on real-world datasets reveal that our method is effective in producing high-quality responses yielding improvement of more than 8.5 compared to the baseline. Further validation through manual examination of the generated responses underscores the efficacy our proposed system.

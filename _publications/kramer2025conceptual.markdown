---
layout: publication
title: 'Conceptual Metaphor Theory As A Prompting Paradigm For Large Language Models'
authors: Oliver Kramer
conference: "Arxiv"
year: 2025
bibkey: kramer2025conceptual
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.01901"}
tags: ['RAG', 'Tools', 'Prompting']
---
We introduce Conceptual Metaphor Theory (CMT) as a framework for enhancing
large language models (LLMs) through cognitive prompting in complex reasoning
tasks. CMT leverages metaphorical mappings to structure abstract reasoning,
improving models' ability to process and explain intricate concepts. By
incorporating CMT-based prompts, we guide LLMs toward more structured and
human-like reasoning patterns. To evaluate this approach, we compare four
native models (Llama3.2, Phi3, Gemma2, and Mistral) against their CMT-augmented
counterparts on benchmark tasks spanning domain-specific reasoning, creative
insight, and metaphor interpretation. Responses were automatically evaluated
using the Llama3.3 70B model. Experimental results indicate that CMT prompting
significantly enhances reasoning accuracy, clarity, and metaphorical coherence,
outperforming baseline models across all evaluated tasks.

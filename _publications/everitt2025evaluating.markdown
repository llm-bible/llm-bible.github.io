---
layout: publication
title: 'Evaluating The Goal-directedness Of Large Language Models'
authors: Tom Everitt, Cristina Garbacea, Alexis Bellot, Jonathan Richens, Henry Papadatos, Sim√©on Campos, Rohin Shah
conference: "Arxiv"
year: 2025
bibkey: everitt2025evaluating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2504.11844"}
tags: ['Prompting', 'Agentic']
---
To what extent do LLMs use their capabilities towards their given goal? We
take this as a measure of their goal-directedness. We evaluate
goal-directedness on tasks that require information gathering, cognitive
effort, and plan execution, where we use subtasks to infer each model's
relevant capabilities. Our evaluations of LLMs from Google DeepMind, OpenAI,
and Anthropic show that goal-directedness is relatively consistent across
tasks, differs from task performance, and is only moderately sensitive to
motivational prompts. Notably, most models are not fully goal-directed. We hope
our goal-directedness evaluations will enable better monitoring of LLM
progress, and enable more deliberate design choices of agentic properties in
LLMs.

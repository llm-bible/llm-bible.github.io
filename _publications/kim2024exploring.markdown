---
layout: publication
title: 'Exploring Large Language Models On Cross-cultural Values In Connection With Training Methodology'
authors: Minsang Kim, Seungjun Baek
conference: "Arxiv"
year: 2024
bibkey: kim2024exploring
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2412.08846"}
tags: ['Training Techniques', 'Ethics and Bias']
---
Large language models (LLMs) closely interact with humans, and thus need an
intimate understanding of the cultural values of human society. In this paper,
we explore how open-source LLMs make judgments on diverse categories of
cultural values across countries, and its relation to training methodology such
as model sizes, training corpus, alignment, etc. Our analysis shows that LLMs
can judge socio-cultural norms similar to humans but less so on social systems
and progress. In addition, LLMs tend to judge cultural values biased toward
Western culture, which can be improved with training on the multilingual
corpus. We also find that increasing model size helps a better understanding of
social values, but smaller models can be enhanced by using synthetic data. Our
analysis reveals valuable insights into the design methodology of LLMs in
connection with their understanding of cultural values.

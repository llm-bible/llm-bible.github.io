---
layout: publication
title: Let Me Speak Freely? A Study On The Impact Of Format Restrictions On Performance Of Large Language Models
authors: Tam Zhi Rui, Wu Cheng-kuang, Tsai Yi-lin, Lin Chieh-yen, Lee Hung-yi, Chen Yun-nung
conference: "Arxiv"
year: 2024
bibkey: tam2024let
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.02442"}
tags: ['Applications', 'Pretraining Methods', 'Reinforcement Learning']
---
Structured generation the process of producing content in standardized formats like JSON and XML is widely utilized in real-world applications to extract key output information from large language models (LLMs). This study investigates whether such constraints on generation space impact LLMs abilities including reasoning and domain knowledge comprehension. Specifically we evaluate LLMs performance when restricted to adhere to structured formats versus generating free-form responses across various common tasks. Surprisingly we observe a significant decline in LLMs reasoning abilities under format restrictions. Furthermore we find that stricter format constraints generally lead to greater performance degradation in reasoning tasks.

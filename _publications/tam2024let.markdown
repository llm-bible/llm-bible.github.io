---
layout: publication
title: 'Let Me Speak Freely? A Study On The Impact Of Format Restrictions On Performance Of Large Language Models'
authors: Zhi Rui Tam, Cheng-kuang Wu, Yi-lin Tsai, Chieh-yen Lin, Hung-yi Lee, Yun-nung Chen
conference: "Arxiv"
year: 2024
bibkey: tam2024let
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2408.02442'}
tags: ['Reinforcement Learning', 'Applications']
---
Structured generation, the process of producing content in standardized
formats like JSON and XML, is widely utilized in real-world applications to
extract key output information from large language models (LLMs). This study
investigates whether such constraints on generation space impact LLMs
abilities, including reasoning and domain knowledge comprehension.
Specifically, we evaluate LLMs performance when restricted to adhere to
structured formats versus generating free-form responses across various common
tasks. Surprisingly, we observe a significant decline in LLMs reasoning
abilities under format restrictions. Furthermore, we find that stricter format
constraints generally lead to greater performance degradation in reasoning
tasks.

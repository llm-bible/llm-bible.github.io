---
layout: publication
title: SWIFTA Scalable Lightweight Infrastructure For Fine45;tuning
authors: Zhao Yuze, Huang Jintao, Hu Jinghan, Wang Xingjun, Mao Yunlin, Zhang Daoze, Jiang Zeyinzi, Wu Zhikai, Ai Baole, Wang Ang, Zhou Wenmeng, Chen Yingda
conference: "Arxiv"
year: 2024
bibkey: zhao2024scalable
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.05517"}
tags: ['Agentic', 'Applications', 'Attention Mechanism', 'Efficiency And Optimization', 'Model Architecture', 'Pretraining Methods', 'Quantization', 'RAG', 'Reinforcement Learning', 'Tools', 'Training Techniques', 'Transformer']
---
Recent development in Large Language Models (LLMs) and Multi45;modal Large Language Models (MLLMs) have leverage Attention45;based Transformer architectures and achieved superior performance and generalization capabilities. They have since covered extensive areas of traditional learning tasks. For instance text45;based tasks such as text45;classification and sequence45;labeling as well as multi45;modal tasks like Visual Question Answering (VQA) and Optical Character Recognition (OCR) which were previously addressed using different models can now be tackled based on one foundation model. Consequently the training and lightweight fine45;tuning of LLMs and MLLMs especially those based on Transformer architecture has become particularly important. In recognition of these overwhelming needs we develop SWIFT a customizable one45;stop infrastructure for large models. With support of over 300+ LLMs and 50+ MLLMs SWIFT stands as the open45;source framework that provide the most comprehensive support for fine45;tuning large models. In particular it is the first training framework that provides systematic support for MLLMs. In addition to the core functionalities of fine45;tuning SWIFT also integrates post45;training processes such as inference evaluation and model quantization to facilitate fast adoptions of large models in various application scenarios. With a systematic integration of various training techniques SWIFT offers helpful utilities such as benchmark comparisons among different training techniques for large models. For fine45;tuning models specialized in agent framework we show that notable improvements on the ToolBench leader45;board can be achieved by training with customized dataset on SWIFT with an increase of 5.237;45;21.837; in the Act.EM metric over various baseline models a reduction in hallucination by 1.637;45;14.137; and an average performance improvement of 837;45;1737;.

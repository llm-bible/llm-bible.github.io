---
layout: publication
title: 'How Does Response Length Affect Long-form Factuality'
authors: James Xu Zhao, Jimmy Z. J. Liu, Bryan Hooi, See-kiong Ng
conference: "Arxiv"
year: 2025
bibkey: zhao2025how
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2505.23295'}
tags: ['Attention Mechanism', 'Language Modeling', 'Model Architecture', 'Applications', 'Tools', 'Ethics and Bias']
---
Large language models (LLMs) are widely used for long-form text generation. However, factual errors in the responses would undermine their reliability. Despite growing attention to LLM factuality, the effect of response length on factuality remains underexplored. In this work, we systematically investigate this relationship by first introducing an automatic and bi-level long-form factuality evaluation framework, which achieves high agreement with human annotations while being cost-effective. Using this framework, we conduct controlled experiments and find that longer responses exhibit lower factual precision, confirming the presence of length bias. To explain this phenomenon, we empirically examine three hypotheses: error propagation, long context, and facts exhaustion. Our results reveal that facts exhaustion, where the model gradually exhausts more reliable knowledge, is the primary cause of factual degradation, rather than the other two hypotheses.

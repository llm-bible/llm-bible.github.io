---
layout: publication
title: Recurrent And Contextual Models For Visual Question Answering
authors: Sharang Abhijit, Lau Eric
conference: "Arxiv"
year: 2017
bibkey: sharang2017recurrent
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/1703.08120"}
tags: ['Applications', 'Attention Mechanism', 'Ethics And Bias', 'Language Modeling', 'Model Architecture']
---
We propose a series of recurrent and contextual neural network models for multiple choice visual question answering on the Visual7W dataset. Motivated by divergent trends in model complexities in the literature we explore the balance between model expressiveness and simplicity by studying incrementally more complex architectures. We start with LSTM45;encoding of input questions and answers; build on this with context generation by LSTM45;encodings of neural image and question representations and attention over images; and evaluate the diversity and predictive power of our models and the ensemble thereof. All models are evaluated against a simple baseline inspired by the current state45;of45;the45;art consisting of involving simple concatenation of bag45;of45;words and CNN representations for the text and images respectively. Generally we observe marked variation in image45;reasoning performance between our models not obvious from their overall performance as well as evidence of dataset bias. Our standalone models achieve accuracies up to 64.637; while the ensemble of all models achieves the best accuracy of 66.6737; within 0.537; of the current state45;of45;the45;art for Visual7W.

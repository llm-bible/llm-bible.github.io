---
layout: publication
title: Predicting Fine45;tuning Performance With Probing
authors: Zhu Zining, Shahtalebi Soroosh, Rudzicz Frank
conference: "Arxiv"
year: 2022
bibkey: zhu2022predicting
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2210.07352"}
tags: ['Applications', 'Attention Mechanism', 'Model Architecture']
---
Large NLP models have recently shown impressive performance in language understanding tasks typically evaluated by their fine45;tuned performance. Alternatively probing has received increasing attention as being a lightweight method for interpreting the intrinsic mechanisms of large NLP models. In probing post45;hoc classifiers are trained on out45;of45;domain datasets that diagnose specific abilities. While probing the language models has led to insightful findings they appear disjointed from the development of models. This paper explores the utility of probing deep NLP models to extract a proxy signal widely used in model development 45;45; the fine45;tuning performance. We find that it is possible to use the accuracies of only three probing tests to predict the fine45;tuning performance with errors 4037; 45; 8037; smaller than baselines. We further discuss possible avenues where probing can empower the development of deep NLP models.

---
layout: publication
title: 'EPIC: Effective Prompting For Imbalanced-class Data Synthesis In Tabular Data Classification Via Large Language Models'
authors: Jinhee Kim, Taesung Kim, Jaegul Choo
conference: "Arxiv"
year: 2024
bibkey: kim2024effective
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2404.12404'}
  - {name: "Code", url: 'https://seharanul17.github.io/project-synthetic-tabular-llm/'}
tags: ['Has Code', 'RAG', 'Efficiency and Optimization', 'Applications', 'Prompting', 'Reinforcement Learning', 'In-Context Learning']
---
Large language models (LLMs) have demonstrated remarkable in-context learning
capabilities across diverse applications. In this work, we explore the
effectiveness of LLMs for generating realistic synthetic tabular data,
identifying key prompt design elements to optimize performance. We introduce
EPIC, a novel approach that leverages balanced, grouped data samples and
consistent formatting with unique variable mapping to guide LLMs in generating
accurate synthetic data across all classes, even for imbalanced datasets.
Evaluations on real-world datasets show that EPIC achieves state-of-the-art
machine learning classification performance, significantly improving generation
efficiency. These findings highlight the effectiveness of EPIC for synthetic
tabular data generation, particularly in addressing class imbalance. Our source
code for our work is available at:
https://seharanul17.github.io/project-synthetic-tabular-llm/

---
layout: publication
title: Building Pre-train LLM Dataset For The INDIC Languages: A Case Study On Hindi
authors: Parida Shantipriya, Panwar Shakshi, Lata Kusum, Mishra Sanskruti, Sekhar Sambit
conference: "Arxiv"
year: 2024
bibkey: parida2024building
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.09855"}
tags: ['Applications', 'Pretraining Methods', 'Reinforcement Learning', 'Training Techniques']
---
Large language models (LLMs) demonstrated transformative capabilities in many applications that require automatically generating responses based on human instruction. However the major challenge for building LLMs particularly in Indic languages is the availability of high-quality data for building foundation LLMs. In this paper we are proposing a large pre-train dataset in Hindi useful for the Indic language Hindi. We have collected the data span across several domains including major dialects in Hindi. The dataset contains 1.28 billion Hindi tokens. We have explained our pipeline including data collection pre-processing and availability for LLM pre-training. The proposed approach can be easily extended to other Indic and low-resource languages and will be available freely for LLM pre-training and LLM research purposes.

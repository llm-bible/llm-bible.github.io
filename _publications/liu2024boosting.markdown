---
layout: publication
title: 'Personaflow: Boosting Research Ideation With Llm-simulated Expert Personas'
authors: Yiren Liu, Pranav Sharma, Mehul Jitendra Oswal, Haijun Xia, Yun Huang
conference: "Arxiv"
year: 2024
bibkey: liu2024boosting
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2409.12538'}
tags: ['Reinforcement Learning', 'RAG', 'Ethics and Bias']
---
Developing novel interdisciplinary research ideas often requires discussions
and feedback from experts across different domains. However, obtaining timely
inputs is challenging due to the scarce availability of domain experts. Recent
advances in Large Language Model (LLM) research have suggested the feasibility
of utilizing LLM-simulated expert personas to support research ideation. In
this study, we introduce PersonaFlow, an LLM-based system using persona
simulation to support the ideation stage of interdisciplinary scientific
discovery. Our findings indicate that using multiple personas during ideation
significantly enhances user-perceived quality of outcomes (e.g., relevance of
critiques, creativity of research questions) without increasing cognitive load.
We also found that users' persona customization interactions significantly
improved their sense of control and recall of generated ideas. Based on the
findings, we discuss highlighting ethical concerns, including potential
over-reliance and cognitive biases, and suggest design implications for
leveraging LLM-simulated expert personas to support research ideation when
human expertise is inaccessible.

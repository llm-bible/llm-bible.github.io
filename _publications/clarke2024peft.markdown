---
layout: publication
title: 'PEFT-U: Parameter-efficient Fine-tuning For User Personalization'
authors: Christopher Clarke, Yuzhao Heng, Lingjia Tang, Jason Mars
conference: "Arxiv"
year: 2024
bibkey: clarke2024peft
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2407.18078'}
tags: ['Training Techniques', 'Model Architecture', 'Applications', 'Fine-Tuning', 'GPT', 'Pretraining Methods']
---
The recent emergence of Large Language Models (LLMs) has heralded a new era
of human-AI interaction. These sophisticated models, exemplified by Chat-GPT
and its successors, have exhibited remarkable capabilities in language
understanding. However, as these LLMs have undergone exponential growth, a
crucial dimension that remains understudied is the personalization of these
models. Large foundation models such as GPT-3 etc. focus on creating a
universal model that serves a broad range of tasks and users. This approach
emphasizes the model's generalization capabilities, treating users as a
collective rather than as distinct individuals. While practical for many common
applications, this one-size-fits-all approach often fails to address the rich
tapestry of human diversity and individual needs. To explore this issue we
introduce the PEFT-U Benchmark: a new dataset for building and evaluating NLP
models for user personalization. \datasetname\{\} consists of a series of
user-centered tasks containing diverse and individualized expressions where the
preferences of users can potentially differ for the same input. Using PEFT-U,
we explore the challenge of efficiently personalizing LLMs to accommodate
user-specific preferences in the context of diverse user-centered tasks.

---
layout: publication
title: 'Tcm-3ceval: A Triaxial Benchmark For Assessing Responses From Large Language Models In Traditional Chinese Medicine'
authors: Tianai Huang, Lu Lu, Jiayuan Chen, Lihao Liu, Junjun He, Yuping Zhao, Wenchao Tang, Jie Xu
conference: "Arxiv"
year: 2025
bibkey: huang2025tcm
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2503.07041'}
tags: ['GPT', 'Model Architecture']
---
Large language models (LLMs) excel in various NLP tasks and modern medicine,
but their evaluation in traditional Chinese medicine (TCM) is underexplored. To
address this, we introduce TCM3CEval, a benchmark assessing LLMs in TCM across
three dimensions: core knowledge mastery, classical text understanding, and
clinical decision-making. We evaluate diverse models, including international
(e.g., GPT-4o), Chinese (e.g., InternLM), and medical-specific (e.g., PLUSE).
Results show a performance hierarchy: all models have limitations in
specialized subdomains like Meridian & Acupoint theory and Various TCM Schools,
revealing gaps between current capabilities and clinical needs. Models with
Chinese linguistic and cultural priors perform better in classical text
interpretation and clinical reasoning. TCM-3CEval sets a standard for AI
evaluation in TCM, offering insights for optimizing LLMs in culturally grounded
medical domains. The benchmark is available on Medbench's TCM track, aiming to
assess LLMs' TCM capabilities in basic knowledge, classic texts, and clinical
decision-making through multidimensional questions and real cases.

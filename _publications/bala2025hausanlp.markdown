---
layout: publication
title: 'Hausanlp At Semeval-2025 Task 3: Towards A Fine-grained Model-aware Hallucination Detection'
authors: Maryam Bala, Amina Imam Abubakar, Abdulhamid Abubakar, Abdulkadir Shehu Bichi, Hafsa Kabir Ahmad, Sani Abdullahi Sani, Idris Abdulmumin, Shamsuddeen Hassan Muhamad, Ibrahim Said Ahmad
conference: "Arxiv"
year: 2025
bibkey: bala2025hausanlp
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2503.19650'}
tags: ['Reinforcement Learning', 'BERT', 'Model Architecture']
---
This paper presents our findings of the Multilingual Shared Task on
Hallucinations and Related Observable Overgeneration Mistakes, MU-SHROOM, which
focuses on identifying hallucinations and related overgeneration errors in
large language models (LLMs). The shared task involves detecting specific text
spans that constitute hallucinations in the outputs generated by LLMs in 14
languages. To address this task, we aim to provide a nuanced, model-aware
understanding of hallucination occurrences and severity in English. We used
natural language inference and fine-tuned a ModernBERT model using a synthetic
dataset of 400 samples, achieving an Intersection over Union (IoU) score of
0.032 and a correlation score of 0.422. These results indicate a moderately
positive correlation between the model's confidence scores and the actual
presence of hallucinations. The IoU score indicates that our model has a
relatively low overlap between the predicted hallucination span and the truth
annotation. The performance is unsurprising, given the intricate nature of
hallucination detection. Hallucinations often manifest subtly, relying on
context, making pinpointing their exact boundaries formidable.

---
layout: publication
title: Taught by the Internet Exploring Bias in OpenAIs GPT3
authors: Ayaz Ali, Nawalgaria Aditya, Yin Ruilian
conference: "Arxiv"
year: 2023
bibkey: ayaz2023taught
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2306.02428"}
tags: ['ARXIV', 'BERT', 'Ethics And Bias', 'GPT', 'Model Architecture', 'NLP']
---
This research delves into the current literature on bias in Natural Language Processing Models and the techniques proposed to mitigate the problem of bias including why it is important to tackle bias in the first place. Additionally these techniques are further analysed in the light of newly developed models that tower in size over past editions. To achieve those aims the authors of this paper conducted their research on GPT3 by OpenAI the largest NLP model available to consumers today. With 175 billion parameters in contrast to BERTs 340 million GPT3 is the perfect model to test the common pitfalls of NLP models. Tests were conducted through the development of an Applicant Tracking System using GPT3. For the sake of feasibility and time constraints the tests primarily focused on gender bias rather than all or multiple types of bias. Finally current mitigation techniques are considered and tested to measure their degree of functionality.

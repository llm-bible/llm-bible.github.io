---
layout: publication
title: 'Image-to-text Logic Jailbreak: Your Imagination Can Help You Do Anything'
authors: Zou Xiaotian, Li Ke, Chen Yongkang
conference: "Arxiv"
year: 2024
bibkey: zou2024image
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.02534"}
tags: ['Attention Mechanism', 'GPT', 'Model Architecture', 'Pretraining Methods', 'Security']
---
Large Visual Language Modeltextbfs (VLMs) such as GPT-4V have achieved remarkable success in generating comprehensive and nuanced responses. Researchers have proposed various benchmarks for evaluating the capabilities of VLMs. With the integration of visual and text inputs in VLMs new security issues emerge as malicious attackers can exploit multiple modalities to achieve their objectives. This has led to increasing attention on the vulnerabilities of VLMs to jailbreak. Most existing research focuses on generating adversarial images or nonsensical image to jailbreak these models. However no researchers evaluate whether logic understanding capabilities of VLMs in flowchart can influence jailbreak. Therefore to fill this gap this paper first introduces a novel dataset Flow-JD specifically designed to evaluate the logic-based flowchart jailbreak capabilities of VLMs. We conduct an extensive evaluation on GPT-4o GPT-4V other 5 SOTA open source VLMs and the jailbreak rate is up to 92.837;. Our research reveals significant vulnerabilities in current VLMs concerning image-to-text jailbreak and these findings underscore the the urgency for the development of robust and effective future defenses.

---
layout: publication
title: Towards Automated Psychotherapy Via Language Modeling
authors: Liu Houjun
conference: "Arxiv"
year: 2021
bibkey: liu2021towards
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2104.10661"}
tags: ['Language Modeling', 'Model Architecture', 'Pretraining Methods', 'Tools', 'Training Techniques', 'Transformer']
---
In this experiment a model was devised trained and evaluated to automate psychotherapist/client text conversations through the use of state45;of45;the45;art Seq2Seq Transformer45;based Natural Language Generation (NLG) systems. Through training the model upon a mix of the Cornell Movie Dialogue Corpus for language understanding and an open45;source anonymized and public licensed psychotherapeutic dataset the model achieved statistically significant performance in published standardized qualitative benchmarks against human45;written validation data 45; meeting or exceeding human45;written responses performance in 59.737; and 67.137; of the test set for two independent test methods respectively. Although the model cannot replace the work of psychotherapists entirely its ability to synthesize human45;appearing utterances for the majority of the test set serves as a promising step towards communizing and easing stigma at the psychotherapeutic point45;of45;care.

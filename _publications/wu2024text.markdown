---
layout: publication
title: Elicitationgpt Text Elicitation Mechanisms Via Language Models
authors: Wu Yifan, Hartline Jason
conference: "Arxiv"
year: 2024
bibkey: wu2024text
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.09363"}
tags: ['GPT', 'Model Architecture', 'Pretraining Methods', 'Training Techniques']
---
Scoring rules evaluate probabilistic forecasts of an unknown state against the realized state and are a fundamental building block in the incentivized elicitation of information and the training of machine learning models. This paper develops mechanisms for scoring elicited text against ground truth text using domain45;knowledge45;free queries to a large language model (specifically ChatGPT) and empirically evaluates their alignment with human preferences. The empirical evaluation is conducted on peer reviews from a peer45;grading dataset and in comparison to manual instructor scores for the peer reviews.

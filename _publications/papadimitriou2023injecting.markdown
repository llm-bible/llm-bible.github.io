---
layout: publication
title: Injecting Structural Hints Using Language Models To Study Inductive Biases In Language Learning
authors: Papadimitriou Isabel, Jurafsky Dan
conference: "Arxiv"
year: 2023
bibkey: papadimitriou2023injecting
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2304.13060"}
tags: ['Ethics And Bias', 'Model Architecture', 'Pretraining Methods', 'RAG', 'Training Techniques', 'Transformer']
---
Both humans and large language models are able to learn language without explicit structural supervision. What inductive biases make this learning possible We address this fundamental cognitive question by leveraging transformer language models we inject inductive bias into language models by pretraining on formally45;structured data and then evaluate the biased learners ability to learn typologically45;diverse natural languages. Our experimental setup creates a testbed for hypotheses about inductive bias in human language learning. We investigate the effect of injecting models with three types of inductive bias 1) recursive hierarchical processing 2) crossing token45;token relationships that cant be modeled by context45;free grammars and 3) a Zipfian power45;law vocabulary distribution. We show that non45;context45;free relationships form the best inductive biases. Our study leverages the capabilities of transformer models to run controlled language learning experiments that are not possible to run on humans and surfaces hypotheses about the structures that facilitate language learning in both humans and machines.

---
layout: publication
title: 'Collective Reasoning Among Llms A Framework For Answer Validation Without Ground Truth'
authors: Seyed Pouyan Mousavi Davoudi, Alireza Shafiee Fard, Alireza Amiri-margavi
conference: "Arxiv"
year: 2025
bibkey: davoudi2025collective
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.20758"}
tags: ['Model Architecture', 'GPT', 'Tools']
---
We present a collaborative framework where multiple large language models,
namely GPT-4-0125-preview, Meta-LLaMA-3-70B-Instruct, Claude-3-Opus, and
Gemini-1.5-Flash, work together to generate and respond to complex PhD-level
probability questions in the absence of definitive ground truth. This study
explores how inter-model consensus enhances response reliability and serves as
a proxy for assessing the quality of generated questions. To quantify agreement
and consistency, we employ statistical methods including chi-square tests,
Fleiss' Kappa, and confidence interval analysis, measuring both response
precision and question clarity. Our findings highlight that Claude and Gemini
generate well-structured and less ambiguous questions, leading to higher
inter-model agreement. This is reflected in their narrower confidence intervals
and stronger alignment with answering models. Conversely, LLaMA demonstrates
increased variability and lower reliability in question formulation, as
indicated by broader confidence intervals and reduced consensus rates. These
results suggest that multi-model collaboration not only enhances the
reliability of responses but also provides a valuable framework for assessing
and improving question quality in the absence of explicit ground truth. This
research offers meaningful insights into optimizing AI-driven reasoning through
collaborative large-language model interactions.

---
layout: publication
title: Exploring Recurrent Memory And Attention Based Architectures For Scoring Interactional Aspects Of Human45;machine Text Dialog
authors: Ramanarayanan Vikram, Mulholland Matthew, Ghosh Debanjan
conference: "Arxiv"
year: 2020
bibkey: ramanarayanan2020exploring
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2005.09834"}
tags: ['Attention Mechanism', 'Merging', 'Model Architecture', 'Pretraining Methods', 'Reinforcement Learning', 'Transformer']
---
An important step towards enabling English language learners to improve their conversational speaking proficiency involves automated scoring of multiple aspects of interactional competence and subsequent targeted feedback. This paper builds on previous work in this direction to investigate multiple neural architectures 45;45; recurrent attention and memory based 45;45; along with feature45;engineered models for the automated scoring of interactional and topic development aspects of text dialog data. We conducted experiments on a conversational database of text dialogs from human learners interacting with a cloud45;based dialog system which were triple45;scored along multiple dimensions of conversational proficiency. We find that fusion of multiple architectures performs competently on our automated scoring task relative to expert inter45;rater agreements with (i) hand45;engineered features passed to a support vector learner and (ii) transformer45;based architectures contributing most prominently to the fusion.

---
layout: publication
title: Zero45;shot Generative Large Language Models For Systematic Review Screening Automation
authors: Wang Shuai, Scells Harrisen, Zhuang Shengyao, Potthast Martin, Koopman Bevan, Zuccon Guido
conference: "Arxiv"
year: 2024
bibkey: wang2024zero
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.06320"}
tags: ['Pretraining Methods', 'Survey Paper']
---
Systematic reviews are crucial for evidence45;based medicine as they comprehensively analyse published research findings on specific questions. Conducting such reviews is often resource45; and time45;intensive especially in the screening phase where abstracts of publications are assessed for inclusion in a review. This study investigates the effectiveness of using zero45;shot large language models~(LLMs) for automatic screening. We evaluate the effectiveness of eight different LLMs and investigate a calibration technique that uses a predefined recall threshold to determine whether a publication should be included in a systematic review. Our comprehensive evaluation using five standard test collections shows that instruction fine45;tuning plays an important role in screening that calibration renders LLMs practical for achieving a targeted recall and that combining both with an ensemble of zero45;shot models saves significant screening time compared to state45;of45;the45;art approaches.

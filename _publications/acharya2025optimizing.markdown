---
layout: publication
title: 'Optimizing Code Runtime Performance Through Context-aware Retrieval-augmented Generation'
authors: Manish Acharya, Yifan Zhang, Kevin Leach, Yu Huang
conference: "Arxiv"
year: 2025
bibkey: acharya2025optimizing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2501.16692"}
tags: ['Tools', 'GPT', 'Efficiency and Optimization', 'RAG', 'Model Architecture', 'Prompting']
---
Optimizing software performance through automated code refinement offers a
promising avenue for enhancing execution speed and efficiency. Despite recent
advancements in LLMs, a significant gap remains in their ability to perform
in-depth program analysis. This study introduces AUTOPATCH, an in-context
learning approach designed to bridge this gap by enabling LLMs to automatically
generate optimized code. Inspired by how programmers learn and apply knowledge
to optimize software, AUTOPATCH incorporates three key components: (1) an
analogy-driven framework to align LLM optimization with human cognitive
processes, (2) a unified approach that integrates historical code examples and
CFG analysis for context-aware learning, and (3) an automated pipeline for
generating optimized code through in-context prompting. Experimental results
demonstrate that AUTOPATCH achieves a 7.3% improvement in execution efficiency
over GPT-4o across common generated executable code, highlighting its potential
to advance automated program runtime optimization.

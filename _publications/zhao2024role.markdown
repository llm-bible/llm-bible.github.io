---
layout: publication
title: 'Role-play Paradox In Large Language Models: Reasoning Performance Gains And Ethical Dilemmas'
authors: Jinman Zhao, Zifan Qian, Linbo Cao, Yining Wang, Yitian Ding, Yulan Hu, Zeyu Zhang, Zeyong Jin
conference: "Arxiv"
year: 2024
bibkey: zhao2024role
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2409.13979"}
tags: ['Ethics and Bias']
---
Role-play in large language models (LLMs) enhances their ability to generate
contextually relevant and high-quality responses by simulating diverse
cognitive perspectives. However, our study identifies significant risks
associated with this technique. First, we demonstrate that autotuning, a method
used to auto-select models' roles based on the question, can lead to the
generation of harmful outputs, even when the model is tasked with adopting
neutral roles. Second, we investigate how different roles affect the likelihood
of generating biased or harmful content. Through testing on benchmarks
containing stereotypical and harmful questions, we find that role-play
consistently amplifies the risk of biased outputs. Our results underscore the
need for careful consideration of both role simulation and tuning processes
when deploying LLMs in sensitive or high-stakes contexts.

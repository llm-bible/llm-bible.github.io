---
layout: publication
title: 'Characterizing Truthfulness In Large Language Model Generations With Local Intrinsic Dimension'
authors: Fan Yin, Jayanth Srinivasa, Kai-wei Chang
conference: "Arxiv"
year: 2024
bibkey: yin2024characterizing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.18048"}
  - {name: "Paper", url: "https://info.arxiv.org/help/prep#abstractsf"}
tags: ['GPT', 'Applications', 'Language Modeling', 'Training Techniques', 'Pretraining Methods', 'Arxiv']
---
We study how to characterize and predict the truthfulness of texts generated
from large language models (LLMs), which serves as a crucial step in building
trust between humans and LLMs. Although several approaches based on entropy or
verbalized uncertainty have been proposed to calibrate model predictions, these
methods are often intractable, sensitive to hyperparameters, and less reliable
when applied in generative tasks with LLMs. In this paper, we suggest
investigating internal activations and quantifying LLM's truthfulness using the
local intrinsic dimension (LID) of model activations. Through experiments on
four question answering (QA) datasets, we demonstrate the effectiveness
ohttps://info.arxiv.org/help/prep#abstractsf our proposed method. Additionally,
we study intrinsic dimensions in LLMs and their relations with model layers,
autoregressive language modeling, and the training of LLMs, revealing that
intrinsic dimensions can be a powerful approach to understanding LLMs.

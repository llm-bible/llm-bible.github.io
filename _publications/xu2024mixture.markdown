---
layout: publication
title: Mixture45;of45;instructions Comprehensive Alignment Of A Large Language Model Through The Mixture Of Diverse System Prompting Instructions
authors: Xu Bowen, Wu Shaoyu, Liu Kai, Hu Lulu
conference: "Arxiv"
year: 2024
bibkey: xu2024mixture
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.18410"}
tags: ['Efficiency And Optimization', 'Fine Tuning', 'Merging', 'Pretraining Methods', 'Prompting', 'RAG', 'Reinforcement Learning']
---
With the proliferation of large language models (LLMs) the comprehensive alignment of such models across multiple tasks has emerged as a critical area of research. Existing alignment methodologies primarily address single task such as multi45;turn dialogue coding mathematical problem45;solving and tool usage. However AI45;driven products that leverage language models usually necessitate a fusion of these abilities to function effectively in real45;world scenarios. Moreover the considerable computational resources required for proper alignment of LLMs underscore the need for a more robust efficient and encompassing approach to multi45;task alignment ensuring improved generative performance. In response to these challenges we introduce a novel technique termed Mixture45;of45;Instructions (MoI) which employs a strategy of instruction concatenation combined with diverse system prompts to boost the alignment efficiency of language models. We have also compiled a diverse set of seven benchmark datasets to rigorously evaluate the alignment efficacy of the MoI45;enhanced language model. Our methodology was applied to the open45;source Qwen45;7B45;chat model culminating in the development of Qwen45;SFT45;MoI. This enhanced model demonstrates significant advancements in generative capabilities across coding mathematics and tool use tasks.

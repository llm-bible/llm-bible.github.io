---
layout: publication
title: 'Physicsassistant: An Llm-powered Interactive Learning Robot For Physics Lab Investigations'
authors: Ehsan Latif, Ramviyas Parasuraman, Xiaoming Zhai
conference: "Arxiv"
year: 2024
bibkey: latif2024llm
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.18721"}
tags: ['Multimodal Models', 'Model Architecture', 'Reinforcement Learning', 'RAG', 'GPT', 'INTERSPEECH']
---
Robot systems in education can leverage Large language models' (LLMs) natural
language understanding capabilities to provide assistance and facilitate
learning. This paper proposes a multimodal interactive robot (PhysicsAssistant)
built on YOLOv8 object detection, cameras, speech recognition, and chatbot
using LLM to provide assistance to students' physics labs. We conduct a user
study on ten 8th-grade students to empirically evaluate the performance of
PhysicsAssistant with a human expert. The Expert rates the assistants'
responses to student queries on a 0-4 scale based on Bloom's taxonomy to
provide educational support. We have compared the performance of
PhysicsAssistant (YOLOv8+GPT-3.5-turbo) with GPT-4 and found that the human
expert rating of both systems for factual understanding is the same. However,
the rating of GPT-4 for conceptual and procedural knowledge (3 and 3.2 vs 2.2
and 2.6, respectively) is significantly higher than PhysicsAssistant (p <
0.05). However, the response time of GPT-4 is significantly higher than
PhysicsAssistant (3.54 vs 1.64 sec, p < 0.05). Hence, despite the relatively
lower response quality of PhysicsAssistant than GPT-4, it has shown potential
for being used as a real-time lab assistant to provide timely responses and can
offload teachers' labor to assist with repetitive tasks. To the best of our
knowledge, this is the first attempt to build such an interactive multimodal
robotic assistant for K-12 science (physics) education.

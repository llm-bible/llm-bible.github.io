---
layout: publication
title: 'SEFL: Harnessing Large Language Model Agents To Improve Educational Feedback Systems'
authors: Mike Zhang, Amalie Pernille Dilling, LÃ©on Gondelman, Niels Erik Ruan Lyngdorf, Euan D. Lindsay, Johannes Bjerva
conference: "Arxiv"
year: 2025
bibkey: zhang2025harnessing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.12927"}
tags: ['Agentic', 'Tools', 'Reinforcement Learning']
---
Providing high-quality feedback is crucial for student success but is
constrained by time, cost, and limited data availability. We introduce
Synthetic Educational Feedback Loops (SEFL), a novel framework designed to
deliver immediate, on-demand feedback at scale without relying on extensive,
real-world student data. In SEFL, two large language models (LLMs) operate in
teacher--student roles to simulate assignment completion and formative
feedback, generating abundant synthetic pairs of student work and corresponding
critiques. We then fine-tune smaller, more computationally efficient LLMs on
these synthetic pairs, enabling them to replicate key features of high-quality,
goal-oriented feedback. Unlike personalized tutoring approaches that offer
multi-turn, individualized instruction, SEFL specifically focuses on
replicating the teacher-->student feedback loop for diverse assignments.
Through both LLM-as-a-judge and human evaluations, we demonstrate that
SEFL-tuned models outperform their non-tuned counterparts in feedback quality,
clarity, and timeliness. These findings reveal SEFL's potential to transform
feedback processes for higher education and beyond, offering an ethical and
scalable alternative to conventional manual feedback cycles.

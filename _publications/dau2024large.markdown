---
layout: publication
title: Xmainframe\: A Large Language Model For Mainframe Modernization
authors: Dau Anh T. V., Dao Hieu Trung, Nguyen Anh Tuan, Tran Hieu Trung, Nguyen Phong X., Bui Nghi D. Q.
conference: "Arxiv"
year: 2024
bibkey: dau2024large
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.04660"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Reinforcement Learning', 'Tools', 'Training Techniques']
---
Mainframe operating systems despite their inception in the 1940s continue to support critical sectors like finance and government. However these systems are often viewed as outdated requiring extensive maintenance and modernization. Addressing this challenge necessitates innovative tools that can understand and interact with legacy codebases. To this end we introduce XMainframe a state-of-the-art large language model (LLM) specifically designed with knowledge of mainframe legacy systems and COBOL codebases. Our solution involves the creation of an extensive data collection pipeline to produce high-quality training datasets enhancing XMainframes performance in this specialized domain. Additionally we present MainframeBench a comprehensive benchmark for assessing mainframe knowledge including multiple-choice questions question answering and COBOL code summarization. Our empirical evaluations demonstrate that XMainframe consistently outperforms existing state-of-the-art LLMs across these tasks. Specifically XMainframe achieves 3037; higher accuracy than DeepSeek-Coder on multiple-choice questions doubles the BLEU score of Mixtral-Instruct 8x7B on question answering and scores six times higher than GPT-3.5 on COBOL summarization. Our work highlights the potential of XMainframe to drive significant advancements in managing and modernizing legacy systems thereby enhancing productivity and saving time for software developers.

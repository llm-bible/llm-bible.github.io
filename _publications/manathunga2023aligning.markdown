---
layout: publication
title: Aligning Large Language Models for Clinical Tasks
authors: Manathunga Supun, Hettigoda Isuru
conference: "Arxiv"
year: 2023
bibkey: manathunga2023aligning
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.02884"}
tags: ['Applications', 'Few Shot', 'Fine Tuning', 'Prompting']
---
Large Language Models (LLMs) have demonstrated remarkable adaptability showcasing their capacity to excel in tasks for which they were not explicitly trained. However despite their impressive natural language processing (NLP) capabilities effective alignment of LLMs remains a crucial challenge when deploying them for specific clinical applications. The ability to generate responses with factually accurate content and to engage in non-trivial reasoning steps are crucial for the LLMs to be eligible for applications in clinical medicine. Employing a combination of techniques including instruction-tuning and in-prompt strategies like few-shot and chain-of-thought prompting has significantly enhanced the performance of LLMs. Our proposed alignment strategy for medical question-answering known as expand-guess-refine offers a parameter and data-efficient solution. A preliminary analysis of this method demonstrated outstanding performance achieving a score of 70.63 on a subset of questions sourced from the USMLE dataset.

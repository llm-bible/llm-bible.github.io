---
layout: publication
title: 'LLM+AL: Bridging Large Language Models And Action Languages For Complex Reasoning About Actions'
authors: Adam Ishay, Joohyung Lee
conference: "Arxiv"
year: 2025
bibkey: ishay2025bridging
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2501.00830'}
tags: ['RAG', 'GPT', 'Applications', 'Model Architecture']
---
Large Language Models (LLMs) have made significant strides in various
intelligent tasks but still struggle with complex action reasoning tasks that
require systematic search. To address this limitation, we propose a method that
bridges the natural language understanding capabilities of LLMs with the
symbolic reasoning strengths of action languages. Our approach, termed
"LLM+AL," leverages the LLM's strengths in semantic parsing and commonsense
knowledge generation alongside the action language's proficiency in automated
reasoning based on encoded knowledge. We compare LLM+AL against
state-of-the-art LLMs, including ChatGPT-4, Claude 3 Opus, Gemini Ultra 1.0,
and o1-preview, using benchmarks for complex reasoning about actions. Our
findings indicate that, although all methods exhibit errors, LLM+AL, with
relatively minimal human corrections, consistently leads to correct answers,
whereas standalone LLMs fail to improve even with human feedback. LLM+AL also
contributes to automated generation of action languages.

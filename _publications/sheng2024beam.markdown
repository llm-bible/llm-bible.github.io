---
layout: publication
title: 'Beam Prediction Based On Large Language Models'
authors: Yucheng Sheng, Kai Huang, Le Liang, Peng Liu, Shi Jin, Geoffrey Ye Li
conference: "Arxiv"
year: 2024
bibkey: sheng2024beam
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2408.08707'}
tags: ['Attention Mechanism', 'RAG', 'Security', 'Model Architecture', 'Prompting']
---
In this letter, we use large language models (LLMs) to develop a
high-performing and robust beam prediction method. We formulate the millimeter
wave (mmWave) beam prediction problem as a time series forecasting task, where
the historical observations are aggregated through cross-variable attention and
then transformed into text-based representations using a trainable tokenizer.
By leveraging the prompt-as-prefix (PaP) technique for contextual enrichment,
our method harnesses the power of LLMs to predict future optimal beams.
Simulation results demonstrate that our LLM-based approach outperforms
traditional learning-based models in prediction accuracy as well as robustness,
highlighting the significant potential of LLMs in enhancing wireless
communication systems.

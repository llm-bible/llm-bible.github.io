---
layout: publication
title: 'Kg-llm-bench: A Scalable Benchmark For Evaluating LLM Reasoning On Textualized Knowledge Graphs'
authors: Elan Markowitz, Krupa Galiya, Greg Ver Steeg, Aram Galstyan
conference: "Arxiv"
year: 2025
bibkey: markowitz2025kg
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2504.07087'}
tags: ['Applications']
---
Knowledge graphs have emerged as a popular method for injecting up-to-date,
factual knowledge into large language models (LLMs). This is typically achieved
by converting the knowledge graph into text that the LLM can process in
context. While multiple methods of encoding knowledge graphs have been
proposed, the impact of this textualization process on LLM performance remains
under-explored. We introduce KG-LLM-Bench, a comprehensive and extensible
benchmark spanning five knowledge graph understanding tasks, and evaluate how
different encoding strategies affect performance across various base models.
Our extensive experiments with seven language models and five textualization
strategies provide insights for optimizing LLM performance on KG reasoning
tasks.

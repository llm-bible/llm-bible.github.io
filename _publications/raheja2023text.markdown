---
layout: publication
title: Coedit Text Editing By Task45;specific Instruction Tuning
authors: Raheja Vipul, Kumar Dhruv, Koo Ryan, Kang Dongyeop
conference: "Arxiv"
year: 2023
bibkey: raheja2023text
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2305.09857"}
  - {name: "Code", url: "https://github.com/vipulraheja/coedit"}
tags: ['Efficiency And Optimization', 'Has Code', 'Reinforcement Learning']
---
We introduce CoEdIT a state45;of45;the45;art text editing system for writing assistance. CoEdIT takes instructions from the user specifying the attributes of the desired text such as Make the sentence simpler or Write it in a more neutral style and outputs the edited text. We present a large language model fine45;tuned on a diverse collection of task45;specific instructions for text editing (a total of 82K instructions). Our model (1) achieves state45;of45;the45;art performance on various text editing benchmarks (2) is competitive with publicly available largest45;sized LLMs trained on instructions while being nearly 60x smaller (3) is capable of generalizing to unseen edit instructions and (4) exhibits abilities to generalize to composite instructions containing different combinations of edit actions. Through extensive qualitative and quantitative analysis we show that writers prefer the edits suggested by CoEdIT relative to other state45;of45;the45;art text editing models. Our code data and models are publicly available at https://github.com/vipulraheja/coedit.

---
layout: publication
title: Lareqa Language45;agnostic Answer Retrieval From A Multilingual Pool
authors: Roy Uma, Constant Noah, Al-rfou Rami, Barua Aditya, Phillips Aaron, Yang Yinfei
conference: "Arxiv"
year: 2020
bibkey: roy2020language
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2004.05484"}
tags: ['Applications', 'BERT', 'Model Architecture', 'Training Techniques']
---
We present LAReQA a challenging new benchmark for language45;agnostic answer retrieval from a multilingual candidate pool. Unlike previous cross45;lingual tasks LAReQA tests for strong cross45;lingual alignment requiring semantically related cross45;language pairs to be closer in representation space than unrelated same45;language pairs. Building on multilingual BERT (mBERT) we study different strategies for achieving strong alignment. We find that augmenting training data via machine translation is effective and improves significantly over using mBERT out45;of45;the45;box. Interestingly the embedding baseline that performs the best on LAReQA falls short of competing baselines on zero45;shot variants of our task that only target weak alignment. This finding underscores our claim that languageagnostic retrieval is a substantively new kind of cross45;lingual evaluation.

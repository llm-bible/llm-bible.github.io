---
layout: publication
title: 'Promptwizard: Task-aware Prompt Optimization Framework'
authors: Eshaan Agarwal, Joykirat Singh, Vivek Dani, Raghav Magazine, Tanuja Ganu, Akshay Nambi
conference: "Arxiv"
year: 2024
bibkey: agarwal2024task
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2405.18369'}
tags: ['Efficiency and Optimization', 'Training Techniques', 'Model Architecture', 'Tools', 'Fine-Tuning', 'Prompting']
---
Large language models (LLMs) have transformed AI across diverse domains, with
prompting being central to their success in guiding model outputs. However,
manual prompt engineering is both labor-intensive and domain-specific,
necessitating the need for automated solutions. We introduce PromptWizard, a
novel, fully automated framework for discrete prompt optimization, utilizing a
self-evolving, self-adapting mechanism. Through a feedback-driven critique and
synthesis process, PromptWizard achieves an effective balance between
exploration and exploitation, iteratively refining both prompt instructions and
in-context examples to generate human-readable, task-specific prompts. This
guided approach systematically improves prompt quality, resulting in superior
performance across 45 tasks. PromptWizard excels even with limited training
data, smaller LLMs, and various LLM architectures. Additionally, our cost
analysis reveals a substantial reduction in API calls, token usage, and overall
cost, demonstrating PromptWizard's efficiency, scalability, and advantages over
existing prompt optimization strategies.

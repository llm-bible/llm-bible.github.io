---
layout: publication
title: Dynathink Fast Or Slow A Dynamic Decision-making Framework For Large Language Models
authors: Pan Jiabao, Zhang Yan, Zhang Chen, Liu Zuozhu, Wang Hongwei, Li Haizhou
conference: "Arxiv"
year: 2024
bibkey: pan2024fast
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.01009"}
tags: ['Efficiency And Optimization', 'Prompting', 'Tools']
---
Large language models (LLMs) have demonstrated emergent capabilities across diverse reasoning tasks via popular Chains-of-Thought (COT) prompting. However such a simple and fast COT approach often encounters limitations in dealing with complicated problems while a thorough method which considers multiple reasoning pathways and verifies each step carefully results in slower inference. This paper addresses the challenge of enabling LLMs to autonomously select between fast and slow inference methods thereby optimizing both efficiency and effectiveness. We introduce a dynamic decision-making framework that categorizes tasks into two distinct pathways Fast designated for tasks where the LLM quickly identifies a high-confidence solution and Slow allocated for tasks that the LLM perceives as complex and for which it has low confidence in immediate solutions as well as requiring more reasoning paths to verify. Experiments on five popular reasoning benchmarks demonstrated the superiority of the DynaThink over baselines.

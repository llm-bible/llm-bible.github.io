---
layout: publication
title: Clip45;guided Vision45;language Pre45;training For Question Answering In 3D Scenes
authors: Parelli Maria, Delitzas Alexandros, Hars Nikolas, Vlassis Georgios, Anagnostidis Sotirios, Bachmann Gregor, Hofmann Thomas
conference: "Arxiv"
year: 2023
bibkey: parelli2023clip
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2304.06061"}
tags: ['Applications', 'Reinforcement Learning', 'Training Techniques']
---
Training models to apply linguistic knowledge and visual concepts from 2D images to 3D world understanding is a promising direction that researchers have only recently started to explore. In this work we design a novel 3D pre45;training Vision45;Language method that helps a model learn semantically meaningful and transferable 3D scene point cloud representations. We inject the representational power of the popular CLIP model into our 3D encoder by aligning the encoded 3D scene features with the corresponding 2D image and text embeddings produced by CLIP. To assess our models 3D world reasoning capability we evaluate it on the downstream task of 3D Visual Question Answering. Experimental quantitative and qualitative results show that our pre45;training method outperforms state45;of45;the45;art works in this task and leads to an interpretable representation of 3D scene features.

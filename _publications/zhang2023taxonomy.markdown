---
layout: publication
title: 'Taxonomy-based Checklist For Large Language Model Evaluation'
authors: Zhang Damin
conference: "Arxiv"
year: 2023
bibkey: zhang2023taxonomy
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.10899"}
tags: ['Bias Mitigation', 'Ethics And Bias', 'Fairness', 'GPT', 'Model Architecture', 'Pretraining Methods', 'Reinforcement Learning', 'Transformer']
---
As large language models (LLMs) have been used in many downstream tasks the internal stereotypical representation may affect the fairness of the outputs. In this work we introduce human knowledge into natural language interventions and study pre-trained language models (LMs) behaviors within the context of gender bias. Inspired by CheckList behavioral testing we present a checklist-style task that aims to probe and quantify LMs unethical behaviors through question-answering (QA). We design three comparison studies to evaluate LMs from four aspects consistency biased tendency model preference and gender preference switch. We probe one transformer-based QA model trained on SQuAD-v2 dataset and one autoregressive large language model. Our results indicate that transformer-based QA models biased tendency positively correlates with its consistency whereas LLM shows the opposite relation. Our proposed task provides the first dataset that involves human knowledge for LLM bias evaluation.

---
layout: publication
title: UI45;JEPA Towards Active Perception Of User Intent Through Onscreen User Activity
authors: Fu Yicheng, Anantha Raviteja, Vashisht Prabal, Cheng Jianpeng, Littwin Etai
conference: "Arxiv"
year: 2024
bibkey: fu2024ui
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2409.04081"}
tags: ['GPT', 'Model Architecture', 'Multimodal Models', 'RAG', 'Tools']
---
Generating user intent from a sequence of user interface (UI) actions is a core challenge in comprehensive UI understanding. Recent advancements in multimodal large language models (MLLMs) have led to substantial progress in this area but their demands for extensive model parameters computing power and high latency makes them impractical for scenarios requiring lightweight on45;device solutions with low latency or heightened privacy. Additionally the lack of high45;quality datasets has hindered the development of such lightweight models. To address these challenges we propose UI45;JEPA a novel framework that employs masking strategies to learn abstract UI embeddings from unlabeled data through self45;supervised learning combined with an LLM decoder fine45;tuned for user intent prediction. We also introduce two new UI45;grounded multimodal datasets Intent in the Wild (IIW) and Intent in the Tame (IIT) designed for few45;shot and zero45;shot UI understanding tasks. IIW consists of 1.7K videos across 219 intent categories while IIT contains 914 videos across 10 categories. We establish the first baselines for these datasets showing that representations learned using a JEPA45;style objective combined with an LLM decoder can achieve user intent predictions that match the performance of state45;of45;the45;art large MLLMs but with significantly reduced annotation and deployment resources. Measured by intent similarity scores UI45;JEPA outperforms GPT45;4 Turbo and Claude 3.5 Sonnet by 10.037; and 7.237; respectively averaged across two datasets. Notably UI45;JEPA accomplishes the performance with a 50.5x reduction in computational cost and a 6.6x improvement in latency in the IIW dataset. These results underscore the effectiveness of UI45;JEPA highlighting its potential for lightweight high45;performance UI understanding.

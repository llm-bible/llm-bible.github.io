---
layout: publication
title: ChatGPT Prompting Cannot Estimate Predictive Uncertainty in High-Resource Languages
authors: Pelucchi Martino, Valdenegro-toro Matias
conference: "Arxiv"
year: 2023
bibkey: pelucchi2023chatgpt
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2311.06427"}
tags: ['ARXIV', 'Chatgpt', 'GPT', 'Model Architecture', 'NLP', 'Prompt', 'Reinforcement Learning']
---
ChatGPT took the world by storm for its impressive abilities. Due to its release without documentation scientists immediately attempted to identify its limits mainly through its performance in natural language processing (NLP) tasks. This paper aims to join the growing literature regarding ChatGPTs abilities by focusing on its performance in high-resource languages and on its capacity to predict its answers accuracy by giving a confidence level. The analysis of high-resource languages is of interest as studies have shown that low-resource languages perform worse than English in NLP tasks but no study so far has analysed whether high-resource languages perform as well as English. The analysis of ChatGPTs confidence calibration has not been carried out before either and is critical to learn about ChatGPTs trustworthiness. In order to study these two aspects five high-resource languages and two NLP tasks were chosen. ChatGPT was asked to perform both tasks in the five languages and to give a numerical confidence value for each answer. The results show that all the selected high-resource languages perform similarly and that ChatGPT does not have a good confidence calibration often being overconfident and never giving low confidence values.

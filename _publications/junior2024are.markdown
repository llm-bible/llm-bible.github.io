---
layout: publication
title: 'Are Large Language Models The New Interface For Data Pipelines?'
authors: Sylvio Barbon Junior, Paolo Ceravolo, Sven Groppe, Mustafa Jarrar, Samira Maghool, Florence SÃ¨des, Soror Sahri, Maurice Van Keulen
conference: "Arxiv"
year: 2024
bibkey: junior2024are
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.06596"}
tags: ['Attention Mechanism', 'Applications', 'Model Architecture']
---
A Language Model is a term that encompasses various types of models designed
to understand and generate human communication. Large Language Models (LLMs)
have gained significant attention due to their ability to process text with
human-like fluency and coherence, making them valuable for a wide range of
data-related tasks fashioned as pipelines. The capabilities of LLMs in natural
language understanding and generation, combined with their scalability,
versatility, and state-of-the-art performance, enable innovative applications
across various AI-related fields, including eXplainable Artificial Intelligence
(XAI), Automated Machine Learning (AutoML), and Knowledge Graphs (KG).
Furthermore, we believe these models can extract valuable insights and make
data-driven decisions at scale, a practice commonly referred to as Big Data
Analytics (BDA). In this position paper, we provide some discussions in the
direction of unlocking synergies among these technologies, which can lead to
more powerful and intelligent AI solutions, driving improvements in data
pipelines across a wide range of applications and domains integrating humans,
computers, and knowledge.

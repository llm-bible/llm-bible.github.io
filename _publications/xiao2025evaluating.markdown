---
layout: publication
title: 'SCOP: Evaluating The Comprehension Process Of Large Language Models From A Cognitive View'
authors: Yongjie Xiao, Hongru Liang, Peixin Qin, Yao Zhang, Wenqiang Lei
conference: "Arxiv"
year: 2025
bibkey: xiao2025evaluating
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2506.05000'}
tags: ['Reinforcement Learning', 'Interpretability and Explainability', 'Training Techniques', 'Tools']
---
Despite the great potential of large language models(LLMs) in machine comprehension, it is still disturbing to fully count on them in real-world scenarios. This is probably because there is no rational explanation for whether the comprehension process of LLMs is aligned with that of experts. In this paper, we propose SCOP to carefully examine how LLMs perform during the comprehension process from a cognitive view. Specifically, it is equipped with a systematical definition of five requisite skills during the comprehension process, a strict framework to construct testing data for these skills, and a detailed analysis of advanced open-sourced and closed-sourced LLMs using the testing data. With SCOP, we find that it is still challenging for LLMs to perform an expert-level comprehension process. Even so, we notice that LLMs share some similarities with experts, e.g., performing better at comprehending local information than global information. Further analysis reveals that LLMs can be somewhat unreliable -- they might reach correct answers through flawed comprehension processes. Based on SCOP, we suggest that one direction for improving LLMs is to focus more on the comprehension process, ensuring all comprehension skills are thoroughly developed during training.

---
layout: publication
title: 'Meaningful Learning: Enhancing Abstract Reasoning In Large Language Models Via Generic Fact Guidance'
authors: Kai Xiong, Xiao Ding, Ting Liu, Bing Qin, Dongliang Xu, Qing Yang, Hongtao Liu, Yixin Cao
conference: "Arxiv"
year: 2024
bibkey: xiong2024meaningful
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.09085"}
  - {name: "Code", url: "https://github.com/Waste-Wood/MeanLearn"}
tags: ['Reinforcement Learning', 'RAG', 'Interpretability', 'Has Code', 'Interpretability and Explainability']
---
Large language models (LLMs) have developed impressive performance and strong
explainability across various reasoning scenarios, marking a significant stride
towards mimicking human-like intelligence. Despite this, when tasked with
several simple questions supported by a generic fact, LLMs often struggle to
abstract and apply the generic fact to provide consistent and precise answers,
revealing a deficiency in abstract reasoning abilities. This has sparked a
vigorous debate about whether LLMs are genuinely reasoning or merely
memorizing. In light of this, we design a preliminary study to quantify and
delve into the abstract reasoning abilities of existing LLMs. Our findings
reveal a substantial discrepancy between their general reasoning and abstract
reasoning performances. To relieve this problem, we tailor an abstract
reasoning dataset (AbsR) together with a meaningful learning paradigm to teach
LLMs how to leverage generic facts for reasoning purposes. The results show
that our approach not only boosts the general reasoning performance of LLMs but
also makes considerable strides towards their capacity for abstract reasoning,
moving beyond simple memorization or imitation to a more nuanced understanding
and application of generic facts. The code is available at
https://github.com/Waste-Wood/MeanLearn.

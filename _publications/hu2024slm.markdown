---
layout: publication
title: SLM Meets LLM Balancing Latency Interpretability And Consistency In Hallucination Detection
authors: Hu Mengya, Xu Rui, Lei Deren, Li Yaxi, Wang Mingyu, Ching Emily, Kamal Eslam, Deng Alex
conference: "Arxiv"
year: 2024
bibkey: hu2024slm
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.12748"}
tags: ['Applications', 'Interpretability And Explainability', 'Pretraining Methods', 'Prompting', 'RAG', 'Tools']
---
Large language models (LLMs) are highly capable but face latency challenges in real45;time applications such as conducting online hallucination detection. To overcome this issue we propose a novel framework that leverages a small language model (SLM) classifier for initial detection followed by a LLM as constrained reasoner to generate detailed explanations for detected hallucinated content. This study optimizes the real45;time interpretable hallucination detection by introducing effective prompting techniques that align LLM45;generated explanations with SLM decisions. Empirical experiment results demonstrate its effectiveness thereby enhancing the overall user experience.

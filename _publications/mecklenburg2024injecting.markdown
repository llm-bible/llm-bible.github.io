---
layout: publication
title: Injecting New Knowledge Into Large Language Models Via Supervised Fine45;tuning
authors: Mecklenburg Nick, Lin Yiyou, Li Xiaoxiao, Holstein Daniel, Nunes Leonardo, Malvar Sara, Silva Bruno, Chandra Ranveer, Aski Vijay, Yannam Pavan Kumar Reddy, Aktas Tolga, Hendry Todd
conference: "Arxiv"
year: 2024
bibkey: mecklenburg2024injecting
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.00213"}
tags: ['Applications', 'Fine Tuning', 'GPT', 'Model Architecture', 'RAG', 'Reinforcement Learning', 'Training Techniques']
---
In recent years Large Language Models (LLMs) have shown remarkable performance in generating human45;like text proving to be a valuable asset across various applications. However adapting these models to incorporate new out45;of45;domain knowledge remains a challenge particularly for facts and events that occur after the models knowledge cutoff date. This paper investigates the effectiveness of Supervised Fine45;Tuning (SFT) as a method for knowledge injection in LLMs specifically focusing on the domain of recent sporting events. We compare different dataset generation strategies 45;45; token45;based and fact45;based scaling 45;45; to create training data that helps the model learn new information. Our experiments on GPT45;4 demonstrate that while token45;based scaling can lead to improvements in Qamp;A accuracy it may not provide uniform coverage of new knowledge. Fact45;based scaling on the other hand offers a more systematic approach to ensure even coverage across all facts. We present a novel dataset generation process that leads to more effective knowledge ingestion through SFT and our results show considerable performance improvements in Qamp;A tasks related to out45;of45;domain knowledge. This study contributes to the understanding of domain adaptation for LLMs and highlights the potential of SFT in enhancing the factuality of LLM responses in specific knowledge domains.

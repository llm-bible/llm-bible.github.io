---
layout: publication
title: A Paradigm Shift The Future Of Machine Translation Lies With Large Language Models
authors: Lyu Chenyang, Du Zefeng, Xu Jitao, Duan Yitao, Wu Minghao, Lynn Teresa, Aji Alham Fikri, Wong Derek F., Liu Siyou, Wang Longyue
conference: "Arxiv"
year: 2023
bibkey: lyu2023paradigm
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2305.01181"}
tags: ['Applications', 'Fine Tuning', 'GPT', 'Model Architecture', 'Prompting', 'Reinforcement Learning']
---
Machine Translation (MT) has greatly advanced over the years due to the developments in deep neural networks. However the emergence of Large Language Models (LLMs) like GPT45;4 and ChatGPT is introducing a new phase in the MT domain. In this context we believe that the future of MT is intricately tied to the capabilities of LLMs. These models not only offer vast linguistic understandings but also bring innovative methodologies such as prompt45;based techniques that have the potential to further elevate MT. In this paper we provide an overview of the significant enhancements in MT that are influenced by LLMs and advocate for their pivotal role in upcoming MT research and implementations. We highlight several new MT directions emphasizing the benefits of LLMs in scenarios such as Long45;Document Translation Stylized Translation and Interactive Translation. Additionally we address the important concern of privacy in LLM45;driven MT and suggest essential privacy45;preserving strategies. By showcasing practical instances we aim to demonstrate the advantages that LLMs offer particularly in tasks like translating extended documents. We conclude by emphasizing the critical role of LLMs in guiding the future evolution of MT and offer a roadmap for future exploration in the sector.

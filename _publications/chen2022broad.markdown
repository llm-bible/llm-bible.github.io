---
layout: publication
title: Curriculum A Broad45;coverage Benchmark For Linguistic Phenomena In Natural Language Understanding
authors: Chen Zeming, Gao Qiyue
conference: "Arxiv"
year: 2022
bibkey: chen2022broad
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2204.06283"}
tags: ['Applications', 'Model Architecture', 'Pretraining Methods', 'RAG', 'Transformer']
---
In the age of large transformer language models linguistic evaluation play an important role in diagnosing models abilities and limitations on natural language understanding. However current evaluation methods show some significant shortcomings. In particular they do not provide insight into how well a language model captures distinct linguistic skills essential for language understanding and reasoning. Thus they fail to effectively map out the aspects of language understanding that remain challenging to existing models which makes it hard to discover potential limitations in models and datasets. In this paper we introduce Curriculum as a new format of NLI benchmark for evaluation of broad45;coverage linguistic phenomena. Curriculum contains a collection of datasets that covers 36 types of major linguistic phenomena and an evaluation procedure for diagnosing how well a language model captures reasoning skills for distinct types of linguistic phenomena. We show that this linguistic45;phenomena45;driven benchmark can serve as an effective tool for diagnosing model behavior and verifying model learning quality. In addition our experiments provide insight into the limitation of existing benchmark datasets and state45;of45;the45;art models that may encourage future research on re45;designing datasets model architectures and learning objectives.

---
layout: publication
title: 'Earthgpt-x: Enabling Mllms To Flexibly And Comprehensively Understand Multi-source Remote Sensing Imagery'
authors: Wei Zhang, Miaoxin Cai, Yaqian Ning, Tong Zhang, Yin Zhuang, He Chen, Jun Li, Xuerui Mao
conference: "Arxiv"
year: 2025
bibkey: zhang2025earthgpt
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2504.12795'}
tags: ['GPT', 'Model Architecture', 'Tools', 'Training Techniques', 'Merging', 'Prompting', 'Reinforcement Learning']
---
Recent advances in the visual-language area have developed natural
multi-modal large language models (MLLMs) for spatial reasoning through visual
prompting. However, due to remote sensing (RS) imagery containing abundant
geospatial information that differs from natural images, it is challenging to
effectively adapt natural spatial models to the RS domain. Moreover, current RS
MLLMs are limited in overly narrow interpretation levels and interaction
manner, hindering their applicability in real-world scenarios. To address those
challenges, a spatial MLLM named EarthGPT-X is proposed, enabling a
comprehensive understanding of multi-source RS imagery, such as optical,
synthetic aperture radar (SAR), and infrared. EarthGPT-X offers zoom-in and
zoom-out insight, and possesses flexible multi-grained interactive abilities.
Moreover, EarthGPT-X unifies two types of critical spatial tasks (i.e.,
referring and grounding) into a visual prompting framework. To achieve these
versatile capabilities, several key strategies are developed. The first is the
multi-modal content integration method, which enhances the interplay between
images, visual prompts, and text instructions. Subsequently, a cross-domain
one-stage fusion training strategy is proposed, utilizing the large language
model (LLM) as a unified interface for multi-source multi-task learning.
Furthermore, by incorporating a pixel perception module, the referring and
grounding tasks are seamlessly unified within a single framework. In addition,
the experiments conducted demonstrate the superiority of the proposed
EarthGPT-X in multi-grained tasks and its impressive flexibility in multi-modal
interaction, revealing significant advancements of MLLM in the RS field.

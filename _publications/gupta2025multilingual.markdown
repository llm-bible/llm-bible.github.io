---
layout: publication
title: 'Multilingual Performance Biases Of Large Language Models In Education'
authors: Vansh Gupta, Sankalan Pal Chowdhury, Vil√©m Zouhar, Donya Rooein, Mrinmaya Sachan
conference: "Arxiv"
year: 2025
bibkey: gupta2025multilingual
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2504.17720"}
tags: ['Ethics and Bias', 'Training Techniques', 'Applications']
---
Large language models (LLMs) are increasingly being adopted in educational
settings. These applications expand beyond English, though current LLMs remain
primarily English-centric. In this work, we ascertain if their use in education
settings in non-English languages is warranted. We evaluated the performance of
popular LLMs on four educational tasks: identifying student misconceptions,
providing targeted feedback, interactive tutoring, and grading translations in
six languages (Hindi, Arabic, Farsi, Telugu, Ukrainian, Czech) in addition to
English. We find that the performance on these tasks somewhat corresponds to
the amount of language represented in training data, with lower-resource
languages having poorer task performance. Although the models perform
reasonably well in most languages, the frequent performance drop from English
is significant. Thus, we recommend that practitioners first verify that the LLM
works well in the target language for their educational task before deployment.

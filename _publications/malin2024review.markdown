---
layout: publication
title: 'A Review Of Faithfulness Metrics For Hallucination Assessment In Large Language Models'
authors: Ben Malin, Tatiana Kalganova, Nikoloas Boulgouris
conference: "Arxiv"
year: 2024
bibkey: malin2024review
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2501.00269"}
tags: ['Tools', 'Survey Paper', 'Applications', 'RAG', 'Prompting']
---
This review examines the means with which faithfulness has been evaluated
across open-ended summarization, question-answering and machine translation
tasks. We find that the use of LLMs as a faithfulness evaluator is commonly the
metric that is most highly correlated with human judgement. The means with
which other studies have mitigated hallucinations is discussed, with both
retrieval augmented generation (RAG) and prompting framework approaches having
been linked with superior faithfulness, whilst other recommendations for
mitigation are provided. Research into faithfulness is integral to the
continued widespread use of LLMs, as unfaithful responses can pose major risks
to many areas whereby LLMs would otherwise be suitable. Furthermore, evaluating
open-ended generation provides a more comprehensive measure of LLM performance
than commonly used multiple-choice benchmarking, which can help in advancing
the trust that can be placed within LLMs.

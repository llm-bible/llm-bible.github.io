---
layout: publication
title: 'Graph-toolformer: To Empower Llms With Graph Reasoning Ability Via Prompt Augmented By Chatgpt'
authors: Jiawei Zhang
conference: "Arxiv"
year: 2023
bibkey: zhang2023graph
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2304.11116"}
tags: ['Model Architecture', 'Tools', 'Reinforcement Learning', 'GPT', 'RecSys', 'Prompting', 'Applications']
---
In this paper, we aim to develop a large language model (LLM) with the
reasoning ability on complex graph data. Currently, LLMs have achieved very
impressive performance on various natural language learning tasks, extensions
of which have also been applied to study the vision tasks with multi-modal
data. However, when it comes to the graph learning tasks, existing LLMs present
very serious flaws due to their several inherited weaknesses in performing
\{multi-step logic reasoning\}, \{precise mathematical calculation\} and
\{perception about the spatial and temporal factors\}.
  To address such challenges, in this paper, we will investigate the
principles, methodologies and algorithms to empower existing LLMs with graph
reasoning ability, which will have tremendous impacts on the current research
of both LLMs and graph learning. Inspired by the latest ChatGPT and Toolformer
models, we propose the Graph-ToolFormer (Graph Reasoning oriented Toolformer)
framework to teach LLMs themselves with prompts augmented by ChatGPT to use
external graph reasoning API tools. Specifically, we will investigate to teach
Graph-ToolFormer to handle various graph data reasoning tasks in this paper,
including both (1) very basic graph data loading and graph property reasoning
tasks, ranging from simple graph order and size to the graph diameter and
periphery, and (2) more advanced reasoning tasks on real-world graph data, such
as bibliographic networks, protein molecules, sequential recommender systems,
social networks and knowledge graphs.

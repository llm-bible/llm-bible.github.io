---
layout: publication
title: 'Call For Papers -- The Babylm Challenge: Sample-efficient Pretraining On A Developmentally Plausible Corpus'
authors: Alex Warstadt, Leshem Choshen, Aaron Mueller, Adina Williams, Ethan Wilcox, Chengxu Zhuang
conference: "Arxiv"
year: 2023
bibkey: warstadt2023call
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2301.11796'}
tags: ['Language Modeling', 'Training Techniques', 'Applications', 'Tools', 'Fine-Tuning', 'Pretraining Methods']
---
We present the call for papers for the BabyLM Challenge: Sample-efficient
pretraining on a developmentally plausible corpus. This shared task is intended
for participants with an interest in small scale language modeling, human
language acquisition, low-resource NLP, and cognitive modeling. In partnership
with CoNLL and CMCL, we provide a platform for approaches to pretraining with a
limited-size corpus sourced from data inspired by the input to children. The
task has three tracks, two of which restrict the training data to pre-released
datasets of 10M and 100M words and are dedicated to explorations of approaches
such as architectural variations, self-supervised objectives, or curriculum
learning. The final track only restricts the amount of text used, allowing
innovation in the choice of the data, its domain, and even its modality (i.e.,
data from sources other than text is welcome). We will release a shared
evaluation pipeline which scores models on a variety of benchmarks and tasks,
including targeted syntactic evaluations and natural language understanding.

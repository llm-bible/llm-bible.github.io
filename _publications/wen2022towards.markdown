---
layout: publication
title: 'Towards Generating Robust, Fair, And Emotion-aware Explanations For Recommender Systems'
authors: Bingbing Wen, Yunhe Feng, Yongfeng Zhang, Chirag Shah
conference: "Arxiv"
year: 2022
bibkey: wen2022towards
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2208.08017"}
tags: ['Transformer', 'Ethics and Bias', 'Interpretability and Explainability', 'Bias Mitigation', 'Model Architecture', 'Reinforcement Learning', 'Interpretability', 'RecSys', 'Attention Mechanism', 'Pretraining Methods', 'Fairness']
---
As recommender systems become increasingly sophisticated and complex, they
often suffer from lack of fairness and transparency. Providing robust and
unbiased explanations for recommendations has been drawing more and more
attention as it can help address these issues and improve trustworthiness and
informativeness of recommender systems. However, despite the fact that such
explanations are generated for humans who respond more strongly to messages
with appropriate emotions, there is a lack of consideration for emotions when
generating explanations for recommendations. Current explanation generation
models are found to exaggerate certain emotions without accurately capturing
the underlying tone or the meaning. In this paper, we propose a novel method
based on a multi-head transformer, called Emotion-aware Transformer for
Explainable Recommendation (EmoTER), to generate more robust, fair, and
emotion-enhanced explanations. To measure the linguistic quality and emotion
fairness of the generated explanations, we adopt both automatic text metrics
and human perceptions for evaluation. Experiments on three widely-used
benchmark datasets with multiple evaluation metrics demonstrate that EmoTER
consistently outperforms the existing state-of-the-art explanation generation
models in terms of text quality, explainability, and consideration for fairness
to emotion distribution. Implementation of EmoTER will be released as an
open-source toolkit to support further research.

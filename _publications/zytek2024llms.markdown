---
layout: publication
title: LLMs for XAI Future Directions for Explaining Explanations
authors: Zytek Alexandra, Pid√≤ Sara, Veeramachaneni Kalyan
conference: "Arxiv"
year: 2024
bibkey: zytek2024llms
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.06064"}
tags: ['ARXIV', 'Explainability', 'Interpretability', 'LLM', 'Prompt']
---
In response to the demand for Explainable Artificial Intelligence (XAI) we investigate the use of Large Language Models (LLMs) to transform ML explanations into natural human-readable narratives. Rather than directly explaining ML models using LLMs we focus on refining explanations computed using existing XAI algorithms. We outline several research directions including defining evaluation metrics prompt design comparing LLM models exploring further training methods and integrating external data. Initial experiments and user study suggest that LLMs offer a promising way to enhance the interpretability and usability of XAI.

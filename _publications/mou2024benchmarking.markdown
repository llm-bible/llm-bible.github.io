---
layout: publication
title: 'Agentsense: Benchmarking Social Intelligence Of Language Agents Through Interactive Scenarios'
authors: Xinyi Mou, Jingcong Liang, Jiayu Lin, Xinnong Zhang, Xiawei Liu, Shiyue Yang, Rong Ye, Lei Chen, Haoyu Kuang, Xuanjing Huang, Zhongyu Wei
conference: "Arxiv"
year: 2024
bibkey: mou2024benchmarking
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2410.19346'}
  - {name: "Code", url: 'https://github.com/ljcleo/agent_sense'}
tags: ['Agentic', 'Has Code', 'RAG', 'GPT', 'Model Architecture', 'Reinforcement Learning']
---
Large language models (LLMs) are increasingly leveraged to empower autonomous
agents to simulate human beings in various fields of behavioral research.
However, evaluating their capacity to navigate complex social interactions
remains a challenge. Previous studies face limitations due to insufficient
scenario diversity, complexity, and a single-perspective focus. To this end, we
introduce AgentSense: Benchmarking Social Intelligence of Language Agents
through Interactive Scenarios. Drawing on Dramaturgical Theory, AgentSense
employs a bottom-up approach to create 1,225 diverse social scenarios
constructed from extensive scripts. We evaluate LLM-driven agents through
multi-turn interactions, emphasizing both goal completion and implicit
reasoning. We analyze goals using ERG theory and conduct comprehensive
experiments. Our findings highlight that LLMs struggle with goals in complex
social scenarios, especially high-level growth needs, and even GPT-4o requires
improvement in private information reasoning. Code and data are available at
\url\{https://github.com/ljcleo/agent_sense\}.

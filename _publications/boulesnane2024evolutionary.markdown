---
layout: publication
title: 'An Evolutionary Large Language Model For Hallucination Mitigation'
authors: Abdennour Boulesnane, Abdelhakim Souilah
conference: "Arxiv"
year: 2024
bibkey: boulesnane2024evolutionary
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2412.02790"}
tags: ['Model Architecture', 'Tools', 'Reinforcement Learning', 'RAG', 'GPT', 'Applications']
---
The emergence of LLMs, like ChatGPT and Gemini, has marked the modern era of
artificial intelligence applications characterized by high-impact applications
generating text, images, and videos. However, these models usually ensue with
one critical challenge called hallucination: confident presentation of
inaccurate or fabricated information. This problem attracts serious concern
when these models are applied to specialized domains, including healthcare and
law, where the accuracy and preciseness of information are absolute conditions.
In this paper, we propose EvoLLMs, an innovative framework inspired by
Evolutionary Computation, which automates the generation of high-quality
Question-answering (QA) datasets while minimizing hallucinations. EvoLLMs
employs genetic algorithms, mimicking evolutionary processes like selection,
variation, and mutation, to guide LLMs in generating accurate, contextually
relevant question-answer pairs. Comparative analysis shows that EvoLLMs
consistently outperforms human-generated datasets in key metrics such as Depth,
Relevance, and Coverage, while nearly matching human performance in mitigating
hallucinations. These results highlight EvoLLMs as a robust and efficient
solution for QA dataset generation, significantly reducing the time and
resources required for manual curation.

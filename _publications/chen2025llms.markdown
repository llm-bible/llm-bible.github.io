---
layout: publication
title: 'Xtragpt: Llms For Human-ai Collaboration On Controllable Academic Paper Revision'
authors: Nuo Chen, Andre Lin Huikai, Jiaying Wu, Junyi Hou, Zining Zhang, Qian Wang, Xidong Wang, Bingsheng He
conference: "Arxiv"
year: 2025
bibkey: chen2025llms
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2505.11336"}
tags: ['Model Architecture', 'Tools', 'Reinforcement Learning', 'Language Modeling', 'RAG', 'GPT', 'Prompting', 'Applications']
---
Despite the growing adoption of large language models (LLMs) in academic workflows, their capabilities remain limited when it comes to supporting high-quality scientific writing. Most existing systems are designed for general-purpose scientific text generation and fail to meet the sophisticated demands of research communication beyond surface-level polishing, such as conceptual coherence across sections. Furthermore, academic writing is inherently iterative and revision-driven, a process not well supported by direct prompting-based paradigms. To address these scenarios, we propose a human-AI collaboration framework for academic paper revision. We first introduce a comprehensive dataset of 7,040 research papers from top-tier venues annotated with over 140,000 instruction-response pairs that reflect realistic, section-level scientific revisions. Building on the dataset, we develop XtraGPT, the first suite of open-source LLMs, designed to provide context-aware, instruction-guided writing assistance, ranging from 1.5B to 14B parameters. Extensive experiments validate that XtraGPT significantly outperforms same-scale baselines and approaches the quality of proprietary systems. Both automated preference assessments and human evaluations confirm the effectiveness of our models in improving scientific drafts.

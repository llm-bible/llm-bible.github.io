---
layout: publication
title: 'Learning From Implicit User Feedback, Emotions And Demographic Information In Task-oriented And Document-grounded Dialogues'
authors: Dominic Petrak, Thy Thy Tran, Iryna Gurevych
conference: "Findings of the Association for Computational Linguistics EMNLP 2024 pages 4573 - 4603 Miami Florida USA"
year: 2024
bibkey: petrak2024learning
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.09248"}
tags: ['Model Architecture', 'GPT', 'Applications', 'Reinforcement Learning']
---
Implicit user feedback, user emotions and demographic information have shown
to be promising sources for improving the accuracy and user engagement of
responses generated by dialogue systems. However, the influence of such
information on task completion and factual consistency, which are important
criteria for task-oriented and document-grounded dialogues, is not yet known.
To address this, we introduce FEDI, the first English task-oriented and
document-grounded dialogue dataset annotated with this information. Our
experiments with Flan-T5, GPT-2 and Llama 2 show a particularly positive impact
on task completion and factual consistency. Participants in our human
evaluation reported that the responses generated by the feedback-trained models
were more informative (Flan-T5 and GPT-2), relevant and factual consistent
(Llama 2).

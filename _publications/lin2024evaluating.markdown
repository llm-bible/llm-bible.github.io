---
layout: publication
title: Evaluating Text45;to45;visual Generation With Image45;to45;text Generation
authors: Lin Zhiqiu, Pathak Deepak, Li Baiqi, Li Jiayao, Xia Xide, Neubig Graham, Zhang Pengchuan, Ramanan Deva
conference: "Arxiv"
year: 2024
bibkey: lin2024evaluating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.01291"}
tags: ['Applications', 'GPT', 'Language Modeling', 'Merging', 'Model Architecture', 'Prompting', 'Reinforcement Learning']
---
Despite significant progress in generative AI comprehensive evaluation remains challenging because of the lack of effective metrics and standardized benchmarks. For instance the widely45;used CLIPScore measures the alignment between a (generated) image and text prompt but it fails to produce reliable scores for complex prompts involving compositions of objects attributes and relations. One reason is that text encoders of CLIP can notoriously act as a bag of words conflating prompts such as the horse is eating the grass with the grass is eating the horse. To address this we introduce the VQAScore which uses a visual45;question45;answering (VQA) model to produce an alignment score by computing the probability of a Yes answer to a simple Does this figure show 123;text125; question. Though simpler than prior art VQAScore computed with off45;the45;shelf models produces state45;of45;the45;art results across many (8) image45;text alignment benchmarks. We also compute VQAScore with an in45;house model that follows best practices in the literature. For example we use a bidirectional image45;question encoder that allows image embeddings to depend on the question being asked (and vice versa). Our in45;house model CLIP45;FlanT5 outperforms even the strongest baselines that make use of the proprietary GPT45;4V. Interestingly although we train with only images VQAScore can also align text with video and 3D models. VQAScore allows researchers to benchmark text45;to45;visual generation using complex texts that capture the compositional structure of real45;world prompts. We introduce GenAI45;Bench a more challenging benchmark with 1600 compositional text prompts that require parsing scenes objects attributes relationships and high45;order reasoning like comparison and logic. GenAI45;Bench also offers over 15000 human ratings for leading image and video generation models such as Stable Diffusion DALL45;E 3 and Gen2.

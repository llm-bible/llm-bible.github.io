---
layout: publication
title: 'Virtualxai: A User-centric Framework For Explainability Assessment Leveraging Gpt-generated Personas'
authors: Georgios Makridis, Vasileios Koukos, Georgios Fatouros, Dimosthenis Kyriazis
conference: "Arxiv"
year: 2025
bibkey: makridis2025user
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2503.04261"}
tags: ['Model Architecture', 'Tools', 'RAG', 'GPT', 'Ethics and Bias', 'Interpretability', 'Interpretability and Explainability']
---
In today's data-driven era, computational systems generate vast amounts of
data that drive the digital transformation of industries, where Artificial
Intelligence (AI) plays a key role. Currently, the demand for eXplainable AI
(XAI) has increased to enhance the interpretability, transparency, and
trustworthiness of AI models. However, evaluating XAI methods remains
challenging: existing evaluation frameworks typically focus on quantitative
properties such as fidelity, consistency, and stability without taking into
account qualitative characteristics such as satisfaction and interpretability.
In addition, practitioners face a lack of guidance in selecting appropriate
datasets, AI models, and XAI methods -a major hurdle in human-AI collaboration.
To address these gaps, we propose a framework that integrates quantitative
benchmarking with qualitative user assessments through virtual personas based
on the "Anthology" of backstories of the Large Language Model (LLM). Our
framework also incorporates a content-based recommender system that leverages
dataset-specific characteristics to match new input data with a repository of
benchmarked datasets. This yields an estimated XAI score and provides tailored
recommendations for both the optimal AI model and the XAI method for a given
scenario.

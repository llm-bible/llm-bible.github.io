---
layout: publication
title: "Can Large Language Models Reason And Plan?"
authors: Kambhampati Subbarao
conference: "Annals of The New York Academy of Sciences; March"
year: 2024
bibkey: kambhampati2024can
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.04121"}
tags: ['Pretraining Methods']
---
While humans sometimes do show the capability of correcting their own erroneous guesses with self-critiquing there seems to be no basis for that assumption in the case of LLMs.

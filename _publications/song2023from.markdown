---
layout: publication
title: 'Moviechat: From Dense Token To Sparse Memory For Long Video Understanding'
authors: Enxin Song et al.
conference: Arxiv
year: 2023
citations: 26
bibkey: song2023from
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2307.16449'}]
tags: [Transformer, Applications]
---
Recently, integrating video foundation models and large language models to
build a video understanding system can overcome the limitations of specific
pre-defined vision tasks. Yet, existing systems can only handle videos with
very few frames. For long videos, the computation complexity, memory cost, and
long-term temporal connection impose additional challenges. Taking advantage of
the Atkinson-Shiffrin memory model, with tokens in Transformers being employed
as the carriers of memory in combination with our specially designed memory
mechanism, we propose the MovieChat to overcome these challenges. MovieChat
achieves state-of-the-art performance in long video understanding, along with
the released MovieChat-1K benchmark with 1K long video and 14K manual
annotations for validation of the effectiveness of our method.
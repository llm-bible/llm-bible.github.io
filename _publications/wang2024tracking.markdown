---
layout: publication
title: Coglm Tracking Cognitive Development Of Large Language Models
authors: Wang Xinglin, Yuan Peiwen, Feng Shaoxiong, Li Yiwei, Pan Boyuan, Wang Heda, Hu Yao, Li Kan
conference: "Arxiv"
year: 2024
bibkey: wang2024tracking
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.09150"}
tags: ['Efficiency And Optimization', 'GPT', 'Model Architecture', 'Pretraining Methods']
---
Piagets Theory of Cognitive Development (PTC) posits that the development of cognitive levels forms the foundation for human learning across various abilities. As Large Language Models (LLMs) have recently shown remarkable abilities across a wide variety of tasks we are curious about the cognitive levels of current LLMs to what extent they have developed and how this development has been achieved. To this end we construct a benchmark CogLM (Cognitive Ability Evaluation for Language Model) based on PTC to assess the cognitive levels of LLMs. CogLM comprises 1220 questions spanning 10 cognitive abilities crafted by more than 20 human experts providing a comprehensive testbed for the cognitive levels of LLMs. Through extensive experiments across multiple mainstream LLMs with CogLM we find that (1) Human-like cognitive abilities have emerged in advanced LLMs (GPT-4) comparable to those of a 20-year-old human. (2) The parameter size and optimization objective are two key factors affecting the cognitive levels of LLMs. (3) The performance on downstream tasks is positively correlated with the level of cognitive abilities. These findings fill the gap in research on the cognitive abilities of LLMs tracing the development of LLMs from a cognitive perspective and guiding the future direction of their evolution.

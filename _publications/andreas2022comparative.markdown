---
layout: publication
title: A Comparative Study On Language Models For Task45;oriented Dialogue Systems
authors: Andreas Vinsen Marselino, Winata Genta Indra, Purwarianti Ayu
conference: ""
year: 2022
bibkey: andreas2022comparative
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2201.08687"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Training Techniques']
---
The recent development of language models has shown promising results by achieving state45;of45;the45;art performance on various natural language tasks by fine45;tuning pretrained models. In task45;oriented dialogue (ToD) systems language models can be used for end45;to45;end training without relying on dialogue state tracking to track the dialogue history but allowing the language models to generate responses according to the context given as input. This paper conducts a comparative study to show the effectiveness and strength of using recent pretrained models for fine45;tuning such as BART and T5 on endto45;end ToD systems. The experimental results show substantial performance improvements after language model fine45;tuning. The models produce more fluent responses after adding knowledge to the context that guides the model to avoid hallucination and generate accurate entities in the generated responses. Furthermore we found that BART and T5 outperform GPT45;based models in BLEU and F1 scores and achieve state45;of45;the45;art performance in a ToD system.

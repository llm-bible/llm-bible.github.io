---
layout: publication
title: Boosting Language Models Reasoning With Chain45;of45;knowledge Prompting
authors: Wang Jianing, Sun Qiushi, Li Xiang, Gao Ming
conference: "Arxiv"
year: 2023
bibkey: wang2023boosting
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2306.06427"}
tags: ['Ethics And Bias', 'Prompting']
---
Recently Chain45;of45;Thought (CoT) prompting has delivered success on complex reasoning tasks which aims at designing a simple prompt like Lets think step by step or multiple in45;context exemplars with well45;designed rationales to elicit Large Language Models (LLMs) to generate intermediate reasoning steps. However the generated rationales often come with mistakes making unfactual and unfaithful reasoning chains. To mitigate this brittleness we propose a novel Chain45;of45;Knowledge (CoK) prompting where we aim at eliciting LLMs to generate explicit pieces of knowledge evidence in the form of structure triple. This is inspired by our human behaviors i.e. we can draw a mind map or knowledge map as the reasoning evidence in the brain before answering a complex question. Benefiting from CoK we additionally introduce a F^245;Verification method to estimate the reliability of the reasoning chains in terms of factuality and faithfulness. For the unreliable response the wrong evidence can be indicated to prompt the LLM to rethink. Extensive experiments demonstrate that our method can further improve the performance of commonsense factual symbolic and arithmetic reasoning tasks.

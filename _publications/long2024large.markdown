---
layout: publication
title: Large Language Models Know What Makes Exemplary Contexts
authors: Long Quanyu, Chen Jianda, Wang Wenya, Pan Sinno Jialin
conference: "Arxiv"
year: 2024
bibkey: long2024large
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.07505"}
tags: ['Agentic', 'Reinforcement Learning', 'Tools', 'Training Techniques']
---
In45;context learning (ICL) has proven to be a significant capability with the advancement of Large Language models (LLMs). By instructing LLMs using few45;shot demonstrative examples ICL enables them to perform a wide range of tasks without needing to update millions of parameters. This paper presents a unified framework for LLMs that allows them to self45;select influential in45;context examples to compose their contexts; self45;rank candidates with different demonstration compositions; self45;optimize the demonstration selection and ordering through reinforcement learning. Specifically our method designs a parameter45;efficient retrieval head that generates the optimized demonstration after training with rewards from LLMs own preference. Experimental results validate the proposed methods effectiveness in enhancing ICL performance. Additionally our approach effectively identifies and selects the most representative examples for the current task and includes more diversity in retrieval.

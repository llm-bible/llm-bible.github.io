---
layout: publication
title: 'Structured Reasoning For Fairness: A Multi-agent Approach To Bias Detection In Textual Data'
authors: Tianyi Huang, Elsa Fan
conference: "Arxiv"
year: 2025
bibkey: huang2025structured
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2503.00355"}
tags: ['Responsible AI', 'Agentic', 'Tools', 'Ethics and Bias', 'Interpretability and Explainability', 'Bias Mitigation', 'Fairness']
---
From disinformation spread by AI chatbots to AI recommendations that
inadvertently reinforce stereotypes, textual bias poses a significant challenge
to the trustworthiness of large language models (LLMs). In this paper, we
propose a multi-agent framework that systematically identifies biases by
disentangling each statement as fact or opinion, assigning a bias intensity
score, and providing concise, factual justifications. Evaluated on 1,500
samples from the WikiNPOV dataset, the framework achieves 84.9%
accuracy\\(\unicode\{x2014\}\\)an improvement of 13.0% over the zero-shot
baseline\\(\unicode\{x2014\}\\)demonstrating the efficacy of explicitly modeling fact
versus opinion prior to quantifying bias intensity. By combining enhanced
detection accuracy with interpretable explanations, this approach sets a
foundation for promoting fairness and accountability in modern language models.

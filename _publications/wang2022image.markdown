---
layout: publication
title: Image As A Foreign Language Beit Pretraining For All Vision And Vision45;language Tasks
authors: Wang Wenhui, Bao Hangbo, Dong Li, Bjorck Johan, Peng Zhiliang, Liu Qiang, Aggarwal Kriti, Mohammed Owais Khan, Singhal Saksham, Som Subhojit, Wei Furu
conference: "Arxiv"
year: 2022
bibkey: wang2022image
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2208.10442"}
tags: ['Applications', 'BERT', 'Language Modeling', 'Masked Language Model', 'Merging', 'Model Architecture', 'Multimodal Models', 'Pretraining Methods', 'Scaling Laws', 'Training Techniques', 'Transformer']
---
A big convergence of language vision and multimodal pretraining is emerging. In this work we introduce a general45;purpose multimodal foundation model BEiT45;3 which achieves state45;of45;the45;art transfer performance on both vision and vision45;language tasks. Specifically we advance the big convergence from three aspects backbone architecture pretraining task and model scaling up. We introduce Multiway Transformers for general45;purpose modeling where the modular architecture enables both deep fusion and modality45;specific encoding. Based on the shared backbone we perform masked language modeling on images (Imglish) texts (English) and image45;text pairs (parallel sentences) in a unified manner. Experimental results show that BEiT45;3 obtains state45;of45;the45;art performance on object detection (COCO) semantic segmentation (ADE20K) image classification (ImageNet) visual reasoning (NLVR2) visual question answering (VQAv2) image captioning (COCO) and cross45;modal retrieval (Flickr30K COCO).

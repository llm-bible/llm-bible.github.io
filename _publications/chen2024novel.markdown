---
layout: publication
title: M^3cot A Novel Benchmark For Multi45;domain Multi45;step Multi45;modal Chain45;of45;thought
authors: Chen Qiguang, Qin Libo, Zhang Jin, Chen Zhi, Xu Xiao, Che Wanxiang
conference: "Arxiv"
year: 2024
bibkey: chen2024novel
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.16473"}
tags: ['Attention Mechanism', 'Model Architecture', 'Pretraining Methods', 'RAG']
---
Multi45;modal Chain45;of45;Thought (MCoT) requires models to leverage knowledge from both textual and visual modalities for step45;by45;step reasoning which gains increasing attention. Nevertheless the current MCoT benchmark still faces some challenges (1) absence of visual modal reasoning (2) single45;step visual modal reasoning and (3) Domain missing thereby hindering the development of MCoT. Motivated by this we introduce a novel benchmark (M^3CoT) to address the above challenges advancing the multi45;domain multi45;step and multi45;modal CoT. Additionally we conduct a thorough evaluation involving abundant MCoT approaches on Vision Large Language Models (VLLMs). In addition we highlight that the current VLLMs still struggle to correctly reason in M^3CoT and there remains a large gap between existing VLLMs and human performance in M^3CoT despite their superior results on previous MCoT benchmarks. To our knowledge we take the first meaningful step toward the multi45;domain multi45;step and multi45;modal scenario in MCoT. We hope that M^3CoT can serve as a valuable resource providing a pioneering foundation in multi45;domain multi45;step multi45;modal chain45;of45;thought research.

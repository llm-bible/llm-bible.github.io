---
layout: publication
title: METAREFLECTION Learning Instructions For Language Agents Using Past Reflections
authors: Gupta Priyanshu, Kirtania Shashank, Singha Ananya, Gulwani Sumit, Radhakrishna Arjun, Shi Sherry, Soares Gustavo
conference: "Arxiv"
year: 2024
bibkey: gupta2024metareflection
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.13009"}
tags: ['Agentic', 'Applications', 'Efficiency And Optimization', 'GPT', 'Model Architecture', 'Prompting', 'Security', 'Training Techniques']
---
Despite the popularity of Large Language Models (LLMs) crafting specific prompts for LLMs to perform particular tasks remains challenging. Users often engage in multiple conversational turns with an LLM-based agent to accomplish their intended task. Recent studies have demonstrated that linguistic feedback in the form of self-reflections generated by the model can work as reinforcement during these conversations thus enabling quicker convergence to the desired outcome. Motivated by these findings we introduce METAREFLECTION a novel technique that learns general prompt instructions for a specific domain from individual self-reflections gathered during a training phase. We evaluate our technique in two domains Infrastructure as Code (IAC) vulnerability detection and question-answering (QA) using REACT and COT. Our results demonstrate a notable improvement with METARELECTION outperforming GPT-4 by 16.8237; (IAC) 31.3337; (COT) and 15.4237; (REACT) underscoring the potential of METAREFLECTION as a viable method for enhancing the efficiency of LLMs.

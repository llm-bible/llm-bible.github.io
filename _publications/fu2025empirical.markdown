---
layout: publication
title: 'Llmpopcorn: An Empirical Study Of Llms As Assistants For Popular Micro-video Generation'
authors: Junchen Fu, Xuri Ge, Kaiwen Zheng, Ioannis Arapakis, Xin Xin, Joemon M. Jose
conference: "Arxiv"
year: 2025
bibkey: fu2025empirical
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.12945"}
tags: ['Model Architecture', 'Tools', 'Reinforcement Learning', 'Language Modeling', 'GPT', 'Prompting', 'Applications']
---
Popular Micro-videos, dominant on platforms like TikTok and YouTube, hold
significant commercial value. The rise of high-quality AI-generated content has
spurred interest in AI-driven micro-video creation. However, despite the
advanced capabilities of large language models (LLMs) like ChatGPT and DeepSeek
in text generation and reasoning, their potential to assist the creation of
popular micro-videos remains largely unexplored.
  In this paper, we conduct an empirical study on LLM-assisted popular
micro-video generation (LLMPopcorn). Specifically, we investigate the following
research questions: (i) How can LLMs be effectively utilized to assist popular
micro-video generation? (ii) To what extent can prompt-based enhancements
optimize the LLM-generated content for higher popularity? (iii) How well do
various LLMs and video generators perform in the popular micro-video generation
task? By exploring these questions, we show that advanced LLMs like DeepSeek-V3
enable micro-video generation to achieve popularity comparable to human-created
content. Prompt enhancements further boost popularity, and benchmarking
highlights DeepSeek-V3 and DeepSeek-R1 among LLMs, while LTX-Video and
HunyuanVideo lead in video generation. This pioneering work advances
AI-assisted micro-video creation, uncovering new research opportunities. We
will release the code and datasets to support future studies.

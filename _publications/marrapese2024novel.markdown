---
layout: publication
title: A Novel Nuanced Conversation Evaluation Framework For Large Language Models In Mental Health
authors: Marrapese Alexander, Suleiman Basem, Ullah Imdad, Kim Juno
conference: "Arxiv"
year: 2024
bibkey: marrapese2024novel
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.09705"}
tags: ['Ethics And Bias', 'GPT', 'Model Architecture', 'Reinforcement Learning', 'Responsible AI', 'Tools']
---
Understanding the conversation abilities of Large Language Models (LLMs) can help lead to its more cautious and appropriate deployment. This is especially important for safety-critical domains like mental health where someones life may depend on the exact wording of a response to an urgent question. In this paper we propose a novel framework for evaluating the nuanced conversation abilities of LLMs. Within it we develop a series of quantitative metrics developed from literature on using psychotherapy conversation analysis literature. While we ensure that our framework and metrics are transferable by researchers to relevant adjacent domains we apply them to the mental health field. We use our framework to evaluate several popular frontier LLMs including some GPT and Llama models through a verified mental health dataset. Our results show that GPT4 Turbo can perform significantly more similarly to verified therapists than other selected LLMs. We conduct additional analysis to examine how LLM conversation performance varies across specific mental health topics. Our results indicate that GPT4 Turbo performs well in achieving high correlation with verified therapists in particular topics such as Parenting and Relationships. We believe our contributions will help researchers develop better LLMs that in turn will more positively support peoples lives.

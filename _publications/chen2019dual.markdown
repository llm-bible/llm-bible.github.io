---
layout: publication
title: DMRM A Dual45;channel Multi45;hop Reasoning Model For Visual Dialog
authors: Chen Feilong, Meng Fandong, Xu Jiaming, Li Peng, Xu Bo, Zhou Jie
conference: "Arxiv"
year: 2019
bibkey: chen2019dual
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/1912.08360"}
tags: ['Agentic', 'Attention Mechanism', 'Model Architecture', 'Multimodal Models', 'RAG']
---
Visual Dialog is a vision45;language task that requires an AI agent to engage in a conversation with humans grounded in an image. It remains a challenging task since it requires the agent to fully understand a given question before making an appropriate response not only from the textual dialog history but also from the visually45;grounded information. While previous models typically leverage single45;hop reasoning or single45;channel reasoning to deal with this complex multimodal reasoning task which is intuitively insufficient. In this paper we thus propose a novel and more powerful Dual45;channel Multi45;hop Reasoning Model for Visual Dialog named DMRM. DMRM synchronously captures information from the dialog history and the image to enrich the semantic representation of the question by exploiting dual45;channel reasoning. Specifically DMRM maintains a dual channel to obtain the question45; and history45;aware image features and the question45; and image45;aware dialog history features by a mulit45;hop reasoning process in each channel. Additionally we also design an effective multimodal attention to further enhance the decoder to generate more accurate responses. Experimental results on the VisDial v0.9 and v1.0 datasets demonstrate that the proposed model is effective and outperforms compared models by a significant margin.

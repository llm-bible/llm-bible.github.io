---
layout: publication
title: The Promise And Challenges Of Using Llms To Accelerate The Screening Process Of Systematic Reviews
authors: Huotala Aleksi, Kuutila Miikka, Ralph Paul, Mäntylä Mika
conference: "Arxiv"
year: 2024
bibkey: huotala2024promise
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.15667"}
tags: ['GPT', 'Model Architecture', 'Prompting', 'RAG', 'Survey Paper']
---
Systematic review (SR) is a popular research method in software engineering (SE). However conducting an SR takes an average of 67 weeks. Thus automating any step of the SR process could reduce the effort associated with SRs. Our objective is to investigate if Large Language Models (LLMs) can accelerate title45;abstract screening by simplifying abstracts for human screeners and automating title45;abstract screening. We performed an experiment where humans screened titles and abstracts for 20 papers with both original and simplified abstracts from a prior SR. The experiment with human screeners was reproduced with GPT45;3.5 and GPT45;4 LLMs to perform the same screening tasks. We also studied if different prompting techniques (Zero45;shot (ZS) One45;shot (OS) Few45;shot (FS) and Few45;shot with Chain45;of45;Thought (FS45;CoT)) improve the screening performance of LLMs. Lastly we studied if redesigning the prompt used in the LLM reproduction of screening leads to improved performance. Text simplification did not increase the screeners screening performance but reduced the time used in screening. Screeners scientific literacy skills and researcher status predict screening performance. Some LLM and prompt combinations perform as well as human screeners in the screening tasks. Our results indicate that the GPT45;4 LLM is better than its predecessor GPT45;3.5. Additionally Few45;shot and One45;shot prompting outperforms Zero45;shot prompting. Using LLMs for text simplification in the screening process does not significantly improve human performance. Using LLMs to automate title45;abstract screening seems promising but current LLMs are not significantly more accurate than human screeners. To recommend the use of LLMs in the screening process of SRs more research is needed. We recommend future SR studies publish replication packages with screening data to enable more conclusive experimenting with LLM screening.

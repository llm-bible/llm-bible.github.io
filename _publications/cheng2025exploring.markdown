---
layout: publication
title: 'Exploring Typographic Visual Prompts Injection Threats In Cross-modality Generation Models'
authors: Hao Cheng, Erjia Xiao, Yichi Wang, Kaidi Xu, Mengshu Sun, Jindong Gu, Renjing Xu
conference: "Arxiv"
year: 2025
bibkey: cheng2025exploring
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2503.11519"}
tags: ['Security', 'Model Architecture', 'Multimodal Models', 'Reinforcement Learning', 'Fine-Tuning', 'Prompting', 'Applications', 'Attention Mechanism']
---
Current Cross-Modality Generation Models (GMs) demonstrate remarkable
capabilities in various generative tasks. Given the ubiquity and information
richness of vision modality inputs in real-world scenarios, Cross-vision,
encompassing Vision-Language Perception (VLP) and Image-to-Image (I2I), tasks
have attracted significant attention. Large Vision Language Models (LVLMs) and
I2I GMs are employed to handle VLP and I2I tasks, respectively. Previous
research indicates that printing typographic words into input images
significantly induces LVLMs and I2I GMs to generate disruptive outputs
semantically related to those words. Additionally, visual prompts, as a more
sophisticated form of typography, are also revealed to pose security risks to
various applications of VLP tasks when injected into images. In this paper, we
comprehensively investigate the performance impact induced by Typographic
Visual Prompt Injection (TVPI) in various LVLMs and I2I GMs. To better observe
performance modifications and characteristics of this threat, we also introduce
the TVPI Dataset. Through extensive explorations, we deepen the understanding
of the underlying causes of the TVPI threat in various GMs and offer valuable
insights into its potential origins.

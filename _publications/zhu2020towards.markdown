---
layout: publication
title: Towards Understanding Sample Variance In Visually Grounded Language Generation Evaluations And Observations
authors: Zhu Wanrong, Wang Xin Eric, Narayana Pradyumna, Sone Kazoo, Basu Sugato, Wang William Yang
conference: "Arxiv"
year: 2020
bibkey: zhu2020towards
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2010.03644"}
tags: ['Attention Mechanism', 'Model Architecture', 'Reinforcement Learning']
---
A major challenge in visually grounded language generation is to build robust benchmark datasets and models that can generalize well in real45;world settings. To do this it is critical to ensure that our evaluation protocols are correct and benchmarks are reliable. In this work we set forth to design a set of experiments to understand an important but often ignored problem in visually grounded language generation given that humans have different utilities and visual attention how will the sample variance in multi45;reference datasets affect the models performance Empirically we study several multi45;reference datasets and corresponding vision45;and45;language tasks. We show that it is of paramount importance to report variance in experiments; that human45;generated references could vary drastically in different datasets/tasks revealing the nature of each task; that metric45;wise CIDEr has shown systematically larger variances than others. Our evaluations on reference45;per45;instance shed light on the design of reliable datasets in the future.

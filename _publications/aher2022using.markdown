---
layout: publication
title: Using Large Language Models To Simulate Multiple Humans And Replicate Human
  Subject Studies
authors: Gati Aher, Rosa I. Arriaga, Adam Tauman Kalai
conference: Arxiv
year: 2022
citations: 69
bibkey: aher2022using
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2208.10264'}]
tags: [Applications, GPT]
---
We introduce a new type of test, called a Turing Experiment (TE), for
evaluating to what extent a given language model, such as GPT models, can
simulate different aspects of human behavior. A TE can also reveal consistent
distortions in a language model's simulation of a specific human behavior.
Unlike the Turing Test, which involves simulating a single arbitrary
individual, a TE requires simulating a representative sample of participants in
human subject research. We carry out TEs that attempt to replicate
well-established findings from prior studies. We design a methodology for
simulating TEs and illustrate its use to compare how well different language
models are able to reproduce classic economic, psycholinguistic, and social
psychology experiments: Ultimatum Game, Garden Path Sentences, Milgram Shock
Experiment, and Wisdom of Crowds. In the first three TEs, the existing findings
were replicated using recent models, while the last TE reveals a
"hyper-accuracy distortion" present in some language models (including ChatGPT
and GPT-4), which could affect downstream applications in education and the
arts.
---
layout: publication
title: Exploring Recommendation Capabilities Of Gpt-4v(ision) A Preliminary Case Study
authors: Zhou Peilin, Cao Meng, Huang You-liang, Ye Qichen, Zhang Peiyan, Liu Junling, Xie Yueqi, Hua Yining, Kim Jaeboum
conference: "Arxiv"
year: 2023
bibkey: zhou2023exploring
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2311.04199"}
  - {name: "Code", url: "https://github.com/PALIN2018/Evaluate_GPT-4V_Rec"}
tags: ['Applications', 'GPT', 'Has Code', 'Model Architecture', 'Multimodal Models', 'Prompting', 'Reinforcement Learning']
---
Large Multimodal Models (LMMs) have demonstrated impressive performance across various vision and language tasks yet their potential applications in recommendation tasks with visual assistance remain unexplored. To bridge this gap we present a preliminary case study investigating the recommendation capabilities of GPT-4V(ison) a recently released LMM by OpenAI. We construct a series of qualitative test samples spanning multiple domains and employ these samples to assess the quality of GPT-4Vs responses within recommendation scenarios. Evaluation results on these test samples prove that GPT-4V has remarkable zero-shot recommendation abilities across diverse domains thanks to its robust visual-text comprehension capabilities and extensive general knowledge. However we have also identified some limitations in using GPT-4V for recommendations including a tendency to provide similar responses when given similar inputs. This report concludes with an in-depth discussion of the challenges and research opportunities associated with utilizing GPT-4V in recommendation scenarios. Our objective is to explore the potential of extending LMMs from vision and language tasks to recommendation tasks. We hope to inspire further research into next-generation multimodal generative recommendation models which can enhance user experiences by offering greater diversity and interactivity. All images and prompts used in this report will be accessible at https://github.com/PALIN2018/Evaluate\_GPT-4V\_Rec.

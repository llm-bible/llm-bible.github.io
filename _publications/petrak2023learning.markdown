---
layout: publication
title: Learning From Free45;text Human Feedback 45;45; Collect New Datasets Or Extend Existing Ones
authors: Petrak Dominic, Moosavi Nafise Sadat, Tian Ye, Rozanov Nikolai, Gurevych Iryna
conference: "Arxiv"
year: 2023
bibkey: petrak2023learning
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.15758"}
tags: ['GPT', 'Model Architecture', 'Reinforcement Learning']
---
Learning from free45;text human feedback is essential for dialog systems but annotated data is scarce and usually covers only a small fraction of error types known in conversational AI. Instead of collecting and annotating new datasets from scratch recent advances in synthetic dialog generation could be used to augment existing dialog datasets with the necessary annotations. However to assess the feasibility of such an effort it is important to know the types and frequency of free45;text human feedback included in these datasets. In this work we investigate this question for a variety of commonly used dialog datasets including MultiWoZ SGD BABI PersonaChat Wizards45;of45;Wikipedia and the human45;bot split of the Self45;Feeding Chatbot. Using our observations we derive new taxonomies for the annotation of free45;text human feedback in dialogs and investigate the impact of including such data in response generation for three SOTA language generation models including GPT45;2 LLAMA and Flan45;T5. Our findings provide new insights into the composition of the datasets examined including error types user response types and the relations between them.

---
layout: publication
title: 'Newsinterview: A Dataset And A Playground To Evaluate Llms'' Ground Gap Via Informational Interviews'
authors: Michael Lu, Hyundong Justin Cho, Weiyan Shi, Jonathan May, Alexander Spangher
conference: "Arxiv"
year: 2024
bibkey: lu2024dataset
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2411.13779"}
tags: ['Agentic', 'Reinforcement Learning']
---
Large Language Models (LLMs) have demonstrated impressive capabilities in
generating coherent text but often struggle with grounding language and
strategic dialogue. To address this gap, we focus on journalistic interviews, a
domain rich in grounding communication and abundant in data. We curate a
dataset of 40,000 two-person informational interviews from NPR and CNN, and
reveal that LLMs are significantly less likely than human interviewers to use
acknowledgements and to pivot to higher-level questions. Realizing that a
fundamental deficit exists in multi-turn planning and strategic thinking, we
develop a realistic simulated environment, incorporating source personas and
persuasive elements, in order to facilitate the development of agents with
longer-horizon rewards. Our experiments show that while source LLMs mimic human
behavior in information sharing, interviewer LLMs struggle with recognizing
when questions are answered and engaging persuasively, leading to suboptimal
information extraction across model size and capability. These findings
underscore the need for enhancing LLMs' strategic dialogue capabilities.

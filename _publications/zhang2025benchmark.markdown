---
layout: publication
title: 'Ontourl: A Benchmark For Evaluating Large Language Models On Symbolic Ontological Understanding, Reasoning And Learning'
authors: Xiao Zhang, Huiyuan Lai, Qianru Meng, Johan Bos
conference: "Arxiv"
year: 2025
bibkey: zhang2025benchmark
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2505.11031"}
tags: ['Reinforcement Learning']
---
Large language models (LLMs) have demonstrated remarkable capabilities across a range of natural language processing tasks, yet their ability to process structured symbolic knowledge remains underexplored. To address this gap, we propose a taxonomy of LLMs' ontological capabilities and introduce OntoURL, the first comprehensive benchmark designed to systematically evaluate LLMs' proficiency in handling ontologies -- formal, symbolic representations of domain knowledge through concepts, relationships, and instances. Based on the proposed taxonomy, OntoURL systematically assesses three dimensions: understanding, reasoning, and learning through 15 distinct tasks comprising 58,981 questions derived from 40 ontologies across 8 domains. Experiments with 20 open-source LLMs reveal significant performance differences across models, tasks, and domains, with current LLMs showing proficiency in understanding ontological knowledge but substantial weaknesses in reasoning and learning tasks. These findings highlight fundamental limitations in LLMs' capability to process symbolic knowledge and establish OntoURL as a critical benchmark for advancing the integration of LLMs with formal knowledge representations.

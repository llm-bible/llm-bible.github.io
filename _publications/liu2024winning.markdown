---
layout: publication
title: 'Toolace: Winning The Points Of LLM Function Calling'
authors: Weiwen Liu, Xu Huang, Xingshan Zeng, Xinlong Hao, Shuai Yu, Dexun Li, Shuai Wang, Weinan Gan, Zhengying Liu, Yuanqing Yu, Zezhong Wang, Yuxian Wang, Wu Ning, Yutai Hou, Bin Wang, Chuhan Wu, Xinzhi Wang, Yong Liu, Yasheng Wang, Duyu Tang, Dandan Tu, Lifeng Shang, Xin Jiang, Ruiming Tang, Defu Lian, Qun Liu, Enhong Chen
conference: "Arxiv"
year: 2024
bibkey: liu2024winning
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2409.00920"}
tags: ['Agentic', 'GPT', 'Tools', 'RAG', 'Model Architecture', 'Training Techniques']
---
Function calling significantly extends the application boundary of large
language models, where high-quality and diverse training data is critical for
unlocking this capability. However, real function-calling data is quite
challenging to collect and annotate, while synthetic data generated by existing
pipelines tends to lack coverage and accuracy. In this paper, we present
ToolACE, an automatic agentic pipeline designed to generate accurate, complex,
and diverse tool-learning data. ToolACE leverages a novel self-evolution
synthesis process to curate a comprehensive API pool of 26,507 diverse APIs.
Dialogs are further generated through the interplay among multiple agents,
guided by a formalized thinking process. To ensure data accuracy, we implement
a dual-layer verification system combining rule-based and model-based checks.
We demonstrate that models trained on our synthesized data, even with only 8B
parameters, achieve state-of-the-art performance on the Berkeley
Function-Calling Leaderboard, rivaling the latest GPT-4 models. Our model and a
subset of the data are publicly available at https://huggingface.co/Team-ACE.

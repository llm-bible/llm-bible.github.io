---
layout: publication
title: Toolace Winning The Points Of LLM Function Calling
authors: Liu Weiwen, Huang Xu, Zeng Xingshan, Hao Xinlong, Yu Shuai, Li Dexun, Wang Shuai, Gan Weinan, Liu Zhengying, Yu Yuanqing, Wang Zezhong, Wang Yuxian, Ning Wu, Hou Yutai, Wang Bin, Wu Chuhan, Wang Xinzhi, Liu Yong, Wang Yasheng, Tang Duyu, Tu Dandan, Shang Lifeng, Jiang Xin, Tang Ruiming, Lian Defu, Liu Qun, Chen Enhong
conference: "Arxiv"
year: 2024
bibkey: liu2024winning
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2409.00920"}
tags: ['Agentic', 'GPT', 'Model Architecture', 'Pretraining Methods', 'RAG', 'Tools', 'Training Techniques']
---
Function calling significantly extends the application boundary of large language models where high45;quality and diverse training data is critical for unlocking this capability. However real function45;calling data is quite challenging to collect and annotate while synthetic data generated by existing pipelines tends to lack coverage and accuracy. In this paper we present ToolACE an automatic agentic pipeline designed to generate accurate complex and diverse tool45;learning data. ToolACE leverages a novel self45;evolution synthesis process to curate a comprehensive API pool of 26507 diverse APIs. Dialogs are further generated through the interplay among multiple agents guided by a formalized thinking process. To ensure data accuracy we implement a dual45;layer verification system combining rule45;based and model45;based checks. We demonstrate that models trained on our synthesized data even with only 8B parameters achieve state45;of45;the45;art performance on the Berkeley Function45;Calling Leaderboard rivaling the latest GPT45;4 models. Our model and a subset of the data are publicly available at https://huggingface.co/Team&#45;ACE.

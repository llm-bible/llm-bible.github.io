---
layout: publication
title: Helpful or Harmful Exploring the Efficacy of Large Language Models for Online Grooming Prevention
authors: Prosser Ellie, Edwards Matthew
conference: "Arxiv"
year: 2024
bibkey: prosser2024helpful
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.09795"}
tags: ['Applications', 'Prompting', 'Reinforcement Learning', 'Responsible AI', 'Tools']
---
Powerful generative Large Language Models (LLMs) are becoming popular tools amongst the general public as question-answering systems and are being utilised by vulnerable groups such as children. With children increasingly interacting with these tools it is imperative for researchers to scrutinise the safety of LLMs especially for applications that could lead to serious outcomes such as online child safety queries. In this paper the efficacy of LLMs for online grooming prevention is explored both for identifying and avoiding grooming through advice generation and the impact of prompt design on model performance is investigated by varying the provided context and prompt specificity. In results reflecting over 6000 LLM interactions we find that no models were clearly appropriate for online grooming prevention with an observed lack of consistency in behaviours and potential for harmful answer generation especially from open-source models. We outline where and how models fall short providing suggestions for improvement and identify prompt designs that heavily altered model performance in troubling ways with findings that can be used to inform best practice usage guides.

---
layout: publication
title: Zhujiu A Multi45;dimensional Multi45;faceted Chinese Benchmark For Large Language Models
authors: Zhang Baoli, Xie Haining, Du Pengfan, Chen Junhao, Cao Pengfei, Chen Yubo, Liu Shengping, Liu Kang, Zhao Jun
conference: "Arxiv"
year: 2023
bibkey: zhang2023multi
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2308.14353"}
tags: ['Pretraining Methods', 'RAG']
---
The unprecedented performance of large language models (LLMs) requires comprehensive and accurate evaluation. We argue that for LLMs evaluation benchmarks need to be comprehensive and systematic. To this end we propose the ZhuJiu benchmark which has the following strengths (1) Multi45;dimensional ability coverage We comprehensively evaluate LLMs across 7 ability dimensions covering 51 tasks. Especially we also propose a new benchmark that focuses on knowledge ability of LLMs. (2) Multi45;faceted evaluation methods collaboration We use 3 different yet complementary evaluation methods to comprehensively evaluate LLMs which can ensure the authority and accuracy of the evaluation results. (3) Comprehensive Chinese benchmark ZhuJiu is the pioneering benchmark that fully assesses LLMs in Chinese while also providing equally robust evaluation abilities in English. (4) Avoiding potential data leakage To avoid data leakage we construct evaluation data specifically for 37 tasks. We evaluate 10 current mainstream LLMs and conduct an in45;depth discussion and analysis of their results. The ZhuJiu benchmark and open45;participation leaderboard are publicly released at http://www.zhujiu&#45;benchmark.com/ and we also provide a demo video at https://youtu.be/qypkJ89L1Ic.

---
layout: publication
title: Biasalert A Plug45;and45;play Tool For Social Bias Detection In Llms
authors: Fan Zhiting, Chen Ruizhe, Xu Ruiling, Liu Zuozhu
conference: "Arxiv"
year: 2024
bibkey: fan2024plug
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.10241"}
tags: ['Applications', 'Bias Mitigation', 'Ethics And Bias', 'GPT', 'Language Modeling', 'Model Architecture', 'Tools']
---
Evaluating the bias in Large Language Models (LLMs) becomes increasingly crucial with their rapid development. However existing evaluation methods rely on fixed45;form outputs and cannot adapt to the flexible open45;text generation scenarios of LLMs (e.g. sentence completion and question answering). To address this we introduce BiasAlert a plug45;and45;play tool designed to detect social bias in open45;text generations of LLMs. BiasAlert integrates external human knowledge with inherent reasoning capabilities to detect bias reliably. Extensive experiments demonstrate that BiasAlert significantly outperforms existing state45;of45;the45;art methods like GPT445;as45;A45;Judge in detecting bias. Furthermore through application studies we demonstrate the utility of BiasAlert in reliable LLM bias evaluation and bias mitigation across various scenarios. Model and code will be publicly released.

---
layout: publication
title: From LLM to Conversational Agent A Memory Enhanced Architecture with Fine-Tuning of Large Language Models
authors: Liu Na, Chen Liangyu, Tian Xiaoyu, Zou Wei, Chen Kaijiang, Cui Ming
conference: "Arxiv"
year: 2024
bibkey: liu2024from
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.02777"}
tags: ['ARXIV', 'Agentic', 'Applications', 'Fine Tuning', 'GPT', 'LLM', 'Pretraining Methods', 'Tools']
---
This paper introduces RAISE (Reasoning and Acting through Scratchpad and Examples) an advanced architecture enhancing the integration of Large Language Models (LLMs) like GPT-4 into conversational agents. RAISE an enhancement of the ReAct framework incorporates a dual-component memory system mirroring human short-term and long-term memory to maintain context and continuity in conversations. It entails a comprehensive agent construction scenario including phases like Conversation Selection Scene Extraction CoT Completion and Scene Augmentation leading to the LLMs Training phase. This approach appears to enhance agent controllability and adaptability in complex multi-turn dialogues. Our preliminary evaluations in a real estate sales context suggest that RAISE has some advantages over traditional agents indicating its potential for broader applications. This work contributes to the AI field by providing a robust framework for developing more context-aware and versatile conversational agents.

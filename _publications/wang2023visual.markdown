---
layout: publication
title: VIGC Visual Instruction Generation And Correction
authors: Bin Wang, Fan Wu, Xiao Han, Jiahui Peng, Huaping Zhong, Pan Zhang, Xiaoyi Dong, Weijia Li, Wei Li, Jiaqi Wang, Conghui He
conference: "Arxiv"
year: 2023
bibkey: wang2023visual
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/http://arxiv.org/abs/2308.12714v3"}
  - {name: "Code", url: "https://opendatalab.github.io/VIGC"}
tags: ['GPT', 'Has Code', 'Model Architecture', 'Multimodal Models', 'RAG', 'Tools']
---
The integration of visual encoders and large language models (LLMs) has driven recent progress in multimodal large language models (MLLMs). However the scarcity of high45;quality instruction45;tuning data for vision45;language tasks remains a challenge. The current leading paradigm such as LLaVA relies on language45;only GPT45;4 to generate data which requires pre45;annotated image captions and detection bounding boxes suffering from understanding image details. A practical solution to this problem would be to utilize the available multimodal large language models (MLLMs) to generate instruction data for vision45;language tasks. However its worth noting that the currently accessible MLLMs are not as powerful as their LLM counterparts as they tend to produce inadequate responses and generate false information. As a solution for addressing the current issue this paper proposes the Visual Instruction Generation and Correction (VIGC) framework that enables multimodal large language models to generate instruction45;tuning data and progressively enhance its quality on45;the45;fly. Specifically Visual Instruction Generation (VIG) guides the vision45;language model to generate diverse instruction45;tuning data. To ensure generation quality Visual Instruction Correction (VIC) adopts an iterative update mechanism to correct any inaccuracies in data produced by VIG effectively reducing the risk of hallucination. Leveraging the diverse high45;quality data generated by VIGC we finetune mainstream models and validate data quality based on various evaluations. Experimental results demonstrate that VIGC not only compensates for the shortcomings of language45;only data generation methods but also effectively enhances the benchmark performance. The models datasets and code are available at https://opendatalab.github.io/VIGC.

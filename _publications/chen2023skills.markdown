---
layout: publication
title: Skills45;in45;context Prompting Unlocking Compositionality In Large Language Models
authors: Chen Jiaao, Pan Xiaoman, Yu Dian, Song Kaiqiang, Wang Xiaoyang, Yu Dong, Chen Jianshu
conference: "Arxiv"
year: 2023
bibkey: chen2023skills
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2308.00304"}
tags: ['Pretraining Methods', 'Prompting', 'Reinforcement Learning', 'Tools', 'Training Techniques']
---
We investigate how to elicit compositional generalization capabilities in large language models (LLMs). Compositional generalization empowers LLMs to solve complex problems by combining foundational skills a critical reasoning ability akin to human intelligence. However even the most advanced LLMs currently struggle with this form of reasoning. We examine this problem within the framework of in45;context learning and find that demonstrating both foundational skills and compositional examples grounded in these skills within the same prompt context is crucial. We refer to this prompt structure as skills45;in45;context (SKiC). With as few as two exemplars this in45;context learning structure enables LLMs to tackle more challenging problems requiring innovative skill combinations achieving near45;perfect systematic generalization across a broad range of tasks. Intriguingly SKiC also unlocks the latent potential of LLMs allowing them to more actively utilize pre45;existing internal skills acquired during earlier pretraining stages to solve complex reasoning problems. The SKiC structure is robust across different skill constructions and exemplar choices and demonstrates strong transferability to new tasks. Finally inspired by our in45;context learning study we show that fine45;tuning LLMs with SKiC45;style data can elicit zero45;shot weak45;to45;strong generalization enabling the models to solve much harder problems directly with standard prompting.

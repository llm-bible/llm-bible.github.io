---
layout: publication
title: 'Vision Language Models As Values Detectors'
authors: Giulio Antonio Abbo, Tony Belpaeme
conference: "Arxiv"
year: 2025
bibkey: abbo2025vision
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2501.03957"}
tags: ['Training Techniques', 'Model Architecture', 'GPT', 'Fine-Tuning', 'Prompting', 'Applications']
---
Large Language Models integrating textual and visual inputs have introduced
new possibilities for interpreting complex data. Despite their remarkable
ability to generate coherent and contextually relevant text based on visual
stimuli, the alignment of these models with human perception in identifying
relevant elements in images requires further exploration. This paper
investigates the alignment between state-of-the-art LLMs and human annotators
in detecting elements of relevance within home environment scenarios. We
created a set of twelve images depicting various domestic scenarios and
enlisted fourteen annotators to identify the key element in each image. We then
compared these human responses with outputs from five different LLMs, including
GPT-4o and four LLaVA variants. Our findings reveal a varied degree of
alignment, with LLaVA 34B showing the highest performance but still scoring
low. However, an analysis of the results highlights the models' potential to
detect value-laden elements in images, suggesting that with improved training
and refined prompts, LLMs could enhance applications in social robotics,
assistive technologies, and human-computer interaction by providing deeper
insights and more contextually relevant responses.

---
layout: publication
title: Mirror A Multiple45;perspective Self45;reflection Method For Knowledge45;rich Reasoning
authors: Yan Hanqi, Zhu Qinglin, Wang Xinyu, Gui Lin, He Yulan
conference: "Arxiv"
year: 2024
bibkey: yan2024multiple
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.14963"}
tags: ['Agentic', 'Efficiency And Optimization', 'Pretraining Methods', 'RAG', 'Reinforcement Learning']
---
While Large language models (LLMs) have the capability to iteratively reflect on their own outputs recent studies have observed their struggles with knowledge45;rich problems without access to external resources. In addition to the inefficiency of LLMs in self45;assessment we also observe that LLMs struggle to revisit their predictions despite receiving explicit negative feedback. Therefore We propose Mirror a Multiple45;perspective self45;reflection method for knowledge45;rich reasoning to avoid getting stuck at a particular reflection iteration. Mirror enables LLMs to reflect from multiple45;perspective clues achieved through a heuristic interaction between a Navigator and a Reasoner. It guides agents toward diverse yet plausibly reliable reasoning trajectory without access to ground truth by encouraging (1) diversity of directions generated by Navigator and (2) agreement among strategically induced perturbations in responses generated by the Reasoner. The experiments on five reasoning datasets demonstrate that Mirrors superiority over several contemporary self45;reflection approaches. Additionally the ablation study studies clearly indicate that our strategies alleviate the aforementioned challenges.

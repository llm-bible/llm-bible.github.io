---
layout: publication
title: Shieldgemma: Generative AI Content Moderation Based On Gemma
authors: Zeng Wenjun, Liu Yuchi, Mullins Ryan, Peran Ludovic, Fernandez Joe, Harkous Hamza, Narasimhan Karthik, Proud Drew, Kumar Piyush, Radharapu Bhaktipriya, Sturman Olivia, Wahltinez Oscar
conference: "Arxiv"
year: 2024
bibkey: zeng2024generative
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.21772"}
tags: ['Ethics And Bias', 'Responsible AI']
---
We present ShieldGemma a comprehensive suite of LLM-based safety content moderation models built upon Gemma2. These models provide robust state-of-the-art predictions of safety risks across key harm types (sexually explicit dangerous content harassment hate speech) in both user input and LLM-generated output. By evaluating on both public and internal benchmarks we demonstrate superior performance compared to existing models such as Llama Guard (+10.837; AU-PRC on public benchmarks) and WildCard (+4.337;). Additionally we present a novel LLM-based data curation pipeline adaptable to a variety of safety-related tasks and beyond. We have shown strong generalization performance for model trained mainly on synthetic data. By releasing ShieldGemma we provide a valuable resource to the research community advancing LLM safety and enabling the creation of more effective content moderation solutions for developers.

---
layout: publication
title: 'Pay Attention To What Matters'
authors: Pedro Luiz Silva, Antonio De Domenico, Ali Maatouk, Fadhel Ayed
conference: "Arxiv"
year: 2024
bibkey: silva2024pay
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2409.19001'}
tags: ['Attention Mechanism', 'Transformer', 'Training Techniques', 'Model Architecture', 'Fine-Tuning', 'Prompting', 'Reinforcement Learning', 'Pretraining Methods']
---
Despite the remarkable success of Large Language Models (LLMs), they still
exhibit a limited capability to align their outputs to the user instructions.
In this work, we introduce a simple and effective method, which we name GUIDE,
that mechanistically increases attention scores in instruction tokens. To
support this operation, we present Influence, a novel metric that highlights
how the user's instructions propagate through the transformer layers and impact
the LLM output. Our results show that GUIDE improves the accuracy of following
instructions 29.4 % to 60.4%, outperforming natural prompting alternatives and
Supervised Fine-Tuning up to 1M tokens.

---
layout: publication
title: Unveiling The Impact Of Multi45;modal Interactions On User Engagement A Comprehensive Evaluation In Ai45;driven Conversations
authors: Zhang Lichao, Yu Jia, Zhang Shuai, Li Long, Zhong Yangyang, Liang Guanbao, Yan Yuming, Ma Qing, Weng Fangsheng, Pan Fayu, Li Jing, Xu Renjun, Lan Zhenzhong
conference: "Arxiv"
year: 2024
bibkey: zhang2024unveiling
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.15000"}
tags: ['Ethics And Bias']
---
Large Language Models (LLMs) have significantly advanced user45;bot interactions enabling more complex and coherent dialogues. However the prevalent text45;only modality might not fully exploit the potential for effective user engagement. This paper explores the impact of multi45;modal interactions which incorporate images and audio alongside text on user engagement in chatbot conversations. We conduct a comprehensive analysis using a diverse set of chatbots and real45;user interaction data employing metrics such as retention rate and conversation length to evaluate user engagement. Our findings reveal a significant enhancement in user engagement with multi45;modal interactions compared to text45;only dialogues. Notably the incorporation of a third modality significantly amplifies engagement beyond the benefits observed with just two modalities. These results suggest that multi45;modal interactions optimize cognitive processing and facilitate richer information comprehension. This study underscores the importance of multi45;modality in chatbot design offering valuable insights for creating more engaging and immersive AI communication experiences and informing the broader AI community about the benefits of multi45;modal interactions in enhancing user engagement.

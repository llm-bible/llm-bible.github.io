---
layout: publication
title: 'Towards Quantifying Commonsense Reasoning With Mechanistic Insights'
authors: Abhinav Joshi, Areeb Ahmad, Divyaksh Shukla, Ashutosh Modi
conference: "Arxiv"
year: 2025
bibkey: joshi2025towards
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2504.10077'}
tags: ['Reinforcement Learning', 'Prompting']
---
Commonsense reasoning deals with the implicit knowledge that is well
understood by humans and typically acquired via interactions with the world. In
recent times, commonsense reasoning and understanding of various LLMs have been
evaluated using text-based tasks. In this work, we argue that a proxy of this
understanding can be maintained as a graphical structure that can further help
to perform a rigorous evaluation of commonsense reasoning abilities about
various real-world activities. We create an annotation scheme for capturing
this implicit knowledge in the form of a graphical structure for 37 daily human
activities. We find that the created resource can be used to frame an enormous
number of commonsense queries (~ 10^\{17\}), facilitating rigorous evaluation of
commonsense reasoning in LLMs. Moreover, recently, the remarkable performance
of LLMs has raised questions about whether these models are truly capable of
reasoning in the wild and, in general, how reasoning occurs inside these
models. In this resource paper, we bridge this gap by proposing design
mechanisms that facilitate research in a similar direction. Our findings
suggest that the reasoning components are localized in LLMs that play a
prominent role in decision-making when prompted with a commonsense query.

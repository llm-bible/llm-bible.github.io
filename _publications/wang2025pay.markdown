---
layout: publication
title: 'Pay More Attention To The Robustness Of Prompt For Instruction Data Mining'
authors: Qiang Wang, Dawei Feng, Xu Zhang, Ao Shen, Yang Xu, Bo Ding, Huaimin Wang
conference: "Arxiv"
year: 2025
bibkey: wang2025pay
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2503.24028"}
tags: ['Fine-Tuning', 'Tools', 'Model Architecture', 'Security', 'Training Techniques', 'Attention Mechanism', 'KDD', 'Pretraining Methods', 'Prompting']
---
Instruction tuning has emerged as a paramount method for tailoring the
behaviors of LLMs. Recent work has unveiled the potential for LLMs to achieve
high performance through fine-tuning with a limited quantity of high-quality
instruction data. Building upon this approach, we further explore the impact of
prompt's robustness on the selection of high-quality instruction data. This
paper proposes a pioneering framework of high-quality online instruction data
mining for instruction tuning, focusing on the impact of prompt's robustness on
the data mining process. Our notable innovation, is to generate the adversarial
instruction data by conducting the attack for the prompt of online instruction
data. Then, we introduce an Adversarial Instruction-Following Difficulty metric
to measure how much help the adversarial instruction data can provide to the
generation of the corresponding response. Apart from it, we propose a novel
Adversarial Instruction Output Embedding Consistency approach to select
high-quality online instruction data. We conduct extensive experiments on two
benchmark datasets to assess the performance. The experimental results serve to
underscore the effectiveness of our proposed two methods. Moreover, the results
underscore the critical practical significance of considering prompt's
robustness.

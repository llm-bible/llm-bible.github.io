---
layout: publication
title: 'Benchmarking Vlms'' Reasoning About Persuasive Atypical Images'
authors: Sina Malakouti, Aysan Aghazadeh, Ashmit Khandelwal, Adriana Kovashka
conference: "Arxiv"
year: 2024
bibkey: malakouti2024benchmarking
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2409.10719'}
tags: ['Uncategorized']
---
Vision language models (VLMs) have shown strong zero-shot generalization
across various tasks, especially when integrated with large language models
(LLMs). However, their ability to comprehend rhetorical and persuasive visual
media, such as advertisements, remains understudied. Ads often employ atypical
imagery, using surprising object juxtapositions to convey shared properties.
For example, Fig. 1 (e) shows a beer with a feather-like texture. This requires
advanced reasoning to deduce that this atypical representation signifies the
beer's lightness. We introduce three novel tasks, Multi-label Atypicality
Classification, Atypicality Statement Retrieval, and Aypical Object
Recognition, to benchmark VLMs' understanding of atypicality in persuasive
images. We evaluate how well VLMs use atypicality to infer an ad's message and
test their reasoning abilities by employing semantically challenging negatives.
Finally, we pioneer atypicality-aware verbalization by extracting comprehensive
image descriptions sensitive to atypical elements. Our findings reveal that:
(1) VLMs lack advanced reasoning capabilities compared to LLMs; (2) simple,
effective strategies can extract atypicality-aware information, leading to
comprehensive image verbalization; (3) atypicality aids persuasive
advertisement understanding. Code and data will be made available.

---
layout: publication
title: 'Turing Representational Similarity Analysis (RSA): A Flexible Method For Measuring Alignment Between Human And Artificial Intelligence'
authors: Mattson Ogg, Ritwik Bose, Jamie Scharf, Christopher Ratto, Michael Wolmetz
conference: "Arxiv"
year: 2024
bibkey: ogg2024turing
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2412.00577'}
tags: ['RAG', 'GPT', 'Model Architecture', 'Prompting', 'Reinforcement Learning']
---
As we consider entrusting Large Language Models (LLMs) with key societal and
decision-making roles, measuring their alignment with human cognition becomes
critical. This requires methods that can assess how these systems represent
information and facilitate comparisons to human understanding across diverse
tasks. To meet this need, we developed Turing Representational Similarity
Analysis (RSA), a method that uses pairwise similarity ratings to quantify
alignment between AIs and humans. We tested this approach on semantic alignment
across text and image modalities, measuring how different Large Language and
Vision Language Model (LLM and VLM) similarity judgments aligned with human
responses at both group and individual levels. GPT-4o showed the strongest
alignment with human performance among the models we tested, particularly when
leveraging its text processing capabilities rather than image processing,
regardless of the input modality. However, no model we studied adequately
captured the inter-individual variability observed among human participants.
This method helped uncover certain hyperparameters and prompts that could steer
model behavior to have more or less human-like qualities at an inter-individual
or group level. Turing RSA enables the efficient and flexible quantification of
human-AI alignment and complements existing accuracy-based benchmark tasks. We
demonstrate its utility across multiple modalities (words, sentences, images)
for understanding how LLMs encode knowledge and for examining representational
alignment with human cognition.

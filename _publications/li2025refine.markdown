---
layout: publication
title: 'Refine Knowledge Of Large Language Models Via Adaptive Contrastive Learning'
authors: Yinghui Li, Haojing Huang, Jiayi Kuang, Yangning Li, Shu-yu Guo, Chao Qu, Xiaoyu Tan, Hai-tao Zheng, Ying Shen, Philip S. Yu
conference: "Arxiv"
year: 2025
bibkey: li2025refine
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.07184"}
tags: ['Pretraining Methods']
---
How to alleviate the hallucinations of Large Language Models (LLMs) has
always been the fundamental goal pursued by the LLMs research community.
Looking through numerous hallucination-related studies, a mainstream category
of methods is to reduce hallucinations by optimizing the knowledge
representation of LLMs to change their output. Considering that the core focus
of these works is the knowledge acquired by models, and knowledge has long been
a central theme in human societal progress, we believe that the process of
models refining knowledge can greatly benefit from the way humans learn. In our
work, by imitating the human learning process, we design an Adaptive
Contrastive Learning strategy. Our method flexibly constructs different
positive and negative samples for contrastive learning based on LLMs' actual
mastery of knowledge. This strategy helps LLMs consolidate the correct
knowledge they already possess, deepen their understanding of the correct
knowledge they have encountered but not fully grasped, forget the incorrect
knowledge they previously learned, and honestly acknowledge the knowledge they
lack. Extensive experiments and detailed analyses on widely used datasets
demonstrate the effectiveness of our method.

---
layout: publication
title: Frustratingly Easy Natural Question Answering
authors: Pan Lin, Chakravarti Rishav, Ferritto Anthony, Glass Michael, Gliozzo Alfio, Roukos Salim, Florian Radu, Sil Avirup
conference: "Arxiv"
year: 2019
bibkey: pan2019frustratingly
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/1909.05286"}
tags: ['Applications', 'Attention Mechanism', 'BERT', 'Fine Tuning', 'Model Architecture']
---
Existing literature on Question Answering (QA) mostly focuses on algorithmic novelty data augmentation or increasingly large pre45;trained language models like XLNet and RoBERTa. Additionally a lot of systems on the QA leaderboards do not have associated research documentation in order to successfully replicate their experiments. In this paper we outline these algorithmic components such as Attention45;over45;Attention coupled with data augmentation and ensembling strategies that have shown to yield state45;of45;the45;art results on benchmark datasets like SQuAD even achieving super45;human performance. Contrary to these prior results when we evaluate on the recently proposed Natural Questions benchmark dataset we find that an incredibly simple approach of transfer learning from BERT outperforms the previous state45;of45;the45;art system trained on 4 million more examples than ours by 1.9 F1 points. Adding ensembling strategies further improves that number by 2.3 F1 points.

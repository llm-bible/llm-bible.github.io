---
layout: publication
title: Utebc45;nlp At Semeval45;2024 Task 9 Can Llms Be Lateral Thinkers
authors: Sadeghi Pouya, Abaskohi Amirhossein, Yaghoobzadeh Yadollah
conference: "Arxiv"
year: 2024
bibkey: sadeghi2024utebc
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.02474"}
tags: ['GPT', 'Model Architecture', 'Prompting', 'RAG']
---
Inspired by human cognition Jiang et al.(2023c) create a benchmark for assessing LLMs lateral thinking45;thinking outside the box. Building upon this benchmark we investigate how different prompting methods enhance LLMs performance on this task to reveal their inherent power for outside45;the45;box thinking ability. Through participating in SemEval45;2024 task 9 Sentence Puzzle sub45;task we explore prompt engineering methods chain of thoughts (CoT) and direct prompting enhancing with informative descriptions and employing contextualizing prompts using a retrieval augmented generation (RAG) pipeline. Our experiments involve three LLMs including GPT45;3.5 GPT45;4 and Zephyr45;7B45;beta. We generate a dataset of thinking paths between riddles and options using GPT45;4 validated by humans for quality. Findings indicate that compressed informative prompts enhance performance. Dynamic in45;context learning enhances model performance significantly. Furthermore fine45;tuning Zephyr on our dataset enhances performance across other commonsense datasets underscoring the value of innovative thinking.

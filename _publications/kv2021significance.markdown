---
layout: publication
title: On The Significance Of Question Encoder Sequence Model In The Out45;of45;distribution Performance In Visual Question Answering
authors: Kv Gouthaman, Mittal Anurag
conference: "Arxiv"
year: 2021
bibkey: kv2021significance
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2108.12585"}
tags: ['Applications', 'Attention Mechanism', 'Ethics And Bias', 'Model Architecture', 'Pretraining Methods', 'Reinforcement Learning', 'Transformer']
---
Generalizing beyond the experiences has a significant role in developing practical AI systems. It has been shown that current Visual Question Answering (VQA) models are over45;dependent on the language45;priors (spurious correlations between question45;types and their most frequent answers) from the train set and pose poor performance on Out45;of45;Distribution (OOD) test sets. This conduct limits their generalizability and restricts them from being utilized in real45;world situations. This paper shows that the sequence model architecture used in the question45;encoder has a significant role in the generalizability of VQA models. To demonstrate this we performed a detailed analysis of various existing RNN45;based and Transformer45;based question45;encoders and along we proposed a novel Graph attention network (GAT)45;based question45;encoder. Our study found that a better choice of sequence model in the question45;encoder improves the generalizability of VQA models even without using any additional relatively complex bias45;mitigation approaches.

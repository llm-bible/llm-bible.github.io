---
layout: publication
title: "EKTVQA: Generalized Use Of External Knowledge To Empower Scene Text In Text-vqa"
authors: Dey Arka Ujjal, Valveny Ernest, Harit Gaurav
conference: "IEEE.ACCESS"
year: 2021
bibkey: dey2021generalized
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2108.09717"}
tags: ['Applications', 'Ethics And Bias', 'Model Architecture', 'Multimodal Models', 'Pretraining Methods', 'Tools', 'Training Techniques', 'Transformer']
---
The open-ended question answering task of Text-VQA often requires reading and reasoning about rarely seen or completely unseen scene-text content of an image. We address this zero-shot nature of the problem by proposing the generalized use of external knowledge to augment our understanding of the scene text. We design a framework to extract validate and reason with knowledge using a standard multimodal transformer for vision language understanding tasks. Through empirical evidence and qualitative results we demonstrate how external knowledge can highlight instance-only cues and thus help deal with training data bias improve answer entity type correctness and detect multiword named entities. We generate results comparable to the state-of-the-art on three publicly available datasets under the constraints of similar upstream OCR systems and training data.

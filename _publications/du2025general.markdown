---
layout: publication
title: 'Omninova:a General Multimodal Agent Framework'
authors: Pengfei Du
conference: "Arxiv"
year: 2025
bibkey: du2025general
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2503.20028'}
tags: ['Agentic', 'Efficiency and Optimization', 'Model Architecture', 'Tools', 'Multimodal Models', 'Reinforcement Learning']
---
The integration of Large Language Models (LLMs) with specialized tools
presents new opportunities for intelligent automation systems. However,
orchestrating multiple LLM-driven agents to tackle complex tasks remains
challenging due to coordination difficulties, inefficient resource utilization,
and inconsistent information flow. We present OmniNova, a modular multi-agent
automation framework that combines language models with specialized tools such
as web search, crawling, and code execution capabilities. OmniNova introduces
three key innovations: (1) a hierarchical multi-agent architecture with
distinct coordinator, planner, supervisor, and specialist agents; (2) a dynamic
task routing mechanism that optimizes agent deployment based on task
complexity; and (3) a multi-layered LLM integration system that allocates
appropriate models to different cognitive requirements. Our evaluations across
50 complex tasks in research, data analysis, and web interaction domains
demonstrate that OmniNova outperforms existing frameworks in task completion
rate (87% vs. baseline 62%), efficiency (41% reduced token usage), and
result quality (human evaluation score of 4.2/5 vs. baseline 3.1/5). We
contribute both a theoretical framework for multi-agent system design and an
open-source implementation that advances the state-of-the-art in LLM-based
automation systems.

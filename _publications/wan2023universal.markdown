---
layout: publication
title: Universal Self45;adaptive Prompting
authors: Wan Xingchen, Sun Ruoxi, Nakhost Hootan, Dai Hanjun, Eisenschlos Julian Martin, Arik Sercan O., Pfister Tomas
conference: "Arxiv"
year: 2023
bibkey: wan2023universal
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2305.14926"}
tags: ['Applications', 'Prompting']
---
A hallmark of modern large language models (LLMs) is their impressive general zero45;shot and few45;shot abilities often elicited through in45;context learning (ICL) via prompting. However while highly coveted and being the most general zero45;shot performances in LLMs are still typically weaker due to the lack of guidance and the difficulty of applying existing automatic prompt design methods in general tasks when ground45;truth labels are unavailable. In this study we address this by presenting Universal Self45;Adaptive Prompting (USP) an automatic prompt design approach specifically tailored for zero45;shot learning (while compatible with few45;shot). Requiring only a small amount of unlabeled data and an inference45;only LLM USP is highly versatile to achieve universal prompting USP categorizes a possible NLP task into one of the three possible task types and then uses a corresponding selector to select the most suitable queries and zero45;shot model45;generated responses as pseudo45;demonstrations thereby generalizing ICL to the zero45;shot setup in a fully automated way. We evaluate USP with PaLM and PaLM 2 models and demonstrate performances that are considerably stronger than standard zero45;shot baselines and often comparable to or even superior to few45;shot baselines across more than 40 natural language understanding natural language generation and reasoning tasks.

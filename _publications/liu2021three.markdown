---
layout: publication
title: A Three45;stage Learning Framework For Low45;resource Knowledge45;grounded Dialogue Generation
authors: Liu Shilei, Zhao Xiaofeng, Li Bochao, Ren Feiliang, Zhang Longhui, Yin Shujuan
conference: "Arxiv"
year: 2021
bibkey: liu2021three
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2109.04096"}
tags: ['Model Architecture', 'Pretraining Methods', 'Reinforcement Learning', 'Tools', 'Training Techniques', 'Transformer']
---
Neural conversation models have shown great potentials towards generating fluent and informative responses by introducing external background knowledge. Nevertheless it is laborious to construct such knowledge45;grounded dialogues and existing models usually perform poorly when transfer to new domains with limited training samples. Therefore building a knowledge45;grounded dialogue system under the low45;resource setting is a still crucial issue. In this paper we propose a novel three45;stage learning framework based on weakly supervised learning which benefits from large scale ungrounded dialogues and unstructured knowledge base. To better cooperate with this framework we devise a variant of Transformer with decoupled decoder which facilitates the disentangled learning of response generation and knowledge incorporation. Evaluation results on two benchmarks indicate that our approach can outperform other state45;of45;the45;art methods with less training data and even in zero45;resource scenario our approach still performs well.

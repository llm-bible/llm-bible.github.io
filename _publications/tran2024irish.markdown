---
layout: publication
title: 'UCCIX: Irish-excellence Large Language Model'
authors: Khanh-tung Tran, Barry O'sullivan, Hoang D. Nguyen
conference: "Arxiv"
year: 2024
bibkey: tran2024irish
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.13010"}
tags: ['Efficiency and Optimization', 'Training Techniques', 'Model Architecture', 'Tools', 'Scaling Laws', 'Large-Scale Training', 'Pre-Training']
---
The development of Large Language Models (LLMs) has predominantly focused on
high-resource languages, leaving extremely low-resource languages like Irish
with limited representation. This work presents UCCIX, a pioneering effort on
the development of an open-source Irish-based LLM. We propose a novel framework
for continued pre-training of LLMs specifically adapted for extremely
low-resource languages, requiring only a fraction of the textual data typically
needed for training LLMs according to scaling laws. Our model, based on Llama
2-13B, outperforms much larger models on Irish language tasks with up to 12%
performance improvement, showcasing the effectiveness and efficiency of our
approach. We also contribute comprehensive Irish benchmarking datasets,
including IrishQA, a question-answering dataset, and Irish version of MT-bench.
These datasets enable rigorous evaluation and facilitate future research in
Irish LLM systems. Our work aims to preserve and promote the Irish language,
knowledge, and culture of Ireland in the digital era while providing a
framework for adapting LLMs to other indigenous languages.

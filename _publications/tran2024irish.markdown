---
layout: publication
title: UCCIX Irish45;excellence Large Language Model
authors: Tran Khanh-tung, O'sullivan Barry, Nguyen Hoang D.
conference: "Arxiv"
year: 2024
bibkey: tran2024irish
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.13010"}
tags: ['Efficiency And Optimization', 'Large Scale Training', 'Model Architecture', 'Scaling Laws', 'Tools', 'Training Techniques']
---
The development of Large Language Models (LLMs) has predominantly focused on high45;resource languages leaving extremely low45;resource languages like Irish with limited representation. This work presents UCCIX a pioneering effort on the development of an open45;source Irish45;based LLM. We propose a novel framework for continued pre45;training of LLMs specifically adapted for extremely low45;resource languages requiring only a fraction of the textual data typically needed for training LLMs according to scaling laws. Our model based on Llama 245;13B outperforms much larger models on Irish language tasks with up to 1237; performance improvement showcasing the effectiveness and efficiency of our approach. We also contribute comprehensive Irish benchmarking datasets including IrishQA a question45;answering dataset and Irish version of MT45;bench. These datasets enable rigorous evaluation and facilitate future research in Irish LLM systems. Our work aims to preserve and promote the Irish language knowledge and culture of Ireland in the digital era while providing a framework for adapting LLMs to other indigenous languages.

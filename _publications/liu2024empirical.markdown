---
layout: publication
title: An Empirical Analysis On Large Language Models In Debate Evaluation
authors: Liu Xinyi, Liu Pinxin, He Hangfeng
conference: "Arxiv"
year: 2024
bibkey: liu2024empirical
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.00050"}
tags: ['Ethics And Bias', 'GPT', 'Model Architecture', 'Prompting']
---
In this study we investigate the capabilities and inherent biases of advanced large language models (LLMs) such as GPT45;3.5 and GPT45;4 in the context of debate evaluation. We discover that LLMs performance exceeds humans and surpasses the performance of state45;of45;the45;art methods fine45;tuned on extensive datasets in debate evaluation. We additionally explore and analyze biases present in LLMs including positional bias lexical bias order bias which may affect their evaluative judgments. Our findings reveal a consistent bias in both GPT45;3.5 and GPT45;4 towards the second candidate response presented attributed to prompt design. We also uncover lexical biases in both GPT45;3.5 and GPT45;4 especially when label sets carry connotations such as numerical or sequential highlighting the critical need for careful label verbalizer selection in prompt design. Additionally our analysis indicates a tendency of both models to favor the debates concluding side as the winner suggesting an end45;of45;discussion bias.

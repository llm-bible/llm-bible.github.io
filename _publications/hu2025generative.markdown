---
layout: publication
title: 'Generative AI In Education: From Foundational Insights To The Socratic Playground For Learning'
authors: Xiangen Hu, Sheng Xu, Richard Tong, Art Graesser
conference: "Arxiv"
year: 2025
bibkey: hu2025generative
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2501.06682"}
tags: ['Transformer', 'Survey Paper', 'Model Architecture', 'Reinforcement Learning', 'Pretraining Methods', 'Prompting']
---
This paper explores the synergy between human cognition and Large Language
Models (LLMs), highlighting how generative AI can drive personalized learning
at scale. We discuss parallels between LLMs and human cognition, emphasizing
both the promise and new perspectives on integrating AI systems into education.
After examining challenges in aligning technology with pedagogy, we review
AutoTutor-one of the earliest Intelligent Tutoring Systems (ITS)-and detail its
successes, limitations, and unfulfilled aspirations. We then introduce the
Socratic Playground, a next-generation ITS that uses advanced transformer-based
models to overcome AutoTutor's constraints and provide personalized, adaptive
tutoring. To illustrate its evolving capabilities, we present a JSON-based
tutoring prompt that systematically guides learner reflection while tracking
misconceptions. Throughout, we underscore the importance of placing pedagogy at
the forefront, ensuring that technology's power is harnessed to enhance
teaching and learning rather than overshadow it.

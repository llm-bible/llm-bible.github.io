---
layout: publication
title: 'Understanding The Capabilities, Limitations, And Societal Impact Of Large Language Models'
authors: Tamkin Alex, Brundage Miles, Clark Jack, Ganguli Deep
conference: "Arxiv"
year: 2021
bibkey: tamkin2021understanding
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2102.02503"}
tags: ['GPT', 'Model Architecture', 'Uncategorized']
---
On October 14th, 2020, researchers from OpenAI, the Stanford Institute for Human-Centered Artificial Intelligence, and other universities convened to discuss open research questions surrounding GPT-3, the largest publicly-disclosed dense language model at the time. The meeting took place under Chatham House Rules. Discussants came from a variety of research backgrounds including computer science, linguistics, philosophy, political science, communications, cyber policy, and more. Broadly, the discussion centered around two main questions: 1) What are the technical capabilities and limitations of large language models? 2) What are the societal effects of widespread use of large language models? Here, we provide a detailed summary of the discussion organized by the two themes above.

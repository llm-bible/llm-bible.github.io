---
layout: publication
title: In Generative AI We Trust Can Chatbots Effectively Verify Political Information
authors: Kuznetsova Elizaveta, Makhortykh Mykola, Vziatysheva Victoria, Stolze Martha, Baghumyan Ani, Urman Aleksandra
conference: "Arxiv"
year: 2023
bibkey: kuznetsova2023generative
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2312.13096"}
tags: ['Ethics And Bias', 'GPT', 'Model Architecture', 'Prompting', 'RAG', 'Reinforcement Learning', 'Training Techniques']
---
This article presents a comparative analysis of the ability of two large language model (LLM)45;based chatbots ChatGPT and Bing Chat recently rebranded to Microsoft Copilot to detect veracity of political information. We use AI auditing methodology to investigate how chatbots evaluate true false and borderline statements on five topics COVID45;19 Russian aggression against Ukraine the Holocaust climate change and LGBTQ+ related debates. We compare how the chatbots perform in high45; and low45;resource languages by using prompts in English Russian and Ukrainian. Furthermore we explore the ability of chatbots to evaluate statements according to political communication concepts of disinformation misinformation and conspiracy theory using definition45;oriented prompts. We also systematically test how such evaluations are influenced by source bias which we model by attributing specific claims to various political and social actors. The results show high performance of ChatGPT for the baseline veracity evaluation task with 72 percent of the cases evaluated correctly on average across languages without pre45;training. Bing Chat performed worse with a 67 percent accuracy. We observe significant disparities in how chatbots evaluate prompts in high45; and low45;resource languages and how they adapt their evaluations to political communication concepts with ChatGPT providing more nuanced outputs than Bing Chat. Finally we find that for some veracity detection45;related tasks the performance of chatbots varied depending on the topic of the statement or the source to which it is attributed. These findings highlight the potential of LLM45;based chatbots in tackling different forms of false information in online environments but also points to the substantial variation in terms of how such potential is realized due to specific factors such as language of the prompt or the topic.

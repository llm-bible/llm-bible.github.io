---
layout: publication
title: Multi45;logieval Towards Evaluating Multi45;step Logical Reasoning Ability Of Large Language Models
authors: Patel Nisarg, Kulkarni Mohith, Parmar Mihir, Budhiraja Aashna, Nakamura Mutsumi, Varshney Neeraj, Baral Chitta
conference: "Arxiv"
year: 2024
bibkey: patel2024multi
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.17169"}
  - {name: "Code", url: "https://github.com/Mihir3009/Multi&#45;LogiEval"}
tags: ['Applications', 'GPT', 'Has Code', 'Model Architecture', 'RAG']
---
As Large Language Models (LLMs) continue to exhibit remarkable performance in natural language understanding tasks there is a crucial need to measure their ability for human45;like multi45;step logical reasoning. Existing logical reasoning evaluation benchmarks often focus primarily on simplistic single45;step or multi45;step reasoning with a limited set of inference rules. Furthermore the lack of datasets for evaluating non45;monotonic reasoning represents a crucial gap since it aligns more closely with human45;like reasoning. To address these limitations we propose Multi45;LogiEval a comprehensive evaluation dataset encompassing multi45;step logical reasoning with various inference rules and depths. Multi45;LogiEval covers three logic types45;45;propositional first45;order and non45;monotonic45;45;consisting of more than 30 inference rules and more than 60 of their combinations with various depths. Leveraging this dataset we conduct evaluations on a range of LLMs including GPT45;4 ChatGPT Gemini45;Pro Yi Orca and Mistral employing a zero45;shot chain45;of45;thought. Experimental results show that there is a significant drop in the performance of LLMs as the reasoning steps/depth increases (average accuracy of ~6837; at depth45;1 to ~4337; at depth45;5). We further conduct a thorough investigation of reasoning chains generated by LLMs which reveals several important findings. We believe that Multi45;LogiEval facilitates future research for evaluating and enhancing the logical reasoning ability of LLMs. Data is available at https://github.com/Mihir3009/Multi&#45;LogiEval.

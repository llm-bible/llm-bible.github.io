---
layout: publication
title: "SCITUNE: Aligning Large Language Models With Scientific Multimodal Instructions"
authors: Horawalavithana Sameera, Munikoti Sai, Stewart Ian, Kvinge Henry
conference: "Arxiv"
year: 2023
bibkey: horawalavithana2023aligning
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2307.01139"}
tags: ['Multimodal Models', 'RAG', 'Tools']
---
Instruction finetuning is a popular paradigm to align large language models (LLM) with human intent. Despite its popularity this idea is less explored in improving the LLMs to align existing foundation models with scientific disciplines concepts and goals. In this work we present SciTune as a tuning framework to improve the ability of LLMs to follow scientific multimodal instructions. To test our methodology we use a human-generated scientific instruction tuning dataset and train a large multimodal model LLaMA-SciTune that connects a vision encoder and LLM for science-focused visual and language understanding. In comparison to the models that are finetuned with machine generated data only LLaMA-SciTune surpasses human performance on average and in many sub-categories on the ScienceQA benchmark.

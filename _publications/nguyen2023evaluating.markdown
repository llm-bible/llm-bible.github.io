---
layout: publication
title: Evaluating The Symbol Binding Ability Of Large Language Models For Multiple45;choice Questions In Vietnamese General Education
authors: Nguyen Duc-vu, Nguyen Quoc-nam
conference: "Arxiv"
year: 2023
bibkey: nguyen2023evaluating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.12059"}
tags: ['Applications', 'GPT', 'Model Architecture']
---
In this paper we evaluate the ability of large language models (LLMs) to perform multiple choice symbol binding (MCSB) for multiple choice question answering (MCQA) tasks in zero45;shot one45;shot and few45;shot settings. We focus on Vietnamese with fewer challenging MCQA datasets than in English. The two existing datasets ViMMRC 1.0 and ViMMRC 2.0 focus on literature. Recent research in Vietnamese natural language processing (NLP) has focused on the Vietnamese National High School Graduation Examination (VNHSGE) from 2019 to 2023 to evaluate ChatGPT. However these studies have mainly focused on how ChatGPT solves the VNHSGE step by step. We aim to create a novel and high45;quality dataset by providing structured guidelines for typing LaTeX formulas for mathematics physics chemistry and biology. This dataset can be used to evaluate the MCSB ability of LLMs and smaller language models (LMs) because it is typed in a strict LaTeX style. We focus on predicting the character (A B C or D) that is the most likely answer to a question given the context of the question. Our evaluation of six well45;known LLMs namely BLOOMZ45;7.1B45;MT LLaMA45;245;7B LLaMA45;245;70B GPT45;3 GPT45;3.5 and GPT45;4.0 on the ViMMRC 1.0 and ViMMRC 2.0 benchmarks and our proposed dataset shows promising results on the MCSB ability of LLMs for Vietnamese. The dataset is available for research purposes only.

---
layout: publication
title: Consistency Analysis Of Chatgpt
authors: Jang Myeongjun Erik, Lukasiewicz Thomas
conference: "The"
year: 2023
bibkey: jang2023consistency
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2303.06273"}
tags: ['GPT', 'Model Architecture', 'Prompting', 'Reinforcement Learning', 'Tools']
---
ChatGPT has gained a huge popularity since its introduction. Its positive aspects have been reported through many media platforms and some analyses even showed that ChatGPT achieved a decent grade in professional exams adding extra support to the claim that AI can now assist and even replace humans in industrial fields. Others however doubt its reliability and trustworthiness. This paper investigates the trustworthiness of ChatGPT and GPT45;4 regarding logically consistent behaviour focusing specifically on semantic consistency and the properties of negation symmetric and transitive consistency. Our findings suggest that while both models appear to show an enhanced language understanding and reasoning ability they still frequently fall short of generating logically consistent predictions. We also ascertain via experiments that prompt designing few45;shot learning and employing larger large language models (LLMs) are unlikely to be the ultimate solution to resolve the inconsistency issue of LLMs.

---
layout: publication
title: 'Steering Large Language Models To Evaluate And Amplify Creativity'
authors: Matthew Lyle Olson, Neale Ratzlaff, Musashi Hinck, Shao-yen Tseng, Vasudev Lal
conference: "Arxiv"
year: 2024
bibkey: olson2024steering
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2412.06060"}
tags: ['Prompting', 'RAG']
---
Although capable of generating creative text, Large Language Models (LLMs)
are poor judges of what constitutes "creativity". In this work, we show that we
can leverage this knowledge of how to write creatively in order to better judge
what is creative. We take a mechanistic approach that extracts differences in
the internal states of an LLM when prompted to respond "boringly" or
"creatively" to provide a robust measure of creativity that corresponds
strongly with human judgment. We also show these internal state differences can
be applied to enhance the creativity of generated text at inference time.

---
layout: publication
title: Language Prompt For Autonomous Driving
authors: Wu Dongming, Han Wencheng, Wang Tiancai, Liu Yingfei, Zhang Xiangyu, Shen Jianbing
conference: "Arxiv"
year: 2023
bibkey: wu2023language
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.04379"}
  - {name: "Code", url: "https://github.com/wudongming97/Prompt4Driving&#125;&#123;https://github.com/wudongming97/Prompt4Driving&#125;"}
tags: ['Has Code', 'Model Architecture', 'Pretraining Methods', 'Prompting', 'RAG', 'Transformer']
---
A new trend in the computer vision community is to capture objects of interest following flexible human command represented by a natural language prompt. However the progress of using language prompts in driving scenarios is stuck in a bottleneck due to the scarcity of paired prompt45;instance data. To address this challenge we propose the first object45;centric language prompt set for driving scenes within 3D multi45;view and multi45;frame space named NuPrompt. It expands Nuscenes dataset by constructing a total of 35367 language descriptions each referring to an average of 5.3 object tracks. Based on the object45;text pairs from the new benchmark we formulate a new prompt45;based driving task ie employing a language prompt to predict the described object trajectory across views and frames. Furthermore we provide a simple end45;to45;end baseline model based on Transformer named PromptTrack. Experiments show that our PromptTrack achieves impressive performance on NuPrompt. We hope this work can provide more new insights for the autonomous driving community. Dataset and Code will be made public at href123;https://github.com/wudongming97/Prompt4Driving&#125;&#123;https://github.com/wudongming97/Prompt4Driving&#125;.

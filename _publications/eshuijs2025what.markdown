---
layout: publication
title: 'But What Is Your Honest Answer? Aiding Llm-judges With Honest Alternatives Using Steering Vectors'
authors: Leon Eshuijs, Archie Chaudhury, Alan Mcbeth, Ethan Nguyen
conference: "Arxiv"
year: 2025
bibkey: eshuijs2025what
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2505.17760'}
tags: ['Prompting', 'Responsible AI', 'Tools']
---
Recent safety evaluations of Large Language Models (LLMs) show that many models exhibit dishonest behavior, such as sycophancy. However, most honesty benchmarks focus exclusively on factual knowledge or explicitly harmful behavior and rely on external judges, which are often unable to detect less obvious forms of dishonesty. In this work, we introduce a new framework, Judge Using Safety-Steered Alternatives (JUSSA), which utilizes steering vectors trained on a single sample to elicit more honest responses from models, helping LLM-judges in the detection of dishonest behavior. To test our framework, we introduce a new manipulation dataset with prompts specifically designed to elicit deceptive responses. We find that JUSSA enables LLM judges to better differentiate between dishonest and benign responses, and helps them identify subtle instances of manipulative behavior.

---
layout: publication
title: More Samples Or More Prompts Exploring Effective In45;context Sampling For LLM Few45;shot Prompt Engineering
authors: Yao Bingsheng, Chen Guiming, Zou Ruishi, Lu Yuxuan, Li Jiachen, Zhang Shao, Sang Yisi, Liu Sijia, Hendler James, Wang Dakuo
conference: "Arxiv"
year: 2023
bibkey: yao2023more
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2311.09782"}
tags: ['Prompting', 'RAG']
---
While most existing works on LLM prompting techniques focus only on how to select a better set of data samples inside one single prompt input (In45;Context Learning or ICL) why can not we design and leverage multiple prompts together to further improve the LLMs performance In this work we propose In45;Context Sampling (ICS) a low45;resource LLM prompting technique to produce confident predictions by optimizing the construction of multiple ICL prompt inputs. Extensive experiments with three open45;source LLMs (FlanT545;XL Mistral45;7B and Mixtral45;8x7B) on four NLI datasets (e45;SNLI Multi45;NLI ANLI and Contract45;NLI) and one QA dataset (CommonsenseQA) illustrate that ICS can consistently enhance LLMs performance. An in45;depth evaluation with three data similarity45;based ICS strategies suggests that these strategies can further elevate LLMs performance which sheds light on a new yet promising future research direction.

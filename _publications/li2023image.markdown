---
layout: publication
title: Image Content Generation With Causal Reasoning
authors: Li Xiaochuan, Fan Baoyu, Zhang Runze, Jin Liang, Wang Di, Guo Zhenhua, Zhao Yaqian, Li Rengang
conference: "Arxiv"
year: 2023
bibkey: li2023image
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2312.07132"}
  - {name: "Code", url: "https://github.com/IEIT&#45;AGI/MIX&#45;Shannon/blob/main/projects/VQAI/lgd&#95;vqai.md"}
tags: ['Applications', 'GPT', 'Has Code', 'Model Architecture', 'Reinforcement Learning']
---
The emergence of ChatGPT has once again sparked research in generative artificial intelligence (GAI). While people have been amazed by the generated results they have also noticed the reasoning potential reflected in the generated textual content. However this current ability for causal reasoning is primarily limited to the domain of language generation such as in models like GPT45;3. In visual modality there is currently no equivalent research. Considering causal reasoning in visual content generation is significant. This is because visual information contains infinite granularity. Particularly images can provide more intuitive and specific demonstrations for certain reasoning tasks especially when compared to coarse45;grained text. Hence we propose a new image generation task called visual question answering with image (VQAI) and establish a dataset of the same name based on the classic textit123;Tom and Jerry125; animated series. Additionally we develop a new paradigm for image generation to tackle the challenges of this task. Finally we perform extensive experiments and analyses including visualizations of the generated content and discussions on the potentials and limitations. The code and data are publicly available under the license of CC BY45;NC45;SA 4.0 for academic and non45;commercial usage. The code and dataset are publicly available at https://github.com/IEIT&#45;AGI/MIX&#45;Shannon/blob/main/projects/VQAI/lgd&#95;vqai.md.

---
layout: publication
title: Fine45;tuned small Llms (still) Significantly Outperform Zero45;shot Generative AI Models In Text Classification
authors: Bucher Martin Juan Jos√©, Martini Marco
conference: "Arxiv"
year: 2024
bibkey: bucher2024fine
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.08660"}
tags: ['BERT', 'Ethics And Bias', 'GPT', 'Model Architecture', 'Prompting', 'Tools', 'Training Techniques']
---
Generative AI offers a simple prompt45;based alternative to fine45;tuning smaller BERT45;style LLMs for text classification tasks. This promises to eliminate the need for manually labeled training data and task45;specific model training. However it remains an open question whether tools like ChatGPT can deliver on this promise. In this paper we show that smaller fine45;tuned LLMs (still) consistently and significantly outperform larger zero45;shot prompted models in text classification. We compare three major generative AI models (ChatGPT with GPT45;3.5/GPT45;4 and Claude Opus) with several fine45;tuned LLMs across a diverse set of classification tasks (sentiment approval/disapproval emotions party positions) and text categories (news tweets speeches). We find that fine45;tuning with application45;specific training data achieves superior performance in all cases. To make this approach more accessible to a broader audience we provide an easy45;to45;use toolkit alongside this paper. Our toolkit accompanied by non45;technical step45;by45;step guidance enables users to select and fine45;tune BERT45;like LLMs for any classification task with minimal technical and computational effort.

---
layout: publication
title: 'The Blessing Of Reasoning: Llm-based Contrastive Explanations In Black-box Recommender Systems'
authors: Yuyan Wang, Pan Li, Minmin Chen
conference: "Arxiv"
year: 2025
bibkey: wang2025blessing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.16759"}
tags: ['Tools', 'Efficiency and Optimization', 'Ethics and Bias', 'Interpretability and Explainability', 'Reinforcement Learning', 'Interpretability', 'RecSys']
---
Modern recommender systems use ML models to predict consumer preferences from
consumption history. Although these "black-box" models achieve impressive
predictive performance, they often suffer from a lack of transparency and
explainability. Contrary to the presumed tradeoff between explainability and
accuracy, we show that integrating large language models (LLMs) with deep
neural networks (DNNs) can improve both. We propose LR-Recsys, which augments
DNN-based systems with LLM reasoning capabilities. LR-Recsys introduces a
contrastive-explanation generator that produces human-readable positive
explanations and negative explanations. These explanations are embedded via a
fine-tuned autoencoder and combined with consumer and product features to
improve predictions. Beyond offering explainability, we show that LR-Recsys
also improves learning efficiency and predictive accuracy, as supported by
high-dimensional, multi-environment statistical learning theory.
  LR-Recsys outperforms state-of-the-art recommender systems by 3-14% on three
real-world datasets. Importantly, our analysis reveals that these gains
primarily derive from LLMs' reasoning capabilities rather than their external
domain knowledge. LR-RecSys presents an effective approach to combine LLMs with
traditional DNNs, two of the most widely used ML models today. The explanations
generated by LR-Recsys provide actionable insights for consumers, sellers, and
platforms, helping to build trust, optimize product offerings, and inform
targeting strategies.

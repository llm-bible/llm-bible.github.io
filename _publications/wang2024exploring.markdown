---
layout: publication
title: 'Exploring The Implicit Semantic Ability Of Multimodal Large Language Models: A Pilot Study On Entity Set Expansion'
authors: Hebin Wang, Yangning Li, Yinghui Li, Hai-tao Zheng, Wenhao Jiang, Hong-gee Kim
conference: "Arxiv"
year: 2024
bibkey: wang2024exploring
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2501.00330"}
tags: ['Multimodal Models', 'Applications', 'Tools', 'Reinforcement Learning']
---
The rapid development of multimodal large language models (MLLMs) has brought
significant improvements to a wide range of tasks in real-world applications.
However, LLMs still exhibit certain limitations in extracting implicit semantic
information. In this paper, we apply MLLMs to the Multi-modal Entity Set
Expansion (MESE) task, which aims to expand a handful of seed entities with new
entities belonging to the same semantic class, and multi-modal information is
provided with each entity. We explore the capabilities of MLLMs to understand
implicit semantic information at the entity-level granularity through the MESE
task, introducing a listwise ranking method LUSAR that maps local scores to
global rankings. Our LUSAR demonstrates significant improvements in MLLM's
performance on the MESE task, marking the first use of generative MLLM for ESE
tasks and extending the applicability of listwise ranking.

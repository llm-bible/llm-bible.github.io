---
layout: publication
title: 'ISQA: Informative Factuality Feedback For Scientific Summarization'
authors: Zekai Li, Yanxia Qin, Qian Liu, Min-yen Kan
conference: "Arxiv"
year: 2024
bibkey: li2024informative
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.13246"}
  - {name: "Code", url: "https://github.com/lizekai-richard/isqa}},"}
tags: ['Agentic', 'Has Code', 'Applications', 'Reinforcement Learning']
---
We propose Iterative Facuality Refining on Informative Scientific
Question-Answering (ISQA) feedback\footnote\{Code is available at
\url\{https://github.com/lizekai-richard/isqa\}\}, a method following human
learning theories that employs model-generated feedback consisting of both
positive and negative information. Through iterative refining of summaries, it
probes for the underlying rationale of statements to enhance the factuality of
scientific summarization. ISQA does this in a fine-grained manner by asking a
summarization agent to reinforce validated statements in positive feedback and
fix incorrect ones in negative feedback. Our findings demonstrate that the ISQA
feedback mechanism significantly improves the factuality of various open-source
LLMs on the summarization task, as evaluated across multiple scientific
datasets.

---
layout: publication
title: ISQA Informative Factuality Feedback For Scientific Summarization
authors: Li Zekai, Qin Yanxia, Liu Qian, Kan Min-yen
conference: "Arxiv"
year: 2024
bibkey: li2024informative
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.13246"}
  - {name: "Code", url: "https://github.com/lizekai&#45;richard/isqa&#125;&#125;,"}
tags: ['Agentic', 'Applications', 'Has Code', 'Reinforcement Learning']
---
We propose Iterative Facuality Refining on Informative Scientific Question45;Answering (ISQA) feedbackfootnote123;Code is available at url123;https://github.com/lizekai&#45;richard/isqa&#125;&#125;, a method following human learning theories that employs model45;generated feedback consisting of both positive and negative information. Through iterative refining of summaries it probes for the underlying rationale of statements to enhance the factuality of scientific summarization. ISQA does this in a fine45;grained manner by asking a summarization agent to reinforce validated statements in positive feedback and fix incorrect ones in negative feedback. Our findings demonstrate that the ISQA feedback mechanism significantly improves the factuality of various open45;source LLMs on the summarization task as evaluated across multiple scientific datasets.

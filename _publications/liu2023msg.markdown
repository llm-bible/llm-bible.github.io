---
layout: publication
title: MSG45;BART Multi45;granularity Scene Graph45;enhanced Encoder45;decoder Language Model For Video45;grounded Dialogue Generation
authors: Liu Hongcheng, Chen Zhe, Li Hui, Wang Pingjie, Wang Yanfeng, Wang Yu
conference: "Arxiv"
year: 2023
bibkey: liu2023msg
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2311.12820"}
tags: ['Applications']
---
Generating dialogue grounded in videos requires a high level of understanding and reasoning about the visual scenes in the videos. However existing large visual45;language models are not effective due to their latent features and decoder45;only structure especially with respect to spatio45;temporal relationship reasoning. In this paper we propose a novel approach named MSG45;BART which enhances the integration of video information by incorporating a multi45;granularity spatio45;temporal scene graph into an encoder45;decoder pre45;trained language model. Specifically we integrate the global and local scene graph into the encoder and decoder respectively to improve both overall perception and target reasoning capability. To further improve the information selection capability we propose a multi45;pointer network to facilitate selection between text and video. Extensive experiments are conducted on three video45;grounded dialogue benchmarks which show the significant superiority of the proposed MSG45;BART compared to a range of state45;of45;the45;art approaches.

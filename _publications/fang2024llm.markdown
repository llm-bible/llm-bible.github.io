---
layout: publication
title: 'On LLM Wizards: Identifying Large Language Models'' Behaviors For Wizard Of Oz Experiments'
authors: Jingchao Fang, Nikos Arechiga, Keiichi Namaoshi, Nayeli Bravo, Candice Hogan, David A. Shamma
conference: "ACM International Conference on Intelligent Virtual Agents (IVA 2024) September 16-19 2024 Glasgow United Kingdom. ACM New York NY USA"
year: 2024
bibkey: fang2024llm
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.08067"}
tags: ['Tools']
---
The Wizard of Oz (WoZ) method is a widely adopted research approach where a
human Wizard ``role-plays'' a not readily available technology and interacts
with participants to elicit user behaviors and probe the design space. With the
growing ability for modern large language models (LLMs) to role-play, one can
apply LLMs as Wizards in WoZ experiments with better scalability and lower cost
than the traditional approach. However, methodological guidance on responsibly
applying LLMs in WoZ experiments and a systematic evaluation of LLMs'
role-playing ability are lacking. Through two LLM-powered WoZ studies, we take
the first step towards identifying an experiment lifecycle for researchers to
safely integrate LLMs into WoZ experiments and interpret data generated from
settings that involve Wizards role-played by LLMs. We also contribute a
heuristic-based evaluation framework that allows the estimation of LLMs'
role-playing ability in WoZ experiments and reveals LLMs' behavior patterns at
scale.

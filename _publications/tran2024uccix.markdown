---
layout: publication
title: UCCIX Irish-excellence Large Language Model
authors: Tran Khanh-tung, O'sullivan Barry, Nguyen Hoang D.
conference: "Arxiv"
year: 2024
bibkey: tran2024uccix
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.13010"}
tags: ['Efficiency And Optimization', 'Large Scale Training', 'Model Architecture', 'Scaling Laws', 'Tools', 'Training Techniques']
---
The development of Large Language Models (LLMs) has predominantly focused on high-resource languages leaving extremely low-resource languages like Irish with limited representation. This work presents UCCIX a pioneering effort on the development of an open-source Irish-based LLM. We propose a novel framework for continued pre-training of LLMs specifically adapted for extremely low-resource languages requiring only a fraction of the textual data typically needed for training LLMs according to scaling laws. Our model based on Llama 2-13B outperforms much larger models on Irish language tasks with up to 1237; performance improvement showcasing the effectiveness and efficiency of our approach. We also contribute comprehensive Irish benchmarking datasets including IrishQA a question-answering dataset and Irish version of MT-bench. These datasets enable rigorous evaluation and facilitate future research in Irish LLM systems. Our work aims to preserve and promote the Irish language knowledge and culture of Ireland in the digital era while providing a framework for adapting LLMs to other indigenous languages.

---
layout: publication
title: Large Language Models Can Enhance Persuasion Through Linguistic Feature Alignment
authors: Shin Minkyu, Kim Jin
conference: "Arxiv"
year: 2023
bibkey: shin2023large
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2311.16466"}
tags: ['GPT', 'Model Architecture', 'Pretraining Methods', 'Reinforcement Learning', 'Tools']
---
Although large language models (LLMs) are reshaping various aspects of human life our current understanding of their impacts remains somewhat constrained. Here we investigate the impact of LLMs on human communication using data on consumer complaints in the financial industry. By employing an AI detection tool on more than 820K complaints gathered by the Consumer Financial Protection Bureau (CFPB) we find a sharp increase in the likely use of LLMs shortly after the release of ChatGPT. Moreover the likely LLM usage was positively correlated with message persuasiveness (i.e. increased likelihood of obtaining relief from financial firms). Computational linguistic analyses suggest that the positive correlation may be explained by LLMs enhancement of various linguistic features. Based on the results of these observational studies we hypothesize that LLM usage may enhance a comprehensive set of linguistic features increasing message persuasiveness to receivers with heterogeneous linguistic preferences (i.e. linguistic feature alignment). We test this hypothesis in preregistered experiments and find support for it. As an instance of early empirical demonstrations of LLM usage for enhancing persuasion our research highlights the transformative potential of LLMs in human communication.

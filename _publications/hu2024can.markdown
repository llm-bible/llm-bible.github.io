---
layout: publication
title: Can Perplexity Reflect Large Language Models Ability In Long Text Understanding
authors: Hu Yutong, Huang Quzhe, Tao Mingxu, Zhang Chen, Feng Yansong
conference: "Arxiv"
year: 2024
bibkey: hu2024can
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.06105"}
tags: ['Attention Mechanism', 'Language Modeling', 'Model Architecture', 'Reinforcement Learning', 'Training Techniques']
---
Recent studies have shown that Large Language Models (LLMs) have the potential to process extremely long text. Many works only evaluate LLMs long45;text processing ability on the language modeling task with perplexity (PPL) as the evaluation metric. However in our study we find that there is no correlation between PPL and LLMs long45;text understanding ability. Besides PPL may only reflect the models ability to model local information instead of catching long45;range dependency. Therefore only using PPL to prove the model could process long text is inappropriate. The local focus feature of PPL could also explain some existing phenomena such as the great extrapolation ability of the position method ALiBi. When evaluating a models ability in long text we might pay more attention to PPLs limitation and avoid overly relying on it.

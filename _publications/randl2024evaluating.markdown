---
layout: publication
title: Evaluating The Reliability Of Self45;explanations In Large Language Models
authors: Randl Korbinian, Pavlopoulos John, Henriksson Aron, Lindgren Tony
conference: "Arxiv"
year: 2024
bibkey: randl2024evaluating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.14487"}
tags: ['Interpretability And Explainability', 'Prompting']
---
This paper investigates the reliability of explanations generated by large language models (LLMs) when prompted to explain their previous output. We evaluate two kinds of such self45;explanations 45; extractive and counterfactual 45; using three state45;of45;the45;art LLMs (2B to 8B parameters) on two different classification tasks (objective and subjective). Our findings reveal that while these self45;explanations can correlate with human judgement they do not fully and accurately follow the models decision process indicating a gap between perceived and actual model reasoning. We show that this gap can be bridged because prompting LLMs for counterfactual explanations can produce faithful informative and easy45;to45;verify results. These counterfactuals offer a promising alternative to traditional explainability methods (e.g. SHAP LIME) provided that prompts are tailored to specific tasks and checked for validity.

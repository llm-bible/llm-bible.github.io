---
layout: publication
title: Sketch\: A Toolkit For Streamlining LLM Operations
authors: Jiang Xin, Li Xiang, Ma Wenjia, Fang Xuezhi, Yao Yiqun, Yu Naitong, Meng Xuying, Han Peng, Li Jing, Sun Aixin, Wang Yequan
conference: "Arxiv"
year: 2024
bibkey: jiang2024toolkit
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2409.03346"}
  - {name: "Code", url: "https://github.com/cofe-ai/Sketch"}
tags: ['Applications', 'Ethics And Bias', 'GPT', 'Has Code', 'Model Architecture', 'Prompting', 'Tools', 'Training Techniques']
---
Large language models (LLMs) represented by GPT family have achieved remarkable success. The characteristics of LLMs lie in their ability to accommodate a wide range of tasks through a generative approach. However the flexibility of their output format poses challenges in controlling and harnessing the models outputs thereby constraining the application of LLMs in various domains. In this work we present Sketch an innovative toolkit designed to streamline LLM operations across diverse fields. Sketch comprises the following components (1) a suite of task description schemas and prompt templates encompassing various NLP tasks; (2) a user-friendly interactive process for building structured output LLM services tailored to various NLP tasks; (3) an open-source dataset for output format control along with tools for dataset construction; and (4) an open-source model based on LLaMA3-8B-Instruct that adeptly comprehends and adheres to output formatting instructions. We anticipate this initiative to bring considerable convenience to LLM users achieving the goal of plug-and-play for various applications. The components of Sketch will be progressively open-sourced at https://github.com/cofe-ai/Sketch."

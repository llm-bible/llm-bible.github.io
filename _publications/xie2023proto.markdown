---
layout: publication
title: Proto45;lm A Prototypical Network45;based Framework For Built45;in Interpretability In Large Language Models
authors: Xie Sean, Vosoughi Soroush, Hassanpour Saeed
conference: "Arxiv"
year: 2023
bibkey: xie2023proto
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2311.01732"}
tags: ['Interpretability And Explainability', 'Tools']
---
Large Language Models (LLMs) have significantly advanced the field of Natural Language Processing (NLP) but their lack of interpretability has been a major concern. Current methods for interpreting LLMs are post hoc applied after inference time and have limitations such as their focus on low45;level features and lack of explainability at higher level text units. In this work we introduce proto45;lm a prototypical network45;based white45;box framework that allows LLMs to learn immediately interpretable embeddings during the fine45;tuning stage while maintaining competitive performance. Our methods applicability and interpretability are demonstrated through experiments on a wide range of NLP tasks and our results indicate a new possibility of creating interpretable models without sacrificing performance. This novel approach to interpretability in LLMs can pave the way for more interpretable models without the need to sacrifice performance.

---
layout: publication
title: "Wizardmath: Empowering Mathematical Reasoning For Large Language Models Via Reinforced Evol-instruct"
authors: Luo Haipeng, Sun Qingfeng, Xu Can, Zhao Pu, Lou Jianguang, Tao Chongyang, Geng Xiubo, Lin Qingwei, Chen Shifeng, Zhang Dongmei
conference: "Arxiv"
year: 2023
bibkey: luo2023empowering
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2308.09583"}
  - {name: "Code", url: "https://github.com/nlpxucan/WizardLM"}
tags: ['Agentic', 'Efficiency And Optimization', 'GPT', 'Has Code', 'Model Architecture', 'Reinforcement Learning']
---
Large language models (LLMs) such as GPT-4 have shown remarkable performance in natural language processing (NLP) tasks including challenging mathematical reasoning. However most existing open-source models are only pre-trained on large-scale internet data and without math-related optimization. In this paper we present WizardMath which enhances the mathematical reasoning abilities of Llama-2 by applying our proposed Reinforcement Learning from Evol-Instruct Feedback (RLEIF) method to the domain of math. Through extensive experiments on two mathematical reasoning benchmarks namely GSM8k and MATH we reveal the extraordinary capabilities of our model. WizardMath surpasses all other open-source LLMs by a substantial margin. Furthermore our model even outperforms ChatGPT-3.5 Claude Instant-1 PaLM-2 and Minerva on GSM8k simultaneously surpasses Text-davinci-002 PaLM-1 and GPT-3 on MATH. More details and model weights are public at https://github.com/nlpxucan/WizardLM and https://huggingface.co/WizardLM."

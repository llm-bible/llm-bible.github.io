---
layout: publication
title: Wizardmath Empowering Mathematical Reasoning For Large Language Models Via Reinforced Evol45;instruct
authors: Luo Haipeng, Sun Qingfeng, Xu Can, Zhao Pu, Lou Jianguang, Tao Chongyang, Geng Xiubo, Lin Qingwei, Chen Shifeng, Zhang Dongmei
conference: "Arxiv"
year: 2023
bibkey: luo2023empowering
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2308.09583"}
  - {name: "Code", url: "https://github.com/nlpxucan/WizardLM"}
tags: ['Agentic', 'Efficiency And Optimization', 'GPT', 'Has Code', 'Model Architecture', 'Reinforcement Learning']
---
Large language models (LLMs) such as GPT45;4 have shown remarkable performance in natural language processing (NLP) tasks including challenging mathematical reasoning. However most existing open45;source models are only pre45;trained on large45;scale internet data and without math45;related optimization. In this paper we present WizardMath which enhances the mathematical reasoning abilities of Llama45;2 by applying our proposed Reinforcement Learning from Evol45;Instruct Feedback (RLEIF) method to the domain of math. Through extensive experiments on two mathematical reasoning benchmarks namely GSM8k and MATH we reveal the extraordinary capabilities of our model. WizardMath surpasses all other open45;source LLMs by a substantial margin. Furthermore our model even outperforms ChatGPT45;3.5 Claude Instant45;1 PaLM45;2 and Minerva on GSM8k simultaneously surpasses Text45;davinci45;002 PaLM45;1 and GPT45;3 on MATH. More details and model weights are public at https://github.com/nlpxucan/WizardLM and https://huggingface.co/WizardLM.

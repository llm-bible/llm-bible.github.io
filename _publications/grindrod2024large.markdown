---
layout: publication
title: 'Large Language Models And Linguistic Intentionality'
authors: Grindrod Jumbly
conference: "Arxiv"
year: 2024
bibkey: grindrod2024large
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.09576"}
tags: ['GPT', 'Model Architecture', 'Pretraining Methods']
---
Do large language models like Chat-GPT or LLaMa meaningfully use the words they produce Or are they merely clever prediction machines simulating language use by producing statistically plausible text There have already been some initial attempts to answer this question by showing that these models meet the criteria for entering meaningful states according to metasemantic theories of mental content. In this paper I will argue for a different approach - that we should instead consider whether language models meet the criteria given by our best metasemantic theories of linguistic content. In that vein I will illustrate how this can be done by applying two such theories to the case of language models Gareth Evans (1982) account of naming practices and Ruth Millikans (1984 2004 2005) teleosemantics. In doing so I will argue that it is a mistake to think that the failure of LLMs to meet plausible conditions for mental intentionality thereby renders their outputs meaningless and that a distinguishing feature of linguistic intentionality - dependency on a pre-existing linguistic system - allows for the plausible result LLM outputs are meaningful.

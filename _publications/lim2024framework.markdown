---
layout: publication
title: 'ERD: A Framework For Improving LLM Reasoning For Cognitive Distortion Classification'
authors: Sehee Lim, Yejin Kim, Chi-hyun Choi, Jy-yong Sohn, Byung-hoon Kim
conference: "Arxiv"
year: 2024
bibkey: lim2024framework
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2403.14255'}
tags: ['Attention Mechanism', 'Agentic', 'Model Architecture', 'Tools', 'Ethics and Bias']
---
Improving the accessibility of psychotherapy with the aid of Large Language
Models (LLMs) is garnering a significant attention in recent years. Recognizing
cognitive distortions from the interviewee's utterances can be an essential
part of psychotherapy, especially for cognitive behavioral therapy. In this
paper, we propose ERD, which improves LLM-based cognitive distortion
classification performance with the aid of additional modules of (1) extracting
the parts related to cognitive distortion, and (2) debating the reasoning steps
by multiple agents. Our experimental results on a public dataset show that ERD
improves the multi-class F1 score as well as binary specificity score.
Regarding the latter score, it turns out that our method is effective in
debiasing the baseline method which has high false positive rate, especially
when the summary of multi-agent debate is provided to LLMs.

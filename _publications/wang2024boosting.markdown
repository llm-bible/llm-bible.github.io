---
layout: publication
title: Instructgraph Boosting Large Language Models Via Graph-centric Instruction Tuning And Preference Alignment
authors: Wang Jianing, Wu Junda, Hou Yupeng, Liu Yao, Gao Ming, Mcauley Julian
conference: "Arxiv"
year: 2024
bibkey: wang2024boosting
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.08785"}
tags: ['GPT', 'Model Architecture', 'Pretraining Methods', 'Tools']
---
Do current large language models (LLMs) better solve graph reasoning and generation tasks with parameter updates In this paper we propose InstructGraph a framework that empowers LLMs with the abilities of graph reasoning and generation by instruction tuning and preference alignment. Specifically we first propose a structured format verbalizer to unify all graph data into a universal code-like format which can simply represent the graph without any external graph-specific encoders. Furthermore a graph instruction tuning stage is introduced to guide LLMs in solving graph reasoning and generation tasks. Finally we identify potential hallucination problems in graph tasks and sample negative instances for preference alignment the target of which is to enhance the outputs reliability of the model. Extensive experiments across multiple graph-centric tasks exhibit that InstructGraph can achieve the best performance and outperform GPT-4 and LLaMA2 by more than 1337; and 3837; respectively.

---
layout: publication
title: 'SC-ML: Self-supervised Counterfactual Metric Learning For Debiased Visual Question Answering'
authors: Shu Xinyao, Yan Shiyang, Yang Xu, Wu Ziheng, Chen Zhongfeng, Lu Zhenyu
conference: "Arxiv"
year: 2023
bibkey: shu2023sc
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2304.01647"}
tags: ['Agentic', 'Applications', 'Ethics And Bias', 'Multimodal Models', 'Security', 'Training Techniques']
---
Visual question answering (VQA) is a critical multimodal task in which an agent must answer questions according to the visual cue. Unfortunately language bias is a common problem in VQA which refers to the model generating answers only by associating with the questions while ignoring the visual content resulting in biased results. We tackle the language bias problem by proposing a self-supervised counterfactual metric learning (SC-ML) method to focus the image features better. SC-ML can adaptively select the question-relevant visual features to answer the question reducing the negative influence of question-irrelevant visual features on inferring answers. In addition question-irrelevant visual features can be seamlessly incorporated into counterfactual training schemes to further boost robustness. Extensive experiments have proved the effectiveness of our method with improved results on the VQA-CP dataset. Our code will be made publicly available.

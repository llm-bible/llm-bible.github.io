---
layout: publication
title: Informed AI Regulation Comparing The Ethical Frameworks Of Leading LLM Chatbots Using An Ethics45;based Audit To Assess Moral Reasoning And Normative Values
authors: Chun Jon, Elkins Katherine
conference: "Arxiv"
year: 2024
bibkey: chun2024informed
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.01651"}
  - {name: "Code", url: "https://github.com/jonchun/llm&#45;sota&#45;chatbots&#45;ethics&#45;based&#45;audit"}
tags: ['Agent', 'Agentic', 'Ethics And Bias', 'GPT', 'Has Code', 'Model Architecture', 'Reinforcement Learning', 'Responsible AI', 'Tools']
---
With the rise of individual and collaborative networks of autonomous agents AI is deployed in more key reasoning and decision45;making roles. For this reason ethics45;based audits play a pivotal role in the rapidly growing fields of AI safety and regulation. This paper undertakes an ethics45;based audit to probe the 8 leading commercial and open45;source Large Language Models including GPT45;4. We assess explicability and trustworthiness by a) establishing how well different models engage in moral reasoning and b) comparing normative values underlying models as ethical frameworks. We employ an experimental evidence45;based approach that challenges the models with ethical dilemmas in order to probe human45;AI alignment. The ethical scenarios are designed to require a decision in which the particulars of the situation may or may not necessitate deviating from normative ethical principles. A sophisticated ethical framework was consistently elicited in one model GPT45;4. Nonetheless troubling findings include underlying normative frameworks with clear bias towards particular cultural norms. Many models also exhibit disturbing authoritarian tendencies. Code is available at https://github.com/jonchun/llm&#45;sota&#45;chatbots&#45;ethics&#45;based&#45;audit.

---
layout: publication
title: 'Prompting As Probing: Using Language Models For Knowledge Base Construction'
authors: Dimitrios Alivanistos, Selene Báez Santamaría, Michael Cochez, Jan-christoph Kalo, Emile Van Krieken, Thiviyan Thanapalasingam
conference: "Arxiv"
year: 2022
bibkey: alivanistos2022prompting
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2208.11057"}
  - {name: "Code", url: "https://github.com/HEmile/iswc-challenge"}
tags: ['Tools', 'GPT', 'Applications', 'RAG', 'Model Architecture', 'Has Code', 'Prompting']
---
Language Models (LMs) have proven to be useful in various downstream
applications, such as summarisation, translation, question answering and text
classification. LMs are becoming increasingly important tools in Artificial
Intelligence, because of the vast quantity of information they can store. In
this work, we present ProP (Prompting as Probing), which utilizes GPT-3, a
large Language Model originally proposed by OpenAI in 2020, to perform the task
of Knowledge Base Construction (KBC). ProP implements a multi-step approach
that combines a variety of prompting techniques to achieve this. Our results
show that manual prompt curation is essential, that the LM must be encouraged
to give answer sets of variable lengths, in particular including empty answer
sets, that true/false questions are a useful device to increase precision on
suggestions generated by the LM, that the size of the LM is a crucial factor,
and that a dictionary of entity aliases improves the LM score. Our evaluation
study indicates that these proposed techniques can substantially enhance the
quality of the final predictions: ProP won track 2 of the LM-KBC competition,
outperforming the baseline by 36.4 percentage points. Our implementation is
available on https://github.com/HEmile/iswc-challenge.

---
layout: publication
title: 'Unigen: A Unified Generative Framework For Retrieval And Question Answering With Large Language Models'
authors: Li Xiaoxi, Zhou Yujia, Dou Zhicheng
conference: "Arxiv"
year: 2023
bibkey: li2023unified
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2312.11036"}
tags: ['Applications', 'Attention Mechanism', 'Efficiency And Optimization', 'Model Architecture', 'RAG', 'Tools']
---
Generative information retrieval, encompassing two major tasks of Generative Document Retrieval (GDR) and Grounded Answer Generation (GAR), has gained significant attention in the area of information retrieval and natural language processing. Existing methods for GDR and GAR rely on separate retrieval and reader modules, which hinder simultaneous optimization. To overcome this, we present \textbf\{UniGen\}, a \textbf\{Uni\}fied \textbf\{Gen\}erative framework for retrieval and question answering that integrates both tasks into a single generative model leveraging the capabilities of large language models. UniGen employs a shared encoder and two distinct decoders for generative retrieval and question answering. To facilitate the learning of both tasks, we introduce connectors, generated by large language models, to bridge the gaps between query inputs and generation targets, as well as between document identifiers and answers. Furthermore, we propose an iterative enhancement strategy that leverages generated answers and retrieved documents to iteratively improve both tasks. Through extensive experiments on the MS MARCO and NQ datasets, we demonstrate the effectiveness of UniGen, showcasing its superior performance in both the retrieval and the question answering tasks.

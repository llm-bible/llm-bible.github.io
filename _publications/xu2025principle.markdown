---
layout: publication
title: 'Physense: Principle-based Physics Reasoning Benchmarking For Large Language Models'
authors: Yinggan Xu, Yue Liu, Zhiqiang Gao, Changnan Peng, Di Luo
conference: "Arxiv"
year: 2025
bibkey: xu2025principle
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2505.24823"}
tags: ['Prompting', 'Tools']
---
Large language models (LLMs) have rapidly advanced and are increasingly capable of tackling complex scientific problems, including those in physics. Despite this progress, current LLMs often fail to emulate the concise, principle-based reasoning characteristic of human experts, instead generating lengthy and opaque solutions. This discrepancy highlights a crucial gap in their ability to apply core physical principles for efficient and interpretable problem solving. To systematically investigate this limitation, we introduce PhySense, a novel principle-based physics reasoning benchmark designed to be easily solvable by experts using guiding principles, yet deceptively difficult for LLMs without principle-first reasoning. Our evaluation across multiple state-of-the-art LLMs and prompt types reveals a consistent failure to align with expert-like reasoning paths, providing insights for developing AI systems with efficient, robust and interpretable principle-based scientific reasoning.

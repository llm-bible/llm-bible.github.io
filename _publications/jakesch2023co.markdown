---
layout: publication
title: 'Co-writing With Opinionated Language Models Affects Users'' Views'
authors: Maurice Jakesch, Advait Bhat, Daniel Buschek, Lior Zalmanson, Mor Naaman
conference: "Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI 23) April 23-28 2023 Hamburg Germany. ACM New York NY USA"
year: 2023
bibkey: jakesch2023co
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2302.00560'}
tags: ['GPT', 'Model Architecture', 'Survey Paper']
---
If large language models like GPT-3 preferably produce a particular point of
view, they may influence people's opinions on an unknown scale. This study
investigates whether a language-model-powered writing assistant that generates
some opinions more often than others impacts what users write - and what they
think. In an online experiment, we asked participants (N=1,506) to write a post
discussing whether social media is good for society. Treatment group
participants used a language-model-powered writing assistant configured to
argue that social media is good or bad for society. Participants then completed
a social media attitude survey, and independent judges (N=500) evaluated the
opinions expressed in their writing. Using the opinionated language model
affected the opinions expressed in participants' writing and shifted their
opinions in the subsequent attitude survey. We discuss the wider implications
of our results and argue that the opinions built into AI language technologies
need to be monitored and engineered more carefully.

---
layout: publication
title: GECOR An End45;to45;end Generative Ellipsis And Co45;reference Resolution Model For Task45;oriented Dialogue
authors: Quan Jun, Xiong Deyi, Webber Bonnie, Hu Changjian
conference: "Arxiv"
year: 2019
bibkey: quan2019end
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/1909.12086"}
tags: ['Applications', 'RAG', 'Tools']
---
Ellipsis and co45;reference are common and ubiquitous especially in multi45;turn dialogues. In this paper we treat the resolution of ellipsis and co45;reference in dialogue as a problem of generating omitted or referred expressions from the dialogue context. We therefore propose a unified end45;to45;end Generative Ellipsis and CO45;reference Resolution model (GECOR) in the context of dialogue. The model can generate a new pragmatically complete user utterance by alternating the generation and copy mode for each user utterance. A multi45;task learning framework is further proposed to integrate the GECOR into an end45;to45;end task45;oriented dialogue. In order to train both the GECOR and the multi45;task learning framework we manually construct a new dataset on the basis of the public dataset CamRest676 with both ellipsis and co45;reference annotation. On this dataset intrinsic evaluations on the resolution of ellipsis and co45;reference show that the GECOR model significantly outperforms the sequence45;to45;sequence (seq2seq) baseline model in terms of EM BLEU and F1 while extrinsic evaluations on the downstream dialogue task demonstrate that our multi45;task learning framework with GECOR achieves a higher success rate of task completion than TSCP a state45;of45;the45;art end45;to45;end task45;oriented dialogue model.

---
layout: publication
title: 'Langpert: Detecting And Handling Task-level Perturbations For Robust Object Rearrangement'
authors: Xu Yin, Min-sung Yoon, Yuchi Huo, Kang Zhang, Sung-eui Yoon
conference: "Arxiv"
year: 2025
bibkey: yin2025detecting
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2504.09893"}
tags: ['Efficiency and Optimization', 'RAG', 'Tools', 'Reinforcement Learning']
---
Task execution for object rearrangement could be challenged by Task-Level
Perturbations (TLP), i.e., unexpected object additions, removals, and
displacements that can disrupt underlying visual policies and fundamentally
compromise task feasibility and progress. To address these challenges, we
present LangPert, a language-based framework designed to detect and mitigate
TLP situations in tabletop rearrangement tasks. LangPert integrates a Visual
Language Model (VLM) to comprehensively monitor policy's skill execution and
environmental TLP, while leveraging the Hierarchical Chain-of-Thought (HCoT)
reasoning mechanism to enhance the Large Language Model (LLM)'s contextual
understanding and generate adaptive, corrective skill-execution plans. Our
experimental results demonstrate that LangPert handles diverse TLP situations
more effectively than baseline methods, achieving higher task completion rates,
improved execution efficiency, and potential generalization to unseen
scenarios.

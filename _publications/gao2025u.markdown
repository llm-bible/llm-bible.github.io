---
layout: publication
title: 'U-NIAH: Unified RAG And LLM Evaluation For Long Context Needle-in-a-haystack'
authors: Yunfan Gao, Yun Xiong, Wenlong Wu, Zijing Huang, Bohan Li, Haofen Wang
conference: "Arxiv"
year: 2025
bibkey: gao2025u
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2503.00353'}
  - {name: "Code", url: 'https://github.com/Tongji-KGLLM/U-NIAH'}
tags: ['Has Code', 'RAG', 'Security', 'Applications', 'Tools', 'Reinforcement Learning', 'Ethics and Bias']
---
Recent advancements in Large Language Models (LLMs) have expanded their
context windows to unprecedented lengths, sparking debates about the necessity
of Retrieval-Augmented Generation (RAG). To address the fragmented evaluation
paradigms and limited cases in existing Needle-in-a-Haystack (NIAH), this paper
introduces U-NIAH, a unified framework that systematically compares LLMs and
RAG methods in controlled long context settings. Our framework extends beyond
traditional NIAH by incorporating multi-needle, long-needle, and
needle-in-needle configurations, along with different retrieval settings, while
leveraging the synthetic Starlight Academy dataset-a fictional magical
universe-to eliminate biases from pre-trained knowledge. Through extensive
experiments, we investigate three research questions: (1) performance
trade-offs between LLMs and RAG, (2) error patterns in RAG, and (3) RAG's
limitations in complex settings. Our findings show that RAG significantly
enhances smaller LLMs by mitigating the "lost-in-the-middle" effect and
improving robustness, achieving an 82.58% win-rate over LLMs. However, we
observe that retrieval noise and reverse chunk ordering degrade performance,
while surprisingly, advanced reasoning LLMs exhibit reduced RAG compatibility
due to sensitivity to semantic distractors. We identify typical error patterns
including omission due to noise, hallucination under high noise critical
condition, and self-doubt behaviors. Our work not only highlights the
complementary roles of RAG and LLMs, but also provides actionable insights for
optimizing deployments. Code: https://github.com/Tongji-KGLLM/U-NIAH.

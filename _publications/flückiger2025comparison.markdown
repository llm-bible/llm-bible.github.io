---
layout: publication
title: 'A Comparison Of Translation Performance Between Deepl And Supertext'
authors: Alex Flückiger, Chantal Amrhein, Tim Graf, Frédéric Odermatt, Martin Pömsl, Philippe Schläpfer, Florian Schottmann, Samuel Läubli
conference: "Arxiv"
year: 2025
bibkey: flückiger2025comparison
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.02577"}
  - {name: "Code", url: "https://github.com/supertext/evaluation_deepl_supertext"}
tags: ['RAG', 'Has Code', 'Applications', 'Reinforcement Learning']
---
As strong machine translation (MT) systems are increasingly based on large language models (LLMs), reliable quality benchmarking requires methods that capture their ability to leverage extended context. This study compares two commercial MT systems -- DeepL and Supertext -- by assessing their performance on unsegmented texts. We evaluate translation quality across four language directions with professional translators assessing segments with full document-level context. While segment-level assessments indicate no strong preference between the systems in most cases, document-level analysis reveals a preference for Supertext in three out of four language directions, suggesting superior consistency across longer texts. We advocate for more context-sensitive evaluation methodologies to ensure that MT quality assessments reflect real-world usability. We release all evaluation data and scripts for further analysis and reproduction at https://github.com/supertext/evaluation_deepl_supertext.

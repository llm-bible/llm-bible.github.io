---
layout: publication
title: Sotana The Open45;source Software Development Assistant
authors: Shi Ensheng, Zhang Fengji, Wang Yanlin, Chen Bei, Du Lun, Zhang Hongyu, Han Shi, Zhang Dongmei, Sun Hongbin
conference: "Arxiv"
year: 2023
bibkey: shi2023open
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2308.13416"}
  - {name: "Code", url: "https://github.com/DeepSoftwareAnalytics/SoTaNa&#125;"}
tags: ['Applications', 'Efficiency And Optimization', 'GPT', 'Has Code', 'Model Architecture', 'Reinforcement Learning', 'Training Techniques']
---
Software development plays a crucial role in driving innovation and efficiency across modern societies. To meet the demands of this dynamic field there is a growing need for an effective software development assistant. However existing large language models represented by ChatGPT suffer from limited accessibility including training data and model weights. Although other large open45;source models like LLaMA have shown promise they still struggle with understanding human intent. In this paper we present SoTaNa an open45;source software development assistant. SoTaNa utilizes ChatGPT to generate high45;quality instruction45;based data for the domain of software engineering and employs a parameter45;efficient fine45;tuning approach to enhance the open45;source foundation model LLaMA. We evaluate the effectiveness of our123;125; in answering Stack Overflow questions and demonstrate its capabilities. Additionally we discuss its capabilities in code summarization and generation as well as the impact of varying the volume of generated data on model performance. Notably SoTaNa can run on a single GPU making it accessible to a broader range of researchers. Our code model weights and data are public at url123;https://github.com/DeepSoftwareAnalytics/SoTaNa&#125;.

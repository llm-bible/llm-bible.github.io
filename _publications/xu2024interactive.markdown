---
layout: publication
title: Interactive Evolution A Neural45;symbolic Self45;training Framework For Large Language Models
authors: Xu Fangzhi, Sun Qiushi, Cheng Kanzhi, Liu Jun, Qiao Yu, Wu Zhiyong
conference: "Arxiv"
year: 2024
bibkey: xu2024interactive
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.11736"}
  - {name: "Code", url: "https://github.com/xufangzhi/ENVISIONS&#125;"}
tags: ['Has Code', 'Pretraining Methods', 'Reinforcement Learning', 'Tools', 'Training Techniques']
---
One of the primary driving forces contributing to the superior performance of Large Language Models (LLMs) is the extensive availability of human45;annotated natural language data which is used for alignment fine45;tuning. This inspired researchers to investigate self45;training methods to mitigate the extensive reliance on human annotations. However the current success of self45;training has been primarily observed in natural language scenarios rather than in the increasingly important neural45;symbolic scenarios. To this end we propose an environment45;guided neural45;symbolic self45;training framework named ENVISIONS. It aims to overcome two main challenges (1) the scarcity of symbolic data and (2) the limited proficiency of LLMs in processing symbolic language. Extensive evaluations conducted on three distinct domains demonstrate the effectiveness of our approach. Additionally we have conducted a comprehensive analysis to uncover the factors contributing to ENVISIONSs success thereby offering valuable insights for future research in this area. Code will be available at url123;https://github.com/xufangzhi/ENVISIONS&#125;.

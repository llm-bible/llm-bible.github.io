---
layout: publication
title: CLIPAG Towards Generator45;free Text45;to45;image Generation
authors: Ganz Roy, Elad Michael
conference: "Arxiv"
year: 2023
bibkey: ganz2023towards
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2306.16805"}
tags: ['Applications', 'Attention Mechanism', 'Model Architecture', 'Pretraining Methods', 'RAG', 'Security']
---
Perceptually Aligned Gradients (PAG) refer to an intriguing property observed in robust image classification models wherein their input gradients align with human perception and pose semantic meanings. While this phenomenon has gained significant research attention it was solely studied in the context of unimodal vision45;only architectures. In this work we extend the study of PAG to Vision45;Language architectures which form the foundations for diverse image45;text tasks and applications. Through an adversarial robustification finetuning of CLIP we demonstrate that robust Vision45;Language models exhibit PAG in contrast to their vanilla counterparts. This work reveals the merits of CLIP with PAG (CLIPAG) in several vision45;language generative tasks. Notably we show that seamlessly integrating CLIPAG in a plug45;n45;play manner leads to substantial improvements in vision45;language generative applications. Furthermore leveraging its PAG property CLIPAG enables text45;to45;image generation without any generative model which typically requires huge generators.

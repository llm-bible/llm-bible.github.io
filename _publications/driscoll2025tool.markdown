---
layout: publication
title: 'Doyoutrustai: A Tool To Teach Students About AI Misinformation And Prompt Engineering'
authors: Phillip Driscoll, Priyanka Kumar
conference: "Arxiv"
year: 2025
bibkey: driscoll2025tool
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2504.13859'}
tags: ['Prompting', 'GPT', 'Tools', 'Model Architecture']
---
AI, especially Large Language Models (LLMs) like ChatGPT, have rapidly
developed and gained widespread adoption in the past five years, shifting user
preference from traditional search engines. However, the generative nature of
LLMs raises concerns about presenting misinformation as fact. To address this,
we developed a web-based application that helps K-12 students enhance critical
thinking by identifying misleading information in LLM responses about major
historical figures. In this paper, we describe the implementation and design
details of the DoYouTrustAI tool, which can be used to provide an interactive
lesson which teaches students about the dangers of misinformation and how
believable generative AI can make it seem. The DoYouTrustAI tool utilizes
prompt engineering to present the user with AI generated summaries about the
life of a historical figure. These summaries can be either accurate accounts of
that persons life, or an intentionally misleading alteration of their history.
The user is tasked with determining the validity of the statement without
external resources. Our research questions for this work were:(RQ1) How can we
design a tool that teaches students about the dangers of misleading information
and of how misinformation can present itself in LLM responses? (RQ2) Can we
present prompt engineering as a topic that is easily understandable for
students? Our findings highlight the need to correct misleading information
before users retain it. Our tool lets users select familiar individuals for
testing to reduce random guessing and presents misinformation alongside known
facts to maintain believability. It also provides pre-configured prompt
instructions to show how different prompts affect AI responses. Together, these
features create a controlled environment where users learn the importance of
verifying AI responses and understanding prompt engineering.

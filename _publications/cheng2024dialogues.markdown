---
layout: publication
title: in Dialogues We Learn Towards Personalized Dialogue Without Pre45;defined Profiles Through In45;dialogue Learning
authors: Cheng Chuanqi, Tu Quan, Wu Wei, Shang Shuo, Mao Cunli, Yu Zhengtao, Yan Rui
conference: "Arxiv"
year: 2024
bibkey: cheng2024dialogues
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.03102"}
tags: ['Applications', 'Attention Mechanism', 'Model Architecture', 'RAG', 'Tools']
---
Personalized dialogue systems have gained significant attention in recent years for their ability to generate responses in alignment with different personas. However most existing approaches rely on pre45;defined personal profiles which are not only time45;consuming and labor45;intensive to create but also lack flexibility. We propose In45;Dialogue Learning (IDL) a fine45;tuning framework that enhances the ability of pre45;trained large language models to leverage dialogue history to characterize persona for completing personalized dialogue generation tasks without pre45;defined profiles. Our experiments on three datasets demonstrate that IDL brings substantial improvements with BLEU and ROUGE scores increasing by up to 20037; and 24737; respectively. Additionally the results of human evaluations further validate the efficacy of our proposed method.

---
layout: publication
title: 'Frame In, Frame Out: Do Llms Generate More Biased News Headlines Than Humans?'
authors: Valeria Pastorino, Nafise Sadat Moosavi
conference: "Arxiv"
year: 2025
bibkey: pastorino2025frame
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2505.05406"}
tags: ['Tools', 'Ethics and Bias', 'Model Architecture', 'Reinforcement Learning', 'Training Techniques']
---
Framing in media critically shapes public perception by selectively
emphasizing some details while downplaying others. With the rise of large
language models in automated news and content creation, there is growing
concern that these systems may introduce or even amplify framing biases
compared to human authors. In this paper, we explore how framing manifests in
both out-of-the-box and fine-tuned LLM-generated news content. Our analysis
reveals that, particularly in politically and socially sensitive contexts, LLMs
tend to exhibit more pronounced framing than their human counterparts. In
addition, we observe significant variation in framing tendencies across
different model architectures, with some models displaying notably higher
biases. These findings point to the need for effective post-training mitigation
strategies and tighter evaluation frameworks to ensure that automated news
content upholds the standards of balanced reporting.

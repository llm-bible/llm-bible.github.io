---
layout: publication
title: Gemini In Reasoning Unveiling Commonsense In Multimodal Large Language Models
authors: Wang Yuqing, Zhao Yun
conference: "Arxiv"
year: 2023
bibkey: wang2023gemini
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2312.17661"}
tags: ['GPT', 'Model Architecture', 'Multimodal Models']
---
The burgeoning interest in Multimodal Large Language Models (MLLMs) such as OpenAIs GPT-4V(ision) has significantly impacted both academic and industrial realms. These models enhance Large Language Models (LLMs) with advanced visual understanding capabilities facilitating their application in a variety of multimodal tasks. Recently Google introduced Gemini a cutting-edge MLLM designed specifically for multimodal integration. Despite its advancements preliminary benchmarks indicate that Gemini lags behind GPT models in commonsense reasoning tasks. However this assessment based on a limited dataset (i.e. HellaSWAG) does not fully capture Geminis authentic commonsense reasoning potential. To address this gap our study undertakes a thorough evaluation of Geminis performance in complex reasoning tasks that necessitate the integration of commonsense knowledge across modalities. We carry out a comprehensive analysis of 12 commonsense reasoning datasets ranging from general to domain-specific tasks. This includes 11 datasets focused solely on language as well as one that incorporates multimodal elements. Our experiments across four LLMs and two MLLMs demonstrate Geminis competitive commonsense reasoning capabilities. Additionally we identify common challenges faced by current LLMs and MLLMs in addressing commonsense problems underscoring the need for further advancements in enhancing the commonsense reasoning abilities of these models.

---
layout: publication
title: Crafting Large Language Models For Enhanced Interpretability
authors: Sun Chung-en, Oikarinen Tuomas, Weng Tsui-wei
conference: "Arxiv"
year: 2024
bibkey: sun2024crafting
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.04307"}
tags: ['Ethics And Bias', 'Interpretability And Explainability']
---
We introduce the Concept Bottleneck Large Language Model (CB45;LLM) a pioneering approach to creating inherently interpretable Large Language Models (LLMs). Unlike traditional black45;box LLMs that rely on post45;hoc interpretation methods with limited neuron function insights CB45;LLM sets a new standard with its built45;in interpretability scalability and ability to provide clear accurate explanations. This innovation not only advances transparency in language models but also enhances their effectiveness. Our unique Automatic Concept Correction (ACC) strategy successfully narrows the performance gap with conventional black45;box LLMs positioning CB45;LLM as a model that combines the high accuracy of traditional LLMs with the added benefit of clear interpretability 45;45; a feature markedly absent in existing LLMs.

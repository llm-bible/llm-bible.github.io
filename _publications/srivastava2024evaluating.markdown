---
layout: publication
title: Evaluating LLMs Mathematical Reasoning in Financial Document Question Answering
authors: Srivastava Pragya, Malik Manuj, Gupta Vivek, Ganu Tanuja, Roth Dan
conference: "Arxiv"
year: 2024
bibkey: srivastava2024evaluating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.11194"}
tags: ['ARXIV', 'Applications', 'LLM', 'Prompt']
---
Large Language Models (LLMs) excel in natural language understanding but their capability for complex mathematical reasoning with an amalgamation of structured tables and unstructured text is uncertain. This study explores LLMs mathematical reasoning on four financial tabular question-answering datasets TATQA FinQA ConvFinQA and Multihiertt. Through extensive experiments with various models and prompting techniques we assess how LLMs adapt to complex tables and mathematical tasks. We focus on sensitivity to table complexity and performance variations with an increasing number of arithmetic reasoning steps. The results provide insights into LLMs capabilities and limitations in handling complex mathematical scenarios for semi-structured tables. Ultimately we introduce a novel prompting technique tailored to semi-structured documents matching or outperforming other baselines in performance while providing a nuanced understanding of LLMs abilities for such a task.

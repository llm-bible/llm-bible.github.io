---
layout: publication
title: 'Towards Efficient Generative Large Language Model Serving: A Survey From Algorithms To Systems'
authors: Xupeng Miao, Gabriele Oliaro, Zhihao Zhang, Xinhao Cheng, Hongyi Jin, Tianqi Chen, Zhihao Jia
conference: "Arxiv"
year: 2023
bibkey: miao2023towards
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2312.15234"}
tags: ['Efficiency and Optimization', 'Survey Paper', 'Tools', 'Reinforcement Learning']
---
In the rapidly evolving landscape of artificial intelligence (AI), generative
large language models (LLMs) stand at the forefront, revolutionizing how we
interact with our data. However, the computational intensity and memory
consumption of deploying these models present substantial challenges in terms
of serving efficiency, particularly in scenarios demanding low latency and high
throughput. This survey addresses the imperative need for efficient LLM serving
methodologies from a machine learning system (MLSys) research perspective,
standing at the crux of advanced AI innovations and practical system
optimizations. We provide in-depth analysis, covering a spectrum of solutions,
ranging from cutting-edge algorithmic modifications to groundbreaking changes
in system designs. The survey aims to provide a comprehensive understanding of
the current state and future directions in efficient LLM serving, offering
valuable insights for researchers and practitioners in overcoming the barriers
of effective LLM deployment, thereby reshaping the future of AI.

---
layout: publication
title: Laviter Learning Aligned Visual And Textual Representations Assisted By Image And Caption Generation
authors: Shaikh Mohammad Abuzar, Ji Zhanghexuan, Moukheiber Dana, Shen Yan, Srihari Sargur, Gao Mingchen
conference: "Arxiv"
year: 2021
bibkey: shaikh2021learning
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2109.04993"}
tags: ['Attention Mechanism', 'Model Architecture', 'Pretraining Methods', 'Training Techniques', 'Transformer']
---
Pre45;training visual and textual representations from large45;scale image45;text pairs is becoming a standard approach for many downstream vision45;language tasks. The transformer45;based models learn inter and intra45;modal attention through a list of self45;supervised learning tasks. This paper proposes LAViTeR a novel architecture for visual and textual representation learning. The main module Visual Textual Alignment (VTA) will be assisted by two auxiliary tasks GAN45;based image synthesis and Image Captioning. We also propose a new evaluation metric measuring the similarity between the learnt visual and textual embedding. The experimental results on two public datasets CUB and MS45;COCO demonstrate superior visual and textual representation alignment in the joint feature embedding space

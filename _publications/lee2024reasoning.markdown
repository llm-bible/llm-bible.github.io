---
layout: publication
title: 'Reasoning Abilities Of Large Language Models: In-depth Analysis On The Abstraction And Reasoning Corpus'
authors: Seungpil Lee, Woochang Sim, Donghyeon Shin, Wongyu Seo, Jiwon Park, Seokki Lee, Sanha Hwang, Sejin Kim, Sundong Kim
conference: "Arxiv"
year: 2024
bibkey: lee2024reasoning
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.11793"}
tags: ['Uncategorized']
---
The existing methods for evaluating the inference abilities of Large Language
Models (LLMs) have been predominantly results-centric, making it challenging to
assess the inference process comprehensively. We introduce a novel approach
using the Abstraction and Reasoning Corpus (ARC) benchmark to evaluate the
inference and contextual understanding abilities of LLMs in a process-centric
manner, focusing on three key components from the Language of Thought
Hypothesis (LoTH): Logical Coherence, Compositionality, and Productivity. Our
carefully designed experiments reveal that while LLMs demonstrate some
inference capabilities, they still significantly lag behind human-level
reasoning in these three aspects. The main contribution of this paper lies in
introducing the LoTH perspective, which provides a method for evaluating the
reasoning process that conventional results-oriented approaches fail to
capture, thereby offering new insights into the development of human-level
reasoning in artificial intelligence systems.

---
layout: publication
title: 'Prompt-unseen-emotion: Zero-shot Expressive Speech Synthesis With Prompt-llm Contextual Knowledge For Mixed Emotions'
authors: Xiaoxue Gao, Huayun Zhang, Nancy F. Chen
conference: "Arxiv"
year: 2025
bibkey: gao2025prompt
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2506.02742"}
tags: ['RAG', 'Prompting', 'Model Architecture']
---
Existing expressive text-to-speech (TTS) systems primarily model a limited set of categorical emotions, whereas human conversations extend far beyond these predefined emotions, making it essential to explore more diverse emotional speech generation for more natural interactions. To bridge this gap, this paper proposes a novel prompt-unseen-emotion (PUE) approach to generate unseen emotional speech via emotion-guided prompt learning. PUE is trained utilizing an LLM-TTS architecture to ensure emotional consistency between categorical emotion-relevant prompts and emotional speech, allowing the model to quantitatively capture different emotion weightings per utterance. During inference, mixed emotional speech can be generated by flexibly adjusting emotion proportions and leveraging LLM contextual knowledge, enabling the model to quantify different emotional styles. Our proposed PUE successfully facilitates expressive speech synthesis of unseen emotions in a zero-shot setting.

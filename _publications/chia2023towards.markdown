---
layout: publication
title: INSTRUCTEVAL Towards Holistic Evaluation Of Instruction45;tuned Large Language Models
authors: Chia Yew Ken, Hong Pengfei, Bing Lidong, Poria Soujanya
conference: "Arxiv"
year: 2023
bibkey: chia2023towards
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2306.04757"}
  - {name: "Code", url: "https://github.com/declare&#45;lab/instruct&#45;eval"}
tags: ['Agentic', 'Applications', 'GPT', 'Has Code', 'Model Architecture', 'Pretraining Methods', 'RAG', 'Reinforcement Learning', 'Tools', 'Training Techniques']
---
Instruction45;tuned large language models have revolutionized natural language processing and have shown great potential in applications such as conversational agents. These models such as GPT45;4 can not only master language but also solve complex tasks in areas like mathematics coding medicine and law. Despite their impressive capabilities there is still a lack of comprehensive understanding regarding their full potential primarily due to the black45;box nature of many models and the absence of holistic evaluation studies. To address these challenges we present INSTRUCTEVAL a more comprehensive evaluation suite designed specifically for instruction45;tuned large language models. Unlike previous works our evaluation involves a rigorous assessment of models based on problem45;solving writing ability and alignment to human values. We take a holistic approach to analyze various factors affecting model performance including the pretraining foundation instruction45;tuning data and training methods. Our findings reveal that the quality of instruction data is the most crucial factor in scaling model performance. While open45;source models demonstrate impressive writing abilities there is substantial room for improvement in problem45;solving and alignment. We are encouraged by the rapid development of models by the open45;source community but we also highlight the need for rigorous evaluation to support claims made about these models. Through INSTRUCTEVAL we aim to foster a deeper understanding of instruction45;tuned models and advancements in their capabilities. INSTRUCTEVAL is publicly available at https://github.com/declare&#45;lab/instruct&#45;eval.

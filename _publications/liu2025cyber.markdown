---
layout: publication
title: 'Cyber Defense Reinvented: Large Language Models As Threat Intelligence Copilots'
authors: Xiaoqun Liu, Jiacheng Liang, Qiben Yan, Jiyong Jang, Sicheng Mao, Muchao Ye, Jinyuan Jia, Zhaohan Xi
conference: "Arxiv"
year: 2025
bibkey: liu2025cyber
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.20791"}
tags: ['Agentic', 'Tools', 'RAG', 'Reinforcement Learning', 'Security']
---
The exponential growth of cyber threat knowledge, exemplified by the
expansion of databases such as MITRE-CVE and NVD, poses significant challenges
for cyber threat analysis. Security professionals are increasingly burdened by
the sheer volume and complexity of information, creating an urgent need for
effective tools to navigate, synthesize, and act on large-scale data to counter
evolving threats proactively. However, conventional threat intelligence tools
often fail to scale with the dynamic nature of this data and lack the
adaptability to support diverse threat intelligence tasks.
  In this work, we introduce CYLENS, a cyber threat intelligence copilot
powered by large language models (LLMs). CYLENS is designed to assist security
professionals throughout the entire threat management lifecycle, supporting
threat attribution, contextualization, detection, correlation, prioritization,
and remediation. To ensure domain expertise, CYLENS integrates knowledge from
271,570 threat reports into its model parameters and incorporates six
specialized NLP modules to enhance reasoning capabilities. Furthermore, CYLENS
can be customized to meet the unique needs of different or ganizations,
underscoring its adaptability. Through extensive evaluations, we demonstrate
that CYLENS consistently outperforms industry-leading LLMs and state-of-the-art
cybersecurity agents. By detailing its design, development, and evaluation,
this work provides a blueprint for leveraging LLMs to address complex,
data-intensive cybersecurity challenges.

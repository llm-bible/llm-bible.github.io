---
layout: publication
title: Vision Encoder-Decoder Models for AI Coaching
authors: Nayak Jyothi S, Khan Afifah Khan Mohammed Ajmal, Manjeshwar Chirag, Banday Imadh Ajaz
conference: "Arxiv"
year: 2023
bibkey: nayak2023vision
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2311.16161"}
tags: ['GPT', 'Model Architecture', 'Multimodal Models', 'Pretraining Methods', 'Transformer']
---
This research paper introduces an innovative AI coaching approach by integrating vision-encoder-decoder models. The feasibility of this method is demonstrated using a Vision Transformer as the encoder and GPT-2 as the decoder achieving a seamless integration of visual input and textual interaction. Departing from conventional practices of employing distinct models for image recognition and text-based coaching our integrated architecture directly processes input images enabling natural question-and-answer dialogues with the AI coach. This unique strategy simplifies model architecture while enhancing the overall user experience in human-AI interactions. We showcase sample results to demonstrate the capability of the model. The results underscore the methodologys potential as a promising paradigm for creating efficient AI coach models in various domains involving visual inputs. Importantly this potential holds true regardless of the particular visual encoder or text decoder chosen. Additionally we conducted experiments with different sizes of GPT-2 to assess the impact on AI coach performance providing valuable insights into the scalability and versatility of our proposed methodology.

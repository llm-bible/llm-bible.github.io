---
layout: publication
title: 'Dreamblend: Advancing Personalized Fine-tuning Of Text-to-image Diffusion Models'
authors: Shwetha Ram, Tal Neiman, Qianli Feng, Andrew Stuart, Son Tran, Trishul Chilimbi
conference: "Arxiv"
year: 2024
bibkey: ram2024advancing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2411.19390"}
tags: ['Training Techniques', 'Model Architecture', 'Reinforcement Learning', 'Merging', 'Pretraining Methods', 'Fine-Tuning', 'Prompting', 'Attention Mechanism']
---
Given a small number of images of a subject, personalized image generation
techniques can fine-tune large pre-trained text-to-image diffusion models to
generate images of the subject in novel contexts, conditioned on text prompts.
In doing so, a trade-off is made between prompt fidelity, subject fidelity and
diversity. As the pre-trained model is fine-tuned, earlier checkpoints
synthesize images with low subject fidelity but high prompt fidelity and
diversity. In contrast, later checkpoints generate images with low prompt
fidelity and diversity but high subject fidelity. This inherent trade-off
limits the prompt fidelity, subject fidelity and diversity of generated images.
In this work, we propose DreamBlend to combine the prompt fidelity from earlier
checkpoints and the subject fidelity from later checkpoints during inference.
We perform a cross attention guided image synthesis from a later checkpoint,
guided by an image generated by an earlier checkpoint, for the same prompt.
This enables generation of images with better subject fidelity, prompt fidelity
and diversity on challenging prompts, outperforming state-of-the-art
fine-tuning methods.

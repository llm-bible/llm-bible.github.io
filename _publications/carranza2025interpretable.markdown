---
layout: publication
title: 'Interpretable And Robust Dialogue State Tracking Via Natural Language Summarization With Llms'
authors: Rafael Carranza, Mateo Alejandro Rojas
conference: "Arxiv"
year: 2025
bibkey: carranza2025interpretable
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2503.08857'}
tags: ['Interpretability and Explainability', 'RAG', 'Security', 'Model Architecture', 'Tools', 'BERT', 'GPT', 'Applications']
---
This paper introduces a novel approach to Dialogue State Tracking (DST) that
leverages Large Language Models (LLMs) to generate natural language
descriptions of dialogue states, moving beyond traditional slot-value
representations. Conventional DST methods struggle with open-domain dialogues
and noisy inputs. Motivated by the generative capabilities of LLMs, our Natural
Language DST (NL-DST) framework trains an LLM to directly synthesize
human-readable state descriptions. We demonstrate through extensive experiments
on MultiWOZ 2.1 and Taskmaster-1 datasets that NL-DST significantly outperforms
rule-based and discriminative BERT-based DST baselines, as well as generative
slot-filling GPT-2 DST models, in both Joint Goal Accuracy and Slot Accuracy.
Ablation studies and human evaluations further validate the effectiveness of
natural language state generation, highlighting its robustness to noise and
enhanced interpretability. Our findings suggest that NL-DST offers a more
flexible, accurate, and human-understandable approach to dialogue state
tracking, paving the way for more robust and adaptable task-oriented dialogue
systems.

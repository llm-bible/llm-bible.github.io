---
layout: publication
title: 'Exploiting Simulated User Feedback For Conversational Search: Ranking, Rewriting,
  And Beyond'
authors: "Paul Owoicho, Ivan Sekuli\u0107, Mohammad Aliannejadi, Jeffrey Dalton, Fabio\
  \ Crestani"
conference: Arxiv
year: 2023
citations: 16
bibkey: owoicho2023exploiting
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2304.13874'}]
tags: [Reinforcement Learning, Tools]
---
This research aims to explore various methods for assessing user feedback in
mixed-initiative conversational search (CS) systems. While CS systems enjoy
profuse advancements across multiple aspects, recent research fails to
successfully incorporate feedback from the users. One of the main reasons for
that is the lack of system-user conversational interaction data. To this end,
we propose a user simulator-based framework for multi-turn interactions with a
variety of mixed-initiative CS systems. Specifically, we develop a user
simulator, dubbed ConvSim, that, once initialized with an information need
description, is capable of providing feedback to a system's responses, as well
as answering potential clarifying questions. Our experiments on a wide variety
of state-of-the-art passage retrieval and neural re-ranking models show that
effective utilization of user feedback can lead to 16% retrieval performance
increase in terms of nDCG@3. Moreover, we observe consistent improvements as
the number of feedback rounds increases (35% relative improvement in terms of
nDCG@3 after three rounds). This points to a research gap in the development of
specific feedback processing modules and opens a potential for significant
advancements in CS. To support further research in the topic, we release over
30,000 transcripts of system-simulator interactions based on well-established
CS datasets.
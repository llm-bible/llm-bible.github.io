---
layout: publication
title: 'D.va: Validate Your Demonstration First Before You Use It'
authors: Qi Zhang, Zhiqing Xiao, Ruixuan Xiao, Lirong Gao, Junbo Zhao
conference: "Arxiv"
year: 2025
bibkey: zhang2025validate
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2502.13646'}
tags: ['Prompting', 'Security', 'In-Context Learning', 'Applications']
---
In-context learning (ICL) has demonstrated significant potential in enhancing
the capabilities of large language models (LLMs) during inference. It's
well-established that ICL heavily relies on selecting effective demonstrations
to generate outputs that better align with the expected results. As for
demonstration selection, previous approaches have typically relied on intuitive
metrics to evaluate the effectiveness of demonstrations, which often results in
limited robustness and poor cross-model generalization capabilities. To tackle
these challenges, we propose a novel method, \textbf\{D\}emonstration
\textbf\{VA\}lidation (\textbf\{D.Va\}), which integrates a demonstration
validation perspective into this field. By introducing the demonstration
validation mechanism, our method effectively identifies demonstrations that are
both effective and highly generalizable. \textbf\{D.Va\} surpasses all existing
demonstration selection techniques across both natural language understanding
(NLU) and natural language generation (NLG) tasks. Additionally, we demonstrate
the robustness and generalizability of our approach across various language
models with different retrieval models.

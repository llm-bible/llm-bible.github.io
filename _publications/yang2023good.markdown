---
layout: publication
title: Good Questions Help Zero45;shot Image Reasoning
authors: Yang Kaiwen, Shen Tao, Tian Xinmei, Geng Xiubo, Tao Chongyang, Tao Dacheng, Zhou Tianyi
conference: "Arxiv"
year: 2023
bibkey: yang2023good
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2312.01598"}
tags: ['Applications', 'Fine Tuning', 'Prompting', 'RAG']
---
Aligning the recent large language models (LLMs) with computer vision models leads to large vision45;language models (LVLMs) which have paved the way for zero45;shot image reasoning tasks. However LVLMs are usually trained on short high45;level captions only referring to sparse focus regions in images. Such a tunnel vision limits LVLMs to exploring other relevant contexts in complex scenes. To address this challenge we introduce Question45;Driven Visual Exploration (QVix) a novel prompting strategy that enhances the exploratory capabilities of LVLMs in zero45;shot reasoning tasks. QVix leverages LLMs strong language prior to generate input45;exploratory questions with more details than the original query guiding LVLMs to explore visual content more comprehensively and uncover subtle or peripheral details. QVix enables a wider exploration of visual scenes improving the LVLMs reasoning accuracy and depth in tasks such as visual question answering and visual entailment. Our evaluations on various challenging zero45;shot vision45;language benchmarks including ScienceQA and fine45;grained visual classification demonstrate that QVix significantly outperforms existing methods highlighting its effectiveness in bridging the gap between complex visual data and LVLMs exploratory abilities.

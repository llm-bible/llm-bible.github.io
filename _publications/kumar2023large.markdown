---
layout: publication
title: 'Large Language Models Humanize Technology'
authors: Pratyush Kumar
conference: "Arxiv"
year: 2023
bibkey: kumar2023large
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2305.05576"}
tags: ['Tools', 'Attention Mechanism', 'Model Architecture', 'Reinforcement Learning']
---
Large Language Models (LLMs) have made rapid progress in recent months and
weeks, garnering significant public attention. This has sparked concerns about
aligning these models with human values, their impact on labor markets, and the
potential need for regulation in further research and development. However, the
discourse often lacks a focus on the imperative to widely diffuse the societal
benefits of LLMs. To qualify this societal benefit, we assert that LLMs exhibit
emergent abilities to humanize technology more effectively than previous
technologies, and for people across language, occupation, and accessibility
divides. We argue that they do so by addressing three mechanizing bottlenecks
in today's computing technologies: creating diverse and accessible content,
learning complex digital tools, and personalizing machine learning algorithms.
We adopt a case-based approach and illustrate each bottleneck with two examples
where current technology imposes bottlenecks that LLMs demonstrate the ability
to address. Given this opportunity to humanize technology widely, we advocate
for more widespread understanding of LLMs, tools and methods to simplify use of
LLMs, and cross-cutting institutional capacity.

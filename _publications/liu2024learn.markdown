---
layout: publication
title: "Let's Learn Step By Step: Enhancing In-context Learning Ability With Curriculum Learning"
authors: Liu Yinpeng, Liu Jiawei, Shi Xiang, Cheng Qikai, Huang Yong, Lu Wei
conference: "Arxiv"
year: 2024
bibkey: liu2024learn
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.10738"}
tags: ['Applications', 'Few Shot', 'Fine Tuning', 'In Context Learning', 'Prompting']
---
Demonstration ordering which is an important strategy for in-context learning (ICL) can significantly affects the performance of large language models (LLMs). However most of the current approaches of ordering require high computational costs to introduce the priori knowledge. In this paper inspired by the human learning process we propose a simple but effective demonstration ordering method for ICL named the few-shot In-Context Curriculum Learning (ICCL). The ICCL implies gradually increasing the complexity of prompt demonstrations during the inference process. The difficulty can be assessed by human experts or LLMs-driven metrics such as perplexity. Then we design extensive experiments to discuss the effectiveness of the ICCL at both corpus-level and instance-level. Moreover we also investigate the formation mechanism of LLMs ICCL capability. Experimental results demonstrate that ICCL developed during the instruction-tuning stage is effective for representative open-source LLMs. To facilitate further research and applications by other scholars we make the code publicly available.

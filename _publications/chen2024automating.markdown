---
layout: publication
title: 'Fortran2cpp: Automating Fortran-to-c++ Translation Using Llms Via Multi-turn Dialogue And Dual-agent Integration'
authors: Le Chen, Bin Lei, Dunzhi Zhou, Pei-hung Lin, Chunhua Liao, Caiwen Ding, Ali Jannesari
conference: "Arxiv"
year: 2024
bibkey: chen2024automating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2412.19770"}
  - {name: "Code", url: "https://github.com/HPC-Fortran2CPP/Fortran2Cpp"}
tags: ['Agentic', 'Applications', 'Reinforcement Learning', 'Training Techniques', 'Has Code']
---
Translating legacy Fortran code into C++ is a crucial step in modernizing
high-performance computing (HPC) applications. However, the scarcity of
high-quality, parallel Fortran-to-C++ datasets and the limited domain-specific
expertise in large language models (LLMs) present significant challenges for
automated translation. In this paper, we introduce Fortran2CPP, a multi-turn
dialogue dataset generated by a novel LLM agent-based approach that integrates
a dual-LLM Questioner-Solver module to enhance translation accuracy. Our
dataset comprises 11.7k dialogues capturing iterative feedback-decision
workflows including code translation, compilation, execution, unit testing, and
error-fixing. Using this dataset, we fine-tune several open-weight LLMs and
achieve up to a 3.31x improvement in CodeBLEU scores and a 92% increase in
compilation success rate, demonstrating enhanced syntactic accuracy and
functional reliability. Our findings highlight the value of dialogue-based LLM
training for complex code translation tasks. The dataset and model have been
open-sourced and are available on our public GitHub
repository\footnote\{\url\{https://github.com/HPC-Fortran2CPP/Fortran2Cpp\}\}.

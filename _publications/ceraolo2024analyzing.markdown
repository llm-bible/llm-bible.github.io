---
layout: publication
title: 'Quriosity: Analyzing Human Questioning Behavior And Causal Inquiry Through Curiosity-driven Queries'
authors: Roberto Ceraolo, Dmitrii Kharlapenko, Ahmad Khan, Amélie Reymond, Rada Mihalcea, Bernhard Schölkopf, Mrinmaya Sachan, Zhijing Jin
conference: "Arxiv"
year: 2024
bibkey: ceraolo2024analyzing
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2405.20318'}
tags: ['Reinforcement Learning', 'Prompting', 'Tools']
---
Recent progress in Large Language Model (LLM) technology has changed our role
in interacting with these models. Instead of primarily testing these models
with questions we already know answers to, we are now using them for queries
where the answers are unknown to us, driven by human curiosity. This shift
highlights the growing need to understand curiosity-driven human questions -
those that are more complex, open-ended, and reflective of real-world needs. To
this end, we present Quriosity, a collection of 13.5K naturally occurring
questions from three diverse sources: human-to-search-engine queries,
human-to-human interactions, and human-to-LLM conversations. Our comprehensive
collection enables a rich understanding of human curiosity across various
domains and contexts. Our analysis reveals a significant presence of causal
questions (up to 42%) in the dataset, for which we develop an iterative prompt
improvement framework to identify all causal queries and examine their unique
linguistic properties, cognitive complexity and source distribution. Our paper
paves the way for future work on causal question identification and open-ended
chatbot interactions.

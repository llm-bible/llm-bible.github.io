---
layout: publication
title: Can Small Language Models Be Good Reasoners For Sequential Recommendation
authors: Yuling Wang, Changxin Tian, Binbin Hu, Yanhua Yu, Ziqi Liu, Zhiqiang Zhang, Jun Zhou, Liang Pang, Xiao Wang
conference: "Arxiv"
year: 2024
bibkey: wang2024can
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/http://arxiv.org/abs/2403.04260v2"}
tags: ['Distillation', 'Efficiency And Optimization', 'GPT', 'Model Architecture', 'Prompting', 'Tools']
---
Large language models (LLMs) open up new horizons for sequential recommendations owing to their remarkable language comprehension and generation capabilities. However there are still numerous challenges that should be addressed to successfully implement sequential recommendations empowered by LLMs. Firstly user behavior patterns are often complex and relying solely on one45;step reasoning from LLMs may lead to incorrect or task45;irrelevant responses. Secondly the prohibitively resource requirements of LLM (e.g. ChatGPT45;175B) are overwhelmingly high and impractical for real sequential recommender systems. In this paper we propose a novel Step45;by45;step knowLedge dIstillation fraMework for recommendation (SLIM) paving a promising path for sequential recommenders to enjoy the exceptional reasoning capabilities of LLMs in a slim (i.e. resource45;efficient) manner. We introduce CoT prompting based on user behavior sequences for the larger teacher model. The rationales generated by the teacher model are then utilized as labels to distill the downstream smaller student model (e.g. LLaMA245;7B). In this way the student model acquires the step45;by45;step reasoning capabilities in recommendation tasks. We encode the generated rationales from the student model into a dense vector which empowers recommendation in both ID45;based and ID45;agnostic scenarios. Extensive experiments demonstrate the effectiveness of SLIM over state45;of45;the45;art baselines and further analysis showcasing its ability to generate meaningful recommendation reasoning at affordable costs.

---
layout: publication
title: AI Safety In Generative AI Large Language Models A Survey
authors: Chua Jaymari, Li Yun, Yang Shiyi, Wang Chen, Yao Lina
conference: "Arxiv"
year: 2024
bibkey: chua2024ai
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.18369"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Pretraining Methods', 'RAG', 'Reinforcement Learning', 'Responsible AI', 'Security', 'Survey Paper']
---
Large Language Model (LLMs) such as ChatGPT that exhibit generative AI capabilities are facing accelerated adoption and innovation. The increased presence of Generative AI (GAI) inevitably raises concerns about the risks and safety associated with these models. This article provides an up45;to45;date survey of recent trends in AI safety research of GAI45;LLMs from a computer scientists perspective specific and technical. In this survey we explore the background and motivation for the identified harms and risks in the context of LLMs being generative language models; our survey differentiates by emphasising the need for unified theories of the distinct safety challenges in the research development and applications of LLMs. We start our discussion with a concise introduction to the workings of LLMs supported by relevant literature. Then we discuss earlier research that has pointed out the fundamental constraints of generative models or lack of understanding thereof (e.g. performance and safety trade45;offs as LLMs scale in number of parameters). We provide a sufficient coverage of LLM alignment 45;45; delving into various approaches contending methods and present challenges associated with aligning LLMs with human preferences. By highlighting the gaps in the literature and possible implementation oversights our aim is to create a comprehensive analysis that provides insights for addressing AI safety in LLMs and encourages the development of aligned and secure models. We conclude our survey by discussing future directions of LLMs for AI safety offering insights into ongoing research in this critical area.

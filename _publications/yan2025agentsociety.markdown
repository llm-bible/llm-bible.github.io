---
layout: publication
title: 'Agentsociety Challenge: Designing LLM Agents For User Modeling And Recommendation On Web Platforms'
authors: Yuwei Yan, Yu Shang, Qingbin Zeng, Yu Li, Keyu Zhao, Zhiheng Zheng, Xuefei Ning, Tianji Wu, Shengen Yan, Yu Wang, Fengli Xu, Yong Li
conference: "Arxiv"
year: 2025
bibkey: yan2025agentsociety
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.18754"}
tags: ['Agentic', 'Reinforcement Learning', 'RecSys', 'Tools']
---
The AgentSociety Challenge is the first competition in the Web Conference
that aims to explore the potential of Large Language Model (LLM) agents in
modeling user behavior and enhancing recommender systems on web platforms. The
Challenge consists of two tracks: the User Modeling Track and the
Recommendation Track. Participants are tasked to utilize a combined dataset
from Yelp, Amazon, and Goodreads, along with an interactive environment
simulator, to develop innovative LLM agents. The Challenge has attracted 295
teams across the globe and received over 1,400 submissions in total over the
course of 37 official competition days. The participants have achieved 21.9%
and 20.3% performance improvement for Track 1 and Track 2 in the Development
Phase, and 9.1% and 15.9% in the Final Phase, representing a significant
accomplishment. This paper discusses the detailed designs of the Challenge,
analyzes the outcomes, and highlights the most successful LLM agent designs. To
support further research and development, we have open-sourced the benchmark
environment at https://tsinghua-fib-lab.github.io/AgentSocietyChallenge.

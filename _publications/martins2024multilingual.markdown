---
layout: publication
title: 'Eurollm: Multilingual Language Models For Europe'
authors: Pedro Henrique Martins, Patrick Fernandes, João Alves, Nuno M. Guerreiro, Ricardo Rei, Duarte M. Alves, José Pombal, Amin Farajian, Manuel Faysse, Mateusz Klimaszewski, Pierre Colombo, Barry Haddow, José G. C. De Souza, Alexandra Birch, André F. T. Martins
conference: "Arxiv"
year: 2024
bibkey: martins2024multilingual
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2409.16235'}
tags: ['Large-Scale Training', 'Efficiency and Optimization', 'Model Architecture', 'Applications', 'Scaling Laws', 'Pre-Training']
---
The quality of open-weight LLMs has seen significant improvement, yet they
remain predominantly focused on English. In this paper, we introduce the
EuroLLM project, aimed at developing a suite of open-weight multilingual LLMs
capable of understanding and generating text in all official European Union
languages, as well as several additional relevant languages. We outline the
progress made to date, detailing our data collection and filtering process, the
development of scaling laws, the creation of our multilingual tokenizer, and
the data mix and modeling configurations. Additionally, we release our initial
models: EuroLLM-1.7B and EuroLLM-1.7B-Instruct and report their performance on
multilingual general benchmarks and machine translation.

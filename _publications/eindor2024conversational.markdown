---
layout: publication
title: Conversational Prompt Engineering
authors: Ein-dor Liat, Toledo-ronen Orith, Spector Artem, Gretz Shai, Dankin Lena, Halfon Alon, Katz Yoav, Slonim Noam
conference: "Arxiv"
year: 2024
bibkey: eindor2024conversational
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.04560"}
tags: ['Applications', 'Prompting']
---
Prompts are how humans communicate with LLMs. Informative prompts are essential for guiding LLMs to produce the desired output. However prompt engineering is often tedious and time45;consuming requiring significant expertise limiting its widespread use. We propose Conversational Prompt Engineering (CPE) a user45;friendly tool that helps users create personalized prompts for their specific tasks. CPE uses a chat model to briefly interact with users helping them articulate their output preferences and integrating these into the prompt. The process includes two main stages first the model uses user45;provided unlabeled data to generate data45;driven questions and utilize user responses to shape the initial instruction. Then the model shares the outputs generated by the instruction and uses user feedback to further refine the instruction and the outputs. The final result is a few45;shot prompt where the outputs approved by the user serve as few45;shot examples. A user study on summarization tasks demonstrates the value of CPE in creating personalized high45;performing prompts. The results suggest that the zero45;shot prompt obtained is comparable to its 45; much longer 45; few45;shot counterpart indicating significant savings in scenarios involving repetitive tasks with large text volumes.

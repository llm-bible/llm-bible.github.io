---
layout: publication
title: 'Vinmt: Neural Machine Translation Toolkit'
authors: Nguyen Hoang Quan, Nguyen Thanh Dat, Nguyen Hoang Minh Cong, Nguyen Van Vinh, Ngo Thi Vinh, Nguyen Phuong Thai, Tran Hong Viet
conference: "Arxiv"
year: 2021
bibkey: quan2021neural
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2112.15272"}
tags: ['Model Architecture', 'Tools', 'Reinforcement Learning', 'Pretraining Methods', 'Transformer', 'Applications']
---
We present an open-source toolkit for neural machine translation (NMT). The
new toolkit is mainly based on vaulted Transformer (Vaswani et al., 2017) along
with many other improvements detailed below, in order to create a
self-contained, simple to use, consistent and comprehensive framework for
Machine Translation tasks of various domains. It is tooled to support both
bilingual and multilingual translation tasks, starting from building the model
from respective corpora, to inferring new predictions or packaging the model to
serving-capable JIT format.

---
layout: publication
title: 'Catalm: Empowering Catalyst Design Through Large Language Models'
authors: Ludi Wang, Xueqing Chen, Yi Du, Yuanchun Zhou, Yang Gao, Wenjuan Cui
conference: "Arxiv"
year: 2024
bibkey: wang2024empowering
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.17440"}
tags: ['Training Techniques', 'Tools', 'RAG', 'Pretraining Methods', 'Fine-Tuning', 'Prompting']
---
The field of catalysis holds paramount importance in shaping the trajectory
of sustainable development, prompting intensive research efforts to leverage
artificial intelligence (AI) in catalyst design. Presently, the fine-tuning of
open-source large language models (LLMs) has yielded significant breakthroughs
across various domains such as biology and healthcare. Drawing inspiration from
these advancements, we introduce CataLM Cata\}lytic Language Model), a large
language model tailored to the domain of electrocatalytic materials. Our
findings demonstrate that CataLM exhibits remarkable potential for facilitating
human-AI collaboration in catalyst knowledge exploration and design. To the
best of our knowledge, CataLM stands as the pioneering LLM dedicated to the
catalyst domain, offering novel avenues for catalyst discovery and development.

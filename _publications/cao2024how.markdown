---
layout: publication
title: 'How Large Language Models (llms) Extrapolate: From Guided Missiles To Guided Prompts'
authors: Xuenan Cao
conference: "Arxiv"
year: 2024
bibkey: cao2024how
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2501.10361"}
tags: ['Efficiency and Optimization', 'Model Architecture', 'GPT', 'BERT', 'Prompting']
---
This paper argues that we should perceive LLMs as machines of extrapolation.
Extrapolation is a statistical function for predicting the next value in a
series. Extrapolation contributes to both GPT successes and controversies
surrounding its hallucination. The term hallucination implies a malfunction,
yet this paper contends that it in fact indicates the chatbot efficiency in
extrapolation, albeit an excess of it. This article bears a historical
dimension: it traces extrapolation to the nascent years of cybernetics. In
1941, when Norbert Wiener transitioned from missile science to communication
engineering, the pivotal concept he adopted was none other than extrapolation.
Soviet mathematician Andrey Kolmogorov, renowned for his compression logic that
inspired OpenAI, had developed in 1939 another extrapolation project that
Wiener later found rather like his own. This paper uncovers the connections
between hot war science, Cold War cybernetics, and the contemporary debates on
LLM performances.

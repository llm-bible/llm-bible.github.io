---
layout: publication
title: 'The GPT Surprise: Offering Large Language Model Chat In A Massive Coding Class Reduced Engagement But Increased Adopters Exam Performances'
authors: Allen Nie, Yash Chandak, Miroslav Suzara, Malika Ali, Juliette Woodrow, Matt Peng, Mehran Sahami, Emma Brunskill, Chris Piech
conference: "Arxiv"
year: 2024
bibkey: nie2024gpt
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2407.09975'}
tags: ['RAG', 'Model Architecture', 'Tools', 'GPT', 'Reinforcement Learning']
---
Large language models (LLMs) are quickly being adopted in a wide range of
learning experiences, especially via ubiquitous and broadly accessible chat
interfaces like ChatGPT and Copilot. This type of interface is readily
available to students and teachers around the world, yet relatively little
research has been done to assess the impact of such generic tools on student
learning. Coding education is an interesting test case, both because LLMs have
strong performance on coding tasks, and because LLM-powered support tools are
rapidly becoming part of the workflow of professional software engineers. To
help understand the impact of generic LLM use on coding education, we conducted
a large-scale randomized control trial with 5,831 students from 146 countries
in an online coding class in which we provided some students with access to a
chat interface with GPT-4. We estimate positive benefits on exam performance
for adopters, the students who used the tool, but over all students, the
advertisement of GPT-4 led to a significant average decrease in exam
participation. We observe similar decreases in other forms of course
engagement. However, this decrease is modulated by the student's country of
origin. Offering access to LLMs to students from low human development index
countries increased their exam participation rate on average. Our results
suggest there may be promising benefits to using LLMs in an introductory coding
class, but also potential harms for engagement, which makes their longer term
impact on student success unclear. Our work highlights the need for additional
investigations to help understand the potential impact of future adoption and
integration of LLMs into classrooms.

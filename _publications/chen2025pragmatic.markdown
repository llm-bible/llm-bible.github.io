---
layout: publication
title: 'Pragmatic Inference Chain (PIC) Improving Llms'' Reasoning Of Authentic Implicit Toxic Language'
authors: Xi Chen, Shuo Wang
conference: "Arxiv"
year: 2025
bibkey: chen2025pragmatic
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2503.01539'}
tags: ['RAG', 'Model Architecture', 'Tools', 'GPT', 'Prompting', 'Ethics and Bias']
---
The rapid development of large language models (LLMs) gives rise to ethical
concerns about their performance, while opening new avenues for developing
toxic language detection techniques. However, LLMs' unethical output and their
capability of detecting toxicity have primarily been tested on language data
that do not demand complex meaning inference, such as the biased associations
of 'he' with programmer and 'she' with household. Nowadays toxic language
adopts a much more creative range of implicit forms, thanks to advanced
censorship. In this study, we collect authentic toxic interactions that evade
online censorship and that are verified by human annotators as inference
intensive. To evaluate and improve LLMs' reasoning of the authentic implicit
toxic language, we propose a new prompting method, Pragmatic Inference Chain
(PIC), drawn on interdisciplinary findings from cognitive science and
linguistics. The PIC prompting significantly improves the success rate of
GPT-4o, Llama-3.1-70B-Instruct, and DeepSeek-v2.5 in identifying implicit toxic
language, compared to both direct prompting and Chain-of-Thought. In addition,
it also facilitates the models to produce more explicit and coherent reasoning
processes, hence can potentially be generalized to other inference-intensive
tasks, e.g., understanding humour and metaphors.

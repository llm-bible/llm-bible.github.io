---
layout: publication
title: 'True Detective: A Deep Abductive Reasoning Benchmark Undoable For GPT-3 And Challenging For GPT-4'
authors: Maksym Del, Mark Fishel
conference: "Arxiv"
year: 2022
bibkey: del2022true
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2212.10114"}
tags: ['RAG', 'Tools', 'GPT', 'Model Architecture']
---
Large language models (LLMs) have demonstrated solid zero-shot reasoning
capabilities, which is reflected in their performance on the current test
tasks. This calls for a more challenging benchmark requiring highly advanced
reasoning ability to be solved. In this paper, we introduce such a benchmark,
consisting of 191 long-form (1200 words on average) mystery narratives
constructed as detective puzzles. Puzzles are sourced from the "5 Minute
Mystery" platform and include a multiple-choice question for evaluation. Only
47% of humans solve a puzzle successfully on average, while the best human
solvers achieve over 80% success rate. We show that GPT-3 models barely
outperform random on this benchmark (with 28% accuracy) while state-of-the-art
GPT-4 solves only 38% of puzzles. This indicates that there is still a
significant gap in the deep reasoning abilities of LLMs and humans and
highlights the need for further research in this area. Our work introduces a
challenging benchmark for future studies on reasoning in language models and
contributes to a better understanding of the limits of LLMs' abilities.

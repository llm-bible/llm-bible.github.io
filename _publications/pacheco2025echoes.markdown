---
layout: publication
title: 'Echoes Of Power: Investigating Geopolitical Bias In US And China Large Language Models'
authors: Andre G. C. Pacheco, Athus Cavalini, Giovanni Comarela
conference: "Arxiv"
year: 2025
bibkey: pacheco2025echoes
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2503.16679"}
tags: ['Tools', 'GPT', 'Ethics and Bias', 'Model Architecture', 'Reinforcement Learning']
---
Large Language Models (LLMs) have emerged as powerful tools for generating
human-like text, transforming human-machine interactions. However, their
widespread adoption has raised concerns about their potential to influence
public opinion and shape political narratives. In this work, we investigate the
geopolitical biases in US and Chinese LLMs, focusing on how these models
respond to questions related to geopolitics and international relations. We
collected responses from ChatGPT and DeepSeek to a set of geopolitical
questions and evaluated their outputs through both qualitative and quantitative
analyses. Our findings show notable biases in both models, reflecting distinct
ideological perspectives and cultural influences. However, despite these
biases, for a set of questions, the models' responses are more aligned than
expected, indicating that they can address sensitive topics without necessarily
presenting directly opposing viewpoints. This study highlights the potential of
LLMs to shape public discourse and underscores the importance of critically
assessing AI-generated content, particularly in politically sensitive contexts.

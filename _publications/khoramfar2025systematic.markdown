---
layout: publication
title: 'DEEPQUESTION: Systematic Generation Of Real-world Challenges For Evaluating Llms Performance'
authors: Ali Khoramfar, Ali Ramezani, Mohammad Mahdi Mohajeri, Mohammad Javad Dousti, Majid Nili Ahmadabadi, Heshaam Faili
conference: "Arxiv"
year: 2025
bibkey: khoramfar2025systematic
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2505.24532'}
tags: ['Reinforcement Learning', 'Tools']
---
LLMs often excel on standard benchmarks but falter on real-world tasks. We introduce DeepQuestion, a scalable automated framework that augments existing datasets based on Bloom's taxonomy and creates novel questions that trace original solution paths to probe evaluative and creative skills. Extensive experiments across ten open-source and proprietary models, covering both general-purpose and reasoning LLMs, reveal substantial performance drops (even up to 70% accuracy loss) on higher-order tasks, underscoring persistent gaps in deep reasoning. Our work highlights the need for cognitively diverse benchmarks to advance LLM progress. DeepQuestion and related datasets will be released upon acceptance of the paper.

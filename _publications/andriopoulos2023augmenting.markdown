---
layout: publication
title: Augmenting Llms With Knowledge A Survey On Hallucination Prevention
authors: Andriopoulos Konstantinos, Pouwelse Johan
conference: "Arxiv"
year: 2023
bibkey: andriopoulos2023augmenting
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.16459"}
tags: ['Fine Tuning', 'Language Modeling', 'Merging', 'Model Architecture', 'Pretraining Methods', 'RAG', 'Reinforcement Learning', 'Survey Paper']
---
Large pre-trained language models have demonstrated their proficiency in storing factual knowledge within their parameters and achieving remarkable results when fine-tuned for downstream natural language processing tasks. Nonetheless their capacity to access and manipulate knowledge with precision remains constrained resulting in performance disparities on knowledge-intensive tasks when compared to task-specific architectures. Additionally the challenges of providing provenance for model decisions and maintaining up-to-date world knowledge persist as open research frontiers. To address these limitations the integration of pre-trained models with differentiable access mechanisms to explicit non-parametric memory emerges as a promising solution. This survey delves into the realm of language models (LMs) augmented with the ability to tap into external knowledge sources including external knowledge bases and search engines. While adhering to the standard objective of predicting missing tokens these augmented LMs leverage diverse possibly non-parametric external modules to augment their contextual processing capabilities departing from the conventional language modeling paradigm. Through an exploration of current advancements in augmenting large language models with knowledge this work concludes that this emerging research direction holds the potential to address prevalent issues in traditional LMs such as hallucinations un-grounded responses and scalability challenges.

---
layout: publication
title: 'Cbeval: A Framework For Evaluating And Interpreting Cognitive Biases In Llms'
authors: Ammar Shaikh, Raj Abhijit Dandekar, Sreedath Panat, Rajat Dandekar
conference: "Arxiv"
year: 2024
bibkey: shaikh2024framework
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2412.03605"}
tags: ['Interpretability', 'Tools', 'Ethics and Bias']
---
Rapid advancements in Large Language models (LLMs) has significantly enhanced
their reasoning capabilities. Despite improved performance on benchmarks, LLMs
exhibit notable gaps in their cognitive processes. Additionally, as reflections
of human-generated data, these models have the potential to inherit cognitive
biases, raising concerns about their reasoning and decision making
capabilities. In this paper we present a framework to interpret, understand and
provide insights into a host of cognitive biases in LLMs. Conducting our
research on frontier language models we're able to elucidate reasoning
limitations and biases, and provide reasoning behind these biases by
constructing influence graphs that identify phrases and words most responsible
for biases manifested in LLMs. We further investigate biases such as round
number bias and cognitive bias barrier revealed when noting framing effect in
language models.

---
layout: publication
title: 'Aligning Crowd-sourced Human Feedback For Reinforcement Learning On Code Generation By Large Language Models'
authors: Man Fai Wong, Chee Wei Tan
conference: "Arxiv"
year: 2025
bibkey: wong2025aligning
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2503.15129'}
tags: ['Agentic', 'Efficiency and Optimization', 'Applications', 'Tools', 'Reinforcement Learning']
---
This paper studies how AI-assisted programming and large language models
(LLM) improve software developers' ability via AI tools (LLM agents) like
Github Copilot and Amazon CodeWhisperer, while integrating human feedback to
enhance reinforcement learning (RLHF) with crowd-sourced computation to enhance
text-to-code generation. Additionally, we demonstrate that our Bayesian
optimization framework supports AI alignment in code generation by distributing
the feedback collection burden, highlighting the value of collecting human
feedback of good quality. Our empirical evaluations demonstrate the efficacy of
this approach, showcasing how LLM agents can be effectively trained for
improved text-to-code generation. Our Bayesian optimization framework can be
designed for general domain-specific languages, promoting the alignment of
large language model capabilities with human feedback in AI-assisted
programming for code generation.

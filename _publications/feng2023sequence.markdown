---
layout: publication
title: Sequence45;to45;sequence Pre45;training With Unified Modality Masking For Visual Document Understanding
authors: Feng Shuwei, Zhan Tianyang, Jie Zhanming, Luong Trung Quoc, Jin Xiaoran
conference: "Arxiv"
year: 2023
bibkey: feng2023sequence
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2305.10448"}
tags: ['Attention Mechanism', 'Ethics And Bias', 'Model Architecture', 'RAG', 'Training Techniques']
---
This paper presents GenDoc a general sequence45;to45;sequence document understanding model pre45;trained with unified masking across three modalities text image and layout. The proposed model utilizes an encoder45;decoder architecture which allows for increased adaptability to a wide range of downstream tasks with diverse output formats in contrast to the encoder45;only models commonly employed in document understanding. In addition to the traditional text infilling task used in previous encoder45;decoder models our pre45;training extends to include tasks of masked image token prediction and masked layout prediction. We also design modality45;specific instruction and adopt both disentangled attention and the mixture45;of45;modality45;experts strategy to effectively capture the information leveraged by each modality. Evaluation of the proposed model through extensive experiments on several downstream tasks in document understanding demonstrates its ability to achieve superior or competitive performance compared to state45;of45;the45;art approaches. Our analysis further suggests that GenDoc is more robust than the encoder45;only models in scenarios where the OCR quality is imperfect.

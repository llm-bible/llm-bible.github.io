---
layout: publication
title: 'Designerly Understanding: Information Needs For Model Transparency To Support
  Design Ideation For Ai-powered User Experience'
authors: Q. Vera Liao, Hariharan Subramonyam, Jennifer Wang, Jennifer Wortman Vaughan
conference: Arxiv
year: 2023
citations: 42
bibkey: liao2023designerly
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2302.10395'}]
tags: [Ethics and Bias, Interpretability and Explainability, Tools]
---
Despite the widespread use of artificial intelligence (AI), designing user
experiences (UX) for AI-powered systems remains challenging. UX designers face
hurdles understanding AI technologies, such as pre-trained language models, as
design materials. This limits their ability to ideate and make decisions about
whether, where, and how to use AI. To address this problem, we bridge the
literature on AI design and AI transparency to explore whether and how
frameworks for transparent model reporting can support design ideation with
pre-trained models. By interviewing 23 UX practitioners, we find that
practitioners frequently work with pre-trained models, but lack support for
UX-led ideation. Through a scenario-based design task, we identify common goals
that designers seek model understanding for and pinpoint their model
transparency information needs. Our study highlights the pivotal role that UX
designers can play in Responsible AI and calls for supporting their
understanding of AI limitations through model transparency and interrogation.
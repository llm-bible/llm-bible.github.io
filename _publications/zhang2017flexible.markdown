---
layout: publication
title: Flexible And Creative Chinese Poetry Generation Using Neural Memory
authors: Jiyuan Zhang et al.
conference: Arxiv
year: 2017
citations: 29
bibkey: zhang2017flexible
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1705.03773'}]
tags: [Transformer, Reinforcement Learning]
---
It has been shown that Chinese poems can be successfully generated by
sequence-to-sequence neural models, particularly with the attention mechanism.
A potential problem of this approach, however, is that neural models can only
learn abstract rules, while poem generation is a highly creative process that
involves not only rules but also innovations for which pure statistical models
are not appropriate in principle. This work proposes a memory-augmented neural
model for Chinese poem generation, where the neural model and the augmented
memory work together to balance the requirements of linguistic accordance and
aesthetic innovation, leading to innovative generations that are still
rule-compliant. In addition, it is found that the memory mechanism provides
interesting flexibility that can be used to generate poems with different
styles.
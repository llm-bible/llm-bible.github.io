---
layout: publication
title: 'Boosting Logical Reasoning In Large Language Models Through A New Framework: The Graph Of Thought'
authors: Lei Bin, Lin Pei-hung, Liao Chunhua, Ding Caiwen
conference: "Arxiv"
year: 2023
bibkey: lei2023boosting
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2308.08614"}
tags: ['GPT', 'Model Architecture', 'Prompting', 'RAG', 'Tools']
---
Recent advancements in large-scale models, such as GPT-4, have showcased
remarkable capabilities in addressing standard queries. However, when facing
complex problems that require multi-step logical reasoning, their accuracy
dramatically decreases. Current research has explored the realm of
\textit\{prompting engineering\} to bolster the inferential capacities of these
models. Our paper unveils a pioneering prompting technique, dubbed
\textit\{Graph of Thoughts (GoT)\}. Through testing on a trio of escalating
challenges: the 24-point game, resolution of high-degree polynomial equations,
and derivation of formulas for recursive sequences, our method outperformed
GPT-4, achieving accuracy improvements of \\(89.7%\\), \\(86%\\), and \\(56%\\) for each
respective task. Moreover, when juxtaposed with the state-of-the-art (SOTA)
prompting method, \textit\{Tree of Thought (ToT)\}, our approach registered an
average accuracy boost of \\(23%\\), \\(24%\\), and \\(15%\\).

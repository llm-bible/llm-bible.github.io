---
layout: publication
title: Leveraging Large Language Models With Chain45;of45;thought And Prompt Engineering For Traffic Crash Severity Analysis And Inference
authors: Zhen Hao, Shi Yucheng, Huang Yongcan, Yang Jidong J., Liu Ninghao
conference: "Arxiv"
year: 2024
bibkey: zhen2024leveraging
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.04652"}
tags: ['GPT', 'Model Architecture', 'Prompting', 'RAG', 'Reinforcement Learning', 'Tools']
---
Harnessing the power of Large Language Models (LLMs) this study explores the use of three state45;of45;the45;art LLMs specifically GPT45;3.545;turbo LLaMA345;8B and LLaMA345;70B for crash severity inference framing it as a classification task. We generate textual narratives from original traffic crash tabular data using a pre45;built template infused with domain knowledge. Additionally we incorporated Chain45;of45;Thought (CoT) reasoning to guide the LLMs in analyzing the crash causes and then inferring the severity. This study also examine the impact of prompt engineering specifically designed for crash severity inference. The LLMs were tasked with crash severity inference to (1) evaluate the models capabilities in crash severity analysis (2) assess the effectiveness of CoT and domain45;informed prompt engineering and (3) examine the reasoning abilities with the CoT framework. Our results showed that LLaMA345;70B consistently outperformed the other models particularly in zero45;shot settings. The CoT and Prompt Engineering techniques significantly enhanced performance improving logical reasoning and addressing alignment issues. Notably the CoT offers valuable insights into LLMs reasoning processes unleashing their capacity to consider diverse factors such as environmental conditions driver behavior and vehicle characteristics in severity analysis and inference.

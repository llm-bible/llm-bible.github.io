---
layout: publication
title: Mixture45;of45;skills Learning To Optimize Data Usage For Fine45;tuning Large Language Models
authors: Wu Minghao, Vu Thuy-trang, Qu Lizhen, Haffari Gholamreza
conference: "Arxiv"
year: 2024
bibkey: wu2024mixture
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.08811"}
tags: ['Agentic', 'Reinforcement Learning', 'Tools']
---
Large language models (LLMs) are typically fine45;tuned on diverse and extensive datasets sourced from various origins to develop a comprehensive range of skills such as writing reasoning chatting coding and more. Each skill has unique characteristics and these datasets are often heterogeneous and imbalanced making the fine45;tuning process highly challenging. Balancing the development of each skill while ensuring the model maintains its overall performance requires sophisticated techniques and careful dataset curation. In this work we propose a general model45;agnostic reinforcement learning framework Mixture45;of45;Skills (MoS) that learns to optimize data usage automatically during the fine45;tuning process. This framework ensures the optimal comprehensive skill development of LLMs by dynamically adjusting the focus on different datasets based on their current learning state. To validate the effectiveness of MoS we conduct extensive experiments using three diverse LLM backbones on two widely used benchmarks and demonstrate that MoS substantially enhances model performance. Building on the success of MoS we propose MoSpec an adaptation for task45;specific fine45;tuning which harnesses the utilities of various datasets for a specific purpose. Our work underlines the significance of dataset rebalancing and present MoS as a powerful general solution for optimizing data usage in the fine45;tuning of LLMs for various purposes.

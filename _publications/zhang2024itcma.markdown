---
layout: publication
title: ITCMA A Generative Agent Based On A Computational Consciousness Structure
authors: Zhang Hanzhong, Yin Jibin, Wang Haoyang, Xiang Ziwei
conference: "Arxiv"
year: 2024
bibkey: zhang2024itcma
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.20097"}
tags: ['Agentic', 'Pretraining Methods', 'Reinforcement Learning']
---
Large Language Models (LLMs) still face challenges in tasks requiring understanding implicit instructions and applying common-sense knowledge. In such scenarios LLMs may require multiple attempts to achieve human-level performance potentially leading to inaccurate responses or inferences in practical environments affecting their long-term consistency and behavior. This paper introduces the Internal Time-Consciousness Machine (ITCM) a computational consciousness structure to simulate the process of human consciousness. We further propose the ITCM-based Agent (ITCMA) which supports action generation and reasoning in open-world settings and can independently complete tasks. ITCMA enhances LLMs ability to understand implicit instructions and apply common-sense knowledge by considering agents interaction and reasoning with the environment. Evaluations in the Alfworld environment show that trained ITCMA outperforms the state-of-the-art (SOTA) by 937; on the seen set. Even untrained ITCMA achieves a 9637; task completion rate on the seen set 537; higher than SOTA indicating its superiority over traditional intelligent agents in utility and generalization. In real-world tasks with quadruped robots the untrained ITCMA achieves an 8537; task completion rate which is close to its performance in the unseen set demonstrating its comparable utility and universality in real-world settings.

---
layout: publication
title: 'Cuify The XR: An Open-source Package To Embed Llm-powered Conversational Agents In XR'
authors: Kadir Burak Buldu, Süleyman Özdel, Ka Hei Carrie Lau, Mengdi Wang, Daniel Saad, Sofie Schönborn, Auxane Boch, Enkelejda Kasneci, Efe Bozkir
conference: "Arxiv"
year: 2024
bibkey: buldu2024cuify
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2411.04671'}
  - {name: "Code", url: 'https://gitlab.lrz.de/hctl/cuify'}
tags: ['Reinforcement Learning', 'Agentic', 'Has Code', 'Training Techniques']
---
Recent developments in computer graphics, machine learning, and sensor
technologies enable numerous opportunities for extended reality (XR) setups for
everyday life, from skills training to entertainment. With large corporations
offering affordable consumer-grade head-mounted displays (HMDs), XR will likely
become pervasive, and HMDs will develop as personal devices like smartphones
and tablets. However, having intelligent spaces and naturalistic interactions
in XR is as important as technological advances so that users grow their
engagement in virtual and augmented spaces. To this end, large language model
(LLM)--powered non-player characters (NPCs) with speech-to-text (STT) and
text-to-speech (TTS) models bring significant advantages over conventional or
pre-scripted NPCs for facilitating more natural conversational user interfaces
(CUIs) in XR. This paper provides the community with an open-source,
customizable, extendable, and privacy-aware Unity package, CUIfy, that
facilitates speech-based NPC-user interaction with widely used LLMs, STT, and
TTS models. Our package also supports multiple LLM-powered NPCs per environment
and minimizes latency between different computational models through streaming
to achieve usable interactions between users and NPCs. We publish our source
code in the following repository: https://gitlab.lrz.de/hctl/cuify

---
layout: publication
title: 'Meta-evaluating Local Llms: Rethinking Performance Metrics For Serious Games'
authors: Andr√©s Isaza-giraldo, Paulo Bala, Lucas Pereira
conference: "Arxiv"
year: 2025
bibkey: isazagiraldo2025meta
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2504.12333"}
tags: ['RAG', 'Model Architecture', 'Tools', 'Reinforcement Learning']
---
The evaluation of open-ended responses in serious games presents a unique
challenge, as correctness is often subjective. Large Language Models (LLMs) are
increasingly being explored as evaluators in such contexts, yet their accuracy
and consistency remain uncertain, particularly for smaller models intended for
local execution. This study investigates the reliability of five small-scale
LLMs when assessing player responses in \textit\{En-join\}, a game that simulates
decision-making within energy communities. By leveraging traditional binary
classification metrics (including accuracy, true positive rate, and true
negative rate), we systematically compare these models across different
evaluation scenarios. Our results highlight the strengths and limitations of
each model, revealing trade-offs between sensitivity, specificity, and overall
performance. We demonstrate that while some models excel at identifying correct
responses, others struggle with false positives or inconsistent evaluations.
The findings highlight the need for context-aware evaluation frameworks and
careful model selection when deploying LLMs as evaluators. This work
contributes to the broader discourse on the trustworthiness of AI-driven
assessment tools, offering insights into how different LLM architectures handle
subjective evaluation tasks.

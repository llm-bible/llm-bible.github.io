---
layout: publication
title: What Affects The Stability Of Tool Learning? An Empirical Study On The Robustness Of Tool Learning Frameworks
authors: Huang Chengrui, Shi Zhengliang, Wen Yuntao, Chen Xiuying, Han Peng, Gao Shen, Shang Shuo
conference: "Arxiv"
year: 2024
bibkey: huang2024what
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.03007"}
tags: ['Applications', 'Fine Tuning', 'Pretraining Methods', 'Prompting', 'Reinforcement Learning', 'Security', 'Tools', 'Training Techniques']
---
Tool learning methods have enhanced the ability of large language models (LLMs) to interact with real-world applications. Many existing works fine-tune LLMs or design prompts to enable LLMs to select appropriate tools and correctly invoke them to meet user requirements. However it is observed in previous works that the performance of tool learning varies from tasks datasets training settings and algorithms. Without understanding the impact of these factors it can lead to inconsistent results inefficient model deployment and suboptimal tool utilization ultimately hindering the practical integration and scalability of LLMs in real-world scenarios. Therefore in this paper we explore the impact of both internal and external factors on the performance of tool learning frameworks. Through extensive experiments on two benchmark datasets we find several insightful conclusions for future work including the observation that LLMs can benefit significantly from increased trial and exploration. We believe our empirical study provides a new perspective for future tool learning research.

---
layout: publication
title: 'Stars, Stripes, And Silicon: Unravelling The Chatgpt''s All-american, Monochrome, Cis-centric Bias'
authors: Federico Torrielli
conference: "1st Workshop on Biased Data in Conversational Agents (Hosted at ECML-PKDD 18-22 September 2023)"
year: 2024
bibkey: torrielli2024unravelling
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2410.13868"}
tags: ['Responsible AI', 'Security', 'Model Architecture', 'Tools', 'Reinforcement Learning', 'GPT', 'Ethics and Bias', 'Applications']
---
This paper investigates the challenges associated with bias, toxicity,
unreliability, and lack of robustness in large language models (LLMs) such as
ChatGPT. It emphasizes that these issues primarily stem from the quality and
diversity of data on which LLMs are trained, rather than the model
architectures themselves. As LLMs are increasingly integrated into various
real-world applications, their potential to negatively impact society by
amplifying existing biases and generating harmful content becomes a pressing
concern. The paper calls for interdisciplinary efforts to address these
challenges. Additionally, it highlights the need for collaboration between
researchers, practitioners, and stakeholders to establish governance
frameworks, oversight, and accountability mechanisms to mitigate the harmful
consequences of biased LLMs. By proactively addressing these challenges, the AI
community can harness the enormous potential of LLMs for the betterment of
society without perpetuating harmful biases or exacerbating existing
inequalities.

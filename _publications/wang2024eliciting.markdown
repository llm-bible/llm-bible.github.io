---
layout: publication
title: 'Absinstruct: Eliciting Abstraction Ability From Llms Through Explanation Tuning With Plausibility Estimation'
authors: Wang Zhaowei, Fan Wei, Zong Qing, Zhang Hongming, Choi Sehyun, Fang Tianqing, Liu Xin, Song Yangqiu, Wong Ginny Y., See Simon
conference: "Arxiv"
year: 2024
bibkey: wang2024eliciting
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.10646"}
tags: ['Interpretability And Explainability', 'Reinforcement Learning', 'Tools']
---
Abstraction ability is crucial in human intelligence, which can also benefit
various tasks in NLP study. Existing work shows that LLMs are deficient in
abstract ability, and how to improve it remains unexplored. In this work, we
design the framework AbsInstruct to enhance LLMs' abstraction ability through
instruction tuning. The framework builds instructions with in-depth
explanations to assist LLMs in capturing the underlying rationale of
abstraction. Meanwhile, we introduce a plausibility estimator to select
instructions that are more consistent with the abstraction knowledge of LLMs to
be aligned. Then, our framework combines abstraction instructions with
general-purpose ones to build a hybrid dataset. Extensive experiments and
analyses demonstrate that our framework can considerably enhance LLMs'
abstraction ability with strong generalization performance while maintaining
their general instruction-following abilities.

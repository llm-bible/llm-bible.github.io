---
layout: publication
title: texttt123;accord125; Closing The Commonsense Measurability Gap
authors: Roewer-després François, Feng Jinyue, Zhu Zining, Rudzicz Frank
conference: "Arxiv"
year: 2024
bibkey: roewerdesprés2024closing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.02804"}
tags: ['GPT', 'Model Architecture', 'Tools']
---
We present texttt123;ACCORD125; a framework and benchmark suite for disentangling the commonsense grounding and reasoning abilities of large language models (LLMs) through controlled multi45;hop counterfactuals. texttt123;ACCORD125; introduces formal elements to commonsense reasoning to explicitly control and quantify reasoning complexity beyond the typical 1 or 2 hops. Uniquely texttt123;ACCORD125; can automatically generate benchmarks of arbitrary reasoning complexity and so it scales with future LLM improvements. Benchmarking state45;of45;the45;art LLMs 45;45; including GPT45;4o (202445;0545;13) Llama45;345;70B45;Instruct and Mixtral45;8x22B45;Instruct45;v0.1 45;45; shows performance degrading to random chance with only moderate scaling leaving substantial headroom for improvement. We release a leaderboard of the benchmark suite tested in this work as well as code for automatically generating more complex benchmarks.

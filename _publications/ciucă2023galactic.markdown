---
layout: publication
title: Galactic Chitchat Using Large Language Models To Converse With Astronomy Literature
authors: Ciucă Ioana, Ting Yuan-sen
conference: "Arxiv"
year: 2023
bibkey: ciucă2023galactic
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2304.05406"}
tags: ['Distillation', 'Efficiency And Optimization', 'Fine Tuning', 'GPT', 'Model Architecture', 'Prompting', 'RAG', 'Reinforcement Learning', 'Tools']
---
We demonstrate the potential of the state-of-the-art OpenAI GPT-4 large language model to engage in meaningful interactions with Astronomy papers using in-context prompting. To optimize for efficiency we employ a distillation technique that effectively reduces the size of the original input paper by 5037; while maintaining the paragraph structure and overall semantic integrity. We then explore the models responses using a multi-document context (ten distilled documents). Our findings indicate that GPT-4 excels in the multi-document domain providing detailed answers contextualized within the framework of related research findings. Our results showcase the potential of large language models for the astronomical community offering a promising avenue for further exploration particularly the possibility of utilizing the models for hypothesis generation.

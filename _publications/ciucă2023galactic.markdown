---
layout: publication
title: 'Galactic Chitchat: Using Large Language Models To Converse With Astronomy Literature'
authors: Ioana Ciucă, Yuan-sen Ting
conference: "Arxiv"
year: 2023
bibkey: ciucă2023galactic
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2304.05406"}
tags: ['Fine-Tuning', 'Tools', 'GPT', 'Efficiency and Optimization', 'RAG', 'Model Architecture', 'Reinforcement Learning', 'Prompting', 'Distillation']
---
We demonstrate the potential of the state-of-the-art OpenAI GPT-4 large
language model to engage in meaningful interactions with Astronomy papers using
in-context prompting. To optimize for efficiency, we employ a distillation
technique that effectively reduces the size of the original input paper by
50%, while maintaining the paragraph structure and overall semantic integrity.
We then explore the model's responses using a multi-document context (ten
distilled documents). Our findings indicate that GPT-4 excels in the
multi-document domain, providing detailed answers contextualized within the
framework of related research findings. Our results showcase the potential of
large language models for the astronomical community, offering a promising
avenue for further exploration, particularly the possibility of utilizing the
models for hypothesis generation.

---
layout: publication
title: 'Task Supportive And Personalized Human-large Language Model Interaction: A User Study'
authors: Wang Ben, Liu Jiqun, Karimnazarov Jamshed, Thompson Nicolas
conference: "Proceedings of the"
year: 2024
bibkey: wang2024task
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.06170"}
tags: ['Applications', 'Ethics And Bias', 'GPT', 'Interpretability And Explainability', 'Model Architecture', 'Prompting', 'Reinforcement Learning', 'Tools']
---
Large language model (LLM) applications such as ChatGPT are a powerful tool for online information-seeking (IS) and problem-solving tasks. However users still face challenges initializing and refining prompts and their cognitive barriers and biased perceptions further impede task completion. These issues reflect broader challenges identified within the fields of IS and interactive information retrieval (IIR). To address these our approach integrates task context and user perceptions into human-ChatGPT interactions through prompt engineering. We developed a ChatGPT-like platform integrated with supportive functions including perception articulation prompt suggestion and conversation explanation. Our findings of a user study demonstrate that the supportive functions help users manage expectations reduce cognitive loads better refine prompts and increase user engagement. This research enhances our comprehension of designing proactive and user-centric systems with LLMs. It offers insights into evaluating human-LLM interactions and emphasizes potential challenges for under served users.

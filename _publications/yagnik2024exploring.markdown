---
layout: publication
title: Medlm\: Exploring Language Models For Medical Question Answering Systems
authors: Yagnik Niraj, Jhaveri Jay, Sharma Vivek, Pila Gabriel
conference: "Arxiv"
year: 2024
bibkey: yagnik2024exploring
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.11389"}
tags: ['Applications', 'Fine Tuning', 'Pretraining Methods', 'Reinforcement Learning', 'Tools', 'Training Techniques']
---
In the face of rapidly expanding online medical literature automated systems for aggregating and summarizing information are becoming increasingly crucial for healthcare professionals and patients. Large Language Models (LLMs) with their advanced generative capabilities have shown promise in various NLP tasks and their potential in the healthcare domain particularly for Closed-Book Generative QnA is significant. However the performance of these models in domain-specific tasks such as medical Qamp;A remains largely unexplored. This study aims to fill this gap by comparing the performance of general and medical-specific distilled LMs for medical Qamp;A. We aim to evaluate the effectiveness of fine-tuning domain-specific LMs and compare the performance of different families of Language Models. The study will address critical questions about these models reliability comparative performance and effectiveness in the context of medical Qamp;A. The findings will provide valuable insights into the suitability of different LMs for specific applications in the medical domain.

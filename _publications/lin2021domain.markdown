---
layout: publication
title: Domain45;independent User Simulation With Transformers For Task45;oriented Dialogue Systems
authors: Lin Hsien-chin, Lubis Nurul, Hu Songbo, Van Niekerk Carel, Geishauser Christian, Heck Michael, Feng Shutong, Gašić Milica
conference: "Arxiv"
year: 2021
bibkey: lin2021domain
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2106.08838"}
tags: ['Agentic', 'Applications', 'Model Architecture', 'Pretraining Methods', 'Reinforcement Learning', 'Training Techniques', 'Transformer']
---
Dialogue policy optimisation via reinforcement learning requires a large number of training interactions which makes learning with real users time consuming and expensive. Many set45;ups therefore rely on a user simulator instead of humans. These user simulators have their own problems. While hand45;coded rule45;based user simulators have been shown to be sufficient in small simple domains for complex domains the number of rules quickly becomes intractable. State45;of45;the45;art data45;driven user simulators on the other hand are still domain45;dependent. This means that adaptation to each new domain requires redesigning and retraining. In this work we propose a domain45;independent transformer45;based user simulator (TUS). The structure of our TUS is not tied to a specific domain enabling domain generalisation and learning of cross45;domain user behaviour from data. We compare TUS with the state of the art using automatic as well as human evaluations. TUS can compete with rule45;based user simulators on pre45;defined domains and is able to generalise to unseen domains in a zero45;shot fashion.

---
layout: publication
title: 'Entity-conditioned Question Generation For Robust Attention Distribution In Neural Information Retrieval'
authors: Reddy Revanth Gangi, Sultan Md Arafat, Franz Martin, Sil Avirup, Ji Heng
conference: "Arxiv"
year: 2022
bibkey: reddy2022entity
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2204.11373"}
tags: ['Applications', 'Attention Mechanism', 'Model Architecture', 'Reinforcement Learning']
---
We show that supervised neural information retrieval (IR) models are prone to learning sparse attention patterns over passage tokens, which can result in key phrases including named entities receiving low attention weights, eventually leading to model under-performance. Using a novel targeted synthetic data generation method that identifies poorly attended entities and conditions the generation episodes on those, we teach neural IR to attend more uniformly and robustly to all entities in a given passage. On two public IR benchmarks, we empirically show that the proposed method helps improve both the model's attention patterns and retrieval performance, including in zero-shot settings.

---
layout: publication
title: Tab45;cot Zero45;shot Tabular Chain Of Thought
authors: Ziqi Jin, Wei Lu
conference: "Arxiv"
year: 2023
bibkey: jin2023tab
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/http://arxiv.org/abs/2305.17812v1"}
tags: ['Pretraining Methods', 'Prompting', 'RAG', 'Reinforcement Learning']
---
The chain45;of45;though (CoT) prompting methods were successful in various natural language processing (NLP) tasks thanks to their ability to unveil the underlying complex reasoning processes. Such reasoning processes typically exhibit implicitly structured steps. Recent efforts also started investigating methods to encourage more explicitly structured reasoning procedures to be captured. In this work we propose Tab45;CoT a novel tabular45;format CoT prompting method which allows the complex reasoning process to be explicitly modelled in a highly structured manner. Despite its simplicity we show that our approach is capable of performing reasoning across multiple dimensions (i.e. both rows and columns). We demonstrate our approachs strong zero45;shot and few45;shot capabilities through extensive experiments on a range of reasoning tasks.

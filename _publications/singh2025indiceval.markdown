---
layout: publication
title: 'Indiceval-xl: Bridging Linguistic Diversity In Code Generation Across Indic Languages'
authors: Ujjwal Singh, Aditi Sharma, Nikhil Gupta, Deepakshi, Vivek Kumar Jha
conference: "Arxiv"
year: 2025
bibkey: singh2025indiceval
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.19067"}
  - {name: "Code", url: "https://github.com/telekom/IndicEval-XL"}
tags: ['Agentic', 'Tools', 'Reinforcement Learning', 'Has Code', 'Prompting', 'Applications']
---
Large Language Models (LLMs) have demonstrated remarkable capabilities in
code generation from natural language prompts, revolutionizing software
development workflows. As we advance towards agent-based development paradigms,
these models form the cornerstone of next-generation software development
lifecycles. However, current benchmarks for evaluating multilingual code
generation capabilities are predominantly English-centric, limiting their
applicability across the global developer community. To address this
limitation, we present IndicEval-XL, a comprehensive benchmark for code
generation that incorporates 6 major Indic languages, collectively spoken by
approximately 14% of the world's population. Our benchmark bridges these
languages with 12 programming languages, creating a robust evaluation
framework. This work is particularly significant given India's representation
of one-eighth of the global population and the crucial role Indic languages
play in Indian society. IndicEval-XL represents a significant step toward
expanding the linguistic diversity in code generation systems and evaluation
frameworks. By developing resources that support multiple languages, we aim to
make AI-powered development tools more inclusive and accessible to developers
of various linguistic backgrounds. To facilitate further research and
development in this direction, we make our dataset and evaluation benchmark
publicly available at https://github.com/telekom/IndicEval-XL

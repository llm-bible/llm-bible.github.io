---
layout: publication
title: Attention Interpretability Across NLP Tasks
authors: Shikhar Vashishth, Shyam Upadhyay, Gaurav Singh Tomar, Manaal Faruqui
conference: Arxiv
year: 2019
citations: 98
bibkey: vashishth2019attention
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1909.11218'}]
tags: [Transformer, Interpretability and Explainability]
---
The attention layer in a neural network model provides insights into the
model's reasoning behind its prediction, which are usually criticized for being
opaque. Recently, seemingly contradictory viewpoints have emerged about the
interpretability of attention weights (Jain & Wallace, 2019; Vig & Belinkov,
2019). Amid such confusion arises the need to understand attention mechanism
more systematically. In this work, we attempt to fill this gap by giving a
comprehensive explanation which justifies both kinds of observations (i.e.,
when is attention interpretable and when it is not). Through a series of
experiments on diverse NLP tasks, we validate our observations and reinforce
our claim of interpretability of attention through manual evaluation.
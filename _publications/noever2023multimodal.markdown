---
layout: publication
title: Multimodal Analysis Of Google Bard And Gpt45;vision Experiments In Visual Reasoning
authors: Noever David, Noever Samantha Elizabeth Miller
conference: "Arxiv"
year: 2023
bibkey: noever2023multimodal
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.16705"}
tags: ['GPT', 'Model Architecture', 'Multimodal Models', 'Reinforcement Learning', 'Tools']
---
Addressing the gap in understanding visual comprehension in Large Language Models (LLMs) we designed a challenge45;response study subjecting Google Bard and GPT45;Vision to 64 visual tasks spanning categories like Visual Situational Reasoning and Next Scene Prediction. Previous models such as GPT4 leaned heavily on optical character recognition tools like Tesseract whereas Bard and GPT45;Vision akin to Google Lens and Visual API employ deep learning techniques for visual text recognition. However our findings spotlight both vision45;language models limitations while proficient in solving visual CAPTCHAs that stump ChatGPT alone it falters in recreating visual elements like ASCII art or analyzing Tic Tac Toe grids suggesting an over45;reliance on educated visual guesses. The prediction problem based on visual inputs appears particularly challenging with no common45;sense guesses for next45;scene forecasting based on current next45;token multimodal models. This study provides experimental insights into the current capacities and areas for improvement in multimodal LLMs.

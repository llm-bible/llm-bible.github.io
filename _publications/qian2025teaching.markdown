---
layout: publication
title: 'Teaching Large Language Models Number-focused Headline Generation With Key Element Rationales'
authors: Zhen Qian, Xiuzhen Zhang, Xiaofei Xu, Feng Xia
conference: "Arxiv"
year: 2025
bibkey: qian2025teaching
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2502.03129'}
tags: ['Applications', 'Tools']
---
Number-focused headline generation is a summarization task requiring both
high textual quality and precise numerical accuracy, which poses a unique
challenge for Large Language Models (LLMs). Existing studies in the literature
focus only on either textual quality or numerical reasoning and thus are
inadequate to address this challenge. In this paper, we propose a novel
chain-of-thought framework for using rationales comprising key elements of the
Topic, Entities, and Numerical reasoning (TEN) in news articles to enhance the
capability for LLMs to generate topic-aligned high-quality texts with precise
numerical accuracy. Specifically, a teacher LLM is employed to generate TEN
rationales as supervision data, which are then used to teach and fine-tune a
student LLM. Our approach teaches the student LLM automatic generation of
rationales with enhanced capability for numerical reasoning and topic-aligned
numerical headline generation. Experiments show that our approach achieves
superior performance in both textual quality and numerical accuracy.

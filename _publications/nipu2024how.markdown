---
layout: publication
title: How Reliable AI Chatbots Are For Disease Prediction From Patient Complaints?
authors: Nipu Ayesha Siddika, Islam K M Sajjadul, Madiraju Praveen
conference: "Arxiv"
year: 2024
bibkey: nipu2024how
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.13219"}
tags: ['Applications', 'BERT', 'Few Shot', 'GPT', 'Model Architecture', 'Pretraining Methods', 'RAG', 'Responsible AI', 'Transformer']
---
Artificial Intelligence (AI) chatbots leveraging Large Language Models (LLMs) are gaining traction in healthcare for their potential to automate patient interactions and aid clinical decision-making. This study examines the reliability of AI chatbots specifically GPT 4.0 Claude 3 Opus and Gemini Ultra 1.0 in predicting diseases from patient complaints in the emergency department. The methodology includes few-shot learning techniques to evaluate the chatbots effectiveness in disease prediction. We also fine-tune the transformer-based model BERT and compare its performance with the AI chatbots. Results suggest that GPT 4.0 achieves high accuracy with increased few-shot data while Gemini Ultra 1.0 performs well with fewer examples and Claude 3 Opus maintains consistent performance. BERTs performance however is lower than all the chatbots indicating limitations due to limited labeled data. Despite the chatbots varying accuracy none of them are sufficiently reliable for critical medical decision-making underscoring the need for rigorous validation and human oversight. This study reflects that while AI chatbots have potential in healthcare they should complement not replace human expertise to ensure patient safety. Further refinement and research are needed to improve AI-based healthcare applications reliability for disease prediction.

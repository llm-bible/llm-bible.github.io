---
layout: publication
title: 'The Reasoning-memorization Interplay In Language Models Is Mediated By A Single Direction'
authors: Yihuai Hong, Dian Zhou, Meng Cao, Lei Yu, Zhijing Jin
conference: "Arxiv"
year: 2025
bibkey: hong2025reasoning
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2503.23084"}
tags: ['Applications', 'Training Techniques', 'Language Modeling', 'Reinforcement Learning']
---
Large language models (LLMs) excel on a variety of reasoning benchmarks, but
previous studies suggest they sometimes struggle to generalize to unseen
questions, potentially due to over-reliance on memorized training examples.
However, the precise conditions under which LLMs switch between reasoning and
memorization during text generation remain unclear. In this work, we provide a
mechanistic understanding of LLMs' reasoning-memorization dynamics by
identifying a set of linear features in the model's residual stream that govern
the balance between genuine reasoning and memory recall. These features not
only distinguish reasoning tasks from memory-intensive ones but can also be
manipulated to causally influence model performance on reasoning tasks.
Additionally, we show that intervening in these reasoning features helps the
model more accurately activate the most relevant problem-solving capabilities
during answer generation. Our findings offer new insights into the underlying
mechanisms of reasoning and memory in LLMs and pave the way for the development
of more robust and interpretable generative AI systems.

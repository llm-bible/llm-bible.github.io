---
layout: publication
title: 'Emptransfo: A Multi-head Transformer Architecture For Creating Empathetic
  Dialog Systems'
authors: Rohola Zandie, Mohammad H. Mahoor
conference: Arxiv
year: 2020
citations: 37
bibkey: zandie2020multi
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2003.02958'}]
tags: [Transformer, GPT, Pre-Training]
---
Understanding emotions and responding accordingly is one of the biggest
challenges of dialog systems. This paper presents EmpTransfo, a multi-head
Transformer architecture for creating an empathetic dialog system. EmpTransfo
utilizes state-of-the-art pre-trained models (e.g., OpenAI-GPT) for language
generation, though models with different sizes can be used. We show that
utilizing the history of emotions and other metadata can improve the quality of
generated conversations by the dialog system. Our experimental results using a
challenging language corpus show that the proposed approach outperforms other
models in terms of Hit@1 and PPL (Perplexity).
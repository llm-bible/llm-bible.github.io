---
layout: publication
title: Fireact Toward Language Agent Fine45;tuning
authors: Chen Baian, Shu Chang, Shareghi Ehsan, Collier Nigel, Narasimhan Karthik, Yao Shunyu
conference: "Arxiv"
year: 2023
bibkey: chen2023toward
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.05915"}
tags: ['Agentic', 'Applications', 'Efficiency And Optimization', 'GPT', 'Model Architecture', 'Prompting', 'Reinforcement Learning', 'Security', 'Tools']
---
Recent efforts have augmented language models (LMs) with external tools or environments leading to the development of language agents that can reason and act. However most of these agents rely on few45;shot prompting techniques with off45;the45;shelf LMs. In this paper we investigate and argue for the overlooked direction of fine45;tuning LMs to obtain language agents. Using a setup of question answering (QA) with a Google search API we explore a variety of base LMs prompting methods fine45;tuning data and QA tasks and find language agents are consistently improved after fine45;tuning their backbone LMs. For example fine45;tuning Llama245;7B with 500 agent trajectories generated by GPT45;4 leads to a 7737; HotpotQA performance increase. Furthermore we propose FireAct a novel approach to fine45;tuning LMs with trajectories from multiple tasks and prompting methods and show having more diverse fine45;tuning data can further improve agents. Along with other findings regarding scaling effects robustness generalization efficiency and cost our work establishes comprehensive benefits of fine45;tuning LMs for agents and provides an initial set of experimental designs insights as well as open questions toward language agent fine45;tuning.

---
layout: publication
title: Large Language Models For Education&#58; A Survey
authors: Xu Hanyi, Gan Wensheng, Qi Zhenlian, Wu Jiayang, Yu Philip S.
conference: "Arxiv"
year: 2024
bibkey: xu2024large
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.13001"}
tags: ['Agentic', 'Applications', 'Efficiency And Optimization', 'Fine Tuning', 'Pretraining Methods', 'Reinforcement Learning', 'Survey Paper', 'Tools', 'Training Techniques']
---
Artificial intelligence (AI) has a profound impact on traditional education. In recent years large language models (LLMs) have been increasingly used in various applications such as natural language processing computer vision speech recognition and autonomous driving. LLMs have also been applied in many fields including recommendation finance government education legal affairs and finance. As powerful auxiliary tools LLMs incorporate various technologies such as deep learning pre-training fine-tuning and reinforcement learning. The use of LLMs for smart education (LLMEdu) has been a significant strategic direction for countries worldwide. While LLMs have shown great promise in improving teaching quality changing education models and modifying teacher roles the technologies are still facing several challenges. In this paper we conduct a systematic review of LLMEdu focusing on current technologies challenges and future developments. We first summarize the current state of LLMEdu and then introduce the characteristics of LLMs and education as well as the benefits of integrating LLMs into education. We also review the process of integrating LLMs into the education industry as well as the introduction of related technologies. Finally we discuss the challenges and problems faced by LLMEdu as well as prospects for future optimization of LLMEdu.

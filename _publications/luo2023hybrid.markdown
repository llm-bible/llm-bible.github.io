---
layout: publication
title: 'Hrot: Hybrid Prompt Strategy And Retrieval Of Thought For Table-text Hybrid Question Answering'
authors: Tongxu Luo, Fangyu Lei, Jiahe Lei, Weihao Liu, Shihu He, Jun Zhao, Kang Liu
conference: "Arxiv"
year: 2023
bibkey: luo2023hybrid
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2309.12669'}
tags: ['Attention Mechanism', 'Few-Shot', 'Model Architecture', 'Applications', 'Prompting', 'Reinforcement Learning', 'In-Context Learning']
---
Answering numerical questions over hybrid contents from the given tables and
text(TextTableQA) is a challenging task. Recently, Large Language Models (LLMs)
have gained significant attention in the NLP community. With the emergence of
large language models, In-Context Learning and Chain-of-Thought prompting have
become two particularly popular research topics in this field. In this paper,
we introduce a new prompting strategy called Hybrid prompt strategy and
Retrieval of Thought for TextTableQA. Through In-Context Learning, we prompt
the model to develop the ability of retrieval thinking when dealing with hybrid
data. Our method achieves superior performance compared to the fully-supervised
SOTA on the MultiHiertt dataset in the few-shot setting.

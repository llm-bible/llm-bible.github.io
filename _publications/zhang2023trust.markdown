---
layout: publication
title: Don't Trust Chatgpt When Your Question Is Not In English\: A Study Of Multilingual Abilities And Types Of Llms
authors: Zhang Xiang, Li Senyu, Hauer Bradley, Shi Ning, Kondrak Grzegorz
conference: "Arxiv"
year: 2023
bibkey: zhang2023trust
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2305.16339"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Prompting', 'Training Techniques']
---
Large Language Models (LLMs) have demonstrated exceptional natural language understanding abilities and have excelled in a variety of natural language processing (NLP)tasks in recent years. Despite the fact that most LLMs are trained predominantly in English multiple studies have demonstrated their comparative performance in many other languages. However fundamental questions persist regarding how LLMs acquire their multi-lingual abilities and how performance varies across different languages. These inquiries are crucial for the study of LLMs since users and researchers often come from diverse language backgrounds potentially influencing their utilization and interpretation of LLMs results. In this work we propose a systematic way of qualifying the performance disparities of LLMs under multilingual settings. We investigate the phenomenon of across-language generalizations in LLMs wherein insufficient multi-lingual training data leads to advanced multi-lingual capabilities. To accomplish this we employ a novel back-translation-based prompting method. The results show that GPT exhibits highly translating-like behaviour in multilingual settings.

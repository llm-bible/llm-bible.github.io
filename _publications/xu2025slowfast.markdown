---
layout: publication
title: 'Slowfast-llava-1.5: A Family Of Token-efficient Video Large Language Models For Long-form Video Understanding'
authors: Mingze Xu, Mingfei Gao, Shiyu Li, Jiasen Lu, Zhe Gan, Zhengfeng Lai, Meng Cao, Kai Kang, Yinfei Yang, Afshin Dehghan
conference: "Arxiv"
year: 2025
bibkey: xu2025slowfast
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2503.18943'}
tags: ['Training Techniques']
---
We introduce SlowFast-LLaVA-1.5 (abbreviated as SF-LLaVA-1.5), a family of
video large language models (LLMs) offering a token-efficient solution for
long-form video understanding. We incorporate the two-stream SlowFast mechanism
into a streamlined training pipeline, and perform joint video-image training on
a carefully curated data mixture of only publicly available datasets. Our
primary focus is on highly efficient model scales (1B and 3B), demonstrating
that even relatively small Video LLMs can achieve state-of-the-art performance
on video understanding, meeting the demand for mobile-friendly models.
Experimental results demonstrate that SF-LLaVA-1.5 achieves superior
performance on a wide range of video and image tasks, with robust results at
all model sizes (ranging from 1B to 7B). Notably, SF-LLaVA-1.5 achieves
state-of-the-art results in long-form video understanding (e.g., LongVideoBench
and MLVU) and excels at small scales across various video benchmarks.

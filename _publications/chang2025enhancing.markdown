---
layout: publication
title: 'Enhancing Low-resource Minority Language Translation With Llms And Retrieval-augmented Generation For Cultural Nuances'
authors: Chen-chi Chang, Chong-fu Li, Chu-hsuan Lee, Hung-shin Lee
conference: "Arxiv"
year: 2025
bibkey: chang2025enhancing
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2505.10829'}
tags: ['Reinforcement Learning', 'RAG', 'Language Modeling', 'Tools']
---
This study investigates the challenges of translating low-resource languages by integrating Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG). Various model configurations were tested on Hakka translations, with BLEU scores ranging from 12% (dictionary-only) to 31% (RAG with Gemini 2.0). The best-performing model (Model 4) combined retrieval and advanced language modeling, improving lexical coverage, particularly for specialized or culturally nuanced terms, and enhancing grammatical coherence. A two-stage method (Model 3) using dictionary outputs refined by Gemini 2.0 achieved a BLEU score of 26%, highlighting iterative correction's value and the challenges of domain-specific expressions. Static dictionary-based approaches struggled with context-sensitive content, demonstrating the limitations of relying solely on predefined resources. These results emphasize the need for curated resources, domain knowledge, and ethical collaboration with local communities, offering a framework that improves translation accuracy and fluency while supporting cultural preservation.

---
layout: publication
title: On The Intersection Of Self45;correction And Trust In Language Models
authors: Krishna Satyapriya
conference: "Arxiv"
year: 2023
bibkey: krishna2023intersection
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2311.02801"}
tags: ['Ethics And Bias']
---
Large Language Models (LLMs) have demonstrated remarkable capabilities in performing complex cognitive tasks. However their complexity and lack of transparency have raised several trustworthiness concerns including the propagation of misinformation and toxicity. Recent research has explored the self45;correction capabilities of LLMs to enhance their performance. In this work we investigate whether these self45;correction capabilities can be harnessed to improve the trustworthiness of LLMs. We conduct experiments focusing on two key aspects of trustworthiness truthfulness and toxicity. Our findings reveal that self45;correction can lead to improvements in toxicity and truthfulness but the extent of these improvements varies depending on the specific aspect of trustworthiness and the nature of the task. Interestingly our study also uncovers instances of self45;doubt in LLMs during the self45;correction process introducing a new set of challenges that need to be addressed.

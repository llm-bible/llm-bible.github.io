---
layout: publication
title: 'Defining Boundaries: A Spectrum Of Task Feasibility For Large Language Models'
authors: Wenbo Zhang, Zihang Xu, Hengrui Cai
conference: "Arxiv"
year: 2024
bibkey: zhang2024defining
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.05873"}
tags: ['Pretraining Methods', 'Training Techniques', 'Applications', 'Fine-Tuning']
---
Large language models (LLMs) have shown remarkable performance in various
tasks but often fail to handle queries that exceed their knowledge and
capabilities, leading to incorrect or fabricated responses. This paper
addresses the need for LLMs to recognize and refuse infeasible tasks due to the
required skills surpassing their capabilities. We first conceptualize
infeasible tasks for LLMs and provide categorizations that cover a spectrum of
related hallucinations over existing literature. We develop and benchmark a new
dataset comprising diverse infeasible and feasible tasks to evaluate multiple
LLMs' abilities to reject infeasible tasks. Furthermore, we explore the
potential of increasing LLMs' refusal capabilities with fine-tuning.
Experiments validate the effectiveness of our trained models, offering
promising directions for refining the operational boundaries of LLMs in real
applications.

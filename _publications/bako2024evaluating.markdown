---
layout: publication
title: 'Evaluating The Semantic Profiling Abilities Of Llms For Natural Language Utterances In Data Visualization'
authors: Hannah K. Bako, Arshnoor Bhutani, Xinyi Liu, Kwesi A. Cobbina, Zhicheng Liu
conference: "Arxiv"
year: 2024
bibkey: bako2024evaluating
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2407.06129'}
tags: ['GPT', 'Model Architecture']
---
Automatically generating data visualizations in response to human utterances
on datasets necessitates a deep semantic understanding of the data utterance,
including implicit and explicit references to data attributes, visualization
tasks, and necessary data preparation steps. Natural Language Interfaces (NLIs)
for data visualization have explored ways to infer such information, yet
challenges persist due to inherent uncertainty in human speech. Recent advances
in Large Language Models (LLMs) provide an avenue to address these challenges,
but their ability to extract the relevant semantic information remains
unexplored. In this study, we evaluate four publicly available LLMs (GPT-4,
Gemini-Pro, Llama3, and Mixtral), investigating their ability to comprehend
utterances even in the presence of uncertainty and identify the relevant data
context and visual tasks. Our findings reveal that LLMs are sensitive to
uncertainties in utterances. Despite this sensitivity, they are able to extract
the relevant data context. However, LLMs struggle with inferring visualization
tasks. Based on these results, we highlight future research directions on using
LLMs for visualization generation.

---
layout: publication
title: 'LLM Social Simulations Are A Promising Research Method'
authors: Jacy Reese Anthis, Ryan Liu, Sean M. Richardson, Austin C. Kozlowski, Bernard Koch, James Evans, Erik Brynjolfsson, Michael Bernstein
conference: "Arxiv"
year: 2025
bibkey: anthis2025llm
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2504.02234'}
tags: ['Training Techniques', 'Tools', 'Fine-Tuning', 'Prompting', 'Survey Paper', 'Pretraining Methods']
---
Accurate and verifiable large language model (LLM) simulations of human research subjects promise an accessible data source for understanding human behavior and training new AI systems. However, results to date have been limited, and few social scientists have adopted this method. In this position paper, we argue that the promise of LLM social simulations can be achieved by addressing five tractable challenges. We ground our argument in a review of empirical comparisons between LLMs and human research subjects, commentaries on the topic, and related work. We identify promising directions, including context-rich prompting and fine-tuning with social science datasets. We believe that LLM social simulations can already be used for pilot and exploratory studies, and more widespread use may soon be possible with rapidly advancing LLM capabilities. Researchers should prioritize developing conceptual models and iterative evaluations to make the best use of new AI systems.

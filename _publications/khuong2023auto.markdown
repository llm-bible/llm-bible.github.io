---
layout: publication
title: 'Auto-survey Challenge'
authors: Thanh Gia Hieu Tau, Lisn Khuong, Benedictus Kent Tau, Lisn Rachmat
conference: "Junior Conference on Data Science and Engineering 2023 Sep 2023 Orsay France"
year: 2023
bibkey: khuong2023auto
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.04480"}
tags: ['Responsible AI', 'Survey Paper', 'Tools', 'Reinforcement Learning', 'Prompting']
---
We present a novel platform for evaluating the capability of Large Language
Models (LLMs) to autonomously compose and critique survey papers spanning a
vast array of disciplines including sciences, humanities, education, and law.
Within this framework, AI systems undertake a simulated peer-review mechanism
akin to traditional scholarly journals, with human organizers serving in an
editorial oversight capacity. Within this framework, we organized a competition
for the AutoML conference 2023. Entrants are tasked with presenting stand-alone
models adept at authoring articles from designated prompts and subsequently
appraising them. Assessment criteria include clarity, reference
appropriateness, accountability, and the substantive value of the content. This
paper presents the design of the competition, including the implementation
baseline submissions and methods of evaluation.

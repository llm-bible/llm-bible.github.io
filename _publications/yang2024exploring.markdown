---
layout: publication
title: 'Exploring The Personality Traits Of Llms Through Latent Features Steering'
authors: Shu Yang, Shenzhe Zhu, Liang Liu, Lijie Hu, Mengdi Li, Di Wang
conference: "Arxiv"
year: 2024
bibkey: yang2024exploring
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2410.10863'}
tags: ['Agentic', 'Interpretability and Explainability', 'Training Techniques', 'Applications', 'Tools', 'Reinforcement Learning', 'Responsible AI']
---
Large language models (LLMs) have significantly advanced dialogue systems and
role-playing agents through their ability to generate human-like text. While
prior studies have shown that LLMs can exhibit distinct and consistent
personalities, the mechanisms through which these models encode and express
specific personality traits remain poorly understood. To address this, we
investigate how various factors, such as cultural norms and environmental
stressors, encoded within LLMs, shape their personality traits, guided by the
theoretical framework of social determinism. Inspired by related work on LLM
interpretability, we propose a training-free approach to modify the model's
behavior by extracting and steering latent features corresponding to factors
within the model, thereby eliminating the need for retraining. Furthermore, we
analyze the implications of these factors for model safety, focusing on their
impact through the lens of personality.

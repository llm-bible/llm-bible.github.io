---
layout: publication
title: 'Beyond Specialization: Assessing The Capabilities Of Mllms In Age And Gender Estimation'
authors: Maksim Kuprashevich, Grigorii Alekseenko, Irina Tolstykh
conference: "Arxiv"
year: 2024
bibkey: kuprashevich2024beyond
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.02302"}
tags: ['Multimodal Models', 'Model Architecture', 'GPT']
---
Multimodal Large Language Models (MLLMs) have recently gained immense
popularity. Powerful commercial models like ChatGPT-4V and Gemini, as well as
open-source ones such as LLaVA, are essentially general-purpose models and are
applied to solve a wide variety of tasks, including those in computer vision.
These neural networks possess such strong general knowledge and reasoning
abilities that they have proven capable of working even on tasks for which they
were not specifically trained. We compared the capabilities of the most
powerful MLLMs to date: ShareGPT4V, ChatGPT, LLaVA-Next in a specialized task
of age and gender estimation with our state-of-the-art specialized model,
MiVOLO. We also updated MiVOLO and provide details and new metrics in this
article. This comparison has yielded some interesting results and insights
about the strengths and weaknesses of the participating models. Furthermore, we
attempted various ways to fine-tune the ShareGPT4V model for this specific
task, aiming to achieve state-of-the-art results in this particular challenge.
Although such a model would not be practical in production, as it is incredibly
expensive compared to a specialized model like MiVOLO, it could be very useful
in some tasks, like data annotation.

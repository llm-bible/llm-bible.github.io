---
layout: publication
title: A Role45;specific Guided Large Language Model For Ophthalmic Consultation Based On Stylistic Differentiation
authors: Fu Laiyi, Fan Binbin, Du Hongkai, Feng Yanxiang, Li Chunhua, Song Huping
conference: "Arxiv"
year: 2024
bibkey: fu2024role
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.18483"}
  - {name: "Code", url: "https://github.com/sperfu/EyeDoc"}
tags: ['GPT', 'Has Code', 'Model Architecture', 'Pretraining Methods', 'RAG']
---
Ophthalmology consultations are crucial for diagnosing treating and preventing eye diseases. However the growing demand for consultations exceeds the availability of ophthalmologists. By leveraging large pre45;trained language models we can design effective dialogues for specific scenarios aiding in consultations. Traditional fine45;tuning strategies for question45;answering tasks are impractical due to increasing model size and often ignoring patient45;doctor role function during consultations. In this paper we propose EyeDoctor an ophthalmic medical questioning large language model that enhances accuracy through doctor45;patient role perception guided and an augmented knowledge base with external disease information. Experimental results show EyeDoctor achieves higher question45;answering precision in ophthalmology consultations. Notably EyeDoctor demonstrated a 7.2537; improvement in Rouge45;1 scores and a 10.1637; improvement in F1 scores on multi45;round datasets compared to second best model ChatGPT highlighting the importance of doctor45;patient role differentiation and dynamic knowledge base expansion for intelligent medical consultations. EyeDoc also serves as a free available web based service and souce code is available at https://github.com/sperfu/EyeDoc.

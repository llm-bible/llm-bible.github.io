---
layout: publication
title: RAG Based Question45;answering For Contextual Response Prediction System
authors: Veturi Sriram, Vaichal Saurabh, Jagadheesh Reshma Lal, Tripto Nafis Irtiza, Yan Nian
conference: "Arxiv"
year: 2024
bibkey: veturi2024rag
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2409.03708"}
tags: ['Agentic', 'Applications', 'BERT', 'Model Architecture', 'RAG', 'Reinforcement Learning', 'Tools']
---
Large Language Models (LLMs) have shown versatility in various Natural Language Processing (NLP) tasks including their potential as effective question45;answering systems. However to provide precise and relevant information in response to specific customer queries in industry settings LLMs require access to a comprehensive knowledge base to avoid hallucinations. Retrieval Augmented Generation (RAG) emerges as a promising technique to address this challenge. Yet developing an accurate question45;answering framework for real45;world applications using RAG entails several challenges 1) data availability issues 2) evaluating the quality of generated content and 3) the costly nature of human evaluation. In this paper we introduce an end45;to45;end framework that employs LLMs with RAG capabilities for industry use cases. Given a customer query the proposed system retrieves relevant knowledge documents and leverages them along with previous chat history to generate response suggestions for customer service agents in the contact centers of a major retail company. Through comprehensive automated and human evaluations we show that this solution outperforms the current BERT45;based algorithms in accuracy and relevance. Our findings suggest that RAG45;based LLMs can be an excellent support to human customer service representatives by lightening their workload.

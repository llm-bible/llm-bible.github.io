---
layout: publication
title: Deceptive AI Ecosystems: The Case Of Chatgpt
authors: Zhan Xiao, Xu Yifan, Sarkadi Stefan
conference: "Arxiv"
year: 2023
bibkey: zhan2023deceptive
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2306.13671"}
tags: ['Ethics And Bias', 'GPT', 'Model Architecture', 'Reinforcement Learning', 'Tools']
---
ChatGPT an AI chatbot has gained popularity for its capability in generating human-like responses. However this feature carries several risks most notably due to its deceptive behaviour such as offering users misleading or fabricated information that could further cause ethical issues. To better understand the impact of ChatGPT on our social cultural economic and political interactions it is crucial to investigate how ChatGPT operates in the real world where various societal pressures influence its development and deployment. This paper emphasizes the need to study ChatGPT in the wild as part of the ecosystem it is embedded in with a strong focus on user involvement. We examine the ethical challenges stemming from ChatGPTs deceptive human-like interactions and propose a roadmap for developing more transparent and trustworthy chatbots. Central to our approach is the importance of proactive risk assessment and user participation in shaping the future of chatbot technology.

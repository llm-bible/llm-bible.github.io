---
layout: publication
title: 'Amadeus-verbo Technical Report: The Powerful Qwen2.5 Family Models Trained In Portuguese'
authors: William Alberto Cruz-castañeda, Marcellus Amadeus
conference: "Arxiv"
year: 2025
bibkey: cruzcastañeda2025amadeus
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2506.00019"}
  - {name: "Code", url: "https://huggingface.co/collections/amadeusai/amadeus-verbo-qwen25-67cf2e7aae69ce2b3bcdcfda"}
tags: ['Has Code', 'Applications']
---
This report introduces the experience of developing Amadeus Verbo, a family of large language models for Brazilian Portuguese. To handle diverse use cases, Amadeus Verbo includes base-tuned, merged, and instruction-tuned models in sizes of 0.5B, 1.5B, 3B, 7B, 14B, 32B, and 72B parameters. Thus, the main objective is to show how easy it is to fine-tune foundation models to democratize the open-source development of Brazilian Portuguese LLMs when data and resources are available. Amadeus-Verbo family models are all available at HuggingFace at https://huggingface.co/collections/amadeusai/amadeus-verbo-qwen25-67cf2e7aae69ce2b3bcdcfda.

---
layout: publication
title: 'Logical Reasoning In Large Language Models: A Survey'
authors: Hanmeng Liu, Zhizhang Fu, Mengru Ding, Ruoxi Ning, Chaoli Zhang, Xiaozhang Liu, Yue Zhang
conference: "Arxiv"
year: 2025
bibkey: liu2025logical
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.09100"}
tags: ['Fine-Tuning', 'Agentic', 'Survey Paper', 'Reinforcement Learning']
---
With the emergence of advanced reasoning models like OpenAI o3 and
DeepSeek-R1, large language models (LLMs) have demonstrated remarkable
reasoning capabilities. However, their ability to perform rigorous logical
reasoning remains an open question. This survey synthesizes recent advancements
in logical reasoning within LLMs, a critical area of AI research. It outlines
the scope of logical reasoning in LLMs, its theoretical foundations, and the
benchmarks used to evaluate reasoning proficiency. We analyze existing
capabilities across different reasoning paradigms - deductive, inductive,
abductive, and analogical - and assess strategies to enhance reasoning
performance, including data-centric tuning, reinforcement learning, decoding
strategies, and neuro-symbolic approaches. The review concludes with future
directions, emphasizing the need for further exploration to strengthen logical
reasoning in AI systems.

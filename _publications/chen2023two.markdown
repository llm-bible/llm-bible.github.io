---
layout: publication
title: Two Failures Of Self45;consistency In The Multi45;step Reasoning Of Llms
authors: Chen Angelica, Phang Jason, Parrish Alicia, Padmakumar Vishakh, Zhao Chen, Bowman Samuel R., Cho Kyunghyun
conference: "Transactions on Machine Learning Research"
year: 2023
bibkey: chen2023two
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2305.14279"}
tags: ['GPT', 'Model Architecture', 'Pretraining Methods', 'Reinforcement Learning']
---
Large language models (LLMs) have achieved widespread success on a variety of in45;context few45;shot tasks but this success is typically evaluated via correctness rather than consistency. We argue that self45;consistency is an important criteria for valid multi45;step reasoning in tasks where the solution is composed of the answers to multiple sub45;steps. We propose two types of self45;consistency that are particularly important for multi45;step reasoning 45;45; hypothetical consistency (a models ability to predict what its output would be in a hypothetical other context) and compositional consistency (consistency of a models final outputs when intermediate sub45;steps are replaced with the models outputs for those steps). We demonstrate that multiple variants of the GPT45;3/45;4 models exhibit poor consistency rates across both types of consistency on a variety of tasks.

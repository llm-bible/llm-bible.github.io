---
layout: publication
title: Building Trust In Mental Health Chatbots: Safety Metrics And Llm-based Evaluation Tools
authors: Park Jung In, Abbasian Mahyar, Azimi Iman, Bounds Dawn, Jun Angela, Han Jaesu, Mccarron Robert, Borelli Jessica, Li Jia, Mahmoudi Mona, Wiedenhoeft Carmen, Rahmani Amir
conference: "Arxiv"
year: 2024
bibkey: park2024building
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.04650"}
tags: ['Agentic', 'Ethics And Bias', 'GPT', 'Model Architecture', 'Reinforcement Learning', 'Responsible AI', 'Tools']
---
Objective This study aims to develop and validate an evaluation framework to ensure the safety and reliability of mental health chatbots which are increasingly popular due to their accessibility human-like interactions and context-aware support. Materials and Methods We created an evaluation framework with 100 benchmark questions and ideal responses and five guideline questions for chatbot responses. This framework validated by mental health experts was tested on a GPT-3.5-turbo-based chatbot. Automated evaluation methods explored included large language model (LLM)-based scoring an agentic approach using real-time data and embedding models to compare chatbot responses against ground truth standards. Results The results highlight the importance of guidelines and ground truth for improving LLM evaluation accuracy. The agentic method dynamically accessing reliable information demonstrated the best alignment with human assessments. Adherence to a standardized expert-validated framework significantly enhanced chatbot response safety and reliability. Discussion Our findings emphasize the need for comprehensive expert-tailored safety evaluation metrics for mental health chatbots. While LLMs have significant potential careful implementation is necessary to mitigate risks. The superior performance of the agentic approach underscores the importance of real-time data access in enhancing chatbot reliability. Conclusion The study validated an evaluation framework for mental health chatbots proving its effectiveness in improving safety and reliability. Future work should extend evaluations to accuracy bias empathy and privacy to ensure holistic assessment and responsible integration into healthcare. Standardized evaluations will build trust among users and professionals facilitating broader adoption and improved mental health support through technology.

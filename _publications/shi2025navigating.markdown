---
layout: publication
title: 'Navigating The Designs Of Privacy-preserving Fine-tuning For Large Language Models'
authors: Haonan Shi, Tu Ouyang, An Wang
conference: "Arxiv"
year: 2025
bibkey: shi2025navigating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2501.04323"}
tags: ['Fine-Tuning', 'Applications', 'Model Architecture', 'Reinforcement Learning', 'Merging', 'Security', 'Training Techniques', 'Pretraining Methods']
---
Instruction tuning has proven effective in enhancing Large Language Models'
(LLMs) performance on downstream tasks. However, real-world fine-tuning faces
inherent conflicts between model providers' intellectual property protection,
clients' data privacy requirements, and tuning costs. While recent approaches
like split learning and offsite tuning demonstrate promising architectures for
privacy-preserving fine-tuning, there is a gap in systematically addressing the
multidimensional trade-offs required for diverse real-world deployments. We
propose several indicative evaluation metrics to guide design trade-offs for
privacy-preserving fine-tuning and a series of example designs, collectively
named GuardedTuning; they result from novel combinations of system
architectures with adapted privacy-enhancement methods and emerging computation
techniques. Each design represents distinct trade-offs across model utility,
privacy guarantees, and costs. Experimental results demonstrate that these
designs protect against data reconstruction attacks while maintaining
competitive fine-tuning performance.

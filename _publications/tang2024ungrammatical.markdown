---
layout: publication
title: Ungrammatical45;syntax45;based In45;context Example Selection For Grammatical Error Correction
authors: Tang Chenming, Qu Fanyi, Wu Yunfang
conference: "Arxiv"
year: 2024
bibkey: tang2024ungrammatical
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.19283"}
tags: ['Attention Mechanism', 'Model Architecture', 'Prompting']
---
In the era of large language models (LLMs) in45;context learning (ICL) stands out as an effective prompting strategy that explores LLMs potency across various tasks. However applying LLMs to grammatical error correction (GEC) is still a challenging task. In this paper we propose a novel ungrammatical45;syntax45;based in45;context example selection strategy for GEC. Specifically we measure similarity of sentences based on their syntactic structures with diverse algorithms and identify optimal ICL examples sharing the most similar ill45;formed syntax to the test input. Additionally we carry out a two45;stage process to further improve the quality of selection results. On benchmark English GEC datasets empirical results show that our proposed ungrammatical45;syntax45;based strategies outperform commonly45;used word45;matching or semantics45;based methods with multiple LLMs. This indicates that for a syntax45;oriented task like GEC paying more attention to syntactic information can effectively boost LLMs performance. Our code will be publicly available after the publication of this paper.

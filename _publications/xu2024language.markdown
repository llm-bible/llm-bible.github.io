---
layout: publication
title: 'On-device Language Models: A Comprehensive Review'
authors: Jiajun Xu, Zhiyuan Li, Wei Chen, Qun Wang, Xin Gao, Qi Cai, Ziyuan Ling
conference: "Arxiv"
year: 2024
bibkey: xu2024language
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2409.00088'}
  - {name: "Code", url: 'https://github.com/NexaAI/Awesome-LLMs-on-device'}
tags: ['Has Code', 'Efficiency and Optimization', 'Distillation', 'Applications', 'Model Architecture', 'Quantization', 'Pruning', 'Survey Paper', 'Reinforcement Learning']
---
The advent of large language models (LLMs) revolutionized natural language
processing applications, and running LLMs on edge devices has become
increasingly attractive for reasons including reduced latency, data
localization, and personalized user experiences. This comprehensive review
examines the challenges of deploying computationally expensive LLMs on
resource-constrained devices and explores innovative solutions across multiple
domains. The paper investigates the development of on-device language models,
their efficient architectures, including parameter sharing and modular designs,
as well as state-of-the-art compression techniques like quantization, pruning,
and knowledge distillation. Hardware acceleration strategies and collaborative
edge-cloud deployment approaches are analyzed, highlighting the intricate
balance between performance and resource utilization. Case studies of on-device
language models from major mobile manufacturers demonstrate real-world
applications and potential benefits. The review also addresses critical aspects
such as adaptive learning, multi-modal capabilities, and personalization. By
identifying key research directions and open challenges, this paper provides a
roadmap for future advancements in on-device language models, emphasizing the
need for interdisciplinary efforts to realize the full potential of ubiquitous,
intelligent computing while ensuring responsible and ethical deployment. For a
comprehensive review of research work and educational resources on on-device
large language models (LLMs), please visit
https://github.com/NexaAI/Awesome-LLMs-on-device. To download and run on-device
LLMs, visit https://www.nexaai.com/models.

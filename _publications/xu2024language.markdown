---
layout: publication
title: On-device Language Models A Comprehensive Review
authors: Xu Jiajun, Li Zhiyuan, Chen Wei, Wang Qun, Gao Xin, Cai Qi, Ling Ziyuan
conference: "Arxiv"
year: 2024
bibkey: xu2024language
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2409.00088"}
  - {name: "Code", url: "https://github.com/NexaAI/Awesome-LLMs-on-device"}
tags: ['Applications', 'Distillation', 'Efficiency And Optimization', 'Has Code', 'Model Architecture', 'Pruning', 'Quantization', 'Reinforcement Learning', 'Survey Paper']
---
The advent of large language models (LLMs) revolutionized natural language processing applications and running LLMs on edge devices has become increasingly attractive for reasons including reduced latency data localization and personalized user experiences. This comprehensive review examines the challenges of deploying computationally expensive LLMs on resource-constrained devices and explores innovative solutions across multiple domains. The paper investigates the development of on-device language models their efficient architectures including parameter sharing and modular designs as well as state-of-the-art compression techniques like quantization pruning and knowledge distillation. Hardware acceleration strategies and collaborative edge-cloud deployment approaches are analyzed highlighting the intricate balance between performance and resource utilization. Case studies of on-device language models from major mobile manufacturers demonstrate real-world applications and potential benefits. The review also addresses critical aspects such as adaptive learning multi-modal capabilities and personalization. By identifying key research directions and open challenges this paper provides a roadmap for future advancements in on-device language models emphasizing the need for interdisciplinary efforts to realize the full potential of ubiquitous intelligent computing while ensuring responsible and ethical deployment. For a comprehensive review of research work and educational resources on on-device large language models (LLMs) please visit https://github.com/NexaAI/Awesome-LLMs-on-device. To download and run on-device LLMs visit https://www.nexaai.com/models."

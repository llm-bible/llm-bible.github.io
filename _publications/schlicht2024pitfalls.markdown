---
layout: publication
title: 'Pitfalls Of Conversational Llms On News Debiasing'
authors: Ipek Baris Schlicht, Defne Altiok, Maryanne Taouk, Lucie Flek
conference: "Arxiv"
year: 2024
bibkey: schlicht2024pitfalls
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.06488"}
tags: ['GPT', 'Ethics and Bias', 'Model Architecture']
---
This paper addresses debiasing in news editing and evaluates the
effectiveness of conversational Large Language Models in this task. We designed
an evaluation checklist tailored to news editors' perspectives, obtained
generated texts from three popular conversational models using a subset of a
publicly available dataset in media bias, and evaluated the texts according to
the designed checklist. Furthermore, we examined the models as evaluator for
checking the quality of debiased model outputs. Our findings indicate that none
of the LLMs are perfect in debiasing. Notably, some models, including ChatGPT,
introduced unnecessary changes that may impact the author's style and create
misinformation. Lastly, we show that the models do not perform as proficiently
as domain experts in evaluating the quality of debiased outputs.

---
layout: publication
title: 'Knowledge Unlearning For Llms: Tasks, Methods, And Challenges'
authors: Si Nianwen, Zhang Hao, Chang Heyu, Zhang Wenlin, Qu Dan, Zhang Weiqiang
conference: "Arxiv"
year: 2023
bibkey: si2023knowledge
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2311.15766"}
tags: ['Applications', 'Efficiency And Optimization', 'In Context Learning', 'Merging', 'Prompting', 'Survey Paper', 'Training Techniques']
---
In recent years large language models (LLMs) have spurred a new research paradigm in natural language processing. Despite their excellent capability in knowledge-based question answering and reasoning their potential to retain faulty or even harmful knowledge poses risks of malicious application. The challenge of mitigating this issue and transforming these models into purer assistants is crucial for their widespread applicability. Unfortunately Retraining LLMs repeatedly to eliminate undesirable knowledge is impractical due to their immense parameters. Knowledge unlearning derived from analogous studies on machine unlearning presents a promising avenue to address this concern and is notably advantageous in the context of LLMs. It allows for the removal of harmful knowledge in an efficient manner without affecting unrelated knowledge in the model. To this end we provide a survey of knowledge unlearning in the era of LLMs. Firstly we formally define the knowledge unlearning problem and distinguish it from related works. Subsequently we categorize existing knowledge unlearning methods into three classes those based on parameter optimization parameter merging and in-context learning and introduce details of these unlearning methods. We further present evaluation datasets used in existing methods and finally conclude this survey by presenting the ongoing challenges and future directions.

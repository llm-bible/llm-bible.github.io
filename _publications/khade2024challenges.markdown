---
layout: publication
title: 'Challenges In Adapting Multilingual Llms To Low-resource Languages Using Lora PEFT Tuning'
authors: Omkar Khade, Shruti Jagdale, Abhishek Phaltankar, Gauri Takalikar, Raviraj Joshi
conference: "Arxiv"
year: 2024
bibkey: khade2024challenges
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2411.18571'}
tags: ['Fine-Tuning', 'Training Techniques', 'Pretraining Methods']
---
Large Language Models (LLMs) have demonstrated remarkable multilingual
capabilities, yet challenges persist in adapting these models for low-resource
languages. In this study, we investigate the effects of Low-Rank Adaptation
(LoRA) Parameter-Efficient Fine-Tuning (PEFT) on multilingual Gemma models for
Marathi, a language with limited resources. Using a translated Alpaca dataset
with 52,000 instruction-response pairs, our findings reveal that while
evaluation metrics often show a performance decline post-fine-tuning, manual
assessments frequently suggest that the fine-tuned models outperform their
original counterparts. The observations indicate improvements in target
language generation capabilities but a reduction in reasoning abilities
following language adaptation. These results underscore the need for improved
evaluation methodologies and the creation of high-quality native datasets to
accurately assess language-specific model performance in low-resource settings.

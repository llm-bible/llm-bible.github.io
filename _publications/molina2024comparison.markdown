---
layout: publication
title: Comparison Of Large Language Models For Generating Contextually Relevant Questions
authors: Molina Ivo Lodovico, Švábenský Valdemar, Minematsu Tsubasa, Chen Li, Okubo Fumiya, Shimada Atsushi
conference: "Arxiv"
year: 2024
bibkey: molina2024comparison
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.20578"}
tags: ['Applications', 'Ethics And Bias', 'GPT', 'Model Architecture', 'Reinforcement Learning', 'Survey Paper']
---
This study explores the effectiveness of Large Language Models (LLMs) for Automatic Question Generation in educational settings. Three LLMs are compared in their ability to create questions from university slide text without fine45;tuning. Questions were obtained in a two45;step pipeline first answer phrases were extracted from slides using Llama 245;Chat 13B; then the three models generated questions for each answer. To analyze whether the questions would be suitable in educational applications for students a survey was conducted with 46 students who evaluated a total of 246 questions across five metrics clarity relevance difficulty slide relation and question45;answer alignment. Results indicate that GPT45;3.5 and Llama 245;Chat 13B outperform Flan T5 XXL by a small margin particularly in terms of clarity and question45;answer alignment. GPT45;3.5 especially excels at tailoring questions to match the input answers. The contribution of this research is the analysis of the capacity of LLMs for Automatic Question Generation in education.

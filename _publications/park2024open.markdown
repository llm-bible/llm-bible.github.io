---
layout: publication
title: 'Open Ko-llm Leaderboard: Evaluating Large Language Models In Korean With Ko-h5 Benchmark'
authors: Park Chanjun, Kim Hyeonwoo, Kim Dahyun, Cho Seonghwan, Kim Sanghoon, Lee Sukyung, Kim Yungi, Lee Hwalsuk
conference: "Arxiv"
year: 2024
bibkey: park2024open
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.20574"}
tags: ['Reinforcement Learning', 'Tools', 'Uncategorized']
---
This paper introduces the Open Ko-LLM Leaderboard and the Ko-H5 Benchmark as
vital tools for evaluating Large Language Models (LLMs) in Korean.
Incorporating private test sets while mirroring the English Open LLM
Leaderboard, we establish a robust evaluation framework that has been well
integrated in the Korean LLM community. We perform data leakage analysis that
shows the benefit of private test sets along with a correlation study within
the Ko-H5 benchmark and temporal analyses of the Ko-H5 score. Moreover, we
present empirical support for the need to expand beyond set benchmarks. We hope
the Open Ko-LLM Leaderboard sets precedent for expanding LLM evaluation to
foster more linguistic diversity.

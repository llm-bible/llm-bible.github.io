---
layout: publication
title: 'Dynamic Fusion With Intra- And Inter- Modality Attention Flow For Visual Question Answering'
authors: Peng Gao, Jiang Zhengkai, You Haoxuan, Lu Pan, Hoi Steven, Wang Xiaogang, Li Hongsheng
conference: "Arxiv"
year: 2018
bibkey: peng2018dynamic
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/1812.05252"}
tags: ['Applications', 'Attention Mechanism', 'Merging', 'Model Architecture', 'Multimodal Models']
---
Learning effective fusion of multi-modality features is at the heart of visual question answering. We propose a novel method of dynamically fusing multi-modal features with intra- and inter-modality information flow, which alternatively pass dynamic information between and across the visual and language modalities. It can robustly capture the high-level interactions between language and vision domains, thus significantly improves the performance of visual question answering. We also show that the proposed dynamic intra-modality attention flow conditioned on the other modality can dynamically modulate the intra-modality attention of the target modality, which is vital for multimodality feature fusion. Experimental evaluations on the VQA 2.0 dataset show that the proposed method achieves state-of-the-art VQA performance. Extensive ablation studies are carried out for the comprehensive analysis of the proposed method.

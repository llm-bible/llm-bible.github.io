---
layout: publication
title: 'SMLT-MUGC: Small, Medium, And Large Texts -- Machine Versus User-generated Content Detection And Comparison'
authors: Anjali Rawal, Hui Wang, Youjia Zheng, Yu-hsuan Lin, Shanu Sushmita
conference: "Arxiv"
year: 2024
bibkey: rawal2024smlt
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.12815"}
tags: ['Model Architecture', 'Reinforcement Learning', 'GPT', 'Ethics and Bias', 'Attention Mechanism']
---
Large language models (LLMs) have gained significant attention due to their
ability to mimic human language. Identifying texts generated by LLMs is crucial
for understanding their capabilities and mitigating potential consequences.
This paper analyzes datasets of varying text lengths: small, medium, and large.
We compare the performance of machine learning algorithms on four datasets: (1)
small (tweets from Election, FIFA, and Game of Thrones), (2) medium (Wikipedia
introductions and PubMed abstracts), and (3) large (OpenAI web text dataset).
Our results indicate that LLMs with very large parameters (such as the XL-1542
variant of GPT2 with 1542 million parameters) were harder (74%) to detect using
traditional machine learning methods. However, detecting texts of varying
lengths from LLMs with smaller parameters (762 million or less) can be done
with high accuracy (96% and above). We examine the characteristics of human and
machine-generated texts across multiple dimensions, including linguistics,
personality, sentiment, bias, and morality. Our findings indicate that
machine-generated texts generally have higher readability and closely mimic
human moral judgments but differ in personality traits. SVM and Voting
Classifier (VC) models consistently achieve high performance across most
datasets, while Decision Tree (DT) models show the lowest performance. Model
performance drops when dealing with rephrased texts, particularly shorter texts
like tweets. This study underscores the challenges and importance of detecting
LLM-generated texts and suggests directions for future research to improve
detection methods and understand the nuanced capabilities of LLMs.

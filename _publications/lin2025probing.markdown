---
layout: publication
title: 'Probing Large Language Models In Reasoning And Translating Complex Linguistic Puzzles'
authors: Zheng-lin Lin, Yu-fei Shih, Shu-kai Hsieh
conference: "Arxiv"
year: 2025
bibkey: lin2025probing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.00817"}
tags: ['Efficiency and Optimization', 'Model Architecture', 'GPT', 'Prompting', 'Applications']
---
This paper investigates the utilization of Large Language Models (LLMs) for
solving complex linguistic puzzles, a domain requiring advanced reasoning and
adept translation capabilities akin to human cognitive processes. We explore
specific prompting techniques designed to enhance ability of LLMs to reason and
elucidate their decision-making pathways, with a focus on Input-Output
Prompting (IO), Chain-of-Thought Prompting (CoT), and Solo Performance
Prompting (SPP). Utilizing datasets from the Puzzling Machine Competition and
various Linguistics Olympiads, we employ a comprehensive set of metrics to
assess the performance of GPT-4 0603, a prominent LLM, across these prompting
methods. Our findings illuminate the potential of LLMs in linguistic reasoning
and complex translation tasks, highlighting their capabilities and identifying
limitations in the context of linguistic puzzles. This research contributes
significantly to the broader field of Natural Language Processing (NLP) by
providing insights into the optimization of LLM applications for improved
reasoning and translation accuracy, thereby enriching the ongoing dialogue in
NLP advancements.

---
layout: publication
title: Large Language Models Are Null45;shot Learners
authors: Taveekitworachai Pittawat, Abdullah Febri, Thawonmas Ruck
conference: "Arxiv"
year: 2024
bibkey: taveekitworachai2024large
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.08273"}
tags: ['Applications', 'Prompting']
---
This paper presents null45;shot prompting. Null45;shot prompting exploits hallucination in large language models (LLMs) by instructing LLMs to utilize information from the Examples section that never exists within the provided context to perform a task. While reducing hallucination is crucial and non45;negligible for daily and critical uses of LLMs we propose that in the current landscape in which these LLMs still hallucinate it is possible in fact to exploit hallucination to increase performance in performing tasks compared to standard zero45;shot prompting. Experiments with eight LLMs show improvements in performance across the majority of eight datasets including reading comprehension arithmetic reasoning and closed45;book question answering. The observed inconsistency in increased relative performance across the LLMs also potentially indicates a different degree of inherent hallucination in each model. These differences show that it is possible to utilize null45;shot prompting as a way to detect degrees of hallucination in LLMs using existing benchmarking datasets. We also perform ablation studies including experimenting with a modified version of null45;shot prompting that incorporates ideas from zero45;shot chain45;of45;thought prompting which shows different trends of results.

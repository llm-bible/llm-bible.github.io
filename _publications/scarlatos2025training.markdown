---
layout: publication
title: 'Training Llm-based Tutors To Improve Student Learning Outcomes In Dialogues'
authors: Alexander Scarlatos, Naiming Liu, Jaewook Lee, Richard Baraniuk, Andrew Lan
conference: "Arxiv"
year: 2025
bibkey: scarlatos2025training
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2503.06424"}
tags: ['Efficiency and Optimization', 'Training Techniques', 'Model Architecture', 'Reinforcement Learning', 'RAG', 'GPT', 'Prompting']
---
Generative artificial intelligence (AI) has the potential to scale up
personalized tutoring through large language models (LLMs). Recent AI tutors
are adapted for the tutoring task by training or prompting LLMs to follow
effective pedagogical principles, though they are not trained to maximize
student learning throughout the course of a dialogue. Therefore, they may
engage with students in a suboptimal way. We address this limitation by
introducing an approach to train LLMs to generate tutor utterances that
maximize the likelihood of student correctness, while still encouraging the
model to follow good pedagogical practice. Specifically, we generate a set of
candidate tutor utterances and score them using (1) an LLM-based student model
to predict the chance of correct student responses and (2) a pedagogical rubric
evaluated by GPT-4o. We then use the resulting data to train an open-source
LLM, Llama 3.1 8B, using direct preference optimization. We show that tutor
utterances generated by our model lead to significantly higher chances of
correct student responses while maintaining the pedagogical quality of GPT-4o.
We also conduct qualitative analyses and a human evaluation to demonstrate that
our model generates high quality tutor utterances.

---
layout: publication
title: Coco45;agent A Comprehensive Cognitive MLLM Agent For Smartphone GUI Automation
authors: Ma Xinbei, Zhang Zhuosheng, Zhao Hai
conference: "Arxiv"
year: 2024
bibkey: ma2024coco
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.11941"}
  - {name: "Code", url: "https://github.com/xbmxb/CoCo&#45;Agent"}
tags: ['Agentic', 'Has Code', 'Multimodal Models', 'Reinforcement Learning']
---
Multimodal large language models (MLLMs) have shown remarkable potential as human45;like autonomous language agents to interact with real45;world environments especially for graphical user interface (GUI) automation. However those GUI agents require comprehensive cognition ability including exhaustive perception and reliable action response. We propose a Comprehensive Cognitive LLM Agent CoCo45;Agent with two novel approaches comprehensive environment perception (CEP) and conditional action prediction (CAP) to systematically improve the GUI automation performance. First CEP facilitates the GUI perception through different aspects and granularity including screenshots and complementary detailed layouts for the visual channel and historical actions for the textual channel. Second CAP decomposes the action prediction into sub45;problems action type prediction and action target conditioned on the action type. With our technical design our agent achieves new state45;of45;the45;art performance on AITW and META45;GUI benchmarks showing promising abilities in realistic scenarios. Code is available at https://github.com/xbmxb/CoCo&#45;Agent.

---
layout: publication
title: An Empirical Study of Multitask Learning to Improve Open Domain Dialogue Systems
authors: Farahani Mehrdad, Johansson Richard
conference: "Arxiv"
year: 2023
bibkey: farahani2023empirical
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2304.08115"}
tags: ['Applications', 'Ethics And Bias', 'GPT', 'Language Modeling', 'Model Architecture', 'Pretraining Methods', 'RAG']
---
Autoregressive models used to generate responses in open-domain dialogue systems often struggle to take long-term context into account and to maintain consistency over a dialogue. Previous research in open-domain dialogue generation has shown that the use of can introduce inductive biases that encourage the model to improve these qualities. However most previous research has focused on encoder-only or encoder/decoder models while the use of auxiliary tasks in autoregressive models is under-explored. This paper describes an investigation where four different auxiliary tasks are added to small and medium-sized GPT-2 models fine-tuned on the PersonaChat and DailyDialog datasets. The results show that the introduction of the new auxiliary tasks leads to small but consistent improvement in evaluations of the investigated models.

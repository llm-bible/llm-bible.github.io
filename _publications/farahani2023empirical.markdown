---
layout: publication
title: An Empirical Study Of Multitask Learning To Improve Open Domain Dialogue Systems
authors: Farahani Mehrdad, Johansson Richard
conference: "Arxiv"
year: 2023
bibkey: farahani2023empirical
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2304.08115"}
tags: ['Applications', 'Ethics And Bias', 'GPT', 'Language Modeling', 'Model Architecture', 'Pretraining Methods', 'RAG']
---
Autoregressive models used to generate responses in open45;domain dialogue systems often struggle to take long45;term context into account and to maintain consistency over a dialogue. Previous research in open45;domain dialogue generation has shown that the use of emph123;auxiliary tasks125; can introduce inductive biases that encourage the model to improve these qualities. However most previous research has focused on encoder45;only or encoder/decoder models while the use of auxiliary tasks in emph123;decoder45;only125; autoregressive models is under45;explored. This paper describes an investigation where four different auxiliary tasks are added to small and medium45;sized GPT45;2 models fine45;tuned on the PersonaChat and DailyDialog datasets. The results show that the introduction of the new auxiliary tasks leads to small but consistent improvement in evaluations of the investigated models.

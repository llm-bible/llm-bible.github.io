---
layout: publication
title: Imagination45;augmented Natural Language Understanding
authors: Lu Yujie, Zhu Wanrong, Wang Xin Eric, Eckstein Miguel, Wang William Yang
conference: "Arxiv"
year: 2022
bibkey: lu2022imagination
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2204.08535"}
tags: ['Applications']
---
Human brains integrate linguistic and perceptual information simultaneously to understand natural language and hold the critical ability to render imaginations. Such abilities enable us to construct new abstract concepts or concrete objects and are essential in involving practical knowledge to solve problems in low45;resource scenarios. However most existing methods for Natural Language Understanding (NLU) are mainly focused on textual signals. They do not simulate human visual imagination ability which hinders models from inferring and learning efficiently from limited data samples. Therefore we introduce an Imagination45;Augmented Cross45;modal Encoder (iACE) to solve natural language understanding tasks from a novel learning perspective 45;45; imagination45;augmented cross45;modal understanding. iACE enables visual imagination with external knowledge transferred from the powerful generative and pre45;trained vision45;and45;language models. Extensive experiments on GLUE and SWAG show that iACE achieves consistent improvement over visually45;supervised pre45;trained models. More importantly results in extreme and normal few45;shot settings validate the effectiveness of iACE in low45;resource natural language understanding circumstances.

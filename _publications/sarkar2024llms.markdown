---
layout: publication
title: LLMs as On-demand Customizable Service
authors: Sarkar Souvika Santu, Babar Mohammad Fakhruddin Santu, Hasan Monowar Santu, Karmaker Shubhra Kanti Santu
conference: "Arxiv"
year: 2024
bibkey: sarkar2024llms
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.16577"}
tags: ['ARXIV', 'Applications', 'LLM', 'Tools']
---
Large Language Models (LLMs) have demonstrated remarkable language understanding and generation capabilities. However training deploying and accessing these models pose notable challenges including resource-intensive demands extended training durations and scalability issues. To address these issues we introduce a concept of hierarchical distributed LLM architecture that aims at enhancing the accessibility and deployability of LLMs across heterogeneous computing platforms including general-purpose computers (e.g. laptops) and IoT-style devices (e.g. embedded systems). By introducing a layered approach the proposed architecture enables on-demand accessibility to LLMs as a customizable service. This approach also ensures optimal trade-offs between the available computational resources and the users application needs. We envision that the concept of hierarchical LLM will empower extensive crowd-sourced user bases to harness the capabilities of LLMs thereby fostering advancements in AI technology in general.

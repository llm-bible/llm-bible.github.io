---
layout: publication
title: Llms As On45;demand Customizable Service
authors: Sarkar Souvika Santu, Babar Mohammad Fakhruddin Santu, Hasan Monowar Santu, Karmaker Shubhra Kanti Santu
conference: "Arxiv"
year: 2024
bibkey: sarkar2024llms
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.16577"}
tags: ['Applications', 'Model Architecture', 'Tools', 'Training Techniques']
---
Large Language Models (LLMs) have demonstrated remarkable language understanding and generation capabilities. However training deploying and accessing these models pose notable challenges including resource45;intensive demands extended training durations and scalability issues. To address these issues we introduce a concept of hierarchical distributed LLM architecture that aims at enhancing the accessibility and deployability of LLMs across heterogeneous computing platforms including general45;purpose computers (e.g. laptops) and IoT45;style devices (e.g. embedded systems). By introducing a layered approach the proposed architecture enables on45;demand accessibility to LLMs as a customizable service. This approach also ensures optimal trade45;offs between the available computational resources and the users application needs. We envision that the concept of hierarchical LLM will empower extensive crowd45;sourced user bases to harness the capabilities of LLMs thereby fostering advancements in AI technology in general.

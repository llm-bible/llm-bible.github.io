---
layout: publication
title: 'Llms As On-demand Customizable Service'
authors: Souvika Santu Sarkar, Mohammad Fakhruddin Santu Babar, Monowar Santu Hasan, Shubhra Kanti Santu Karmaker
conference: "Arxiv"
year: 2024
bibkey: sarkar2024llms
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2401.16577'}
tags: ['Training Techniques', 'Tools', 'Model Architecture']
---
Large Language Models (LLMs) have demonstrated remarkable language
understanding and generation capabilities. However, training, deploying, and
accessing these models pose notable challenges, including resource-intensive
demands, extended training durations, and scalability issues. To address these
issues, we introduce a concept of hierarchical, distributed LLM architecture
that aims at enhancing the accessibility and deployability of LLMs across
heterogeneous computing platforms, including general-purpose computers (e.g.,
laptops) and IoT-style devices (e.g., embedded systems). By introducing a
"layered" approach, the proposed architecture enables on-demand accessibility
to LLMs as a customizable service. This approach also ensures optimal
trade-offs between the available computational resources and the user's
application needs. We envision that the concept of hierarchical LLM will
empower extensive, crowd-sourced user bases to harness the capabilities of
LLMs, thereby fostering advancements in AI technology in general.

---
layout: publication
title: 'AI Hallucinations: A Misnomer Worth Clarifying'
authors: Negar Maleki, Balaji Padmanabhan, Kaushik Dutta
conference: Arxiv
year: 2024
citations: 41
bibkey: maleki2024ai
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2401.06796'}]
tags: [Language Modeling, Applications, Survey Paper]
---
As large language models continue to advance in Artificial Intelligence (AI),
text generation systems have been shown to suffer from a problematic phenomenon
termed often as "hallucination." However, with AI's increasing presence across
various domains including medicine, concerns have arisen regarding the use of
the term itself. In this study, we conducted a systematic review to identify
papers defining "AI hallucination" across fourteen databases. We present and
analyze definitions obtained across all databases, categorize them based on
their applications, and extract key points within each category. Our results
highlight a lack of consistency in how the term is used, but also help identify
several alternative terms in the literature. We discuss implications of these
and call for a more unified effort to bring consistency to an important
contemporary AI issue that can affect multiple domains significantly.
---
layout: publication
title: Beyond Metrics Evaluating Llms Effectiveness In Culturally Nuanced Low45;resource Real45;world Scenarios
authors: Ochieng Millicent, Gumma Varun, Sitaram Sunayana, Wang Jindong, Chaudhary Vishrav, Ronen Keshet, Bali Kalika, O'neill Jacki
conference: "Arxiv"
year: 2024
bibkey: ochieng2024beyond
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.00343"}
tags: ['Applications', 'Ethics And Bias', 'GPT', 'Interpretability And Explainability', 'Model Architecture', 'Reinforcement Learning']
---
The deployment of Large Language Models (LLMs) in real45;world applications presents both opportunities and challenges particularly in multilingual and code45;mixed communication settings. This research evaluates the performance of seven leading LLMs in sentiment analysis on a dataset derived from multilingual and code45;mixed WhatsApp chats including Swahili English and Sheng. Our evaluation includes both quantitative analysis using metrics like F1 score and qualitative assessment of LLMs explanations for their predictions. We find that while Mistral45;7b and Mixtral45;8x7b achieved high F1 scores they and other LLMs such as GPT45;3.545;Turbo Llama45;245;70b and Gemma45;7b struggled with understanding linguistic and contextual nuances as well as lack of transparency in their decision45;making process as observed from their explanations. In contrast GPT45;4 and GPT45;445;Turbo excelled in grasping diverse linguistic inputs and managing various contextual information demonstrating high consistency with human alignment and transparency in their decision45;making process. The LLMs however encountered difficulties in incorporating cultural nuance especially in non45;English settings with GPT45;4s doing so inconsistently. The findings emphasize the necessity of continuous improvement of LLMs to effectively tackle the challenges of culturally nuanced low45;resource real45;world settings and the need for developing evaluation benchmarks for capturing these issues.

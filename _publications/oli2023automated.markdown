---
layout: publication
title: Automated Assessment Of Students Code Comprehension Using Llms
authors: Oli Priti, Banjade Rabin, Chapagain Jeevan, Rus Vasile
conference: "Arxiv"
year: 2023
bibkey: oli2023automated
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.05399"}
tags: ['Attention Mechanism', 'Interpretability And Explainability', 'Model Architecture', 'Pretraining Methods', 'Prompting', 'Reinforcement Learning', 'Transformer']
---
Assessing students answers and in particular natural language answers is a crucial challenge in the field of education. Advances in machine learning including transformer45;based models such as Large Language Models(LLMs) have led to significant progress in various natural language tasks. Nevertheless amidst the growing trend of evaluating LLMs across diverse tasks evaluating LLMs in the realm of automated answer assesment has not received much attention. To address this gap we explore the potential of using LLMs for automated assessment of students short and open45;ended answer. Particularly we use LLMs to compare students explanations with expert explanations in the context of line45;by45;line explanations of computer programs. For comparison purposes we assess both Large Language Models (LLMs) and encoder45;based Semantic Textual Similarity (STS) models in the context of assessing the correctness of students explanation of computer code. Our findings indicate that LLMs when prompted in few45;shot and chain45;of45;thought setting perform comparable to fine45;tuned encoder45;based models in evaluating students short answers in programming domain.

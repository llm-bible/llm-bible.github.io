---
layout: publication
title: Verification And Refinement Of Natural Language Explanations Through Llm45;symbolic Theorem Proving
authors: Quan Xin, Valentino Marco, Dennis Louise A., Freitas Andr√©
conference: "Arxiv"
year: 2024
bibkey: quan2024verification
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.01379"}
tags: ['Interpretability And Explainability', 'Reinforcement Learning', 'Tools']
---
Natural language explanations have become a proxy for evaluating explainable and multi45;step Natural Language Inference (NLI) models. However assessing the validity of explanations for NLI is challenging as it typically involves the crowd45;sourcing of apposite datasets a process that is time45;consuming and prone to logical errors. To address existing limitations this paper investigates the verification and refinement of natural language explanations through the integration of Large Language Models (LLMs) and Theorem Provers (TPs). Specifically we present a neuro45;symbolic framework named Explanation45;Refiner that augments a TP with LLMs to generate and formalise explanatory sentences and suggest potential inference strategies for NLI. In turn the TP is employed to provide formal guarantees on the logical validity of the explanations and to generate feedback for subsequent improvements. We demonstrate how Explanation45;Refiner can be jointly used to evaluate explanatory reasoning autoformalisation and error correction mechanisms of state45;of45;the45;art LLMs as well as to automatically enhance the quality of human45;annotated explanations of variable complexity in different domains.

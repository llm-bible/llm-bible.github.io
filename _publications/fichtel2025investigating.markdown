---
layout: publication
title: 'Investigating Co-constructive Behavior Of Large Language Models In Explanation Dialogues'
authors: Leandra Fichtel, Maximilian Spliethöver, Eyke Hüllermeier, Patricia Jimenez, Nils Klowait, Stefan Kopp, Axel-cyrille Ngonga Ngomo, Amelie Robrecht, Ingrid Scharlau, Lutz Terfloth, Anna-lisa Vollmer, Henning Wachsmuth
conference: "Arxiv"
year: 2025
bibkey: fichtel2025investigating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2504.18483"}
tags: ['Interpretability and Explainability']
---
The ability to generate explanations that are understood by explainees is the
quintessence of explainable artificial intelligence. Since understanding
depends on the explainee's background and needs, recent research has focused on
co-constructive explanation dialogues, where the explainer continuously
monitors the explainee's understanding and adapts explanations dynamically. We
investigate the ability of large language models (LLMs) to engage as explainers
in co-constructive explanation dialogues. In particular, we present a user
study in which explainees interact with LLMs, of which some have been
instructed to explain a predefined topic co-constructively. We evaluate the
explainees' understanding before and after the dialogue, as well as their
perception of the LLMs' co-constructive behavior. Our results indicate that
current LLMs show some co-constructive behaviors, such as asking verification
questions, that foster the explainees' engagement and can improve understanding
of a topic. However, their ability to effectively monitor the current
understanding and scaffold the explanations accordingly remains limited.

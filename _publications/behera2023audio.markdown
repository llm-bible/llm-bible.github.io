---
layout: publication
title: AQUALLM Audio Question Answering Data Generation Using Large Language Models
authors: Behera Swarup Ranjan, Injeti Krishna Mohan, Patibandla Jaya Sai Kiran, Pokala Praveen Kumar, Pailla Balakrishna Reddy
conference: "Arxiv"
year: 2023
bibkey: behera2023audio
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2312.17343"}
  - {name: "Code", url: "https://github.com/swarupbehera/AQUALLM&#125;&#125;"}
tags: ['Applications', 'Attention Mechanism', 'Has Code', 'Model Architecture', 'Reinforcement Learning', 'Tools']
---
Audio Question Answering (AQA) constitutes a pivotal task in which machines analyze both audio signals and natural language questions to produce precise natural language answers. The significance of possessing high45;quality diverse and extensive AQA datasets cannot be overstated when aiming for the precision of an AQA system. While there has been notable focus on developing accurate and efficient AQA models the creation of high45;quality diverse and extensive datasets for the specific task at hand has not garnered considerable attention. To address this challenge this work makes several contributions. We introduce a scalable AQA data generation pipeline denoted as the AQUALLM framework which relies on Large Language Models (LLMs). This framework utilizes existing audio45;caption annotations and incorporates state45;of45;the45;art LLMs to generate expansive high45;quality AQA datasets. Additionally we present three extensive and high45;quality benchmark datasets for AQA contributing significantly to the progression of AQA research. AQA models trained on the proposed datasets set superior benchmarks compared to the existing state45;of45;the45;art. Moreover models trained on our datasets demonstrate enhanced generalizability when compared to models trained using human45;annotated AQA data. Code and datasets will be accessible on GitHub~footnote123;url123;https://github.com/swarupbehera/AQUALLM&#125;&#125;.

---
layout: publication
title: 'Empowering Few-shot Recommender Systems With Large Language Models -- Enhanced Representations'
authors: Wang Zhoumeng
conference: "Arxiv"
year: 2023
bibkey: wang2023empowering
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2312.13557"}
tags: ['Applications', 'Few Shot', 'Prompting', 'Uncategorized']
---
Recommender systems utilizing explicit feedback have witnessed significant
advancements and widespread applications over the past years. However,
generating recommendations in few-shot scenarios remains a persistent
challenge. Recently, large language models (LLMs) have emerged as a promising
solution for addressing natural language processing (NLP) tasks, thereby
offering novel insights into tackling the few-shot scenarios encountered by
explicit feedback-based recommender systems. To bridge recommender systems and
LLMs, we devise a prompting template that generates user and item
representations based on explicit feedback. Subsequently, we integrate these
LLM-processed representations into various recommendation models to evaluate
their significance across diverse recommendation tasks. Our ablation
experiments and case study analysis collectively demonstrate the effectiveness
of LLMs in processing explicit feedback, highlighting that LLMs equipped with
generative and logical reasoning capabilities can effectively serve as a
component of recommender systems to enhance their performance in few-shot
scenarios. Furthermore, the broad adaptability of LLMs augments the
generalization potential of recommender models, despite certain inherent
constraints. We anticipate that our study can inspire researchers to delve
deeper into the multifaceted dimensions of LLMs's involvement in recommender
systems and contribute to the advancement of the explicit feedback-based
recommender systems field.

---
layout: publication
title: Application Of Frozen Large45;scale Models To Multimodal Task45;oriented Dialogue
authors: Kawamoto Tatsuki, Suzuki Takuma, Miyama Ko, Meguro Takumi, Takagi Tomohiro
conference: "Arxiv"
year: 2023
bibkey: kawamoto2023application
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.00845"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Multimodal Models', 'Pretraining Methods', 'Tools', 'Training Techniques', 'Transformer']
---
In this study we use the existing Large Language Models ENnhanced to See Framework (LENS Framework) to test the feasibility of multimodal task45;oriented dialogues. The LENS Framework has been proposed as a method to solve computer vision tasks without additional training and with fixed parameters of pre45;trained models. We used the Multimodal Dialogs (MMD) dataset a multimodal task45;oriented dialogue benchmark dataset from the fashion field and for the evaluation we used the ChatGPT45;based G45;EVAL which only accepts textual modalities with arrangements to handle multimodal data. Compared to Transformer45;based models in previous studies our method demonstrated an absolute lift of 10.837; in fluency 8.837; in usefulness and 5.237; in relevance and coherence. The results show that using large45;scale models with fixed parameters rather than using models trained on a dataset from scratch improves performance in multimodal task45;oriented dialogues. At the same time we show that Large Language Models (LLMs) are effective for multimodal task45;oriented dialogues. This is expected to lead to efficient applications to existing systems.

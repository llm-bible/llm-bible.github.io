---
layout: publication
title: 'Application Of Frozen Large-scale Models To Multimodal Task-oriented Dialogue'
authors: Kawamoto Tatsuki, Suzuki Takuma, Miyama Ko, Meguro Takumi, Takagi Tomohiro
conference: "Arxiv"
year: 2023
bibkey: kawamoto2023application
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2310.00845"}
tags: ['Applications', 'GPT', 'Model Architecture', 'Multimodal Models', 'Pretraining Methods', 'Tools', 'Training Techniques', 'Transformer']
---
'In this study, we use the existing Large Language Models ENnhanced to See Framework (LENS Framework) to test the feasibility of multimodal task-oriented dialogues. The LENS Framework has been proposed as a method to solve computer vision tasks without additional training and with fixed parameters of pre-trained models. We used the Multimodal Dialogs (MMD) dataset, a multimodal task-oriented dialogue benchmark dataset from the fashion field, and for the evaluation, we used the ChatGPT-based G-EVAL, which only accepts textual modalities, with arrangements to handle multimodal data. Compared to Transformer-based models in previous studies, our method demonstrated an absolute lift of 10.8&#37; in fluency, 8.8&#37; in usefulness, and 5.2&#37; in relevance and coherence. The results show that using large-scale models with fixed parameters rather than using models trained on a dataset from scratch improves performance in multimodal task-oriented dialogues. At the same time, we show that Large Language Models (LLMs) are effective for multimodal task-oriented dialogues. This is expected to lead to efficient applications to existing systems.'

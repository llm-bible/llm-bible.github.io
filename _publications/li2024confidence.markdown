---
layout: publication
title: Confidence Matters Revisiting Intrinsic Self45;correction Capabilities Of Large Language Models
authors: Li Loka, Chen Zhenhao, Chen Guangyi, Zhang Yixuan, Su Yusheng, Xing Eric, Zhang Kun
conference: "Arxiv"
year: 2024
bibkey: li2024confidence
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.12563"}
  - {name: "Code", url: "https://github.com/MBZUAI&#45;CLeaR/IoE&#45;Prompting.git"}
tags: ['Has Code', 'Pretraining Methods', 'Prompting', 'Reinforcement Learning', 'Tools']
---
The recent success of Large Language Models (LLMs) has catalyzed an increasing interest in their self45;correction capabilities. This paper presents a comprehensive investigation into the intrinsic self45;correction of LLMs attempting to address the ongoing debate about its feasibility. Our research has identified an important latent factor 45; the confidence of LLMs 45; during the self45;correction process. Overlooking this factor may cause the models to over45;criticize themselves resulting in unreliable conclusions regarding the efficacy of self45;correction. We have experimentally observed that LLMs possess the capability to understand the confidence in their own responses. It motivates us to develop an If45;or45;Else (IoE) prompting framework designed to guide LLMs in assessing their own confidence facilitating intrinsic self45;corrections. We conduct extensive experiments and demonstrate that our IoE45;based Prompt can achieve a consistent improvement regarding the accuracy of self45;corrected responses over the initial answers. Our study not only sheds light on the underlying factors affecting self45;correction in LLMs but also introduces a practical framework that utilizes the IoE prompting principle to efficiently improve self45;correction capabilities with confidence. The code is available at https://github.com/MBZUAI&#45;CLeaR/IoE&#45;Prompting.git.

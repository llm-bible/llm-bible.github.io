---
layout: publication
title: QASE Enhanced Plms Improved Control In Text Generation For MRC
authors: Ai Lin, Hui Zheng, Liu Zizhou, Hirschberg Julia
conference: "Arxiv"
year: 2024
bibkey: ai2024qase
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2403.04771"}
tags: ['Applications', 'GPT', 'Language Modeling', 'Model Architecture']
---
To address the challenges of out45;of45;control generation in generative models for machine reading comprehension (MRC) we introduce the Question45;Attended Span Extraction (QASE) module. Integrated during the fine45;tuning of pre45;trained generative language models (PLMs) QASE enables these PLMs to match SOTA extractive methods and outperform leading LLMs like GPT45;4 in MRC tasks without significant increases in computational costs.

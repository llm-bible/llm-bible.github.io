---
layout: publication
title: 'Exploring The Role Of Reasoning Structures For Constructing Proofs In Multi-step Natural Language Reasoning With Large Language Models'
authors: Zi'ou Zheng, Christopher Malon, Martin Renqiang Min, Xiaodan Zhu
conference: "Arxiv"
year: 2024
bibkey: zheng2024exploring
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2410.08436'}
tags: ['Interpretability and Explainability', 'RAG', 'Efficiency and Optimization', 'Prompting', 'Pruning', 'Interpretability', 'In-Context Learning']
---
When performing complex multi-step reasoning tasks, the ability of Large
Language Models (LLMs) to derive structured intermediate proof steps is
important for ensuring that the models truly perform the desired reasoning and
for improving models' explainability. This paper is centred around a focused
study: whether the current state-of-the-art generalist LLMs can leverage the
structures in a few examples to better construct the proof structures with
\textit\{in-context learning\}. Our study specifically focuses on structure-aware
demonstration and structure-aware pruning. We demonstrate that they both help
improve performance. A detailed analysis is provided to help understand the
results.

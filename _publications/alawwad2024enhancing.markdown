---
layout: publication
title: 'Enhancing Textual Textbook Question Answering With Large Language Models And Retrieval Augmented Generation'
authors: Hessa Abdulrahman Alawwad, Areej Alhothali, Usman Naseem, Ali Alkhathlan, Amani Jamal
conference: "Pattern Recognition Volume 162 2025 Article 111332"
year: 2024
bibkey: alawwad2024enhancing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.05128"}
  - {name: "Code", url: "https://github.com/hessaAlawwad/PLR-TQA"}
tags: ['Fine-Tuning', 'Tools', 'Applications', 'RAG', 'Model Architecture', 'Has Code', 'Multimodal Models']
---
Textbook question answering (TQA) is a challenging task in artificial
intelligence due to the complex nature of context needed to answer complex
questions. Although previous research has improved the task, there are still
some limitations in textual TQA, including weak reasoning and inability to
capture contextual information in the lengthy context. We propose a framework
(PLRTQA) that incorporates the retrieval augmented generation (RAG) technique
to handle the out-of-domain scenario where concepts are spread across different
lessons, and utilize transfer learning to handle the long context and enhance
reasoning abilities. Our architecture outperforms the baseline, achieving an
accuracy improvement of 4. 12% in the validation set and 9. 84% in the test set
for textual multiple-choice questions. While this paper focuses on solving
challenges in the textual TQA, It provides a foundation for future work in
multimodal TQA where the visual components are integrated to address more
complex educational scenarios. Code: https://github.com/hessaAlawwad/PLR-TQA

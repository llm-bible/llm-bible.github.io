---
layout: publication
title: 'Rethinking External Slow-thinking: From Snowball Errors To Probability Of Correct Reasoning'
authors: Zeyu Gan, Yun Liao, Yong Liu
conference: "Arxiv"
year: 2025
bibkey: gan2025rethinking
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2501.15602"}
  - {name: "Code", url: "https://github.com/ZyGan1999/Snowball-Errors-and-Probability"}
tags: ['Tools', 'Has Code', 'Reinforcement Learning']
---
Test-time scaling, which is also often referred to as slow-thinking, has been
demonstrated to enhance multi-step reasoning in large language models (LLMs).
However, despite its widespread utilization, the mechanisms underlying
slow-thinking methods remain poorly understood. This paper explores the
mechanisms of external slow-thinking from a theoretical standpoint. We begin by
examining the snowball error effect within the LLM reasoning process and
connect it to the likelihood of correct reasoning using information theory.
Building on this, we show that external slow-thinking methods can be
interpreted as strategies to mitigate the error probability. We further provide
a comparative analysis of popular external slow-thinking approaches, ranging
from simple to complex, highlighting their differences and interrelationships.
Our findings suggest that the efficacy of these methods is not primarily
determined by the specific framework employed, and that expanding the search
scope or the model's internal reasoning capacity may yield more sustained
improvements in the long term. We open-source our code at
https://github.com/ZyGan1999/Snowball-Errors-and-Probability.

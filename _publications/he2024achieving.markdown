---
layout: publication
title: Achieving Tool Calling Functionality in LLMs Using Only Prompt Engineering Without Fine-Tuning
authors: He Shengtao
conference: "Arxiv"
year: 2024
bibkey: he2024achieving
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.04997"}
tags: ['ARXIV', 'Fine Tuning', 'LLM', 'Pretraining Methods', 'Prompting', 'Reinforcement Learning', 'Training Techniques']
---
Currently the vast majority of locally deployed open-source large language models (LLMs) and some commercial model interfaces do not support stable tool calling functionality. The existing solution involves fine-tuning LLMs which results in significant time and computational resource consumption. This paper proposes a method that enables LLMs to achieve stable tool calling capabilities using only prompt engineering and some ingenious code design. We conducted experiments on multiple LLMs that lack tool calling capabilities across various tool calling tasks achieving a success rate of 100.

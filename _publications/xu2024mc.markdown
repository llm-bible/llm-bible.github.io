---
layout: publication
title: 'Mc-bench: A Benchmark For Multi-context Visual Grounding In The Era Of Mllms'
authors: Yunqiu Xu, Linchao Zhu, Yi Yang
conference: "Arxiv"
year: 2024
bibkey: xu2024mc
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2410.12332"}
tags: ['Fine-Tuning', 'RAG', 'Reinforcement Learning', 'Multimodal Models', 'Prompting']
---
While multimodal large language models (MLLMs) have demonstrated
extraordinary vision-language understanding capabilities and shown potential to
serve as general-purpose assistants, their abilities to solve instance-level
visual-language problems beyond a single image warrant further exploration. In
order to assess these unproven abilities of MLLMs, this paper proposes a new
visual grounding task called multi-context visual grounding, which aims to
localize instances of interest across multiple images based on open-ended text
prompts. To facilitate this research, we meticulously construct a new dataset
MC-Bench for benchmarking the visual grounding capabilities of MLLMs. MC-Bench
features 2K high-quality and manually annotated samples, consisting of
instance-level labeled image pairs and corresponding text prompts that indicate
the target instances in the images. In total, there are three distinct styles
of text prompts, covering 20 practical skills. We benchmark over 20
state-of-the-art MLLMs and foundation models with potential multi-context
visual grounding capabilities. Our evaluation reveals a non-trivial performance
gap between existing MLLMs and humans across all metrics. We also observe that
existing MLLMs typically outperform foundation models without LLMs only on
image-level metrics, and the specialist MLLMs trained on single images often
struggle to generalize to multi-image scenarios. Moreover, a simple stepwise
baseline integrating advanced MLLM and a detector can significantly surpass
prior end-to-end MLLMs. We hope our MC-Bench and empirical findings can
encourage the research community to further explore and enhance the untapped
potentials of MLLMs in instance-level tasks, particularly in multi-image
contexts. Project page: https://xuyunqiu.github.io/MC-Bench/.

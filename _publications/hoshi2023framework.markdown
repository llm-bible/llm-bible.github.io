---
layout: publication
title: Ralle A Framework For Developing And Evaluating Retrieval45;augmented Large Language Models
authors: Hoshi Yasuto, Miyashita Daisuke, Ng Youyang, Tatsuno Kento, Morioka Yasuhiro, Torii Osamu, Deguchi Jun
conference: "Arxiv"
year: 2023
bibkey: hoshi2023framework
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2308.10633"}
  - {name: "Code", url: "https://github.com/yhoshi3/RaLLe"}
tags: ['Applications', 'Efficiency And Optimization', 'Ethics And Bias', 'Has Code', 'Prompting', 'RAG', 'Tools']
---
Retrieval45;augmented large language models (R45;LLMs) combine pre45;trained large language models (LLMs) with information retrieval systems to improve the accuracy of factual question45;answering. However current libraries for building R45;LLMs provide high45;level abstractions without sufficient transparency for evaluating and optimizing prompts within specific inference processes such as retrieval and generation. To address this gap we present RaLLe an open45;source framework designed to facilitate the development evaluation and optimization of R45;LLMs for knowledge45;intensive tasks. With RaLLe developers can easily develop and evaluate R45;LLMs improving hand45;crafted prompts assessing individual inference processes and objectively measuring overall system performance quantitatively. By leveraging these features developers can enhance the performance and accuracy of their R45;LLMs in knowledge45;intensive generation tasks. We open45;source our code at https://github.com/yhoshi3/RaLLe.

---
layout: publication
title: 'Find The Intention Of Instruction: Comprehensive Evaluation Of Instruction Understanding For Large Language Models'
authors: Hyeonseok Moon, Jaehyung Seo, Seungyoon Lee, Chanjun Park, Heuiseok Lim
conference: "Arxiv"
year: 2024
bibkey: moon2024find
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2412.19450"}
tags: ['Uncategorized']
---
One of the key strengths of Large Language Models (LLMs) is their ability to
interact with humans by generating appropriate responses to given instructions.
This ability, known as instruction-following capability, has established a
foundation for the use of LLMs across various fields and serves as a crucial
metric for evaluating their performance. While numerous evaluation benchmarks
have been developed, most focus solely on clear and coherent instructions.
However, we have noted that LLMs can become easily distracted by
instruction-formatted statements, which may lead to an oversight of their
instruction comprehension skills. To address this issue, we introduce the
Intention of Instruction (IoInst) benchmark. This benchmark evaluates LLMs'
capacity to remain focused and understand instructions without being misled by
extraneous instructions. The primary objective of this benchmark is to identify
the appropriate instruction that accurately guides the generation of a given
context. Our findings suggest that even recently introduced state-of-the-art
models still lack instruction understanding capability. Along with the
proposition of IoInst in this study, we also present broad analyses of the
several strategies potentially applicable to IoInst.

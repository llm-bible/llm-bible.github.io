---
layout: publication
title: 'Assistant-guided Mitigation Of Teacher Preference Bias In Llm-as-a-judge'
authors: Zhuo Liu, Moxin Li, Xun Deng, Qifan Wang, Fuli Feng
conference: "Arxiv"
year: 2025
bibkey: liu2025assistant
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2505.19176"}
  - {name: "Code", url: "https://github.com/Liuz233/AGDe-Judge"}
tags: ['Tools', 'GPT', 'Ethics and Bias', 'Model Architecture', 'Reinforcement Learning', 'Training Techniques', 'Has Code']
---
LLM-as-a-Judge employs large language models (LLMs), such as GPT-4, to evaluate the quality of LLM-generated responses, gaining popularity for its cost-effectiveness and strong alignment with human evaluations. However, training proxy judge models using evaluation data generated by powerful teacher models introduces a critical yet previously overlooked issue: teacher preference bias, where the proxy judge model learns a biased preference for responses from the teacher model. To tackle this problem, we propose a novel setting that incorporates an additional assistant model, which is not biased toward the teacher model's responses, to complement the training data. Building on this setup, we introduce AGDe-Judge, a three-stage framework designed to debias from both the labels and feedbacks in the training data. Extensive experiments demonstrate that AGDe-Judge effectively reduces teacher preference bias while maintaining strong performance across six evaluation benchmarks. Code is available at https://github.com/Liuz233/AGDe-Judge.

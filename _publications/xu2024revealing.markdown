---
layout: publication
title: Activerag Revealing The Treasures Of Knowledge Via Active Learning
authors: Xu Zhipeng, Liu Zhenghao, Liu Yibin, Xiong Chenyan, Yan Yukun, Wang Shuo, Yu Shi, Liu Zhiyuan, Yu Ge
conference: "Arxiv"
year: 2024
bibkey: xu2024revealing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.13547"}
  - {name: "Code", url: "https://github.com/OpenMatch/ActiveRAG"}
tags: ['Has Code', 'RAG', 'Tools']
---
Retrieval Augmented Generation (RAG) has introduced a new paradigm for Large Language Models (LLMs) aiding in the resolution of knowledge45;intensive tasks. However current RAG models position LLMs as passive knowledge receptors thereby restricting their capacity for learning and comprehending external knowledge. In this paper we present ActiveRAG an innovative RAG framework that shifts from passive knowledge acquisition to an active learning mechanism. This approach utilizes the Knowledge Construction mechanism to develop a deeper understanding of external knowledge by associating it with previously acquired or memorized knowledge. Subsequently it designs the Cognitive Nexus mechanism to incorporate the outcomes from both chains of thought and knowledge construction thereby calibrating the intrinsic cognition of LLMs. Our experimental results demonstrate that ActiveRAG surpasses previous RAG models achieving a 537; improvement on question45;answering datasets. All data and codes are available at https://github.com/OpenMatch/ActiveRAG.

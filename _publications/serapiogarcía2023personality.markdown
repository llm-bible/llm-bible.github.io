---
layout: publication
title: Personality Traits In Large Language Models
authors: Serapio-garcía Greg, Safdari Mustafa, Crepy Clément, Sun Luning, Fitz Stephen, Romero Peter, Abdulhai Marwa, Faust Aleksandra, Matarić Maja
conference: "Arxiv"
year: 2023
bibkey: serapiogarcía2023personality
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2307.00184"}
tags: ['Agentic', 'Ethics And Bias', 'Prompting', 'Reinforcement Learning', 'Responsible AI', 'Tools', 'Training Techniques']
---
The advent of large language models (LLMs) has revolutionized natural language processing enabling the generation of coherent and contextually relevant human-like text. As LLMs increasingly power conversational agents used by the general public world-wide the synthetic personality embedded in these models by virtue of training on large amounts of human data is becoming increasingly important. Since personality is a key factor determining the effectiveness of communication we present a comprehensive method for administering and validating personality tests on widely-used LLMs as well as for shaping personality in the generated text of such LLMs. Applying this method we found 1) personality measurements in the outputs of some LLMs under specific prompting configurations are reliable and valid; 2) evidence of reliability and validity of synthetic LLM personality is stronger for larger and instruction fine-tuned models; and 3) personality in LLM outputs can be shaped along desired dimensions to mimic specific human personality profiles. We discuss application and ethical implications of the measurement and shaping method in particular regarding responsible AI.

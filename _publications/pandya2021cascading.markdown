---
layout: publication
title: Cascading Adaptors To Leverage English Data To Improve Performance Of Question Answering For Low45;resource Languages
authors: Pandya Hariom A., Ardeshna Bhavik, Bhatt Brijesh S.
conference: "Arxiv"
year: 2021
bibkey: pandya2021cascading
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2112.09866"}
tags: ['Applications', 'Fine Tuning', 'Model Architecture', 'Pretraining Methods', 'RAG', 'Transformer']
---
Transformer based architectures have shown notable results on many down streaming tasks including question answering. The availability of data on the other hand impedes obtaining legitimate performance for low45;resource languages. In this paper we investigate the applicability of pre45;trained multilingual models to improve the performance of question answering in low45;resource languages. We tested four combinations of language and task adapters using multilingual transformer architectures on seven languages similar to MLQA dataset. Additionally we have also proposed zero45;shot transfer learning of low45;resource question answering using language and task adapters. We observed that stacking the language and the task adapters improves the multilingual transformer models performance significantly for low45;resource languages.

---
layout: publication
title: Etrica Event-triggered Context-aware Story Generation Augmented By Cross Attention
authors: Tang Chen, Lin Chenghua, Huang Henglin, Guerin Frank, Zhang Zhihao
conference: "EMNLP"
year: 2022
bibkey: tang2022etrica
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2210.12463"}
tags: ['Attention Mechanism', 'Model Architecture', 'RAG', 'Transformer']
---
One of the key challenges of automatic story generation is how to generate a long narrative that can maintain fluency relevance and coherence. Despite recent progress current story generation systems still face the challenge of how to effectively capture contextual and event features which has a profound impact on a models generation performance. To address these challenges we present EtriCA a novel neural generation model which improves the relevance and coherence of the generated stories through residually mapping context features to event sequences with a cross-attention mechanism. Such a feature capturing mechanism allows our model to better exploit the logical relatedness between events when generating stories. Extensive experiments based on both automatic and human evaluations show that our model significantly outperforms state-of-the-art baselines demonstrating the effectiveness of our model in leveraging context and event features.

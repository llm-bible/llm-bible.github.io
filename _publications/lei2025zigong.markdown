---
layout: publication
title: 'Zigong 1.0: A Large Language Model For Financial Credit'
authors: Yu Lei, Zixuan Wang, Chu Liu, Tongyao Wang
conference: "Arxiv"
year: 2025
bibkey: lei2025zigong
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.16159"}
tags: ['Security', 'Training Techniques', 'Efficiency and Optimization', 'Reinforcement Learning', 'Pruning', 'Pretraining Methods', 'Fine-Tuning', 'Applications']
---
Large Language Models (LLMs) have demonstrated strong performance across
various general Natural Language Processing (NLP) tasks. However, their
effectiveness in financial credit assessment applications remains suboptimal,
primarily due to the specialized financial expertise required for these tasks.
To address this limitation, we propose ZiGong, a Mistral-based model enhanced
through multi-task supervised fine-tuning. To specifically combat model
hallucination in financial contexts, we introduce a novel data pruning
methodology. Our approach utilizes a proxy model to score training samples,
subsequently combining filtered data with original datasets for model training.
This data refinement strategy effectively reduces hallucinations in LLMs while
maintaining reliability in downstream financial applications. Experimental
results show our method significantly enhances model robustness and prediction
accuracy in real-world financial scenarios.

---
layout: publication
title: 'A Statistical Analysis Of Llms'' Self-evaluation Using Proverbs'
authors: Ryosuke Sonoda, Ramya Srinivasan
conference: "Arxiv"
year: 2024
bibkey: sonoda2024statistical
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2410.16640"}
tags: ['Model Architecture', 'GPT', 'Tools']
---
Large language models (LLMs) such as ChatGPT, GPT-4, Claude-3, and Llama are
being integrated across a variety of industries. Despite this rapid
proliferation, experts are calling for caution in the interpretation and
adoption of LLMs, owing to numerous associated ethical concerns. Research has
also uncovered shortcomings in LLMs' reasoning and logical abilities, raising
questions on the potential of LLMs as evaluation tools. In this paper, we
investigate LLMs' self-evaluation capabilities on a novel proverb reasoning
task. We introduce a novel proverb database consisting of 300 proverb pairs
that are similar in intent but different in wordings, across topics spanning
gender, wisdom, and society. We propose tests to evaluate textual consistencies
as well as numerical consistencies across similar proverbs, and demonstrate the
effectiveness of our method and dataset in identifying failures in LLMs'
self-evaluation which in turn can highlight issues related to gender
stereotypes and lack of cultural understanding in LLMs.

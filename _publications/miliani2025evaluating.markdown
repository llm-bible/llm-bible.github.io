---
layout: publication
title: 'Explica: Evaluating Explicit Causal Reasoning In Large Language Models'
authors: Martina Miliani, Serena Auriemma, Alessandro Bondielli, Emmanuele Chersoni, Lucia Passaro, Irene Sucameli, Alessandro Lenci
conference: "Arxiv"
year: 2025
bibkey: miliani2025evaluating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.15487"}
tags: ['Prompting']
---
Large Language Models (LLMs) are increasingly used in tasks requiring
interpretive and inferential accuracy. In this paper, we introduce ExpliCa, a
new dataset for evaluating LLMs in explicit causal reasoning. ExpliCa uniquely
integrates both causal and temporal relations presented in different linguistic
orders and explicitly expressed by linguistic connectives. The dataset is
enriched with crowdsourced human acceptability ratings. We tested LLMs on
ExpliCa through prompting and perplexity-based metrics. We assessed seven
commercial and open-source LLMs, revealing that even top models struggle to
reach 0.80 accuracy. Interestingly, models tend to confound temporal relations
with causal ones, and their performance is also strongly influenced by the
linguistic order of the events. Finally, perplexity-based scores and prompting
performance are differently affected by model size.

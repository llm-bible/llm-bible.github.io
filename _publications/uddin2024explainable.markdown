---
layout: publication
title: 'An Explainable Transformer-based Model For Phishing Email Detection: A Large Language Model Approach'
authors: Mohammad Amaz Uddin, Iqbal H. Sarker
conference: "Arxiv"
year: 2024
bibkey: uddin2024explainable
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.13871"}
tags: ['Masked Language Model', 'Security', 'Model Architecture', 'Pretraining Methods', 'BERT', 'Transformer', 'Interpretability and Explainability']
---
Phishing email is a serious cyber threat that tries to deceive users by
sending false emails with the intention of stealing confidential information or
causing financial harm. Attackers, often posing as trustworthy entities,
exploit technological advancements and sophistication to make detection and
prevention of phishing more challenging. Despite extensive academic research,
phishing detection remains an ongoing and formidable challenge in the
cybersecurity landscape. Large Language Models (LLMs) and Masked Language
Models (MLMs) possess immense potential to offer innovative solutions to
address long-standing challenges. In this research paper, we present an
optimized, fine-tuned transformer-based DistilBERT model designed for the
detection of phishing emails. In the detection process, we work with a phishing
email dataset and utilize the preprocessing techniques to clean and solve the
imbalance class issues. Through our experiments, we found that our model
effectively achieves high accuracy, demonstrating its capability to perform
well. Finally, we demonstrate our fine-tuned model using Explainable-AI (XAI)
techniques such as Local Interpretable Model-Agnostic Explanations (LIME) and
Transformer Interpret to explain how our model makes predictions in the context
of text classification for phishing emails.

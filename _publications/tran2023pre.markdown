---
layout: publication
title: Bartphobeit Pre45;trained Sequence45;to45;sequence And Image Transformers Models For Vietnamese Visual Question Answering
authors: Tran Khiem Vinh, Van Nguyen Kiet, Nguyen Ngan Luu Thuy
conference: "Arxiv"
year: 2023
bibkey: tran2023pre
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2307.15335"}
tags: ['Applications', 'Model Architecture', 'Pretraining Methods', 'Transformer']
---
Visual Question Answering (VQA) is an intricate and demanding task that integrates natural language processing (NLP) and computer vision (CV) capturing the interest of researchers. The English language renowned for its wealth of resources has witnessed notable advancements in both datasets and models designed for VQA. However there is a lack of models that target specific countries such as Vietnam. To address this limitation we introduce a transformer45;based Vietnamese model named BARTPhoBEiT. This model includes pre45;trained Sequence45;to45;Sequence and bidirectional encoder representation from Image Transformers in Vietnamese and evaluates Vietnamese VQA datasets. Experimental results demonstrate that our proposed model outperforms the strong baseline and improves the state45;of45;the45;art in six metrics Accuracy Precision Recall F145;score WUPS 0.0 and WUPS 0.9.

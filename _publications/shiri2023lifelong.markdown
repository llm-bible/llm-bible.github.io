---
layout: publication
title: L3 Ensembles Lifelong Learning Approach For Ensemble Of Foundational Language Models
authors: Shiri Aidin, Roy Kaushik, Sheth Amit, Gaur Manas
conference: "Arxiv"
year: 2023
bibkey: shiri2023lifelong
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2311.06493"}
tags: ['Efficiency And Optimization', 'Merging', 'Pretraining Methods', 'Tools', 'Training Techniques']
---
Fine45;tuning pre45;trained foundational language models (FLM) for specific tasks is often impractical especially for resource45;constrained devices. This necessitates the development of a Lifelong Learning (L3) framework that continuously adapts to a stream of Natural Language Processing (NLP) tasks efficiently. We propose an approach that focuses on extracting meaningful representations from unseen data constructing a structured knowledge base and improving task performance incrementally. We conducted experiments on various NLP tasks to validate its effectiveness including benchmarks like GLUE and SuperGLUE. We measured good performance across the accuracy training efficiency and knowledge transfer metrics. Initial experimental results show that the proposed L3 ensemble method increases the model accuracy by 437; ~ 3637; compared to the fine45;tuned FLM. Furthermore L3 model outperforms naive fine45;tuning approaches while maintaining competitive or superior performance (up to 15.437; increase in accuracy) compared to the state45;of45;the45;art language model (T5) for the given task STS benchmark.

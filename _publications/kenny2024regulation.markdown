---
layout: publication
title: 'Regulation Of Language Models With Interpretability Will Likely Result In A Performance Trade-off'
authors: Eoin M. Kenny, Julie A. Shah
conference: "Arxiv"
year: 2024
bibkey: kenny2024regulation
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2412.12169"}
tags: ['Interpretability and Explainability']
---
Regulation is increasingly cited as the most important and pressing concern
in machine learning. However, it is currently unknown how to implement this,
and perhaps more importantly, how it would effect model performance alongside
human collaboration if actually realized. In this paper, we attempt to answer
these questions by building a regulatable large-language model (LLM), and then
quantifying how the additional constraints involved affect (1) model
performance, alongside (2) human collaboration. Our empirical results reveal
that it is possible to force an LLM to use human-defined features in a
transparent way, but a "regulation performance trade-off" previously not
considered reveals itself in the form of a 7.34% classification performance
drop. Surprisingly however, we show that despite this, such systems actually
improve human task performance speed and appropriate confidence in a realistic
deployment setting compared to no AI assistance, thus paving a way for fair,
regulatable AI, which benefits users.

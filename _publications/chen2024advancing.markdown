---
layout: publication
title: Advancing Tool45;augmented Large Language Models Integrating Insights From Errors In Inference Trees
authors: Chen Sijia, Wang Yibo, Wu Yi-feng, Chen Qing-guo, Xu Zhao, Luo Weihua, Zhang Kaifu, Zhang Lijun
conference: "Arxiv"
year: 2024
bibkey: chen2024advancing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.07115"}
tags: ['Agentic', 'Efficiency And Optimization', 'Fine Tuning', 'RAG', 'Reinforcement Learning', 'Tools', 'Training Techniques']
---
Tool45;augmented large language models (LLMs) leverage tools often in the form of APIs to enhance their reasoning capabilities on complex tasks thus taking on the role of intelligent agents interacting with the real world. The recently introduced ToolLLaMA model by Qin et al. 2024 utilizes the depth45;first search45;based decision tree (DFSDT) method for reasoning with 16000+ real45;world APIs which effectively improves the planning and inferencing performance of tool45;augmented LLMs compared to traditional chain reasoning approaches. However their approach only employs successful paths from decision trees (also called inference trees) for supervised fine45;tuning (SFT) during training which does not fully exploit the advantages of the tree of thought. In this study we propose an inference trajectory optimization framework based on the preference data extracted from decision trees to address this limitation. We first introduce a novel method for constructing preference data from the tree of thought capitalizing on the failed explorations previously overlooked in the trees. Specifically we generate an effective step45;wise preference dataset named ToolPreference for tool use based on the ToolBench dataset. In the subsequent training phase we first fine45;tune the LLM with tool45;usage expert trajectories and then use these step45;wise preference pairs for direct preference optimization (DPO) to update the policy of the LLM resulting in our ToolPrefer45;LLaMA (TP45;LLaMA) model. Our experiments demonstrate that by obtaining insights from errors in inference trees TP45;LLaMA significantly outperforms the baselines across almost all test scenarios by a large margin and exhibits better generalization capabilities with unseen APIs. At the same time TP45;LLaMA has also demonstrated superior reasoning efficiency compared to the baselines making it more suitable for complex tool45;usage reasoning tasks.

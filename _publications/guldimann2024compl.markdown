---
layout: publication
title: 'COMPL-AI Framework: A Technical Interpretation And LLM Benchmarking Suite For The EU Artificial Intelligence Act'
authors: Philipp Guldimann, Alexander Spiridonov, Robin Staab, Nikola Jovanović, Mark Vero, Velko Vechev, Anna-maria Gueorguieva, Mislav Balunović, Nikola Konstantinov, Pavol Bielik, Petar Tsankov, Martin Vechev
conference: "Arxiv"
year: 2024
bibkey: guldimann2024compl
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2410.07959"}
tags: ['Responsible AI', 'Security', 'Fairness', 'Survey Paper', 'Tools', 'Reinforcement Learning', 'RAG', 'Bias Mitigation', 'Ethics and Bias']
---
The EU's Artificial Intelligence Act (AI Act) is a significant step towards
responsible AI development, but lacks clear technical interpretation, making it
difficult to assess models' compliance. This work presents COMPL-AI, a
comprehensive framework consisting of (i) the first technical interpretation of
the EU AI Act, translating its broad regulatory requirements into measurable
technical requirements, with the focus on large language models (LLMs), and
(ii) an open-source Act-centered benchmarking suite, based on thorough
surveying and implementation of state-of-the-art LLM benchmarks. By evaluating
12 prominent LLMs in the context of COMPL-AI, we reveal shortcomings in
existing models and benchmarks, particularly in areas like robustness, safety,
diversity, and fairness. This work highlights the need for a shift in focus
towards these aspects, encouraging balanced development of LLMs and more
comprehensive regulation-aligned benchmarks. Simultaneously, COMPL-AI for the
first time demonstrates the possibilities and difficulties of bringing the
Act's obligations to a more concrete, technical level. As such, our work can
serve as a useful first step towards having actionable recommendations for
model providers, and contributes to ongoing efforts of the EU to enable
application of the Act, such as the drafting of the GPAI Code of Practice.

---
layout: publication
title: 'Character-level Question Answering With Attention'
authors: Golub David, He Xiaodong
conference: "Arxiv"
year: 2016
citations: 110
bibkey: golub2016character
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/1604.00727"}
tags: ['Model Architecture', 'Tools', 'Attention Mechanism', 'Merging', 'Applications']
---
We show that a character-level encoder-decoder framework can be successfully
applied to question answering with a structured knowledge base. We use our
model for single-relation question answering and demonstrate the effectiveness
of our approach on the SimpleQuestions dataset (Bordes et al., 2015), where we
improve state-of-the-art accuracy from 63.9% to 70.9%, without use of
ensembles. Importantly, our character-level model has 16x fewer parameters than
an equivalent word-level model, can be learned with significantly less data
compared to previous work, which relies on data augmentation, and is robust to
new entities in testing.

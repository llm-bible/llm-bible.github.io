---
layout: publication
title: 'Bottom-up And Top-down Analysis Of Values, Agendas, And Observations In Corpora And Llms'
authors: Scott E. Friedman, Noam Benkler, Drisana Mosaphir, Jeffrey Rye, Sonja M. Schmer-galunder, Micah Goldwater, Matthew Mclure, Ruta Wheelock, Jeremy Gottlieb, Robert P. Goldman, Christopher Miller
conference: "Arxiv"
year: 2024
bibkey: friedman2024bottom
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2411.05040"}
tags: ['Responsible AI', 'Training Techniques', 'Prompting']
---
Large language models (LLMs) generate diverse, situated, persuasive texts
from a plurality of potential perspectives, influenced heavily by their prompts
and training data. As part of LLM adoption, we seek to characterize - and
ideally, manage - the socio-cultural values that they express, for reasons of
safety, accuracy, inclusion, and cultural fidelity. We present a validated
approach to automatically (1) extracting heterogeneous latent value
propositions from texts, (2) assessing resonance and conflict of values with
texts, and (3) combining these operations to characterize the pluralistic value
alignment of human-sourced and LLM-sourced textual data.

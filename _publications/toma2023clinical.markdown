---
layout: publication
title: Clinical Camel An Open Expert45;level Medical Language Model With Dialogue45;based Knowledge Encoding
authors: Toma Augustin, Lawler Patrick R., Ba Jimmy, Krishnan Rahul G., Rubin Barry B., Wang Bo
conference: "Arxiv"
year: 2023
bibkey: toma2023clinical
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2305.12031"}
tags: ['Applications', 'Ethics And Bias', 'Fine Tuning', 'GPT', 'Model Architecture', 'RAG', 'Responsible AI', 'Training Techniques']
---
We present Clinical Camel an open large language model (LLM) explicitly tailored for clinical research. Fine45;tuned from LLaMA45;2 using QLoRA Clinical Camel achieves state45;of45;the45;art performance across medical benchmarks among openly available medical LLMs. Leveraging efficient single45;GPU training Clinical Camel surpasses GPT45;3.5 in five45;shot evaluations on all assessed benchmarks including 64.337; on the USMLE Sample Exam (compared to 58.537; for GPT45;3.5) 77.937; on PubMedQA (compared to 60.237;) 60.737; on MedQA (compared to 53.637;) and 54.237; on MedMCQA (compared to 51.037;). In addition to these benchmarks Clinical Camel demonstrates its broader capabilities such as synthesizing plausible clinical notes. This work introduces dialogue45;based knowledge encoding a novel method to synthesize conversational data from dense medical texts. While benchmark results are encouraging extensive and rigorous human evaluation across diverse clinical scenarios is imperative to ascertain safety before implementation. By openly sharing Clinical Camel we hope to foster transparent and collaborative research working towards the safe integration of LLMs within the healthcare domain. Significant challenges concerning reliability bias and the potential for outdated knowledge persist. Nonetheless the transparency provided by an open approach reinforces the scientific rigor essential for future clinical applications.

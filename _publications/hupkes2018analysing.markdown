---
layout: publication
title: Analysing The Potential Of Seq45;to45;seq Models For Incremental Interpretation In Task45;oriented Dialogue
authors: Hupkes Dieuwke, Bouwmeester Sanne, Fern√°ndez Raquel
conference: "Arxiv"
year: 2018
bibkey: hupkes2018analysing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/1808.09178"}
tags: ['Attention Mechanism', 'Ethics And Bias', 'Model Architecture', 'Reinforcement Learning']
---
We investigate how encoder45;decoder models trained on a synthetic dataset of task45;oriented dialogues process disfluencies such as hesitations and self45;corrections. We find that contrary to earlier results disfluencies have very little impact on the task success of seq45;to45;seq models with attention. Using visualisation and diagnostic classifiers we analyse the representations that are incrementally built by the model and discover that models develop little to no awareness of the structure of disfluencies. However adding disfluencies to the data appears to help the model create clearer representations overall as evidenced by the attention patterns the different models exhibit.

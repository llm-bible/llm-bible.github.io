---
layout: publication
title: 'Large Language Model Augmented Narrative Driven Recommendations'
authors: Mysore Sheshera, Mccallum Andrew, Zamani Hamed
conference: "Arxiv"
year: 2023
bibkey: mysore2023large
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2306.02250"}
tags: ['Few Shot', 'In Context Learning', 'Prompting', 'Reinforcement Learning', 'Tools', 'Training Techniques']
---
Narrative-driven recommendation (NDR) presents an information access problem where users solicit recommendations with verbose descriptions of their preferences and context, for example, travelers soliciting recommendations for points of interest while describing their likes/dislikes and travel circumstances. These requests are increasingly important with the rise of natural language-based conversational interfaces for search and recommendation systems. However, NDR lacks abundant training data for models, and current platforms commonly do not support these requests. Fortunately, classical user-item interaction datasets contain rich textual data, e.g., reviews, which often describe user preferences and context - this may be used to bootstrap training for NDR models. In this work, we explore using large language models (LLMs) for data augmentation to train NDR models. We use LLMs for authoring synthetic narrative queries from user-item interactions with few-shot prompting and train retrieval models for NDR on synthetic queries and user-item interaction data. Our experiments demonstrate that this is an effective strategy for training small-parameter retrieval models that outperform other retrieval and LLM baselines for narrative-driven recommendation.

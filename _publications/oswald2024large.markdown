---
layout: publication
title: "Large Language Models As Planning Domain Generators"
authors: Oswald James, Srinivas Kavitha, Kokel Harsha, Lee Junkyu, Katz Michael, Sohrabi Shirin
conference: "Arxiv"
year: 2024
bibkey: oswald2024large
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.06650"}
  - {name: "Code", url: "https://github.com/IBM/NL2PDDL"}
tags: ['Applications', 'Has Code', 'Reinforcement Learning', 'Tools']
---
Developing domain models is one of the few remaining places that require manual human labor in AI planning. Thus in order to make planning more accessible it is desirable to automate the process of domain model generation. To this end we investigate if large language models (LLMs) can be used to generate planning domain models from simple textual descriptions. Specifically we introduce a framework for automated evaluation of LLM-generated domains by comparing the sets of plans for domain instances. Finally we perform an empirical analysis of 7 large language models including coding and chat models across 9 different planning domains and under three classes of natural language domain descriptions. Our results indicate that LLMs particularly those with high parameter counts exhibit a moderate level of proficiency in generating correct planning domains from natural language descriptions. Our code is available at https://github.com/IBM/NL2PDDL."

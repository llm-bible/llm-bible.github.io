---
layout: publication
title: Pushing Large Language Models To The 6G Edge: Vision, Challenges, And Opportunities
authors: Lin Zheng, Qu Guanqiao, Chen Qiyuan, Chen Xianhao, Chen Zhe, Huang Kaibin
conference: "Arxiv"
year: 2023
bibkey: lin2023pushing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.16739"}
tags: ['Applications', 'Efficiency And Optimization', 'Fine Tuning', 'Model Architecture', 'Multimodal Models', 'Pretraining Methods', 'Quantization', 'Reinforcement Learning', 'Tools', 'Training Techniques']
---
Large language models (LLMs) which have shown remarkable capabilities are revolutionizing AI development and potentially shaping our future. However given their multimodality the status quo cloud-based deployment faces some critical challenges 1) long response time; 2) high bandwidth costs; and 3) the violation of data privacy. 6G mobile edge computing (MEC) systems may resolve these pressing issues. In this article we explore the potential of deploying LLMs at the 6G edge. We start by introducing killer applications powered by multimodal LLMs including robotics and healthcare to highlight the need for deploying LLMs in the vicinity of end users. Then we identify the critical challenges for LLM deployment at the edge and envision the 6G MEC architecture for LLMs. Furthermore we delve into two design aspects i.e. edge training and edge inference for LLMs. In both aspects considering the inherent resource limitations at the edge we discuss various cutting-edge techniques including split learning/inference parameter-efficient fine-tuning quantization and parameter-sharing inference to facilitate the efficient deployment of LLMs. This article serves as a position paper for thoroughly identifying the motivation challenges and pathway for empowering LLMs at the 6G edge.

---
layout: publication
title: 'TACOMORE: Leveraging The Potential Of Llms In Corpus-based Discourse Analysis With Prompt Engineering'
authors: Bingru Li, Han Wang
conference: "Arxiv"
year: 2024
bibkey: li2024leveraging
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2412.10139"}
tags: ['Model Architecture', 'Tools', 'RAG', 'GPT', 'Prompting']
---
The capacity of LLMs to carry out automated qualitative analysis has been
questioned by corpus linguists, and it has been argued that corpus-based
discourse analysis incorporating LLMs is hindered by issues of unsatisfying
performance, hallucination, and irreproducibility. Our proposed method,
TACOMORE, aims to address these concerns by serving as an effective prompting
framework in this domain. The framework consists of four principles, i.e.,
Task, Context, Model and Reproducibility, and specifies five fundamental
elements of a good prompt, i.e., Role Description, Task Definition, Task
Procedures, Contextual Information and Output Format. We conduct experiments on
three LLMs, i.e., GPT-4o, Gemini-1.5-Pro and Gemini-1.5.Flash, and find that
TACOMORE helps improve LLM performance in three representative discourse
analysis tasks, i.e., the analysis of keywords, collocates and concordances,
based on an open corpus of COVID-19 research articles. Our findings show the
efficacy of the proposed prompting framework TACOMORE in corpus-based discourse
analysis in terms of Accuracy, Ethicality, Reasoning, and Reproducibility, and
provide novel insights into the application and evaluation of LLMs in automated
qualitative studies.

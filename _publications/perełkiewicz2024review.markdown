---
layout: publication
title: "A Review Of The Challenges With Massive Web-mined Corpora Used In Large Language Models Pre-training"
authors: Perełkiewicz Michał, Poświata Rafał
conference: "Arxiv"
year: 2024
bibkey: perełkiewicz2024review
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.07630"}
tags: ['Ethics And Bias', 'Survey Paper', 'Training Techniques']
---
This article presents a comprehensive review of the challenges associated with using massive web-mined corpora for the pre-training of large language models (LLMs). This review identifies key challenges in this domain including challenges such as noise (irrelevant or misleading information) duplication of content the presence of low-quality or incorrect information biases and the inclusion of sensitive or personal information in web-mined corpora. Addressing these issues is crucial for the development of accurate reliable and ethically responsible language models. Through an examination of current methodologies for data cleaning pre-processing bias detection and mitigation we highlight the gaps in existing approaches and suggest directions for future research. Our discussion aims to catalyze advancements in developing more sophisticated and ethically responsible LLMs.

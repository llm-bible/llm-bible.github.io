---
layout: publication
title: 'Beyond Turing Test: Can GPT-4 Sway Experts'' Decisions?'
authors: Takehiro Takayanagi, Hiroya Takamura, Kiyoshi Izumi, Chung-chi Chen
conference: "Arxiv"
year: 2024
bibkey: takayanagi2024beyond
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2409.16710"}
tags: ['RAG', 'GPT', 'Model Architecture', 'Reinforcement Learning']
---
In the post-Turing era, evaluating large language models (LLMs) involves
assessing generated text based on readers' reactions rather than merely its
indistinguishability from human-produced content. This paper explores how
LLM-generated text impacts readers' decisions, focusing on both amateur and
expert audiences. Our findings indicate that GPT-4 can generate persuasive
analyses affecting the decisions of both amateurs and professionals.
Furthermore, we evaluate the generated text from the aspects of grammar,
convincingness, logical coherence, and usefulness. The results highlight a high
correlation between real-world evaluation through audience reactions and the
current multi-dimensional evaluators commonly used for generative models.
Overall, this paper shows the potential and risk of using generated text to
sway human decisions and also points out a new direction for evaluating
generated text, i.e., leveraging the reactions and decisions of readers. We
release our dataset to assist future research.

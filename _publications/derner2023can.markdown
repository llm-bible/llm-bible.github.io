---
layout: publication
title: 'Can Chatgpt Read Who You Are?'
authors: Erik Derner, Dalibor Kučera, Nuria Oliver, Jan Zahálka
conference: "Arxiv"
year: 2023
bibkey: derner2023can
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2312.16070"}
tags: ['Responsible AI', 'GPT', 'Applications', 'Ethics and Bias', 'Model Architecture', 'Reinforcement Learning', 'Merging', 'Prompting']
---
The interplay between artificial intelligence (AI) and psychology,
particularly in personality assessment, represents an important emerging area
of research. Accurate personality trait estimation is crucial not only for
enhancing personalization in human-computer interaction but also for a wide
variety of applications ranging from mental health to education. This paper
analyzes the capability of a generic chatbot, ChatGPT, to effectively infer
personality traits from short texts. We report the results of a comprehensive
user study featuring texts written in Czech by a representative population
sample of 155 participants. Their self-assessments based on the Big Five
Inventory (BFI) questionnaire serve as the ground truth. We compare the
personality trait estimations made by ChatGPT against those by human raters and
report ChatGPT's competitive performance in inferring personality traits from
text. We also uncover a 'positivity bias' in ChatGPT's assessments across all
personality dimensions and explore the impact of prompt composition on
accuracy. This work contributes to the understanding of AI capabilities in
psychological assessment, highlighting both the potential and limitations of
using large language models for personality inference. Our research underscores
the importance of responsible AI development, considering ethical implications
such as privacy, consent, autonomy, and bias in AI applications.

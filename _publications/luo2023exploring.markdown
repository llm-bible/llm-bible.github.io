---
layout: publication
title: Exploring Small Language Models With Prompt45;learning Paradigm For Efficient Domain45;specific Text Classification
authors: Luo Hengyu, Liu Peng, Esping Stefan
conference: "Arxiv"
year: 2023
bibkey: luo2023exploring
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.14779"}
tags: ['Agentic', 'Efficiency And Optimization', 'GPT', 'Model Architecture', 'Prompting']
---
Domain45;specific text classification faces the challenge of scarce labeled data due to the high cost of manual labeling. Prompt45;learning known for its efficiency in few45;shot scenarios is proposed as an alternative to traditional fine45;tuning methods. And besides although large language models (LLMs) have gained prominence small language models (SLMs with under 1B parameters) offer significant customizability adaptability and cost45;effectiveness for domain45;specific tasks given industry constraints. In this study we investigate the potential of SLMs combined with prompt45;learning paradigm for domain45;specific text classification specifically within customer45;agent interactions in retail. Our evaluations show that in few45;shot settings when prompt45;based model fine45;tuning is possible T545;base a typical SLM with 220M parameters achieve approximately 7537; accuracy with limited labeled data (up to 1537; of full data) which shows great potentials of SLMs with prompt45;learning. Based on this We further validate the effectiveness of active few45;shot sampling and the ensemble strategy in the prompt45;learning pipeline that contribute to a remarkable performance gain. Besides in zero45;shot settings with a fixed model we underscore a pivotal observation that although the GPT45;3.545;turbo equipped with around 154B parameters garners an accuracy of 55.1637; the power of well designed prompts becomes evident when the FLAN45;T545;large a model with a mere 0.537; of GPT45;3.545;turbos parameters achieves an accuracy exceeding 3137; with the optimized prompt a leap from its sub45;1837; performance with an unoptimized one. Our findings underscore the promise of prompt45;learning in classification tasks with SLMs emphasizing the benefits of active few45;shot sampling and ensemble strategies in few45;shot settings and the importance of prompt engineering in zero45;shot settings.

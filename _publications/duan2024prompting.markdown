---
layout: publication
title: Prompting Multi45;modal Tokens To Enhance End45;to45;end Autonomous Driving Imitation Learning With Llms
authors: Duan Yiqun, Zhang Qiang, Xu Renjing
conference: "Published as oral presentation paper atthe"
year: 2024
bibkey: duan2024prompting
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.04869"}
tags: ['Agentic', 'Attention Mechanism', 'Ethics And Bias', 'Model Architecture', 'Prompting', 'Reinforcement Learning', 'Tools']
---
The utilization of Large Language Models (LLMs) within the realm of reinforcement learning particularly as planners has garnered a significant degree of attention in recent scholarly literature. However a substantial proportion of existing research predominantly focuses on planning models for robotics that transmute the outputs derived from perception models into linguistic forms thus adopting a pure45;language strategy. In this research we propose a hybrid End45;to45;End learning framework for autonomous driving by combining basic driving imitation learning with LLMs based on multi45;modality prompt tokens. Instead of simply converting perception results from the separated train model into pure language input our novelty lies in two aspects. 1) The end45;to45;end integration of visual and LiDAR sensory input into learnable multi45;modality tokens thereby intrinsically alleviating description bias by separated pre45;trained perception models. 2) Instead of directly letting LLMs drive this paper explores a hybrid setting of letting LLMs help the driving model correct mistakes and complicated scenarios. The results of our experiments suggest that the proposed methodology can attain driving scores of 49.2137; coupled with an impressive route completion rate of 91.3437; in the offline evaluation conducted via CARLA. These performance metrics are comparable to the most advanced driving models.

---
layout: publication
title: 'Triple Phase Transitions: Understanding The Learning Dynamics Of Large Language Models From A Neuroscience Perspective'
authors: Yuko Nakagi, Keigo Tada, Sota Yoshino, Shinji Nishimoto, Yu Takagi
conference: "Arxiv"
year: 2025
bibkey: nakagi2025triple
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.20779"}
tags: ['Training Techniques', 'Model Architecture', 'Reinforcement Learning']
---
Large language models (LLMs) often exhibit abrupt emergent behavior, whereby
new abilities arise at certain points during their training. This phenomenon,
commonly referred to as a ''phase transition'', remains poorly understood. In
this study, we conduct an integrative analysis of such phase transitions by
examining three interconnected perspectives: the similarity between LLMs and
the human brain, the internal states of LLMs, and downstream task performance.
We propose a novel interpretation for the learning dynamics of LLMs that vary
in both training data and architecture, revealing that three phase transitions
commonly emerge across these models during training: (1) alignment with the
entire brain surges as LLMs begin adhering to task instructions Brain Alignment
and Instruction Following, (2) unexpectedly, LLMs diverge from the brain during
a period in which downstream task accuracy temporarily stagnates Brain
Detachment and Stagnation, and (3) alignment with the brain reoccurs as LLMs
become capable of solving the downstream tasks Brain Realignment and
Consolidation. These findings illuminate the underlying mechanisms of phase
transitions in LLMs, while opening new avenues for interdisciplinary research
bridging AI and neuroscience.

---
layout: publication
title: 'Indicsquad: A Comprehensive Multilingual Question Answering Dataset For Indic Languages'
authors: Sharvi Endait, Ruturaj Ghatage, Aditya Kulkarni, Rajlaxmi Patil, Raviraj Joshi
conference: "Arxiv"
year: 2025
bibkey: endait2025comprehensive
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2505.03688"}
  - {name: "Code", url: "https://github.com/l3cube-pune/indic-nlp"}
tags: ['Tools', 'Applications', 'Model Architecture', 'Training Techniques', 'Has Code', 'BERT', 'Multimodal Models']
---
The rapid progress in question-answering (QA) systems has predominantly benefited high-resource languages, leaving Indic languages largely underrepresented despite their vast native speaker base. In this paper, we present IndicSQuAD, a comprehensive multi-lingual extractive QA dataset covering nine major Indic languages, systematically derived from the SQuAD dataset. Building on previous work with MahaSQuAD for Marathi, our approach adapts and extends translation techniques to maintain high linguistic fidelity and accurate answer-span alignment across diverse languages. IndicSQuAD comprises extensive training, validation, and test sets for each language, providing a robust foundation for model development. We evaluate baseline performances using language-specific monolingual BERT models and the multilingual MuRIL-BERT. The results indicate some challenges inherent in low-resource settings. Moreover, our experiments suggest potential directions for future work, including expanding to additional languages, developing domain-specific datasets, and incorporating multimodal data. The dataset and models are publicly shared at https://github.com/l3cube-pune/indic-nlp

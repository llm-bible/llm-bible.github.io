---
layout: publication
title: 'Using Large Language Models To Create AI Personas For Replication, Generalization And Prediction Of Media Effects: An Empirical Test Of 133 Published Experimental Research Findings'
authors: Leo Yeykelis, Kaavya Pichai, James J. Cummings, Byron Reeves
conference: "Arxiv"
year: 2024
bibkey: yeykelis2024using
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.16073"}
tags: ['Prompting', 'Ethics and Bias', 'Tools']
---
This report analyzes the potential for large language models (LLMs) to
expedite accurate replication and generalization of published research about
message effects in marketing. LLM-powered participants (personas) were tested
by replicating 133 experimental findings from 14 papers containing 45 recent
studies published in the Journal of Marketing. For each study, the measures,
stimuli, and sampling specifications were used to generate prompts for LLMs to
act as unique personas. The AI personas, 19,447 in total across all of the
studies, generated complete datasets and statistical analyses were then
compared with the original human study results. The LLM replications
successfully reproduced 76% of the original main effects (84 out of 111),
demonstrating strong potential for AI-assisted replication. The overall
replication rate including interaction effects was 68% (90 out of 133).
Furthermore, a test of how human results generalized to different participant
samples, media stimuli, and measures showed that replication results can change
when tests go beyond the parameters of the original human studies. Implications
are discussed for the replication and generalizability crises in social
science, the acceleration of theory building in media and marketing psychology,
and the practical advantages of rapid message testing for consumer products.
Limitations of AI replications are addressed with respect to complex
interaction effects, biases in AI models, and establishing benchmarks for AI
metrics in marketing research.

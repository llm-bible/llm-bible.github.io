---
layout: publication
title: Evaluating Zero45;shot GPT45;4V Performance On 3D Visual Question Answering Benchmarks
authors: Singh Simranjit, Pavlakos Georgios, Stamoulis Dimitrios
conference: "Arxiv"
year: 2024
bibkey: singh2024evaluating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.18831"}
tags: ['Agentic', 'Applications', 'GPT', 'Model Architecture']
---
As interest in reformulating the 3D Visual Question Answering (VQA) problem in the context of foundation models grows it is imperative to assess how these new paradigms influence existing closed45;vocabulary datasets. In this case study we evaluate the zero45;shot performance of foundational models (GPT45;4 Vision and GPT45;4) on well45;established 3D VQA benchmarks namely 3D45;VQA and ScanQA. We provide an investigation to contextualize the performance of GPT45;based agents relative to traditional modeling approaches. We find that GPT45;based agents without any fine45;tuning perform on par with the closed vocabulary approaches. Our findings corroborate recent results that blind models establish a surprisingly strong baseline in closed45;vocabulary settings. We demonstrate that agents benefit significantly from scene45;specific vocabulary via in45;context textual grounding. By presenting a preliminary comparison with previous baselines we hope to inform the communitys ongoing efforts to refine multi45;modal 3D benchmarks.

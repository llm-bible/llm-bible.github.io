---
layout: publication
title: 'Enhanced Multimodal Aspect-based Sentiment Analysis By Llm-generated Rationales'
authors: Jun Cao, Jiyi Li, Ziwei Yang, Renjie Zhou
conference: "Arxiv"
year: 2025
bibkey: cao2025enhanced
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2505.14499"}
tags: ['Multimodal Models', 'Model Architecture', 'Tools', 'Merging', 'Transformer', 'Interpretability and Explainability', 'Attention Mechanism']
---
There has been growing interest in Multimodal Aspect-Based Sentiment Analysis (MABSA) in recent years. Existing methods predominantly rely on pre-trained small language models (SLMs) to collect information related to aspects and sentiments from both image and text, with an aim to align these two modalities. However, small SLMs possess limited capacity and knowledge, often resulting in inaccurate identification of meaning, aspects, sentiments, and their interconnections in textual and visual data. On the other hand, Large language models (LLMs) have shown exceptional capabilities in various tasks by effectively exploring fine-grained information in multimodal data. However, some studies indicate that LLMs still fall short compared to fine-tuned small models in the field of ABSA. Based on these findings, we propose a novel framework, termed LRSA, which combines the decision-making capabilities of SLMs with additional information provided by LLMs for MABSA. Specifically, we inject explanations generated by LLMs as rationales into SLMs and employ a dual cross-attention mechanism for enhancing feature interaction and fusion, thereby augmenting the SLMs' ability to identify aspects and sentiments. We evaluated our method using two baseline models, numerous experiments highlight the superiority of our approach on three widely-used benchmarks, indicating its generalizability and applicability to most pre-trained models for MABSA.

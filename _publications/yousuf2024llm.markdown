---
layout: publication
title: 'LLM Augmentations To Support Analytical Reasoning Over Multiple Documents'
authors: Raquib Bin Yousuf, Nicholas Defelice, Mandar Sharma, Shengzhe Xu, Naren Ramakrishnan
conference: "Arxiv"
year: 2024
bibkey: yousuf2024llm
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2411.16116"}
tags: ['Model Architecture', 'Applications', 'Reinforcement Learning']
---
Building on their demonstrated ability to perform a variety of tasks, we
investigate the application of large language models (LLMs) to enhance in-depth
analytical reasoning within the context of intelligence analysis. Intelligence
analysts typically work with massive dossiers to draw connections between
seemingly unrelated entities, and uncover adversaries' plans and motives. We
explore if and how LLMs can be helpful to analysts for this task and develop an
architecture to augment the capabilities of an LLM with a memory module called
dynamic evidence trees (DETs) to develop and track multiple investigation
threads. Through extensive experiments on multiple datasets, we highlight how
LLMs, as-is, are still inadequate to support intelligence analysts and offer
recommendations to improve LLMs for such intricate reasoning applications.

---
layout: publication
title: 'Reasoning About Affordances: Causal And Compositional Reasoning In Llms'
authors: Magnus F. Gjerde, Vanessa Cheung, David Lagnado
conference: "Arxiv"
year: 2025
bibkey: gjerde2025reasoning
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2502.16606'}
tags: ['GPT', 'Tools', 'Prompting', 'Model Architecture']
---
With the rapid progress of Large Language Models (LLMs), it becomes
increasingly important to understand their abilities and limitations. In two
experiments, we investigate the causal and compositional reasoning abilities of
LLMs and humans in the domain of object affordances, an area traditionally
linked to embodied cognition. The tasks, designed from scratch to avoid data
contamination, require decision-makers to select unconventional objects to
replace a typical tool for a particular purpose, such as using a table tennis
racket to dig a hole. In Experiment 1, we evaluated GPT-3.5 and GPT-4o, finding
that GPT-4o, when given chain-of-thought prompting, performed on par with human
participants, while GPT-3.5 lagged significantly. In Experiment 2, we
introduced two new conditions, Distractor (more object choices, increasing
difficulty) and Image (object options presented visually), and evaluated Claude
3 Sonnet and Claude 3.5 Sonnet in addition to the GPT models. The Distractor
condition significantly impaired performance across humans and models, although
GPT-4o and Claude 3.5 still performed well above chance. Surprisingly, the
Image condition had little impact on humans or GPT-4o, but significantly
lowered Claude 3.5's accuracy. Qualitative analysis showed that GPT-4o and
Claude 3.5 have a stronger ability than their predecessors to identify and
flexibly apply causally relevant object properties. The improvement from
GPT-3.5 and Claude 3 to GPT-4o and Claude 3.5 suggests that models are
increasingly capable of causal and compositional reasoning in some domains,
although further mechanistic research is necessary to understand how LLMs
reason.

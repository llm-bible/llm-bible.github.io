---
layout: publication
title: 'Injecting Domain-specific Knowledge Into Large Language Models: A Comprehensive Survey'
authors: Zirui Song, Bin Yan, Yuhan Liu, Miao Fang, Mingzhe Li, Rui Yan, Xiuying Chen
conference: "Arxiv"
year: 2025
bibkey: song2025injecting
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.10708"}
  - {name: "Code", url: "https://github.com/abilliyb/Knowledge_Injection_Survey_Papers,"}
tags: ['Efficiency and Optimization', 'Survey Paper', 'Applications', 'Merging', 'Reinforcement Learning', 'Has Code', 'Prompting']
---
Large Language Models (LLMs) have demonstrated remarkable success in various
tasks such as natural language understanding, text summarization, and machine
translation. However, their general-purpose nature often limits their
effectiveness in domain-specific applications that require specialized
knowledge, such as healthcare, chemistry, or legal analysis. To address this,
researchers have explored diverse methods to enhance LLMs by integrating
domain-specific knowledge. In this survey, we provide a comprehensive overview
of these methods, which we categorize into four key approaches: dynamic
knowledge injection, static knowledge embedding, modular adapters, and prompt
optimization. Each approach offers unique mechanisms to equip LLMs with domain
expertise, balancing trade-offs between flexibility, scalability, and
efficiency. We discuss how these methods enable LLMs to tackle specialized
tasks, compare their advantages and disadvantages, evaluate domain-specific
LLMs against general LLMs, and highlight the challenges and opportunities in
this emerging field. For those interested in delving deeper into this area, we
also summarize the commonly used datasets and benchmarks. To keep researchers
updated on the latest studies, we maintain an open-source at:
https://github.com/abilliyb/Knowledge_Injection_Survey_Papers, dedicated to
documenting research in the field of specialized LLM.

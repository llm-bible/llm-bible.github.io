---
layout: publication
title: Assessing The Potential Of Mid45;sized Language Models For Clinical QA
authors: Bolton Elliot, Xiong Betty, Muralidharan Vijaytha, Schamroth Joel, Muralidharan Vivek, Manning Christopher D., Daneshjou Roxana
conference: "Arxiv"
year: 2024
bibkey: bolton2024assessing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.15894"}
tags: ['GPT', 'Model Architecture', 'Pretraining Methods']
---
Large language models such as GPT45;4 and Med45;PaLM have shown impressive performance on clinical tasks; however they require access to compute are closed45;source and cannot be deployed on device. Mid45;size models such as BioGPT45;large BioMedLM LLaMA 2 and Mistral 7B avoid these drawbacks but their capacity for clinical tasks has been understudied. To help assess their potential for clinical use and help researchers decide which model they should use we compare their performance on two clinical question45;answering (QA) tasks MedQA and consumer query answering. We find that Mistral 7B is the best performing model winning on all benchmarks and outperforming models trained specifically for the biomedical domain. While Mistral 7Bs MedQA score of 63.037; approaches the original Med45;PaLM and it often can produce plausible responses to consumer health queries room for improvement still exists. This study provides the first head45;to45;head assessment of open source mid45;sized models on clinical tasks.

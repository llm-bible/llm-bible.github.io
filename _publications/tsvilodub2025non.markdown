---
layout: publication
title: 'Non-literal Understanding Of Number Words By Language Models'
authors: Polina Tsvilodub, Kanishk Gandhi, Haoran Zhao, Jan-philipp Fr√§nken, Michael Franke, Noah D. Goodman
conference: "Arxiv"
year: 2025
bibkey: tsvilodub2025non
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2502.06204'}
tags: ['Reinforcement Learning', 'RAG', 'Prompting', 'Tools']
---
Humans naturally interpret numbers non-literally, effortlessly combining context, world knowledge, and speaker intent. We investigate whether large language models (LLMs) interpret numbers similarly, focusing on hyperbole and pragmatic halo effects. Through systematic comparison with human data and computational models of pragmatic reasoning, we find that LLMs diverge from human interpretation in striking ways. By decomposing pragmatic reasoning into testable components, grounded in the Rational Speech Act framework, we pinpoint where LLM processing diverges from human cognition -- not in prior knowledge, but in reasoning with it. This insight leads us to develop a targeted solution -- chain-of-thought prompting inspired by an RSA model makes LLMs' interpretations more human-like. Our work demonstrates how computational cognitive models can both diagnose AI-human differences and guide development of more human-like language understanding capabilities.

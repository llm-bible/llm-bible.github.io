---
layout: publication
title: Shortcut Learning of Large Language Models in Natural Language Understanding
authors: Du Mengnan, He Fengxiang, Zou Na, Tao Dacheng, Hu Xia
conference: "Arxiv"
year: 2022
bibkey: du2022shortcut
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2208.11857"}
tags: ['Applications', 'Ethics And Bias', 'Security', 'Survey Paper']
---
Large language models (LLMs) have achieved state-of-the-art performance on a series of natural language understanding tasks. However these LLMs might rely on dataset bias and artifacts as shortcuts for prediction. This has significantly affected their generalizability and adversarial robustness. In this paper we provide a review of recent developments that address the shortcut learning and robustness challenge of LLMs. We first introduce the concepts of shortcut learning of language models. We then introduce methods to identify shortcut learning behavior in language models characterize the reasons for shortcut learning as well as introduce mitigation solutions. Finally we discuss key research challenges and potential research directions in order to advance the field of LLMs.

---
layout: publication
title: 'Shortcut Learning Of Large Language Models In Natural Language Understanding'
authors: Mengnan Du, Fengxiang He, Na Zou, Dacheng Tao, Xia Hu
conference: "Arxiv"
year: 2022
bibkey: du2022shortcut
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2208.11857'}
tags: ['Ethics and Bias', 'Security', 'Applications', 'Survey Paper']
---
Large language models (LLMs) have achieved state-of-the-art performance on a
series of natural language understanding tasks. However, these LLMs might rely
on dataset bias and artifacts as shortcuts for prediction. This has
significantly affected their generalizability and adversarial robustness. In
this paper, we provide a review of recent developments that address the
shortcut learning and robustness challenge of LLMs. We first introduce the
concepts of shortcut learning of language models. We then introduce methods to
identify shortcut learning behavior in language models, characterize the
reasons for shortcut learning, as well as introduce mitigation solutions.
Finally, we discuss key research challenges and potential research directions
in order to advance the field of LLMs.

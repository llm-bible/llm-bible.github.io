---
layout: publication
title: 'Fundamental Principles Of Linguistic Structure Are Not Represented By O3'
authors: Elliot Murphy, Evelina Leivada, Vittoria Dentella, Fritz Gunther, Gary Marcus
conference: "Arxiv"
year: 2025
bibkey: murphy2025fundamental
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2502.10934"}
tags: ['Tools']
---
A core component of a successful artificial general intelligence would be the
rapid creation and manipulation of grounded compositional abstractions and the
demonstration of expertise in the family of recursive hierarchical syntactic
objects necessary for the creative use of human language. We evaluated the
recently released o3 model (OpenAI; o3-mini-high) and discovered that while it
succeeds on some basic linguistic tests relying on linear, surface statistics
(e.g., the Strawberry Test), it fails to generalize basic phrase structure
rules; it fails with comparative sentences involving semantically illegal
cardinality comparisons ('Escher sentences'); its fails to correctly rate and
explain acceptability dynamics; and it fails to distinguish between
instructions to generate unacceptable semantic vs. unacceptable syntactic
outputs. When tasked with generating simple violations of grammatical rules, it
is seemingly incapable of representing multiple parses to evaluate against
various possible semantic interpretations. In stark contrast to many recent
claims that artificial language models are on the verge of replacing the field
of linguistics, our results suggest not only that deep learning is hitting a
wall with respect to compositionality (Marcus 2022), but that it is hitting [a
[stubbornly [resilient wall]]] that cannot readily be surmounted to reach
human-like compositional reasoning simply through more compute.

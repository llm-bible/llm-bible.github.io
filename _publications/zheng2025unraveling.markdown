---
layout: publication
title: 'Logidynamics: Unraveling The Dynamics Of Logical Inference In Large Language Model Reasoning'
authors: Tianshi Zheng, Jiayang Cheng, Chunyang Li, Haochen Shi, Zihao Wang, Jiaxin Bai, Yangqiu Song, Ginny Y. Wong, Simon See
conference: "Arxiv"
year: 2025
bibkey: zheng2025unraveling
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2502.11176'}
  - {name: "Code", url: 'https://github.com/HKUST-KnowComp/LogiDynamics'}
tags: ['Has Code', 'RAG', 'Fine-Tuning', 'Prompting', 'In-Context Learning']
---
Modern large language models (LLMs) employ various forms of logical
inference, both implicitly and explicitly, when addressing reasoning tasks.
Understanding how to optimally leverage these inference paradigms is critical
for advancing LLMs' reasoning capabilities. This paper adopts an exploratory
approach by introducing a controlled evaluation environment for analogical
reasoning -- a fundamental cognitive task -- that is systematically
parameterized across three dimensions: modality (textual, visual, symbolic),
difficulty (easy, medium, hard), and task format (multiple-choice or free-text
generation). We analyze the comparative dynamics of inductive, abductive, and
deductive inference pipelines across these dimensions, and demonstrate that our
findings generalize to broader in-context learning tasks. Additionally, we
investigate advanced paradigms such as hypothesis selection, verification, and
refinement, revealing their potential to scale up logical inference in LLM
reasoning. This exploratory study provides a foundation for future research in
enhancing LLM reasoning through systematic logical inference strategies.
Resources are available at https://github.com/HKUST-KnowComp/LogiDynamics.

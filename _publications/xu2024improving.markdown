---
layout: publication
title: 'Improving In-context Learning With Prediction Feedback For Sentiment Analysis'
authors: Hongling Xu, Qianlong Wang, Yice Zhang, Min Yang, Xi Zeng, Bing Qin, Ruifeng Xu
conference: "Arxiv"
year: 2024
bibkey: xu2024improving
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2406.02911'}
tags: ['RAG', 'Prompting', 'In-Context Learning', 'Tools']
---
Large language models (LLMs) have achieved promising results in sentiment
analysis through the in-context learning (ICL) paradigm. However, their ability
to distinguish subtle sentiments still remains a challenge. Inspired by the
human ability to adjust understanding via feedback, this paper enhances ICL by
incorporating prior predictions and feedback, aiming to rectify sentiment
misinterpretation of LLMs. Specifically, the proposed framework consists of
three steps: (1) acquiring prior predictions of LLMs, (2) devising predictive
feedback based on correctness, and (3) leveraging a feedback-driven prompt to
refine sentiment understanding. Experimental results across nine sentiment
analysis datasets demonstrate the superiority of our framework over
conventional ICL methods, with an average F1 improvement of 5.95%.

---
layout: publication
title: Structured Flexible And Robust Benchmarking And Improving Large Language Models Towards More Human45;like Behavior In Out45;of45;distribution Reasoning Tasks
authors: Collins Katherine M., Wong Catherine, Feng Jiahai, Wei Megan, Tenenbaum Joshua B.
conference: "Arxiv"
year: 2022
bibkey: collins2022benchmarking
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2205.05718"}
tags: ['Interpretability And Explainability', 'Pretraining Methods']
---
Human language offers a powerful window into our thoughts 45;45; we tell stories give explanations and express our beliefs and goals through words. Abundant evidence also suggests that language plays a developmental role in structuring our learning. Here we ask how much of human45;like thinking can be captured by learning statistical patterns in language alone We first contribute a new challenge benchmark for comparing humans and distributional large language models (LLMs). Our benchmark contains two problem45;solving domains (planning and explanation generation) and is designed to require generalization to new out45;of45;distribution problems expressed in language. We find that humans are far more robust than LLMs on this benchmark. Next we propose a hybrid Parse45;and45;Solve model which augments distributional LLMs with a structured symbolic reasoning module. We find that this model shows more robust adaptation to out45;of45;distribution planning problems demonstrating the promise of hybrid AI models for more human45;like reasoning.

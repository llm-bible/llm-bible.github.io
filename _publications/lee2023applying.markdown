---
layout: publication
title: Applying Large Language Models And Chain45;of45;thought For Automatic Scoring
authors: Lee Gyeong-geon, Latif Ehsan, Wu Xuansheng, Liu Ninghao, Zhai Xiaoming
conference: "Arxiv"
year: 2023
bibkey: lee2023applying
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2312.03748"}
tags: ['GPT', 'Interpretability And Explainability', 'Model Architecture', 'Prompting', 'Reinforcement Learning', 'Tools']
---
This study investigates the application of large language models (LLMs) specifically GPT45;3.5 and GPT45;4 with Chain45;of45;Though (CoT) in the automatic scoring of student45;written responses to science assessments. We focused on overcoming the challenges of accessibility technical complexity and lack of explainability that have previously limited the use of artificial intelligence45;based automatic scoring tools among researchers and educators. With a testing dataset comprising six assessment tasks (three binomial and three trinomial) with 1650 student responses we employed six prompt engineering strategies to automatically score student responses. The six strategies combined zero45;shot or few45;shot learning with CoT either alone or alongside item stem and scoring rubrics. Results indicated that few45;shot (acc = .67) outperformed zero45;shot learning (acc = .60) with 12.637; increase. CoT when used without item stem and scoring rubrics did not significantly affect scoring accuracy (acc = .60). However CoT prompting paired with contextual item stems and rubrics proved to be a significant contributor to scoring accuracy (13.4437; increase for zero45;shot; 3.737; increase for few45;shot). We found a more balanced accuracy across different proficiency categories when CoT was used with a scoring rubric highlighting the importance of domain45;specific reasoning in enhancing the effectiveness of LLMs in scoring tasks. We also found that GPT45;4 demonstrated superior performance over GPT 45;3.5 in various scoring tasks when combined with the single45;call greedy sampling or ensemble voting nucleus sampling strategy showing 8.6437; difference. Particularly the single45;call greedy sampling strategy with GPT45;4 outperformed other approaches.

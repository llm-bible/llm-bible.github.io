---
layout: publication
title: AMBER An Llm45;free Multi45;dimensional Benchmark For Mllms Hallucination Evaluation
authors: Junyang Wang, Yuhang Wang, Guohai Xu, Jing Zhang, Yukai Gu, Haitao Jia, Jiaqi Wang, Haiyang Xu, Ming Yan, Ji Zhang, Jitao Sang
conference: "Arxiv"
year: 2023
bibkey: wang2023llm
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/http://arxiv.org/abs/2311.07397v2"}
  - {name: "Code", url: "https://github.com/junyangwang0410/AMBER"}
tags: ['GPT', 'Has Code', 'Model Architecture', 'Pretraining Methods']
---
Despite making significant progress in multi45;modal tasks current Multi45;modal Large Language Models (MLLMs) encounter the significant challenge of hallucinations which may lead to harmful consequences. Therefore evaluating MLLMs hallucinations is becoming increasingly important in model improvement and practical application deployment. Previous works are limited in high evaluation costs (e.g. relying on humans or advanced LLMs) and insufficient evaluation dimensions (e.g. types of tasks and hallucinations). In this paper we propose an LLM45;free multi45;dimensional benchmark AMBER which can be used to evaluate both generative task and discriminative task including existence attribute and relation hallucination. Based on AMBER we design a low45;cost and efficient evaluation pipeline. Additionally we conduct a comprehensive evaluation and detailed analysis of mainstream MLLMs including GPT45;4V(ision) and also give guideline suggestions for mitigating hallucinations. The data and code of AMBER are available at https://github.com/junyangwang0410/AMBER.

---
layout: publication
title: 'High-dimension Human Value Representation In Large Language Models'
authors: Samuel Cahyawijaya, Delong Chen, Yejin Bang, Leila Khalatbari, Bryan Wilie, Ziwei Ji, Etsuko Ishii, Pascale Fung
conference: "Arxiv"
year: 2024
bibkey: cahyawijaya2024high
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2404.07900'}
tags: ['Training Techniques', 'Language Modeling', 'Model Architecture']
---
The widespread application of LLMs across various tasks and fields has
necessitated the alignment of these models with human values and preferences.
Given various approaches of human value alignment, there is an urgent need to
understand the scope and nature of human values injected into these LLMs before
their deployment and adoption. We propose UniVaR, a high-dimensional neural
representation of symbolic human value distributions in LLMs, orthogonal to
model architecture and training data. This is a continuous and scalable
representation, self-supervised from the value-relevant output of 8 LLMs and
evaluated on 15 open-source and commercial LLMs. Through UniVaR, we visualize
and explore how LLMs prioritize different values in 25 languages and cultures,
shedding light on complex interplay between human values and language modeling.

---
layout: publication
title: Knowhalu Hallucination Detection Via Multi45;form Knowledge Based Factual Checking
authors: Zhang Jiawei, Xu Chejian, Gai Yu, Lecue Freddy, Song Dawn, Li Bo
conference: "Arxiv"
year: 2024
bibkey: zhang2024hallucination
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2404.02935"}
tags: ['Applications', 'Efficiency And Optimization', 'Merging', 'RAG']
---
This paper introduces KnowHalu a novel approach for detecting hallucinations in text generated by large language models (LLMs) utilizing step45;wise reasoning multi45;formulation query multi45;form knowledge for factual checking and fusion45;based detection mechanism. As LLMs are increasingly applied across various domains ensuring that their outputs are not hallucinated is critical. Recognizing the limitations of existing approaches that either rely on the self45;consistency check of LLMs or perform post45;hoc fact45;checking without considering the complexity of queries or the form of knowledge KnowHalu proposes a two45;phase process for hallucination detection. In the first phase it identifies non45;fabrication hallucinations45;45;responses that while factually correct are irrelevant or non45;specific to the query. The second phase multi45;form based factual checking contains five key steps reasoning and query decomposition knowledge retrieval knowledge optimization judgment generation and judgment aggregation. Our extensive evaluations demonstrate that KnowHalu significantly outperforms SOTA baselines in detecting hallucinations across diverse tasks e.g. improving by 15.6537; in QA tasks and 5.5037; in summarization tasks highlighting its effectiveness and versatility in detecting hallucinations in LLM45;generated content.

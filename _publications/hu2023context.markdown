---
layout: publication
title: Context45;aware Prompt Tuning For Vision45;language Model With Dual45;alignment
authors: Hu Hongyu, Lin Tiancheng, Wang Jie, Sun Zhenbang, Xu Yi
conference: "Arxiv"
year: 2023
bibkey: hu2023context
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2309.04158"}
tags: ['Ethics And Bias', 'GPT', 'Model Architecture', 'Prompting', 'RAG', 'Reinforcement Learning', 'Training Techniques']
---
Large45;scale vision45;language models (VLMs) e.g. CLIP learn broad visual concepts from tedious training data showing superb generalization ability. Amount of prompt learning methods have been proposed to efficiently adapt the VLMs to downstream tasks with only a few training samples. We introduce a novel method to improve the prompt learning of vision45;language models by incorporating pre45;trained large language models (LLMs) called Dual45;Aligned Prompt Tuning (DuAl45;PT). Learnable prompts like CoOp implicitly model the context through end45;to45;end training which are difficult to control and interpret. While explicit context descriptions generated by LLMs like GPT45;3 can be directly used for zero45;shot classification such prompts are overly relying on LLMs and still underexplored in few45;shot domains. With DuAl45;PT we propose to learn more context45;aware prompts benefiting from both explicit and implicit context modeling. To achieve this we introduce a pre45;trained LLM to generate context descriptions and we encourage the prompts to learn from the LLMs knowledge by alignment as well as the alignment between prompts and local image features. Empirically DuAl45;PT achieves superior performance on 11 downstream datasets on few45;shot recognition and base45;to45;new generalization. Hopefully DuAl45;PT can serve as a strong baseline. Code will be available.

---
layout: publication
title: Machine Unlearning Of Pre45;trained Large Language Models
authors: Yao Jin, Chien Eli, Du Minxin, Niu Xinyao, Wang Tianhao, Cheng Zezhou, Yue Xiang
conference: "Arxiv"
year: 2024
bibkey: yao2024machine
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2402.15159"}
tags: ['Ethics And Bias', 'Pretraining Methods', 'Responsible AI', 'Security', 'Tools', 'Training Techniques']
---
This study investigates the concept of the right to be forgotten within the context of large language models (LLMs). We explore machine unlearning as a pivotal solution with a focus on pre45;trained models45;45;a notably under45;researched area. Our research delineates a comprehensive framework for machine unlearning in pre45;trained LLMs encompassing a critical analysis of seven diverse unlearning methods. Through rigorous evaluation using curated datasets from arXiv books and GitHub we establish a robust benchmark for unlearning performance demonstrating that these methods are over 10^5 times more computationally efficient than retraining. Our results show that integrating gradient ascent with gradient descent on in45;distribution data improves hyperparameter robustness. We also provide detailed guidelines for efficient hyperparameter tuning in the unlearning process. Our findings advance the discourse on ethical AI practices offering substantive insights into the mechanics of machine unlearning for pre45;trained LLMs and underscoring the potential for responsible AI development.

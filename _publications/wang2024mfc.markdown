---
layout: publication
title: Mfc45;bench Benchmarking Multimodal Fact45;checking With Large Vision45;language Models
authors: Wang Shengkang, Lin Hongzhan, Luo Ziyang, Ye Zhen, Chen Guang, Ma Jing
conference: "Arxiv"
year: 2024
bibkey: wang2024mfc
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2406.11288"}
  - {name: "Code", url: "https://github.com/wskbest/MFC&#45;Bench,"}
tags: ['Applications', 'Attention Mechanism', 'Ethics And Bias', 'Has Code', 'Model Architecture', 'Multimodal Models']
---
Large vision45;language models (LVLMs) have significantly improved multimodal reasoning tasks such as visual question answering and image captioning. These models embed multimodal facts within their parameters rather than relying on external knowledge bases to store factual information explicitly. However the content discerned by LVLMs may deviate from actual facts due to inherent bias or incorrect inference. To address this issue we introduce MFC45;Bench a rigorous and comprehensive benchmark designed to evaluate the factual accuracy of LVLMs across three tasks Manipulation Out45;of45;Context and Veracity Classification. Through our evaluation on MFC45;Bench we benchmarked 12 diverse and representative LVLMs uncovering that current models still fall short in multimodal fact45;checking and demonstrate insensitivity to various forms of manipulated content. We hope that MFC45;Bench could raise attention to the trustworthy artificial intelligence potentially assisted by LVLMs in the future. The MFC45;Bench and accompanying resources are publicly accessible at https://github.com/wskbest/MFC&#45;Bench, contributing to ongoing research in the multimodal fact45;checking field.

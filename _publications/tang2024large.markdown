---
layout: publication
title: 'Large Language Models For Automated Literature Review: An Evaluation Of Reference Generation, Abstract Writing, And Review Composition'
authors: Xuemei Tang, Xufeng Duan, Zhenguang G. Cai
conference: "Arxiv"
year: 2024
bibkey: tang2024large
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2412.13612"}
tags: ['RAG', 'Tools', 'Survey Paper', 'Applications']
---
Large language models (LLMs) have emerged as a potential solution to automate
the complex processes involved in writing literature reviews, such as
literature collection, organization, and summarization. However, it is yet
unclear how good LLMs are at automating comprehensive and reliable literature
reviews. This study introduces a framework to automatically evaluate the
performance of LLMs in three key tasks of literature writing: reference
generation, literature summary, and literature review composition. We introduce
multidimensional evaluation metrics that assess the hallucination rates in
generated references and measure the semantic coverage and factual consistency
of the literature summaries and compositions against human-written
counterparts. The experimental results reveal that even the most advanced
models still generate hallucinated references, despite recent progress.
Moreover, we observe that the performance of different models varies across
disciplines when it comes to writing literature reviews. These findings
highlight the need for further research and development to improve the
reliability of LLMs in automating academic literature reviews.

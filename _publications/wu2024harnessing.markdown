---
layout: publication
title: 'Strago: Harnessing Strategic Guidance For Prompt Optimization'
authors: Yurong Wu, Yan Gao, Bin Benjamin Zhu, Zineng Zhou, Xiaodi Sun, Sheng Yang, Jian-guang Lou, Zhiming Ding, Linjun Yang
conference: "Arxiv"
year: 2024
bibkey: wu2024harnessing
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2410.08601"}
tags: ['Efficiency and Optimization', 'Applications', 'RAG', 'Prompting', 'In-Context Learning']
---
Prompt engineering is pivotal for harnessing the capabilities of large
language models (LLMs) across diverse applications. While existing prompt
optimization methods improve prompt effectiveness, they often lead to prompt
drifting, where newly generated prompts can adversely impact previously
successful cases while addressing failures. Furthermore, these methods tend to
rely heavily on LLMs' intrinsic capabilities for prompt optimization tasks. In
this paper, we introduce StraGo (Strategic-Guided Optimization), a novel
approach designed to mitigate prompt drifting by leveraging insights from both
successful and failed cases to identify critical factors for achieving
optimization objectives. StraGo employs a how-to-do methodology, integrating
in-context learning to formulate specific, actionable strategies that provide
detailed, step-by-step guidance for prompt optimization. Extensive experiments
conducted across a range of tasks, including reasoning, natural language
understanding, domain-specific knowledge, and industrial applications,
demonstrate StraGo's superior performance. It establishes a new
state-of-the-art in prompt optimization, showcasing its ability to deliver
stable and effective prompt improvements.

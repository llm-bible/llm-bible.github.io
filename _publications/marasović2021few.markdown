---
layout: publication
title: Few45;shot Self45;rationalization With Natural Language Prompts
authors: Marasović Ana, Beltagy Iz, Downey Doug, Peters Matthew E.
conference: "Arxiv"
year: 2021
bibkey: marasović2021few
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2111.08284"}
tags: ['Ethics And Bias', 'GPT', 'Interpretability And Explainability', 'Model Architecture', 'Prompting', 'RAG', 'Training Techniques']
---
Self45;rationalization models that predict task labels and generate free45;text elaborations for their predictions could enable more intuitive interaction with NLP systems. These models are however currently trained with a large amount of human45;written free45;text explanations for each task which hinders their broader usage. We propose to study a more realistic setting of self45;rationalization using few training examples. We present FEB 45;45; a standardized collection of four existing English45;language datasets and associated metrics. We identify the right prompting approach by extensively exploring natural language prompts on FEB. Then by using this prompt and scaling the model size we demonstrate that making progress on few45;shot self45;rationalization is possible. We show there is still ample room for improvement in this task the average plausibility of generated explanations assessed by human annotators is at most 5137; (with GPT45;3) while plausibility of human explanations is 7637;. We hope that FEB and our proposed approach will spur the community to take on the few45;shot self45;rationalization challenge.

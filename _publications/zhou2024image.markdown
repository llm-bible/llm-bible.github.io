---
layout: publication
title: Image45;of45;thought Prompting For Visual Reasoning Refinement In Multimodal Large Language Models
authors: Zhou Qiji, Zhou Ruochen, Hu Zike, Lu Panzhong, Gao Siyang, Zhang Yue
conference: "Arxiv"
year: 2024
bibkey: zhou2024image
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2405.13872"}
tags: ['Interpretability And Explainability', 'Multimodal Models', 'Prompting', 'Reinforcement Learning']
---
Recent advancements in Chain45;of45;Thought (CoT) and related rationale45;based works have significantly improved the performance of Large Language Models (LLMs) in complex reasoning tasks. With the evolution of Multimodal Large Language Models (MLLMs) enhancing their capability to tackle complex multimodal reasoning problems is a crucial frontier. However incorporating multimodal rationales in CoT has yet to be thoroughly investigated. We propose the Image45;of45;Thought (IoT) prompting method which helps MLLMs to extract visual rationales step45;by45;step. Specifically IoT prompting can automatically design critical visual information extraction operations based on the input images and questions. Each step of visual information refinement identifies specific visual rationales that support answers to complex visual reasoning questions. Beyond the textual CoT IoT simultaneously utilizes visual and textual rationales to help MLLMs understand complex multimodal information. IoT prompting has improved zero45;shot visual reasoning performance across various visual understanding tasks in different MLLMs. Moreover the step45;by45;step visual feature explanations generated by IoT prompting elucidate the visual reasoning process aiding in analyzing the cognitive processes of large multimodal models

---
layout: publication
title: Llm-japanese-dataset V0&#58; Construction Of Japanese Chat Dataset For Large Language Models And Its Methodology
authors: Hirano Masanori, Suzuki Masahiro, Sakaji Hiroki
conference: "Arxiv"
year: 2023
bibkey: hirano2023llm
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2305.12720"}
tags: ['Pretraining Methods', 'Reinforcement Learning', 'Training Techniques']
---
This study constructed a Japanese chat dataset for tuning large language models (LLMs) which consist of about 8.4 million records. Recently LLMs have been developed and gaining popularity. However high-performing LLMs are usually mainly for English. There are two ways to support languages other than English by those LLMs constructing LLMs from scratch or tuning existing models. However in both ways datasets are necessary parts. In this study we focused on supporting Japanese in those LLMs and making a dataset for training or tuning LLMs in Japanese. The dataset we constructed consisted of various tasks such as translation and knowledge tasks. In our experiment we tuned an existing LLM using our dataset and evaluated the performance qualitatively. The results suggest that our dataset is possibly beneficial for LLMs. However we also revealed some difficulties in constructing LLMs in languages other than English.

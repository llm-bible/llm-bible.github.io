---
layout: publication
title: 'Exploring React Prompting For Task-oriented Dialogue: Insights And Shortcomings'
authors: Michelle Elizabeth, Morgan Veyret, Miguel Couceiro, Ondrej Dusek, Lina M. Rojas-barahona
conference: "Arxiv"
year: 2024
bibkey: elizabeth2024exploring
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2412.01262"}
tags: ['Prompting', 'Agentic', 'Reinforcement Learning']
---
Large language models (LLMs) gained immense popularity due to their
impressive capabilities in unstructured conversations. Empowering LLMs with
advanced prompting strategies such as reasoning and acting (ReAct) (Yao et al.,
2022) has shown promise in solving complex tasks traditionally requiring
reinforcement learning. In this work, we apply the ReAct strategy to guide LLMs
performing task-oriented dialogue (TOD). We evaluate ReAct-based LLMs
(ReAct-LLMs) both in simulation and with real users. While ReAct-LLMs severely
underperform state-of-the-art approaches on success rate in simulation, this
difference becomes less pronounced in human evaluation. Moreover, compared to
the baseline, humans report higher subjective satisfaction with ReAct-LLM
despite its lower success rate, most likely thanks to its natural and
confidently phrased responses.

---
layout: publication
title: COSMO Contrastive Streamlined Multimodal Model With Interleaved Pre45;training
authors: Wang Alex Jinpeng, Li Linjie, Lin Kevin Qinghong, Wang Jianfeng, Lin Kevin, Yang Zhengyuan, Wang Lijuan, Shou Mike Zheng
conference: "Arxiv"
year: 2024
bibkey: wang2024contrastive
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2401.00849"}
tags: ['Applications', 'GPT', 'Language Modeling', 'Multimodal Models', 'Pretraining Methods', 'RAG', 'Reinforcement Learning', 'Tools', 'Training Techniques']
---
In the evolution of Vision45;Language Pre45;training shifting from short45;text comprehension to encompassing extended textual contexts is pivotal. Recent autoregressive vision45;language models like cite123;flamingo palme125; leveraging the long45;context capability of Large Language Models have excelled in few45;shot text generation tasks but face challenges in alignment tasks. Addressing this gap we introduce the contrastive loss into text generation models presenting the COntrastive45;Streamlined MultimOdal framework (ModelName) strategically partitioning the language model into dedicated unimodal text processing and adept multimodal data handling components. ModelName our unified framework merges unimodal and multimodal elements enhancing model performance for tasks involving textual and visual data while notably reducing learnable parameters. However these models demand extensive long45;text datasets yet the availability of high45;quality long45;text video datasets remains limited. To bridge this gap this work introduces VideoDatasetName an inaugural interleaved video45;text dataset featuring comprehensive captions marking a significant step forward. Demonstrating its impact we illustrate how VideoDatasetName123;125; enhances model performance in image45;text tasks. With 3437; learnable parameters and utilizing 7237; of the available data our model demonstrates significant superiority over OpenFlamingo~cite123;openflamingo125;. For instance in the 445;shot flickr captioning task performance notably improves from 57.237; to 65.37;. The contributions of ModelName123;125; and VideoDatasetName123;125; are underscored by notable performance gains across 14 diverse downstream datasets encompassing both image45;text and video45;text tasks.

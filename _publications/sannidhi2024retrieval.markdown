---
layout: publication
title: 'Retrieval-augmented Generation Meets Data-driven Tabula Rasa Approach For Temporal Knowledge Graph Forecasting'
authors: Sannidhi Geethan, Sakhinana Sagar Srinivas, Runkana Venkataramana
conference: "Arxiv"
year: 2024
bibkey: sannidhi2024retrieval
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2408.13273"}
tags: ['Applications', 'Ethics And Bias', 'GPT', 'Model Architecture', 'Prompting', 'RAG', 'Security', 'Tools']
---
Pre-trained large language models (PLLMs) like OpenAI ChatGPT and Google Gemini face challenges such as inaccurate factual recall hallucinations biases and future data leakage for temporal Knowledge Graph (tKG) forecasting. To address these issues we introduce sLA-tKGF (small-scale language assistant for tKG forecasting) which utilizes Retrieval-Augmented Generation (RAG) aided custom-trained small-scale language models through a tabula rasa approach from scratch for effective tKG forecasting. Our framework constructs knowledge-infused prompts with relevant historical data from tKGs web search results and PLLMs-generated textual descriptions to understand historical entity relationships prior to the target time. It leverages these external knowledge-infused prompts for deeper understanding and reasoning of context-specific semantic and temporal information to zero-shot prompt small-scale language models for more accurate predictions of future events within tKGs. It reduces hallucinations and mitigates distributional shift challenges through comprehending changing trends over time. As a result it enables more accurate and contextually grounded forecasts of future events while minimizing computational demands. Rigorous empirical studies demonstrate our framework robustness scalability and state-of-the-art (SOTA) performance on benchmark datasets with interpretable and trustworthy tKG forecasting.

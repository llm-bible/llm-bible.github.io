---
layout: publication
title: 'Why Representation Engineering Works: A Theoretical And Empirical Study In Vision-language Models'
authors: Bowei Tian, Xuntao Lyu, Meng Liu, Hongyi Wang, Ang Li
conference: "Arxiv"
year: 2025
bibkey: tian2025why
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2503.22720"}
tags: ['Tools', 'Applications', 'Ethics and Bias', 'Interpretability and Explainability', 'Bias Mitigation', 'Reinforcement Learning', 'Interpretability', 'Fairness', 'Security', 'Multimodal Models']
---
Representation Engineering (RepE) has emerged as a powerful paradigm for
enhancing AI transparency by focusing on high-level representations rather than
individual neurons or circuits. It has proven effective in improving
interpretability and control, showing that representations can emerge,
propagate, and shape final model outputs in large language models (LLMs).
However, in Vision-Language Models (VLMs), visual input can override factual
linguistic knowledge, leading to hallucinated responses that contradict
reality. To address this challenge, we make the first attempt to extend RepE to
VLMs, analyzing how multimodal representations are preserved and transformed.
Building on our findings and drawing inspiration from successful RepE
applications, we develop a theoretical framework that explains the stability of
neural activity across layers using the principal eigenvector, uncovering the
underlying mechanism of RepE. We empirically validate these instrinsic
properties, demonstrating their broad applicability and significance. By
bridging theoretical insights with empirical validation, this work transforms
RepE from a descriptive tool into a structured theoretical framework, opening
new directions for improving AI robustness, fairness, and transparency.

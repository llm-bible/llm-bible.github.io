---
layout: publication
title: 'Dataset Cartography For Large Language Model Alignment: Mapping And Diagnosing Preference Data'
authors: Seohyeong Lee, Eunwon Kim, Hwaran Lee, Buru Chang
conference: "Arxiv"
year: 2025
bibkey: lee2025dataset
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2505.23114"}
tags: ['Efficiency and Optimization', 'Model Architecture', 'GPT', 'Reinforcement Learning']
---
Human preference data plays a critical role in aligning large language models (LLMs) with human values. However, collecting such data is often expensive and inefficient, posing a significant scalability challenge. To address this, we introduce Alignment Data Map, a GPT-4o-assisted tool for analyzing and diagnosing preference data. Using GPT-4o as a proxy for LLM alignment, we compute alignment scores for LLM-generated responses to instructions from existing preference datasets. These scores are then used to construct an Alignment Data Map based on their mean and variance. Our experiments show that using only 33 percent of the data, specifically samples in the high-mean, low-variance region, achieves performance comparable to or better than using the entire dataset. This finding suggests that the Alignment Data Map can significantly improve data collection efficiency by identifying high-quality samples for LLM alignment without requiring explicit annotations. Moreover, the Alignment Data Map can diagnose existing preference datasets. Our analysis shows that it effectively detects low-impact or potentially misannotated samples. Source code is available online.

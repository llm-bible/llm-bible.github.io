---
layout: publication
title: Cognitive Modeling With Scaffolded Llms A Case Study Of Referential Expression Generation
authors: Tsvilodub Polina, Franke Michael, Carcassi Fausto
conference: "Arxiv"
year: 2024
bibkey: tsvilodub2024cognitive
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2407.03805"}
tags: ['Applications', 'GPT', 'Model Architecture']
---
To what extent can LLMs be used as part of a cognitive model of language generation In this paper we approach this question by exploring a neuro45;symbolic implementation of an algorithmic cognitive model of referential expression generation by Dale amp; Reiter (1995). The symbolic task analysis implements the generation as an iterative procedure that scaffolds symbolic and gpt45;3.545;turbo45;based modules. We compare this implementation to an ablated model and a one45;shot LLM45;only baseline on the A3DS dataset (Tsvilodub amp; Franke 2023). We find that our hybrid approach is cognitively plausible and performs well in complex contexts while allowing for more open45;ended modeling of language generation in a larger domain.

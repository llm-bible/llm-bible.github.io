---
layout: publication
title: Evaluating Large Language Models On A Highly45;specialized Topic Radiation Oncology Physics
authors: Holmes Jason, Liu Zhengliang, Zhang Lian, Ding Yuzhen, Sio Terence T., Mcgee Lisa A., Ashman Jonathan B., Li Xiang, Liu Tianming, Shen Jiajian, Liu Wei
conference: "Arxiv"
year: 2023
bibkey: holmes2023evaluating
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2304.01938"}
tags: ['GPT', 'Model Architecture', 'Pretraining Methods', 'Prompting', 'RAG']
---
We present the first study to investigate Large Language Models (LLMs) in answering radiation oncology physics questions. Because popular exams like AP Physics LSAT and GRE have large test45;taker populations and ample test preparation resources in circulation they may not allow for accurately assessing the true potential of LLMs. This paper proposes evaluating LLMs on a highly45;specialized topic radiation oncology physics which may be more pertinent to scientific and medical communities in addition to being a valuable benchmark of LLMs. We developed an exam consisting of 100 radiation oncology physics questions based on our expertise at Mayo Clinic. Four LLMs ChatGPT (GPT45;3.5) ChatGPT (GPT45;4) Bard (LaMDA) and BLOOMZ were evaluated against medical physicists and non45;experts. ChatGPT (GPT45;4) outperformed all other LLMs as well as medical physicists on average. The performance of ChatGPT (GPT45;4) was further improved when prompted to explain first then answer. ChatGPT (GPT45;3.5 and GPT45;4) showed a high level of consistency in its answer choices across a number of trials whether correct or incorrect a characteristic that was not observed in the human test groups. In evaluating ChatGPTs (GPT45;4) deductive reasoning ability using a novel approach (substituting the correct answer with None of the above choices is the correct answer.) ChatGPT (GPT45;4) demonstrated surprising accuracy suggesting the potential presence of an emergent ability. Finally although ChatGPT (GPT45;4) performed well overall its intrinsic properties did not allow for further improvement when scoring based on a majority vote across trials. In contrast a team of medical physicists were able to greatly outperform ChatGPT (GPT45;4) using a majority vote. This study suggests a great potential for LLMs to work alongside radiation oncology experts as highly knowledgeable assistants.

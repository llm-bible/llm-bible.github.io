---
layout: publication
title: 'Thinking With Knowledge Graphs: Enhancing LLM Reasoning Through Structured Data'
authors: Xue Wu, Kostas Tsioutsiouliklis
conference: "Arxiv"
year: 2024
bibkey: wu2024thinking
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2412.10654"}
tags: ['RAG', 'Applications']
---
Large Language Models (LLMs) have demonstrated remarkable capabilities in
natural language understanding and generation. However, they often struggle
with complex reasoning tasks and are prone to hallucination. Recent research
has shown promising results in leveraging knowledge graphs (KGs) to enhance LLM
performance. KGs provide a structured representation of entities and their
relationships, offering a rich source of information that can enhance the
reasoning capabilities of LLMs. For this work, we have developed different
techniques that tightly integrate KG structures and semantics into LLM
representations. Our results show that we are able to significantly improve the
performance of LLMs in complex reasoning scenarios, and ground the reasoning
process with KGs. We are the first to represent KGs with programming language
and fine-tune pretrained LLMs with KGs. This integration facilitates more
accurate and interpretable reasoning processes, paving the way for more
advanced reasoning capabilities of LLMs.

---
layout: publication
title: 'Friend Or Foe? Exploring The Implications Of Large Language Models On The Science System'
authors: Benedikt Fecher, Marcel Hebing, Melissa Laufer, JÃ¶rg Pohle, Fabian Sofsky
conference: "Arxiv"
year: 2023
citations: 32
bibkey: fecher2023friend
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2306.09928'}
tags: ['GPT', 'Applications', 'Model Architecture', 'Prompting', 'Reinforcement Learning', 'Ethics and Bias']
---
The advent of ChatGPT by OpenAI has prompted extensive discourse on its
potential implications for science and higher education. While the impact on
education has been a primary focus, there is limited empirical research on the
effects of large language models (LLMs) and LLM-based chatbots on science and
scientific practice. To investigate this further, we conducted a Delphi study
involving 72 experts specialising in research and AI. The study focused on
applications and limitations of LLMs, their effects on the science system,
ethical and legal considerations, and the required competencies for their
effective use. Our findings highlight the transformative potential of LLMs in
science, particularly in administrative, creative, and analytical tasks.
However, risks related to bias, misinformation, and quality assurance need to
be addressed through proactive regulation and science education. This research
contributes to informed discussions on the impact of generative AI in science
and helps identify areas for future action.

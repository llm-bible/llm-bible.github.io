---
layout: publication
title: 'Gemma: Open Models Based On Gemini Research And Technology'
authors: Gemma Team et al.
conference: "Arxiv"
year: 2024
citations: 83
bibkey: gemmateam2024open
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2403.08295'}
tags: ['Reinforcement Learning', 'Responsible AI']
---
This work introduces Gemma, a family of lightweight, state-of-the art open
models built from the research and technology used to create Gemini models.
Gemma models demonstrate strong performance across academic benchmarks for
language understanding, reasoning, and safety. We release two sizes of models
(2 billion and 7 billion parameters), and provide both pretrained and
fine-tuned checkpoints. Gemma outperforms similarly sized open models on 11 out
of 18 text-based tasks, and we present comprehensive evaluations of safety and
responsibility aspects of the models, alongside a detailed description of model
development. We believe the responsible release of LLMs is critical for
improving the safety of frontier models, and for enabling the next wave of LLM
innovations.

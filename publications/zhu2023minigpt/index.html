<!DOCTYPE html>
<html lang="en-us">

  <head>
  <!-- Begin Web-Stat code v 7.0 -->
  <span id="wts2185292"></span>
  <script>
    var wts = document.createElement('script');
    wts.async = true;
    wts.src = 'https://app.ardalio.com/log7.js';
    document.head.appendChild(wts);
    wts.onload = function() {
      wtslog7(2185292, 2);
    };
  </script>
  <noscript>
    <a href="https://www.web-stat.com">
      <img src="https://app.ardalio.com/7/2/2185292.png" alt="Web-Stat analytics">
    </a>
  </noscript>
  <!-- End Web-Stat code v 7.0 -->

  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta
    name="keywords"
    content="large language models, GPT, transformers, BERT, natural language processing, NLP, deep learning, machine learning, source code, big code, naturalness, software engineering, programming languages, fine-tuning, pretraining, autoregressive models, attention mechanisms, multi-modal models, text generation, reinforcement learning with human feedback, RLHF, GPT-3, GPT-4, ChatGPT, OpenAI, model architectures, transfer learning, LLM applications, LLM benchmarks, LLM interpretability"
  >
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [["\\(","\\)"]],
        displayMath: [["\\[","\\]"]],
      },
      options: {
        processHtmlClass: "mathjax-content",
        processEscapes: true,
      }
    };
  </script>
  <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <title>
    
      Minigpt-4: Enhancing Vision-language Understanding With Advanced Large Language Models &middot; The Large Language Model Bible
    
  </title>

  <!-- Enable responsiveness on mobile devices -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link
    rel="stylesheet"
    href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface"
  >

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link
    rel="search"
    href="/public/opensearchdescription.xml"
    type="application/opensearchdescription+xml"
    title="LLM-Bible"
  />

  <!-- jQuery Library -->
  <script
    src="https://code.jquery.com/jquery-3.2.1.min.js"
    integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
    crossorigin="anonymous"
  ></script>

  <!-- DataTables CSS -->
  <link
    rel="stylesheet"
    type="text/css"
    href="https://cdn.datatables.net/1.10.20/css/jquery.dataTables.css"
  >

  <!-- DataTables JS -->
  <script
    type="text/javascript"
    charset="utf8"
    src="https://cdn.datatables.net/1.10.20/js/jquery.dataTables.js"
  ></script>
</head>


  <body class="theme-base-0d layout-reverse">

    <a href='/contributing.html' class='ribbon'>Contribute to LLM-Bible</a>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          The Large Language Model Bible
        </a>
      </h1>
      <p class="lead">Research on Large Language Models. Maintained by <a href="http://sjmoran.github.io/">Sean Moran</a>.</p>      
    </div>

    <nav class="sidebar-nav">
      <div class="sidebar-item">
        <p style="font-size: 12px">Search related work 
          <input type='text' id='searchTarget' size="16"/> 
          <button onClick="search();">Go</button>
        </p>
      </div>
      <a class="sidebar-nav-item" href="/papers.html">List of Papers</a>
      <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
      <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
      <a class="sidebar-nav-item" href="/topic-viz.html">Topic-based Explorer</a>
      <a class="sidebar-nav-item" href="/chatbot.html">Chatbot-based Explorer</a>
      <a class="sidebar-nav-item" href="/resources.html">Resources, Courses & Events</a>
      <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
    </nav>

    <div class="sidebar-item">
      <p style="font-size: 12px">Contact <a href="https://sjmoran.github.io">Sean Moran</a> about this survey or website.
      <span style="font-size: 9px">
        Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
      </span></p>
    </div>
  </div>
</div>

<script>
  // Initiate search when 'Enter' is pressed in the search input
  $("#searchTarget").keydown(function (e) {	
    if (e.keyCode == 13) {
      search();
    }
  });

  function search() {
    var query = $("#searchTarget").val();
    try {
      ga('send', 'event', 'search', 'search', query);  // Google Analytics event tracking
    } finally {
      // Redirect to papers.html with the query as a hash
      window.location = "/papers.html#" + encodeURIComponent(query);
    }
  }
</script>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">Minigpt-4: Enhancing Vision-language Understanding With Advanced Large Language Models</h1>
  <h5>
  Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, Mohamed Elhoseiny. Arxiv 2023
  
    – <span>351 citations</span>
  
  </h5>
  <p>
    
      [<a href="http://arxiv.org/abs/2304.10592v2" target="_blank">Paper</a>]
    
      [<a href="https://minigpt-4.github.io/" target="_blank">Code</a>]
    
    &nbsp;<a href='http://scholar.google.com/scholar?q=Minigpt-4: Enhancing Vision-language Understanding With Advanced Large Language Models' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
    &nbsp;<a href='https://www.semanticscholar.org/search?q=Minigpt-4: Enhancing Vision-language Understanding With Advanced Large Language Models' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
    <br/>
    
      <tag><a href="/tags.html#GPT">GPT</a></tag>
    
      <tag><a href="/tags.html#RAG">RAG</a></tag>
    
      <tag><a href="/tags.html#Reinforcement Learning">Reinforcement Learning</a></tag>
    
      <tag><a href="/tags.html#Multimodal Models">Multimodal Models</a></tag>
    
      <tag><a href="/tags.html#Fine-Tuning">Fine-Tuning</a></tag>
    
  </p>
  <p><p>The recent GPT-4 has demonstrated extraordinary multi-modal abilities, such
as directly generating websites from handwritten text and identifying humorous
elements within images. These features are rarely observed in previous
vision-language models. However, the technical details behind GPT-4 continue to
remain undisclosed. We believe that the enhanced multi-modal generation
capabilities of GPT-4 stem from the utilization of sophisticated large language
models (LLM). To examine this phenomenon, we present MiniGPT-4, which aligns a
frozen visual encoder with a frozen advanced LLM, Vicuna, using one projection
layer. Our work, for the first time, uncovers that properly aligning the visual
features with an advanced large language model can possess numerous advanced
multi-modal abilities demonstrated by GPT-4, such as detailed image description
generation and website creation from hand-drawn drafts. Furthermore, we also
observe other emerging capabilities in MiniGPT-4, including writing stories and
poems inspired by given images, teaching users how to cook based on food
photos, and so on. In our experiment, we found that the model trained on short
image caption pairs could produce unnatural language outputs (e.g., repetition
and fragmentation). To address this problem, we curate a detailed image
description dataset in the second stage to finetune the model, which
consequently improves the model’s generation reliability and overall usability.
Our code, pre-trained model, and collected dataset are available at
https://minigpt-4.github.io/.</p>
</p>

  <h6>Similar Work</h6>
  <p>
    <ul id="relwork">

    </ul>
  </p>

 <script>  
    $(document).ready(
      function() {
        $.getJSON("/publications-metadata/zhu2023minigpt.json", function(data) {
          num_papers = data.length;
          html = "";
          for (let i=0; i < num_papers; i++) {
              html += '<li><a href="/publications/' + data[i][0] + '">'+ data[i][1] +'</a></li>'
          }
          $("#relwork").append(html);
        });
      });
  </script>


</div>

    </div>

    <!-- 
    <script>
      document.addEventListener('DOMContentLoaded', function () {
        let isBot = true;

        // Check for mouse movement or keyboard interaction
        document.addEventListener('mousemove', function () {
          isBot = false;
        });
        document.addEventListener('keydown', function () {
          isBot = false;
        });

        // Redirect or take action if no user interaction is detected
        setTimeout(function () {
          if (isBot) {
            // Redirect to a challenge page or show a message
            window.location.href = '/challenge-page.html'; // Update with your actual challenge page
          }
        }, 5000); // Adjust the time delay as needed
      });
    </script>
    -->
  </body>
</html>

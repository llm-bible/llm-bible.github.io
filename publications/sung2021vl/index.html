<!DOCTYPE html>
<html lang="en-us">

  <head>
  <!-- Begin Web-Stat code v 7.0 -->
  <span id="wts2185292"></span>
  <script>
    var wts = document.createElement('script');
    wts.async = true;
    wts.src = 'https://app.ardalio.com/log7.js';
    document.head.appendChild(wts);
    wts.onload = function() {
      wtslog7(2185292, 2);
    };
  </script>
  <noscript>
    <a href="https://www.web-stat.com">
      <img src="https://app.ardalio.com/7/2/2185292.png" alt="Web-Stat analytics">
    </a>
  </noscript>
  <!-- End Web-Stat code v 7.0 -->

  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta
    name="keywords"
    content="large language models, GPT, transformers, BERT, natural language processing, NLP, deep learning, machine learning, source code, big code, naturalness, software engineering, programming languages, fine-tuning, pretraining, autoregressive models, attention mechanisms, multi-modal models, text generation, reinforcement learning with human feedback, RLHF, GPT-3, GPT-4, ChatGPT, OpenAI, model architectures, transfer learning, LLM applications, LLM benchmarks, LLM interpretability"
  >
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [["\\(","\\)"]],
        displayMath: [["\\[","\\]"]],
      },
      options: {
        processHtmlClass: "mathjax-content",
        processEscapes: true,
      }
    };
  </script>
  <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <title>
    
      Vl-adapter: Parameter-efficient Transfer Learning For Vision-and-language Tasks &middot; The Large Language Model Bible
    
  </title>

  <!-- Enable responsiveness on mobile devices -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link
    rel="stylesheet"
    href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface"
  >

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link
    rel="search"
    href="/public/opensearchdescription.xml"
    type="application/opensearchdescription+xml"
    title="LLM-Bible"
  />

  <!-- jQuery Library -->
  <script
    src="https://code.jquery.com/jquery-3.2.1.min.js"
    integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
    crossorigin="anonymous"
  ></script>

  <!-- DataTables CSS -->
  <link
    rel="stylesheet"
    type="text/css"
    href="https://cdn.datatables.net/1.10.20/css/jquery.dataTables.css"
  >

  <!-- DataTables JS -->
  <script
    type="text/javascript"
    charset="utf8"
    src="https://cdn.datatables.net/1.10.20/js/jquery.dataTables.js"
  ></script>
</head>


  <body class="theme-base-0d layout-reverse">

    <a href='/contributing.html' class='ribbon'>Contribute to LLM-Bible</a>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          The Large Language Model Bible
        </a>
      </h1>
      <p class="lead">Research on Large Language Models. Maintained by <a href="http://sjmoran.github.io/">Sean Moran</a>.</p>      
    </div>

    <nav class="sidebar-nav">
      <div class="sidebar-item">
        <p style="font-size: 12px">Search related work 
          <input type='text' id='searchTarget' size="16"/> 
          <button onClick="search();">Go</button>
        </p>
      </div>
      <a class="sidebar-nav-item" href="/papers.html">List of Papers</a>
      <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
      <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
      <a class="sidebar-nav-item" href="/topic-viz.html">Topic-based Explorer</a>
      <a class="sidebar-nav-item" href="/chatbot.html">Chatbot-based Explorer</a>
      <a class="sidebar-nav-item" href="/resources.html">Resources, Courses & Events</a>
      <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
    </nav>

    <div class="sidebar-item">
      <p style="font-size: 12px">Contact <a href="https://sjmoran.github.io">Sean Moran</a> about this survey or website.
      <span style="font-size: 9px">
        Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
      </span></p>
    </div>
  </div>
</div>

<script>
  // Initiate search when 'Enter' is pressed in the search input
  $("#searchTarget").keydown(function (e) {	
    if (e.keyCode == 13) {
      search();
    }
  });

  function search() {
    var query = $("#searchTarget").val();
    try {
      ga('send', 'event', 'search', 'search', query);  // Google Analytics event tracking
    } finally {
      // Redirect to papers.html with the query as a hash
      window.location = "/papers.html#" + encodeURIComponent(query);
    }
  }
</script>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">Vl-adapter: Parameter-efficient Transfer Learning For Vision-and-language Tasks</h1>
  <h5>
  Yi-lin Sung, Jaemin Cho, Mohit Bansal. Arxiv 2021
  
    â€“ <span>160 citations</span>
  
  </h5>
  <p>
    
      [<a href="https://arxiv.org/abs/2112.06825" target="_blank">Paper</a>]
    
      [<a href="https://github.com/ylsung/VL_adapter" target="_blank">Code</a>]
    
    &nbsp;<a href='http://scholar.google.com/scholar?q=Vl-adapter: Parameter-efficient Transfer Learning For Vision-and-language Tasks' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
    &nbsp;<a href='https://www.semanticscholar.org/search?q=Vl-adapter: Parameter-efficient Transfer Learning For Vision-and-language Tasks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
    <br/>
    
      <tag><a href="/tags.html#Pre-Training">Pre-Training</a></tag>
    
      <tag><a href="/tags.html#Fine-Tuning">Fine-Tuning</a></tag>
    
      <tag><a href="/tags.html#Efficiency and Optimization">Efficiency and Optimization</a></tag>
    
      <tag><a href="/tags.html#Prompting">Prompting</a></tag>
    
  </p>
  <p><p>Recently, fine-tuning language models pre-trained on large text corpora have
provided huge improvements on vision-and-language (V&amp;L) tasks as well as on
pure language tasks. However, fine-tuning the entire parameter set of
pre-trained models becomes impractical since the model size is growing rapidly.
Hence, in this paper, we introduce adapter-based parameter-efficient transfer
learning techniques to V&amp;L models such as VL-BART and VLT5. We evaluate our
methods in a unified multi-task setup on both image-text and video-text
benchmarks. For the image-text tasks, we use four diverse V&amp;L datasets: VQAv2,
GQA, NLVR2 , and MSCOCO image captioning. For video-text tasks, we use TVQA,
How2QA, TVC, and YC2C. With careful training and thorough experiments, we
benchmark three popular adapter-based methods (Adapter, Hyperformer, Compacter)
against the standard full fine-tuning and the recently proposed prompt-tuning
approach. We also enhance the efficiency and performance of adapters by sharing
their weights to attain knowledge across tasks. Our results demonstrate that
training the adapter with the weight-sharing technique (4.18% of total
parameters for image-text tasks and 3.39% for video-text tasks) can match the
performance of fine-tuning the entire model. Lastly, we present a comprehensive
analysis including the combination of adapter and task-specific prompts and the
impact of V&amp;L pre-training on adapters. Our code is available at:
https://github.com/ylsung/VL_adapter.</p>
</p>

  <h6>Similar Work</h6>
  <p>
    <ul id="relwork">

    </ul>
  </p>

 <script>  
    $(document).ready(
      function() {
        $.getJSON("/publications-metadata/sung2021vl.json", function(data) {
          num_papers = data.length;
          html = "";
          for (let i=0; i < num_papers; i++) {
              html += '<li><a href="/publications/' + data[i][0] + '">'+ data[i][1] +'</a></li>'
          }
          $("#relwork").append(html);
        });
      });
  </script>


</div>

    </div>

    <!-- 
    <script>
      document.addEventListener('DOMContentLoaded', function () {
        let isBot = true;

        // Check for mouse movement or keyboard interaction
        document.addEventListener('mousemove', function () {
          isBot = false;
        });
        document.addEventListener('keydown', function () {
          isBot = false;
        });

        // Redirect or take action if no user interaction is detected
        setTimeout(function () {
          if (isBot) {
            // Redirect to a challenge page or show a message
            window.location.href = '/challenge-page.html'; // Update with your actual challenge page
          }
        }, 5000); // Adjust the time delay as needed
      });
    </script>
    -->
  </body>
</html>

[["huang2023survey", "A Survey On Hallucination In Large Language Models: Principles, Taxonomy, Challenges, And Open Questions"], ["carlini2023are", "Are Aligned Neural Networks Adversarially Aligned?"], ["si2020better", "Better Robustness By More Coverage: Adversarial Training With Mixup Augmentation For Robust Fine-tuning"], ["liu2020adversarial", "Adversarial Training For Large Neural Language Models"]]
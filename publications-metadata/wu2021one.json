[["wu2021distilling", "Newsbert: Distilling Pre-trained Language Model For Intelligent News Application"], ["lu2022ernie", "Ernie-search: Bridging Cross-encoder With Dual-encoder Via Self On-the-fly Distillation For Dense Passage Retrieval"], ["li2024unsupervised", "Promptkd: Unsupervised Prompt Distillation For Vision-language Models"], ["sun2020contrastive", "Contrastive Distillation On Intermediate Representations For Language Model Compression"]]
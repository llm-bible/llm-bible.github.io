[["eichenberg2021magma", "MAGMA -- Multimodal Augmentation Of Generative Models Through Adapter-based Finetuning"], ["bao2022vl", "Vl-beit: Generative Vision-language Pretraining"], ["singh2020are", "Are We Pretraining It Right? Digging Deeper Into Visio-linguistic Pretraining"], ["yu2022contrastive", "Coca: Contrastive Captioners Are Image-text Foundation Models"]]
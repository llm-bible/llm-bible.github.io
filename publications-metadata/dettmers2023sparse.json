[["frantar2022accurate", "GPTQ: Accurate Post-training Quantization For Generative Pre-trained Transformers"], ["huang2024pushing", "Billm: Pushing The Limit Of Post-training Quantization For Llms"], ["bondarenko2021understanding", "Understanding And Overcoming The Challenges Of Efficient Transformer Quantization"], ["xiao2022accurate", "Smoothquant: Accurate And Efficient Post-training Quantization For Large Language Models"]]
[["li2019unicoder", "Unicoder-vl: A Universal Encoder For Vision And Language By Cross-modal Pre-training"], ["meng2022generating", "Generating Training Data With Language Models: Towards Zero-shot Language Understanding"], ["wu2022little", "Noisytune: A Little Noise Can Help You Finetune Pretrained Language Models Better"], ["qi2020cross", "Imagebert: Cross-modal Pre-training With Large-scale Weak-supervised Image-text Data"]]
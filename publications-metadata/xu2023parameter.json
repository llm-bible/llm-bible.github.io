[["wang2022mixture", "Adamix: Mixture-of-adaptations For Parameter-efficient Model Tuning"], ["lialin2023scaling", "Scaling Down To Scale Up: A Guide To Parameter-efficient Fine-tuning"], ["hu2023llm", "Llm-adapters: An Adapter Family For Parameter-efficient Fine-tuning Of Large Language Models"], ["liu2022few", "Few-shot Parameter-efficient Fine-tuning Is Better And Cheaper Than In-context Learning"]]
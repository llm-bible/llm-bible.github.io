[["shayegani2023survey", "Survey Of Vulnerabilities In Large Language Models Revealed By Adversarial Attacks"], ["carlini2023are", "Are Aligned Neural Networks Adversarially Aligned?"], ["biderman2023emergent", "Emergent And Predictable Memorization In Large Language Models"], ["zhang2021counterfactual", "Counterfactual Memorization In Neural Language Models"]]
[["liu2020very", "Very Deep Transformers For Neural Machine Translation"], ["vaswani2017attention", "Attention Is All You Need"], ["ma2020xlm", "XLM-T: Scaling Up Multilingual Machine Translation With Pretrained Cross-lingual Transformer Encoders"], ["huang2020trans", "TRANS-BLSTM: Transformer With Bidirectional LSTM For Language Understanding"]]
[["hendrycks2020pretrained", "Pretrained Transformers Improve Out-of-distribution Robustness"], ["li2020closer", "A Closer Look At The Robustness Of Vision-and-language Pre-trained Models"], ["liu2020adversarial", "Adversarial Training For Large Neural Language Models"], ["wang2021adversarial", "Adversarial GLUE: A Multi-task Benchmark For Robustness Evaluation Of Language Models"]]
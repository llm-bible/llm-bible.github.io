[["samsi2023from", "From Words To Watts: Benchmarking The Energy Costs Of Large Language Model Inference"], ["zadeh2020quantizing", "GOBO: Quantizing Attention-based NLP Models For Low Latency And Energy Efficient Inference"], ["xu2022survey", "A Survey On Model Compression And Acceleration For Pretrained Language Models"], ["zhou2020bert", "BERT Loses Patience: Fast And Robust Inference With Early Exit"]]
[["eisenschlos2021multi", "MATE: Multi-view Attention For Table Transformer Efficiency"], ["liu2017table", "Table-to-text Generation By Structure-aware Seq2seq Learning"], ["chen2022large", "Large Language Models Are Few(1)-shot Table Reasoners"], ["ye2023large", "Large Language Models Are Versatile Decomposers: Decompose Evidence And Questions For Table-based Reasoning"]]
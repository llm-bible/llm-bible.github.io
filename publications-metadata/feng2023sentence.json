[["barkan2019scalable", "Scalable Attentive Sentence-pair Modeling Via Distilled Sentence Embedding"], ["ni2021sentence", "Sentence-t5: Scalable Sentence Encoders From Pre-trained Text-to-text Models"], ["cohan2019pretrained", "Pretrained Language Models For Sequential Sentence Classification"], ["zheng2020towards", "Towards Making The Most Of Context In Neural Machine Translation"]]
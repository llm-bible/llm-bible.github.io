[["ni2021sentence", "Sentence-t5: Scalable Sentence Encoders From Pre-trained Text-to-text Models"], ["ma2019universal", "Universal Text Representation From BERT: An Empirical Study"], ["barkan2019scalable", "Scalable Attentive Sentence-pair Modeling Via Distilled Sentence Embedding"], ["guo2018non", "Non-autoregressive Neural Machine Translation With Enhanced Decoder Input"]]
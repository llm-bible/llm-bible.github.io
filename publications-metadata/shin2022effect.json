[["whang2019effective", "An Effective Domain Adaptive Post-training Method For BERT In Response Selection"], ["xie2021explanation", "An Explanation Of In-context Learning As Implicit Bayesian Inference"], ["kim2021what", "What Changes Can Large-scale Language Models Bring? Intensive Study On Hyperclova: Billions-scale Korean Generative Pretrained Transformers"], ["singh2020are", "Are We Pretraining It Right? Digging Deeper Into Visio-linguistic Pretraining"]]
[["vari\u01612021sequence", "Sequence Length Is A Domain: Length-based Overfitting In Transformer Models"], ["levy2024same", "Same Task, More Tokens: The Impact Of Input Length On The Reasoning Performance Of Large Language Models"], ["hendy2023how", "How Good Are GPT Models At Machine Translation? A Comprehensive Evaluation"], ["weng2019acquiring", "Acquiring Knowledge From Pre-trained Model To Neural Machine Translation"]]
[["alizadeh2023llm", "LLM In A Flash: Efficient Large Language Model Inference With Limited Memory"], ["rajbhandari2019memory", "Zero: Memory Optimizations Toward Training Trillion Parameter Models"], ["narayanan2021efficient", "Efficient Large-scale Language Model Training On GPU Clusters Using Megatron-lm"], ["gholami2024ai", "AI And Memory Wall"]]
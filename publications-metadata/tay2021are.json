[["lukovnikov2020pretrained", "Pretrained Transformers For Simple Question Answering Over Knowledge Graphs"], ["tay2020long", "Long Range Arena: A Benchmark For Efficient Transformers"], ["chefer2021generic", "Generic Attention-model Explainability For Interpreting Bi-modal And Encoder-decoder Transformers"], ["poli2023hyena", "Hyena Hierarchy: Towards Larger Convolutional Language Models"]]
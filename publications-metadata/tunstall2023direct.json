[["lu2022ernie", "Ernie-search: Bridging Cross-encoder With Dual-encoder Via Self On-the-fly Distillation For Dense Passage Retrieval"], ["shleifer2020pre", "Pre-trained Summarization Distillation"], ["liu2019multi", "MKD: A Multi-task Knowledge Distillation Approach For Pretrained Language Models"], ["sahu2022data", "Data Augmentation For Intent Classification With Off-the-shelf Large Language Models"]]
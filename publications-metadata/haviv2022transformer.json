[["ke2020rethinking", "Rethinking Positional Encoding In Language Pre-training"], ["irie2019language", "Language Modeling With Deep Transformers"], ["kazemnejad2023impact", "The Impact Of Positional Encoding On Length Generalization In Transformers"], ["yang2021causal", "Causal Attention For Vision-language Tasks"]]
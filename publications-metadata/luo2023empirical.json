[["smith2022coda", "Coda-prompt: Continual Decomposed Attention-based Prompting For Rehearsal-free Continual Learning"], ["xu2019forget", "Forget Me Not: Reducing Catastrophic Forgetting For Domain Adaptation In Reading Comprehension"], ["zheng2023preventing", "Preventing Zero-shot Transfer Degradation In Continual Learning Of Vision-language Models"], ["scialom2022fine", "Fine-tuned Language Models Are Continual Learners"]]
[["zheng2023preventing", "Preventing Zero-shot Transfer Degradation In Continual Learning Of Vision-language Models"], ["liu2020exploring", "Exploring Fine-tuning Techniques For Pre-trained Cross-lingual Models Via Continual Learning"], ["smith2022coda", "Coda-prompt: Continual Decomposed Attention-based Prompting For Rehearsal-free Continual Learning"], ["kim2021scalable", "Scalable And Efficient Moe Training For Multitask Multilingual Models"]]
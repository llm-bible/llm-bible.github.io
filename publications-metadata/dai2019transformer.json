[["ding2020ernie", "Ernie-doc: A Retrospective Long-document Modeling Transformer"], ["htut2019do", "Do Attention Heads In BERT Track Syntactic Dependencies?"], ["kazemnejad2023impact", "The Impact Of Positional Encoding On Length Generalization In Transformers"], ["ahmad2020transformer", "A Transformer-based Approach For Source Code Summarization"]]
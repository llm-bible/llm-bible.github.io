[["xiao2022pre", "Retromae: Pre-training Retrieval-oriented Language Models Via Masked Auto-encoder"], ["zhu2020incorporating", "Incorporating BERT Into Neural Machine Translation"], ["dong2022masked", "Maskclip: Masked Self-distillation Advances Contrastive Language-image Pretraining"], ["li2019unicoder", "Unicoder-vl: A Universal Encoder For Vision And Language By Cross-modal Pre-training"]]
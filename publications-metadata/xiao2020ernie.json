[["dong2019unified", "Unified Language Model Pre-training For Natural Language Understanding And Generation"], ["an2022contrastive", "Cont: Contrastive Neural Text Generation"], ["qi2020predicting", "Prophetnet: Predicting Future N-gram For Sequence-to-sequence Pre-training"], ["schmidt2019generalization", "Generalization In Generation: A Closer Look At Exposure Bias"]]
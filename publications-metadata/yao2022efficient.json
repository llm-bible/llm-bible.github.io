[["xiao2022accurate", "Smoothquant: Accurate And Efficient Post-training Quantization For Large Language Models"], ["bondarenko2021understanding", "Understanding And Overcoming The Challenges Of Efficient Transformer Quantization"], ["huang2024pushing", "Billm: Pushing The Limit Of Post-training Quantization For Llms"], ["frantar2022accurate", "GPTQ: Accurate Post-training Quantization For Generative Pre-trained Transformers"]]
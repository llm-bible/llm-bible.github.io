[["li2021supervision", "Supervision Exists Everywhere: A Data Efficient Contrastive Language-image Pre-training Paradigm"], ["gao2021pre", "Condenser: A Pre-training Architecture For Dense Retrieval"], ["xu2023bridging", "Bridging Vision And Language Encoders: Parameter-efficient Tuning For Referring Image Segmentation"], ["song2022clip", "CLIP Models Are Few-shot Learners: Empirical Studies On VQA And Visual Entailment"]]
[["yang2023llm", "Llm-grounder: Open-vocabulary 3D Visual Grounding With Large Language Model As An Agent"], ["song2022clip", "CLIP Models Are Few-shot Learners: Empirical Studies On VQA And Visual Entailment"], ["parelli2023clip", "Clip-guided Vision-language Pre-training For Question Answering In 3D Scenes"], ["ni2021sentence", "Sentence-t5: Scalable Sentence Encoders From Pre-trained Text-to-text Models"]]
[["yu2023rlhf", "RLHF-V: Towards Trustworthy Mllms Via Behavior Alignment From Fine-grained Correctional Human Feedback"], ["huang2023survey", "A Survey On Hallucination In Large Language Models: Principles, Taxonomy, Challenges, And Open Questions"], ["li2023seed", "Seed-bench-2: Benchmarking Multimodal Large Language Models"], ["wang2023evaluation", "Evaluation And Analysis Of Hallucination In Large Vision-language Models"]]
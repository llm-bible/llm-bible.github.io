[["devlin2018pre", "BERT: Pre-training Of Deep Bidirectional Transformers For Language Understanding"], ["zhang2020when", "When Do You Need Billions Of Words Of Pretraining Data?"], ["huang2020trans", "TRANS-BLSTM: Transformer With Bidirectional LSTM For Language Understanding"], ["zhu2020incorporating", "Incorporating BERT Into Neural Machine Translation"]]
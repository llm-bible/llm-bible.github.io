[["ye2022unreliability", "The Unreliability Of Explanations In Few-shot Prompting For Textual Reasoning"], ["mohankumar2020towards", "Towards Transparent And Explainable Attention Models"], ["k2022can", "Can Language Models Learn From Explanations In Context?"], ["li2022explanations", "Explanations From Large Language Models Make Small Reasoners Better"]]
[["zhang2021cpm", "CPM-2: Large-scale Cost-effective Pre-trained Language Models"], ["wu2021one", "One Teacher Is Enough? Pre-trained Language Model Distillation From Multiple Teachers"], ["li2021pretrained", "Pretrained Language Models For Text Generation: A Survey"], ["taylor2022clinical", "Clinical Prompt Learning With Frozen Language Models"]]
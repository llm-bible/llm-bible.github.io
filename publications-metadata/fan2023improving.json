[["song2022clip", "CLIP Models Are Few-shot Learners: Empirical Studies On VQA And Visual Entailment"], ["chen2022altering", "Altclip: Altering The Language Encoder In CLIP For Extended Language Capabilities"], ["wang2022clip", "CLIP-TD: CLIP Targeted Distillation For Vision-language Tasks"], ["cui2022democratizing", "Democratizing Contrastive Language-image Pre-training: A CLIP Benchmark Of Data, Model, And Supervision"]]
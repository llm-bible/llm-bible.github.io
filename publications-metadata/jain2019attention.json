[["mohankumar2020towards", "Towards Transparent And Explainable Attention Models"], ["chrysostomou2021improving", "Improving The Faithfulness Of Attention-based Explanations With Task-specific Information For Text Classification"], ["bastings2020elephant", "The Elephant In The Interpretability Room: Why Use Attention As Explanation When We Have Saliency Methods?"], ["vashishth2019attention", "Attention Interpretability Across NLP Tasks"]]
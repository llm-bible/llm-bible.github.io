[["eisenschlos2021multi", "MATE: Multi-view Attention For Table Transformer Efficiency"], ["ye2023large", "Large Language Models Are Versatile Decomposers: Decompose Evidence And Questions For Table-based Reasoning"], ["parikh2020controlled", "Totto: A Controlled Table-to-text Generation Dataset"], ["chen2022large", "Large Language Models Are Few(1)-shot Table Reasoners"]]
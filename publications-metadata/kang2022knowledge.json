[["wu2022little", "Noisytune: A Little Noise Can Help You Finetune Pretrained Language Models Better"], ["wu2021one", "One Teacher Is Enough? Pre-trained Language Model Distillation From Multiple Teachers"], ["zhang2021cpm", "CPM-2: Large-scale Cost-effective Pre-trained Language Models"], ["chen2022transferability", "On The Transferability Of Pre-trained Language Models For Low-resource Programming Languages"]]
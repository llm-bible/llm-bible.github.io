[["bondarenko2021understanding", "Understanding And Overcoming The Challenges Of Efficient Transformer Quantization"], ["kim2023memory", "Memory-efficient Fine-tuning Of Compressed Large Language Models Via Sub-4-bit Integer Quantization"], ["frantar2022accurate", "GPTQ: Accurate Post-training Quantization For Generative Pre-trained Transformers"], ["park2022lut", "LUT-GEMM: Quantized Matrix Multiplication Based On Luts For Efficient Inference In Large-scale Generative Language Models"]]
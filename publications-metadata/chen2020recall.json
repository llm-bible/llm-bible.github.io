[["luo2023empirical", "An Empirical Study Of Catastrophic Forgetting In Large Language Models During Continual Fine-tuning"], ["tang2023when", "When Prompt-based Incremental Learning Does Not Meet Strong Pretraining"], ["singh2020are", "Are We Pretraining It Right? Digging Deeper Into Visio-linguistic Pretraining"], ["smith2022coda", "Coda-prompt: Continual Decomposed Attention-based Prompting For Rehearsal-free Continual Learning"]]
[["lauren\u00e7on2023bigscience", "The Bigscience ROOTS Corpus: A 1.6TB Composite Multilingual Dataset"], ["muennighoff2022crosslingual", "Crosslingual Generalization Through Multitask Finetuning"], ["hu2023llm", "Llm-adapters: An Adapter Family For Parameter-efficient Fine-tuning Of Large Language Models"], ["sanh2021multitask", "Multitask Prompted Training Enables Zero-shot Task Generalization"]]
[["li2021structural", "Structurallm: Structural Pre-training For Form Understanding"], ["hao2019modeling", "Modeling Recurrence For Transformer"], ["sun2023retentive", "Retentive Network: A Successor To Transformer For Large Language Models"], ["lei2021when", "When Attention Meets Fast Recurrence: Training Language Models With Reduced Compute"]]
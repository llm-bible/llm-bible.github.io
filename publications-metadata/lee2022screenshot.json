[["aghajanyan2021hyper", "HTLM: Hyper-text Pre-training And Prompting Of Language Models"], ["ye2023universal", "Ureader: Universal Ocr-free Visually-situated Language Understanding With Multimodal Large Language Model"], ["eisenschlos2021multi", "MATE: Multi-view Attention For Table Transformer Efficiency"], ["bao2022vl", "Vl-beit: Generative Vision-language Pretraining"]]
[["haviv2022transformer", "Transformer Language Models Without Positional Encodings Still Learn Positional Information"], ["irie2019language", "Language Modeling With Deep Transformers"], ["kazemnejad2023impact", "The Impact Of Positional Encoding On Length Generalization In Transformers"], ["liu2020survey", "A Survey On Contextual Embeddings"]]
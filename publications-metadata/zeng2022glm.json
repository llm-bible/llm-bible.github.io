[["wang2021ernie", "ERNIE 3.0 Titan: Exploring Larger-scale Knowledge Enhanced Pre-training For Language Understanding And Generation"], ["yao2022efficient", "Zeroquant: Efficient And Affordable Post-training Quantization For Large-scale Transformers"], ["frantar2022accurate", "GPTQ: Accurate Post-training Quantization For Generative Pre-trained Transformers"], ["zhang2020large", "CPM: A Large-scale Generative Chinese Pre-trained Language Model"]]
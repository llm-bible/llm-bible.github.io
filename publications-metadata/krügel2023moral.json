[["jin2022when", "When To Make Exceptions: Exploring Language Models As Accounts Of Human Moral Judgment"], ["ganguli2023capacity", "The Capacity For Moral Self-correction In Large Language Models"], ["schramowski2021large", "Large Pre-trained Language Models Contain Human-like Biases Of What Is Right And Wrong To Do"], ["almeida2023exploring", "Exploring The Psychology Of Llms' Moral And Legal Reasoning"]]
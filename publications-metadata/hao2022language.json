[["ma2021encoder", "Deltalm: Encoder-decoder Pre-training For Language Generation And Translation By Augmenting Pretrained Multilingual Encoders"], ["xu2022building", "Bridgetower: Building Bridges Between Encoders In Vision-language Representation Learning"], ["wang2022what", "What Language Model Architecture And Pretraining Objective Work Best For Zero-shot Generalization?"], ["wu2023next", "Next-gpt: Any-to-any Multimodal LLM"]]
[["chang2023text", "Muse: Text-to-image Generation Via Masked Generative Transformers"], ["ding2023scaling", "Longnet: Scaling Transformers To 1,000,000,000 Tokens"], ["mansimov2019generalized", "A Generalized Framework Of Sequence Generation With Application To Undirected Sequence Models"], ["ma2021linear", "Luna: Linear Unified Nested Attention"]]
[["huang2020trans", "TRANS-BLSTM: Transformer With Bidirectional LSTM For Language Understanding"], ["devlin2018pre", "BERT: Pre-training Of Deep Bidirectional Transformers For Language Understanding"], ["chen2019distilling", "Distilling Knowledge Learned In BERT For Text Generation"], ["xia2021using", "Using Prior Knowledge To Guide Bert's Attention In Semantic Textual Matching Tasks"]]
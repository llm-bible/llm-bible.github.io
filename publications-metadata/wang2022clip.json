[["song2022clip", "CLIP Models Are Few-shot Learners: Empirical Studies On VQA And Visual Entailment"], ["fan2023improving", "Improving CLIP Training With Language Rewrites"], ["cui2022democratizing", "Democratizing Contrastive Language-image Pre-training: A CLIP Benchmark Of Data, Model, And Supervision"], ["chen2022altering", "Altclip: Altering The Language Encoder In CLIP For Extended Language Capabilities"]]
[["xiao2021hallucination", "On Hallucination And Predictive Uncertainty In Conditional Language Generation"], ["desai2020calibration", "Calibration Of Pre-trained Transformers"], ["xiong2023can", "Can Llms Express Their Uncertainty? An Empirical Evaluation Of Confidence Elicitation In Llms"], ["tian2023just", "Just Ask For Calibration: Strategies For Eliciting Calibrated Confidence Scores From Language Models Fine-tuned With Human Feedback"]]
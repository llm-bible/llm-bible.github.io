[["carlini2023are", "Are Aligned Neural Networks Adversarially Aligned?"], ["robey2023defending", "Smoothllm: Defending Large Language Models Against Jailbreaking Attacks"], ["shayegani2023survey", "Survey Of Vulnerabilities In Large Language Models Revealed By Adversarial Attacks"], ["si2020better", "Better Robustness By More Coverage: Adversarial Training With Mixup Augmentation For Robust Fine-tuning"]]
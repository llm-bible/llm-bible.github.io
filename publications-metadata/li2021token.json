[["zeng2021pangu", "Pangu-\\(\u03b1\\): Large-scale Autoregressive Pretrained Chinese Language Models With Auto-parallel Computation"], ["narayanan2021efficient", "Efficient Large-scale Language Model Training On GPU Clusters Using Megatron-lm"], ["shoeybi2019megatron", "Megatron-lm: Training Multi-billion Parameter Language Models Using Model Parallelism"], ["sun2023retentive", "Retentive Network: A Successor To Transformer For Large Language Models"]]
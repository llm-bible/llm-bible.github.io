[["bi2020pre", "PALM: Pre-training An Autoencoding&autoregressive Language Model For Context-conditioned Generation"], ["zhou2019unified", "Unified Vision-language Pre-training For Image Captioning And VQA"], ["dong2019unified", "Unified Language Model Pre-training For Natural Language Understanding And Generation"], ["xiao2022pre", "Retromae: Pre-training Retrieval-oriented Language Models Via Masked Auto-encoder"]]
[["cui2022democratizing", "Democratizing Contrastive Language-image Pre-training: A CLIP Benchmark Of Data, Model, And Supervision"], ["rao2021language", "Denseclip: Language-guided Dense Prediction With Context-aware Prompting"], ["yu2020fine", "Fine-tuning Pre-trained Language Model With Weak Supervision: A Contrastive-regularized Self-training Approach"], ["song2022clip", "CLIP Models Are Few-shot Learners: Empirical Studies On VQA And Visual Entailment"]]
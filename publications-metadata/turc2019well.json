[["xu2020bert", "Bert-of-theseus: Compressing BERT By Progressive Module Replacing"], ["xia2022structured", "Structured Pruning Learns Compact And Accurate Models"], ["liu2019multi", "MKD: A Multi-task Knowledge Distillation Approach For Pretrained Language Models"], ["lu2022ernie", "Ernie-search: Bridging Cross-encoder With Dual-encoder Via Self On-the-fly Distillation For Dense Passage Retrieval"]]
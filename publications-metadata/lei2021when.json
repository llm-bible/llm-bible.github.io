[["hao2019modeling", "Modeling Recurrence For Transformer"], ["ding2020ernie", "Ernie-doc: A Retrospective Long-document Modeling Transformer"], ["vaswani2017attention", "Attention Is All You Need"], ["hutchins2022block", "Block-recurrent Transformers"]]
[["barkan2019scalable", "Scalable Attentive Sentence-pair Modeling Via Distilled Sentence Embedding"], ["kim2021self", "Self-guided Contrastive Learning For BERT Sentence Representations"], ["ni2021sentence", "Sentence-t5: Scalable Sentence Encoders From Pre-trained Text-to-text Models"], ["wang2019bert", "BERT Has A Mouth, And It Must Speak: BERT As A Markov Random Field Language Model"]]
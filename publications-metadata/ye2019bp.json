[["ma2021linear", "Luna: Linear Unified Nested Attention"], ["choi2018fine", "Fine-grained Attention Mechanism For Neural Machine Translation"], ["dao2023flashattention", "Flashattention-2: Faster Attention With Better Parallelism And Work Partitioning"], ["zhao2019explicit", "Explicit Sparse Transformer: Concentrated Attention Through Explicit Selection"]]
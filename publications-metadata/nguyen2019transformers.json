[["shleifer2021improved", "Normformer: Improved Transformer Pretraining With Extra Normalization"], ["liu2020very", "Very Deep Transformers For Neural Machine Translation"], ["gu2017non", "Non-autoregressive Neural Machine Translation"], ["vaswani2017attention", "Attention Is All You Need"]]
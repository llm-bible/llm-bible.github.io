[["petrov2023language", "Language Model Tokenizers Introduce Unfairness Between Languages"], ["lowphansirikul2021pretraining", "Wangchanberta: Pretraining Transformer-based Thai Language Models"], ["bostrom2020byte", "Byte Pair Encoding Is Suboptimal For Language Model Pretraining"], ["choe2019bridging", "Bridging The Gap For Tokenizer-free Language Models"]]
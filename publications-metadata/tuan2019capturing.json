[["prabhumoye2021focused", "Focused Attention Improves Document-grounded Generation"], ["yu2022generate", "Generate Rather Than Retrieve: Large Language Models Are Strong Context Generators"], ["maruf2019selective", "Selective Attention For Context-aware Neural Machine Translation"], ["wang2017joint", "A Joint Model For Question Answering And Question Generation"]]
[["liu2020very", "Very Deep Transformers For Neural Machine Translation"], ["choi2018fine", "Fine-grained Attention Mechanism For Neural Machine Translation"], ["voita2019analyzing", "Analyzing Multi-head Self-attention: Specialized Heads Do The Heavy Lifting, The Rest Can Be Pruned"], ["meng2016interactive", "Interactive Attention For Neural Machine Translation"]]
[["liu2019robustly", "Roberta: A Robustly Optimized BERT Pretraining Approach"], ["kim2019probing", "Probing What Different NLP Tasks Teach Machines About Function Word Comprehension"], ["korbak2023pretraining", "Pretraining Language Models With Human Preferences"], ["cheng2022recipe", "Vindlu: A Recipe For Effective Video-and-language Pretraining"]]
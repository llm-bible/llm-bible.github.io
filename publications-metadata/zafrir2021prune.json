[["zhao2019explicit", "Explicit Sparse Transformer: Concentrated Attention Through Explicit Selection"], ["li2020efficient", "Efficient Transformer-based Large Scale Language Representations Using Hardware-friendly Block Structured Pruning"], ["kurtic2022optimal", "The Optimal BERT Surgeon: Scalable And Accurate Second-order Pruning For Large Language Models"], ["lee2019contextualized", "Contextualized Sparse Representations For Real-time Open-domain Question Answering"]]
[["ramamurthy2022is", "Is Reinforcement Learning (not) For Natural Language Processing: Benchmarks, Baselines, And Building Blocks For Natural Language Policy Optimization"], ["song2023preference", "Preference Ranking Optimization For Human Alignment"], ["rafailov2023direct", "Direct Preference Optimization: Your Language Model Is Secretly A Reward Model"], ["sun2023aligning", "Aligning Large Multimodal Models With Factually Augmented RLHF"]]
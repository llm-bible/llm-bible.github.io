[["cui2022democratizing", "Democratizing Contrastive Language-image Pre-training: A CLIP Benchmark Of Data, Model, And Supervision"], ["li2021supervision", "Supervision Exists Everywhere: A Data Efficient Contrastive Language-image Pre-training Paradigm"], ["song2022clip", "CLIP Models Are Few-shot Learners: Empirical Studies On VQA And Visual Entailment"], ["fan2023improving", "Improving CLIP Training With Language Rewrites"]]
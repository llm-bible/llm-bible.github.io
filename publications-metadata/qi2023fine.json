[["sun2023safety", "Safety Assessment Of Chinese Large Language Models"], ["wei2023how", "Jailbroken: How Does LLM Safety Training Fail?"], ["zeng2024how", "How Johnny Can Persuade Llms To Jailbreak Them: Rethinking Persuasion To Challenge AI Safety By Humanizing Llms"], ["thoppilan2022language", "Lamda: Language Models For Dialog Applications"]]
[["ma2021linear", "Luna: Linear Unified Nested Attention"], ["vari\u01612021sequence", "Sequence Length Is A Domain: Length-based Overfitting In Transformer Models"], ["poli2023hyena", "Hyena Hierarchy: Towards Larger Convolutional Language Models"], ["zhao2019parallel", "MUSE: Parallel Multi-scale Attention For Sequence To Sequence Learning"]]
[["hu2021low", "Lora: Low-rank Adaptation Of Large Language Models"], ["mehta2020deep", "Delight: Deep And Light-weight Transformer"], ["wang2022mixture", "Adamix: Mixture-of-adaptations For Parameter-efficient Model Tuning"], ["wang2022position", "Position-guided Text Prompt For Vision-language Pre-training"]]
[["dou2021empirical", "An Empirical Study Of Training End-to-end Vision-and-language Transformers"], ["tiong2022plug", "Plug-and-play VQA: Zero-shot VQA By Conjoining Large Pretrained Models With Zero Training"], ["dou2022coarse", "Coarse-to-fine Vision-language Pre-training With Fusion In The Backbone"], ["fang2021compressing", "Compressing Visual-linguistic Model Via Knowledge Distillation"]]
[["wang2022exploring", "Exploring The Limits Of Domain-adaptive Training For Detoxifying Large-scale Language Models"], ["mallen2022when", "When Not To Trust Language Models: Investigating Effectiveness Of Parametric And Non-parametric Memories"], ["madaan2022language", "Language Models Of Code Are Few-shot Commonsense Learners"], ["liu2018efficient", "Efficient Contextualized Representation: Language Model Pruning For Sequence Labeling"]]
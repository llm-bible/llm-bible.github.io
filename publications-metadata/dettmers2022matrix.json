[["park2022lut", "LUT-GEMM: Quantized Matrix Multiplication Based On Luts For Efficient Inference In Large-scale Generative Language Models"], ["xiao2022accurate", "Smoothquant: Accurate And Efficient Post-training Quantization For Large Language Models"], ["bondarenko2021understanding", "Understanding And Overcoming The Challenges Of Efficient Transformer Quantization"], ["dettmers2023sparse", "Spqr: A Sparse-quantized Representation For Near-lossless LLM Weight Compression"]]
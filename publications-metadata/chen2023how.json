[["li2020closer", "A Closer Look At The Robustness Of Vision-and-language Pre-trained Models"], ["hendrycks2020pretrained", "Pretrained Transformers Improve Out-of-distribution Robustness"], ["wang2023robustness", "On The Robustness Of Chatgpt: An Adversarial And Out-of-distribution Perspective"], ["moradi2021evaluating", "Evaluating The Robustness Of Neural Language Models To Input Perturbations"]]
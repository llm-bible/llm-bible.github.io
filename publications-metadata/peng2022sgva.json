[["fu2020lrc", "LRC-BERT: Latent-representation Contrastive Knowledge Distillation For Natural Language Understanding"], ["liu2019multi", "MKD: A Multi-task Knowledge Distillation Approach For Pretrained Language Models"], ["sohn2022visual", "Visual Prompt Tuning For Generative Transfer Learning"], ["gao2021clip", "Clip-adapter: Better Vision-language Models With Feature Adapters"]]
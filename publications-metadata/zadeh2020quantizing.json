[["bondarenko2021understanding", "Understanding And Overcoming The Challenges Of Efficient Transformer Quantization"], ["kim2021i", "I-BERT: Integer-only BERT Quantization"], ["tambe2020sentence", "Edgebert: Sentence-level Energy Optimizations For Latency-aware Multi-task NLP Inference"], ["xiao2022accurate", "Smoothquant: Accurate And Efficient Post-training Quantization For Large Language Models"]]
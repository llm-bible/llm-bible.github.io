[["xu2024when", "When Large Language Model Agents Meet 6G Networks: Perception, Grounding, And Alignment"], ["xu2022survey", "A Survey On Model Compression And Acceleration For Pretrained Language Models"], ["dettmers2023sparse", "Spqr: A Sparse-quantized Representation For Near-lossless LLM Weight Compression"], ["kim2023memory", "Memory-efficient Fine-tuning Of Compressed Large Language Models Via Sub-4-bit Integer Quantization"]]
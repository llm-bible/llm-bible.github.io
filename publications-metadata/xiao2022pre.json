[["lu2021less", "Less Is More: Pre-train A Strong Text Encoder For Dense Retrieval Using A Weak Decoder"], ["bao2022vl", "Vl-beit: Generative Vision-language Pretraining"], ["song2019masked", "MASS: Masked Sequence To Sequence Pre-training For Language Generation"], ["barkan2019scalable", "Scalable Attentive Sentence-pair Modeling Via Distilled Sentence Embedding"]]
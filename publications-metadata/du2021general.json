[["fei2023unifying", "Lasuie: Unifying Information Extraction With Latent Adaptive Structure-aware Generative Language Model"], ["guo2020incorporating", "Incorporating BERT Into Parallel Sequence Decoding With Adapters"], ["zhang2020when", "When Do You Need Billions Of Words Of Pretraining Data?"], ["wang2022what", "What Language Model Architecture And Pretraining Objective Work Best For Zero-shot Generalization?"]]
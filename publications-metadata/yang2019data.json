[["kumar2020data", "Data Augmentation Using Pre-trained Transformer Models"], ["wang2019multi", "Multi-passage BERT: A Globally Normalized BERT Model For Open-domain Question Answering"], ["wang2017reinforced", "R\\(^3\\): Reinforced Reader-ranker For Open-domain Question Answering"], ["longpre2020how", "How Effective Is Task-agnostic Data Augmentation For Pretrained Transformers?"]]
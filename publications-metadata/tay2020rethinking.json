[["tay2020long", "Long Range Arena: A Benchmark For Efficient Transformers"], ["hofst\u00e4tter2020improving", "Improving Efficient Neural Ranking Models With Cross-architecture Knowledge Distillation"], ["liang2023encouraging", "Encouraging Divergent Thinking In Large Language Models Through Multi-agent Debate"], ["jain2019attention", "Attention Is Not Explanation"]]
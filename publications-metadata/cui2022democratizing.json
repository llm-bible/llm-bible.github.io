[["li2021supervision", "Supervision Exists Everywhere: A Data Efficient Contrastive Language-image Pre-training Paradigm"], ["song2022clip", "CLIP Models Are Few-shot Learners: Empirical Studies On VQA And Visual Entailment"], ["fan2023improving", "Improving CLIP Training With Language Rewrites"], ["wang2022clip", "CLIP-TD: CLIP Targeted Distillation For Vision-language Tasks"]]
[["li2020unsupervised", "Unsupervised Vision-and-language Pre-training Without Parallel Images And Captions"], ["parcalabescu2020seeing", "Seeing Past Words: Testing The Cross-modal Capabilities Of Pretrained V&L Models On Counting Tasks"], ["ramos2023retrieval", "Retrieval-augmented Image Captioning"], ["zhang2021tip", "Tip-adapter: Training-free Clip-adapter For Better Vision-language Modeling"]]
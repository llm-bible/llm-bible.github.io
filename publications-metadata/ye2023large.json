[["chen2022large", "Large Language Models Are Few(1)-shot Table Reasoners"], ["eisenschlos2021multi", "MATE: Multi-view Attention For Table Transformer Efficiency"], ["talmor2021complex", "Multimodalqa: Complex Question Answering Over Text, Tables And Images"], ["yin2020pretraining", "Tabert: Pretraining For Joint Understanding Of Textual And Tabular Data"]]
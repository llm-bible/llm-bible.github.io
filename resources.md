---
layout: default
title: Resources on Large Language Models
---

## Blog Posts

- [LLM Powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent/): A deep dive into how large language models are powering the next generation of autonomous agents, enabling systems to perform complex tasks with minimal human input.

- [Google "We Have No Moat, And Neither Does OpenAI"](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither): Leaked internal Google document discussing the competitive landscape of AI and arguing that neither Google nor OpenAI have sustainable competitive advantages in the long term.

- [Prompt Engineering](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/): An introduction to prompt engineering techniques, providing guidelines on how to effectively interact with large language models to obtain the best results.

- [How does GPT Obtain its Ability? Tracing Emergent Abilities of Language Models to their Sources](https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1): This article investigates how GPT models acquire their emergent abilities, tracing them back to the training data and architectures used.

- [Why did all of the public reproduction of GPT-3 fail?](https://jingfengyang.github.io/gpt): This post explores the difficulties and challenges researchers faced when attempting to reproduce the capabilities of GPT-3, offering insights into why these efforts largely fell short.

## Courses on Large Language Models (LLMs)

Below is a collection of university and online courses that offer a deep dive into the concepts, tools, and applications of Large Language Models (LLMs). These courses range from theoretical foundations to practical applications in business and data science.

### University Courses

1. [Stanford University - TECH 16: Large Language Models for Business with Python](https://continuingstudies.stanford.edu/courses/professional-and-personal-development/large-language-models-for-business-with-python/20232_TECH-16): This course covers the use of LLMs in business applications, with a focus on practical programming with Python. Students learn how to integrate LLMs into business processes to drive innovation and efficiency.

2. [ETH Zürich - 263-5354-00L: Large Language Models](https://rycolab.io/classes/llm-s23/): Focused on the theoretical underpinnings and current developments of LLMs, this course covers a broad range of topics from model training to application.

3. [University of Toronto - COMP790-101: Large Language Models](https://github.com/craffel/llm-seminar): This seminar-style course reviews the latest research on LLMs, covering both foundational knowledge and emerging trends in their development.

### Online Courses

1. [Coursera - Natural Language Processing with Transformers](https://www.coursera.org/learn/transformers): This course introduces transformers, which are the foundation of modern LLMs. It focuses on using transformers for various NLP tasks such as text classification, summarization, and translation.

2. [DataCamp - Transformer Models for NLP](https://www.datacamp.com/courses/transformer-models-for-nlp): Learn how to leverage transformer models to perform advanced natural language processing tasks with hands-on coding exercises in Python.

3. [Udemy - GPT-3 and OpenAI API: A Guide for Building LLM-Powered Applications](https://www.udemy.com/course/gpt3-openai-api/): This course provides practical insights into using GPT-3 and OpenAI’s API to build applications that utilize LLMs, with a focus on creating conversational agents and content generation.

4. [DeepLearning.AI - Generative AI with Large Language Models](https://www.deeplearning.ai/courses/generative-ai-with-llms/): This course from DeepLearning.AI covers the key concepts of generative AI, with a particular focus on LLMs. It includes hands-on practice in fine-tuning LLMs, prompt engineering, and applying these models to real-world use cases.
  
## Tools & Packages

- [LangChain](https://python.langchain.com/docs/get_started/introduction): A framework for building LLM-powered applications with modular integrations, memory, and chaining prompts.

- [LlamaIndex](https://gpt-index.readthedocs.io/en/latest/): Connects LLMs with external data like documents and databases, ideal for knowledge-augmented applications.

- [Dyson](https://github.com/turing-technologies/dyson): Enables dynamic instruction tuning and fine-tuning of LLMs with custom prompts and instructions.

- [LangGraph](https://github.com/langchain-ai/langgraph): Integrates LLMs with graph-based data, enhancing structured data querying and reasoning.

- [DeepSpeed](https://www.deepspeed.ai/): Optimizes large model training with techniques like ZeRO, quantization, and memory efficiency.

- [Hugging Face Transformers](https://huggingface.co/docs/transformers): Provides tools for using, fine-tuning, and deploying transformer models like GPT and BERT.

- [OpenRouter](https://openrouter.ai/): An open-source alternative for routing prompts through multiple LLM APIs like GPT-4 and Claude.

- [Guidance](https://github.com/guidance-ai/guidance): A library to guide and structure LLM outputs programmatically for complex tasks.

- [Haystack](https://haystack.deepset.ai/overview/intro): A framework for building scalable LLM-powered search and retrieval systems, including RAG pipelines.

- [FastRAG](https://github.com/IntelLabs/fastRAG): Efficient framework for low-latency, scalable Retrieval-Augmented Generation (RAG) pipelines.

- [DSPy](https://github.com/stanfordnlp/dspy): A library that allows you to optimize prompts and LLM outputs through programmatic evaluation.

### Books

1. [Deep Learning](https://www.deeplearningbook.org/) by Ian Goodfellow, Yoshua Bengio, and Aaron Courville: A foundational book that covers the principles of deep learning. It provides theoretical insights and practical applications, making it essential for understanding the building blocks of LLMs.

2. [Natural Language Processing with Transformers](https://www.oreilly.com/library/view/natural-language-processing/9781098136789/) by Lewis Tunstall, Leandro von Werra, and Thomas Wolf: This book offers a practical guide to using transformer models for NLP tasks, with a focus on tools like Hugging Face's libraries. It’s a great resource for anyone working with modern LLMs.

3. [Transformers for Natural Language Processing](https://www.packtpub.com/en-us/product/transformers-for-natural-language-processing-9781800565791?srsltid=AfmBOooDVYPilamoz-i2YbaiP8K2QrslJGiP-QAy37HSb-iR0WdbsSdy) by Denis Rothman: This book provides an in-depth look at transformer models, from BERT to GPT-3, and explains how to implement them for a variety of NLP tasks.

4. [GPT-3: Building Innovative NLP Products Using Large Language Models](https://www.amazon.co.uk/Gpt-3-Building-Innovative-Products-Language/dp/1098113624) by Sandra Kublik, Shubham Saboo, and Dhaval Pattani: A hands-on guide for building applications using GPT-3, covering everything from prompt engineering to integrating GPT-3 into real-world products.

5. [Neural Networks and Deep Learning][(http://neuralnetworksanddeeplearning.com/) by Michael Nielsen: A classic introduction to neural networks and deep learning, providing a step-by-step guide to building and understanding deep models, which serve as the foundation for LLMs.

6. [Hands-On Large Language Models: Language Understanding and Generation ](https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/): provides practical tools for using LLMs in tasks like copywriting, summarization, and semantic search. It covers transformer architecture, generative models, and fine-tuning techniques to optimize LLMs for specific applications.

### Other Collections of Related Work

1. [Awesome-LLM: a curated list of Large Language Mode](https://github.com/Hannibal046/Awesome-LLM): A comprehensive and well-maintained repository that curates resources, papers, tools, and frameworks related to Large Language Models (LLMs). It covers a wide range of topics including model architectures, training techniques, and applications.

Please, feel free to submit a [contribution](Contributions.html) to adding more links in this page.
